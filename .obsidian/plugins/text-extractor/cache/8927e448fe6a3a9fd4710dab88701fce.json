{"path":"Books and Papers/Thermodynamics & Statistical Mechanics/Daniel J. Amit, Yosef Verbin, Rami Tzafriri - Statistical physics_ an introductory course-World Scientific Publishing Company (1999).pdf","text":"This Page Intentionally Left BlankPublished by World Scientific Publishing Co. Pte. Ltd. P O Box 128, Farrer Road, Singapore 912805 USA office: Suite 1B, 1060 Main Street, River Edge, NJ 07661 UK office: 57 Shelton Street, Covent Garden, London WC2H 9HE Printed in Singapore. For photocopying of material in this volume, please pay a copying fee through the Copyright Clearance Center, Inc., 222 Rosewood Drive, Danvers, MA 01923, USA. In this case permission to photocopy is not required from the publisher. All rights reserved. This book, or parts thereof, may not be reproduced in any form or by any means, electronic or mechanical, including photocopying, recording or any information storage and retrieval system now known or to be invented, without written permission from the Publisher. Copyright © 1999 by World Scientific Publishing Co. Pte. Ltd. Library of Congress Cataloging-in-Publication Data Amit, D. J., 1938– Statistical physics : an introductory course / Daniel J. Amit, Yosef Verbin; translated from the Hebrew by Rarni Tzafriri. p. cm. Includes index. ISBN 981023192X -- ISBN 9810234767 (sc) 1. Statistical physics. I. Verbin, Yosef. II. Title. QC174.8.A45 1999 530.13--dc21 99-057215 British Library Cataloguing-in-Publication Data A catalogue record for this book is available from the British Library. First published in Hebrew in 1995 by The Open University of Israel. Contents Preface xi Part I The Kinetic Theory of Gases 1 Introduction 3 Chapter 1 Velocity and Position Distributions of Molecules in a Gas 6 1.1 Avogadro’s law, or the equation of state of an ideal gas 1.2 Temperature and thermal equilibrium 9 1.3 Equipartition of energy per molecule and its constituent parts — a fundamental problem 13 1.4 The density in an isothermal atmosphere — the Boltzmann factor in the potential energy 20 1.5 The Maxwell–Boltzmann distribution 24 1.6 Averages and distributions 28 Chapter 2 Brownian Motion 32 2.1 Historical background 32 2.2 Characteristic scales of Brownian motion 33 2.3 Random walk 35 2.4 Brownian motion, random force and friction: the Langevin equation 37 2.5 Solvingthe Langevin equation: approximations and orders of magnitude 41 2.6 Applications and implications 44 Chapter 3 Transport Coeﬃcients 49 3.1 Introduction 49 3.2 The mean free path and mean free time 50 3.3 Self-diﬀusion 56 3.4 The mobility coeﬃcient 61 3.5 The connection between the diﬀusion coeﬃcient and the mobility 63 3.6 Viscosity and thermal conductivity 64 3.7 Appendix: a more detailed calculation of the diﬀusion coeﬃcient 68 Self-assessment exercises 71 v vi Contents Solutions to exercises in the text 74 Solutions to self-assessment exercises 107 Part II Statistical Physics with Paramagnets 119 Introduction 121 Chapter 0 Essential Background in Thermodynamics 124 0.1 The ﬁrst law 124 0.2 The second law and the entropy 128 0.3 Thermodynamic potentials 129 0.4 The third law 133 Chapter 1 Thermodynamics with Magnetic Variables 134 1.1 Introduction 134 1.2 The ﬁrst law in magnetic variables 136 Chapter 2 Microscopic States and Averages 138 2.1 Magnetic states, angular momentum and paramagnetism 138 2.2 Microscopic states, observables 141 2.3 Probabilities and averages 143 Chapter 3 Isolated Paramagnet — Microcanonical Ensemble 147 3.1 Number of states and probabilities 147 3.2 Calculatingaverages and correlations 149 3.3 Numerical examples and Stirling’s formula 152 Chapter 4 Isolated Paramagnet — Subsystems and Temperature 156 4.1 Microscopic states and thermodynamic equilibrium 156 4.2 β and the temperature 157 4.3 Sharpness of the maximum 158 4.4 Identiﬁcation of temperature and entropy 161 4.5 Negative temperature 163 4.6 Summary 164 Chapter 5 Paramagnet at a Given Temperature 165 5.1 The canonical ensemble 165 5.2 The partition function and thermodynamic quantities 167 5.3 Susceptibility and speciﬁc heat of a paramagnet 170 5.4 Paramagnet with J> 1/2 173 Contents vii Chapter 6 Order, Disorder and Entropy 174 Chapter 7 Comparison with Experiment 177 Summary 178 Self-assessment exercises 180 Solutions to exercises in the text 183 Solutions to self-assessment exercises 213 Part III Statistical Physics and Thermodynamics 223 Introduction 225 Chapter 1 The Canonical Ensemble and Thermodynamics 226 1.1 The partition function and the internal energy 226 1.2 Thermodynamic work 228 1.3 Entropy, free energy, the ﬁrst and second laws 233 1.4 The paramagnet — revisited 236 1.5 On the statistical meaningof the free energy 237 Chapter 2 Harmonic Oscillator and Einstein Solid 243 2.1 Microscopic states 243 2.2 Partition function for oscillators 245 2.3 Einstein’s solid 248 Chapter 3 Statistical Mechanics of Classical Systems 253 3.1 Statistical mechanics of a single particle 253 3.2 Statistical mechanics of a classical gas 258 Chapter 4 Statistical Mechanics of an Ideal Gas 261 4.1 The ideal gas 261 4.2 Mixtures of ideal gases — Dalton’s law 263 4.3 Maxwell–Boltzmann distribution and equipartition 265 4.4 Ideal gas of quantum particles 268 Chapter 5 The Gibbs Paradox and the Third Law 275 5.1 Two diﬃculties 275 5.2 The Gibbs paradox and its resolution 276 5.3 Remarks on the third law of thermodynamics 281 5.4 Summary 283 viii Contents Chapter 6 Fluctuations and Thermodynamic Quantities 284 6.1 Paramagnet: ﬂuctuations in the magnetization 284 6.2 Energy ﬂuctuations and the speciﬁc heat 286 6.3 Summary 287 Self-assessment exercises 288 Solutions to exercises in the text 292 Solutions to self-assessment exercises 322 Part IV From Ideal Gas to Photon Gas 337 Introduction 339 Chapter 1 An Ideal Gas of Molecules with Internal Degrees of Freedom 340 1.1 Center of mass and internal motions 340 1.2 Kinematics of a diatomic molecule 342 1.3 Gas of general composite molecules 346 1.4 Diatomic gas: classical treatment 352 1.5 Diatomic molecules: vibration and rotation 356 1.6 The equipartition principle and its violation 361 1.7 Diatomic gas — quantum calculation 363 Chapter 2 Gases in Chemical Reactions 366 2.1 Conditions for chemical equilibrium 366 2.2 The law of mass action 368 2.3 Dissociation in a diatomic gas 373 Chapter 3 Phonon Gas and the Debye Model 376 3.1 Sound waves in a crystal 376 3.2 Vibrational modes, phonons and enumeration of states 379 3.3 The Debye model 382 Chapter 4 Thermodynamics of Electromagnetic Radiation 385 4.1 General considerations of radiation at thermal equilibrium 385 4.2 Radiation density 387 4.3 Black body radiation 390 4.4 Absorption and emission of radiation — Kirchhoﬀ’s law 394 4.5 Role of black body radiation in modern physics 398 Appendix Calculation of Some Integrals 401 Contents ix Self-assessment exercises 403 Solutions to exercises in the text 406 Solutions to self-assessment exercises 434 Part V Of Fermions and Bosons 451 Introduction 453 Chapter 1 Grand Canonical Ensemble 454 1.1 Deﬁnitions and motivation 454 1.2 Connection to thermodynamics 455 Chapter 2 Statistical Mechanics of Identical Quantum Particles 458 2.1 Classiﬁcation of states — occupation numbers 458 2.2 Quantum statistics — many-particle states 460 2.3 Thermodynamics of fermions and bosons 461 2.4 Average occupation numbers 463 Chapter 3 Electrical Conductivity in Metals 466 3.1 The Drude model 466 3.2 A critique of the Drude model 470 3.3 The Sommerfeld model 471 3.4 Electrons at high and low temperatures 474 3.5 Metals at room temperature 478 3.6 Thermodynamics of the Sommerfeld model 479 Chapter 4 Boson Gas 485 4.1 Bose–Einstein distribution 485 4.2 Chemical potential at low temperatures 486 4.3 Bose–Einstein condensation 488 4.4 Superﬂuidity 490 4.5 Bose–Einstein condensation in helium 493 4.6 Viscosity of a superﬂuid 497 4.7 Fermi liquid and superconductivity 503 Appendix Calculation of Some Integrals 509 Self-assessment exercises 512 Solutions to exercises in the text 514 Solutions to self-assessment exercises 536 Index 547 This Page Intentionally Left Blank Preface This book is an introduction to statistical physics aimed at undergraduate students in physics and engineering. It may also serve as a reference for graduate students and researchers. The fact that thermodynamics and statistical physics have a very wide domain of relevance and validity, as well as a very longtradition, often leads to abstract and axiomatic presentations even for beginners. We have chosen the opposite direction, namely to discuss the key ideas and methods through concrete representative systems, and to treat general ideas as casual by-products. This choice is expressed already in the structure of the book, consistingof ﬁve parts: (I) The Kinetic Theory of Gases;(II) Statistical Physics with Paramagnets; (III) Statistical Physics and Thermodynamics, which deals with the Einstein solid and monoatomic ideal gases; (IV) From Ideal Gas to Photon Gas, which covers also equilibrium of chemical reactions and the Debye model; (V) Of Fermions and Bosons. This approach runs the pedagogical risk that a casual reader may form the im- pression that he is facinga limited set of special cases. We confront this pitfall technically, by introducingexplicit remarks about the generality of results at ap- propriate places; methodologically, by accumulating enough applications for every major idea to make its validity and generality stand out; and philosophically, ob- servingthat physics moves forward most of its ideas by analogies to cleverly chosen simple systems for which profound intuitions have been formed. Originally this text was the backbone of a course in statistical physics at the Open University of Israel, which is a university for education at a distance. As such, it is vital to provide the student with a text that not only presents the material clearly, but also stimulates him or her to a higher state of active participation, to replace frontal study. This is achieved by insertinga large number of tasks (exercises) into the body of the text. They are aimed at maintainingcontact with the experience of the student, either by numerical examples or by rederivinga result in a new way. They are also intended to reduce the amount of inattentive reading, by systematic insertions of break-points. Exercises of a second type serve as corollary applications of newly introduced methods and techniques. A third type ﬁlls the gaps left (intentionally) in the process of many derivations. In some places we have preferred not to break the ﬂow of reasoning, introducing ﬁrst the result and only then the correspondingexercise which calls for the reader to complete the details. Thus, a little patience is required at least at the outset. In order to raise further the level of active involvement, each part is followed by several “self-assessment” exercises which are generally more extensive and of higher level than the ones in the text. They require frequently an ability to integrate ideas and methods from several parts of the course. The last — and very important — component is the detailed solutions to all exercises of all types, at the end of each part, which should contribute signiﬁcantly to a successful study. xi xii Preface After the ﬁrst Hebrew edition was used for about ten years, a second edition was published and is still in use by the Open University. It is this revised and extended version that we now make available to a wider audience. This volume is mainly a translation of the second Hebrew edition, but includes further revisions, additions and updates and should be considered a third edition of the text. The material of this text corresponds to a semester’s course, preferably in a sec- ond year. It assumes a prior acquaintance with calculus, basic mechanics, electricity and magnetism and modern physics, as well as some familiarity with thermodynamic concepts. Usually, a statistical physics course is taken after thermodynamics. How- ever, we felt that the text would be more self-contained if a brief compendium of thermodynamic concepts and methods was introduced for coherence with the rest of the text. This led to Chap. 0 of Part II. A ﬁnal word concerningnotation and units. We have adopted the convention of bold letters for vectors and italics for their absolute value or other scalars. Thus we write, for example, |v| = v. As for units we follow the increasingtendency towards the SI (International System), based on the metric system. However, this convention is used in moderation and we allow, from time to time, other commonly used units, like electron volt (eV) as an energy scale for atomic systems or atmosphere for pressure. The deviations from the SI are particularly pronounced in dealingwith magnetic systems. In that case we have chosen to avoid the confusion caused by attributingdiﬀerent units to the magnetic quantities B, H and M, and have adhered to the cgs system. This book has beneﬁted from the many fruitful suggestions and comments by col- leagues, students and reviewers associated with the three editions, including Daniel Bar, David J. Bergman, Rachel Danor, Yossef Dothan, Ofer Eyal, Aharon Kapit- ulnik, Yoram Kirsh, Ora Maor-Bareket, Guy Sella, Yonathan Shapir, Haim Shinar and Shmuel Weiss. The book would not have taken its present form without their help. Daniel Amit and Yosef Verbin Rome and Tel-Aviv, June 1999 Part I The Kinetic Theory of Gases This Page Intentionally Left Blank Introduction The theoretical transition from mechanics to the properties of matter is complex as well as technically difficult. Major parts of it are ever-expanding research subjects. In principle, given the laws of dynamics - classical or quantum-mechanical - and a model of the forces acting between the constituent parts of the material, we can determine all that is fit to be determined about the system. Its properties, i.e. material properties, are subject to computation - if the initial conditions are given as well, of course. However, a moment’s reflection is sufficient to make one realize that this is not the right approach. The attempt to characterize initial conditions for a macroscopic system, such as 1O23electrons in a cubic centimeter of metal, or to solve dif- ferential equations, is bound to convince one that this is technically impossible. A more profound reason for abandoning this approach is the fact that the duration of a typical experiment (or measurement) on a macroscopic system is very long compared to times during which the system changes on a microscopic scale. For example, let us calculate the average number of collisions of a gas molecule in an experiment that lasts s. Suppose that the density of the gas is and that it is maintained at a relatively low temperature, 100 K. If we assume that the mass of the molecule is about kg, then its typical speed is about m At the given density the typical distance between molecules is m, so that a molecule will collide approximately once every s. Hence, the ratio between the duration of the experiment and the average time between collisions is of order That is to say, during the experiment the system passes over a huge number of states. What is measured in the experiment is, actually, an average of all these states. The detailed dynamical transitions from one state to another are not only technically difficult to follow, but also uninteresting. Classical thermodynamics demonstrates the above consideration in its extreme form. Not only is the detailed dynamical evolution of the system discarded, but the 3 4 Introduction entire dynamical model. here stems the vast power of thermodynamics, and also the source of its weakness. Its power lies in its generality, which has withstood to date the upheavals of dynamics particles, continuum, fields, relativity and quantum mechanics. Its weakness is the lack of detail and its restriction to equilib- rium states (or to near equilibrium states; the thermodynamics of states that are far from equilibrium is an important research subject however, it is still in its infancy). The most detailed level for the treatment of phenomena in systems with many particles (or degrees of freedom) is statistical mechanics, at which we will arrive in the coming parts of this book. A sort of intermediate level between thermodynamics and statistical mechanics is found in the kinetic theory of gases, which we discuss in detail in this part. The degrees of freedom of a system are a collection of independent variables, required to character- ize the system. Thus, for instance, the degrees of freedom of a gas, in a thermodynamic description, are its volume and pressure (or a pair of other variables). The degrees of freedom of a system of particles are the collection of the coordinates and the velocities of all the particles. This theory, whose development we owe to such giants as Maxwell, Boltzmann and Gibbs, was of crucial importance for the conceptual development of physics in the second half of the 19th century. The successes of the theory, such as the calculation of the dependence of the viscosity upon pressure and temperature and its measurement, which was carried out by Maxwell (see Chapter 3 of this part), contributed to the establishment of the particle description of matter, and thus also to the unifying outlook in physics, i.e. to the strengthening of the relationship between the Newtonian dynamics and the macroscopic properties. On the other hand, kinetic theory has provided the hints which led Willard Gibbs to formulate statistical mechanics, at the beginning of this century, in the form which is still commonly accepted today. In this and the subsequent parts we will discuss, among other things, topics which may be familiar to the reader from previous study. In most cases such topics constitute tests of the more detailed level of our discussion: each treatment at a detailed level must stand an uncompromising test - it must reproduce the results that are known at the less detailed level. Thus, for instance, results derived from the kinetic theory must be compatible with the laws of thermodynamics; statistical mechanics must agree with the kinetic theory as well as with thermodynamics. In some cases the recurring subjects will appear in a logical order different from before, and from a different standpoint. This does not disqualify, or cast doubt on, the preceding approach. Different approaches make different assumptions and the scope of their results varies: different approaches usually emphasize different aspects more experimental or more formal. Contemplating and confronting different approaches widens and deepens the understanding of the results and of the deductive process in the physical theory. Introduction Here we approach the kinetic theory of gases in its status as an intermediate level. On the one hand, we will view it as a tool for the calculation of important quantities such as transport coefficient and for the development of physical intuition in complex cases. On the other hand, we will try to view it as a corridor for ideas and methods of statistical mechanics, with which we deal in the coming parts. Transport coefficients are quantities that characterize the rate at which a system approaches equilibrium when there is a slight deviation from a state of equilibrium. (See Chapter 3 of this part Chapter 1 Velocity and Position Distributions of Molecules in a Gas 1.1 Avogadro’s law, or the equation of state of an ideal gas The equation of state of ideal gases and its connection with the Boltzmann distribution can be introduced in at least three diﬀerent ways. One way is to postulate the Boltzmann distribution as the fundamental principle of statistical mechanics, from which the equation of state of an ideal gas can be derived. We opted for the opposite way. We will derive the ideal gas equation of state from a few very simple fundamental considerations. This will serve as a ﬁrst step towards the introduction of the Boltzmann distribution toward the end of this chapter. You will get to know a third approach for reachingthe same point in Part III. Before derivingthe equa- tion of state of an ideal gas, which depends on the concept of temperature, we discuss Avogadro’s law: At equal pressure and temperature, equal volumes of gases contain an equalAvogadro’s law number of molecules. Avogadro deduced this law from an empirical rule in chemistry: if two gases, at the same temperature and pressure, combine in a chemical reac- tion without leftover constituents, their volumes stand in simple integral proportions. For example, if H2 and O2, at the same temperature and pressure, combine to give H2O, with no leftovers of oxygen or hydrogen, the correspondingvolumes must be in a ratio of 2:1. We would say that two H2 molecules are needed to combine with every O2 molecule. Here we will show that Avogadro’s law is a direct consequence of Newton’s laws. A microscopic description of a dilute gas begins with the clariﬁcation of the concept of pressure. In order to keep things simple we will only consider a gas whose molecules all have the same mass. The pressure of a gas is the force which the gas exerts on a unit area. This pressure is measured by the force which must be applied on a piston in order to 6 1.1 Avogadro’s law, or the equation of state of an ideal gas 7 keep it stationary. The force which the gas exerts on the piston is due to the momentum imparted by the gas molecules which collide with it. For example, if a molecule undergoes an elastic collision with the piston, the magnitude of the component of the momentum that is perpendicular to the piston is conserved, but its sign is reversed; the component parallel to the piston does not change (see Fig. 1.1.1).➤ ➤ ➤➤ ➤➤ ➤ ➤ py px x y p'y p'x piston Fig. 1.1.1 A gas molecule colliding with the piston. Therefore, in such a collision the amount of momentum imparted to the piston is ∆px =2px =2mvx . The number of molecules with a velocity component vx,alongthe x axis, that will hit the piston, of area A, duringa very short time interval ∆t, is equal to the number of molecules with such a velocity, inside a cylinder of area A and length vx∆t. This number is given by the product of the volume Avx∆t and the density. The amount of momentum, transferred to the piston duringthe time ∆t, by this type of molecules (with velocity vx along x)is ∆px =2mvx · vx∆tA · n(vx) , (1.1.1) where n(vx) is the number of molecules per unit volume with velocity component vx. The force exerted on the piston is given by the amount of the momen- tum transferred to the piston per unit time; this force per unit area is the pressure. Note that this is where Newton’s laws enter. Therefore, the contribution of molecules with a velocity component vx to the pressure is P (vx)=2 · mv2 xn(vx) . (1.1.2) Clearly, not all of the gas molecules have the same velocity component along x, and we must sum over all the possible values of vx. If we carry out this summation in Eq. (1.1.2) we ﬁnd, for the total pressure exerted on the piston, P = n ·⟨mv2 x⟩ , (1.1.3) 8 Ch. 1 Velocity and Position Distributions of ... where n denotes the total number of molecules per unit volume, and the angular brackets denote an average. Note that the number of molecules per unit volume is n = ∑ n(vx) , where the sum is over all values of vx and the average of v2 x is ⟨v2 x⟩ = 1 n ∑ n(vx)v2 x . Exercise 1.1 (a) Prove that in a state of equilibrium the sum of (1.1.2) is indeed equal to (1.1.3). Where did the 2 disappear? (b) What would the formulation of (1.1.1)–(1.1.3) be if you were to treat the velocity as a continuous variable? Solution on page 74 In a state of equilibrium the averages of v2 x, v2 y and v2 z will be equal, so in this case we can write (1.1.3) as P = 1 3 nm⟨v2⟩ = 2 3 N V 〈 1 2 mv2〉 = 2 3 E V . (1.1.4) ⟨v2⟩ = ⟨v2⟩ = ⟨v2 x⟩ + ⟨v2 y⟩ + ⟨v2 z ⟩. E is the total kinetic energy of the gas, N is the total number of molecules and V is its volume. Note that the energies used in calculating E are the kinetic energies of the centers of mass of the molecules (or of the atoms, in the case of a monoatomic gas). Equation (1.1.4) is a very impressive result (even though it was simple to derive!). It states that two gases kept at the same pressure, and whose molecules have the same average kinetic energies (independent of mass, structure and color), will occupy equal volumes, if they contain the same number of molecules. And all this from the direct use of the atomic assumption, Newton’s laws and nothingmore. This, however, is not exactly Avogadro’s law, but it is not far from it. That is, if we try to identify “temperature” with “average kinetic energy” of a molecule — up to a constant factor, which will take care of the units — we obtain on the one hand Avogadro’s law, and on the other the equation of state of an ideal gas. The constant mentioned, k, will beequation of state chosen such that 〈 1 2 mv2〉 = 3 2 kT (1.1.5) and T is the temperature. 1.2 Temperature and thermal equilibrium 9 From (1.1.4) we obtain PV = 2 3 E = NkT . (1.1.6) The manner in which we identiﬁed the average kinetic energy with the absolute temperature may seem arbitrary. Nevertheless, arbitrary identi- ﬁcation is characteristic and necessary when one is passingfrom one level of description onto another. As we will see later on — for example in the identiﬁcation of the laws of thermodynamics within the framework of statistical mechanics (Part III) — in transitions of this sort one has to identify within a broader framework (Newtonian dynamics, in the case we discussed) concepts that are deﬁned naturally in the less detailed de- scription (the temperature, in thermodynamics). But the identiﬁcation is not as arbitrary as it may appear at this stage. It must undergo many consistency tests of additional results derived from it. Another way of lookingat Eq. (1.1.6) is to say: “But is this not the familiar gas law we have always cherished?” Of course it is! And this is an alternative way of validatingour interpretation of (1.1.5) as deﬁning temperature. Exercise 1.2 It is possible to treat electromagnetic radiation in a container, whose walls are mirrors, as a gas of particles (photons) with a constant speed c and whose energy is related to their momentum, p, which is directed parallel to their velocity, by ϵ(p)= pc. Show that if the container in Fig. 1.1.1 is full of radiation, the equation of state will be PV = 1 3 E. (1.1.7) Solution on page 75 Finally, we note that once the temperature has been identiﬁed, it is possible to express the partition of the average kinetic energy as follows: with every direction of motion of a molecule we associate an average energy of 1 2 kT . Instead of “direction of motion” the accepted term is “degree of freedom”; it generalizes the term “direction of motion” also to rotations degrees of freedomand internal vibrations. We have seen, therefore, that a molecule in an ideal gas has three degrees of freedom. 1.2 Temperature and thermal equilibrium If we adopt the identiﬁcation (1.1.5), we obtain the ideal gas equation of state, in which we know how to identify the constant k. This is, of course, 10 Ch. 1 Velocity and Position Distributions of ... the Boltzmann constant: k =1.38 × 10 −23 JK −1 . If we express the number of molecules in terms of the number of moles ν and Avogadro’s number N0 : N = N0ν, then Eq. (1.1.6) will take the form PV = νRT , (1.1.8) where R = N0k =(6.02 × 10 23) · (1.38 × 10 −23)JK−1 =8.3J K −1 . Exercise 1.3 Calculate the average kinetic energy per gas molecule at room tempera- ture. Solution on page 76 As mentioned in the previous section, the identiﬁcation of the tem- perature requires many additional tests. The temperature has many properties, which are known from our daily experience and from ther- modynamics. Central amongthese is the role the temperature plays in determiningthe equilibrium between systems, which interact thermally as well as mechanically. Let us consider a volume in which there is a mixture of two gases. In a state of equilibrium, the number of molecules with a certain velocity v is independent of direction. This statement deserves additional reﬂection, since the argument that leads to it is very typical in the framework of the kinetic theory of gases. Indeed, the molecules collide with each other at a high rate. In collisions, even if they are elastic, the directions of the velocities change. Suppose there were a preferred direction, i.e. there were more molecules movingin that direction than in others. Then more molecules movingin the preferred direction would scatter to other (less preferred) directions than the other way around. Therefore, the state of the system would change with time, and this would not be a state of equilibrium. Only if the distribution of the velocity is independent of direction is a state of equilibrium possible. This is a necessary condition. This condition immediately implies that ⟨vx⟩ = ⟨vy⟩ = ⟨vz⟩ =0, and therefore ⟨a · v⟩ = 0 (1.1.9) for every constant vector a. We will now prove that in a state of equilibrium, the average kinetic energy per molecule, in a mixture of two gases, is equal. To this end let 1.2 Temperature and thermal equilibrium 11 us consider pairs of molecules that include one molecule of each type of gas. Let v1 and v2 denote the velocities of the two molecules of the pair. Each of the gases satisﬁes Eq. (1.1.9), separately. In addition, v1 and v2 are independent of one another, so the average of their product equals the product of the separate averages, both of which vanish in equilibrium. Hence ⟨v1 · v2⟩ =0 , (1.1.10) where the averaging is over both types of molecules. We now note that instead of describingthe motion of the molecules by the velocities v1 and v2, it is possible to describe it usingthe velocity of the center of mass, vcm, and the relative velocity, vrel. center of mass Reminder: vcm = 1 m1+m2 (m1v1 + m2v2) , vrel = v1 − v2 . If the distributions of v1 and v2 are independent so are those of vcm and vrel. In equilibrium, these distributions will also be independent of direction. Consequently, in a state of equilibrium, ⟨vcm · vrel⟩ =0 . (1.1.11) From Eqs. (1.1.10) and (1.1.11) we obtain 〈 1 2 m1v2 1 〉 = 〈 1 2 m2v2 2 〉 . (1.1.12) Exercise 1.4 Deduce the equality in (1.1.12) from Eqs. (1.1.10) and (1.1.11). Solution on page 76 The conclusion is that if the system is in equilibrium, the average kinetic energy per molecule is equal in the two gases. This means that the identiﬁcation we made [Eq. (1.1.5)] is in accord with the fact that if the two gases are in equilibrium, their temperatures are equal. In the language of mechanics we can say that in a state of equilibrium the distribution of molecules in the heavy gas will tend toward the slower molecules. This means that there will be more slow molecules in the heavy gas than in the lighter gas, and fewer fast molecules (see Fig. 1.1.2). 12 Ch. 1 Velocity and Position Distributions of ... 2kT m2 2kT m1 |v| n(|v|) m2 m1 Fig. 1.1.2 A qualitative description of the distribution of the absolute value of the velocity in a gas for two mass values: m1 <m2 . In order to make the picture clearer we have also chosen a state with more light molecules. Concerning the values along the horizontal axis, see self-assessment exercise 2b. Exercise 1.5 Dalton’s law states that the pressure of a mixture of gases is equal to theDalton’s law sum of pressures that the gases would exert if each of them were separately in the same conditions as the mixture. Deduce this law from similar reasoningto that we used to obtain (1.1.5). Solution on page 77 Without going into too many complications, we will treat somewhat superﬁcially, openly so, the case where a piston, of negligible friction, separates two gases inside a cylinder (Fig. 1.1.3). We ask: When will this system be in a state of equilibrium? First, from mechanics we conclude that the forces (or pressures) ex- erted on the two sides of the piston must be equal. Equation (1.1.4) implies therefore that N1 V1 〈 1 2 m1v2 1 〉 = N2 V2 〈 1 2 m2v2 2 〉 . (1.1.13) But this condition is not suﬃcient, if energy is allowed to pass from side to side, via the piston. That is, if there are very energetic molecules 1.3 Equipartition of energy per molecule and ... 13 12 Fig. 1.1.3 Two gases in a container separated by a piston. on one side, by hittingthe piston they will impart the energy to the other side, so that the energy (or velocity) distribution on both sides will change. The balance in (1.1.13) will be violated, and the piston will go over to a new state, in which it will attempt to balance the pressures, and so on and so forth. If we apply the argument which led to (1.1.12) to a molecule of one of the gases and to the piston (as a single molecule of the other gas), the conclusion will be that in a state of equilibrium the average kinetic energy of the piston, in its small hops left and right, must be equal to that of a gas molecule. The same argument applies to both sides of the piston. Hence, the average kinetic energies on the two sides must be equal in a state of equilibrium. We ﬁnd again a property that corresponds to a familiar characteristic of temperature. Exercise 1.6 Show that if in the cylinder of Fig. 1.1.3, the average kinetic energy on the two sides of the piston is equal, and if the total energy in the cylinder is a constant of magnitude E, and the number of molecules (N1, N2)of each gas is also constant, then the position of the piston is determined in a state of equilibrium. What will be the value of the average energy per molecule in this state? Solution on page 78 1.3 Equipartition of energy per molecule and its constituent parts — a fundamental problem Till now we have treated molecules as rigid objects devoid of internal structure, which exchange momentum via elastic collisions. We found that the average kinetic energy per molecule in any gas at a given temperature (i.e. in a gas that is in thermal equilibrium with a given system) is constant and is given by Eq. (1.1.5), 〈 1 2 mv2〉 = 3 2 kT , 14 Ch. 1 Velocity and Position Distributions of ... and the total energy of the gas is given by the product of the number of molecules and 3 2 kT . This is an adequate description for a monoatomic gas. But, what happens if the gas molecules are made up of several atoms so that their internal structure comes into play? This question has several components: (a) What is the average kinetic energy of each atom in a molecule? (b) What is the average kinetic energy of the center of mass of a molecule? (c) What is the connection between the answers to (a) and (b)? (d) How is the gas law aﬀected? Question (a) arises since inside the molecule there are forces acting between the atoms. Therefore, it seems as if the kinetic energy exchanges in collisions, the same energy exchanges that are responsible for the equi- librium, will not be so free. The answer to (a) is that every atom in the molecule has an average kinetic energy of 3 2 kT as in Eq. (1.1.5). This is a conclusion from the equipartition theorem, which will be presented inequipartition theorem Part III. Although the atoms in the molecule are bound to one another, they move inside it in all directions. When one of the atoms in the molecule collides with another atom of a diﬀerent molecule, the only important fac- tors are the velocities of the two atoms, immediately prior to the collision. When an atom in the molecule changes its velocity in a collision, the only eﬀect of the forces will be that the internal motion in the molecule will be rearranged. The collision itself takes place as if the atoms were free. However, if every atom in a diatomic molecule, for example, has an average kinetic energy 3 2 kT , then question (b) arises: What is the ki- netic energy of the center of mass of the whole molecule? The answer is surprising: 3 2 kT , as for a monoatomic gas. One way to obtain this result is to view the system at a lower reso- lution, so that we see only molecules and not atoms, and to go over the precedingarguments. The molecules will be seen to be moving to and fro at diﬀerent velocities. They will be seen to collide and as a result to change their velocities, which are the velocities of their centers of mass. At equilibrium we will ﬁnd that the average kinetic energy is 3 2 kT .But this conclusion leaves question (c) open. In order to answer this question, we calculate the average kinetic en- ergy of the center of mass, in a diatomic molecule, under the assumption that both parts of the molecule — atoms 1 and 2 — have an average 1.3 Equipartition of energy per molecule and ... 15 energy, as implied by (a): 3 2 kT . The average kinetic energy of the center of mass will be ⟨Ecm k ⟩ = 〈 1 2 (m1 + m2) ( m1v1 + m2v2 m1 + m2 )2〉 = 1 m1 + m2 [〈 1 2 m 2 1v2 1 〉 + 〈 1 2 m 2 2v2 2 〉 + m1m2⟨v1 · v2⟩ ] . (1.1.14) Accordingto our answer to (a), the ﬁrst two terms in the sum are equal to 3 2 kT m1 and 3 2 kT m2, respectively. Therefore ⟨Ecm k ⟩ = 3 2 kT + m1m2 m1 + m2 ⟨v1 · v2⟩ . (1.1.15) The question is therefore: What is the value of the average ⟨v1 · v2⟩ between the two parts of the molecule? It seems as if there is a correlation between the velocities of the two parts. Nevertheless, it is clear that there is no correlation between the direction of the center of mass velocity vcm of the molecule and the relative velocity vrel of the two parts. Therefore, ⟨vcm · vrel⟩ =0 , (1.1.16) precisely as occurs for two diﬀerent molecules. But this relation, together with the fact that the average kinetic energy of each part is 3 2 kT , implies that ⟨v1 · v2⟩ = 0 (1.1.17) and thus ⟨Ecm k ⟩ = 3 2 kT . (1.1.18) Exercise 1.7 Prove that in fact ⟨v1 · v2⟩ =0. Solution on page 79 As to question (d), we must remember that the pressure of the gas is related to the momentum imparted to the piston, and the question is: What is the amount of imparted momentum when the molecule collides elastically with the wall? By elastic collision we mean that there is no change in the internal state of the colliding systems. Of course this is an idealization, but in a state of equilibrium it does not introduce any error. 16 Ch. 1 Velocity and Position Distributions of ... Therefore, the motion of the center of mass of the molecule is the decisive factor, and the gas law remains the same [Eq. (1.1.6)]: PV = NkT , where N is, of course, the number of molecules. The average kinetic energy per molecule can be calculated from two points of view: as the sum of the kinetic energies of all the atoms of the molecule or as the sum of the energy of the center of mass and the energy of the internal motions of the molecule. Since the average kinetic energy is shared equally between the three directions of the velocity of the atom (three degrees of freedom per atom), and is also shared equally between all the atoms of the molecule, a molecule of r atoms has an average kinetic energy of ⟨Emol k ⟩ = r · ( 3 2 kT ) = 3r 2 kT . (1.1.19) This means that every molecule has 3r degrees of freedom related to its kinetic energy. If we choose the second viewpoint, we should note that 3 2 kT of this energy is carried by the center of mass, so that (r − 1) · ( 3 2 kT ) is the average kinetic energy of the internal motions of the molecule. These motions may be rotations and vibrations of the atoms relative to each other (see Fig. 1.1.4). Here as well we may speak of degrees of freedom that will now be rotational degrees of freedom and degrees of freedom of atomic vibrations. The triatomic molecule depicted in Fig. 1.1.4 has an average kinetic energy of 9 2 kT (nine degrees of freedom): 3 2 kT of them related to the center of mass (three degrees of freedom), 3 2 kT to the three ➤ ↔↔ ↔ ➤➤ Fig. 1.1.4 Rotations and vibrations of a triatomic molecule. 1.3 Equipartition of energy per molecule and ... 17 diﬀerent vibrations (another three degrees of freedom), and 3 2 kT to the three possible rotations (another three degrees of freedom). The origin of the internal partition will be clariﬁed in the comingchapters. 3r 2 kT is not the total energy of an r-atomic molecule, since it does not include the potential energy of the forces between the atoms. The above discussion has disregarded these forces. The conclusion is that the right hand side of the gas equation is not 2 3 E,with E the total kinetic energy as in Eq. (1.1.6) for a monoatomic gas, but PV = 2 3r E, (1.1.20) and if we deﬁne γ =1 + 2 3r (1.1.21) we obtain PV =(γ − 1)E. (1.1.22) For the case of a monoatomic gas, for example, γ =5/3. Exercise 1.8 Deduce Eq. (1.1.20) from Eq. (1.1.6). Solution on page 79 A classical physicist of the nineteenth century could have said, there- fore, that the thermodynamic measurement of the curves of adiabatic expansion will provide him with γ, and hence r — which is the answer to the question: What is the number of the fundamental buildingblocks in familiar molecules? On the other hand, a contemporary physicist would state that r must be huge, as atoms are made up of a large number of electrons, protons and neutrons, and the latter are themselves made up of quarks and antiquarks, and maybe even the latter are not fundamen- tal. This is a formulation from a modern viewpoint of the “heat capacity problem,” here discussed in the context of adiabatic expansion. It was one of the most troublingopen problems of physics, and was eventually resolved only within the framework of quantum mechanics, as we shall see below. 18 Ch. 1 Velocity and Position Distributions of ... Classical mechanics allows continuous energy changes, and therefore the momentum exchanges that bring about the equilibrium state can take place separately with each of the molecule’s constituents. Every collision with the molecule that is not limited to a change in the motion of the cen- ter of mass, causes an internal excitation in the molecule of a vibrational, or rotational, type. Since classical mechanics allows vibrations and rota- tions of arbitrarily small energies, even a very slow particle can exchange momentum with each part of the molecule separately. In quantum theory the situation is totally diﬀerent. In quantum the- ory internal excitations are allowed only between certain levels which are separated from each other by discrete energy diﬀerences. Exciting an in- ternal motion is impossible, for example, if in the collision the energy passed on to the molecule is below a certain threshold, which depends on Planck’s constant. Very slow particles, which are the most abundant at low temperatures, will not be able to exchange momentum with molecular parts, since they are unable to excite internal motions. Their collisions will always be elastic as those of rigid bodies. We can ask, of course: What are low temperatures and what are large energy intervals? The answer is clear: if the average kinetic energy, whose magnitude is about kT , is small compared to the distance between two energy levels of internal excitations, the molecule will behave as if it had less than 3r degrees of freedom. In order to make this clearer we redeﬁne the number of degrees of freedom per molecule f ,as the number of portions of 1 2 kT that are contained by the average kinetic energy of the molecule: ⟨Emol k ⟩ = f 2 kT . (1.1.23) In this sense f is the eﬀective number of degrees of freedom. We obtain instead of (1.1.20) PV = 2 f E, (1.1.24) and if we deﬁne γ =1 + 2 f (1.1.25) Eq. (1.1.22) remains valid. The quantization of energy ﬁnds expression in values of f that are smaller than expected accordingto classical mechanics, or by values of γ that are too large. 1.3 Equipartition of energy per molecule and ... 19 Exercise 1.9 The diﬀerence between electronic states in the atom is measured in eV. The diﬀerence between nuclear states is measured in MeV = 106 eV. Subnuclear energies are are measured in GeV = 109 eV. At what temperature will the electronic, nuclear and subnuclear (quark) degrees of freedom come into play in the calculation of γ? Solution on page 80 In its original formulation, the “heat capacity problem” focused on try- ingto predict the value of the constant γ theoretically. For a monoatomic gas γ =5/3 [Eq. (1.1.21) with r = 1 or (1.1.25) with f = 3]. Indeed, the result of the calculation for the rare gases ﬁts the experimental results nicely, even at low temperatures. The experimental result for He at 100K (−173◦C) is γ =1.660; on the other hand, for diatomic molecules, such as H2 and O2,the situation is quite bad. Theory — Eq. (1.1.21) or (1.1.25) — gives γ =4/3. The ex- perimental result at 100◦Cis γ =1.4. This result implies that eﬀectively there are fewer than six degrees of freedom. It seems as if the number is ﬁve. Attempts to solve this problem by takinginto account internal forces were counterproductive, since it was found that internal forces add poten- tial energies and by so doing increase the number of degrees of freedom and decrease the value of γ. In a more quantitative language, we may say that (1.1.23) is replaced by ⟨Emol⟩ = f 2 kT ,where Emol is the total energy of a molecule and f is (therefore) larger than 3r and represents all the degrees of freedom of the molecule. This replacement keeps Eqs. (1.1.24) and (1.1.25) intact. In a diatomic gas, for example, the number of degrees of freedom includingthe internal forces is 7, so that γ =9/7only (see Sec. 1.4, Part IV). Classical mechanics is unable to provide any mecha- nism that can increase γ (or decrease f ) beyond the value that is obtained from calculatingthe kinetic energies. The solution is found, as already mentioned, in quantum theory, which is able to explain why the internal vibrations of a diatomic molecule do not come into play at a temperature of 100◦C (i.e. become “frozen”). The answer is, of course, that the energy diﬀerence of adjacent levels of the internal vibrations is too large, and an energy of kT (T = 100◦C) is not suﬃcient to excite them, so the number of degrees of freedom does in fact decrease to ﬁve. On the other hand, this explanation implies that increasingthe temperature will eventually cause an “unfreezing” of the inactive degrees of freedom of the internal vibration, leadingto a decrease in γ. Indeed, at high temperatures — 2000◦C — the value of γ for the diatomic gases decreases to 1.286, which 20 Ch. 1 Velocity and Position Distributions of ... is very close to 9/7. We revisit all these questions, at a much deeper level, in Chap. 1 of Part IV. To summarize: (a) At equilibrium, at a temperature T , each particle has an average kinetic energy of 1 2 kT for every possible direction of the velocity. (b) In a molecule of r atoms each atom has an average kinetic energy of 3 2 kT . (c) The average kinetic energy of the center of mass is also 3 2 kT . (d) Internal forces increase the number of degrees of freedom, i.e. the number of portions of 1 2 kT per molecule. (e) Experiment at moderate temperatures indicates that the number of degrees of freedom is smaller than the number obtained from kinetic energy arguments. (f) The heat capacity (adiabatic expansion) problem does not have a so- lution in the framework of classical mechanics. Quantum mechanics provides the solution to this problem. 1.4 The density in an isothermal atmosphere — the Boltzmann factor in the potential energy How are molecules distributed in a force ﬁeld? As a special case of this question we will consider the gravitational case. A typical example for this situation is an isothermal atmosphere, namely a volume of gas at a uniform temperature T , in a closed cylinder, as depicted in Fig. 1.1.5. We ask: What is the density of the gas as a function of the height z,at thermal equilibrium? We divide the volume of the cylinder into layers, such that each layer will have a very small thickness compared to the distance that characterizes the rate of change of the force, but is still very large compared to the intermolecular distances. In order to convince yourself that this can really be done, solve the followingexercise. ➤ ➤ ➤ ➤ ➤ z P(z) P(z+dz) g }∆z Fig. 1.1.5 Gas inside a container residing in a gravitational ﬁeld. 1.4 The density in isothermal atmosphere 21 Exercise 1.10 Calculate the change in height at the earth’s surface that will cause the gravitational ﬁeld to change by a thousandth of a percent. What is the ratio between this distance and the average intermolecular distance in a gas at standard conditions? Solution on page 81 Thermal equilibrium guarantees that the velocity distribution is iden- tical in all the layers; however, due to the gravitational force the pressure diﬀers at each height, since the pressure of the gas is determined by the weight of the gas above it. Hence, the density of the gas changes with height. The requirement that the thickness of the layers should be small (com- pared to the earth’s radius, for example) allows us to assume that all the molecules of one layer experience an identical gravitational force. More- over, we can attribute a constant density to the gas contained in a given layer. The requirement that the thickness should be very large com- pared to the intermolecular distance, allows us to attribute thermody- namic properties to the small volume, as the number of molecules in it will still be very large. In order to demonstrate the principle of the calculation we will make a further simplifyingassumption and neglect the variation of the grav- itational force with height. We are discussing, therefore, an isothermal atmosphere in a uniform gravitational ﬁeld. If the area of the base of the cylinder is A, the volume of the layer will be A · ∆z (see Fig. 1.1.5), and the force exerted upon it by gravity is ∆F = mg · n(z)∆z · A, (1.1.26a) where m is the mass of a molecule, n(z) is the density at height z,and g is the gravitational free fall acceleration. In a state of equilibrium, this force is balanced by the diﬀerence in pressure beneath the layer and above it, and hence [P (z) − P (z +∆z)]A =∆F, (1.1.26b) so that dP (z) dz = −mg · n(z) . (1.1.27) Since our layer is thick enough, we can attribute an equation of state of the type (1.1.6) to it. Namely P (z)= n(z)kT . (1.1.28) 22 Ch. 1 Velocity and Position Distributions of ... We assumed that T is independent of z, so we substitute (1.1.28) into (1.1.27), and obtain a diﬀerential equation for n(z). The equation is dn(z) dz = − mg kT n(z) (1.1.29) and its solution n(z)= n(0) exp ( − mgz kT ) . (1.1.30) Check that this is in fact the solution to the equation. n(0) is the value of the density at the point z = 0. This value is related to the total number of molecules N , since if the total height of the container is h,then N A = n(0) ∫ h 0 exp ( − mgz kT ) dz = n(0)kT mg [ 1 − exp (− mgh kT )] , (1.1.31) so that in a container in which N is constant, the density at its bottom is determined by n(0) = Nmg AkT [ 1 − exp ( − mgh kT )]−1 . Equation (1.1.30) states that the density of molecules decreases with height; however, the extent of variation depends on the temperature. The higher the temperature, the less signiﬁcant are the variations in height (see Fig. 1.1.6). The decisive factor in determining the decrease in den- sity between two points whose altitudes diﬀer by ∆z is the ratio of the diﬀerence in their potential energies mg∆z to kT . This is a dimensionless quantity, of course. If the temperature becomes very low, all the particles concentrate at the bottom of the cylinder. The thermal energy is not large enough to overcome the increase in potential. Actually, we use the term potential here instead of potential energy. This is common practice in the literature and it is always possible to identify the meaning from the context. Now we can go back and remove the simplifying assumption about the uniformity of the force ﬁeld actingon the molecules. This we do in the followingexercise: 1.4 The density in isothermal atmosphere 23 T1 2T1 4T1 n(z) z➤ ➤ Fig. 1.1.6 The dependence of the density on height in an isothermal atmosphere at three diﬀerent temperatures. Note: n(0) also depends on T . Exercise 1.11 Prove that for a gas in a force ﬁeld that is derived from the potential U (r), n(r)= n(r0)exp [ − U (r) kT ] . (1.1.32) Solution on page 82 Since our aim is to arrive at statistical mechanics via the kinetic theory, we will describe the result in Eq. (1.1.32) in a slightly diﬀerent language. Our system contains many molecules. Thus, we can treat n(r) or, more precisely, n(r)/N as the probability for a molecule to be in an inﬁnitesimal volume dV around the point r,where N is the total number of molecules. Notice that from here to the end of this chapter P denotes the probability and not the pressure. In other words P (r)dV = 1 N n(r)dV (1.1.33) is the probability that a particle will be in the volume dV around r. It is important to remember that although the volume element dV is “tiny,” the number of molecules inside it is very large, and in every such volume there exists a velocity distribution. However, as we mentioned, around each point r there is exactly the same velocity distribution, since the system is at thermal equilibrium. 24 Ch. 1 Velocity and Position Distributions of ... Exercise 1.12 Calculate the dimensions of P (r). Is it normalized? Solution on page 83 Now we want to ask a diﬀerent question: Not what is the probability of ﬁnding any particle at a certain place, but what is the probability of a given conﬁguration of the system, i.e. what is the probability that N particles will be in the volumes dV1,... ,dVN around the points r1,... , rN , respectively, in a space with a potential ﬁeld U (r)? In the present context a conﬁguration is a list of all the coordinates of the particles. Such a collection characterizes a state of the system, and every state of the system is described by an appropriate conﬁguration. Since the positions of the diﬀerent particles are independent (ideal gas), the probability is a product of the individual probabilities, i.e. PN (r1, r2,... , rN )dV1 ... dVN = P (r1)dV1P (r2)dV2 ... P (rN )dVN = [ n(r0) N ]N exp [ − 1 kT N∑ i=1 U (ri) ] dV1 ... dVN . (1.1.34) Multiparticle probability distributions are discussed at length in the following parts. Note though that if we integrate over N −1 of the coordinates, we obtain the probability distribution of the Nth particle. ∑ U (ri) is just the total potential energy of the N particles of the gas. Hence, the conclusion is that the probability density for a certain con- ﬁguration of the system of particles is proportional to the exponential of minus the total potential energy of the conﬁguration, where the potential energy is measured in units of kT . 1.5 The Maxwell–Boltzmann distribution As already mentioned, n(r), which is the particle density in a small vol- ume dV around the point r, is made up of particles that are movingat diﬀerent velocities. The distribution of the velocities is independent of r, just as the coordinate distribution P (r) is independent of v.We now enquire how many of the particles in a volume element dV , around the point r, i.e. out of n(r)dV , have a velocity inside the volume element dvxdvydvz(≡ dτ ) in velocity space around v (see Fig. 1.1.7). We denote the probability for a particle to have a velocity v in that velocity volume 1.5 The Maxwell–Boltzmann distribution 25 ➤➤ ➤ vy vz vx v dτ ➤ ➤ Fig. 1.1.7 A volume element in velocity space. by f (v)dτ , so that with the help of Eq. (1.1.33), n(r)dV f (v)dτ = NP (r)f (v)dτ dV (1.1.35) is the number of molecules with a velocity in a region dτ around the velocity v, that are located in a volume dV around the location r. Just as the dimensions of P are length to the minus three, [L]−3,so the dimensions of f (v) are velocity to the minus three, i.e. dimensions of length over time, to the minus three [LT −1]−3. As mentioned above, f (v) is the probability per unit velocity volume for a molecule to have a velocity near v. The form of this probability function, named after Maxwell, will be derived next. Many authors obtain the form of f (v) as a special case of the general assertion of the Boltzmann distribution. Here we take the opposite way. Maxwell’s result for the velocity distribution is much more fundamental, and provides a clue to the form of the general distribution. Moreover, the simple argument leading to this distribution is so nice that it merits presentation even if one has no bias concerning the direction of the progress of knowledge. Actually the Maxwell distribution is obtained from two very reasonable and very simple assumptions: (a) In a state of equilibrium there is no preferred direction. (b) Orthogonal motions are independent of one another. The ﬁrst assumption, whose reasonableness was considered on the way to Eq. (1.1.9), states that f (v) must be a function of v2 only: f (v)= h(v2) . (1.1.36) The second assumption implies that f (v) must be a product of the form f (v)= g(v2 x)g(v2 y)g(v2 z ) . (1.1.37) 26 Ch. 1 Velocity and Position Distributions of ... The fact that we wrote the functions g as functions of the squares of the components of v again follows from (a), since a dependence on the sign of the component is impossible. The conclusion from (a) and (b) together is h(v2 x + v2 y + v2 z)= g(v2 x)g(v2 y)g(v2 z ) . (1.1.38) This is a functional equation that determines the forms of h and g. Before solvingEq. (1.1.38) we note that we already know one possible simple solution: h and g are exponential functions g(v2)= eλv2 .We want to show that this is the only solution and to this end we will solve the equation. In order to do this simply we rename our variables and deﬁne v2 x = ξ, v2 y = η, v2 z = ζ, (1.1.39) ρ = ξ + η + ζ. (1.1.40) We want, therefore, to solve the equation h(ρ)= g(ξ)g(η)g(ζ) . (1.1.41) Note that h depends on ξ, η, ζ only through the variable ρ.In order to solve Eq. (1.1.41) we diﬀerentiate both sides with respect to ξ.On the left hand side we make use of the chain rule and of the fact that ∂ρ/∂ξ =1 to obtain dh dρ = dg dξ g(η)g(ζ) . (1.1.42) We now divide both sides of this equation by Eq. (1.1.41), obtaining 1 h dh dρ = 1 g dg dξ . (1.1.43) Note that the left hand side can in principle depend on all three vari- ables ξ, η, ζ through ρ. However, the right hand side depends only on ξ. Therefore, the function h−1dh/dρ cannot depend on η and ζ. However, if we diﬀerentiate Eq. (1.1.41), this time with respect to η,and repeat the arguments, we will reach the conclusion that the function h−1dh/dρ cannot depend on ξ or ζ. The conclusion is that h−1dh/dρ is a constant function. If we denote its value by λ, then we obtain dh dρ = λh . (1.1.44) The general solution to this equation is of course h = Ce λρ = Ce λv2 , (1.1.45) 1.5 The Maxwell–Boltzmann distribution 27 where C is a constant. From here we obtain, with the help of (1.1.36), f (v)= h(v2)= Ce λv2 . (1.1.46) Since fdτ is a probability, f is positive, and its integral over all possible vectors v must be 1. Hence, we must have C> 0and λ< 0. If we denote the negative constant λ by −A,wecan write f (v)= Ce −Av2 . (1.1.47) This is the Maxwell velocity distribution. The arguments we have used do not provide the constant A. However, C is determined as a function of A from the normalization condition. Exercise 1.13 Show that C = ( A π )3/2 . Solution on page 83 In order to obtain A some physics must enter our arguments. What is needed is to note that given the distribution f (v) we are able to compute the average of any function of v. In particular we can compute ⟨ 1 2 mv2⟩, obtaining 〈 1 2 mv2〉 = 3m 4A ; (1.1.48) however, this average is known to us from the discussion of the ideal gas where it was seen to be equal to 3 2 kT . Hence, we can express A in terms of the temperature and the molecular mass. The result is f (v)dτ = ( m 2πkT )3/2 exp ( − mv2 2kT ) dτ (1.1.49) for the probability in velocity space. Exercise 1.14 Prove that (1.1.49) is the only determination of C and A in (1.1.47) which gives a normalized f (v) and the correct average kinetic energy. Solution on page 84 Now, just as we derived from the coordinate distribution of N parti- cles (1.1.33) the probability for a certain conﬁguration (1.1.34), we want 28 Ch. 1 Velocity and Position Distributions of ... to derive from the velocity distribution (1.1.49) the probability for a given conﬁguration of the coordinates and the velocities of the particles, namely the probability for N particles to be in volumes dV1,... ,dVN around the points r1,... , rN , respectively, as well as in the velocity region dτ1,... ,dτN around the respective velocities v1,... , vN . The conﬁgura- tion of the coordinates and velocities characterizes the state of the (clas- sical) system completely. It is possible to think of such a conﬁguration as apoint in aspaceof 6N dimensions (six dimensions per molecule). Note that here the term “conﬁguration” signiﬁes the list of the coordinates and velocities of all the molecules. The probability for a molecule to be near r, and for its velocity to be near v, is, as already stated, P (r)dV f (v)dτ . In an ideal gas with N molecules, the coordinates and velocities of each molecule are independent of the coordinates and velocities of every other molecule. There is, of course, no dependence between the position of a molecule and its velocity. Hence, the probability for a conﬁguration where molecule No. 1 is near location r1 and has a velocity near v1; molecule No.2,near r2 and v2;and so on,is P (r1) ... P (rN )dV1 ... dVN f (v1) ... f (vN )dτ1 ... dτN = C exp { − 1 kT N∑ i=1 [ 1 2 miv2 i + U (ri) ]} dV1 ... dVN dτ1 ... dτN . (1.1.50) We found, therefore, that given a complete description of the state of the system, the probability of ﬁndingsuch a state is proportional to the exponential of minus the total energy of the system in this state, in units of kT . This distribution is called the Maxwell–BoltzmannMaxwell– Boltzmann distribution distribution. 1.6 Averages and distributions In the precedingtwo paragraphs we developed expressions for the density distribution resultingfrom the presence of a potential — Eq. (1.1.32) — and the distribution of molecules in velocity space — Eq. (1.1.49). Given these distributions we can compute averages of any function that depends on the coordinates and/or the velocities. 1.6 Averages and distributions 29 We can, for example, calculate the average height of a molecule in the isothermal atmosphere whose density is given by Eq. (1.1.30) with the help of the one-dimensional version of Eq. (1.1.33): ⟨z⟩ = ∫ ∞ 0 zP (z)dz = ∫ ∞ 0 zn(z)dz∕∫ ∞ 0 n(z)dz = ∫ ∞ 0 z exp (− mgz kT ) dz∕ ∫ ∞ 0 exp ( − mgz kT ) dz , (1.1.51) where zero height denotes the bottom of the cyclinder containing the gas. In the present case it is possible to evaluate the integrals explicitly. It is, however, unnecessary. ⟨z⟩ can be calculated usinga trick that is widely used in statistical mechanics: ﬁrst we note that we can rewrite it as ⟨z⟩ = − d dα ln Z(α) , (1.1.52) where Z(α) stands for the integral in the denominator of (1.1.51) and α stands for mg/kT . The dimensions of α can be evaluated either di- rectly from the explicit expression or from the knowledge that zα,the exponent in (1.1.51), must be dimensionless. The results are, of course, identical: [α] = [length]−1 =[L] −1 . Since the integral Z(α) has the dimensions of length, and as there is no other variable with dimensions of length in the problem, it must be proportional to 1/α. If we write Z(α)= K/α,where K is a constant, we immediately obtain the average height of a molecule from (1.1.52): ⟨z⟩ = 1 α = kT mg . (1.1.53) Exercise 1.15 Show that the average square deviation (the variance) of the height of the molecules is given by (∆z) 2 ≡⟨(z −⟨z⟩) 2⟩ = d2 dα2 ln Z(α) . (1.1.54) Solution on page 85 30 Ch. 1 Velocity and Position Distributions of ... Exercise 1.16 Assume that in Eq. (1.1.32) the potential is given by U (z)= U0zn . Usingonly dimensional arguments calculate ⟨zn⟩ and ⟨U (z)⟩. Solution on page 86 In a similar manner the Maxwell distribution, Eq. (1.1.49), determines the averages of functions of the velocity. Now we can calculate the averages of diﬀerent powers of the velocity — called moments of the distribution — with the help of dimensional arguments. First of all it is clear that the average of v, in the distribution (1.1.49), is zero. The average of ⟨|v|2⟩ in this distribution, which is also the average square deviation, is given by ⟨|v| 2⟩ = − d dα ln Z(α) , (1.1.55) where this time Z(α)= ∫ e −α|v|2dτ (1.1.56) and α = m 2kT . (1.1.57) Dimensional analysis gives [α] = [velocity]−2 , [Z(α)] = [velocity]3 . Since the only dimensional quantity in Z(α)is α, it must be that Z(α)= Cα −3/2 , (1.1.58) and substitutingthis into Eq. (1.1.55) we obtain ⟨|v| 2⟩ = 3 2α = 3kT m , (1.1.59) which is equivalent to (1.1.5). See also (1.1.48). 1.6 Averages and distributions 31 Exercise 1.17 (a) How does ⟨|v|2⟩ vary with the dimensionality of space? (b) If a gas is placed in a three-dimensional harmonic potential, U (r)= 1 2 C|r| 2 , what is the average square separation (the average square distance) of a molecule from the center of force? (c) Under the conditions of (b), show that the average potential energy per molecule in the gas is ⟨U (r)⟩ = 1 2 DkT , (1.1.60) where D is the dimensionality of space. Solution on page 87 Chapter 2 Brownian Motion 2.1 Historical background The fact that each degree of freedom of a particle which is in equilibrium with gas molecules has an average kinetic energy equal to that of a degree of freedom of the gas molecules, i.e. 1 2 kT , has far-reachingconsequences. The possibility of explainingthe motion of small specks, hoveringin a gas or in a liquid, within the framework of the kinetic theory was, from a historical point of view, the most important of these consequences, due to its contribution to the resolution of the ideological struggle for and against the atomic structure of matter. This titanic struggle went on during the second half of the nineteenth century and involved the prominent physicists of that era. We can learn of its acuteness from the fact that even in the beginning of this century one of the pillars of physics — Ernst Mach — could be heard to say: “If the belief in the existence of atoms is so crucial in your eyes, I hereby withdraw from the physicist’s way of thought... ” An even stronger evidence for the heat of the debate is the fact that the sharp criticism that was aimed at LudwigBoltzmann seems to have contributed to his suicide in 1906. The experiment by the botanist Robert Brown, concerningthe drifting of specks with radii on the order of micrometers (1µm= 10−6 m) in liquids and in gases, had been known since 1827. However, only in 1905 did Einstein explain the phenomenon. Within his explanation, which was based on the kinetic theory, Einstein connected in a quantitative manner the Brownian motion and quantities that appear in the kinetic theory — such as the coeﬃcients of mobility and viscosity — and he brought the debate to a conclusion in a very short time. But the importance of the subject far transcends the resolution of the heated debate about atomism. This subject is also of great practical 32 2.2 Characteristic scales of Brownian motion 33 importance: understandingthe eﬀect of the thermal motions of atoms on sensitive instruments that are not too heavy and are in equilibrium with their surroundings, is very important for understanding the limits on the sensitivity of very accurate measuringinstruments. Among these are the galvanometers, which are based on the deviations of a small mir- ror hanging from a thin thread, and the voltage variations in sensitive electric circuitry containingresistors. The random motion, which is due to the equipartition of thermal energy, is a source of “noise” in many systems. The theoretical treatment of Brownian motion is a workshop for the understandingof such phenomena. Moreover, the treatment of this subject begins to shed some light on the deep and important problem of the connection between thermal ﬂuctuations and the “erosion of energy” energy dissipation(dissipation), or frictional phenomena. 2.2 Characteristic scales of Brownian motion The sort of phenomenon we are about to treat is schematically as follows: a large body hovers in a crowd of tiny particles — as a giant bear ﬂoats in a huge crowd of bees (see Winnie the Pooh, Chapter 1). The tiny particles are movingto and fro. In this process they make many fast knocks against the large body. The knocks are random and each has a very small eﬀect on the body, since the ratio of the mass of the body to that of the particle is very large. The hoveringparticles that Robert Brown was able to see under his microscope have a diameter of a few micrometers. To acquaint ourselves with the data of the problem described in Fig. 1.2.1, we suppose that the body is hoveringin a gas under standard conditions. The density of such a gas is n ≈ 1026 m−3. The thermal energy of a particle at room temperature is ϵ ≈ kT ≈ 5 × 10 −21 J (k is the Boltzmann constant). We are interested only in orders of mag- nitude, so the factor 3/2 was omitted. We will assume that the density of the body is a tenth of a gram per cm3. Its mass will therefore be M ≈ 10−16 kg. From the assumption that the body is in thermal equilibrium with the gas, we can deduce that its typical velocity is 10−2 ms−1 (check this). Similarly, if we take a typical value of 10−26 kgfor the mass of the surroundingmolecules, the molecular velocities will be 103 ms−1. 34 Ch. 2 Brownian Motion 1µm 1Å ➤➤➤➤ Fig. 1.2.1 A body executing Brownian motion. Exercise 2.1 Calculate, for the above data, the velocity which a molecule of typical velocity can impart to the body in a head-on elastic collision. Solution on page 88 Another scale that characterizes the situation is the distance that the body can traverse between two collisions. This distance is called the mean free path, or simply the free path (see also Chap. 3). In order to ﬁnd themean free path orders of magnitude of the free path, we apply the following consideration: if the body were to move, parallel to itself, a distance L (Fig. 1.2.2), it would bump into N = n · (S · L) molecules, where n is the gas density and S is the cross section area of the body. In order to bump into one molecule the body must traverse, typically, a distance L such that N =1. Namely L = 1 nS . (1.2.1) L ➤➤➤S cross section Fig. 1.2.2 Motion of a body in gas. 2.3 Randomwalk 35 Under the conditions of our problem L ≈ 10−14 m(do check), so that even usinga very advanced microscope we are unable to discern isolated events: the motion will seem continuous and smooth, but lacking a preferred direction. Alongwith the free path, L, it is possible to deﬁne the correspond- ingtime scale, mean free time, which, as indicated by its name, is the mean free timetime it takes for a particle to traverse a distance L.In our case τ ≈ 10−12 s, which means that the body gets hit by 1012 molecules per second! 2.3 Random walk If we follow the motions of diﬀerent bodies from an initial time t =0, we see that each body follows a diﬀerent trajectory, reﬂectingthe randomness of the collisions. The average over many trajectories of the displacement, R, of each body from its initial position gives zero. However, the average square distance is not zero. Experiments show that it grows linearly with time. Namely ⟨R 2⟩ = αt . (1.2.2) Thus if, for example, at time t = 0 all the bodies were at the same location, they would gradually move from their initial location so that most of them would be found near a sphere of radius proportional to t1/2. The major achievement in Einstein’s work, as already mentioned, was that the atomic assumption and the use of the kinetic theory enabled him to express α in terms of other quantities of the kinetic theory. How this can be done will be shown in the followingparagraphs. First we inquire whether Eq. (1.2.2) ﬁts a simple intuitive picture of the nature of the process. We assume, for the sake of simplicity, that the collisions of the body with the molecules cause it to move as in a random walk. A two-dimensional example of such a walk is shown in Fig. 1.2.3. The sketched walk consists of 36 steps. The characteristic of such a walk, a drunk’s walk from a bar, is a series of steps of more or less constant length, that are randomly directed, in the correspondingspace — two-dimensional for the drunk, three-dimensional for the hoveringbody. Obviously, every drunk will reach a speciﬁc point, in a given series of steps. We cannot say where every particular walk will arrive; however, we will have something to say about the average location of a group of drunks who leave the bar together. You may be surprised to ﬁnd that we do not need to compute the probability of reachingevery location. We can get alongwith a few very general considerations. 36 Ch. 2 Brownian Motion B A Fig. 1.2.3 Thirty-six steps in the walk of a drunk. We will assume that the length of a step is L,that after N steps the drunk has reached the point RN , and that his next step will be in the direction n (n is the unit vector, which determines the direction of the next step). After N + 1 steps the position of the drunk will be RN +1: RN +1 = RN + Ln . (1.2.3a) First, clearly, the average position of the drunks remains at the bar, since each one of them moves in a diﬀerent direction, ⟨RN ⟩ =0 (see also Exercise 2.2). We can learn about the extent of the scatteringof the drunks from the square distance from the initial position, which is given by R 2 N +1 =(RN + Ln) 2 = R 2 N + L 2 +2Ln · RN . (1.2.3b) (Note that we used the fact that n2 =1.) We apply the randomness argument to Eq. (1.2.3b) in the following manner: we average both sides of the equation. The fact that the direction of n is random with respect to RN leads to a zero average for the last term on the right hand side [cf. (1.1.9)]. The conclusion is that ⟨R 2 N +1⟩ = ⟨R 2 N ⟩ + L 2 , (1.2.4) from which it is immediately inferred that ⟨R 2 N ⟩ = NL 2 . (1.2.5) 2.4 Randomforce and friction... 37 L2 is constant and N is the number of steps, which is proportional to the duration of the walk, so that the result of Eq. (1.2.5), is not diﬀerent from that of Eq. (1.2.2). Finally, we note that exactly the same results can be obtained if we interpret the averages in Eqs. (1.2.4) and (1.2.5) as averages over time for a single drunk, in the following manner: We observe a certain drunk over a very longperiod of time — a large number of steps. Every point alongthe drunk’s path can be considered as an initial point (assumingthat the eﬀect of the liquor does not diminish). Every such point can be considered as the origin of a coordinate system. For every such choice it is possible to ﬁnd the point that is reached by the drunk after N additional steps. In a coordinate system whose origin is at that initial point the drunk will be at RN . After reaching RN the drunk will take his next step in a random fashion (for if it were not so he would not be drunk); this means that for every choice of an initial point Ln will point in a diﬀerent direction. The averaging over all the choices of the initial point is the averaging from the second point of view. Exercise 2.2 Prove that for both points of view ⟨RN ⟩ =0. Solution on page 89 2.4 Brownian motion, random force and friction: the Langevin equation The treatment weusebelow is notexactly thesameas that formulated by Einstein in 1905, but is similar to the formulation by his close friend, Pierre Langevin, a short while later (1908). We describe the center of mass motion of a body in a gas as it evolves under an external force Fe and friction, i.e. a restrainingforce. The equa- tion of motion is M¨r + µ˙r = Fe . (1.2.6) A simple example of the appearance of a restraining force that is proportional to the velocity can be found in Self-Assessment Exercise 6 of this part. µ˙r is the restrainingforce, proportional to the velocity — this is a typical description of a frictional force. µ is a friction coeﬃcient and is connected, as will be mentioned later, to the viscosity. First, let us elucidate the role of the friction term in Eq. (1.2.6). We do this by way of the following exercises: 38 Ch. 2 Brownian Motion Exercise 2.3 (a) Calculate the dimensions of µ. (b) Show that in the absence of an external force the velocity of the body tends to zero for longtimes, even if its initial value is diﬀerent from zero, i.e. the friction restores the system to equilibrium. Solution on page 89 We will not enter here into an involved discussion of the connection between µ and the viscosity. We will limit ourselves to the following description: The viscosity describes an internal friction between diﬀerent layers of the ﬂuid (see also Sec. 3.6 below). A body in motion through a liquid drags along nearby liquid layers, giving rise to friction between successive liquid layers. This friction is expressed as a restrainingforce that acts on the body and is proportional to its velocity. If the body is a ball of radius a then the proportionality coeﬃcient is especially simple, as was found by Stokes: F =6πaηv. η is called the viscosity coeﬃcient. Its dimensions are [M ][L]−1[T ]−1, i.e. mass divided by length and time,viscosity and its units in cgs are poise, P. (1P = 10−1 kgm −1 s−1.) For a gas, η is about 10−4 P; it is 10−2 P for water and 8.5 P for glycerine. Exercise 2.4 The one-dimensional system (1.2.6) with Fe = mg describes a sky diver in a gravitational ﬁeld in air. Solve the equation, and verify that for long times the velocity of the sky diver is constant. What are longtimes? Solution on page 90 The solution to Exercise 2.4 indicates a way of measuring µ directly. The method is the same as that used for measuringthe viscosity. Namely, bodies are dropped in a gravitational ﬁeld in a certain medium and their ﬁnal speed is measured. Its absolute value is Mg/µ. From the fact that the frictional force causes the sky diver of Exer- cise 2.4 to accelerate at a slower rate than in a free fall, it follows that its total energy decreases with time. Exercise 2.5 Show that if Fe is a force derived from a potential, then the rate of change of the total energy of a body whose motion is described by Eq. (1.2.6) is dE dt = −µ˙r 2 . This is the rate of energy dissipation. 2.4 Randomforce and friction... 39 Reminder:the connection between the force and the potential is given by F = −∇U , where U is the potential energy. Solution on page 91 We have seen, therefore, that due to the friction µ˙r the particle can lose energy with time. Where does the friction come from and where does the energy go to? The friction that restores the body to equilibrium originates of course from the numerous fast collisions with the gas molecules. These collisions also give rise to the Brownian motion of the body. The connection between µ and microscopic factors will be considered in the next chapter. Here we note that µ˙r is part of the eﬀect of the momentum exchange between the gas molecules and the body, due to collisions. In these momentum exchanges the body transfers more energy to the gas molecules than it receives from them, due to the fact that in the direction of motion the body makes more frequent and harder collisions than it makes in the opposite direction. In other words, the energy of the body dissipates. Beyond the dampingeﬀect of the collisions with the molecules, these fast momentum exchanges contribute a sort of random force, Fe,that acts on the body in the absence of any external force. We make here two remarks: (a) The randomness of the force Fe is expressed by the fact that, if we average over many particles (averaging over an ensemble), or ensemble over diﬀerent initial times, we get ⟨Fe⟩ = 0 (1.2.7) as well as ⟨r · Fe⟩ =0 . (1.2.8) Compare this with the discussion in Sec. 2.3. Figure 1.2.4 shows a series of graphs that describes the behavior with time of a random force. The series can be read as an ensemble of diﬀerent systems, or as diﬀerent time intervals in the behavior of the same system alongthe time axis. The eﬀect of a random force actingon one system can be substituted by random forces actingon many systems. The as- sumption that these two approaches lead to the same result, an assumption that seems so natural, is called the ergodic hypoth- esis. The generality of its validity is still the subject of active research. (b) It is especially important to note that, if we were to assume that the entire eﬀect of the collisions amounts to the appearance of 40 Ch. 2 Brownian Motion a random force, i.e. µ = 0 in Eq. (1.2.6), the result would have been that the body could maintain a constant average velocity, without re-equilibratingwith its surroundings. The fact that the average velocity is conserved, in the absence of friction, is inferred from the observation that the average of a random force is zero — Eq. (1.2.7). Hence, if we substitute µ = 0 in Eq. (1.2.6) and average both sides we obtain d dt ⟨˙r⟩ =0 . system 1 system 2 system k ➤➤ ➤➤ ➤➤t1 F1 F2 Fk t2 t t t Fig. 1.2.4 Random forces. Exercise 2.6 Show that the above result is an immediate consequence of Eq. (1.2.6). Solution on page 92 The practical summary of the discussion above is, therefore, that the eﬀect of the collisions can be written (followingLangevin) as a sum of two contributingforces: one gives rise to the friction term and is proportional to the velocity, while the other is the random force that we called Fe. Equation (1.2.6) with a random force Fe is the Langevin equation. 2.5 The Langevin equation ... 41 2.5 Solving the Langevin equation: approximations and orders of magnitude Let us suppose that the force Fe in the Langevin equation (1.2.6) is the random force due to collisions with the gas molecules only, and attempt to deduce the time variation of the average square displacement of the body, ⟨r2⟩. Our aim is to show that this system, described by Eq. (1.2.6), has a solution that describes Brownian motion. We expect, therefore, ⟨r2⟩ to be proportional to the time. Since the solution involves analytic arguments along with statistical arguments, we shall discuss it in detail. As we are interested in the change of the magnitude ⟨r2⟩, we ﬁrst obtain an equation for r2: 1 2 M d2r2 dt2 + 1 2 µ dr2 dt − M ˙r 2 = r · Fe . (1.2.9) Note that Eq. (1.2.9) goes beyond the familiar context of diﬀerential equations. Beside functions of t and their derivatives, it contains a random element correspondingto some temporal sequence of the force, Fe,as those exempliﬁed in Fig. 1.2.4. It is a stochastic diﬀerential equation.Here we stochastic diﬀerential equation will restrict ourselves to a few comments concerningsuch equations: (a) To any given sequence, Fe, corresponds a particular solution; (b) The solution correspondingto any particular sequence of the random force is of little interest; (c) A quantity can be signiﬁcant only if it is not strongly dependent on the particular sequence; (d) Such a quantity can be calculated by averaging over all “acceptable” sequences, just because it is insensitive. (e) The “acceptable” set of sequences, the ensemble, has to be speciﬁed. The transition from Eq. (1.2.6) to Eq. (1.2.9) is obtained by taking the scalar product of Eq. (1.2.6) with r and usingthe identities d dt r2 =2r · dr dt , (1.2.10) d2 dt2 r2 =2r · d2r dt2 +2˙r 2 . Exercise 2.7 Complete the deduction of Eq. (1.2.9). Solution on page 92 The next step is to average both sides of Eq. (1.2.9) over the ensemble, simplifyingthe right hand side with the help of Eq. (1.2.8). In this manner 42 Ch. 2 Brownian Motion we obtain a diﬀerential equation for ⟨r2⟩: 1 2 M d2 dt2 ⟨r2⟩ + 1 2 µ d dt ⟨r2⟩− 2 〈 1 2 Mv2〉 =0 , where v was substituted for ˙r. The last average on the left hand side can be evaluated, at equilibrium, by the equipartition principle. Every degree of freedom, for each dimen- sion of space, is assigned an energy of 1 2 kT . The last term is therefore DkT ,where D denotes the number of dimensions of space. Thus the equation becomes M ¨u + µ ˙u =2DkT , (1.2.11) where we denoted ⟨r2⟩ by u. This equation can be fully solved. The initial conditions are chosen to be r(t = 0) = 0, namely the origin of the coordinate system of each body in the ensemble is chosen as its position at t =0. In this case u(t =0) = ˙u(t = 0) = 0, and u(t)= 2DkT µ [ t + θ(e −t/θ − 1) ] , (1.2.12) where θ = M µ . (1.2.13) Exercise 2.8 Check that Eq. (1.2.12) is in fact the solution to Eq. (1.2.11), satisfying the initial conditions, and that the parameter θ has the dimensions of time. Solution on page 93 Let us inquire what happens to the body a very short and a very longtime after the initiation of its motion, and compare to our physical intuition. Short and longtimes must be measured with respect to a char- acteristic time appearingin the problem. In our case this characteristic time is θ. That is, at short times t ≪ θ, it is possible to expand the exponential in Eq. (1.2.12): u(t)= ⟨r2⟩≈ DkT M t2 . (1.2.14) ex =1 + x + x2 2! + x3 3! + ··· . Puttingit simply, at very short times, relative to times between col- lisions, the body moves as a free particle with constant velocity. The 2.5 The Langevin equation ... 43 constant velocity is the thermal velocity as determined at equilibrium, i.e. vT =(DkT /M )1/2. Notice that although we considered short times we have not ignored the body’s previous collisions (before t =0), which allowed it to acquire thermal velocity. Otherwise our entire discussion of short times is invalid, since without thermal velocity we cannot use Eq. (1.2.11). For longtimes t ≫ θ, the exponential decays away, and θ can be neglected, in this limit, compared to t.So u(t)= ⟨r2⟩∼ 2DkT µ t. (1.2.15) This result is the same as Eq. (1.2.2), with a bonus of a relation between the coeﬃcient α and the macroscopic characteristics of the problem: α = 2DkT µ . (1.2.16) To obtain an idea of the orders of magnitude of the times for which the two approximations are valid, we compute the magnitude of the time θ. To this end, let us assume that our Brownian particles are spherical. This will allow us to use Stokes’ law for a sphere: µ =6πηa. We further assume that the small sphere is ﬂoatingin water, whose viscosity is η =10−2 P. The particle’s mass, whose radius is about one micrometer and whose speciﬁc weight is close to that of water, will be about 5 × 10−12 g,sothat M µ ≈ 2 × 10 −7 s . This means that in any reasonable experiment, lastingmore than 10−3 s, we will not notice the region t ≪ θ but only the region t ≫ θ. Hence, the average square distance of the body from its initial position, will be linear with time. We further remark on the role of D — the dimensionality of space — in Eq. (1.2.16). In experiment ⟨r2⟩ is usually measured in a space whose dimensionality is less than that of the space in which the body actually moves. This happens, for example, when we measure the projection of the position of the body on the focal plane of the microscope lens. In this case D = 2, though the body’s real motion is in three-dimensional space. As already mentioned, µ and η can be measured directly. With the help of the Brownian motion, i.e. with the help of Eq. (1.2.16) it is pos- sible to measure the Boltzmann constant k. Combiningthis with the gas equation which gives R, it is possible to obtain Avogadro’s number. Indeed, this is how J. Perrin obtained the ﬁrst precise determination of Avogadro’s number in 1908. 44 Ch. 2 Brownian Motion 2.6 Applications and implications The Brownian behavior — the ﬂuctuations that are induced in the motion of a ﬁne system as a result of the thermal agitation of the surroundings with which the system is in equilibrium — appears in diﬀerent contexts. We shall here elaborate on the two cases that were mentioned in Sec. 2.1. But before doingthat let us broaden the discussion in Secs. 2.4 and 2.5, even if in a somewhat artiﬁcial manner. Let us assume that the ﬂoatingbody is attached to a spring connected at the origin. In this case Eq. (1.2.6) will take the form M¨r + µ˙r + Cr = Fe . (1.2.17) The last term on the left hand side originates, of course, from the work required in order to stretch the spring( 1 2 Cr2). Since it is quadratic in r, the thermal average of 1 2 Cr2 is given by the equipartition principle, and is identical to that of the kinetic energy, as in Eq. (1.1.60) of Sec. 1.6. That is, at thermal equilibrium (and only then) 〈 1 2 Cr 2〉 = 〈 1 2 M ˙r 2〉 = 1 2 DkT . (1.2.18) If we perform on (1.2.17) the same operations that brought us from Eq. (1.2.6) to Eq. (1.2.9) and to Eq. (1.2.11), we obtain for u = ⟨r2⟩ the equation M ¨u + µ ˙u +2Cu =2DkT . (1.2.19) Exercise 2.9 Derive the above equation. Solution on page 93 Equation (1.2.19) appears exactly like the one-dimensional version of Eq. (1.2.17), except that instead of the random external force a constant force is acting. Alternatively, it is possible to transfer the “force” 2DkT to the left hand side, and to imagine that u describes the displacement of the springnot from a loose state but from a state in which it is stretched on average according to 2Cu =2DkT . Thus, if we deﬁne a new variable v = u − DkT /C we obtain an equation that is identical to the equation of a damped harmonic oscillator: M ¨v + µ ˙v +2Cv =0 . (1.2.20) The solution to Eq. (1.2.20) includes an exponentially decayingfactor, as for the case C = 0, in addition to a restoringforce (2Cv) producing 2.6 Applications and implications 45 vibrations around v = 0. Thus, even without investigating the solution in detail we can reach the conclusion that at longtimes v tends to its equilibrium value, i.e. zero, and that u tends to its equilibrium value, DkT /C, as inferred from Eq. (1.2.18). If we search for a solution of the form e−γt, we ﬁnd that the substitu- tion in Eq. (1.2.19) gives two possible values (both positive) for γ: γ1,2 = 1 2θ ( 1 ± √ 1 − 8CM µ2 ) ,γ2 >γ1 . (1.2.21) And the solution correspondingto the initial conditions u(t =0)= ˙u(t =0) =0 is ⟨r2⟩ = u(t)= DkT C ( 1 − γ2e−γ1t − γ1e−γ2t γ2 − γ1 ) . (1.2.22) Indeed, for longtimes ⟨r2⟩ tends to its equilibrium value. (See also Fig. 1.2.5.) DkT C t <r2> Fig. 1.2.5 A graphic representation of Eq. (1.2.22). Finally, we note that when the square root in Eq. (1.2.21) becomes imaginary, i.e. when the damping is small, the exponential solution be- comes a solution of damped oscillations. This solution also tends to DkT /C at longtimes. Exercise 2.10 Obtain Eq. (1.2.22), and check its short time behavior. When is u(t)a linear function of time? Solution on page 93 Notice that the behavior at times which are not too longresembles that of ordinary Brownian motion without an elastic force. At ﬁrst u 46 Ch. 2 Brownian Motion grows quadratically with time, when the eﬀect of the collisions and of the elastic force are still negligible. Later, when the eﬀect of the collisions starts to be signiﬁcant, but the elastic force is still negligible, the body does indeed move as in Brownian motion. In contrast, at longtimes the elastic force dominates and does not allow further separation beyond the limit set by the temperature. This situation does not describe a group of drunk people who move freely from the moment they leave the bar, but rather a group of drunk horses that are tied by ﬂexible straps at the entrance to the bar. A more physical example for this state of aﬀairs is the galvanome- ter. This instrument is used to measure very small currents, by means of the very small angles of rotation of a quartz whisker that these currents induce. We shall not halt here to explain how the currents induce the rotations of the whisker, but rather concentrate on the way these rota- tions are measured. A tiny mirror is connected to the whisker. Light is projected on the mirror and the angle of rotation φ of the whisker is measured by registering the angle into which light is reﬂected from the mirror, on a scale (see Fig. 1.2.6). ➤ ➤ lightφ deflection angle Fig. 1.2.6 Measurement of the angle of reﬂection in a galvanometer. Here as well, the mirror and the quartz whisker are in thermal equi- librium with the surroundinggas. The rotations of the whisker have a kinetic energy that depends on the moment of inertia of the system, i.e. 1 2 I ˙φ2, and a potential energy U = 1 2 aφ2,where −aφ is the restoringforce of the whisker. In this case the temporal behavior of φ(t) is determined by Eq. (1.2.17), with the followingsubstitutions: dimensionality D =1 ,C → a, M → I, r → φ. Here, too, there exists a random force or torque, originating from the collisions of the whisker and the mirror with the gas molecules, that gives 2.6 Applications and implications 47 a friction term µ ˙φ, which restores equilibrium, as well as the force Fe, whose average vanishes. The result is that even in the absence of a current, deviations will ap- pear due to thermal ﬂuctuations. The average square angular deviations will be given by Eq. (1.2.22) in terms of the parameters of the galvanome- ter. For longtimes one ﬁnds ⟨φ 2⟩ = kT a , which is appropriately dimensionless. This is a noise that limits the pre- cision of the instrument. In order to reduce it, the instrument has to be cooled. But where? The answer can be found in Sec. 2.4. The ﬂuctuations that give rise to ⟨φ2⟩ are the ones that produce the friction, and therefore the part in which friction is created has to be cooled. This can be, for example, the mirror which suﬀers collisions with the gas molecules. In this case the gas has to be cooled. Exercise 2.11 How can we measure the restoringforce constant a of the whisker? Solution on page 94 In Sec. 2.5 we saw that the characteristic time for Brownian motion θ = M/µ is very short — 10−7 s. Thus, it is impossible to observe in an experiment on Brownian motion the exponential decay to the linear region. Here, on the other hand, θ = I/µ, but µ can be reduced by reducingthe pressure of the gas, making it possible to increase θ up to measurable magnitudes and to check the predictions of the theory in great detail, as was done by Kappler in 1931. Finally, we mention another analogous instance — the Johnson noise, Johnson noisecaused by the ﬂuctuations in a resistor, of a resonatingcircuit with a high Q factor (see Fig. 1.2.7). The thermal ﬂuctuations, caused by the collisions of electrons, which form the current I, with the atoms in the quality factorresistor, produce also here the double eﬀect — resistance R, which damps the system and drags it towards equilibrium at zero current, and a random induction resistor L C R capacitor Fig. 1.2.7 A resonating circuit. A high Q value means that the circuit ampliﬁes signiﬁcantly only in a very narrow band around the resonant frequency ω =1/ √LC. 48 Ch. 2 Brownian Motion (electromotive) force. The equation of the circuit determines the charge on the capacitor q: L¨q + R ˙q + q C = Ve . (1.2.23) Here C is the capacitance, L the induction and Ve the random electro- motive force originating from the ﬂuctuations in the resistor. This is the Langevin equation, analogous to Eq. (1.2.17), with the substitutions D =1 , Fe → Ve ,C → 1 C ,µ → R, M → L, r → q. We are of course interested not in the solution to Eq. (1.2.23), but in the solution to the equation that determines the time dependence of ⟨q2⟩ or of the directly measurable quantity ⟨V 2⟩,where V = q C is the voltage across the capacitor. The equation obtained for ⟨V 2⟩ has the same form as Eq. (1.2.19), which was solved in detail. But even without solvingthe equation we can reach the following conclusions: the ﬁrst term of Eq. (1.2.23) comes about from the “kinetic energy” term, 1 2 LI 2, while the last term originates in a “potential energy” term, q2 2C . Therefore, at equilibrium we obtain an equation that resembles Eq. (1.2.18): 〈 q2 2C 〉 = 〈 1 2 LI 2〉 = 1 2 kT . (1.2.24) Since there are charge ﬂuctuations, there will also be voltage ﬂuctuations (Johnson noise), which are ⟨V 2⟩ = kT C (1.2.25) or ⟨V 2⟩ = ω2LkT , (1.2.26) where ω is the resonant frequency of the circuit. Chapter 3 Transport Coeﬃcients 3.1 Introduction One of the strongobjections against the kinetic theory of Maxwell and Boltzmann was known as “slow diﬀusion.” In simple words, according diﬀusion to the kinetic theory, the average (thermal) velocities in gases in stan- dard conditions are about 103 ms−1. Hence, if a gas is inserted at one end of an empty container, the molecules should appear at its other end within a fraction of a second. However, this is not what is observed in experiment. In order to cope with this observation Clausius introduced (in 1889) the concepts of mean free path and mean free time.He asserted that it is true that the average distance between molecules in a gas is large compared to the size of the molecules, but because of the high speeds the molecules collide very frequently, changing their direction of motion, so that the gas moves in a given direction at a speed that is much lower than the thermal speed — it moves at the diﬀusion speed. The concept of a mean free path, the average distance traversed by mean free patha molecule in the gas between two collisions, is a very central concept of the kinetic theory (it was mentioned in Sec. 2.2 in connection with the Brownian particle). Directly connected with the mean free path is the mean free time, which is the average time between consecutive collisions mean free timein the gas. In other words, this is the average time during which the molecule moves as a free particle. The clariﬁcation of the concept of a mean free path and its quantitative evaluation opened the way for the calculation of many important quanti- ties, transport coeﬃcients, amongst which we ﬁnd the mobility, diﬀusion coeﬃcients of sorts, the viscosity, thermal conductivity and more. The transport coeﬃcients describe the behavior of the system when there is a slight deviation from an equilibrium state. Such a deviation can be caused by the application of an external force (in the cases of mobility 49 50 Ch. 3 Transport Coeﬃcients and viscosity) or by creatingconcentration gradients (in the case of diﬀu- sion) or temperature gradients (in the case of thermal conductivity). Such deviations from equilibrium create currents, which drive the system back to equilibrium. The ratios between the currents and the disturbances that create them are the transport coeﬃcients. All of these will be treated in this chapter. 3.2 The mean free path and mean free time The problem at hand is the calculation of an average distance, ℓ,for which an average gas molecule will collide at least once — this is the mean free path. For the sake of simplicity we will suppose that the molecules are rigid balls, of radius a, so that their trajectories change only when there is direct contact between them. This is a reasonable approximation for the noble gases. If we will know ℓ, as a function of the characteristic parameters of the gas (temperature, density, molecular radii, etc.), we will be able to obtain the mean free time from τ · ¯v = ℓ, (1.3.1) where ¯v is the average velocity of the molecules. ➤➤ π(2a)2 ➤➤L Fig. 1.3.1 Collision cross section of a rigid ball of radius a. We start with a very rough calculation, in the spirit of Sec. 2.2, and proceed to a more sophisticated and complicated calculation, which ex- poses some of the approximations made in the rough calculation, and of their precision. Figure 1.3.1 visualizes the fact that a molecule moving in a straight line will collide with every molecule whose center is found in a cylinder alongits directon of motion whose radius is twice the radius of the molecule. The number of molecules in a cylinder of this radius and length L is (4πa2L)n,where n is the density. The average distance traversed by a molecule until the ﬁrst collision is the distance in which 3.2 The meanfreepathand meanfreetime 51 the average number of molecules in this cylinder is 1. Hence ℓ = 1 4πa2n . (1.3.2) We will make a few remarks on this simple expression. First, clearly, the true meaningof the size 4πa2 is: the cross section for the collision of two molecules. cross section Scattering cross section:the area normal to the direction of motion, such that every molecule that passes through it is bound to collide with the target. In our case this is a circle whose radius is twice the radius of a molecule. Second, the properties of ℓ, as reﬂected from Eq. (1.3.2), correspond nicely with intuition. As the density of molecules or their cross section areas increase, ℓ must decrease. Exercise 3.1 Is the dependence on n and a, together with a dimensional analysis, suf- ﬁcient to lead to the expression (1.3.2) for ℓ? Solution on page 95 Third, the arguments we used are very rough, and may be criticized in many respects. Some of the implicit assumptions in this calculation will remain even in the more detailed calculation that will be made below. Exercise 3.2 What are the implicit assumptions of the above calculation? Solution on page 95 We now want to calculate the mean free path and the average time between collisions, namely the mean free time, in a more precise fashion, while still retainingtwo simplifyingassumptions: (a) The gas is dilute so that collisions occur only between pairs of molecules. (b) The molecules behave as rigid balls of radius a. Before turningto the calculation of the mean free time we calculate a simpler quantity that will be useful later on, that is the average rate at which the molecules beat against a unit area of the side of the container. 52 Ch. 3 Transport Coeﬃcients ➤ ➤ –z v A θ Fig. 1.3.2 A molecule with velocity v will strike an area A of thesideof thecontainer. Actually we almost calculated this quantity on our way to Eq. (1.1.3). The number of molecules strikingan area A duringtime ∆t and whose velocity component normal to the surface is vz, was found in Sec. 1.1 to be ∆N (vz)= vz∆tAn(vz) , (1.3.3) where n(vz) is the density of molecules of velocity vz. Notice that what we called the x direction in Sec. 1.1 we here call z. In order to ﬁnd the total number of molecules that strike the surface, we have to sum over all the values of the velocity vz such that vz > 0, since molecules for which vz < 0 are movingaway from the surface and will not strike it. We have ∆N = A∆t ∫ ∞ 0 vzn(vz)dvz . (1.3.4) The distribution of the velocity component vz is given by the one- dimensional Maxwell distribution obtained from the integration of f ( v) [see Eq. (1.1.49)] with respect to all values of vx and vy: n(vz)= N V ∫ f (v)dvxdvy . (1.3.5) Substitutingthis into Eq. (1.3.4) we obtain ∆N = A∆t N V ∫ vz>0 vzf (v)dvxdvydvz . (1.3.6) Now, because the velocity distribution is isotropic (there is no pre- ferred direction for the velocities) f (v) depends, actually, only on the absolute value of the velocity, v, as is seen on the right hand side of Eq. (1.1.49). Thus, we can perform the integration over all possible an- gles separately from the integration over v. Because vz = v cos θ and dvxdvydvz = v2 sin θdvdθdφ,we ﬁnd that ∆N = A∆t N V 2π ∫ ∞ 0 v3f (v)dv ∫ π/2 0 cos θ sin θdθ . (1.3.7) 3.2 The meanfreepathand meanfreetime 53 Note that θ can vary only up to π/2—reﬂectingthefactthat weare only takinginto account molecules that are approaching the side (vz > 0). The second integral is simple to evaluate and its value is 1/2. A closer look at the ﬁrst integral reveals that it is proportional to the average of the absolute value of the molecular velocity, ¯v,since ¯v = ⟨|v|⟩ = ∫ f (v)|v|dvxdvydvz =4π ∫ ∞ 0 f (v)v3dv . (1.3.8) We have found, therefore, without makingany assumptions about the form of the velocity distribution apart from the assumption of isotropy, that the rate at which molecules strike a unit area of a side, ν,is ν = 1 4 n¯v. (1.3.9) If the velocity distribution is given explicitly it is possible to express ¯v in terms of the characteristic quantities of the gas. For example, if the velocity distribution is Maxwellian we ﬁnd ν = n √ kT 2πm . (1.3.10) Exercise 3.3 (a) Derive Eq. (1.3.10). (b) Calculate the escape rate of the gas molecules from a container with a small hole of area A at its side. Solution on page 96 Next we calculate the average time between two consecutive collisions of a given molecule. We apply considerations of the type introduced in computingthe mean free path. As we said there, for a given molecule to encounter another, it must travel a distance 1 4πa2n . If one molecule is sta- tionary and the other is moving, this distance is crossed in a time 1 4πa2n¯v , on the average. But since both molecules are moving, ¯v should be replaced by the average relative velocity at equilibrium, ¯vrel. In Exercise 3.4 we show that ¯vrel = √ 2¯v. (1.3.11) Exercise 3.4 Prove Eq. (1.3.11). Solution on page 96 54 Ch. 3 Transport Coeﬃcients Hence we ﬁnd that the mean free time τ is τ = 1 √ 24πa2n¯v . (1.3.12) Our ﬁrst inclination would be to substitute this expression for τ in Eq. (1.3.1), and to calculate the mean free path ℓ.If we do this we obtain a result that is closer to the truth than Eq. (1.3.2), yet not totally accurate: ℓ ≈ 1 √ 2 · 1 4πa2n =0.707 1 4πa2n . (1.3.13) The reason for this inaccuracy is the fact that the mean free time for a given molecule depends, as indicated by Eq. (1.3.12), on its veloc- ity. Thus, the accurate way of calculating ℓ will be to ﬁrst calculate the mean free path for a molecule that moves at a given velocity, and then to average over all the velocities using the Maxwellian distribution func- tion. The result of this calculation, which will not be performed here, will be the replacement of the factor of 0.707 in Eq. (1.3.13) by a factor of 0.677. Exercise 3.5 Show that in a gas under standard conditions the ratio between ℓ and the intermolecular distance is 103, while the ratio of ℓ and a is 104. Solution on page 97 Exercise 3.6 Oxygen ﬁlls a cubic container with a side of 5 cm, at a temperature of 100◦C. At what pressure will the mean free path be equal to the size of the container? What will the mean free time then be? Solution on page 98 Exercise 3.7 Use the simple argument for calculating the mean free path to obtain the mean free path in a mixture of gases of densities n1 and n2 and molecular radii a1 and a2, respectively. Solution on page 99 3.2 The meanfreepathand meanfreetime 55 Fig. 1.3.3 The number of molecules that cover a distance s without colliding. Clearly not all molecules traverse an equal distance between collisions, and not all of them remain a time τ without collisions. What is, there- fore, the distribution of the free distances, i.e. the probability of ﬁnding molecules that have traversed a distance s without experiencinga colli- sion. Actually it is better to think here in terms of numbers of molecules and to ask how many of the molecules travel a given distance without colliding. Let us suppose that N0 molecules leave the last collision, and denote by N (s) the number amongthem that traveled a distance s with- out colliding. The number of collisions per unit length is 1/ℓ. Hence, the average number of molecules that will collide, when the distance grows from s to s + ds,is N (s)ds/ℓ, i.e. the product of the number of molecules that went a distance s without colliding, and the ratio between the extra distance ds and the distance ℓ required for one more collision. However, this number is also the reduction in N (s), namely N (s) − N (s + ds), where N (s + ds) is the number of molecules that traveled the distance s + ds without colliding. Hence dN = − 1 ℓ N (s)ds (1.3.14) and from here N (s)= N0e −s/ℓ . (1.3.15) The actual probability we set out to ﬁnd is P (s)= 1 ℓ e−s/ℓ. Note the diﬀerence between: (a) The probability that the distance traveled by a molecule between two collisions is exactly s. (b) The probability that the distance traveled by a molecule between two collisions is at least s. 56 Ch. 3 Transport Coeﬃcients Actually, we mentioned only the distribution corresponding to (b). It is possible to show that distribution (a) is also exponential. Exercise 3.8 Prove that the average distance traversed by a molecule without experi- encingany collisions, with the distribution (1.3.15), is ℓ. Solution on page 99 Exercise 3.9 Show that the distribution of times between collisions is N (t)= N0e −t/τ . (1.3.16) Solution on page 100 3.3 Self-diﬀusion The common diﬀusion problem deals with a mixture of two materials (gases in our case), whose relative density changes from place to place. Thus, without the application of an external force, currents of the two materials ﬂow — currents that drive the system towards a state of equi- librium, namely to a spatial uniformity. The current J is related to the density of the particles n and to their velocities by J = nv. Sometimes J is called the current density, while the term “current” is used tocurrent density refer to the product of J and a given area perpendicular to the ﬂow, as is done in the deﬁnition of the electric current. We will here treat a simpler problem, yet it contains the main ideas. We will discuss a problem in which the gas is composed of molecules, of equal mass and equal size, that belongto two distinguishable types. An approximation to this situation can be found in a mixture of N2Oand CO2 (both with molecular mass of 44), or in a mixture of two isotopes. The total density is uniform in the container, but the densities of the constituents vary. We shall concentrate on one of the constituents and assume, for sim- plicity, that its density n1 varies in one direction only, which we choose to be the direction of the z axis. Experiments establish that the current — the number of particles of the type considered, which cross a unit area in the xy plane per unit time — is proportional to the derivative of the density: Jz = −D ∂n1 ∂z . (1.3.17) 3.3 Self-diﬀusion 57 The minus sign signiﬁes that the current ﬂows from high density to low density The derivative is partial since n1 depends on time as well. D is called the diﬀusion coeﬃcient. Its dimensions are [L]2[T ]−1,and its units are m2 s−1. As will be seen later on, it is closely connected with the coeﬃcient α in Eq. (1.2.2), which can also be expressed in terms of the frictional coeﬃcient and the temperature [see Eq. (1.2.16)]. Note that from now on the letter D stands for the diﬀusion coeﬃcient and not for the dimensionality of the system as in (1.2.16). Typical values for gases, in these units, are 10−5–10−4. For liquids the typical values are a million times smaller. The origin of the current and its connection with the density variation are quite obvious. Because the temperature in the gas is uniform, the molecules have equal velocity distributions in all directions at every point. As a result molecules move from place to place at a rate that is equal to the product of the velocity and the density. This rate is the number of molecules that will cross a unit area in unit time. Therefore, more molecules will cross per unit time from a location of high density to a location of low density than in the opposite direction, since the velocity distributions are identical at both locations. This simple argument will now be turned into a quantitative relation- ship between D and the characteristics of the gas. This will be done in two ways: the ﬁrst is simpliﬁed, and the second (which appears in the appendix) is more complex and will indicate the sort of arguments that need to be made for a more careful calculation. Simple calculation. The idea is that the molecules that pass through the plane z = 0 will come on average from a distance which is the mean free path, above this plane or below it. On average 1/6 of the molecules have a velocity along+z or −z (1/3 for the choice of a given axis and 1/2 for the choice of direction). The net current density ﬂowingup across z =0 is Jz ≈ 1 6 ¯v[n1(−ℓ) − n1(ℓ)] , (1.3.18) as is depicted, schematically, in Fig. 1.3.4. If the density n1(z) varies slowly — on a scale of the mean free path — we can expand the right hand side of Eq. (1.3.18) in powers of ℓ.If we keep only the linear term, we obtain Jz ≈− 1 3 ¯vℓ ∂n1 ∂z . (1.3.19) 58 Ch. 3 Transport Coeﬃcients Fig. 1.3.4 Pictorial description of Eq. (1.3.18). A comparison with Eq. (1.3.17) yields D ≈ 1 3 ¯vℓ . (1.3.20) Exercise 3.10 Showthatatconstanttemperature thedependence of D on P is given by D ∝ 1 P , and that at a constant pressure D ∝ T 3/2 . Solution on page 100 We now draw a few conclusions. First, Eq. (1.3.17) can be generalized to the case where n1 varies alongan arbitrary direction. The generaliza- tion is simple and can be deduced from geometrical arguments: since the current is a vector, the right hand side must also be a vector. The vector that can be created from ﬁrst derivatives is the gradient, so that J = −D∇n1 . (1.3.21) Since the gradient of n1 is directed alongthe direction of the fastest vari- ation of n1, it is natural for this to be the direction of the current. The meaning of Eq. (1.3.21) in terms of components is Jx = −D ∂n1 ∂x ,Jy = −D ∂n1 ∂y ,Jz = −D ∂n1 ∂z . In order to see that ∇n1 is directed along the direction of the fastest variation in n1, we write the change in n1 between the initial point r and a nearby point r +∆r: ∆n1 ≈ ∂n1 ∂x ∆x + ∂n1 ∂y ∆y + ∂n1 ∂z ∆z =(∇n1) · ∆r , and it is clear that ∆n1 will be maximal when the angle between ∇n1 and ∆r is zero, namely when ∆r is in the direction of the gradient. 3.3 Self-diﬀusion 59 left inside: flow in:➤➤➤ ∆t (∆n1)∆x∆y∆z = [n1(t+∆t)–n1(t)]∆x∆y∆z Jz(z+∆z)∆x∆y∆t Jz(z)∆x∆y∆t z z+∆z ∆x ∆y flow out: Fig. 1.3.5 The balance of currents in the region around z. Second, the number of particles of every type is conserved. This means that each type of particle satisﬁes a continuity equation, expressingthe continuity equationfact that the density changes must come from the balance of the current entering the region around a given point and the current that is leaving it. For particles of type 1, for example, Fig. 1.3.5 is a pictorial derivation of the continuity equation ∂n1 ∂t = − ∂Jz ∂z . (1.3.22) Exercise 3.11 What is the generalization of Eq. (1.3.22) to the three-dimensional case? Use geometrical arguments. Solution on page 101 If we substitute Eq. (1.3.17) into Eq. (1.3.22), we obtain the celebrated diﬀusion equation diﬀusion equation∂n1 ∂t = D ∂2n1 ∂z2 . (1.3.23) For the one-dimensional case, n1 is a function only of z and t.A typical solution to this equation, with an initial condition that at the time t =0 60 Ch. 3 Transport Coeﬃcients all the particles of type 1 are concentrated at z =0, is n1(z, t)= C √ Dte −z2/4Dt , (1.3.24) where C = N1/ √4π is a normalization factor (see Exercise 3.12). The av- erage square displacement of the particles of type 1 can also be computed in terms of the solution (1.3.24): ⟨z2⟩ =2Dt . (1.3.25) Exercise 3.12 (a) Verify that Eq. (1.3.24) is in fact a solution to Eq. (1.3.23). (b) Show that the total number of particles of type 1 does not depend on time and clarify the meaningof the constant C. (c) Plot n1(z, t) as a function of t, at a given value of z ̸=0. (d) Prove Eq. (1.3.25) and ﬁnd the relation between the time needed for a molecule to traverse a certain distance by diﬀusion, and the time it needs to traverse the same distance by free motion at the thermal velocity. Solution on page 101 Finally, we note that in the more realistic case of a three-dimensional system the diﬀusion equation will take the form ∂n1 ∂t = D ( ∂2n1 ∂x2 + ∂2n1 ∂y2 + ∂2n1 ∂z2 ) (1.3.26) and the analogof the solution (1.3.24) will be n1 = N1 (4πDt)3/2 e −r2/4Dt , (1.3.27) where N1 is the total number of particles of type 1: N1 = ∫ n1dV .The average square distance will in this case be ⟨r2⟩ =6Dt . (1.3.28) A comparison of Eq. (1.3.28) with Eq. (1.2.2) clariﬁes immediately that α and D are one and the same apart from a numerical factor, i.e. α =6 in this case. 3.4 The mobility coeﬃcient 61 3.4 The mobility coeﬃcient In our discussion concerningdiﬀusion we saw that a small deviation from a state of equilibrium, in the form of an induced density gradient in the gas, gives rise to a current. Another way to create currents is by applying an external force. When a particle moves freely, exertion of a force causes it to accelerate and the acceleration, accordingto Newton, is proportional to the force. As already mentioned, with respect to Brownian motion, a particle that is movingin the gas is exposed to damping and its velocity is proportional to the exerted force. That is, if a constant force is actingon a special particle in the gas (diﬀerent charge, diﬀerent mass), then its velocity, the drift velocity, will be vd = KF . (1.3.29) K is called the mobility coeﬃcient. Its dimensions are mobility [K]=[M ] −1[T ] . It is possible to understand Eq. (1.3.29) and to express K with the help of the parameters of the gas using a very simple argument: between two collisions the particle which feels the force is accelerated accordingto Newton’s law, a = F m , (1.3.30) where a is the acceleration and m is the mass of the particle, so that its velocity at time t after a given collision is v = v0 + F m t, (1.3.31) where v0 is the velocity of the particle immediately after the collision. If we now calculate the average of v over many collisions alongits path, the average of v0 will be zero, since the velocities that particles have immediately after a collision are completely random. Thus, the average velocity of the accelerated particles will be equal to the acceleration times the average time ⟨t⟩ elapsed since the previous collision, which is the same as the average time between collisions τ (see the calculation of ⟨t⟩ in Solution 3.13). Namely vd = ⟨v⟩ = F m τ, (1.3.32) Comparingwith Eq. (1.3.29) one obtains the mobility as a function of quantities from the kinetic theory: K = τ m . (1.3.33) 62 Ch. 3 Transport Coeﬃcients The drift velocity vd is therefore the “eﬀective” velocity at which the particle advances (alongthe direction of the force), in spite of the random collisions with the molecules of the gas. The external force “drags” the particle in a speciﬁc direction, and in its absence the drift velocity is zero. Note the diﬀerence between the drift velocity and the average thermal velocity ¯v. These are two diﬀerent averages! Exercise 3.13 We can try to calculate K in the followingway. The distance d that is covered by the particle duringthe mean free time is d = 1 2 F m τ 2 . The average velocity is the ratio of this distance to the average time. The result is that K is two times smaller than in Eq. (1.3.33). Which result is correct? What happened here? Hint: calculate v and d with the help of the distribution (1.3.16). Solution on page 103 The argument given above as a derivation of Eq. (1.3.29) is actually a paraphrase of the description of a body executingBrownian motion in Chap. 2 (Secs. 2.4 and 2.5). In that case the numerous collisions with the molecules of the gas were expressed as a viscosity. The diﬀerence with respect to our discussion here is that here an additional constant external force with nonzero average is acting on the body. Hence, a direct averaging of Eq. (1.2.6) yields m d⟨v⟩ dt + µ⟨v⟩ = ⟨Fe⟩ . (1.3.34) Since, as we have seen, the characteristic time m/µ is about 10−7 s (Sec. 2.5), the average acceleration of the body vanishes almost imme- diately, and we obtain vd = µ −1F . (1.3.35) This means that, in addition to the Brownian motion around its original position, the particle drifts alongthe direction of the force at a velocity vd. If we compare this equation with Eq. (1.3.32), we ﬁnd that the mobility is none other than K = 1 µ . (1.3.36) 3.5 Diﬀusion and mobility 63 So far we have been talkingof the mobility of a special particle in the gas. However, it is possible to repeat the arguments for one of the particles of the gas itself when an external force acts on all or some of them. Examples for this situation are the motion of ions in a gas or in a solution when an electric ﬁeld is applied, the motion of particles in a centrifuge or in a gravitational ﬁeld, and so on. In Part V we will apply the same methods to the electric conductivity of metals. In this situation Eq. (1.3.32) describes the average velocity of one of the particles on which the force is acting. But because there is a macroscopic number of such particles, we can use the ergodic hypothesis to interpret vd also as the average velocity of all the particles at a given time. Equation (1.3.32) describes, therefore, a ﬂow of particles in which, in addition to their random motion, there is an ordered (small) velocity component movingthem in the direction of the force. 3.5 The connection between the diﬀusion coeﬃcient and the mobility Comparison of Eqs. (1.2.15) and (1.3.28) leads to the relation D = kT µ , (1.3.37) keepingin mind that in the ﬁrst D is the number of dimensions, while in (1.3.28) it is the diﬀusion coeﬃcient. On the other hand, we have established that K = µ−1, so that in three dimensions D K = kT . (1.3.38) This is a very impressive result: the ratio of two very diﬀerent quan- tities depends solely on the temperature, and in a very simple manner. However, the impression is spoiled by the observation that the ratio was obtained by usingLangevin’s equation, which describes the motion of a Brownian particle. The validity of this equation for the motion of molecules or ions is by no means obvious. We will now see, following Feynman’s Lecture Notes in Physics, that the relation (1.3.38) is indeed very general. We assume that n1 is the number of molecules of type 1 per unit volume, as in Sec. 3.3. These are the labeled molecules. If a force F is actingon them, their drift velocity is [Eq. (1.3.29)] v = KF , 64 Ch. 3 Transport Coeﬃcients so that a current of particles of type 1 is created, which is JM = n1v = n1KF . (1.3.39) On the other hand, a diﬀusion current of molecules of type 1 will develop [Eq. (1.3.21)], which we will denote by JD: JD = −D∇n1 . (1.3.40) In a state of equilibrium, JD + JM =0 , (1.3.41) and so F satisﬁes n1KF = D∇n1 . (1.3.42) But from the discussion of the isothermal atmosphere (Sec. 1.4) we know that a relationship exists between a force (or potential) ﬁeld and the den- sity. If the force F is derived from a potential U , i.e. F = −∇U , then the presence of F corresponds to a spatial distribution or density distribution, Eq. (1.1.32): n1 = Ce −U/kT , and the correspondingdensity gradient is ∇n1 = − 1 kT n1∇U = 1 kT n1F . (1.3.43) For this density gradient to satisfy the equilibrium conditions, Eq. (1.3.42), the relation (1.3.38) must hold. That is, the possibility of exertinga force and maintaining a density gradient (even in a thought experiment) requires that the diﬀusion current be canceled by the drift current, from which D/K = kT . And if the result (1.3.38) seemed impressive at ﬁrst, then the way it was deduced here is even more impressive, and worth a second and a third reﬂection. 3.6 Viscosity and thermal conductivity Viscosity An experimental situation in which the viscosity will appear under simple conditions is the following: A container with parallel plane walls is ﬁlled with gas. One of the walls, to which the large arrow is attached in Fig. 1.3.6, is moving at a constant velocity u. 3.6 Viscosity and thermal conductivity 65➤ ➤ ➤ x –y z Fig. 1.3.6 A typical situation in which viscosity appears. A velocity gradient appears in the gas. Each layer in the gas, parallel to the xy plane, advances at a diﬀerent speed, ux(z), alongthe x direction. It turns out that in order to maintain the speed ux(z), a constant force must be exerted on the movingplane along the x direction, which is proportional to the area in motion and to the speed gradient in the gas dux/dz. The force, i.e. the viscosity force, acts to stop the motion of the plane. The gas exerts, therefore, a force σxz per unit area on the moving plane, which is written as σxz = −η dux dz . (1.3.44) The label xz signiﬁes that a force is exerted in the x direction as a result of the variation of the speed in the z direction. Actually, in more complex situations there can be other components, such as σxy ,σyz, in which case the derivative in Eq. (1.3.44) is replaced by a partial derivative. Maxwell was the ﬁrst to analyze the viscosity in the framework of the kinetic theory. The idea is rather simple. Actually each layer of the gas that is parallel to the xy plane (in the case described in Fig. 1.3.6) ex- erts a force on every other layer. The reason is that due to the existence of a velocity gradient the molecules in two diﬀerent layers have diﬀer- ent speeds, ux. This speed exists in addition to the thermal velocities. Thus in two diﬀerent layers the molecules have diﬀerent momenta, which 66 Ch. 3 Transport Coeﬃcients on average are diﬀerent from zero. But the thermal motion transfers molecules from one layer to another. The result is that a certain amount of net momentum is transferred between the layers per unit time per unit area, and this is the force of viscosity. We will perform the calculation of η at the same level that we calculated D, in the previous section. (It is possible, of course, to perform the calculation at the level of the appendix, and it is a worthwhile eﬀort.) Consider Fig. 1.3.4 in the present context and focus on a layer at z = 0. As before, molecules that are crossingthe z = 0 plane arrive on average from a distance of one mean free path ℓ above or below it. The density of the gas is uniform, and so is the temperature. Again, 1/6of the molecules are movingon average at a speed ¯v in a direction perpendicular toward the z = 0 plane, and the current passingthrough the plane is a momentum current. Let us stress that this momentum is along x! In a unit of time the amount of momentum passingthrough a unit area of the z =0 plane is 1 6 n¯vmux(ℓ) from above down, and 1 6 n¯vmux(−ℓ) from beneath up. If ux(z) is an increasingfunction of z, more momentum is transferred downwards than upwards. The balance is the force that is actingin the x direction per unit area of the movinglayer: σxz ≈ 1 6 n¯vm[ux(−ℓ) − ux(ℓ)] . (1.3.45) To ﬁrst order in ℓ this is σxz ≈− 1 3 n¯vmℓ dux dz , (1.3.46) which is Eq. (1.3.44) with η ≈ 1 3 m¯vℓn . (1.3.47) Exercise 3.14 (a) How will the coeﬃcient of viscosity change with the mass of the gas molecule at a constant temperature? (b) Show that at a constant temperature η is independent of the pressure. (c) How does η change with temperature? Solution on page 104 3.6 Viscosity and thermal conductivity 67 Thermal conductivity When the gas is contained between two parallel planes (parallel to the xy plane), kept at diﬀerent temperatures, heat ﬂows through the gas. If the heat transferred by convection (when parts of the gas move with respect to one another) is negligible, then the amount of heat that has to be supplied per unit time per unit area, in order to maintain the temperature gradient, is experimentally found to be Qz = − ¯K dT dz . (1.3.48) Q is called the energy current or the energy current density or the energy ﬂux density, and it is the amount of energy that is transferred per unit time across a unit area. This time the role of the kinetic theory is to calculate ¯K —the thermal conductivity. The conditions are: the density is uniform in the container, and the average velocity is zero everywhere. But the temperature changes, so that the average energy per molecule ¯ϵ changes from one layer to another along the z direction. The amount of heat passingthrough a unit area in unit time, alongthe z direction, is Qz ≈ 1 6 n¯v [¯ϵ(−ℓ) − ¯ϵ(ℓ)] , (1.3.49) and to ﬁrst order in ℓ, when the temperature gradient is not too large, Qz ≈− 1 3 n¯vℓ d¯ϵ dT dT dz . (1.3.50) Exercise 3.15 Explain the transition to the last equation. Solution on page 105 We have therefore obtained Eq. (1.3.48), and found that the thermal conductivity is ¯K ≈ 1 3 n¯vℓc , (1.3.51) where c = d¯ϵ dT , is the speciﬁc heat (at constant volume) per molecule. 68 Ch. 3 Transport Coeﬃcients Exercise 3.16 Show that the thermal conductivity of an ideal gas does not depend on the pressure, and varies as T 1/2. Solution on page 105 3.7 Appendix: a more detailed calculation of the diﬀusion coeﬃcient Amongthe prominent ﬂaws in the calculation of the diﬀusion coeﬃcient, as presented in Sec. 3.3, are the following: (a) Not all of the molecules have the same velocity — in magnitude or direction. (b) The molecules do not all start from a distance ℓ. Let us calculate, therefore, the number of molecules that are crossing an element of area, dA, which was chosen in Fig. 1.3.7 to be in the xy plane surroundingthe origin. We are still assuming that the particle density n1 depends only on z.➤ ➤ ➤ x y z dV dA r θ θ Fig. 1.3.7 The geometric quantities that appear in a diﬀusion problem. We start by calculatingthe number of molecules that are in a volume dV around the point whose coordinates are (x, y, z), and whose velocities are between v and v + dv. The number of molecules in the volume is n1(z)dV , which can be approximated, when the gradients are small, by ( n1(0) + z ∂n1 ∂z ) dV . (1.3.52) 3.7 Appendix: detailed calculation of diﬀusion 69 This number has to be multiplied by the probability for a molecule to have a velocity (in absolute value) between v and v + dv,given by the Maxwell–Boltzmann distribution (see Sec. 1.5), namely 4πv2f (v)dv . (1.3.53) The directions of the velocities of the molecules are random, so that the probability of ﬁndingmolecules with velocities in the direction of our unit area is equal to the ratio between the solid angle, spanned by the unit area towards dV ,and 4π, or between the eﬀective area of dA and the surface area of the entire sphere of radius r, i.e. dA cos θ 4πr2 . (1.3.54) Accordingto (1.3.15) the fraction of molecules that will arrive from a distance r without collidingis e−r/ℓ and the correspondingprobability is e−r/ℓ/ℓ. This should be multiplied by v to obtain the fraction per unit time per unit area. As an intermediate result we ﬁnd that the number of molecules in dV that will begin to move towards the unit area in unit time, with a velocity between v and v + dv,is [( n1(0) + z ∂n1 ∂z ) dV ] · [4πv2f (v)dv] · [ dA cos θ 4πr2 ] . (1.3.55) The total number of molecules passingdownwards through the unit area in unit time is obtained insertingthe survival probability and dividing by dA. The result is J↓ = ∫ ( n1(0) + z ∂n1 ∂z ) cos θ 4πr2 e −r/ℓdV ∫ ∞ 0 4π ℓ v3f (v)dv = ¯v ℓ ∫ π/2 0 ∫ ∞ 0 ( n1 + ∂n1 ∂z r cos θ) sin θ cos θ e−r/ℓ 2 drdθ . (1.3.56) In the ﬁrst line the second integral is proportional to ¯v [see Eq. (1.3.8)], while in the ﬁrst integral, apart from the product of all the factors, we substituted z = r cos θ and dV = r2 sin θdrdθdφ and integrated over the variable φ between 0 and 2π. The current passingupwards is given by an almost identical expression. The only diﬀerence is a minus sign before the factor ∂n1/∂z, due to the fact that the density enteringfrom below is n1(−z). The net current is Jz = J↑ − J↓ = − 1 3 ¯vℓ ∂n1 ∂z . (1.3.57) 70 Ch. 3 Transport Coeﬃcients Exercise 3.17 Carry out the integrations in the expression for Jz. Solution on page 105 We, therefore, rederived Eq. (1.3.19). The result is to be considered still an intermediate result that takes into account only some of the factors which determine the diﬀusion coeﬃcient.Self-assessment exercises Exercise 1 Solution on page 107 A gas of molecules of mass m is in thermodynamic equilibrium at tem- perature T . The velocity of a gas molecule is v =(vx,vy,vz). Compute the followingaverages: (a) ⟨vx⟩ (b) ⟨v2 x⟩ (c) ⟨v2 xvy⟩ (d) ⟨|v|2vz⟩ (e) ⟨(vx + bvy)2⟩ (f) ⟨v2 xv2 y⟩ Exercise 2 Solution on page 109 A gas of molecules of mass m is in thermal equilibrium at temperature T . (a) Calculate the average ⟨1/|v|⟩, and compare it to the quantity 1/⟨|v|⟩. (b) Calculate the most probable value for the energy of a molecule in the ensemble, Em,and compare it to 1 2 mv2 m,where vm is the most probable velocity. Exercise 3 Solution on page 111 A gas of molecules is in a central potential, given by U (r)= C|r| n , where |r| is the distance from the origin. Calculate the average potential energy per molecule. 71 72 Self-assessment exercises Exercise 4 Solution on page 112 Molecules of a monoatomic ideal gas are leaking from a container, which is at a constant temperature T , through a small hole in the container’s wall. (a) From physical considerations (without any calculation!), would you expect that the average energy ⟨E0⟩ of a molecule in the leakingbeam will be larger than, equal to, or smaller than the average energy ⟨Ei⟩ of a molecule in the container? (b) Calculate ⟨E0⟩. Express your answer terms of ⟨Ei⟩. Exercise 5 Solution on page 113 Consider a gas at constant temperature T in a container of volume V . The gas is leaking out slowly through a small hole of cross section area A. The pressure outside the container is low enough, so that it is possible to neglect the leak into the container. Find the time in which the pressure inside the container will decrease to 1/e of its initial value. Express your answer in terms of A, V and the average velocity ¯v of a molecule in the gas. Exercise 6 Solution on page 114 A satellite of mass M , in the form of a cube of edge L, is movingin outer space in a direction parallel to one of its edges, at a velocity V . The dilute gas in which the satellite is moving is made up of molecules of mass m and their number per unit volume is n. The temperature of the gas, T , is such that the thermal velocity of the molecules, ¯v, is much larger than the velocity of the satellite. (a) Assumingthat the collisions of the molecules with the satellite are elastic, calculate the average slowing force exerted on the satellite by the interstellar gas. (b) No other external force is actingon the satellite. Calculate the time in which the velocity reaches half its initial value. Exercise 7 Solution on page 115 Assume a general situation where the temperature T of a material depends on the time t and the position z. The density of the material is ρ,its speciﬁc heat per molecule c and its thermal conductivity ¯K. Usingconsiderations similar to those that led to Eq. (1.3.23), obtain the diﬀerential equation governing the temperature distribution T (t, z)in Self-assessment exercises 73 a one-dimensional system: ∂T ∂t = ( ¯K cn ) ∂2T ∂z2 . This is the Fourier equation. Exercise 8 Solution on page 116 Aluminum grains whose diameter is one micrometer are ﬂoating in water at room temperature. The density of aluminum is 3.26 g/cm3,and the viscosity of water is 1 × 10−2 P. Find the steady precipitation rate of the aluminum due to gravitation. Exercise 9 Solution on page 117 The viscosity coeﬃcient of gaseous helium at atmospheric pressure and a temperature of 273 K is η1 =1.87 × 10−4 P. The viscosity coeﬃcient of gaseous argon under these conditions is η2 =2.105 × 10−4 P. The atomic masses of the two gases are, respectively, µ1 =4 amu and µ2 =40 amu. (a) Find the ratio ℓ2/ℓ1 of the mean free paths of the two gases, and theapproximatevalues of ℓ1 and ℓ2. (b) Calculate the ratio ¯K2/ ¯K1 of the thermal conductivities of the two gases. (c) Calculate the ratio D2/D1 of the respective diﬀusion coeﬃcients. Solutions to exercises in the text Solution 1.1 Exercise on page 8 (a) The contribution of the molecules, with a velocity component vx, to the pressure is P (vx)= 2 · mv2 x · n(vx) . (i) In order to obtain the pressure exerted on the piston, we have to sum over all possible values of vx. Only molecules with a positive component vx will hit the piston (molecules with negative vx will move away from the piston; see Fig. 1.1.1). Thus P = ∑ vx>0 2 · mv2 x · n(vx) . (ii) In a state of equilibrium we expect molecular “chaos,” i.e. if there is no external factor forcingthe molecules to move in a certain direction, then they will move in all directions with equal prob- ability. Hence, the density of molecules of velocity vx should be equal to the density of molecules of velocity −vx: n(vx)= n(−vx) . (iii) We can write v2 xn(vx)= 1 2 [v2 xn(vx)+ (−vx) 2n(−vx)] and replace the summation over vx > 0 in Eq. (ii) by a summation over all the values of vx: P = ∑ vx mv2 x · n(vx) . (iv) The right hand side of Eq. (iv) is almost the average of mv2 x.The diﬀerence is that the average is calculated using the probability 74 Solutions to exercises in the text 75 of ﬁndinga molecule with a velocity vx and not in terms of the density of molecules which have a velocity vx. However, the prob- ability that a molecule will have velocity vx is n(vx)/n,where n is the number of molecules per unit volume which is constant in a state of equilibrium. We therefore write Eq. (iv) in the form P = n ∑ vx mv2 x n(vx) n = nm ∑ vx v2 x n(vx) n . (v) The sum on the right hand side of Eq. (v) is the average of v2 x. Since m is constant, we ﬁnd that P = n⟨mv2 x⟩ . (b) When we attribute to vx a continuous distribution, we must re- place the summations of section (a) by an integral. Namely P = ∫ ∞ 0 2mv2 xn(vx)dvx . (ii)′ The conditions (iii) holds here as well, so P = ∫ ∞ −∞ mv2 xn(vx)dvx = n⟨mv2 x⟩ . (iv)′ Notice that in (a) n(vx) has the dimensions of number per unit volume, whereas in (b) it has the dimensions of number per unit volume per unit velocity! Solution 1.2 Exercise on page 9 In discussingradiation, it is photons that are colliding with the “piston,” which is actingas an ideal mirror. The relation between the energy and the momentum, in the case of photons, is ϵ(p)= pc , (i) where p is the momentum of the photon, ϵ its energy, and c the speed of light. Since the momentum is parallel to the velocity, p · v = pc . (ii) We can repeat the derivation that we made in Solution 1.1. A photon that is reﬂected from the piston imparts to it a momentum amountingto 2px. All of the photons have the same speed, the speed of light, but there exists 76 Solutions to exercises in the text a distribution of directions, so that there will again be a distribution of vx. Equation (1.1.2) can be rewritten as P (vx)= 2pxvx · n(vx) . (iii) We must sum (iii) over all positive vx, in order to obtain the total pressure: P = ∑ vx>0 2pxvx · n(vx) . (iv) As in Solution 1.1, we get P = n⟨pxvx⟩ , (v) where n is the photon density in the container. In a state of equilibrium, the averages of pxvx,pyvy and pzvz will be equal, i.e. ⟨pxvx⟩ = ⟨pyvy⟩ = ⟨pzvz⟩ = 1 3 ⟨p · v⟩ = 1 3 ⟨ϵ⟩ , (vi) where in the last equality we have made use of Eqs. (i) and (ii). Substi- tutingin Eq. (v) we obtain the required result: P = n 1 3 ⟨ϵ⟩ = 1 3 N V ⟨ϵ⟩ = 1 3 E V . Solution 1.3 Exercise on page 10 Room temperature is 300 K. Substitution in Eq. (1.1.5) yields 〈 1 2 mv2〉 =6.21 × 10 −21 J=0.039 eV . Solution 1.4 Exercise on page 11 Substituting vcm and vrel, by their deﬁnitions, in the average ⟨vcm · vrel⟩ we obtain ⟨vcm · vrel⟩ = 1 m1 + m2 ⟨(m1v1 + m2v2) · (v1 − v2)⟩ = 1 m1 + m2 [〈 m1v2 1 2 〉 − 〈 m2v2 2 2 〉] + m2 − m1 m1 + m2 ⟨v1 · v2⟩ . Solutions to exercises in the text 77 Equations (1.1.10) and (1.1.11) imply, therefore, that 〈 m1v2 1 2 〉 − 〈 m2v2 2 2 〉 =0 , which is (1.1.12). Solution 1.5 Exercise on page 12 The proof of Dalton’s law uses mainly the concept of molecular (or atomic) “chaos,” and the fact that there is no interaction between the molecules of the gas. We suppose for simplicity that the mixture is composed of two gases of N1 and N2 molecules, respectively (the derivation can easily be generalized to any number of gases). The two gases occupy the same volume V and the total number of molecules N (= N1 + N2) is constant. The number of molecules N1 and N2 are not necessarily equal. Since the gases are at thermal equilibrium, their average kinetic ener- gies are equal: 〈 1 2 m1v2 1 〉 = 〈 1 2 m2v2 2 〉 . Accordingto Eq. (1.1.4), if each of the gases were to occupy by itself the same volume V at the same temperature, the partial pressures P1 and P2 would have been P1 = 2 3 N1 V 〈 1 2 m1v2 1 〉 , P2 = 2 3 N2 V 〈 1 2 m2v2 2 〉 . The partial pressure of a gas in a mixture is the pressure it would have if it were to occupy all the volume by itself. However, the total pressure of the mixture is P = 2 3 N V ( average energy per molecule ) = 2 3 N1 + N2 V ( average energy per molecule ) = 2 3 N1 V 〈 1 2 m1v2 1 〉 + 2 3 N2 V 〈 1 2 m2v2 2 〉 = P1 + P2 . 78 Solutions to exercises in the text Solution 1.6 Exercise on page 13 We are given the total volume V , the number of molecules N1 and N2 on both sides of the piston, and the total energy. All these are constants. The average kinetic energy on both sides of the piston is equal (there are no temperature diﬀerences). Hence, from Eq. (1.1.4) or Eq. (1.1.6) it follows that P1V1 N1 = P2V2 N2 . (i) where V1 and V2 are the volumes on the two sides of the piston. At equilibrium, the pressure on the two sides must equalize (otherwise a force will act, and the piston will move). Therefore, Eq. (i) implies that V1 V2 = L1 L2 = N1 N2 , (ii) where L1 and L2 are the lengths of V1 and V2, respectively. (See ﬁgure.) However, V1 + V2 = V ⇒ L1 + L2 = L, (iii) and we obtain from Eqs. (ii) and (iii) V1 = N1 N1 + N2 V, V2 = N2 N1 + N2 V, L1 = N1 N1 + N2 L, L2 = N2 N1 + N2 L. (iv) L1 ➤➤➤➤L2 N1 N2 P1 P2 A L ➤➤ The variables deﬁning the problem. Now we can calculate the average kinetic energy at equilibrium — as the pressure becomes uniform: The total energy is given by 3 2 P1V1 + 3 2 P2V2 = 3 2 PV = E, (v) and the pressure at equilibrium is consequently P = 2 3 E V . (vi) Solutions to exercises in the text 79 The average kinetic energy per molecule to the right of the piston is 〈 1 2 mv2〉 = 3 2 P1V1 N1 = 3 2 P V1 N1 . (vii) UsingEqs. (iv) and (vi) we obtain 〈 1 2 mv2〉 = 3 2 ( 2 3 E V )( V N1 + N2 ) = E N1 + N2 . (viii) Since the result in (viii) is independent of any quantity speciﬁc to the gas on the right of the piston, the same result must apply to the average kinetic energy to the left of the piston. Solution 1.7 Exercise on page 15 The assertion ⟨vcm · vrel⟩ =0 implies that ⟨(m1v1 + m2v2) · (v1 − v2)⟩ = ⟨m1v2 1⟩−⟨m2v2 2⟩ + ⟨(m2 − m1)v1 · v2⟩ . But the two parts of the molecule have the same average kinetic energy, i.e. 〈 m1v2 1 2 〉 = 〈 m2v2 2 2 〉 = 3 2 kT , and so ⟨(m2 − m1)v1 · v2⟩ =0 . m2 − m1 can be taken out of the averaging sign, and since in a generic case m1 ̸= m2,weobtain ⟨v1 · v2⟩ =0 . If m1 = m2, this argument cannot be used. But in this case the velocity distributions of the two atoms in the molecule will also be identical. Thus, calculating ⟨v1 · v2⟩ is the same as calculatingthe average of the product of v1 at time t = t1 and v1 at time t = t2: ⟨v1 · v2⟩ = ⟨v1(t1) · v1(t2)⟩ . Since the collisions are random there is no correlation between v1 at two diﬀerent times and the average is zero again. Solution 1.8 Exercise on page 17 (a) The total kinetic energy is given by E = N 3 2 rkT . 80 Solutions to exercises in the text However, only the center of mass energy produces the pressure in the gas, and so PV = NkT = 2 3r E. (b) Equation (1.1.22) implies that PdV + VdP =(γ − 1)dE . (i) For an adiabatic process we have as well dE = −PdV , (ii) and substitutingthis relation into Eq. (i) we obtain γP dV + VdP =0 , (iii) and from here γ dV V = − dP P , (iv) Integrating both sides we obtain ln V γ +ln P = K, (v) where K is a constant. From here of course PV γ =const . (c) The heat capacity is the quantity of heat required per unit temperature change. At constant volume the heat is equal to the energy change of the gas. Hence CV = ∂E ∂T . (vi) For a mole of monoatomic ideal gas, E = 3 2 N0kT and CV = 3 2 N0k = 3 2 R =12.45 J K−1 . (vii) Solution 1.9 Exercise on page 19 A degree of freedom will become relevant if its energy intervals, e.g. its ex- citation energies, are of the order of the equipartition energy kT available at temperature T . The electronic degrees of freedom in the atom will be excited when kTe ≈ 1eV , Solutions to exercises in the text 81 but 1eV = 1.6 × 10 −19 J so that Te ≈ 1.6 × 10−19 1.4 × 10−23 ≈ 10 4 K . The nuclear degrees of freedom, whose energies are of the order of MeV, will come into play when kTN ≈ 10 6 eV or TN ≈ 10 10 K . The quark degrees of freedom, which signify the intranuclear excitations, will aﬀect the speciﬁc heat when kTQ ≈ 10 9 eV or TQ ≈ 10 13 K . Solution 1.10 Exercise on page 21 The earth’s gravitational ﬁeld EG at the point r,where r is the distance from the earth’s center, is given by EG = α r2 , (i) where α is a constant. The change in the gravitational ﬁeld, owing to a small change in r, ∆r,is ∆EG = − 2α r3 ∆r. (ii) The relative change of the gravitational ﬁeld is obtained from Eqs. (i) and (ii): ∣ ∣ ∣ ∣ ∆EG EG ∣ ∣ ∣ ∣ ≈ ∆r RE , (iii) where RE is the radius of the earth (RE ≈ 6.4 × 106 m). In order to change the gravitational ﬁeld by a thousandth of a percent, we have to change the height by ∆r ≈ 10 −5RE ≈ 100 m . (iv) Under standard conditions the intermolecular distance l is given by l ≈ ( P kT )−1/3 ≈ ( 105 1.4 × 10−23 × 300 )−1/3 ≈ 3.5 × 10 −9 m , (v) where we substituted a pressure of one atmosphere and a temperature of 300 K. From (iv) and (v) we obtain the ratio l ∆r ≈ 3.5 × 10−9 102 ≈ 10 −11 ≪ 1 . 82 Solutions to exercises in the text That is, the changes in the gravitational ﬁeld are negligible when one is consideringdistances on the order of the intermolecular distance, and therefore it is possible to choose a region in space small enough so that the gravitational ﬁeld within it is constant, and large enough so that we can consider it as a macroscopic system. Solution 1.11 Exercise on page 23 The density of the gas in a force ﬁeld that is derived from a potential, F(r)= −∇U (r) , (i) can be obtained as in the one-dimensional case, replacingeverywhere z with r, and the derivative d/dz with the gradient ∇. Equation (i) gives the force that is actingon a gas molecule at point r. When U is the gravitational potential, U = mgz, Eq. (i) reduces to F = − dU dz ˆz = −mgˆz . The equation for the pressure is obtained by generalizing Eq. (1.1.27) to ∇P (r)= F(r)n(r) . (ii) Applying the same arguments as in Sec. 1.4, we attribute to the gas a local equation of state [cf. Eq. (1.1.28)] in a small volume around r: P (r)= n(r)kT . (iii) Since T is independent of r, we obtain from Eqs. (i)–(iii) an equation for n(r), kT ∇n(r)= −n(r)∇U (r) , (iv) correspondingto Eq. (1.1.29), with ∇U replacing mg. Equation (iv) can be written in the form ∇n(r) n(r) = − 1 kT ∇U (r)or ∇ ln n(r)= ∇ [ − U (r) kT ] . (v) The solution to this equation is ln n(r)= − U (r) kT + C, where C is a constant, or n(r)= n(r0)e −U (r)/kT , (vi) where n(r0) is the density at the point where the potential U (r)vanishes. Solutions to exercises in the text 83 Notice what happens in the case when the potential is the gravitational potential as of a planet. In this case Eq. (iv) implies that very far from the planet the gas density does not vanish but remains constant. This is of course impossible, since the number of molecules, although very large, is ﬁnite. It means that a gas cannot be in a state of thermodynamic equilibrium at constant T in a Newtonian gravitational ﬁeld. Solution 1.12 Exercise on page 24 P (r)dV is a probability, and therefore dimensionless. dV is a volume element, so [dV ]=[L] 3 , and hence [P (r)] = [dV ] −1 =[L] −3 , which means that the dimensions of P (r)are (volume)−1. P (r) is indeed normalized, since the integration of n(r) yields the total number of molecules, N , which appears in the denominator of Eq. (1.1.33). Solution 1.13 Exercise on page 27 The constant C in the Maxwell–Boltzmann distribution, f (v)= Ce −Av2 , is ﬁxed by the normalization condition ∫ f (v)dτ =1 , (i) where the integration is carried out over the entire velocity space. We have to calculate C from C ∫ ∞ −∞ ∫ ∞ −∞ ∫ ∞ −∞ e −A(v2 x+v2 y+v2 z )dvxdvydvz =1 . (ii) However, because the integration variables are independent, it is possible to write the triple integral as a product of three integrals: C ∫ ∞ −∞ e −Av2 xdvx ∫ ∞ −∞ e −Av2 y dvy ∫ ∞ −∞ e −Av2 z dvz = C (∫ ∞ −∞ e −Av2 xdvx )3 =1 . (iii) We calculate, therefore, an integral of the type S = ∫ ∞ −∞ e −αx2dx . (iv) The calculation is not complicated, as we shall see, and the result is √ π/α. It is possible of course to look up the result in a table of integrals. 84 Solutions to exercises in the text Substitutingthe result into (iii) we get C ( π A )3/2 =1 ⇒ C = ( A π )3/2 . Remark. The integral may be calculated in the following manner: We write S2 = ∫ ∞ −∞ e −αx2dx ∫ ∞ −∞ e −αy2 dy = ∫ ∞ −∞ e −α(x2+y2)dxdy . (v) In the double integral over the xy plane we transform to polar coordinates θ, r. The area element is rdθdr and x2 +y2 = r2. Equation (v) is therefore written as S2 = ∫ ∞ 0 ∫ 2π 0 e −αr2rdθdr =2π ∫ ∞ 0 re −αr2dr =2π (− 1 2α e −αr2 )∞ 0 = π α , (vi) and hence S = ∫ ∞ −∞ e −αx2dx = ( π α )1/2 . (vii) Solution 1.14 Exercise on page 27 The requirement that f (v) be normalized ﬁxes C as a function of A: C = ( A π )3/2 . A is determined from the requirement that the average kinetic energy per molecule be 3 2 kT . Symmetry considerations give ⟨v2 x⟩ = ⟨v2 y⟩ = ⟨v2 z ⟩ , which means that v2 = ⟨v2 x + v2 y + v2 z ⟩ =3⟨v2 x⟩ , so to calculate ⟨v2⟩ it is enough to calculate ⟨v2 x⟩.Thus 3 2 kT = 〈 1 2 mv2〉 = ∫ 3 2 mv2 xf (v)dτ = 3 2 ( A π )3/2 m ∫ ∞ −∞ ∫ ∞ −∞ ∫ ∞ −∞v2 xe −A(v2 x+v2 y+v2 z )dvxdvydvz = 3 2 ( A π )3/2 m ∫ ∞ −∞v2 xe −Av2 xdvx ∫ ∞ −∞e −Av2 y dvy ∫ ∞ −∞e −Av2 z dvz = 3 2 ( A π )1/2 m ∫ ∞ −∞v2 xe −Av2 xdvx , (i) Solutions to exercises in the text 85 where we have used the result (vii) of the previous exercise for the normalization. Next we calculate an integral of the form I = ∫ ∞ −∞ x 2e −αx2dx . Integration by parts yields I = − 1 2α ∫ ∞ −∞ x ( d dx e −αx2 ) dx = 1 2α ∫ ∞ −∞ e −αx2dx = 1 2 ( π α3 )1/2 , andthen[by (i)] 3 2 kT = 3 2 ( A π )1/2 m 1 2 ( π A3 )1/2 = 3m 4A , (ii) which leads to A = m 2kT , (iii) C = ( A π )3/2 = ( m 2πkT )3/2 . (iv) Substituting(iv) in f (v) we obtain the distribution function Eq. (1.1.49). Startingfrom Eq. (1.1.49) and calculating ∫ f (v)dτ and 〈 1 2 mv2〉,we ﬁnd that Eq. (1.1.49) determines C and A,asrequired. Remark. A diﬀerent method for calculatingaverages will be intro- duced in Sec. 1.6. We will repeat the calculation of 〈 1 2 mv2〉 usingthat method. Solution 1.15 Exercise on page 29 We wrote Z(α)= ∫ ∞ 0 e −αzdz . (i) Now d dz ln Z = 1 Z dZ dα , (ii) d2 dα2 ln Z = 1 Z d2Z dα2 − 1 Z 2 ( dZ dα )2 . From Eq. (i) we ﬁnd that dZ dα = − ∫ ∞ 0 ze −αzdz = −Z⟨z⟩ , (iii) d2Z dα2 = ∫ ∞ 0 z2e −αzdz = Z⟨z2⟩ , (iv) where we have made use of the deﬁnitions of ⟨z⟩ and ⟨z2⟩, Eq. (1.1.51). 86 Solutions to exercises in the text SubstitutingEqs. (iii) and (iv) into (ii) we obtain d2 dα2 ln Z = ⟨z2⟩−⟨z⟩ 2 . (v) But ⟨(z −⟨z⟩) 2⟩ = ⟨(z2 − 2z⟨z⟩ + ⟨z⟩ 2)⟩ = ⟨z2⟩− 2⟨z⟩ 2 + ⟨z⟩ 2 = ⟨z2⟩− ⟨z⟩ 2 , so that we ﬁnd from (v) that the average square deviation is given by (∆z) 2 = ⟨(z −⟨z⟩) 2⟩ = d2 dα2 ln Z. Solution 1.16 Exercise on page 30 The average ⟨zn⟩ can be written as ⟨zn⟩ = ∫ ∞ −∞ zn exp(−U0zn/kT )dz Z , (i) where Z = ∫ ∞ 0 exp ( − U0zn kT ) dz . (ii) We substitute α = U0 kT (iii) and using Z(α)wecan write ⟨zn⟩ as ⟨zn⟩ = − d dα ln Z(α) , (iv) similar to what we did in Eqs. (1.1.51) and (1.1.52). The dimensions of Z(α) arethesameas thoseof z, namely dimensions of length. The dimensions of α are determined by the fact that αzn is dimensionless. Therefore, α has the same dimensions as z−n.Thus Z(α)= Kα −1/n . (v) Substituting(v) into (iv) we get ⟨zn⟩ = 1 nα = kT nU0 , where in the last equality we have made use of (iii). Consequently ⟨U (z)⟩ = kT n . (vi) Solutions to exercises in the text 87 Solution 1.17 Exercise on page 31 (a) Z(α)= ∫ exp(−α|v|2)dτ ,where dτ = dv1dv2 ... dvD is an in- ﬁnitesimal D-dimensional volume. The only diﬀerence between the present calculation and the one performed in Eq. (1.1.56) is that the volume of integration in Z(α)is D-dimensional. The dimensions of α remain as before. From dimensional considerations, identical to the ones we made in Sec. 1.6, we conclude that Z(α)= Kα −D/2 . Substitutingin Eq. (1.1.55), ⟨|v| 2⟩ = − d dα ln Z(α) , we obtain ⟨|v| 2⟩ = D 2α . In usual, three-dimensional, space (D =3), ⟨|v|2⟩ =3/2α,as we found in Eq. (1.1.59). In two dimensions, ⟨|v|2⟩ =1/α;in one dimension, ⟨v2⟩ =1/2α. (b) For a gas in a three-dimensional harmonic potential U (r)= 1 2 C|r| 2 . The potential is centered at r = 0, and therefore we want to ﬁnd ⟨|r|2⟩. In Solution 1.11 we showed that the distribution function is given by n(r)= n(r0)e −U (r)/kT , so that in our case n(r)= n(0)e −C|r|2/2kT . There is no need to carry out any further calculations: denoting α = C/2kT , we obtain the distribution function we know, where |r| is written instead of |v|. The result of the calculation of ⟨|r|2⟩ will not change, because |r| and |v| are merely variables of inte- gration, and the integration is over the entire space. The result is therefore ⟨|r| 2⟩ = 3 2α = 3kT C . 88 Solutions to exercises in the text (c) In order to ﬁnd the average energy per molecule we have to cal- culate ⟨ 1 2 C|r|2⟩. We use the result of (a) and the arguments of (b) above, to ﬁnd ⟨|r|2⟩ in a D-dimensional space: ⟨|r| 2⟩ = D 2α , (i) so that ⟨U (r)⟩ = 〈 1 2 C|r| 2〉 = 1 2 C D 2α . (ii) Since α = C/2kT , ⟨U (r)⟩ = 1 2 DkT , accordingto which each vibrational degree of freedom has an average potential energy of 1 2 kT . Solution 2.1 Exercise on page 34 The problem of a head-on elastic collision between two bodies can, in principle, be solved with the help of the conservation laws for energy and momentum. But we are not interested in an exact solution — an approximate solution is suﬃcient. A typical molecule has a mass m ≈ 10−26 kgand a velocity v ≈ 103 m s−1. The body has a mass M ≈ 10−16 kgand a velocity V ≈ 10−2 ms−1, i.e. m ≪ M and v ≫ V . What is actually takingplace in the system is that a small and fast molecule hits the enormous body, which is almost stationary. We therefore expect that the molecule will transfer to the body momentum of order 2mv and will be reﬂected with almost the same speed, v,as it had before the collision. The body will absorb this momentum and change its speed by a very small amount, ∆V . We can therefore write M ∆V ≈ 2mv , so that ∆V ≈ 2 m M v. Solutions to exercises in the text 89 Substitutingthe typical values v ≈ 103 ms−1, m/M ≈ 10−10, we ﬁnd that in the collision with the molecule the body’s velocity changes by about 2 × 10−7 ms−1. Solution 2.2 Exercise on page 37 The drunk’s position after N +1 steps is RN +1 = RN + Ln , (i) where n is the direction of the (N + 1)th step, i.e. the direction of the step taken by a drunk located at the point RN . The origin has been chosen at R0 =0. From the ﬁrst point of view we say that the drunks of the group that are located at RN will advance with equal probability in all the possible directions around RN ,so that ⟨n⟩ =0 , (ii) and we obtain ⟨RN +1⟩ = ⟨RN ⟩ . (iii) The equality (iii) implies that ⟨RN ⟩ = ⟨RN −1⟩ = ··· = ⟨R0⟩ =0 , and so ⟨RN ⟩ =0 (iv) for all N . From the second point of view we say that alongthe drunk’s path, each point may be considered as the beginning. If from every point we draw the vector RN , to which the drunk arrives after N more steps, we ﬁnd that the number of appearances of RN equals the number of appearances of −RN .Thus on average ⟨RN ⟩ =0. Solution 2.3 Exercise on page 38 (a) From Eq. (1.2.6) we see that µ˙r has dimensions of force. Hence [µ]= [ F ˙r ] = [M ][L][T ]−2 [L][T ]−1 =[M ][T ] −1 . (b) In the absence of an external force, the equation of motion of the body [Eq. (1.2.6)] takes the form M¨r + µ˙r =0 90 Solutions to exercises in the text or M ˙v + µv =0 . (i) Equation (i) is a vector equation, so that each component of the ve- locity satisﬁes an equation of the form M ˙v + µv =0 . (ii) The solution to (ii) is v = v0e −(µ/M )t , so that the solution to (i) is v = v0e −(µ/M )t , (iii) where v0 is the initial velocity of the body. From the solution (iii) we immediately see that lim t→∞ v = lim t→∞(v0e −(µ/M )t)= 0 . Solution 2.4 Exercise on page 38 The motion of the sky diver is one-dimensional alongthe z axis. We will choose the positive direction to be downwards, so that Fe = mg.The equation of motion (1.2.6) then takes the form m¨z + µ ˙z = mg . (i) We choose the origin to be the height from which the sky diver jumped, so that z(0) = 0. Furthermore, we assume that the sky diver’s initial velocity is zero, namely ˙z(0) = 0. In order to solve the equation we write (i) in the form m ˙v + µv = mg , (ii) where v is the sky diver’s velocity. The solution to Eq. (ii) with the initial condition v(0) = 0 is v = mg µ (1 − e −(µ/m)t) . (iii) At long times the exponential term in (iii) decays and becomes negligible, so that lim t→∞ v = mg µ . Solutions to exercises in the text 91 The characteristic time, θ, of the decay is the time after which the term v0e−µt/m decays to 1/e of its initial value, namely θ = m/µ.Longtimes are therefore times t ≫ m/µ, for which the exponential term is negligible, and then v ≈ mg/µ. The solution to the original Eq. (i) is determined by integrating (iii) and choosing the integration constant such that z(0) = 0: z = mg µ [ t + m µ (e −(µ/m)t − 1) ] . (iv) Solution 2.5 Exercise on page 38 When Fe is derived from a potential, Eq. (1.2.6) is written in the form M¨r + µ˙r = −∇U. (i) Takingthe scalar product of (i) with ˙r, M ˙r · ¨r + µ(˙r) 2 = −˙r ·∇U. (ii) But d dt (˙r) 2 =2˙r · ¨r , and so 1 2 M d dt (˙r) 2 + µ(˙r) 2 = −˙r ·∇U. (iv) The right hand side of (iv) is none other than the time derivative of U (with negative sign): dU dt = ∂U ∂x dx dt + ∂U ∂y dy dt + ∂U ∂z dz dt =(∇U ) · ˙r , so that we can write (iv) as d dt [ 1 2 M (˙r) 2 + U ] = −µ(˙r) 2 . (v) Observe that the expression in square brackets is the total energy E of the body, and thus dE dt = −µ(˙r) 2 . (vi) Equation (i) is a vector equation. For each component xi M d 2xi dt2 + µ dxi dt = − ∂U ∂xi . Equation (ii) is a scalar equation, and is a sum of three equations, 3∑ i=1 [ M dxi dt d2xi dt2 + µ ( dxi dt )2] = − 3∑ i=1 ∂U ∂xi dxi dt = − dU dt , 92 Solutions to exercises in the text but d dt ( dxi dt )2 =2 dxi dt d2xi dt2 , 3∑ i=1 ( dxi dt )2 = ˙r 2 , so that 1 2 M d dt ( ˙r 2)+ µ ˙r 2 = − ˙U, andthisisactually Eq. (v). Solution 2.6 Exercise on page 40 When there is no friction, Eq. (1.2.6) reduces to M¨r = Fe or M d dt (˙r)= Fe . Averaging both sides of this equation (the left hand side can be averaged before diﬀerentiation), we obtain M d dt ⟨˙r⟩ = ⟨Fe⟩ =0 . Its solution is ⟨˙r⟩ =const , which means motion at constant average velocity ⟨v⟩. Solution 2.7 Exercise on page 41 Takingthe scalar product of the equation M¨r + µ˙r = Fe (i) with r,weobtain M r · ¨r + µr · ˙r = r · Fe . (ii) Usingthe identities (1.2.10), we have r · ¨r = 1 2 d2r2 dt2 − (˙r) 2 , so that Eq. (ii) takes the form (1.2.9): 1 2 M d2r2 dt2 + 1 2 µ dr2 dt − M (˙r) 2 = r · Fe . Solutions to exercises in the text 93 Solution 2.8 Exercise on page 42 Equation (1.2.11) is identical to the equation of motion of the sky diver in Exercise 2.4, where instead of mg we write 2DkT ,and z is to be replaced here by u. The solution which satisﬁes the required initial condition is therefore obtained by the appropriate substitutions in Solution 2.4, so (1.2.12) is obtained. The dimensions of the parameter θ are [θ]=[M/µ]= [M ] [F/v] = [M ] [M ][L][T ]−2[T ][L]−1 =[T ] . Solution 2.9 Exercise on page 44 Takingthe scalar product of Eq. (1.2.17) M¨r + µ˙r + Cr = Fe (i) with r, and usingthe identities (1.2.10), we get 1 2 M d2r2 dt2 + 1 2 µ dr2 dt + Cr2 − M (˙r) 2 = r · Fe . (ii) Averaging Eq. (ii) we obtain 1 2 M d2 dt2 ⟨r2⟩ + 1 2 µ d dt ⟨r2⟩ +2 〈 1 2 Cr2〉 − 2 〈 1 2 Mv2〉 =0 , (iii) where we wrote v instead of ˙r. Denoting u = ⟨r2⟩ and using (1.2.18) for the average kinetic energy, we obtain Eq. (1.2.19). Notice that we have not replaced the average potential energy 1 2 Cr2 by 1 2 DkT . Had we done so, this would have been equivalent to the as- sumption that u is a constant independent of time! Since our interest here is in the time dependence of u, we must keep the term 2Cu in the equation. We are assuming, therefore, that the numerous collisions have caused the velocity to reach its thermal value before the time t =0. Solution 2.10 Exercise on page 45 Substituting v = Ke−γt into Eq. (1.2.20), we ﬁnd that γ must satisfy the equation γ2 − 1 θ γ + 2C M =0 , (i) whose solution is Eq. (1.2.21). 94 Solutions to exercises in the text Hence the general solution to (1.2.20) is a sum of two exponentials correspondingto the two solutions for γ: v = Ae −γ1t + Be −γ2t . (ii) The initial conditions u(t =0) = ˙u(t =0) =0 imply that A + B = − DkT C , (iii) γ1A + γ2B =0 . The solution of these equations for A and B leads to Eq. (1.2.22). To investigate the behavior at short times, we note that the system has two characteristic times: 1/γ1 and 1/γ2. Short times are thus short by comparison with 1/γ2, which is the shorter of the two, and a power expansion yields a quadratic behavior: u(t)= ⟨r2⟩≈ DkT γ1γ2 2C t2 . (iv) Notice that γ1γ2 =2C/M , which gives exactly Eq. (1.2.14) again. The region in which u is approximately linear is around the point at which ¨u = 0 (zero “acceleration” means a constant velocity and a distance linear with time). DiﬀerentiatingEq. (1.2.22) twice we obtain γ2γ2 1 e −γ1t − γ1γ2 2e −γ2t =0 (v) or e (γ2−γ1)t = γ2 γ1 , (vi) which means that, around a time correspondingto the solution of Eq. (vi), ⟨r2⟩ grows linearly with time. It is not the behavior at long times. Solution 2.11 Exercise on page 47 A practical method of measuringthe restoringforce constant of the whisker is based on the fact that if we shift the mirror by an angular deviation φ0, that is not too large, the mirror will execute harmonic mo- tion at a frequency: ω2 = a I . By measuringthe period of the vibrations and the moment of inertia of the mirror, we obtain a. Solutions to exercises in the text 95 In order for it to be possible to neglect the inﬂuence of the random force on the measurement, the experiment is carried out at a very low pressure. Solution 3.1 Exercise on page 51 It is possible to make the followingqualitative argument: the mean free path decreases as the probability for the molecule to collide with other molecules increases. This probability grows with increasing gas density as well as with increasingmolecular radius. That is, the mean free path must decrease when the density increases and when the molecular radius increases. The dimensions of the mean free path are dimensions of length. To obtain length from the density and the radius, by a function that de- creases with each of them we note that the dimensions of the density are (length)−3, and the radius has dimensions of length, so 1/a2n has the dimensions of length and is a decreasing function of a and n. However, since there are two quantities with dimensions in the prob- lem, n and a, (1.3.2) is not a unique solution. It is possible to create a dimensionless quantity, a3n,and if 1/a2n is multiplied by an arbitrary function of a3n, the dimensions of the expression would still be length. For instance, (1/a2n)e−a3n satisﬁes all of our requirements. Thus, in this case, dimensional analysis is not suﬃcient. Solution 3.2 Exercise on page 51 A few of the implicit assumptions that were made in the calculation are: (a) We assumed that the distance that a molecule travels between collisions is constant, while this quantity has a distribution and that ℓ is only its average. (b) The use of the average velocity in Eq. (1.3.2) is also an approx- imation, because the collision between the two molecules occurs when both are in motion so that ¯v is not the average velocity of a gas molecule but the average relative velocity. (c) We assumed that collisions always involve only two molecules. This assumption is good for a dilute gas. When the density of the molecules increases, so does the probability for a simultaneous collision between three molecules, and these collisions have to be taken into account. (d) We assumed that the cross section for scatteringdepends only on the geometric dimensions of the molecules. In fact, it also depends on the relative velocity of the collidingmolecule and, eventually, also on the force between them. 96 Solutions to exercises in the text Solution 3.3 Exercise on page 53 (a) In order to prove Eq. (1.3.10) we need only calculate ¯v usingthe Maxwell–Boltzmann distribution ¯v =4π ∫ ∞ 0 f (v)v3dv =4π ( m 2πkT )3/2 ∫ ∞ 0 v3e −mv2/2kT dv . (i) The integral that we obtained, which we denote as I, can be evaluated with the help of integration by parts: I = − kT m ∫ ∞ 0 d dv (e −mv2/2kT )v2dv = 2kT m ∫ ∞ 0 e −mv2/2kT vdv =2 ( kT m )2 , so that ¯v = √ 8kT /πm , (ii) and Eq. (1.3.10) follows. (b) For the calculation of the escape rate of the gas molecules it is possible to repeat the argument that led to Eq. (1.3.9), where this time the area A, which the molecule hits, is the area of the hole at the side of the container. All the molecules that hit it pass through it and leave the container. The escape rate from the container is therefore νA. Solution 3.4 Exercise on page 53 The average relative speed of a pair of molecules is ¯vrel = ∫ f (v1)f (v2)|v1 − v2|dτ1dτ2 , (i) where dτ1 and dτ2 are volume elements in velocity space dτ = dvxdvydvz, and f (v) is given by Eq. (1.1.49). As was mentioned in Chap. 1, it is also possible to describe the motion of two molecules in terms of the center of mass velocity vcm and the relative velocity vrel. The product f (v1)f (v2) is an exponential function of the total kinetic energy of the two molecules, exp[−(m1v2 1 + m2v2 2)/kT ], so we express it in terms of vrel and vcm.Since    v1 = vcm + m2 m1 + m2 vrel , v2 = vcm − m1 m1 + m2 vrel , (ii) we obtain 1 2 (m1v2 1 + m2v2 2)= 1 2 (Mv2 cm + µv2 rel) , (iii) Solutions to exercises in the text 97 where M = m1 + m2 , 1 µ = 1 m1 + 1 m2 . (iv) This means that the motion of the two molecules is equivalent to the motion of two particles, one with a mass equal to the sum of the molecular masses, M ,and velocity vcm, and the other of mass µ (the reduced mass) and velocity vrel. All this should be well known from mechanics. Notice that at this stage it is more convenient not to require equal masses and instead to allow m1 and m2 to take on arbitrary values. Returningto the integrand in Eq. (i), it becomes a product of a func- tion that depends only on vcm and a function that depends only on vrel: f (v1)f (v2)|v1 − v2| = ( M 2πkT )3/2 exp ( − Mv2 cm 2kT ) · ( µ 2πkT )3/2 × exp ( − µv2 rel 2kT ) vrel . (v) Note that the normalization factors have been changed using the identity m1m2 = µM . The integration is to be carried out over all possible values of v1 and v2 or, alternatively, over all possible values of vrel and vcm. Integration over vcm will simply give unity, as the ﬁrst factor in (v) is precisely the normalized distribution function (1.1.49). Thus, we are left with ¯vrel = ( µ 2πkT )3/2 ∫ exp ( − µv2 rel 2kT ) vreldτrel . (vi) This expression is none other than the familiar expression for the average speed of a particle of mass m = µ, which we calculated in Exercise 3.3. If the two molecules are identical (which is the case for a monocomponent gas), then µ = m/2and ¯vrel = √ 8kT πµ = √ 2¯v. Solution 3.5 Exercise on page 54 The mean free path is approximately [Eq. (1.3.2)] ℓ = 1 4πa2n , where n is the gas density. Each molecule occupies an average volume of 1/n, so that the average intermolecular distance is n−1/3.Under standard 98 Solutions to exercises in the text conditions T ≈ 300 K, P ≈ 105 Nm−2 and from the equation of state n ≈ 1025 m−3. For a typical molecule of radius 1 ˚Awe obtain ℓ n−1/3 = ℓn1/3 = 1 4πa2n2/3 ≈ 10 3 , ℓ a = 1 4πa3n ≈ 10 4 . Solution 3.6 Exercise on page 54 We will assume that oxygen is an ideal gas so that P = nkT . (i) Since we have already made an approximation here, there is no point in usingthe full equations (1.3.12) and (1.3.13), which were themselves ob- tained under somewhat unrealistic assumptions. Hence we use Eqs. (1.3.1) and (1.3.2). The mean free path is therefore ℓ ≈ 1 4πa2n . (ii) Equations (i) and (ii) imply that P ≈ kT 4πa2ℓ . (iii) We are lookingfor P such that ℓ =5cm: P = 1.4 × 10−23 × 373 4π × 10−20 × 5 × 10−2 ≈ 0.8Nm −2 ≈ 8 × 10 −6 atm . The meanfreetimeisgiven by τ = ℓ ¯v . We estimate ¯v in terms of the temperature: 3 2 kT ≈ 1 2 m¯v2 , where the mass of an oxygen molecule O2 is m =5.3 × 10 −26 kg , so ﬁnally τ ≈ ℓ ( m 3kT )1/2 =0.05 ( 5.3 × 10−26 3 × 1.4 × 10−23 × 373 )1/2 ≈ 10 −4 s . Solutions to exercises in the text 99 Solution 3.7 Exercise on page 54 We calculate the mean free path of molecules of type 1, whose radius is a1 and whose density is n1. There are also molecules of type 2, whose radius is a2 and whose density is n2. We perform the calculation as we did to obtain (1.3.2). The idea, we recall, is to calculate the number of collisions that the chosen molecule experiences per unit time, and to divide the molecule’s thermal speed by this number. The number of collisions experienced by a molecule of type 1 with identical molecules, per unit time, is calculated as in Sec. 3.2. The result is ν11 = 1 τ11 ≈ (4πa 2 1¯v)n1 . (i) In order to calculate the number of collisions of the same molecule with type 2 molecules, in the same time unit, we ignore the molecules of type 1. This time the cylinder that the molecule intersects in its collisions, the one that will replace the cylinder of radius 2a in Fig. 1.3.1, will be a cylinder of radius a1 + a2. In other words, a molecule of type 1 will collide with a molecule of type 2 if the distance between their centers is smaller than a1 + a2. Hence, the number of collisions between 1 and 2 will be ν12 = 1 τ12 = π(a1 + a2) 2¯vn2 , (ii) and since the total rate for collisions of molecules of type 1 is the sum of (i) and (ii), ν1 = 1 τ11 + 1 τ12 = ¯v ℓ11 + ¯v ℓ12 , we ﬁnd that 1 ℓ1 = 1 ℓ11 + 1 ℓ12 or ℓ1 =[4πa 2 1n1 + π(a1 + a2) 2n2] −1 . (iii) The mean free path of a type 2 molecule is obtained from Eq. (iii) by interchanging the indices 1 and 2. Note that a more accurate calculation would require accountingfor the fact that the average relative velocity of two molecules of the same type is diﬀerent from that of two molecules of diﬀerent types. Solution 3.8 Exercise on page 56 For the distribution in Eq. (1.3.15), N = N0e −s/ℓ , 100 Solutions to exercises in the text the average distance traversed by a molecule without colliding is ⟨s⟩ = ∫ ∞ 0 sN (s)ds ∫ ∞ 0 N (s)ds = − d d(1/ℓ) ln (∫ ∞ 0 N0e −s/ℓds) = − d d(1/ℓ) ln(N0ℓ)= d d(1/ℓ) ln 1 ℓ = ℓ. Solution 3.9 Exercise on page 56 The average distance traversed by a molecule between two successive collisions with other molecules is ℓ, the mean free path. The average time between two collisions is τ . Hence, the average number of collisions experienced by a molecule per unit time is 1/τ , and in a time interval dt it will experience dt/τ collisions. If at time t the number of molecules that did not experience collisions since t =0 is N (t), then N (t)dt/τ of them will collide between t and t+dt. Thus, the change in the number of molecules that did not experience collisions will be dN (t)= − N (t)dt τ , so that the distribution is N (t)= N0e −t/τ , where N0 is the number of molecules at time t =0. Solution 3.10 Exercise on page 58 The diﬀusion coeﬃcient is given in Eq. (1.3.20) in the form D = 1 3 ¯vℓ , (i) and the mean free path ℓ ∝ 1 n . (ii) For an ideal gas P = nkT , (iii) and from equipartition ¯v ∝ T 1/2 , (iv) thus D ∝ T 1/2 · T P = T 3/2 P . (v) Solutions to exercises in the text 101 Therefore, at a constant temperature D ∝ 1 P (vi) and at constant pressure D ∝ T 3/2 . (vii) Solution 3.11 Exercise on page 59 To generalize Eq. (1.3.22) to the three-dimensional case, we consider a small box centered around the point r =(x, y, z), with sides ∆x, ∆y and ∆z (see Fig. 1.3.5). To obtain the change in the number of particles per unit volume in the box ∂n1 ∂t , we have to sum over the changes due to the ﬂow into and out of its six faces. The change in the number of particles, due to the ﬂux in the z direc- tion, is −∂Jz/∂z [in analogy with Eq. (1.3.22)], where Jz is the component of the ﬂux alongthe z direction. The two other components of J do not transport molecules across the faces which are normal to the z axis. Similarly, the change in the density as a result of the ﬂow in the directions of x and y will be −∂Jx/∂x and −∂Jy/∂y, respectively. Hence we obtain − ∂n1 ∂t = ∂Jx ∂x + ∂Jy ∂y + ∂Jz ∂z = ∇· J . The divergence operator ∇· J can be thought of as a scalar product of the gradient operator ∇ = ˆx ∂ ∂x + ˆy ∂ ∂y + ˆz ∂ ∂z and the vector J. This equation expresses the conservation of the number of particles and is called the (three-dimensional) continuity equation. Alternatively, we can make the followingargument. n1 is a scalar and so is ∂n1 ∂t . The ﬂux J is a vector. The generalization of (1.3.22) must give the change of n1 in time in terms of the ﬁrst derivatives of the vector components, and yield a scalar. The only such scalar that can be formed is ∇· J. Solution 3.12 Exercise on page 60 (a) n1(z, t)= C √ Dt e −z2/4Dt ⇓ ∂n1 ∂t = − C √ Dte −z2/4Dt ( 1 2t − z2 4Dt2 ) , 102 Solutions to exercises in the text ∂n1 ∂z = − C √ Dt e −z2/4Dt z 2Dt , ∂2n1 ∂z2 = − C √ Dte −z2/4Dt [ − ( z 2Dt )2 + 1 2Dt ] ⇓ D ∂2n1 ∂z2 = − C √ Dt e −z2/4Dt ( − z2 4Dt2 + 1 2t ) = ∂n1 ∂t , hence (1.3.24) is a solution of (1.3.23). (b) The number of particles of type 1, N1, is obtained by integration of n1(z, t) over all (one-dimensional) “space”: N1 = ∫ ∞ −∞ n1(z, t)dz = C √ Dt ∫ ∞ −∞ e −z2/4Dtdz = C √ Dt √ 4πDt =2C√ π. Hence N1 is independent of time. Moreover, we have found an expres- sion for the constant C : C = N1/ √4π. (c) The graph of n1 as a function of time at a given point z ̸=0 is drawn in the ﬁgure. ➤ ➤n1(z) 0 z2 2D tz2 D 2z2 D The time dependence of the density at point z. (d) The average square distance ⟨z2⟩ = 1 N1 ∫ ∞ −∞ z2n1(z, t)dz = 1 2C√ π C √ Dt ∫ ∞ −∞ z2e −z2/4Dtdt . Integrating by parts in the last integral we obtain ∫ ∞ −∞ z2e −z2/4Dtdz =(4Dt) 3/2 · √ π 2 , Solutions to exercises in the text 103 so that ⟨z2⟩ =2Dt . This means that, on average, the distance of the molecules from their initial position grows as √ t (and not as t), which gives a “diﬀusion time” much longer than the “thermal” time. The time required to cross a distance L by diﬀusion is t1 = L2 2D . The time required for travelingthe same distance at the thermal speed ¯v is t2 = L ¯v . The ratio of these times is t1 t2 = L¯v 2D . Takinginto account Eq. (1.3.20), D = 1 3 ¯vℓ , we get t1 t2 = 3 2 L ℓ , which means that if the distance traveled is very large compared to the mean free path, the diﬀusion time will be much longer than the time of the respective motion at thermal speed. Solution 3.13 Exercise on page 62 The velocity of the accelerated particle at time t, since its last collision, is v = v0 + F m t. (i) Calculatingits average speed, using the distribution (1.3.16), we obtain vd = F m ⟨t⟩ = F m ∫ ∞ 0 te−t/τ dt ∫ ∞ 0 e−t/τ dt . (ii) Note that N0 has canceled out. We have already calculated the ratio of such integrals before. The result is vd = F m τ, (iii) namely (1.3.32). 104 Solutions to exercises in the text In order to calculate K in terms of the distance traversed by the ac- celerated particle between its last collision and time t,wewrite r = v0t + F 2m t2 . (iv) When we average this equation over many intervals along the particle’s trajectory (or over an ensemble), the ﬁrst term on the right hand side of (iv) vanishes so that we obtain ⟨r⟩ = F 2m ⟨t2⟩ (v) or d = 1 2 F m⟨t2⟩ , (vi) but ⟨t2⟩ = ∫ ∞ 0 t2e−t/τ dt ∫ ∞ 0 e−t/τ dt = 2τ 3 τ =2τ 2 , (vii) namely d = F mτ 2 , (viii) and consequently ⟨v⟩ = d τ = F m · τ, (ix) as obtained in the other method. The error in the argument given in the exercise was that we wrote ⟨t2⟩ = τ 2, but the distribution is an exponential that is linear in t and not in t2,so ⟨t2⟩ =2τ 2. Solution 3.14 Exercise on page 66 The viscosity coeﬃcient: η ∝ mℓ¯vn The mean free path: ℓ ∝ 1 n The average speed: ¯v ∝ √ T m Hence η ∝ m · 1 n · √ T m · n = √mT . From here we deduce that: (a) η ∝ m1/2, (b) For T =const,η =const, so that η is independent of the pressure (or the density). (c) η ∝ T 1/2. Solutions to exercises in the text 105 Solution 3.15 Exercise on page 67 We have seen that the amount of heat that crosses a unit area per unit time, along z,is Qz ≈ 1 6 n¯v[¯ϵ(−ℓ) − ¯ϵ(ℓ)] . For small enough ℓ and an almost constant temperature, we can use the approximation ¯ϵ(ℓ) − ¯ϵ(−ℓ)= d¯ϵ dz ∣ ∣ ∣ ∣z=0 · 2ℓ, Qz ≈− 1 6 n¯v d¯ϵ dz 2ℓ. The gradient of ¯ϵ is determined in terms of the gradient of T ,which is the quantity that varies with z. And we ﬁnd Qz ≈− 1 3 n¯vℓ d¯ϵ dT dT dz . Solution 3.16 Exercise on page 68 The thermal conductivity ¯K ∝ nℓ¯vc . (i) For an ideal gas ℓ ∝ 1 n , ¯v ∝ √ T, ϵ ∝ T ⇒ c = dε dT =const . And substitutingin (i) we obtain ¯K ∝ √ T. Solution 3.17 Exercise on page 70 When we add J↓ and J↑ the term proportional to n1(0) cancels out, leaving Jz = − ¯v ℓ ∂n1 ∂z ∫ π/2 0 sin θ cos2 θdθ ∫ ∞ 0 re −r/ℓdr . Note that ∂n1 ∂z has been treated as a constant in the integration, since it is evaluated at z =0. 106 Solutions to exercises in the text The calculation of the two remainingintegrals is immediate: ∫ π/2 0 sin θ cos2 θdθ = 1 3 , ∫ ∞ 0 re −r/ℓdr = ℓ 2 , and ﬁnally Jz = − 1 3 ¯vℓ ∂n1 ∂z . Solutions to self-assessment exercises Solution 1 Exercise on page 71 The calculation of the required averages is done by means of the velocity distribution function (1.1.49): f (v)= ( m 2πkT )3/2 exp ( − mv2 2kT ) , where v2 = v2 x + v2 y + v2 z . This function is separable, i.e. it can be written as f (v)= g(vx)g(vy)g(vz) , and is symmetric in its velocity components, i.e. g(x)= g(−x). Before passingon to the calculations themselves, recall that the in- tegral of an antisymmetric function G(x)= −G(−x)from −∞ to ∞ vanishes. This is so because, if we change integration variable according to y = −x,both G and dx change sign and the limits of integration switch. Hence ∫ +∞ −∞ G(x)dx = ∫ −∞ +∞ G(y)dy . When we switch the limits of integration back, we pick up another minus sign and the integral on the right becomes minus the one on the left, but the two integrals are identical. Hence they must vanish. Reminder: ∫ b a G(x)dx = − ∫ a b G(x)dx . Also since the distribution function is symmetric, its product with an antisymmetric function is antisymmetric. If f and A are separable functions of several variables, namely f (r, s, t)= g1(r)g2(s)g3(t) , A(r, s, t)= h1(r)h2(s)h3(t) , 107 108 Solutions to self-assessment exercises we can write the average of A in the form ⟨A⟩ = ∫ h1(r)g1(r)dr ∫ h2(s)g2(s)ds ∫ h3(t)g3(t)dt = ⟨h1⟩· ⟨h2⟩· ⟨h3⟩ , where each average is calculated with the one-dimensional distribution. Moreover, if f is symmetric with respect to r, s, t and A is antisymmetric with respect to at least one of these variables, ⟨A⟩ =0. We now pass on to the solution of the problem: (a) First, ⟨vx⟩ =0 since, as already mentioned, f (or g) is symmetric with respect to vx, and A = vx is antisymmetric. (b) ⟨v2 x⟩ can be calculated directly from (1.1.49): ⟨v2 x⟩ = ( m 2πkT )3/2 ∫ ∞ −∞ exp ( − mv2 x 2kT ) v2 xdvx × ∫ ∞ −∞ exp ( − mv2 y 2kT ) dvy ∫ ∞ −∞ exp ( − mv2 z 2kT ) dvz . In fact we have already calculated all these integrals in Exercise 1.14 and obtained m 2 ⟨v2 x⟩ = 1 2 kT ; see Sec. 1.6 as well. Hence ⟨v2 x⟩ = kT m . (c) A = v2 xvy is antisymmetric with respect to vy,and so ⟨v2 xvy⟩ = ⟨v2 x⟩⟨vy⟩ =0 . (d) Here A = |v|2vz is antisymmetric with respect to vz,so that ⟨|v| 2vz⟩ = ⟨v2 x⟩⟨vz⟩ + ⟨v2 y⟩⟨vz⟩ + ⟨v3 z ⟩ =0 . (e) We compute the average of A =(vx + bvy)2 = v2 x + b2v2 y +2bvxvy , ⟨v2 x⟩ = kT m , ⟨b2v2 y⟩ = b2⟨v2 y⟩ = b2kT m . Solutions to self-assessment exercises 109 And from considerations of symmetry ⟨2bvxvy⟩ =2b⟨vxvy⟩ =0 ⇓ ⟨(vx + bvy)2⟩ =(1 + b2) kT m . (f) Since f is separable, we have ⟨v2 xv2 y⟩ = ⟨v2 x⟩⟨v2 y⟩ = ( kT m )2 . Solution 2 Exercise on page 71 (a) 〈 1 |v| 〉 = ( m 2πkT )3/2 ∫ 1 |v| e −mv2/2kT dτ . We use spherical coordinates, since f (v) depends only on the magni- tude of the velocity. The volume element of the velocity space in spherical coordinates is dτ = v2dv sin θdθdφ . The angular integration gives 4π,sothat 〈 1 |v| 〉 =4π ( m 2πkT )3/2 ∫ ∞ 0 ve −mv2/2kT dv . The last integral is elementary and hence 〈 1 |v| 〉 =4π ( m 2πkT )3/2 ( − kT m e −mv2/2kT )∞ 0 = ( 2m πkT )1/2 . Usingsimilar considerations we calculate ⟨|v|⟩: ⟨|v|⟩ = ( m 2πkT )3/2 ∫ |v| exp ( − mv2 2kT ) dτ =4π ( m 2πkT )3/2 ∫ ∞ 0 v3 exp ( − mv2 2kT ) dv = ( 8kT πm )1/2 , usingthe result obtained already in Exercise 3.3 or Eq. (1.3.8). From here 1 ⟨|v|⟩ = ( πm 8kT )1/2 . 110 Solutions to self-assessment exercises The relation between the results is therefore 〈 1 |v| 〉 = 4 π · 1 ⟨|v|⟩ . That is, the discrepancy is a factor of order 1, as expected. (b) The probability for the speed of a molecule to be between v and v +dv is obtained by integrating f (v) [Eq. (1.1.49)] over all directions. This yields P (v)dv = ( m 2πkT )3/2 4πv2e −mv2/2kT dv . (i) The most probable molecular speed vm is the value for which P (v) attains its maximum. We diﬀerentiate P (v), equate its derivative to zero, and obtain 2v − m kT v3 =0 ⇒ vm = ( 2kT m )1/2 . It is easy to check that this is where P (v) attains its maximum and not its minimum. Thus 1 2 mv2 m = kT . P (v)dv is the probability of ﬁndingthe molecule with speed between v and v + dv. We are lookingfor a function of E, ˜P (E), such that ˜P (E)dE be the probability of ﬁndingthe particle with energy in the interval (E, E + dE). v is a function of E, v(E), hence we can write P (v)as P (v(E)). But we must take into account that to an interval dv there corresponds an interval in energy (dv/dE) · dE. Hence ˜P (E)= P (v(E)) dv dE and since ˜P (E)dE = P (v(E)) dv dE · dE , (ii) the integral of ˜P (E)over all E is equal to the integral of P (v)over all v and hence the probability in E is normalized. Since E = 1 2 mv2, we obtain from (i) and (ii) ˜P (E)dE = ( m 2πkT )3/2 4π 2 m E dE (2mE)1/2 e −E/kT = 2/ √ π (kT )3/2 E1/2e −E/kT dE . (iii) Solutions to self-assessment exercises 111 The most probable energy Em,for which ˜P (E)ismaximal,isfound here by diﬀerentiation with respect to E and equatingto zero, which yields 1 2E1/2 − E1/2 kT =0 ⇒ Em = 1 2 kT . Again, it is easy to see that ˜P (Em) is in fact the maximum of ˜P (E), and not its minimum. Comparingthe two results gives 1 2 mv2 m =2Em , which means that the most probable energy is not the energy calcu- lated at the most probable speed! We have another example of this type in section (a) of this exercise. Solution 3 Exercise on page 71 The distribution function that we use is P = Ke −U/kT , where K is a normalization constant and U (r)= C|r| n . To ﬁnd the average energy per molecule we have to calculate ⟨|r|n⟩: ⟨|r| n⟩ = ∫ |r|n exp(−C|r|n/kT )dV ∫ exp(−C|r|n/kT )dV , (i) where dV = dxdydz . We denote α = C/kT , and write (i) in the form ⟨|r| n⟩ = − d dα ln Z(α) , (ii) where Z(α) is the normalization factor (actually 1/K) Z(α)= ∫ e −α|r|ndV . With the help of dimensional considerations we can immediately write Z(α)= Aα −3/n , (iii) where A is a constant. 112 Solutions to self-assessment exercises Substituting(iii) into (ii) we get ⟨|r| n⟩ = 3 nα = 3kT Cn . The average energy of a molecule is therefore ⟨U (r)⟩ = ⟨C|r| n⟩ = 3kT n . For n = 2 (harmonic potential) we obtain the familiar result ⟨U (r)⟩ = 3 2 kT . Solution 4 Exercise on page 72 (a) We are assuminga very slow process, so that the equipartition prin- ciple applies to the molecules in the container; namely, the average energy per molecule in the container is 3 2 kT . The situation is a bit diﬀerent for the molecules of the leaking beam. Here there is clearly a preferred direction, which is the z axis, which is perpendicular to the hole. The degrees of freedom in the x and y directions of the leakingbeam will obviously remain un- changed; they will contribute 1 2 kT per degree of freedom, according to the equipartition principle. The number of molecules crossingthe hole per unit time is proportional to the velocity of the molecules in the direction z. Hence more molecules with high vz will be present in the outgoing beam and the average speed in the beam is higher. Consequently also the average energy will be higher than 3 2 kT ,namely higher than that of a molecule inside the container. (b) Since we are assumingthat the process is almost static, the average energy of molecules inside ⟨Ei⟩ is given in a state of equilibrium by ⟨Ei⟩ = ∫ 1 2 mv2 ( m 2πkT )3/2 e −mv2/2kT dτ = 3 2 kT . (i) The average energy in the leaking beam ⟨E0⟩, movingout, is calcu- lated in the followingmanner: The number of molecules of velocity v that pass through the hole per unit time per unit area can be found usingEq. (1.3.3): J(v)= ∆N (v) A∆t = nf (v)vz . (ii) This is of course the current of particles of velocity v. Hence the energy that is carried out through the hole per unit time per unit area by molecules of velocity v is S(v)= nf (v)vz · m 2 |v| 2 (iii) Solutions to self-assessment exercises 113 and the total energy ﬂux will be S = n m 2 ∫ vz≥0 vzv2f (v)dvxdvydvz . (iv) The average energy of a molecule that leaves through the hole can be deﬁned by S = J ·⟨E0⟩ , (v) where J is the particle ﬂux [called ν in Eq. (1.3.9)]. It is the integral of (ii) over all velocities, J = n ∫ vz≥0 vzf (v)dvxdvydvz , (vi) so that ⟨E0⟩ = S J = m 2 · ∫ vz≥0 vzv2f (v)dvxdvydvz ∫ vz≥0 vzf (v)dvxdvydvz . (vii) Passingto spherical coordinates for the evaluation of the integrals in (vii), we ﬁnd that ⟨E0⟩ = 1 2 m ∫ 2π 0 dφ ∫ π/2 0 sin θ cos θdθ ∫ ∞ 0 v5e−mv2/2kT dv ∫ 2π 0 dφ ∫ π/2 0 sin θ cos θdθ ∫ ∞ 0 v3e−mv2/2kT dv = 1 2 m [ − d d(m/2kT ) ln ∫ ∞ 0 v3e −mv2/2kT dv] = 1 2 m · 4kT m =2kT . (viii) A comparison of the results (i) and (viii) shows that indeed we have ⟨Ei⟩ < ⟨E0⟩. Solution 5 Exercise on page 72 We assume that at each moment t the gas in the container is at equilib- rium; namely, it satisﬁes the ideal gas equation of state: P (t)V = N (t)kT , (i) where the temperature and the volume are constant. The number of molecules that leak through the hole in the short time interval ∆t is given by Eq. (1.3.9), so that the number of molecules will change at the rate dN dt = − 1 4 A V ¯vN , (ii) 114 Solutions to self-assessment exercises where the negative sign means that the number of molecules decreases with time. The solution of Eq. (ii) is N (t)= N0e −t/τ , where N0 is the number of molecules at the moment the hole is opened, which is deﬁned as t =0; τ is the time constant for the escape of the molecules (τ is not the mean free time): τ = 4V A¯v . Duringan interval τ the number of particles decreases by a factor 1/e. Since the pressure in the container is proportional to the number of particles inside it, τ is also the time duringwhich the pressure decreases by a factor 1/e. Solution 6 Exercise on page 72 (a) First we calculate the rate at which the molecules collide with the satellite. Since V ≪ ¯v, it is possible to consider the satellite stationary, so that Eq. (1.3.9) applies. The rate at which the molecules collide with each side of the satellite is ν = 1 4 n¯vL 2 (i) and the average time between two collisions with each side is τ = 4 n¯vL2 . (ii) To understand the collision process note that the satellite is much heavier than the molecules and its speed is many times smaller. There- fore, to a good approximation, the molecule will reverse its direction of motion, without changing its speed. Hence, in a collision with the satellite an average molecule will transfer momentum of order 2m(¯v + V ) if the molecule and the satellite are movingtowards one another, and 2m(¯v − V ) if the molecule is movingin the same di- rection as the satellite. Thus in an interval ∆t the satellite will lose momentum on order ∆p = −[2m(¯v + V ) − 2m(¯v − V )] ∆t τ , where ∆t/τ is the number of collisions with each side duringtime ∆t. Substituting(ii) into (iii) we ﬁnd that the restraining force ∆p/∆t will be F = −(m¯vnL 2)V. (iv) Solutions to self-assessment exercises 115 Notice the direct proportionality between the force and the velocity which is characteristic of a friction force. (See Sec. 2.4). (b) We obtain the satellite’s equation of motion from Newton’s second law: M dV dt = −µV , µ = m¯vnL 2 , whose solution is V (t)= V0e −µt/M , where V0 is the satellite’s velocity at time t =0. The velocity decreases to half its initial value after a time t∗,which is determined by e −µt∗/M = 1 2 , namely t∗ = M µ ln 2 = M ln 2 m¯vnL2 . We assume that n ≈ 109 m−3, and substitute characteristic orders of magnitude: M ≈ 102 kg, m ≈ 10−26 kg, ¯v ≈ 102 ms−1, L ≈ 10 m, and we obtain t∗ ≈ 102 ln 2 10−26 × 102 × 109 × 102 ≈ 10 15 s ≈ 10 10 days . Solution 7 Exercise on page 72 Equation (1.3.48), Qz = − ¯K dT dz , (i) was obtained from the balance of molecules crossinga given plane z = const, at ﬁxed temperature gradient. The thermal energy current density alongthe z axis, Qz, is proportional to the temperature change per unit length along this axis. The proportionality constant is − ¯K,where ¯K is the thermal conductivity coeﬃcient of the material, given in (1.3.51). Next, we want to obtain a continuity equation as in (1.3.22), relating the energy current Qz and the energy density, which we denote by u. Consider a surface element of material, with area ∆x∆y,located be- tween the planes z and z + dz as in Fig. 1.3.5. In a short time interval ∆t hot molecules will enter the layer and cold molecules will leave it. If ∂T /∂z > 0, i.e. if the z+dz is warmer than the z plane, then hot molecules will enter through the top plane and cold molecules will exit through the bottom plane. The change of the internal energy in the layer is the dif- ference between the thermal energy brought in by the hot molecules and 116 Solutions to self-assessment exercises the thermal energy carried out by the cold molecules. Namely [u(t +∆t) − u(t)]∆x∆y∆z = −[Qz(z +∆z) − Qz(z)]∆x∆y∆t. (ii) As ∆t and ∆z tend to zero, one obtains from (ii) the (one-dimensional) continuity equation for the energy: ∂u ∂t = − ∂Qz ∂z . (iii) We now apply the chain rule to the derivative of the energy density, ∂u ∂t = ∂u ∂T ∂T ∂t , and since ∂u ∂T = cn , where c is the speciﬁc heat per molecule and n is the density of the molecules, we obtain from Eq. (iii) cn ∂T ∂t = − ∂Qz ∂z . (iv) Substituting(i) into (iv) we obtain cn ∂T ∂t = − ∂ ∂z ( − ¯K ∂T ∂z ) , and since the thermal conductivity is constant in space, we ﬁnd the re- quired equation: ∂T ∂t = ( ¯K cn ) ∂2T ∂z2 . Solution 8 Exercise on page 73 The equation of motion for the height of an aluminum grain, z,with respect to the bottom of the container is m¨z + µ ˙z = −mg (i) where µ is given by Stokes’ law, µ =6πaη. The rate of precipitation of the grain is ˙z. The steady precipitation rate is the solution of Eq. (i) for longtimes: ˙z = − mg µ = − mg 6πaη = − 2ρa2g 9η . (ii) Solutions to self-assessment exercises 117 Substitutingthe numerical data we obtain ˙z = − 2 × 3.26 × (0.5 × 10−4)2 × 980 9 × 10−2 ≈−1.8 × 10 −4 cm/s . The solution of this exercise is similar to that of Exercise 2.4 in the text. Solution 9 Exercise on page 73 (a) Accordingto Eq. (1.3.47), η is proportional to m¯vℓn,where m is the mass of a molecule. The ratio between the viscosity coeﬃcients of the two gases is therefore η2 η1 = m2¯v2ℓ2n2 m1¯v1ℓ1n1 . At a constant temperature and pressure, the densities of two ideal gases are equal. The relationship between the average speed of a molecule in the gas and its mass is given by ¯v ∝ m−1/2.Thus η2 η1 = m2 · m −1/2 2 · ℓ2 m1 · m −1/2 1 · ℓ1 = ( m2 m1 )1/2 ℓ2 ℓ1 . Since the ratio of the masses is equal to the ratio of the atomic masses, ℓ2 ℓ1 = ( µ1 µ2 )1/2 η2 η1 =0.356 . It is also possible to obtain an estimate of ℓ1 and ℓ2 from Eq. (1.3.47). If we substitute for ¯v ¯v ≈ √ 3kT m and for n n = P kT , we obtain ℓ ≈ n P √ 3kT m . At a pressure of one atmosphere and a temperature of 273 K we obtain for helium ℓ1 ≈ 2.4 × 10 −7 m and for argon ℓ2 ≈ 8.5 × 10 −8 m . 118 Solutions to self-assessment exercises (b) Accordingto Eq. (1.3.51), ¯K is proportional to n¯vℓc,where c is the speciﬁc heat per molecule. Since the average energy per atom is in- dependent of the type of atom and depends only on the temperature, the speciﬁc heat per atom is also independent of the type of atom. Moreover, the density of the two gases is equal at equal tempera- ture and pressure. Thus ¯K2 ¯K1 = ¯v2ℓ2 ¯v1ℓ1 = m −1/2 2 ℓ2 m −1/2 1 ℓ1 = ( µ2 µ1 )−1/2 ( µ1 µ2 )1/2 η2 η1 = µ1η2 µ2η1 , where we have used the result of (a) above. Hence ¯K2 ¯K1 =0.113 . (c) Accordingto Eq. (1.3.20), D is proportional to ¯vℓ.Thus D2 D1 = ¯v2ℓ2 ¯v1ℓ1 = ¯K2 ¯K1 = µ1η2 µ2η1 =0.113 . Part II Statistical Physics with Paramagnets This Page Intentionally Left Blank Introduction As promised in the Introduction to Part I, we now turn to the treat- ment of material systems from a more detailed point of view. This means that the system, be it a system of molecules, a system of magnetic mo- ments, or a system of electrons and protons, is described by a dynamical model. The dynamical model has two components: (a) the rules accord- ingto which the system evolves in time (the laws of classical mechanics (Newton), or the laws of relativistic mechanics (Einstein), or the laws of quantum mechanics (Schr¨odinger); (b) the forces governing this evolu- tion (electric, magnetic, gravitational, etc.). Moreover, in such a model we must also deﬁne the relevant degrees of freedom (these may be elec- trons and protons); it may suﬃce to describe the system as a collection of atoms, or perhaps molecules are suﬃciently stable and can serve as build- ingblocks. For instance, the ideal gas discussed in Part I is described by the coordinates and velocities (or momenta) of each of its molecules — a total of 6N variables. Its evolution in time is determined by the laws of classical mechanics (Newton), and to describe its microscopic evolu- tion in time we would have to solve 3N coupled, second order, diﬀerential equations. We noted already in the Introduction to Part I that we are not inter- ested in a speciﬁc trajectory, i.e. a detailed solution of the given problem, and in followingeach of its degrees of freedom in time. In typical experi- ments (or measurements) we are not interested in the detailed evolution, but in averages over long times and over large spatial regions. When speakingof long times we mean that the durations of the experiments, or the averaging times, are very long compared to the times during which the system changes its microscopic state. For instance, the microscopic time in the gas will be the time between successive collisions — the mean 121 122 Introduction free time, which is the characteristic time after which the particles change their velocities. What we need, therefore, is a method of calculatingaverages over longtimes, alongthe evolution trajectory of the system. The system may change its state for diﬀerent reasons: because of the forces that are acting between its constituents, or because of the eﬀects of its surroundings (the system may be in contact with a source of heat, with a piston on which an external force is acting, or with an electric or magnetic ﬁeld, etc.). The calculation of averages over long times along the system’s tra- jectories is almost impossible. Hence the time averaging is replaced by ensemble averaging. The idea is similar to the one we met in the dis-ensemble cussion of Brownian motion (Chap. 2 of Part I): instead of followingthe system’s motion from state to state, we assume, followingGibbs, that we are given many similar systems each in a diﬀerent allowed state of the evolvingsystem. The probability, or the recurrence, of a certain state in the ensemble is equal to that which would have been obtained alongthe path. The averages are then performed over the ensemble. The next two parts of the book are devoted to the clariﬁcation of this method. We mention here two examples of ensembles, two types of assumptions, which will be discussed in detail later on: (a) In insulated systems the energy is conserved. Therefore, dur- ing its evolution, the system will only pass through equienergetic states (there may be other conservation laws or constraints, which will not be violated. The particles will remain, for instance, in their designated volume, etc.). A natural assumption in this case is that the system, evolvingin time, will pass through all the allowed states at the same reccurence rate. That is, after a suf- ﬁciently longtime every state of the system, havingthe same given energy, will have appeared the same number of times (this is the ergodic hypothesis). The average over long times will equal, therefore, the average over the ensemble of all the equienergetic states, all with the same probability. Such an ensemble is calledmicrocanoni- cal ensemble a microcanonical ensemble. (b) A system coupled to a heat reservoir has a given temperature, and is able to exchange energy. Hence if we want to replace the trajectory by an ensemble, we must determine the relative occurrence of systems in states with diﬀerent energies. In Part I we saw that the temperature is related to the av- erage energy per degree of freedom, and that states whose en- ergies are much larger than the average energy are less proba- ble. It is not unreasonable to assume, extrapolatingfrom the Introduction 123 Maxwell–Boltzmann distribution, that equienergetic states have the same probability, whereas the relative recurrence rate of states with diﬀerent energies is given by their Boltzmann factor, namely by the quantity e−E/kT . Such an ensemble is called a canonical ensemble. canonical ensemble As was emphasized in the introduction to the previous part, all results from the more detailed approaches must face a consistency test with the consequences of the less detailed theories, such as the kinetic theory, and ultimately with thermodynamics. Part I will serve as a reference for results of the kinetic theory. Thermodynamics is not developed in this course and for reference we have introduced Chap. 0 in this part, to recapitulate essential ideas from thermodynamics. The rest of this part illustrates the application of the idea of ensembles in the simple example of the paramagnet rather than in gases or liquids. This system is attractive because it can be described in terms of discrete degrees of freedom, which makes probabilistic considerations less abstract. Despite the simplicity of the model, it describes a few experimental systems in a surprisingly precise manner. In Part III we will formulate these concepts in a more general context. Chapter 1 concentrates on clarifyingthe microscopic and thermody- namic concepts for magnetic variables. The magnetic moments in our paramagnet have discrete states. This would be typical of a quantum theory, and not in the classical one. Here we take this fact as given and concentrate on the statistical technique, which is simpler for discrete variables. Chapter 2 deals with the identiﬁcation of the paramagnet’s mi- croscopic states and the followingtwo chapters treat the insulated para- magnet, namely a system at constant energy. In Chap. 5 we turn to the discussion of a paramagnet in contact with a “heat bath”, namely a system at constant temperature. Chapter 6 is dedicated to deepening the understandingof the concept of entropy based on the example of the paramagnet, and the last chapter presents experimental results. Chapter 0 Essential Background in Thermodynamics 0.1 The ﬁrst law This chapter is intended as a condensed review of basic notions in thermo- dynamics. Its role is to compile ideas that are presupposed to be known from previous study and are either underlyingcertain parts of this course or derived in it. It can serve as a condensed reference and it includes sev- eral bibliographical suggestions for wider expositions of the various topics. Though it is basically a compendium, several exercises have been included alongthe way to maintain the style of this course. The presentation is based, for concreteness and simplicity, on a speciﬁc physical system: the ideal gas. The ﬁrst law of thermodynamics is the law of conservation of energy. It is written as dE = δQ − δW . (2.0.1) dE is the increase in the energy of the system, δW is the work done by the system and δQ is the heat transferred to the system. In fact, δQ is deﬁned as the sum of the increase in the system’s mechanical energy and the mechanical work done by it. In mechanics this sum is strictly zero. For a gas in a container whose volume expands by dV against a pressure P , δW = PdV and Eq. (2.0.1) becomes dE = δQ − PdV . (2.0.2) A state of a system in thermodynamic equilibrium is speciﬁed by a reduced set of macroscopic variables. The minimal set of variables deﬁnes the state space of the system. For an ideal gas of N molecules conﬁnedinavolume V at temperature T ,any twoofthe variables (P, V, T ) deﬁne the state space. Any other quantity at equilibrium is determined when any two of these are speciﬁed. This is the case because the 124 0.1 The ﬁrst law 125 ideal gas obeys the equation of state: equation of state PV = NkT (2.0.3) [compare (1.1.6)], which gives any one of the three in terms of the other two. The two that are chosen may be thought of as coordinates in a two-dimensional state space. Thus, any state of the system corresponds to a point in the state space. Other dependent thermodynamic variables which are fully determined by the point in state space are called functions of state. For the ideal gas, for any choice of two of the three variables, the third one is a function of state. As we shall see below, the internal energy of the ideal gas is also a function of state [see Eq. (2.0.4), below]. Thermodynamic variables are classiﬁed into two types: extensive vari- extensive andables and intensive variables. Extensive variables have a magnitude pro- intensive variables portional to the size of the system. If two identical systems are combined into one, each extensive variable is doubled in value. The volume and number of particles of the gas are examples. The energy, Eq. (2.0.4), is another. Intensive variables are independent of the size of the system. T and P are such variables. While the energy is a function of state, work or heat are not. Specifying a thermodynamic state of the system does not ﬁx the values of these quantities. When the state of a system changes, i.e. it undergoes a process of some kind, the amount of work done by the system depends upon the process, i.e. upon the path in the space of states which corresponds to the process and not only upon the initial and ﬁnal points. The same is true for the amount of heat transferred to the system. In mathematical terms: δQ and δW are not exact diﬀerentials and one uses δ instead of d for these inﬁnitesimal quantities. By analogy, in classical mechanics, if a force is not conservative, the initial and ﬁnal values of the coordinates and the velocities of its particles do not determine the work done by the system in the transition between these two states; the entire path must be speciﬁed. Reminder:A diﬀerential in two variables x, y is written as δa = Ax(x, y)dx + Ay(x, y)dy. It is an exact diﬀerential if it is the diﬀerence between the values of some function z(x, y) at two neighboring points, i.e. if δa = z(x + dx, y + dy) − z(x, y). A necessary and suﬃcient condition for this is that ∂Ax ∂y − ∂Ay ∂x = 0. If this condition holds, then Ax(x, y)= ∂z ∂x and Ay(x, y)= ∂z ∂y for some function z(x, y)and δa is the diﬀerence of the values of this function. The above can be simply generalized to any number of variables. As an example, consider again the ideal gas. The relation between energy and (absolute) temperature is E = f 2 NkT , (2.0.4) 126 Ch. 0 Essential Background in Thermodynamics where f is the number of degrees of freedom per molecule. See also Part I, Chap. 1. Keeping N ﬁxed, we write δQ for a process where T , V and P are varied. The state space is two-dimensional. Taking T and V as the independent variables (coordinates), Eq. (2.0.2) gives for δQ δQ = Nk ( f 2 dT + T V dV ) . (2.0.5) The right hand side of (2.0.5) does not give equal cross derivatives with respect to V and T and hence is not an exact diﬀerential. Consequently, the amount of heat transferred to the system in a given process, which is obtained by integrating δQ alongthe appropriate path, is not the diﬀer- ence of the values of some “heat” function between the ﬁnal and initial points, but depends on the particular process (the path between the two points in state space.) Several processes are given special names: isothermal process —the temperature is kept constant; isochoric process — the volume is kept con- stant; isobaric process — the pressure is kept constant; adiabatic process — there is no heat exchange: dE = −δW . Exercise 0.1 Calculate the amount of heat transferred to an ideal gas of N molecules with f degrees of freedom in: (a) An isothermal process. (b) An isochoric process. (c) An isobaric process. Solution on page 183 Exercise 0.2 An ideal gas is at temperature T1 and volume V1. The gas is taken through an isobaric process to a state of higher temperature T2.It is then taken via an isochoric process to a state of temperature T1 and ﬁnally back to the initial state in an isothermal process. (a) Calculate the amount of heat transferred to the gas in the cycle. (b) Same as (a) but in reverse cycle. (c) What would be the result if δQ were an exact diﬀerential? Solution on page 183 Exercise 0.3 (a) Calculate the work done by the gas during the cycle described in the previous exercise. 0.1 The ﬁrst law 127 (b) Is it equal to Q? (c) Calculate the work done by the gas during an adiabatic process. (d) Show that if the ideal gas undergoes an adiabatic process T and V satisfy VT f/2 =const alongthe path. Solution on page 184 The heat capacity is the quantity of heat required to change the tem- perature of the system by δT . Since the heat capacity is deﬁned in terms of the heat, it depends on the process. For example, there is the heat ca- pacity at constant volume, CV , and the heat capacity at constant pressure, CP . The heat capacity is not a derivative of Q. One can schematically write CV = ( δQ δT ) V . (2.0.6) It represents the coeﬃcient of dT in the expression for δQ when it is written in terms of the variables T and V . This expression already appears in Eq. (2.0.5) and one has CV = f 2 Nk . (2.0.7) The heat capacity at constant pressure is deﬁned analogously as CP = ( δQ δT ) P . (2.0.8) To calculate it one identiﬁes the coeﬃcient of dT in the expression for δQ when it is written in terms of T and P . Exercise 0.4 Show that the heat capacity at constant pressure for an ideal gas is CP = ( 1+ f 2 ) Nk . (2.0.9) Solution on page 185 The ratio between the two heat capacities is simply the adiabatic pa- rameter γ =1 + 2 f . See also Eq. (1.1.25). Exercise 0.5 Show that γ is the same γ as in the adiabatic equation, PV γ =const. Solution on page 185 128 Ch. 0 Essential Background in Thermodynamics 0.2 The second law and the entropy Clausius formulation: It is impossible for any engine working continuously in a cycle to transfer heat from a colder to a hotter body and to produce no other eﬀect. Kelvin formulation: It is impossible for an engine working in a cycle to extract heat from a single reservoir, produce an equal amount of work and have no other eﬀect. The analysis of the second law leads to the conclusion that δQ T is an exact diﬀerential, i.e. a diﬀerential of a new function of state. This is the entropy S. dS = δQ T . (2.0.10) It is an extensive variable. In mathematical terms 1 T is an integration factor of the diﬀerential δQ. It converts it into an exact diﬀerential. The ﬁrst law, Eq. (2.0.2), may thus be written in terms of state func- tions only: dE = TdS − PdV . (2.0.11) This relation may be used to calculate the entropy diﬀerences between states of a gas. Given that at this stage the entropy is deﬁned only up to an additive constant this is the most one can do. More about this in Part III, Chap. 5. Exercise 0.6 (a) Startingfrom (2.0.5) show that the entropy of an ideal gas of N molecules with f degrees of freedom is S = Nk ln ( cV T f/2 N ) . (2.0.12) (b) Calculate the entropy increase of an ideal gas in an isothermal process. (c) Calculate the entropy increase of an ideal gas in an isochoric process. (d) What is the process in which the entropy remains constant? Solution on page 186 An alternative expression for the heat capacity is obtained in terms of the entropy, Eq. (2.0.10). One can write δQ as δQ = T ( ∂S ∂T dT + ∂S ∂V dV ) . (2.0.13) The coeﬃcient of dT is CV . Hence CV = T ( ∂S ∂T ) V . (2.0.14) 0.3 Thermodynamic potentials 129 Analogously CP = T ( ∂S ∂T ) P . (2.0.15) CV and CP can also be obtained from other functions of state: The ﬁrst law is δQ = dE + PdV , hence at constant volume δQ = dE and CV = ( δQ δT ) V = ( ∂E ∂T ) V . (2.0.16) To calculate CP we deﬁne the enthalpy H as enthalpy H = E + PV . (2.0.17) It is one member of a family of thermodynamic potentials discussed in the next section. It is a function of state, since it depends only on functions of state. We reserve the ordinary H for the magnetic ﬁeld. We write δQ with dE replaced by dH: δQ = dE + PdV = dH − VdP = ( ∂H ∂T ) P dT + [( ∂H ∂P ) T − V ] dP . (2.0.18) If T and P are the independent variables, the heat transfer due to a change in the temperature at constant pressure equals the change in the enthalpy at constant pressure: CP = ( δQ δT ) P = ( ∂H ∂T ) P . (2.0.19) Exercise 0.7 Calculate the enthalpy of an ideal gas and from it CP . Solution on page 186 0.3 Thermodynamic potentials The energy is a thermodynamic potential when expressed in terms of S and V : Eq. (2.0.11) gives the variation of the energy in terms of the variations of the independent variables S and V . It is a function of state. From Eq. (2.0.11) one obtains two relations: T = ( ∂E ∂S ) V ,P = − ( ∂E ∂V ) S . (2.0.20) If one rewrites Eq. (2.0.11) isolating dS and regards the entropy as a function of E and V ,then the entropy S is identiﬁed as another 130 Ch. 0 Essential Background in Thermodynamics thermodynamic potential, S(E, V ). It is a function of state and two new relations follow: 1 T = ( ∂S ∂E ) V , P T = ( ∂S ∂V ) E . (2.0.21) This structure is rather general: The basic function of state, or the thermodynamic potential, is an extensive quantity which is a function ofthermodyna- mic potential extensive variables. Its diﬀerential is a linear combination of diﬀerentials of extensive variables with intensive variables as coeﬃcients. The par- tial derivative of a thermodynamic potential with respect to an extensive variable yields its conjugate intensive variable. Once a thermodynamic po- tential is given, all the thermodynamic properties can be derived from it. Exercise 0.8 Given the followingexpression for the entropy of a system: S = Nk ln ( aV E3/2 N 5/2 ) , (2.0.22) where a is a constant, obtain all the thermodynamic information about this system, P , T etc. Solution on page 187 When the number of particles N is reconsidered as a thermodynamic variable that may vary from state to state as a result of an exchange of particles with the surrounding, or a chemical reaction, one adds in the expression for the ﬁrst law the corresponding chemical work. dE = TdS − PdV + µdN . (2.0.23) The thermodynamic potential E thus becomes a function of S, V and N . The coeﬃcient µ is the chemical potential. It represents the change inchemical potential the energy of the system associated with a unit increase in the number of particles. µ is an intensive variable. Exercise 0.9 Show that the chemical potential for a monoatomic ideal gas is given by µ = −kT ln (bV T 3/2 N ) , (2.0.24) where b is a constant. Solution on page 187 0.3 Thermodynamic potentials 131 Since energy and entropy are not easy to control experimentally, one develops alternative representations of the thermodynamic information, expressed in terms of other thermodynamic potentials, which depend on the temperature instead of the energy or the entropy. This is carried out by a Legendre transformation. Startingfrom an E(S, V, N ), Eq. (2.0.20) gives an expression for T in terms of S, V (and N ). Hence it provides S as a function of T , V (and N ). One then considers the function F = E − TS , (2.0.25) called the Helmholtz free energy (or the free energy). It is a Legendre free energy transform of the energy. To identify the independent variables, one writes the diﬀerential of F [using(2.0.23)]: dF = dE − TdS − SdT = −SdT − PdV + µdN . (2.0.26) Hence, it is a thermodynamic potential with T , V and N as its natural variables. Startingfrom an expression for the free energy one derives the pressure as a function of T , V and N (which is the equation of state) as well the entropy and the chemical potential by S = − (∂F ∂T ) V,N ,P = − ( ∂F ∂V ) T,N ,µ = ( ∂F ∂N ) T,V . (2.0.27) In contrast to S or E, F is a potential that depends on an intensive variable, T .Since F is extensive, its derivative with respect to T , i.e. S, is extensive as well. These expressions lead to the Maxwell relations between various deri- Maxwell relationsvatives of the entropy, pressure and chemical potential. They all express the fact that the mixed second partial derivatives of F (T, V, N )are inde- pendent of the order of derivation. One ﬁnds that − ( ∂P ∂N ) T,V = ( ∂µ ∂V ) T,N , − ( ∂S ∂N ) T,V = ( ∂µ ∂T ) V,N , ( ∂S ∂V ) T,N = ( ∂P ∂T ) V,N . Exercise 0.10 Calculate the free energy of a monoatomic ideal gas. Give the result in terms of the variables T , V and N and choose the arbitrary constant to be consistent with (2.0.24). Solution on page 187 132 Ch. 0 Essential Background in Thermodynamics Exercise 0.11 The free energy for a photon gas is given by F = − a 3 VT 4 , (2.0.28) where a is a constant. The origin of this result and the meaning of a will be discussed in Part IV. (a) Calculate the entropy of the photon gas. (b) Calculate the pressure of the photon gas and its equation of state. (c) Calculate the energy of the photon gas. (d) What is the chemical potential of the photon gas? Solution on page 188 Exercise 0.12 Calculate the equation of the adiabatics of a photon gas. Solution on page 189 Exercise 0.13 Verify the Maxwell relations for: (a) Ideal gas. (b) Photon gas. Solution on page 189 To consider systems which may exchange not only energy but also particles with a reservoir, the number of particles N is replaced by its conjugate variable, the chemical potential µ. Mathematically, another Legendre transformation is performed, leading from the free energy to a new thermodynamic potential whose natural variables are T , V and µ. This is done by deﬁningthe grand potential, or just the thermodynamic potential, Ω: Ω= F − µN = E − TS − µN , (2.0.29) where the three N ’s (the explicit one, the one inside S and the one inside E) are expressed in terms of T , V and µ, usingthe equation for µ(T, V, N ), in Eq. (2.0.27). Then usingEq. (2.0.23) the diﬀerential, in terms of the independent variables T , V and µ, becomes dΩ= −SdT − PdV − Ndµ. (2.0.30) 0.4 The third law 133 One obtains a set of relations analogous to (2.0.27): S = − ( ∂Ω ∂T ) V,µ ,P = − ( ∂Ω ∂V ) T,µ ,N = − ( ∂Ω ∂µ ) T,V , (2.0.31) with the associated Maxwell relations, which are left as an exercise. Exercise 0.14 (a) Derive the Maxwell relations associated with the thermodynamic po- tential Ω. (b) Calculate Ω for a monoatomic ideal gas. Solution on page 190 Finally, we express the heat capacity at constant volume (and number of particles) in terms of F . CV is a derivative of the energy with respect to T at constant V and N [Eq. (2.0.16)]. But E is a function of S, V and N [Eq. (2.0.23)], so ﬁrst one needs the dependence of E on T .This is done usingEq. (2.0.25), substituting S(T, V, N ) from (2.0.27). One can write E(T, V, N )= F (T, V, N ) − T ( ∂F ∂T ) V,N , (2.0.32) and the heat capacity at constant volume becomes CV = ( ∂E ∂T ) V,N = −T (∂2F ∂T 2 ) V,N . (2.0.33) This is just a rewritingof Eq. (2.0.14). Correspondingly, CP should be calculated from the enthalpy which is written as a function of T , P and N . These variables call for a new thermodynamic potential. 0.4 The third law The experimental failure to reach absolute zero together with the theoret- ical failure to derive the impossibility of reaching0 K from the ﬁrst two laws, led to the formulation of the third law: Formulation 1: By no ﬁnite series of processes is absolute zero attainable. Formulation 2: As the temperature tends to zero, the magnitude of the entropy change in any reversible process tends to zero. We will return to this issue and its consequences in Part III. Suggested reading (1) E. Fermi, Thermodynamics (Dover, New York). (2) A.B.Pippard, Classical Thermodynamics (Cambridge University Press, London). (3) C. J. Adkins, Equilibrium Thermodynamics (McGraw-Hill, London). Chapter 1 Thermodynamics with Magnetic Variables 1.1 Introduction Since part of the testingof statistical mechanics is its ability to reproduce the laws of thermodynamics, and since the magnetic system is a convenient example, we open the discussion with a thermodynamic description of systems which respond to a magnetic ﬁeld. We will use these results in Chaps. 4 and 5. Before passingon to the discussion of the thermodynamic variables, we recall the relevant concepts from the electromagnetic theory. The fundamental concept here is the dipole moment (electric or magnetic), which has two important characteristics. First, a dipole moment in an external ﬁeld is acted upon by a torque which tends to align it along the direction of the ﬁeld as described in Fig. 2.1.1. A simple calculation, which will not be given here, shows that the magnitude of the electric dipole moment, p, of a pair of charges ±q is proportional to the distance between them, d, i.e. p = qd, and that the magnetic dipole moment of a planar loop, µ (not necessarily rectangular!), carrying a current I iselectric/ magnetic dipole moment proportional to its area, a : µ = Ia/c (c is the speed of light). Since the dipole prefers to align itself along the direction of the ﬁeld, it is clear that it has a potential energy that depends on the angle between its direction and the direction of the ﬁeld or, in other words, on their scalar product: Eel = −p · E , (2.1.1a) Emag = −µ · B . (2.1.1b) This means that the potential energy decreases as the angle between the direction of the dipole and the direction of the ﬁeld decreases. 134 1.1 Introduction 135 Fig. 2.1.1 The torque acting on a current loop (a) and a side view of the magnetic moment of the loop (b). For comparison the electric dipole is depicted (c). The second role is that each dipole moment is also a source of an electric or magnetic ﬁeld. An important fact for us is that the presence of a macroscopic number of dipoles, for example in a bulk of dielectric material, changes considerably the external ﬁeld that would exist in that region in the absence of the material. The intensity of the ﬁeld originating from these dipoles is determined by the polarization density, which is the dipole moment per unit volume of the material and is denoted by P in theelectric caseand M in the magnetic case. M is also called magnetization density or magnetization per unit volume. The relation between the induced ﬁelds and the polarization density is E = −4πP , (2.1.2a) B =4πM . (2.1.2b) Notice the diﬀerence in sign between the electric and the magnetic equations. It stems from the opposite behavior of the ﬁelds “inside” the dipoles. Consider, for example, a single dipole moment in a medium of many other dipoles: It will feel (via the torque) the external ﬁeld H and also the additional ﬁeld 4πM, originating from the neighboring dipoles. The sum of these two eﬀects is the magnetic induction B, and the relationship between them is B = H +4πM . (2.1.3) A similar relationship can be formulated for the electric case, but we will restrict ourselves to magnetic systems. To conclude the introduction, we further remark that there is a practi- cal reason for concentratingon the ﬁeld H, and not the magnetic induction B,which is that H is the external variable which is under control: We are able to change the currents, thereby aﬀecting what would have happened in the absence of the material. The appearance of the magnetic induction 136 Ch. 1 Thermodynamics with Magnetic Variables depends on M, the magnetization density, which is the system’s response to H. Hence, even though B is the natural variable in electromagnetic theory, in thermodynamics we prefer to express quantities in terms of H. 1.2 The ﬁrst law in magnetic variables The thermodynamic description is of a much more general validity than would seem so when dealingwith a mechanical set of variables — pressure P and volume V , characteristic of gases and liquids. Analogously, we can describe a system respondingto a magnetic ﬁeld, using the mechanical- like variables: the magnetic ﬁeld H and the magnetization (i.e. the total magnetic moment) M. The relationship between the magnetization M and the magnetization density M is, of course, M = MV ,where V is the volume of the system. The ﬁeld H is an intensive variable, while M,the response to H, is an extensive variable. An increase in P leads to a decrease in V , while the increase in H increases M; however, this is only a diﬀerence in sign [see Eq. (2.1.10)]. We can similarly characterize the system by an electric ﬁeld E (intensive) and an electric polarization (extensive), etc. We saw in the previous chapter that the ﬁrst law of thermodynamics is written in the form dE = δQ − δW . (2.1.4) dE is the increase in the energy of the system, δQ is the heat transferred to the system and δW is the work done by the system. When the system expands by dV against a pressure P , δW = PdV . In order to formulate the ﬁrst law in magnetic variables, we must ﬁrst inquire how the work is expressed in these variables, namely what is the work done by the system when the external ﬁeld changes by dH. For the sake of simplicity we assume that our system is a long, thin cylindrical bar, with its axis along the magnetic ﬁeld. The external mag- netic ﬁeld orders the microscopic dipoles in the bar, giving rise to an induced magnetic moment, M . This situation is described in Fig. 2.1.2, where the external magnetic ﬁeld along the bar is depicted — before the change and after it. Suppose the magnetic system at a given instant is in a microscopic state r in which it has an induced magnetic moment Mr and the ﬁeld is H. The change of H to H + dH lowers the energy of H ➤ ➤ ➤ H+dH M Fig. 2.1.2 A long, thin bar having an induced magnetic moment in an external ﬁeld. 1.2 The ﬁrst law in magnetic variables 137 the state. The change in energy is obtained by multiplying the magnetic moment by the change in the ﬁeld: dEr = −MrdH , (2.1.5) which means that in such a change the system will perform work of MrdH. In thermodynamics we are not interested in a given state of the system, but in the average over long times. Therefore the work performed by the system when H changes will be δW = MdH , (2.1.6) where M is the average of Mr. We now write (2.1.4) in the form dE = δQ − MdH . (2.1.7) And the entropy [Eq. (2.0.10)] is given by dS = dE T + MdH T . (2.1.8) It is of course possible to deﬁne a new energy: E∗ = E + MH , (2.1.9) which is the energy of the state, together with the energy of the electro- magnetic ﬁeld. This is a standard Legendre transformation which produces a new thermodynamic potential. See e.g. Sec. 0.3. In terms of E∗ we can express the entropy change in the form TdS = dE∗ − HdM , (2.1.10) which is more reminiscent of the correspondingequation for gases, in that both diﬀerentials are of extensive quantities, except for the sign diﬀerence: PdV →−HdM . (2.1.11) Exercise 1.1 What is the physical meaningof the diﬀerent derivatives of S, as inferred from (2.1.8) and (2.1.10), and the relationships between them? Solution on page 190 Chapter 2 Microscopic States and Averages 2.1 Magnetic states, angular momentum and paramagnetism Diﬀerent materials respond diﬀerently when a magnetic ﬁeld is applied to them. The simplest response is that as a result of the application of the ﬁeld a magnetic moment is induced, which vanishes with the vanishing of the ﬁeld. If in addition the induced moment is directed alongthe ﬁeld, the response is called paramagnetic. The magnetic moment (the magnetization) may also be directed opposite to the ﬁeld. In this case the material is called diamagnetic. There is a large diversity of other behaviors, but here we will mention only the ferromagnet (ferro for iron), a substance which at moderate temperatures retains its magnetization, even after the removal of the magnetic ﬁeld. Before going on to the thermodynamic discussion of paramagnetism, we recall that the source of the magnetization that appears in materials is microscopic and each atom or ion possesses an intrinsic magnetic dipole moment. Actually, this intrinsic dipole moment originates from the elec- trons of the atom or ion, as hinted in Fig. 2.1.1(a). An electron revolving around the nucleus at radius r and velocity v behaves as a circular current loop of area πr2 and current ev/2πr. The magnetic moment of the loop is µ = 1 2c evr . (2.2.1) Equation (2.2.1) can be written in the form µ = eℓ/2mc or in its vector version: µ = − e 2mc ℓ , (2.2.2) where m is the mass of the electron and ℓ is its angular momentum. How- ever, despite the oversimpliﬁed assumptions upon which it is based, this connection between the magnetic moment and the mechanical quantities 138 2.1 Magnetic states, angular momentum and paramagnetism 139 related to the motion of the electron is of general validity. Equation (2.2.2) also holds for noncircular orbits and remains valid even within the frame- work of quantum mechanics, which is the appropriate theoretical frame- work for the discussion of electrons in atoms. In quantum theory the angular momentum of the electron (or, in fact, of any other particle) is quantized and can take on values which are integer multiples of the fun- damental quantum of angular momentum, ¯h. Planck’s constant h =6.626 × 10−34 J · s=6.626 × 10−27 erg · s , ¯h = h 2π . Both h and ¯h are referred to as Planck’s constant in the literature. Concerning the quantization of angular momentum, see any text on modern physics. It is therefore convenient to deﬁne a dimensionless vector L which measures the angular momentum in units of ¯h: L = ℓ ¯h . (2.2.3) ℓ and L are both called angular momentum; we will leave no room for confusion between them. Since the angular momentum of the electron is quantized, the magnetic moment related to it is also quantized, and the fundamental quantum of the magnetic moment of the electron is called the Bohr magneton, Bohr’s magneton µB = e¯h 2mc =9.273 × 10 −21 erg/gauss , so that we can write µ = −µBL . (2.2.4a) But this is not the end of the story, because in addition to the orbital angular momentum ℓ the electron also possesses an internal angular mo- mentum or spin S. Like all angular momenta, also the spin assumes only spin discrete values but, in contrast to the orbital angular momentum, which can only take on integral multiples of ¯h, the spin can also take on half- integral values. The spin of the electron can take on the values ± 1 2¯h only. This fact is conventionally summarized in the literature by the words “the electron has spin 1 2 .” On the basis of Eq. (2.2.2) we could expect the spin itself to create an additional magnetic moment of 1 2 µB, but this is not so: a magnitude twice as large is found experimentally. Hence the relation between the 140 Ch. 2 Microscopic States and Averages magnetic moment and the spin of the electron is µ = − e ms = −2µBS , (2.2.4b) where again we have deﬁned a dimensionless spin by S = s/¯h. The reason for the factor-of-2 discrepancy with the expected result for the electron’s magnetic moment is explained by taking into account relativistic eﬀects in the quantum treatment of the electron, as was ﬁrst done by Dirac at the end of the twenties. Actually, the true value is slightly larger than 2 (by two parts in a thousand). This fact can be explained within the framework of quantum electrodynamics. The total magnetic moment of a single electron is thus the sum of (2.2.4a) and (2.2.4b). The magnetic moment of the whole atom or ion, which is in fact our main interest, is the sum of the contributions of all its electrons. The electrons in the atom are arranged in shells, so that each electron in every shell has a speciﬁc angular momentum. The total angular momentum of electrons in a full shell or subshell is zero. If one electron is added to or removed from a full shell the ion remains with an angular momentum equal in size to the angular momentum of the additional or missing electron. Since a charged particle, possessing angular momentum, has a magnetic moment, we can assign the ion that magnetic moment. In light of Eq. (2.2.4) the magnetic moment of the ion is proportional to its total (dimensionless) angular momentum: J = ∑ i (Li + Si) . (2.2.5) Moreover, it is possible to show that in an external magnetic ﬁeld, the ion increases its energy by an amount which is proportional to J: ∆E = gµBJ · H , (2.2.6) where g is a numerical factor of order 1 which is determined by the struc- ture of the atom. g is called the gyromagnetic factor and it actually de-gyromagne- tic ratio scribes the ratio between the magnetic moment of the ion and its to- tal angular momentum. For a free electron we obtain g =2, as already mentioned. As an example we consider doubly ionized copper, Cu ++.In the ex- ternal shell, the fourth shell, Cu contains a single electron. The double ionization removes this last electron as well as one from the full, highest subshell of the third shell, 3d. The ion has a single hole in the 3d shell with angular momentum 5 2 ¯h, as explained above. There are diﬀerent kinds of paramagnets. Here we discuss a type for which the ions possessingangular momenta are set in ﬁxed positions in a crystal. For example, in ionic crystals of copper salts, manganese or 2.2 Microscopic states, observables 141 gadolinium, the ions Cu ++,Mn++,Gd++ give rise to the paramagnetism of the salt. If there are many nonmagnetic atoms in the salt per magnetic ion, then it is reasonable to assume that due to the large separation of the magnetic ions they do not aﬀect one another. This is the case, for example, in copper potassium sulphate: CuSO4 · K2SO4 · 6H2O. Remark. Equations (2.2.1) and (2.2.2) are valid only in cgs units. In the SI system the factor of c (the speed of light) in the denominator should be dropped. Hence the Bohr magneton is in SI units: µB = e¯h 2m =9.273 × 10 −24 JT−1 . All other equations have the same form in both systems. 2.2 Microscopic states, observables The simplest case that we begin with is a paramagnet in which N magnetic ions have “spin 1 2 .” This means that any projection (component) of S may take on the values ± 1 2 only. From here on the total angular momentum of the ion will be referred to as the spin. This is so since we are not interested in the details of such an ion and are considering only its general characteristics, which are its spin and magnetic moment. The spin will serve for the enumeration of states and the magnetic moment for the calculation of its energy in a magnetic ﬁeld. If a ﬁeld H is applied to a single moment µi, the energy is given by ϵi = −µi · H . (2.2.7) However, in our case, the magnetic moment can have only two projections alongthe ﬁeld (µB or −µB), so that we can write ϵi = −µBHσi , (2.2.8) where σi is a variable that has two possible values: ±1. σ describes the projection of the spin along the direction of the ﬁeld. In the case of spin 1 2 , its projection along the ﬁeld is ¯hσ/2, where σ = ±1. Since we are assumingthat the magnetic moments are far from one another (which means that there is no interaction between the magnetic ions), we can write the energy of a conﬁguration or of a microscopic state of the system of moments in the form E(σ1,... ,σN )= −µBH N∑ i=1 σi . (2.2.9) 142 Ch. 2 Microscopic States and Averages ➤ ➤ ➤ ➤ ➤ ➤ H➤ z➤ Fig. 2.2.1 A model of a paramagnet in an external ﬁeld. By the term conﬁguration or microscopic state we mean a state in which all the degrees of freedom of the system are speciﬁed (see also Sec. 1.5 of Part I). In the present case the system has N degrees of freedom corresponding to N magnetic ions, which we denote by σi. Each degree of freedom can assume one of two possible values, σi = ±1 (because we chose ions with spin 1 2 ). If each σi is assigned a value, a speciﬁc conﬁguration, or a speciﬁc microscopic state, is determined. For instance, the conﬁguration σi =+1 for every i is the state in which all the magnetic moments point along the ﬁeld, while σi = −1 for every i is the state in which all the magnetic moments are opposite to the ﬁeld. Figure 2.2.1 depicts a lattice on which there are “spherical” atoms, black and white, which have zero magnetic moments. There are also “elongated” atoms, with arrowheads represent- ingtheir magnetic moments. Their serial number is i and the projection of their magnetic moment along the z axis, which is chosen alongthe ﬁeld, is ±µB. There is no interaction between them. This is our model system. This system has 2N microscopic states. Each of them is character- ized by N numbers (σ1,... ,σN ), which determine the projection of each spin. In each microscopic state the properties of the system are com- pletely deﬁned. With each microscopic state one can associate observ- ables, A(σ1,σ2,... ,σN ), which are numbers associated with the particu-observables lar state. For instance, the total magnetic moment along the z axis is an observable given by M (σ1,... ,σN )= µB N∑ i=1 σi , (2.2.10) as is the total energy given by (2.2.9). 2.3 Probabilities and averages 143 The magnetic moment of a subsystem with Na of the N magnetic moments is an observable of the full system Ma(σ1,... ,σN )= µB Na∑ i=1 σi , (2.2.11) despite the fact that it depends only on part of the variables. So is the energy of the subsystem Ea = −HMa. The value of a particular spin σi is also an observable, etc. With a little extra eﬀort it is possible to generalize the present model to the case in which the ions have an angular momentum J> 1 2 ,where J is the sum of the orbital angular momentum and the spin [Eq. (2.2.5)]. In this case the possible values of the projection of the angular mo- mentum along H are Jz = −J, −J +1, −J +2,... ,J . Thus, there are 2J + 1 possibile projections. The energy levels of such an ion are given again by multiplying µBJzH by the gyromagnetic factor. All the expressions that we have written in this section still hold, with the proviso that every degree of freedom will now have 2J + 1 states, instead of just two. Consequently, there will now be (2J +1)N microscopic states. 2.3 Probabilities and averages As was mentioned in the Introduction to this part, the role of statistical mechanics is to create a bridge from microscopic states to averages. To this end we want to know the probability for a certain microscopic state to appear alongthe system’s trajectory in conﬁguration space. Such a trajectory is described by giving the N -tuples (σ1,... ,σN ) in a certain time interval. This approach is replaced, of necessity, by the ensemble approach, in which the time evolution is ignored, and probabilities are assigned to all allowed states. The ensemble is deﬁned by the collection of probabilities, or recur- rence rates, of every microscopic state. We denote the probability of the state (σ1,... ,σN )by P (σ1,... ,σN ). Once P is given, the problem of evaluatingaverages becomes a mere technicality. Since, if A(σ1,... ,σN ) is an observable of the paramagnetic system, in the microscopic state (σ1,... ,σN ), the required average is just ⟨A⟩ = ∑ {σ} P (σ1,... ,σN )A(σ1,... ,σN ) , (2.2.12) 144 Ch. 2 Microscopic States and Averages where ∑ {σ} denotes the summation over all microscopic states. Thus, the sum is over 2N states, wherein each spin takes on both possible values. In thecaseof a spin J, each spin takes on 2J + 1 values, and the sum is over (2J +1)N microscopic states of the system. Thus, for example, the average magnetic moment of the system, in an ensemble deﬁned by P , is determined by the average of A = M = µB(σ1 + σ2 + ··· + σN ), so that ⟨M ⟩ = µB ∑ {σ} ( ∑ i σi ) P (σ1,... ,σN ) . (2.2.13) The fog of mathematical symbols can be reduced by writing Eq. (2.2.13) in the simple cases of small N.For N =3 we obtain ⟨M ⟩ = µB ∑ σ1,σ2,σ3(σ1 + σ2 + σ3)P (σ1,σ2,σ3) , where the summation is performed independently over σ1,σ2 and σ3, each assuming the values ±1. There are a total of eight possibilities. Next, we show that ⟨M ⟩ is proportional to the average magnetic mo- ment of a single spin. To this end we deﬁne the probability for a given spin — with i = 1 for example — to have the moment σ1(+1 or −1): P (σ1)= ∑ {σ} ′P (σ1,... ,σN ) , (2.2.14) where ∑′ denotes that we are summingover microscopic states with ﬁxed σ1, or in other words we are summingover all possible values of σ2,... ,σN . Of course, all the moments are equivalent so there is no special signif- icance to σ1. The prime can be attributed to any other spin i,and then the sum in Eq. (2.2.14) represents the probability P (σi) for that spin to have the value +1 or −1. Thus we can denote all of them by P (σ). We can therefore rewrite Eq. (2.2.13) in the form ⟨M ⟩ = µBN ∑ σ=±1 σP (σ)= µBN ⟨σ⟩ , (2.2.15) where ⟨σ⟩ is the average of the observable A = σi. Exercise 2.1 Does the result (2.2.15) seem reasonable to you, without a detailed cal- culation? What would you expect to be, without calculating, the average magnetic moment of the subsystem of the Na spins [whose moment is given by Eq. (2.2.11)]? Solution on page 191 2.3 Probabilities and averages 145 The transition from Eq. (2.2.13) to Eq. (2.2.15) was done in the fol- lowingmanner. We change the order of summations in Eq. (2.2.13) and write ⟨M ⟩ = µB N∑ i=1 ∑ {σ} σiP (σ1,... ,σN ) . (2.2.16) The summation over the states may be carried out in two stages. First, we hold σi constant for a certain i, and carry out the inner summation over all possible σj with j ̸= i.After that we sum over σi. The inner sum is ∑ {σ} σiP (σ1,... ,σN )= ∑ σi=±1 σi ∑ {σ} ′P (σ1,... ,σN ) , (2.2.17) where, as before, ∑′ denotes a sum in which each spin takes the values ±1, except for σi, whose value is ﬁxed. UsingEq. (2.2.14) we note that the primed sum is P (σi), so that we may write the right hand side of Eq. (2.2.17) in the form ∑ σi=±1 σiP (σi)= ⟨σi⟩ . (2.2.18) Now we are left with the outer summation in Eq. (2.2.16), after we sub- stitute Eq. (2.2.18) into Eq. (2.2.16). Since ⟨σi⟩ is independent of i [as P (σi) are also independent of i], we are summing N equal terms ⟨σ⟩,and we obtain Eq. (2.2.15). The independence of i means that we obtain the same result for each of the magnetic moments of the system, the reason for which is of course that they are all identical. Exercise 2.2 Show that it is possible to write the probability that two spins i and j will have components σi and σj, respectively, as P (σi,σj)= ∑ {σ} ′′P (σ1,... ,σN ) , (2.2.19) where σi and σj areheldﬁxedinthe summation, and thesummation is carried out over all other N − 2 spins. Solution on page 191 With the help of Eq. (2.2.19) we can write the covariance between two spins, which measures the dependence of one spin (say, i =1)onthe state of another (say, j = 2). We denote the covariance by C(1, 2) or generally C(i, j). Its deﬁnition is C(1, 2) = ⟨σ1σ2⟩− ⟨σ1⟩⟨σ2⟩ . (2.2.20) 146 Ch. 2 Microscopic States and Averages Clearly, if the two spins are independent of each other, C vanishes. C is positive if a given value of σ1 encourages spin 2 to have the same value. C will be negative if σ1 encourages spin 2 to have the opposite value. An explicit example for the calculation of C(1, 2) will be given in the next chapter. Chapter 3 Isolated Paramagnet — Microcanonical Ensemble 3.1 Number of states and probabilities When one is tryingto determine the ensemble, to decide on the occur- rence rates of the distinct microscopic states of a system, it is vital to take into account the strict constraints. It is clear, for example, that if a gas is in a sealed vessel, the time evolution of the system will not re- sult in the appearance of states in which molecules are found outside the vessel. Similarly, all conservation laws must apply to the states of the ensemble. The ﬁrst conservation law which comes to mind is the conservation of energy of an isolated system. Clearly, the trajectory of an isolated system will contain only states whose energy is equal to the initial energy. Taking into account the conservation laws and the external constraints applied to the system, it is natural to assume, in the absence of other information, that all the states are equally probable. One may ask, of course, how it is possible for the paramagnetic system to pass from one state to another, and not remain in a single microscopic state if the spins do not aﬀect one another. The answer is that there are, necessarily, interactions between the diﬀerent spins, but that these involve energies that are very small compared to the energy of the moments in the magnetic ﬁeld. Nevertheless, since we are dealing with many states of the same energy, even a small perturbation can (in the quantum description) transfer the system from state to state, with ﬁnite probability. Thus it is reasonable to treat the problem as if the energy were given by (2.2.9) and the system’s trajectory, in the space of microscopic states, passes through all of the allowed states. A similar question may be asked for the case of an ideal gas of pointlike molecules, and the answer is, of course, that the collisions of the molecules with one another and with the walls of the container cause the gas to pass from one microscopic state to another. 147 148 Ch. 3 Isolated Paramagnet — Microcanonical Ensemble Moreover, we shall interpret the state of thermal equilibrium as a state to which the system has evolved after a longenough time, so that by now all the microscopic states appear at the same occurrence rate duringits time evolution. This collection of states corresponds to a macroscopic state. The ensemble we deﬁned, of constant energy, is called a micro-microcanoni- cal ensemble canonical ensemble (there is no point in tryingto ﬁnd a deep meaningto this name). In such an ensemble, if the energy is E, the probability for a certain microscopic state is, simply, 1/Γ(E), where Γ(E) is the number of states with energy E. Namely for our paramagnet P (σ1,... ,σN )= 1 Γ(E) . (2.3.1) Up to this point the considerations are of universal generality. To say more about Γ(E) we turn to the simple model of the paramagnet. The model is so simple that it is possible to answer this question in detail, usingcombinatorial considerations. The energy of the state depends only on the diﬀerence between the number of spins that point alongthe ﬁeld, N+, and those that point in the opposite direction, N−. Denotingthis diﬀerence by q,namely q = N+ − N− , (2.3.2) we obtain from (2.2.9) E = −µBHq , (2.3.3) which means that constant E is equivalent to constant q. However, since the sum of N+ and N− is also constant, and equal to the total number of spins, constant q means that both N− and N+ are constant. But we can immediately write down the number of states with given N− and N+, since this is simply the number of ways of dividing N objects into two groups, N+ in one and N− in the other. That is, Γ(E)= N ! N+!N−! . (2.3.4) Exercise 3.1 Show that Γ(E)= N ! ( N 2 − E 2µBH )! ( N 2 + E 2µBH )! . (2.3.5) Solution on page 192 3.2 Calculating averages and correlations 149 3.2 Calculating averages and correlations The ﬁrst calculation we can perform is of the average magnetization. This is an especially simple calculation, since in all the states of equal energy the magnetization is identical. Hence ⟨M ⟩ = µBq = − E H (2.3.6) and the average magnetization per degree of freedom (spin) is simply µBq/N ,or −E/(NH). Next we calculate P (σ1), which was deﬁned in Eq. (2.2.14) as the probability for spin number 1 to have a projection σ1 alongthe ﬁeld. We start with σ1 = 1. That is, we calculate P (σ1 = 1) (as already mentioned and will be veriﬁed by the calculation, the result is independent of our choice of spin i = 1). We carry out the summation in (2.2.14) with P (σ1,... ,σN )given by 1/Γ(E) in (2.3.5). Since the probabilities are all equal, the problem reduces to ﬁnding the number of microscopic states with given q,for which σ1 =+1. We have to calculate the number of states of the remaining N − 1 spins, with an excess (N+ − N−)along+z,equalto q − 1. In other words, these are the states with N− spins along −z, as in the calculation of Γ(E) but with only N+ − 1along z. This number is (N − 1)! (N+ − 1)!N−! , so that P (σ1 =+1) = (N − 1)! (N+ − 1)!N−! · 1 Γ(E) = N+ N = 1 2 − E/N 2µBH . (2.3.7) The answer indicates that we could have calculated P (σ1 =1) in a simpler way: the probability for spin 1 to have projection +1 is equal to the probability for any one of other spins to have projection +1. Thus the required probability is also equal to the probability for an arbitrary spin to have projection +1, and is of course equal to the ratio of the number of spins with projection +1 and their total number: N+/N . Exercise 3.2 Show that P (σ1 = −1) = 1 2 + E/N 2µBH . (2.3.8) Solution on page 193 150 Ch. 3 Isolated Paramagnet — Microcanonical Ensemble Exercise 3.3 Show that it is possible to deduce P (σ1) from Eq. (2.2.15). Solution on page 193 In other words, we can say that if the energy is negative, the spins tend to align themselves along the magnetic ﬁeld. Namely, the probability for a spin to point alongthe ﬁeld is larger than 1 2 . If the energy is positive, the spins tend to be opposite to the ﬁeld. Let us consider a few representative cases: (a) The maximal energy of the system is NµBH: all the spins point opposite to the ﬁeld. If this is the given energy it is obvious that we will not ﬁnd any spin that is pointingalong the ﬁeld and so P (σ1 =1) =0 ,P (σ1 = −1) = 1 . The same result will of course be obtained from a direct substi- tution into (2.3.7) and (2.3.8). (b) The minimal energy is −NµBH: all the spins point alongthe ﬁeld — P (σ1 =1) =1 ,P (σ1 = −1) = 0 . (c) E =0: P (σ1 =1) = P (σ1 = −1) = 1 2 . The behavior of P (+1) and P (−1) as functions of the energy is depicted in Fig. 2.3.1. The average moment per spin ⟨σ⟩ is calculated as follows: ⟨σ⟩ = ∑ σ σP (σ)= 1 · P (1) + (−1)P (−1) = N+ N − N− N = q N . (2.3.9)➤ ➤ P E/µBHN P(–1)P(+1) 1–1 1 1/2 Fig. 2.3.1 A graphical representation of Eqs. (2.3.7) and (2.3.8). 3.2 Calculating averages and correlations 151 A more interestingquestion with a somewhat surprising answer, maybe, is the question of the covariance between the spins in the iso- lated system. P (σ1,σ2)and C(1, 2) are deﬁned by (2.2.19) and (2.2.20). An argument similar to the one made concerning P (σ1) will hold here as well, and we can write down    P (+1, +1) = (N+ − 1)N+ N (N − 1) , P (+1, −1) = P (−1, +1) = N+N− N (N − 1) , P (−1, −1) = (N− − 1)N− N (N − 1) . (2.3.10) Note that P (−1, +1) and P (+1, −1) are equal but correspond to dif- ferent microscopic states. Hence the normalization is P (+1, +1) + P (+1, −1) + P (−1, +1) + P (−1, −1) = 1 . Exercise 3.4 Produce the detailed argument that leads to (2.3.10). Solution on page 194 The covariance of the spins number 1 and 2, Eq. (2.2.20), is C(1, 2) = ∑ σ1,σ2 σ1σ2P (σ1σ2) − [∑ σ1 σ1P (σ1) ]2 = (N+ − 1)N+ (N − 1)N + (N− − 1)N− (N − 1)N − 2 N+N− (N − 1)N − (N+ − N−)2 N 2 , in which for the last term we have used Eq. (2.3.9). A bit of algebra leads to C(1, 2) = 1 N − 1 ( q2 N 2 − 1 ) < 0 . (2.3.11) That is, although there are no interactions between the spins it seems as if they “disturb” one another from aligning in the same direction. This is implied by the fact that C(1, 2) < 0. However, it is important to note that the correlations are independent of the distance between spin number 1 and spin number 2. This fact points to the origin of the correlations. They appear since, when N+ − N− = q is constant, the combinatorics of N − 2 spins is diﬀerent from that of N − 1 spins. In other words, choosing the value of σ1 to be, for example, +1, reduces the number of possibilities for the rest of the spins to have the value +1 so that it also reduces the 152 Ch. 3 Isolated Paramagnet — Microcanonical Ensemble probability of ﬁnding σ2 = +1. The origin of these correlations, therefore, is not dynamical but combinatorial. In order to learn from the correlations about the dynamics of the system, we must remove from the system the combinatorial eﬀect, which can be done by takingthe thermodynamic limit. The thermodynamic limit is the limit in which N tends to inﬁnity and is the limit that generally interests us in statistical physics. The covariance in Eq. (2.3.11) is of order 1/N ,since q/N is of order 1. So it tends to zero as N tends to inﬁnity, as indeed we would expect to occur. The probabilities (2.3.7) and (2.3.8) etc. depend on the ratio E/N , and do not tend to zero in the thermodynamic limit, since E/N remains ﬁnite. This is also the rule for treatingall the other extensive quantities: in the thermodynamic limit the extensive quantities are to be evaluated per degree of freedom. For instance, ⟨E⟩ and ⟨M ⟩ are extensive quantities, so that they yield meaningful values for ⟨E⟩/N and ⟨M ⟩/N in the thermodynamic limit. This means that when calculating an extensive quantity we are interested only in the largest term, which is proportional to the number of particles (or to the volume). Since the number of particles is very large, the successive terms are negligible. Exercise 3.5 Calculate the average square deviation of M from its average (∆M )2. Solution on page 195 Exercise 3.6 What is the probability that spin number 1, 2 and 3 will all be +1, in the thermodynamic limit? Express the result in terms of the number of spins and the energy. Solution on page 197 3.3 Numerical examples and Stirling’s formula In order to obtain a better sense for the orders of magnitude of the num- ber of states we are dealingwith, we shall study Γ(E) of Eq. (2.3.5) for diﬀerent values of N .For N = 1, i.e. for a single spin, there are two possible values for E, each of them correspondingto a single state. For the case N = 2 there are already three possibilities for E.Two states correspond to E = ±2µBH, one state to each sign and two more states correspond to E = 0, Γ(0) = 2. For the not-too-simple case N =10 the results are summarized in Table 3.1. 3.3 Numerical examples and Stirling’s formula 153 Table 3.1 E/µBH −10 −8 −6 −4 −2 024 6 8 10 Γ 1 10 45 120 210 252 210 120 45 10 1 Notice the emerging trend that the largest number of states corre- sponds to E = 0. This trend becomes more pronounced as the number of degrees of freedom (spins) increases. This fact hints that, if our system were not isolated, but could ex- change energy with its surroundings, it would have had to compromise between its tendency towards the state with minimal energy and the most probable (microscopic) state with zero energy. In order to eﬀectively analyze the cases with macroscopic N (∼ 1022), we have to ﬁnd a good method of calculating, at least approximately, factorials of numbers of this order. This is achieved by usingStirling’s formula: n! ≃ nne −n√ 2πn . (2.3.12) Stirling’s formula gives an approximation that improves as n increases. Already for n = 10 substitution into (2.3.12) gives 3.60 × 10 6 compared to the true value, which is 10! = 3628800. Instead of directly calculatingΓ(E) for large values of N , we deﬁne a function S/k as the logarithm of Γ(E) in (2.3.5), and calculate it. That is, 1 k S ≡ ln Γ ≃− ( N 2 − E 2µBH ) ln ( 1 2 − E/N 2µBH ) − ( N 2 + E 2µBH ) ln ( 1 2 + E/N 2µBH ) . (2.3.13) The ﬁrst part of (2.3.13) is a deﬁnition and is referred to as Boltzmann’s formula (it should not come as a great surprise to the reader if we leak at this stage the fact, to be discussed in the next chapter, that S is the entropy). The second part is an approximation, using(2.3.12), in which entropy we keep the ﬁrst term, which is the largest, in the expansion in powers of N . The term wehavekeptis proportional to N ,since E is proportional to N . The ﬁrst term that we neglected is independent of N (in the limit N →∞, the neglected term divided by N tends to 0), so that when N is very large the approximation is justiﬁed. We have found, therefore, that S is an extensive quantity. 154 Ch. 3 Isolated Paramagnet — Microcanonical Ensemble Exercise 3.7 (a) Use Stirling’s formula to deduce Eq. (2.3.13). (b) Check if (2.3.13) gives values that are close to the ones that appear in Table 3.1. Solution on page 198 The followingfact is of interest: Stirling’s approximation is justiﬁed for all three factorials in (2.3.5), except for a few states at the edges of the spectrum. The energies of our paramagnets start at −NµBH and end at +NµBH. At these energies the number of states is one. Thus S must vanish at the edges of the spectrum. Even though Stirling’s approximation does not apply near these points, the leadingterm in S, (2.3.13), has the property that it vanishes at the edges of the spectrum, as it should.➤S/Nk E/µBHN 1–1 ln2 ➤ Fig. 2.3.2 The “entropy” per spin for the paramagnet. The shape of the function S is shown in Fig. 2.3.2. Note that the vertical axis corresponds to S/N ,not S. With the help of S we can now calculate the number of states Γ = eS/k as a function of E or, better yet, as a function of E/(NµBH), which measures the energy per degree of freedom in units of µBH.The shape of Γ(E) is described in Fig. 2.3.3 for N =10, 100, 1000. Note the huge increase in the number of states as a function of N and the concentration near E =0. A study of Fig. 2.3.3 reveals a great similarity to the shape of the Gaussian (normal) distribution. And indeed it is possible to show that when N ≫ 1 the number of states with energy E depends on E in a Gaussian manner: Γ(E)= C exp ( −E2 2Nµ2 BH 2 ) , (2.3.14) 3.3 Numerical examples and Stirling’s formula 155 Fig. 2.3.3 Graphs of the number of states as a function of the dimensionless variable E/(NµBH), for (a) N = 10, (b) N = 100, (c) N = 1000. The vertical scale is diﬀerent in each of the graphs. where C is a constant that depends only on N (and not on E), and can be calculated, for instance, from the normalization requirement, accordingto which the integral of Γ(E) over all values of E should be 2N . Exercise 3.8 Prove (2.3.14), and calculate the normalization constant. Solution on page 200 Finally, it is worth mentioningthat S of Eq. (2.3.13) can be expressed in terms of P (±1), from Eqs. (2.3.7) and (2.3.8), and has the form S = −Nk[P (+1) ln P (+1) + P (−1) ln P (−1)] . (2.3.15) Chapter 4 Isolated Paramagnet — Subsystems and Temperature 4.1 Microscopic states and thermodynamic equilibrium So far only one new concept has been introduced beyond the dynamics of the system, which is the probability within a set of states, or an ensem- ble. It is time to try and connect this new concept with thermodynamic quantities. The ﬁrst amongthese is the temperature. We turn therefore to the identiﬁcation of the relative temperature of two systems. Obviously, in order to discuss temperature we need at least two sys- tems, since the temperature is precisely the intensive variable, whose equality characterizes the equilibrium between them when there is no mechanical interaction. We choose, therefore, two paramagnetic systems: System a with Na spins and a magnetic ﬁeld Ha, System b with Nb spins and a magnetic ﬁeld Hb. We isolate both systems from the rest of the universe, but allow them to interact thermally. This means that the total energy of the two systems, E, will be constant but the energies of the two systems Ea and Eb are unconstrained provided Ea +Eb = E. No forces will act between the spins, except for the tiny forces we mentioned earlier which drive the system towards thermal equilibrium — namely, to uniform occurrence rates of all microscopic states of the combined isolated system, as explained in Chap. 3. The energy of a given state of system a is Ea = −µBHa Na∑ i=1 σi (2.4.1) and that of system b is Eb = E − Ea . (2.4.2) 156 4.2 β and the temperature 157 If the number of states of system a with energy Ea is Γ(Ea), then system b has Γ(E − Ea) states, and the total number of states of the composite system, for which system a has energy Ea,is ΓT =Γ(Ea,Ha,Na) · Γ(Eb,Hb,Nb) =Γ(Ea,Ha,Na) · Γ(E − Ea,Hb,Nb) , (2.4.3) where we have emphasized the dependence of both factors on the number of spins of the subsystems and on the magnetic ﬁeld of each of them. The rest of the argument has the following structure: When the numbers Na and Nb are very large, there exists a value of Ea, which we denote by ¯Ea,for which ΓT is maximal. Moreover, the maximum is extremely sharp, and the number of states in which Ea diﬀers from ¯Ea is, relatively, very small. This will be the equilibrium state, because if the combined system “visits” all the states with total energy E at the same frequency, it will almost always be in a state for which Ea = ¯Ea.In this case we can identify the intensive quantity that becomes equal in the two subsystems. This quantity will be called the temperature. In order to proceed, we write (2.4.3) in the form ΓT =exp ( S(Ea,Ha,Na)+ S(E − Ea,Hb,Nb) k ) , (2.4.4) where for each system we have deﬁned separately S/k =ln Γ. The number of states attains its maximum at ¯Ea, which may be deter- mined by the requirement that the derivative of the exponent with respect to Ea should vanish, or 1 k ∂S(Ea,Ha,Na) ∂Ea ∣ ∣ ∣ ∣ ¯Ea = 1 k ∂S(Eb,Hb,Nb) ∂Eb ∣ ∣ ∣ ∣ ¯Eb ≡ β, (2.4.5a) where Eb is not an independent variable but satisﬁes Eb = E − Ea and ¯Eb = E − ¯Ea. β has the dimensions of energy to the power of −1. Since Γ is a monotonic function of S,if S has a maximum Γ is maximal as well. In conclusion, we found an intensive quantity which characterizes the maximum of ΓT and has the same value in the two subsystems. We called this quantity β. Second, if we also ﬁnd that almost all the states of the composite system satisfy Ea = ¯Ea, then this will be the system’s thermal equilibrium state. 4.2 β and the temperature Before we proceed to prove the sharpness of the maximum, let us iden- tify the quantity β in our model of a paramagnet. β came about from 158 Ch. 4 Isolated Paramagnet — Subsystems and Temperature equilibrium considerations between two systems a and b, but it is possi- ble to deﬁne it in general for a single paramagnetic system with a given energy E: β = 1 k ∂S(E, H, N ) ∂E . (2.4.5b) The “entropy” S of an isolated paramagnet is given by Eq. (2.3.13) and by diﬀerentiatingit we obtain β = 1 2µBH ln [( 1 2 − E/N 2µBH )∕( 1 2 + E/N 2µBH )] . (2.4.6) Recallingthe expressions (2.3.7) and (2.3.8), for the probabilities for a spin to point up or down, we can write 2µBHβ =ln [ P (σ =+1) P (σ = −1) ] , (2.4.7) from which we obtain the interestingresult P (+1) P (−1) = e 2µBHβ . (2.4.8) Exercise 4.1 Use Eq. (2.4.8) to calculate P (+1) and P (−1). Compare to (2.3.7) and (2.3.8). Solution on page 201 Namely, if we knew that β =1/kT , then (2.4.8) would be the expres- sion for the Boltzmann distribution, as in Part I. That is, the ratio of the probabilities of the two states is e−∆E/kT ,where ∆E is their energy diﬀerence. Butat presentwe cannotconclude that1/β is proportional to an abso- lute temperature, only that it is an increasingfunction of the relative tem- perature — since even after demonstratingthe sharpness of the maximum, we will only know that β is identical for systems at thermal equilibrium with each other. In order to identify β as deﬁned by Eq. (2.4.5) as an ab- solute temperature, we have to show that it connects the entropy change with the heat increase, or that it may be identiﬁed from the ideal gas law. However, we may note that if S is indeed the entropy, then (2.4.5b) is the connection between the entropy and the absolute temperature. 4.3 Sharpness of the maximum In order to ﬁnd the behavior of the number of states of the combined system as a function of Ea, near its maximum, we will use the expression 4.3 Sharpness of the maximum 159 for Γ(E)when N ≫ 1, i.e. Eq. (2.3.14). Insertingit into Eq. (2.4.3) and takingfor simplicity Ha = Hb = H,we obtain ΓT = CaCb exp ( − E2 a 2Naµ2 BH 2 ) exp [ − (E − Ea)2 2Nbµ2 BH 2 ] , (2.4.9) where Ca and Cb are normalization constants that depend on Na and Nb. In terms of the “entropy” we obtain 1 k ST = 1 k (Sa + Sb)=ln ΓT =ln(CaCb) − 1 2(µBH)2 [ E2 a Na + (E − Ea)2 Nb ] . (2.4.10) Next we ﬁnd the maximum of the entropy. Since (2.4.10) is a quadratic function of Ea, there is no need to diﬀerentiate with respect to Ea;it is enough to complete the expression in brackets to a square: E2 a Na + (E − Ea)2 Nb = (Na + Nb)E2 a NaNb − 2EEa Nb + E2 Nb = Na + Nb NaNb (Ea − NaE Na + Nb )2 + E2 Na + Nb , (2.4.11) so that 1 k ST =ln(CaCb) − 1 2(µBH)2 [ Na + Nb NaNb ( Ea − NaE Na + Nb )2 + E2 Na + Nb ] . (2.4.12) This is a quadratic function of Ea whose maximum is attained at ¯Ea = NaE Na + Nb . (2.4.13) As will immediately be shown, ΓT has a sharp maximum at this energy, so that this will also be the average of Ea. We see, therefore, that the energy is distributed between the two systems in direct proportionality to their size. In order to show that the overwhelmingmajority of states are concentrated around Ea = ¯Ea,we return toΓT , and rewrite it using (2.4.12) in the form ΓT (Ea)= CT exp [ − Na + Nb 2(µBH)2NaNb (Ea − ¯Ea) 2] , (2.4.14) where the constant CT includes all the factors which do not depend on Ea. 160 Ch. 4 Isolated Paramagnet — Subsystems and Temperature Equation (2.4.14) describes a Gaussian distribution whose width (stan- dard deviation), ∆Ea,is µBH√ NaNb/(Na + Nb). If both systems are macroscopic, Na and Nb will both be of order N (= Na + Nb), and the width of the distribution will be of order µBHN 1/2. Apparently, this is not the result we anticipated, since instead of decreasingwith N the width of the distribution increases with N . However, we must remember that what is relevant is the relative width of the distribution, which is ∆Ea/ ¯Ea. since ¯Ea is proportional to N , the relative width tends to zero as N −1/2: ∆Ea ¯Ea ∼ N −1/2 −−−→ N →∞ 0 , (2.4.15) which means that in the thermodynamic limit the states of the combined system for which Ea = ¯Ea exhaust the states of the isolated system. Hence, Ea = ¯Ea describes thermal equilibrium between the two systems. It is possible to understand the state of thermodynamic equilibrium between two systems from a slightly diﬀerent perspective on Eq. (2.4.14). Since in the thermodynamic limit Ea diverges, it is more natural to con- sider the distribution of the quantity Ea/Na, which is the energy per degree of freedom. To this end we need only rewrite Eq. (2.4.14) in the slightly diﬀerent form ΓT = CT exp  − ( Ea Na − ¯Ea Na )2 · Na/Nb 2(µBH)2 N   . (2.4.16) And it is immediately clear that the width of this (Gaussian) distribution of Ea/Na behaves as N −1/2 and vanishes in the thermodynamic limit. Exercise 4.2 Verify that (2.4.14) actually implies (2.4.15). Solution on page 202 Returningto (2.4.10), we ﬁnd that at thermal equilibrium (Ea = ¯Ea) ST = ¯ST = S( ¯Ea)+ S( ¯Eb) . (2.4.17) This means that the “entropy” is extensive: It grows linearly with the size of the system. The distribution of the number of states of the composite system, as a function of Ea/Na, is depicted in Fig. 2.4.1. In the thermodynamic limit the width of the peak tends to zero. An instructive exercise is to sketch ΓT from (2.4.3) with Γ from (2.3.5) for small values of Na and Nb (even 12), and a value of E around 6µBH. 4.4 Identiﬁcation of temperature and entropy 161 Ea/N ➤ – Ea/N ΓT➤ Fig. 2.4.1 The number of states of the combined system (2.4.16). Fig. 2.4.2 The number of states in Eq. (2.4.3) as a function of Ea with E = NaµBH/2 for (a) Na = Nb = 12, (b) Na = Nb = 100. Notice that we have not made use of the approximation (2.4.14). The calculation of Γ can be performed by a direct calculation of the factorials in (2.3.5) or usingthe approximation (2.3.13). The result is depicted in Fig. 2.4.2(a). To demonstrate the behavior of the width of the distribution as a function of N , we give in Fig. 2.4.2(b) a sketch of ΓT for Na = Nb = 100 and E =50 µBH. 4.4 Identiﬁcation of temperature and entropy After ﬁndingthat the equality of β is the condition for thermodynamic equilibrium, we return to discuss an isolated paramagnet and to identify β. To this end we note that S, as given in Eq. (2.3.13), is a function of M (M = −E/H)alone. Namely, S = − 1 2 k[(N + M/µB)ln(1 + M/NµB) +(N − M/µB)ln(1 − M/NµB) − 2N ln 2] . (2.4.18) 162 Ch. 4 Isolated Paramagnet — Subsystems and Temperature Hence changing the magnetization of the system will lead to a change in the “entropy” given by dS = ∂S ∂M dM = − k 2µB ln ( 1+ M/N µB 1 − M/N µB ) dM . (2.4.19) Using(2.4.6) with M = −E/H we obtain dS = −kβHdM . (2.4.20) We compare this expression with the expression for the entropy, as it appears in thermodynamics. From Eq. (2.1.10) we can obtain the entropy change due to a change of M or E∗. But the paramagnet is a special system for which E = −MH,sothat E∗ = 0, and the entropy cannot depend on E∗.Thus we obtain from (2.1.10) dS = − H T dM . (2.4.21) This meansthatifweidentify β as kβ = 1 T , (2.4.22) we obtain a full correspondence between the statistical mechanics of a paramagnet and its thermodynamics. T , which appears on the right hand side of (2.4.22), is of course the absolute temperature. And if k is the Boltzmann constant, then the unit of temperature is identical in the two scales. The identiﬁcation (2.4.22) also states that S, which thus far has been referred to as “entropy,” is really the entropy, since if we insert (2.4.22) into (2.4.20) we immediately obtain (2.4.21). Now, after havingidentiﬁed the meaning of β and S, wecan usethe equations we derived not only for a paramagnet at a given energy (iso- lated) but also for other situations, such as when the system is at a given temperature. This we do in the followingexercise. Exercise 4.3 (a) Show that for a paramagnet at a given temperature, the average value of the spin’s projection alongthe ﬁeld is ⟨σ⟩ =tanh(βµBH) . (2.4.23) What is the average magnetic moment M of the whole system? Sketch the average moment as a function of H. (b) Repeat the calculation of the magnetization M (β, H) usingEq. (2.4.6). 4.5 Negative temperature 163 (c) Repeat the calculation of the magnetization using Eq. (2.4.21) and the explicit expression for S(M ) (2.4.18). (d) Show that for a paramagnet at a given temperature, the average en- ergy is given by E = −NµBH tanh(βµBH) . (2.4.24) Solution on page 203 4.5 Negative temperature It is worth notingthat the deﬁnition of the inverse temperature 1/kT via the energy derivative of the entropy, Eq. (2.4.5), gives the paramagnet a range of energies with negative temperatures (see Fig. 2.4.3). This is the range E> 0, where the entropy decreases with increasingenergy. At E =0, where the slope of S as a function of E vanishes, the temperature is inﬁnite. Systems with negative temperatures are warmer than the systems with positive temperature: if two systems are brought together, one with negative temperature and the other with positive temperature, heat will ﬂow from the ﬁrst to the second. This phenomenon is typical of systems whose energy spectrum is bounded from above. Here we will not enter into more detail. We mention only that in realistic systems there are also kinetic energies, which we did not account for, thus having an energy spectrum that is not bounded from above. In fact, it is impossible for a state of real thermodynamic equilibrium to exist at negative temperatures.➤ T ➤ S T E Fig. 2.4.3 The entropy and temperature of a paramagnet vs energy. Since 1/T = ∂S/∂E, T> 0for increasing S,“T = ∞” for maximal S,and T< 0 for decreasing S. 164 Ch. 4 Isolated Paramagnet — Subsystems and Temperature 4.6 Summary The discussion of the paramagnet suggests that in the framework of the microcanonical ensemble, in which each microscopic state of the isolated system has the same probability, it is possible to deﬁne entropy and tem- perature. The entropy is given by the Boltzmann formula: S(E)= k ln Γ(E) , (2.4.25) where Γ(E) is the number of states with energy E. The absolute temperature is determined by studyingthe equilibrium of subsystems and is deﬁned as β = 1 kT = 1 k ∂S ∂E , (2.4.26) where on the right hand side the external parameters are constant. Given β, the probability for a single spin to have projection σ along the magnetic ﬁeld is, according to (2.4.8) and Exercise 4.1, P (σ)= Ce βµBHσ = Ce −βϵ(σ) , (2.4.27) where ϵ(σ) is the energy per spin with projection σ and C is the normal- ization constant of the probability. Chapter 5 Paramagnet at a Given Temperature 5.1 The canonical ensemble A system is kept at a ﬁxed temperature when it is in thermal equilibrium with a much larger system, referred to as a heat bath. Clearly, the en- ergy of the system under discussion is not constant, since the system is in thermal contact with the heat bath, so that it may exchange energy with it. We thus have to determine probabilities for states with diﬀerent ener- gies. In the Introduction (to Part II) we proposed that in such a case, the recurrence of systems in the ensemble, describingthe smaller system, will be proportional to the Boltzmann factor e−E/kT ,where E is the energy of the small system. The Boltzmannian proposal is not arbitrary. First, the kinetic theory hinted in this direction; second, studyingEq. (2.4.8) or (2.4.27) in the precedingchapter we ﬁnd that in the isolated paramagnetic system, the single spin satisﬁes the Boltzmann distribution in a state of equilibrium. We pick from the isolated system a subsystem a of spins whose number n is very small compared to the total number of spins N (n ≪ N but still n ≫ 1; for example, N =1023,n =1020) — so that we may consider the rest as a heat bath. The probability for these spins to have values σ1,... ,σn will be the product of the probabilities for the single spins. Since as longas n ≫ 1 there are no correlations, as we have learned in Sec. 3.2 (the artiﬁcial correlations, which enter owingto the constraint of a constant energy, vanish when n is very large). Hence P (σ1,... ,σn)= C exp ( βµBH n∑ i=1 σi ) = Ce −β(ϵ1+...+ϵn) . (2.5.1a) But E = n∑ i=1 ϵi (2.5.1b) is the energy of a microscopic state with n spins — the microscopic state, given by (σ1,... ,σn). 165 166 Ch. 5 Paramagnet at a Given Temperature We have seen therefore that the probability that in thermodynamic equilibrium our n-spin system will be found in a speciﬁc state (σ1,... ,σn) is indeed proportional to e−E/kT ,where E is the total energy in this state. Notice that there may exist many states with the same value of E and hence also the same probability. As we will see later on, we will have to take all of them into account. Exercise 5.1 Show that the constant C in (2.5.1a) is given by C −1 = ∑ σ1=±1 ... ∑ σn=±1 e −βE(σ1,...,σn) . (2.5.2) Solution on page 204 In other words, the Boltzmann distribution correspondingto the canonical ensemble, describingthe system at a given temperature, is de-canonical ensemble rived from the ﬁrst ensemble we discussed — the microcanonical ensemble, describingan isolated system. It is true that here we have only shown this for the special case of a paramagnet, but the assertion holds quite generally. The derivation of the canonical distribution, from the microcanonical one, in the general case is not more complicated: The number of states of the isolated system in which the subsystem a is in a speciﬁc microscopic state with energy Ea, is given by the second exponential in Eq. (2.4.4) (considered as a product) with Ha = Hb. The ﬁrst one counts the number of states of the subsystem with energy Ea.Since Ea ≪ E, the second term in the exponent can be expanded to ﬁrst order in Ea, giving ΓT =exp ( S(E, H, N ) k ) exp(−βEa)= Ce −βEa , (2.5.3) where use has been made of (2.4.5). The fact that the two ensembles are equivalent is of double importance. First, the temperature is a much more natural variable than the energy. Second, calculations with constant energy are several times more com- plicated than those at constant temperature. It implies that the results we obtain for the thermodynamic functions from each of the ensembles will be identical. The diﬀerence is that each of the ensembles will give the state functions in terms of diﬀerent controllable quantities, so that we will have to “translate” from one language to the other. For instance, in the case of the paramagnet, the microcanonical ensemble is described by E, N, H as controlled variables, while the canonical ensemble is described by T, N, H. We re-emphasize the diﬀerences and the similarities between the two types of ensembles from a microscopic standpoint: 5.2 The partition function and thermodynamic quantities 167 In a microcanonical ensemble all states have the same energy. All of these states are assigned the same probability. In a canonical ensemble the system may exchange energy with its surroundings, but it is in ther- mal equilibrium with a heat bath, so that it has a well-deﬁned average energy. The magnitude of the heat exchanged with the heat bath is small compared to the average energy. In the canonical ensemble the system is assigned a temperature, and every state can appear in it. However, the probability of a state is pro- portional to e−E/kT , if the energy of the state is E. The canonical ensemble is related to the microcanonical ensemble in that a large system can be subdivided into a relatively small system and a heat bath. The system as a whole is isolated and is described by a mi- crocanonical ensemble; however, the subsystem does not have a constant energy. The distribution of subsystems must be derived from the assump- tions of equilibrium and the equality of the probabilities of all states of the large isolated systems (subsystem + heat bath) having the same energy. And, indeed, the result is the Boltzmann result as formulated above. 5.2 The partition function and thermodynamic quantities We pass on, therefore, to the calculation of the properties of the param- agnet, whose temperature is 1/kβ = T . To this end we ﬁrst deﬁne an partition functionall-important concept, which is the partition function: Z = ∑ all microscopic states e −βE (microscopic state) . (2.5.4) The common notation for the partition function, Z, originates from its German name Zustandsumme, meaning “sum over states.” Actually, we have already seen the partition function as the normal- ization factor 1/C in Eqs. (2.5.2) and (2.5.3). This function, known in probability theory as the “generating function,” is very useful in the cal- culation of averages. The idea is that we can replace the computation of the average of many observables by the computation of derivatives of Z with respect to the appropriate controlled variables. For instance, the average energy at temperature T is an ordinary av- erage [Eq. (2.2.12)] with probabilities P = Z−1e −βE . (2.5.5) Namely, ⟨E⟩ = Z−1 ∑ {σ} E(σ1,... ,σn)e −βE(σ1,...,σn) , (2.5.6) where the summation is over all possible states (σ1,... ,σn). 168 Ch. 5 Paramagnet at a Given Temperature A brief study of Eq. (2.5.6) reveals that the sum appearingin it can be written as −∂Z/∂β.Thus ⟨E⟩ = − 1 Z ∂Z ∂β = − ∂ ln Z ∂β . (2.5.7) Note the similarity to the method of calculating averages which was presented in Sec. 1.6. In a similar manner it is possible to write the average magnetization in the form ⟨M ⟩ = 1 β ∂ ln Z ∂H . (2.5.8) Exercise 5.2 Prove Eq. (2.5.8). Solution on page 204 Exercise 5.3 Show that if Z is a function of βH only, then we can immediately deduce that ⟨E⟩ = −H⟨M ⟩ from Eqs. (2.5.7) and (2.5.8). Solution on page 205 For the paramagnetic system it is possible to directly evaluate Z,since in this case each term of the sum in (2.5.4) is a product, makingit possible to write Z as Z(β, H)= ∑ σ1,σ2,...,σn e −βϵ1(σ1) · e −βϵ2(σ2) · ... · e −βϵn(σn) . (2.5.9) Now, it is possible to sum over each of the variables (σ1,... ,σn) indepen- dently, and to write the sum of products as a product of sums: Z(β, H)=   ∑ σ1=±1 e −βϵ1   ...   ∑ σn=±1 e −βϵn   . (2.5.10) It is easy to see that every term of the product we wrote appears in (2.5.9), and every term of (2.5.9) appears in (2.5.10). For example, for n = 2 Eq. (2.5.9) takes the form Z = e−βϵ1(−1)e−βϵ2(−1) + e−βϵ1(−1)e−βϵ2(+1) +e−βϵ1(+1)e−βϵ2(−1) + e−βϵ1(+1)e−βϵ2(+1) , while [Eq. (2.5.10)] Z = ( e−βϵ1(−1) + e−βϵ1(+1))( e−βϵ2(−1) + e−βϵ2(+1)) , which is exactly equivalent. 5.2 The partition function and thermodynamic quantities 169 All the terms in the product (2.5.10) are identical, and equal to z(β, H)= e −βµBH + e βµBH =2 cosh(βµBH) . (2.5.11) Hence Z(β, H)= [z(β, H)] n . (2.5.12) It is possible to think of z as the partition function of a single spin. Substituting(2.5.12) into (2.5.7), we obtain ⟨E⟩ = −n ∂ ln z ∂β = −nµBH tanh(βµBH) . (2.5.13) This expression is identical to (2.4.24). Obviously the magnetization, obtained from substituting (2.5.12) in (2.5.8), is ⟨M ⟩ = nµB tanh(βµBH) , (2.5.14) as was already obtained in Exercise 4.3. It is of course possible to use the relationship ⟨E⟩ = −H⟨M ⟩ . As a ﬁnal note in this section the reader is warned, if he has not noticed it himself already, of the notational ambiguity, characteristic of statistical mechanics, expressed by the fact that no special notation is used to distinguish between the thermodynamic random variables and their averages. For example, one meets Eqs. (2.5.7) and (2.5.8) repeatedly in the literature (in this text as well!) in the form E = − ∂ ln Z ∂β ,M = 1 β ∂ ln Z ∂H , and so on. The reason for this is of course that due to the huge number of degrees of freedom, in a thermodynamic system, each observable takes its average value with negligible relative deviations. Moreover, there is no room for such a distinction within thermodynamics since the concept of probability does not enter its framework at all. This fact requires the reader to be alert and to notice always, especially in the calculation of averages and probabilities, which are the quantities that have already been averaged and which have not. The reader will be warned where necessary. 170 Ch. 5 Paramagnet at a Given Temperature 5.3 Susceptibility and speciﬁc heat of a paramagnet The behavior of the average energy and of the magnetization, as a function of the external variables H and β, is determined by the behavior of ⟨σ⟩. In order to study it, it is convenient to deﬁne the dimensionless variable, x = βµBH. Now, we can draw ⟨σ⟩ as a function of x,as depicted in Fig. 2.5.1. x ➤ 1➤<σ> –1 Fig. 2.5.1 ⟨σ⟩ as a function of x = βµBH. This graph may be interpreted in two ways: (a) As the description of the average projection of the spin along the direction of the ﬁeld as a function of H, at a constant temperature. We see that at zero ﬁeld (x = 0) there is no preferred direction, and the average projection is zero. It starts to grow linearly with H (see below) and ﬁnally, at a very large ﬁeld, the average of the projection attains the full value of the spin, ⟨σ⟩→ 1, namely the polarization saturates. The region x< 0 describes the case in which the direction of H is reversed, so that at saturation the direction of the magnetization will also reverse, ⟨σ⟩→ −1. (b) As the description of the behavior of the average spin projection at a decreasingtemperature, when the external ﬁeld is held constant. At very high temperatures, x = βµBH → 0 , there is no diﬀerence between the probability for the spin to have a projection alongthe ﬁeld and the probability for its projection opposite to the ﬁeld. Hence ⟨σ⟩ tends to 0. When H is constant and T → 0, the thermal energy ﬁnds it hard to ﬂip spins, and again the average spin projection tends to 5.3 Susceptibility and speciﬁc heat of a paramagnet 171 saturate the spin, alongthe ﬁeld. More and more spins “freeze” alongthe direction of the ﬁeld. Low and high temperatures are deﬁned relative to the characteristic temperature Θ = µBH/k. At very high temperatures the energy of a single moment, µBH, is negligible compared to the thermal energy kT . At very low temperatures the reverse is true. As mentioned above, at low ﬁelds the magnetization grows linearly with the ﬁeld. This property is the main characteristic of the paramagnet. The coeﬃcient of H is called the magnetic susceptibility and it measures susceptibility the size of the magnetic response of the system to changes in the external magnetic ﬁeld. If we write ⟨M ⟩≃ nχH , (2.5.15) then χ is the magnetic susceptibility per spin. Its value is obtained from (2.5.14) with the help of the fact that tanh x ≃ x for small x. The result is χ = µ2 B kT . (2.5.16) The existence of an inverse relationship between the susceptibility and the temperature was found experimentally by P. Curie in 1895, and has since been referred to as the Curie law. From (2.5.16) we learn that as the temperature decreases the system magnetizes more easily — the slope at the origin, in Fig. 2.5.1, grows. As to the correspondence of this result with experiments, we will return to discuss this point in Chap. 7. Finally, we calculate the speciﬁc heat per degree of freedom at a con- stant ﬁeld. Since at a constant ﬁeld δQ = δE [see Eq. (2.1.7)], clearly speciﬁc heat cH = 1 n ( ∂E ∂T ) H . (2.5.17) Exercise 5.4 Prove that cH = µ2 BH 2 kT 2 cosh2(βµBH) . (2.5.18) Solution on page 205 In the speciﬁc heat the characteristic temperature of the paramagnet appears in the most dramatic manner. cH is drawn as a function of 1/x = kT /µBH in Fig. 2.5.2. The speciﬁc heat attains its maximum at kT ≃ 0.8 µBH. (2.5.19) 172 Ch. 5 Paramagnet at a Given Temperature cH/k kT/µBH ➤➤ 0.4 0.1 0.2 0.3 0.4 0.8 1.2 1.6 2.0 3.0 Fig. 2.5.2 The speciﬁc heat (2.5.18). The general appearance of the graph could have been guessed in advance. At low temperatures (kT ≪ µBH), changing the temperature does not change the energy, since each spin has thermal energy of order kT but requires energy (which it lacks) of order µBH to reverse its direction. Stated diﬀerently, the system is saturated and the energy is minimal. At high temperatures (kT ≫ µBH), disorder is total and cannot be increased by raisingthe temperature. Thus cH → 0when T → 0and when T →∞. Since there are in this problem only two characteristic energies, µBH and kT , clearly everythingthat happens depends on their ratio, y ≡ kT /µBH; otherwise, changing the units would aﬀect the behavior of the system. The two limits that we studied are y → 0and y →∞. Thus, somewhere between them we expect to attain a maximum, since cH (y) is nonnegative, and must therefore grow near y = 0 and decrease towards y →∞.The location of the maximum would be around y =1, as both the thermal energy and the magnetic energy are signiﬁcant in this region. Exercise 5.5 Sketch the magnetization per spin at a constant ﬁeld as a function of temperature. Solution on page 206 Exercise 5.6 (a) Calculate the entropy of the paramagnet as a function of T and H. (b) Sketch the entropy per spin at a constant ﬁeld as a function of temperature. (c) Sketch the entropy per spin at a constant temperature as a function of the ﬁeld (sketch in one drawingtwo graphs whose temperatures have a ratio of 5). Solution on page 206 5.4 Paramagnet with J> 1/2 173 5.4 Paramagnet with J > 1/2 The results we have obtained in this chapter can easily be generalized to the case in which the spin is not 1 2 . Such a spin would have more than two states. If the magnitude of the spin is J,then there are 2J + 1 possible values for the projection of the spin alongthe direction of the ﬁeld, taking the values from −J to +J in unit steps. Since the ion acquires in a magnetic ﬁeld an additional energy given by Eq. (2.2.6), the energy of ion number i in a magnetic ﬁeld H will be given by a generalization of (2.2.8): ϵi = − 1 2 gµBHσi , (2.5.20) where σi = −2J, −2(J − 1),... , 2J. (2.5.21) The number of microscopic states of a system of N spins is not 2N any more but (2J +1)N . The properties of a paramagnet with general J will be revealed by solvingthe following exercise. Exercise 5.7 (a) Calculate the partition function (2.5.4) for a paramagnet with gene- ral J. (b) Calculate the average magnetization per spin, and sketch it as a func- tion of H. (c) Calculate the susceptibility and compare it with that we calculated for J = 1 2 . (d) Calculate the speciﬁc heat cH, and compare it with the result for J = 1 2 . Solution on page 207 Chapter 6 Order, Disorder and Entropy It is commonly said that the magnitude of the entropy measures the dis- order in a system, and that the tendency of the entropy to increase is the same as the tendency for increasingdisorder. These concepts and relationships take on a more deﬁnite and quantitative character within information theory, which is related in this way to thermodynamics. Here we exemplify only a few of these concepts in connection with the sim- ple paramagnetic model, without giving detailed deﬁnitions and without enteringinto a formal discussion. If the system is ordered, one glance at the system is enough to de- termine its state. There are not many states to confuse us. Thus, for example, if a small collection of cubes is ordered into a large cube, it is easy to discern the state of the system. A very small number of parameters will describe it, there are very few states similar to the or- dered one. Conversely, if the cubes are scattered, the number of states which create a similar impression is huge, and the system appears to be disordered. The same applies to our spins. Here each state of the system corre- sponds to a certain orderingof the spins, some of which are along the ﬁeld while others are in the opposite direction. If all are pointingalong the ﬁeld (E = −NµBH), or in the opposite direction (E =+NµBH), we will naturally say that the system is in an ordered state. Notice that there is only one state (corresponding to a single ordering) with each of the energies we mentioned. Thus for these energies Γ(E = −NµBH)= Γ(E = NµBH) = 1 (2.6.1) and the entropy for these energy values vanishes [see (2.3.13) or (2.4.18)]. If we know that the system has energy −(N − 2)µBH, then obviously one spin is pointingin a direction opposite to the ﬁeld. If this fact is all that is known about the system (this is the information we obtained in our glance), the system can be in one of N diﬀerent states, in each of 174 Order, disorder and entropy 175 which a diﬀerent spin is the exception. Namely, Γ[E = −(N − 2)µBH]= N (2.6.2a) and the correspondingentropy is S[E = −(N − 2)µBH]= k ln N. (2.6.2b) All these states are equally probable, and the fact that the same amount of information, namely the knowledge of E, is much less informative about the state of the system, indicates the increase in disorder. We recall a few expressions for the entropy, for example (2.3.13): S k = − ( N 2 − E 2µBH ) ln ( 1 2 − E/N 2µBH ) − ( N 2 + E 2µBH ) ln ( 1 2 + E/N 2µBH ) . (2.6.3) This is the expression which was depicted in Fig. 2.3.2. It has a maximum at E =0, where S(E =0) = kN ln 2 . (2.6.4) Since the number of states is maximal, we cannot say anythingabout the system if only the energy E = 0 is given. Disorder dominates. As we have already seen in the solutions of Exercises 3.7 and 3.8, the number of states with E = 0 is not given simply by eS/k =2N but by Γ(E =0) = 2N √ 2πN . (2.6.5) A diﬀerent expression for the entropy, which we have seen earlier, is (2.3.15), is given in terms of single spin probabilities: S = −Nk[P (+1) ln P (+1) + P (−1) ln P (−1)] . (2.6.6) Exercise 6.1 What assumptions will transfer us from (2.6.6) to (2.6.4)? Solution on page 211 We will try to view this expression as a particular case of a situation in which there are m states, which we will denote by α, α =1,... ,m, whose probabilities are Pα,and S is given by S = −k m∑ α=1 Pα ln Pα . (2.6.7) 176 Ch. 6 Order, disorder and entropy Note that S = −k⟨ln P ⟩. Alongwith (2.6.7) there exists of course the relationship m∑ α=1 Pα =1 . (2.6.8) Without enteringinto detailed proofs, which are a mathematical exercise of interest in itself, we note that: (a) S has a minimum if the system is in a state — say, α =1 — and hence P1 =1 and Pα =0 forall α ̸=1. In this casewe infer from (2.6.7) that S = 0. We can again identify this probability distribution with order, since amongthe m states only one is possible, with the information at hand. (b) S has a maximum if Pα =1/m for all α,and then S = k ln m. (2.6.9) In this condition we are unable to distinguish between the diﬀer- ent possibilities: disorder dominates. For example, a paramagnet of N spins can be in one of m = 2N possible states. If we denote them accordingto ascending order in energy, then α = 1 will be the unique state for which E = −NµBH and α =2N will be the unique state for which E =+NµBH. Thus, for example, if it is known that E = −NµBH, then clearly P1 =1, and all other Pα vanish. If it is known that E = 0, we ﬁnd from (2.6.5) that the number of states is 2N / √2πN , and the probability for each state is √ 2πN /2N . Hence a substitution in (2.6.7) or (2.6.9) will give again, in the limit N →∞, the already familiar result S(E =0) = kN ln 2, which describes maximal disorder. Finally, note that Eq. (2.6.7) implies that for the canonical ensemble S = k(ln Z + β⟨E⟩) . (2.6.10) Exercise 6.2 Prove Eq. (2.6.10). Solution on page 211 Chapter 7 Comparison with Experiment The magnetization of several paramagnetic ionic salts has been measured, from very small ﬁelds up to saturation. Figure 2.7.1 describes the exper- imental results for the ions of chromium, iron and gadolinium which are all triply ionized, composed in salts, whose other components are non- magnetic. The correspondence between theory and experiment is very impressive. This includes the fact that measurements performed at diﬀer- ent temperatures, for the same salt, when plotted as a function of H/T , fall on the same curve. Let us consider some characteristics of the results. The ﬁrst is the saturation value of the magnetization which diﬀers from ion to ion. The reason for this is, of course, the dependence of the magnetization upon the spin, which was obtained in Exercise 5.7(b). At saturation (H/T →∞) we ﬁnd that ⟨M ⟩/N → gµBJ, (2.7.1) so that there is a linear relationship between the magnetization at sat- uration and the spin. Thus, had we not known the value of J by other means, we could have determined it from these experiments. The second characteristic of the results is the diﬀerent slopes of the graphs at the origin, i.e. for H → 0. The relevant feature is the depen- dence of the susceptibility — described by the slope of the graph at the origin — on the spin, a dependence which was studied in Exercise 5.7(c). It reads χ =(gµB) 2 J(J +1) 3kT . (2.7.2) Actually, we could have used these two equations to ﬁnd in addition to J the value of g, which is equal in all three ions to 2. In parenthesis we note that the reason for this is that their atomic structure is such that only the spin, and not the orbital angular momentum, contributes to the total angular momentum J [see Eq. (2.2.5)]. 177 178 Ch. 7 Comparison with Experiment M/NµB 0 1.00 2.00 3.00 4.00 5.00 6.00 7.00 0 J=7/2 (Gd3+) III J=5/2 (Fe3+) II J=3/2 (Cr3+) I 1.30K 2.00K 3.00K 4.21K H/T (10–3 Gauss/K) 10 20 30 40 ➤ Fig. 2.7.1 Graphs of the average magnetization per ion in units of µB as a function of H/T . The measurements were made at diﬀerent temperatures, as noted in the ﬁgure. In all the cases g = 2. Taken from W. E. Henry, Phys. Rev. 88, 561 (1952). The speciﬁc heat with the interestingstructure (2.5.18) is very hard to measure experimentally, because it requires separatingthe magnetic eﬀect from the numerous extra contributions originating from the lattice vibra- tions, the nonmagnetic electrons, and the like, which obscure the picture. Summary We have treated the special case of a paramagnet having N degrees of free- dom (spins of ions), which can take two values (the projections alongthe direction of the magnetic ﬁeld), or a larger, but ﬁnite, number of values. We have used it to exemplify the microcanonical ensemble, represent- ingan isolated system — a system with strictly constant energy. In such an ensemble, all states have equal probability: equal to the inverse of the total number of states with the same energy. In order to deﬁne the temperature of a system, we must think of it as part of a larger isolated system. The isolated system is then composed of two systems, both of which are macroscopic; one of them is much larger Summary 179 than the other. The two subsystems — of which the larger one is a heat bath — exchange energy until they reach equilibrium. Equilibrium is attained when the total energy is distributed between them in such a way that the number of states is maximized. At the maximum, the energy derivative of the entropy in the system and in the heat bath are equal. This common value is found to be β = 1/kT , from the relation between the quantity of heat and the entropy. The states of the small system are not restricted by conservation of energy. Instead, at a given temperature, the probabilities of its states are proportional to the Boltzmann factor e−E/kT . This is the canonical ensemble. All this has a nice experimental veriﬁcation shown in Fig. 2.7.1. Self-assessment exercises Exercise 1 Solution on page 213 The number of states of the system composed of subsystems a and b in Eq. (2.4.3), ΓT , has a maximum at Ea = ¯Ea.Calculate ¯Ea and ¯Eb for the special case in which Ha = Hb. Exercise 2 Solution on page 213 (a) Prove that the speciﬁc heat at constant ﬁeld (2.5.18) may also be calculated from cH = T n ( ∂S ∂T ) H . (b) Describe the similarities and diﬀerences between the paramagnet and the ideal gas. Exercise 3 Solution on page 214 It is possible to describe the behavior of certain materials in nature by spins with magnetic moment m which can point in three possible direc- tions, all in one plane, as depicted in the ﬁgure below. (a) Calculate the energy of a single spin, in each of the above states, in the presence of an external magnetic ﬁeld H = H ˆx. 180 Self-assessment exercises 181 (b) A paramagnet whose constituents are spins of the type described above is at temperature T . There is no interaction between the spins. Find its partition function when an external magnetic ﬁeld is applied along x. (c) Find the average magnetization per spin in the paramagnet described in (b). Calculate the value of the magnetization using two methods: (1) As a canonical weighted average of the moment of a single spin. (2) By direct calculation from the partition function. (d) Calculate the magnetic susceptibility per spin of the paramagnet. Does the Curie law apply (namely, χ ∝ 1/T )? (e) Calculate the average energy (per spin) of this paramagnet. (f) Calculate its speciﬁc heat. Exercise 4 Solution on page 217 Repeat the solution of Exercise 3 for a material for which the magnetic moment m has four possible directions as in the ﬁgure below. The ﬁeld is still in the x direction. Exercise 5 Solution on page 219 Calculate the probability for a paramagnet of ions with J = 1 2 at temper- ature T and magnetic ﬁeld H to have energy E. Exercise 6 Solution on page 219 The probability for the drunk in the random walk of Part I to be found at a distance R from his initial location, after N steps, has the same mathematical structure as the probability for a paramagnet of N spins to have magnetization M . (a) Calculate the probability for a drunk who is walkingin one dimension andhavingastepof length L to be found at a distance x from his initial location after N steps. 182 Self-assessment exercises (b) Show that when N ≫ 1 but x L ≪ N , the probability which you calculated in (a) goes over to a Gaussian distribution. Use Stirling’s formula. (c) Calculate the width (standard deviation) of the distribution, ∆x,and its relative width, ∆x/N L. Solutions to exercises in the text Solution 0.1 Exercise on page 126 (a) For an isothermal process we may use Eq. (2.0.5) to compute δQ. In a process with initial volume Vi, ﬁnal volume Vf and (constant) temperature T we obtain QT = ∫ T δQ = ∫ Vf Vi Nk T V dV = NkT ln ( Vf Vi ) , (i) where the subscript on Q denotes the variable kept ﬁxed. (b) In an isochoric (constant V ) process we calculate analogously QV = ∫ V δQ = ∫ Tf Ti f 2 NkdT = f 2 Nk(Tf − Ti) . (ii) (c) In an isobaric (constant P ) process none of the terms in Eq. (2.0.5) vanishes, but the equation of state (2.0.3) provides a relation between the diﬀerentials: PdV = NkdT .So we obtain QP = ∫ P δQ = ∫ Tf Ti ( 1+ f 2 ) NkdT = ( 1+ f 2 ) Nk(Tf − Ti) . (iii) If instead the volume is the integration variable, one obtains the equivalent result QP = ∫ P δQ = ∫ Vf Vi ( 1+ f 2 ) PdV = ( 1+ f 2 ) P (Vf − Vi) . (iv) Solution 0.2 Exercise on page 126 (a) Combiningthe results of the previous solution one ﬁnds that Q = ∮ δQ = Nk [ T2 − T1 − T1 ln ( V2 V1 )] , (i) 183 184 Solutions to exercises in the text where V2 is the volume at the end of the isobaric process. Since there is a linear relation between volume and temperature in an isobaric process, we may write the result (i) in terms of temperatures only: Q = Nk [ T2 − T1 − T1 ln ( T2 T1 )] . (ii) We write Q in Eq. (ii) in the form Q = NkT1 [ T2 T1 − 1 − ln ( T2 T1 )] . (iii) This is an increasingfunction of T2/T1 for T2/T1 ≥ 1(whichone veriﬁes by notingthat its derivative is always positive in this interval) with a minimum Q =0at T2/T1 = 1. Hence Q is positive in this cycle. (b) If the cycle is reversed Q changes sign and becomes negative. (c) If δQ were an exact diﬀerential we would have found Q =0, since the integration over a closed path would then have vanished. Solution 0.3 Exercise on page 126 (a) In the isobaric process we have WP = ∫ P δW = ∫ V2 V1 PdV = P (V2 − V1) . (i) In the isochoric process WV = 0 and in the isothermal step WT = ∫ T δW = ∫ V1 V2 NkT V dV = −NkT1 ln ( V2 V1 ) . (ii) Addingthe three contributions one ﬁnds that W = ∮ δW = P (V2 − V1) − NkT1 ln ( V2 V1 ) . (iii) (b) Usingthe equation of state, Eq. (2.0.3), one notes that this is the same result for Q of Eq. (i) of the previous solution. The reason is that the energy is a function of state and so its integral over any process depends only on the initial and ﬁnal states: ∫ dE = Ef − Ei . Thus, its contribution over a full cycle vanishes and W = Q. Solutions to exercises in the text 185 (c) In an adiabatic processes δQ = 0 and hence δW = −dE = − f 2 NkdT , which is integrated to obtain Wadiabatic = − f 2 Nk(Tf − Ti) . (iv) (d) Substituting δQ = 0 in Eq. (2.0.5) we ﬁnd that VT f/2 =const . (v) Solution 0.4 Exercise on page 127 We express δQ in terms of the variables T and P . Usingthe equation of state (2.0.3) we transform the inﬁnitesimal work to the form PdV = NkdT − VdP . Then, usingthe expression for E, Eq. (2.0.4), we use Eq. (2.0.2) to write δQ = dE + PdV = f 2 NkdT +(NkdT − VdP )= Nk ( 1+ f 2 ) dT − VdP , leadingto Eq. (2.0.9). Solution 0.5 Exercise on page 127 For an adiabatic process we have from Eq. (v) of Solution 0.3 VT f/2 =const , (i) or TV 2/f =const . (ii) Expressing T in terms of P and V by the equation of state gives, for a ﬁxed number of particles, PV γ =const , (iii) with γ =1 + 2 f . See also Solution 1.8b in Part I. 186 Solutions to exercises in the text Solution 0.6 Exercise on page 128 (a) We write Eq. (2.0.5) replacing δQ = TdS to obtain dS = Nk ( f 2 dT T + dV V ) . (i) The right hand side of Eq. (i) is now an exact diﬀerential [unlike the right hand side of Eq. (2.0.5)] and it can be integrated to give S = Nk ln(bV T f/2) , (ii) where b is a constant. This constant may be taken out of the loga- rithmic function to become an additive constant. As written above, S is not an extensive function because of the V inside the logarithm. It is made extensive by writing b = c/N , which (at constant N ) adds but a constant to S. (b) We can use Eq. (ii) at both end points, where the volumes are Vi and Vf (and the temperatures cancel), to obtain ∆S = Nk ln ( Vf Vi ) . (iii) Note that one could obtain the same result by taking QT /T from Eq. (i) in Solution 0.1. (c) UsingEq. (ii) at both end points, where the temperatures are Ti and Tf ,one obtains ∆S = f 2 Nk ln ( Tf Ti ) . (iv) (d) If the entropy remains constant, dS =0 and also δQ =0. The process is therefore adiabatic. For an ideal gas Eq. (ii) holds and hence duringthe process the product VT f/2 remains constant [see also Exercise 0.3(d)] or TV γ−1 =const . (v) Solution 0.7 Exercise on page 129 UsingEq. (2.0.17) the enthalpy of an ideal gas is found to be H = ( 1+ f 2 ) NkT , which gives, via (2.0.19), the correct value for CP , Eq. (2.0.9). Solutions to exercises in the text 187 Solution 0.8 Exercise on page 130 We use Eqs. (2.0.21). The ﬁrst of these equations gives the identiﬁcation of the temperature: 1 T = ( ∂S ∂E ) V = 3 2 Nk E . (i) The second gives P T = ( ∂S ∂V ) E = Nk V . (ii) These are just the relations between energy and temperature for a monoatomic ideal gas and its equation of state. Equation (2.0.22) is the same as (2.0.12) written in terms of the energy and with f =3. Solution 0.9 Exercise on page 130 It is possible to use Eq. (2.0.23) as the fundamental relation and calculate the chemical potential as µ = ( ∂E ∂N ) S,V . (i) However, this way requires the explicit form of the function E(S, V, N ), which can be obtained by inversion of (2.0.22). Instead we use Eq. (2.0.23) in the form dS = 1 T (dE + PdV − µdN ) (ii) and calculate µ = −T ( ∂S ∂N ) E,V = −kT [ ln ( aV E3/2 N 5/2 ) − 5 2 ] . (iii) Expressingthe energy in terms of N and T and absorbingthe 5/2inthe constant a, one obtains (2.0.24). Solution 0.10 Exercise on page 131 In order to calculate F (T, V, N ) one needs E and S in terms of T , V and N . These are found in Eqs. (2.0.4) and (2.0.12). We substitute into the deﬁnition (2.0.25) to obtain the required expression for the free energy, F = −NkT [ ln ( cV T 3/2 N ) − 3 2 ] . (i) 188 Solutions to exercises in the text Now we calculate the chemical potential as µ = ( ∂F ∂N ) T,V = −kT [ ln (cV T 3/2 N ) − 5 2 ] . (ii) Comparison with Eq. (2.0.24) gives b = ce−5/2, and thus F = −NkT [ ln ( bV T 3/2 N ) +1 ] . (iii) The entropy of the ideal gas, which was used to ﬁnd the free energy explicitly, is rederived by applying(2.0.27): S = − ( ∂F ∂T ) V,N . Solution 0.11 Exercise on page 132 (a) Usingthe free energy, Eq. (2.0.27), one obtains S = 4a 3 VT 3 . (b) Similarly, P = a 3 T 4 . This is the form of the equation of state of a photon gas. Note that the pressure is independent of the volume. (c) To calculate the energy we use Eq. (2.0.25) to write E = F + TS = aV T 4 . (d) Since the free energy is independent of N , the chemical potential vanishes. This means that photons may be freely emitted or absorbed by the walls of the container. Solution 0.12 Exercise on page 132 The equation of state of a photon gas (1.1.7) is PV = 1 3 E. (i) Solutions to exercises in the text 189 In an adiabatic compression, all of the work goes to changing the internal energy, i.e. PdV = −dE . (ii) From Eq. (i) we obtain dE =3PdV +3VdP . (iii) Addingup Eqs. (ii) and (iii), 4PdV +3VdP =0 ⇓ 4 3 dV V + dP P =0 . (iv) The solution of Eq. (iv) is PV 4/3 =const . (v) Equation (v) is the required adiabatic equation. Solution 0.13 Exercise on page 132 (a) The ﬁrst of the Maxwell relations is satisﬁed because ( ∂P ∂N ) T,V = kT V , ( ∂µ ∂V ) T,N = − kT V . In order to verify the other two, we use Eq. (iii) in Solution 0.10 to write the entropy in the form S = − ( ∂F ∂T ) V,N = Nk [ ln ( bV T 3/2 N ) + 5 2 ] , (i) as well as the expressions for P (T, V, N ) [Eq. (ii) of Solution 0.8] and µ(T, V, N ) [Eq. (ii) of Solution 0.10]. (b) For the photon gas nothing depends on N . Therefore the ﬁrst two Maxwell relations are empty, i.e. 0 = 0. Usingthe results of (a) and (b) in Solution 0.11, the third relation is veriﬁed. 190 Solutions to exercises in the text Solution 0.14 Exercise on page 133 (a) Derivingfrom Eq. (2.0.31) the mixed second derivatives, one ﬁnds that ( ∂P ∂µ ) T,V = ( ∂N ∂V ) T,µ , ( ∂S ∂µ ) T,V = ( ∂N ∂T ) V,µ , ( ∂S ∂V ) T,µ = ( ∂P ∂T ) V,µ . (b) To calculate Ω(T, V, µ) one uses the deﬁnition (2.0.29) with the explicit relation for N (µ) obtained from Eq. (2.0.24). The result is Ω= −N (µ)kT = −kbV T 5/2e µ/kT . Solution 1.1 Exercise on page 137 We compare the entropy changes, as given in Eqs. (2.1.8) and (2.1.10): dS = 1 T dE + M T dH , (i) dS = 1 T dE∗ − H T dM , (ii) with the diﬀerentials of S,which is dS = ( ∂S ∂E ) H dE + ( ∂S ∂H ) E dH , (i)′ dS = ( ∂S ∂E∗ ) M dE∗ + ( ∂S ∂H ) E∗ dM . (ii)′ We obtain from Eqs. (i) and (i)′ (E and H are independent variables) ( ∂S ∂E ) H = 1 T , ( ∂S ∂H ) E = M T . (iii) Solutions to exercises in the text 191 And from Eqs. (ii) and (ii)′ (E∗ and M are independent variables) we obtain ( ∂S ∂E∗ ) M = 1 T , ( ∂S ∂M ) E∗ = − H T . (iv) The second order mixed derivatives of (iii) and (iv) give the Maxwell relations: ∂2S ∂E∂H = [ ∂(1/T ) ∂H ] E = [ ∂(M/T ) ∂E ] H , ∂2S ∂E∗∂M = [ ∂(1/T ) ∂M ] E∗ = − [ ∂(H/T ) ∂E∗ ] M . (v) Solution 2.1 Exercise on page 144 Because the average of a sum is the sum of averages, ⟨M ⟩ = 〈 N∑ i=1 µBσi 〉 = µB ∑ i ⟨σi⟩ , (i) and ⟨σi⟩ does not depend on the spin’s index i,we obtain ⟨M ⟩ = µBN ⟨σ⟩ . (ii) The result (ii) is (2.2.15). This means that (2.2.15) is a reasonable result, since it is derivable from simple general considerations. If there are Na spins in the subsystem, the same argument will give ⟨Ma⟩ = µBNa⟨σ⟩ . Solution 2.2 Exercise on page 145 In order to ﬁnd the probability for spin i to have a given value for its projection alongthe z direction, σi, and for spin j to have the value σj, we have to evaluate the ratio of the number of conﬁgurations in which spins i and j assume these speciﬁed values, and the total number of con- ﬁgurations, which is of course 2N . 192 Solutions to exercises in the text The number of conﬁgurations in which spin i has the speciﬁed projection σi and spin j the projection σj,is the sum of the number of all conﬁgurations, in which these two spins have these speciﬁc values, whereas all others can have every possible value. We start from the fact that the number of conﬁgurations with all spin projec- tions speciﬁed, Q(σ1,... ,σN )= 2N P (σ1,... ,σN ). To obtain the total number of states with speciﬁed σi and σj, Q(σi,σj), we perform the sum: Q(σi,σj)= ∑′′ {σ} Q(σ1,... ,σi,... ,σj,... ,σN ) =2 N ∑′′ {σ} P (σ1,... ,σN ) , (i) in which the double prime indicates that while N − 2 spins diﬀerent from i and j assume, each, its two values ±1, the projections of spins i and j are kept ﬁxed. The probability, P (σi,σj), for spin i to have component σi and spin j component σj, is therefore P (σi,σj)= 1 2N Q(σi,σj) (ii) and substitutingEq. (i) for Q we obtain Eq. (2.2.19). Solution 3.1 Exercise on page 148 The number of states with energy E is given by Eq. (2.3.4): Γ(E)= N ! N+!N−! , (i) where the relationship between the number of spins N+ and N− (in the direction of the ﬁeld and in the opposite direction, respectively) and the energy E is given by Eqs. (2.3.2) and (2.3.3): E = −µBH(N+ − N−) , (ii) and the total number of spins N is N = N+ + N− . (iii) Solutions to exercises in the text 193 From Eqs. (ii) and (iii) we obtain N+ = N 2 − E 2µBH , N− = N 2 + E 2µBH . (iv) Substituting(iv) in (i) we obtain Γ(E)= N ! ( N 2 − E 2µBH )! ( N 2 + E 2µBH )! . (v) Solution 3.2 Exercise on page 149 The calculation of P (σ1 = −1) is similar to the calculation of P (σ1 =1). Also here σ1 is constant, but this time we have to calculate the number of states of N − 1 spins, with an excess along+z,equalto q +1. In these states there are N+ spins as in the calculation of Γ(E)and N− − 1 spins along −z (since spin σ1 is directed along −z). The required number of states is therefore the number of possibilities of choosing N− − 1out of N − 1: (N − 1)! (N− − 1)!N+! , so that P (σ1 = −1) = 1 Γ(E) (N − 1)! (N− − 1)!N+! = N− N , where we have used Eq. (2.3.4) for Γ. Instead of N− we substitute the expression we obtained for it in Solu- tions 3.1 (iv), to obtain P (σ1 = −1) = 1 2 + E/N 2µBH . Alternatively, one can calculate the probability as a ratio between the number of spins with projection −1 and the total number of spins. Solution 3.3 Exercise on page 150 Since in our model the spin has only two possible values, we can write P (1) + P (−1) = 1 . (i) 194 Solutions to exercises in the text Equation (2.2.15) takes the form ⟨M ⟩ = µBN [P (1) − P (−1)] or P (1) − P (−1) = ⟨M ⟩ µBN . (ii) Equations (i) and (ii) are equations in two unknowns, P (1) and P (−1), whose solution is P (1) = 1 2 + ⟨M ⟩ 2µBN , P (−1) = 1 2 − ⟨M ⟩ 2µBN . (iii) Since E = −H⟨M ⟩ [see Eq. (2.3.6)], we immediately obtain Eqs. (2.3.7) and (2.3.8). Solution 3.4 Exercise on page 151 In order to obtain Eqs. (2.3.10) we calculate the number of states in which there are two constant spins, whereas all the other spins can have every possible value, under the constraint that there are a total of N+ spins alongthe ﬁeld and N− spins in the opposite direction. (a) Calculation of P (+1, +1). Amongthe N − 2 spins N+ − 2 are directed alongthe ﬁeld and N− in the opposite direction. The number of possible states is thus (N − 2)! (N+ − 2)!N−! . Hence P (+1, +1) = 1 Γ(E) (N − 2)! (N+ − 2)!N−! = N+(N+ − 1) N (N − 1) . (b) Calculation of P (+1, −1) or P (−1, +1). Amongthe N − 2 spins N+ − 1 are directed alongthe ﬁeld and N− − 1 in the opposite direction. The number of possible states is (N − 2)! (N+ − 1)!(N− − 1)! . Solutions to exercises in the text 195 Hence P (+1, −1) = P (−1, +1) = 1 Γ(E) (N − 2)! (N+ − 1)!(N− − 1)! = N−N+ N (N − 1) . (c) Calculation of P (−1, −1). Amongthe N − 2 spins N+ are directed alongthe ﬁeld and N− − 2 in the opposite direction. The number of possible states is (N − 2)! N+!(N− − 2)! , so that P (−1, −1) = N−(N− − 1) N (N − 1) . Solution 3.5 Exercise on page 152 Since the magnetization is identical in all states with the same energy, there are no states with magnetization diﬀerent from µBq, so that the deviation of M from its average vanishes, and hence (∆M )2 = 0. However, even though we already know the answer we will calculate (∆M )2 in a direct manner, as this method of calculation is typical of many other cases and is worth knowing. You have already seen a simple example of such a calculation in Exercise 1.15 of Part I. The average square deviation of M from its average is (∆M ) 2 = ⟨(M −⟨M ⟩) 2⟩ = ⟨(M 2 − 2M ⟨M ⟩ + ⟨M ⟩ 2)⟩ = ⟨M 2⟩−⟨M ⟩ 2 . (i) ⟨M ⟩ is given in Eq. (2.3.6) or (2.3.9): ⟨M ⟩ = µBq. (ii) Calculation of ⟨M 2⟩: From Eq. (2.2.10) M = µB N∑ i=1 σi . Hence ⟨M 2⟩ = ∑ {σ} ( µB N∑ i=1 σi )2 P (σ1,... ,σN ) = ∑ {σ} µ 2 B N∑ i=1 N∑ j=1 σiσjP (σ1,... ,σN ) . 196 Solutions to exercises in the text We have used the fact that ( ∑ k xk )2 = ( ∑ i xi )( ∑ j xj ) = ∑ i ∑ j xixj . Hence ⟨M 2⟩ = µ 2 B N∑ i=1 N∑ j=1 ∑ {σ} σiσjP (σ1,... ,σN ) = µ 2 B N∑ i=1 N∑ j=1 j̸=i ∑ {σ} σiσjP (σ1,... ,σN ) +µ2 B N∑ i=1 ∑ {σ} σ2 i P (σ1,... ,σN ) ≡ Σ1 +Σ2 , where we have separated between the cases with i ̸= j ( ∑ 1)and those with i = j ( ∑ 2). (a) To calculate ∑ 1 we rewrite the inner sum in the form ∑ {σ} σiσjP (σ1,... ,σN )= ∑ σi,σj σiσj ∑ {σ} ′′P (σ1,... ,σN ) = ∑ σi,σj σiσjP (σi,σj) , where we have used the notations of Chap. 2 and Eq. (2.2.19). P (σi,σj) has already been found [Eqs. (2.3.10)], and since it is independent of i and j we obtain Σ1 = µ 2 B N∑ i=1 N∑ j=1 j̸=i [P (+1, +1) − P (+1, −1) − P (−1, +1) + P (−1, −1)] = µ2 BN (N − 1) [ (N+ − 1)N+ N (N − 1) − 2 N+N− N (N − 1) + (N− − 1)N− N (N − 1) ] . Note that N∑ i=1 N∑ j=1 j̸=i 1= N(N − 1) . Solutions to exercises in the text 197 Hence Σ1 = µ 2 B(N 2 + − N+ − 2N+N− + N 2 − − N−) = µ 2 B[(N+ − N−) 2 − (N+ + N−)] = µ2 B(q2 − N ) . (iii) (b) Calculation of Σ2: Since σ2 i =1 for all i and ∑ {σ} P (σ1,... ,σN )=1, Σ2 = µ 2 B N∑ i=1 ∑ {σ} σ2 i P (σ1,... ,σN )= µ 2 BN. (iv) From (iii) and (iv) we obtain ⟨M 2⟩ =Σ1 +Σ2 = µ 2 B(q2 − N )+ µ 2 BN = µ2 Bq2 . Substituting(v) and (ii) into (i), we get (∆M ) 2 = µ 2 Bq2 − µ 2 Bq2 =0 , (v) as anticipated. Solution 3.6 Exercise on page 152 In order to calculate P (σ1 =+1,σ2 =+1,σ3 = +1), we have to calculate the number of states with N −3 spins, havingan excess in the +z direction equal to q − 3. This number is (N − 3)! (N+ − 3)!N−! , so that P (+1, +1, +1) = 1 Γ(E) (N − 3)! (N+ − 3)!N−! = N+(N+ − 1)(N+ − 2) N (N − 1)(N − 2) . In the thermodynamic limit both N+ and N →∞,and P (+1, +1, +1) → ( N+ N )3 . 198 Solutions to exercises in the text In the solution to Exercise 3.1 we found that N+ = N 2 − E 2µBH = N 2 ( 1 − E/N µBH ) , so that in the thermodynamic limit P (+1, +1, +1) = 1 8 ( 1 − E/N µBH )3 . Solution 3.7 Exercise on page 154 (a) From Eqs. (2.3.4) and (2.3.5) Γ(E)= N ! ( N 2 − E 2µBH )! ( N 2 + E 2µBH )! = N ! N+!N−! . From the deﬁnition of the function S 1 k S ≡ ln Γ(E)= ln N ! − ln N+! − ln N−! . (i) Applying Stirling’s formula for large n, Eq. (2.3.12), we obtain ln n! ≃ ( n + 1 2 ) ln n − n + 1 2 ln(2π) . (ii) Assumingthat N , N+ and N− are all large enough, we substitute their approximation (ii) in (i), to obtain 1 k S ≃ ( N + 1 2 ) ln N − N − ( N+ + 1 2 ) ln N+ + N+ − ( N− + 1 2 ) ln N− + N− − 1 2 ln(2π) = ( N + 1 2 ) ln N − ( N+ + 1 2 ) ln N+ − ( N− + 1 2 ) ln N− − 1 2 ln(2π) . (iii) We now write N± = N · N± N , (iv) Solutions to exercises in the text 199 and then 1 k S = ( N + 1 2 ) ln N − (N+ + 1 2 )( ln N +ln N+ N ) − ( N− + 1 2 )( ln N +ln N− N ) − 1 2 ln(2π) = − ( N+ + 1 2 ) ln N+ N − (N− + 1 2 ) ln N− N − 1 2 ln(2πN ) , (v) where the last transition was made after we noticed that from all the terms proportional to ln N the only one left was − 1 2 ln N . But (see Solution 3.1) N+ = N 2 − E 2µBH , N− = N 2 + E 2µBH (vi) ⇓ N± N = 1 2 ∓ E/N 2µBH . Substituting(vi) in (v) we obtain 1 k S ≃− ( N 2 − E 2µBH ) ln ( 1 2 − E/N 2µBH ) − ( N 2 + E 2µBH ) ln ( 1 2 + E/N 2µBH ) − 1 2 ln(2πN ) , (vii) where we have further neglected the term 1 2 compared to N±. Finally, we note that the ﬁrst two terms on the right hand side are proportional to N whereas the third one is proportional to ln N only. For N →∞ the third term is negligible compared to the ﬁrst two, so that we ﬁnd (2.3.13). (b) Equation (2.3.13) is not suﬃciently accurate for the calculation of the number of states for large, but not macroscopic, values of N even though Stirling’s approximation is already quite accurate. To this end we must return all the “branches we cut” in the process of obtaining (2.3.13), i.e. use Eq. (v) of (a) above: 1 k ˜S = − 1 2 ln(2πN ) − ( N +1 2 − E 2µBH ) ln ( 1 2 − E/N 2µBH ) − ( N +1 2 + E 2µBH ) ln ( 1 2 + E/N 2µBH ) . (viii) 200 Solutions to exercises in the text The followingtable summarizes the results of the calculation with eS/k [Eq. (2.3.13)] and with e ˜S/k [Eq. (viii) here] for N = 10. E/µBH −10 −8 −6 −4 −20 2 4 6 8 10 eS/k 1 25.8 149.0 449.7 837.2 1024.0 837.2 449.7 149.0 25.8 1 e ˜S/k – 10.9 47.0 123.8 215.6 258.4 215.6 123.8 47.0 10.9 – Note the good agreement between the results in the second row of the table and the results of Table 3.1. Nevertheless, at the edges of the spectrum it is not possible to use ˜S as it diverges there. This does not mean that (2.3.13) is wrong, but that it is valid only in the macroscopic limit, N →∞. Solution 3.8 Exercise on page 155 We use the notation ϵ = E/µBH for short, and write (2.3.13) in the form 1 k S = − N 2 ( 1 − ϵ N )[ln ( 1 − ϵ N ) − ln 2 ] − N 2 ( 1+ ϵ N )[ln ( 1+ ϵ N ) − ln 2 ] = N ln 2 − N 2 [( 1 − ϵ N ) ln (1 − ϵ N ) + ( 1+ ϵ N ) ln ( 1+ ϵ N )] . (i) Now, if N ≫ 1 we may approximate the logarithmic function by the ﬁrst two terms in its power expansion: 1 k S ≃ N ln 2 − N 2 [( 1 − ϵ N )( − ϵ N − ϵ2 2N 2 ) +( 1+ ϵ N )( ϵ N − ϵ2 2N 2 )] . (ii) Keepingterms up to the second order in ϵ we obtain 1 k S ≃ N ln 2 − ϵ2 2N (iii) or Γ= e S/k ≃ Ce −ϵ2/2N , (iv) which is Eq. (2.3.14). The constant C is not 2N , as might be expected from Eq. (iii), since we neglected too many terms depending on N on our way to Eq. (iv). If we use instead of (2.3.13) the more exact result we obtained in the answer to the previous exercise [Eq. (viii)], then we should add − 1 2 ln(2πN ) to the right hand side of Eq. (i). Thus we obtain, instead of Eq. (iii), 1 k ˜S ≃ ln ( 2N √ 2πN ) − ϵ2 2N , (v) Solutions to exercises in the text 201 so that C = 2N √ 2πN . (vi) The same result is also obtained from the normalization condition: C ∫ ∞ −∞ exp ( − ϵ2 2N ) dϵ =2 N , (vii) since the value of the integral on the left hand side is √ 2πN . Note that we integrated over energies from −∞ to ∞, although clearly our approxi- mation is valid only when ϵ/N is very small. But this means that most of the area of the graph is concentrated around ϵ = 0 and the exponential function decays extremely fast, so that the “tail” does not aﬀect the sum. Solution 4.1 Exercise on page 158 We calculate P (+1) and P (−1) by solvingtwo equations in two unknowns: The sum of the probabilities satisﬁes P (+1) + P (−1) = 1 . (i) Equation (2.4.8) reads P (+1) P (−1) = e 2µBHβ (ii) ⇓ P (+1) 1 − P (+1) = e 2µBHβ ⇓ P (+1) = e2µBHβ 1+ e2µBHβ . With the help of (i): P (−1) = 1 1+ e2µBHβ . Multiplyingboth by e−µBHβ: ⇓ P (+1) = eµBHβ 2cosh(µBHβ) , P (−1) = e−µBHβ 2cosh(µBHβ) . 202 Solutions to exercises in the text P (±1) as calculated here are the same probabilities given in Eqs. (2.3.7) and (2.3.8). The diﬀerence is that now they are expressed not as functions of E and H but as functions of β and H. By comparingthe two forms it is possible to obtain the relationship (2.4.6) between E and β. Solution 4.2 Exercise on page 160 The energy distribution (2.4.14) is a Gaussian distribution, which we write as ΓT (Ea)= C exp [ − (Ea − ¯Ea)2 2Nα2 ] , where α remains ﬁnite in the thermodynamic limit (check!). The simplest way to estimate the width of a Gaussian curve is to measure the distance to the energy value for which the distribution decreases to half of its maximal height. Thus, we search for an energy Ea satisfying C 2 = C exp [ − (Ea − ¯Ea)2 2Nα2 ] or ln 2 = (Ea − ¯Ea)2 2Nα2 ⇓ Ea = ¯Ea ± (2Nα 2 ln 2) 1/2 . This means that the width of the curve is ∆Ea ≃ 2(2Nα 2 ln 2) 1/2 ∼ N 1/2 . As the average energy is proportional to the number of spins in the system, we have ∆E ¯Ea ∼ N 1/2 N ∼ N −1/2 . The calculation may, of course, be performed in a more exact manner, if we calculate (∆Ea)2 = ⟨(Ea − ¯Ea)2⟩ , ⟨(Ea − ¯Ea)2⟩ = ∫ ∞ −∞(Ea − ¯Ea)2 exp [ −(Ea − ¯Ea)2/2Nα2] dEa ∫ ∞ −∞ exp [−(Ea − ¯Ea)2/2Nα2] dEa . Calculatingthe integral by the methods we developed in Part I, we obtain (∆Ea) 2 = Nα 2 . Hence ∆Ea ∼ N 1/2 . Solutions to exercises in the text 203 We again use the fact that ¯Ea ∼ N ,so that ∆Ea ¯Ea ∼ 1 N 1/2 . Solution 4.3 Exercise on page 162 (a) ⟨σ⟩ =(+1)P (+1) + (−1)P (−1) = P (+1) − P (−1). Usingthe results of Solution 4.1 for P (+1) and P (−1) we obtain ⟨σ⟩ = eµBHβ 2cosh(µBHβ) − e−µBHβ 2cosh(µBHβ) =tanh(µBHβ) . (i) Since the N spins are independent of one another, we have [Eq. (2.2.15)] M = µBN ⟨σ⟩ , and hence M = µBN tanh(µBHβ) . (ii) M/N H ➤➤ µB −µB (b) Equation (2.4.6) provides us with the relationship between energy and temperature, and since E = −MH, also with a relationship between the magnetization and the temperature, e 2µBHβ = NµB + M NµB − M , and, if we solve for M ,we get M = µBN tanh(µBHβ) . (c) From (2.4.21) and (2.4.19) we obtain H T = − ∂S ∂M = k 2µB ln 1+ M/N µB 1 − M/N µB . Now we can invert the relationship and express M in terms of all the other quantities exactly as in (b), and obtain (ii) again. 204 Solutions to exercises in the text (d) Equation (2.4.24) can simply be obtained from E = −MH using M from (a) or (b) above. Solution 5.1 Exercise on page 166 The constant C in Eq. (2.5.1a) is a normalization constant, which ensures that ∑ {σ} P (σ1,... ,σn)=1 , (i) where {σ} denotes the summation over all possible conﬁgurations, with σi = ±1for each i. Reminder:Eq. (i) is necessary if P is to be interpreted as the probability of a conﬁg- uration. That is, we require that ∑ {σ} C exp ( βµBH n∑ i=1 σi ) =1 , or C −1 = ∑ {σ} exp ( βµBH n∑ i=1 σi ) . (ii) The energy of a given conﬁguration is E(σ1,... ,σn)= −µBH n∑ i=1 σi . Writingthe summation over {σ} in (ii) in detail, we obtain C −1 = ∑ σ1=±1 ... ∑ σn=±1 e −βE(σ1,...,σn) . Solution 5.2 Exercise on page 168 The average magnetization is given by ⟨M ⟩ = ∑ {σ} [ µB n∑ i=1 σi ] P (σ1,... ,σn) = 1 Z ∑ {σ} [ µB n∑ i=1 σi ] exp  βµBH n∑ j=1 σj   , (i) Solutions to exercises in the text 205 where Z = ∑ {σ} exp ( βµBH n∑ i=1 σi ) . (ii) Since the sum in (i) is 1 β ∂Z ∂H , we immediately obtain ⟨M ⟩ = 1 β 1 Z ∂Z ∂H = 1 β ∂ ln Z ∂H . Solution 5.3 Exercise on page 168 If f is a function of x = βH only, then the followingrelations hold: ∂f ∂β = ∂f ∂x ∂x ∂β = H ∂f ∂x , ∂f ∂H = ∂f ∂x ∂x ∂H = β ∂f ∂x . If f (x)=ln Z(x), then ∂ ln Z ∂β = H ∂ ln Z ∂x , ∂ ln Z ∂H = β ∂ ln Z ∂x ⇓ ∂ ln Z ∂β = 1 β H ∂ ln Z ∂H . And from Eqs. (2.5.7) and (2.5.8) we obtain ⟨E⟩ = −H⟨M ⟩ . Solution 5.4 Exercise on page 171 We substitute in the deﬁnition of the heat capacity per spin at constant ﬁeld (2.5.17), cH = 1 n ( ∂E ∂T ) H , (i) the average energy of the system, E, as given by Eq. (2.5.13): E = −nµBH tanh(βµBH) . (ii) Diﬀerentiatingwith respect to T we obtain ( ∂E ∂T ) H = dβ dT ( ∂E ∂β ) H = −kβ2 ( ∂E ∂β ) H = kβ2nµBH µBH cosh2(βµBH) = nµ2 BH 2 kT 2 cosh2(βµBH) . (iii) 206 Solutions to exercises in the text From (i) and (iii) we obtain cH = µ2 BH 2 kT 2 cosh2(βµBH) . Solution 5.5 Exercise on page 172 The magnetization per spin at a constant temperature was plotted in Solution 4.3. See also Fig. 2.5.1. The plot at constant ﬁeld is: M/NµB kT/µBH ➤➤ 0.5 1.0 240 4 0 H>0 Note that this graph corresponds to the region H> 0 in Solution 4.3 or x> 0 in Fig. 2.5.1, and that the abscissa variable here is 1/x. Solution 5.6 Exercise on page 172 (a) The entropy of the paramagnet as a function of M is given by Eq. (2.4.18), which we rearrange and rewrite in a slightly diﬀerent manner: S = − Nk 2 [ ln ( 1 − ( M NµB )2) + M NµB ln ( NµB + M NµB − M ) − 2ln 2 ] . (i) Substitutingthe explicit expression (2.5.14) for M as a function of T and H,we obtain S(T, H)= − Nk 2 [ln(1 − tanh2 x)+tanh x ln ( 1+ tanh x 1 − tanh x )−2ln 2 ] , (ii) where x ≡ βµBH and N is the number of spins. Now, usingthe identities 1 − tanh2 x = 1 cosh2 x , 1+ tanh x 1 − tanh x = e 2x , Solutions to exercises in the text 207 we obtain S(T, H)= Nk[ln(2 cosh x) − x tanh x] = Nk { ln [ 2cosh ( µBH kT )] − µBH kT tanh ( µBH kT )} . (iii) (b) The entropy per spin as a function of temperature (at a constant ﬁeld) is depicted in the followinggraph:➤ ➤ T kln2 S/N (c) The entropy per spin as a function of the ﬁeld (at constant tempera- ture):➤ ➤ H kln2 S/N 5T T Solution 5.7 Exercise on page 173 (a) First we calculate, in analogy to Eq. (2.5.11), the partition function per ion: z = 2J∑ σi=−2J e βgµBHσi/2 . (i) 208 Solutions to exercises in the text The summation in (i) can be computed, as a geometric series whose ﬁrst term is eβgµBHJ .Denote x = βgµBH;then z = 2J∑ σi=−2J e xσi/2 = ex(J+1) − e−xJ ex − 1 . (ii) Reminder: 1+ q + q2 + ··· + qn−1 = qn − 1 q − 1 . Note that σi changes in steps of 2. Multiplyingthe numerator and the denominator in the last fraction by e−x/2,we obtain z = ex(J+1/2) − e−x(J+1/2) ex/2 − e−x/2 = sinh(J +1/2)x sinh(x/2) . (iii) If the number of spins is N , then the system’s partition function is obtained by (2.5.12): Z = [ sinh(J +1/2)x sinh(x/2) ]N . (iv) (b) The average magnetization per spin is calculated in a manner similar to that which brought us (in the case of spin 1 2 ) to Eq. (2.5.14). Recall that Eq. (2.5.8) is completely general. We continue to express Z in terms of x, and in order to obtain the derivative with respect to H we use the chain rule. ⟨M ⟩ N = 1 N 1 β ∂ ln Z ∂H = 1 N 1 β d ln Z dx ∂x ∂H = gµB d dx ln [sinh(J +1/2)x sinh(x/2) ] = gµB [(J +1/2) cosh(J +1/2)x sinh(J +1/2)x − 1/2cosh(x/2) sinh(x/2) ] . (v) We deﬁne Brillouin’s function by BJ (x) ≡ 1 J [( J + 1 2 ) coth ( J + 1 2 ) x − 1 2 coth ( x 2 )] (vi) and write (v) in the shortened form ⟨M ⟩ N = gµBJBJ (x) Solutions to exercises in the text 209 or, usingthe deﬁnition of x, ⟨M ⟩ N = gµBJBJ (βgµBH) . (vii) In order to plot a graph of ⟨M ⟩/N as a function of H,we have to analyze the behavior of the Brillouin function BJ (x). Since it is an odd function, it is suﬃcient to study the region x ≥ 0. For x →∞ it is easy to see that BJ (x) → 1. This means that the saturation value of ⟨M ⟩/N is gµBJ. At ﬁrst sight it seems as if BJ (x) diverges for x → 0. However, we know that for J = 1 2 , BJ (x)=tanh x,which behaves like x at small x,sowe have tostudy its behaviornearthe origin more carefully. We expand BJ (x)around x =0, and write coth y = ey + e−y ey − e−y = 2+ y2 + ... 2y + y3/3+ ... . For y ≪ 1itispossible towrite coth y ≃ 1+ y2/2 y(1 + y2/6) . But, for y ≪ 1, 1 1+ y2/6 ≃ 1 − y2 6 , so that we obtain coth y ≃ 1 y ( 1+ y2 2 )( 1 − y2 6 ) , and by neglecting terms of order higher than y2, coth y ≃ 1 y ( 1+ y2 3 ) = 1 y + y 3 . (viii) Hence, for small x the function BJ (x) takes the form BJ (x) ≃ 1 J {( J + 1 2 )[ 1 (J +1/2)x + 1 3 ( J + 1 2 ) x ] − 1 2 ( 2 x + x 6 )} = 1 J [ 1 3 ( J + 1 2 )2 x − 1 12 x ] = x 3J (J 2 + J)= ( J +1 3 ) x (ix) and this is the behavior we already know for the case J = 1 2 .Now we still have to check if indeed nothingspecial happens between x =0 and x →∞. To this end we calculate the derivative: dBJ dx = − (J +1/2)2 J sinh 2(J +1/2)x + 1 4J sinh 2 x/2 . 210 Solutions to exercises in the text A brief study reveals that dBJ /dx is positive for all x,so BJ (x)isa monotonic increasingfunction in the region under discussion. Hence ⟨M ⟩/N as a function of H will look as in the followingﬁgure: <M>/NgµB J=7/2 J=2 J=1/2 ➤ βgµBH➤ All we have used to arrive at the qualitative form of these curves is that the value at which they saturate increases in proportion to J and their slope at the origin in proportion to J(J + 1) [Eqs. (vii) and (ix)]. (c) We obtain the susceptibility from the behavior of ⟨M ⟩ at small ﬁelds. From Eqs. (vii) and (ix) we immediately ﬁnd ⟨M ⟩ N ≈ gµBJ · J +1 3 · βgµBH =(gµB) 2 J(J +1) 3kT H, (x) and the susceptibility is χ =(gµB) 2 J(J +1) 3kT . (xi) Substituting J = 1 2 and g = 2, we obtain the result (2.5.16). (d) We calculate the speciﬁc heat at a constant ﬁeld usingEqs. (2.5.17) and (2.5.7): cH = 1 N ( ∂E ∂T ) H = − 1 N kβ2 ( ∂E ∂β ) H = 1 N kβ2 ∂ ∂β ( ∂ ln Z ∂β ) = kβ2 ∂2 ln z ∂β2 , (xii) Solutions to exercises in the text 211 where we have substituted Z = zN . Nextwenotethat ∂2 ln z ∂β2 =(gµBH) 2 d2 ln z dx2 . But we have already computed the derivative d ln z/dx in (v). Using (v) and (vii) we obtain d ln z dx = JBJ (x) , d2 ln z dx2 = J dBJ (x) dx = − (J +1/2)2 sinh 2(J + 1 2 )x + 1/4 sinh 2 x/2 , so that ﬁnally cH = k(βgµBH) 2   1 4sinh2 ( 1 2 βgµBH) − (J +1/2)2 sinh 2((J +1/2)βgµBH)   . Substituting J = 1 2 ,g = 2 we obtain (2.5.18). Solution 6.1 Exercise on page 175 If E = 0 we have equal probabilities for each state P (+1) = P (−1) = 1 2 , and then S k = −N ( 1 2 ln 1 2 + 1 2 ln 1 2 ) = N ln 2 . This means that the assumption that the probabilities for a spin to be alongthe direction of the ﬁeld or in the opposite direction are equal, brings us from (2.6.6) to (2.6.4). In this case the thermal energy easily overcomes the interaction energy of the spins with the ﬁeld, so that there is no preferred direction: the temperature is very high and disorder dominates. Solution 6.2 Solution on page 176 Substitutingthe probabilities (2.5.5) into Eq. (2.6.7) we obtain S = −kZ−1 m∑ α=1 (−βEα − ln Z)e −βEα = kβZ−1 m∑ α=1 Eαe −βEα + kZ−1 ln Z m∑ α=1 e −βEα . 212 Solutions to exercises in the text The ﬁrst term includes the average energy ⟨E⟩. In the second term there appears the sum of probabilities which is of course 1. Hence S = kβ⟨E⟩ + k ln Z, which is the required result. Solutions to self-assessment exercises Solution 1 Exercise on page 180 From Eq. (2.4.5a) and from the explicit expression for β as a function of E, Eq. (2.4.6), we obtain the followingequation for ¯Ea: 1 2µBHa ln µBHaNa − ¯Ea µBHaNa + ¯Ea = 1 2µBHb ln µBHbNb − E + ¯Ea µBHbNb + E − ¯Ea . If Ha = Hb = H, the coeﬃcients of the logarithms cancel and their arguments must be equal. With a little algebra we obtain ¯Ea = Na Na + Nb E. ¯Eb has to make up the diﬀerence between ¯Ea and E,so that ¯Eb = Nb Na + Nb E. You may have been able to guess in advance that the energies at equilib- rium are distributed in direct proportion to the sizes of the two systems, so that each of them has the same energy per degree of freedom. How- ever, it is nice to ﬁnd yet another veriﬁcation that we are treadingon solid ground. Solution 2 Exercise on page 180 (a) Since δQ = TdS, the speciﬁc heat at constant ﬁeld is T (∂S/∂T )H , and the speciﬁc heat per degree of freedom is cH = T n ( ∂S ∂T ) H . We now use the expression that we found for S(T, H)in Exercise 5.6(a): S(T, H)= nk[ln(2 cosh x) − x tanh x] ,x ≡ µBH kT . 213 214 Solutions to self-assessment exercises Hence ∂S ∂T = − x T dS dx = nkx2 T 1 cosh2 x , so that cH = k x2 cosh2 x , and this result is identical to Eq. (2.5.18). (b) Ideal gas Paramagnet Extensive variable VM Intensive variable P −H TdS = dE + PdV T dS = dE∗ − HdM TdS = dH − VdP T dS = dE + MdH Enthalpy H = E + PV E∗ = E + MH E = 3 2 PV E∗ ≡ 0 Equation of state PV = NkT M = NµB tanh ( µBH kT ) (High T ) M ≃ N µBH kT Adiabatic system dS =0 dS =0 dE = −PdV dM =0 or H =0 PV γ =const M = const or H =0 Solution 3 Exercise on page 180 (a) The energy of a magnetic moment, m,in a ﬁeld H is given by ϵ = −m · H = −mH cos α. (i) Substitutingthe value of α into each of the possible states, we ﬁnd ϵ(α)=    −mH , α =0 , mH 2 ,α = 2π 3 , mH 2 ,α = 4π 3 . (ii) (b) Since the temperature is given, it is natural to use the canonical en- semble. The partition function is Z(β, H)= ∑ {all states} e −βE(state) . (iii) Solutions to self-assessment exercises 215 The same argument that led to (2.5.12), which is based solely on the fact that the spins are independent, will yield for the paramagnetic system under discussion as well, Z(β, H)= [z(β, H)] N , (iv) where N is the number of spins in the system, and z is the single spin partition function. In this case z(β, H)= ∑ α e −βϵ(α) , (v) with α =0, 2π/3, 4π/3. The energy per spin has already been calculated in (a), Eq. (ii), and thus z(β, H)= e βmH +2e −βmH/2 (vi) ⇓ Z(β, H)= (e βmH +2e −βmH/2) N . (vii) (c) In the absence of an external ﬁeld there will be an equal population in each of the three possible states, and hence a vanishingmagnetization. Since the ﬁeld is actingin the x direction, the spins aligned in the x direction have a lower energy, so that they have a higher probability. Thus it is expected that the net magnetization will also be in the x direction. (Note: there is a complete symmetry between the directions y and −y. Hence the magnetization of this system cannot have a component along y.) We shall verify this conclusion quantitatively usingboth methods mentioned. (1) The contribution to the magnetization in the x direction, of each of the states, is mx(α)= m cos α ⇓    mx(0) = m, mx ( 2π 3 ) = mx ( 4π 3 ) = m cos ( 2π 3 ) = − m 2 . (viii) 216 Solutions to self-assessment exercises The contribution along y is my(α)= m cos ( α − π 2 ) ⇓    my(0) = 0 , my ( 2π 3 ) = m √ 3 2 , my ( 4π 3 ) = −m √3 2 . (ix) The probability of a given one-particle state, α,is given by Pα(β, H)= e−βϵ(α) z(β, H) , (x) where the denominator, given in Eq. (v) or (vi), guarantees that the sum of probabilities is 1. In order to obtain the magnetization, we multiply the contribution of each state, Eqs. (viii) and (ix), by the probability of that state (x) and sum over the products: ⟨mx(β, H)⟩ = ∑ α mx(α)Pα(β, H)= m eβmH − e−βmH/2 eβmH +2e−βmH/2 , (xi) ⟨my(β, H)⟩ = ∑ α my(α)Pα(β, H)= 0 . (xii) This is of course the average magnetization per spin. (2) Since the ﬁeld is in the x direction we can use (2.5.8) and write the average magnetization per spin in the form ⟨mx⟩ = 1 βN ∂ ln Z ∂H , (xiii) where Z is given in Eq. (vii); from which ln Z = N ln(e βmH +2e −βmH/2) (xiv) and hence ⟨mx⟩ = 1 β eβmH − e−βmH/2 eβmH +2e−βmH/2 βm , (xv) which is the result we obtained in (xi). Solutions to self-assessment exercises 217 (d) Since the ﬁeld is weak, we use the approximation ex ≃ 1+ x for the numerator and the denominator in Eq. (xi), and hence ⟨mx⟩≃ m 3βmH/2 3 = βm2H 2 , (xvi) and from here χ = m2 2kT , (xvii) i.e. χ ∝ 1/T , and Curie’s law is recovered. (e) The average energy per spin may be calculated either from Eq. (2.5.7) or simply from ⟨ϵ⟩ = −⟨mx⟩H. Both methods yield ⟨ϵ⟩ = −mH eβmH − e−βmH/2 eβmH +2e−βmH/2 = −mH ( 1 − 3 2+ e3βmH/2 ) . (xviii) (f) The speciﬁc heat per spin at a constant ﬁeld is cH = ( ∂⟨ϵ⟩ ∂T ) H =2k (3βmH/2)2 (2e−3βmH/4 + e3βmH/4)2 (xix) Solution 4 Exercise on page 181 (a) The energy of a magnetic moment in an external ﬁeld H in the x direction ϵ(α)= −m · H = −mH cos α, where in this case α =0 , π 2 ,π, 3π 2 ⇓ ϵ(0) = −mH , ϵ ( π 2 ) =0 , (i) ϵ(π)= mH , ϵ ( 3π 2 ) =0 . (b) For this paramagnet as well the partition function is a product of single particle partition functions: Z(β, H)= [z(β, H)] N , where N is the number of spins in the system. This time the single spin states are characterized by four angles. Hence z(β, H)= e βmH + e −βmH +2 , (ii) so that Z(β, H)= (e βmH + e −βmH +2) N . (iii) 218 Solutions to self-assessment exercises (c) Calculation of the average magnetization per spin: (1) In this case only the states α =0and α = π contribute to the magnetization along x, since the other two states have zero pro- jections along x. With a ﬁeld in the x direction the magnetization does not have a component along y here as well. The average magnetization per spin is therefore ⟨mx⟩ = mx(α =0)Pα=0(β, H)+ mx(α = π)Pα=π(β, H) = m eβmH − e−βmH eβmH + e−βmH +2 . (iv) (2) Diﬀerentiatingthe partition function we obtain ⟨mx⟩ = 1 βN ∂ ln Z ∂H = 1 β ∂ ln z ∂H = m eβmH − e−βmH eβmH + e−βmH +2 . (d) A power expansion of the numerator and the denominator in Eq. (iv), alongwith the approximation ex ≃ 1+ x for x ≪ 1, gives the magne- tization for weak ﬁelds: ⟨mx⟩≃ βm2 2 H, so that χ = m2 2kT . (v) In this case as well Curie’s law is valid and we obtain the same result as in Exercise 3. (e) UsingEq. (2.5.7) and the result (ii), we obtain ⟨ϵ⟩ = − ∂ ln z ∂β = −mH eβmH − e−βmH eβmH + e−βmH +2 = −mH tanh ( βmH 2 ) , (vi) which means that, as expected for a paramagnet, ⟨ϵ⟩ = −⟨mx⟩H. (f) The heat capacity per spin at a constant external ﬁeld is cH = ( ∂⟨ϵ⟩ ∂T ) H , (vii) Solutions to self-assessment exercises 219 where ⟨ϵ⟩ is given in Eq. (vi). Diﬀerentiating we obtain cH =2k (βmH/2)2 cosh2(βmH/2) . Solution 5 Exercise on page 181 The probability for a given state, α,with energy Eα = E is Z −1e−βE [Eq. (2.5.5)]. However, there are many states with the same energy E. TheirnumberΓ(E) is given by (2.3.5). Thus the probability of ﬁnding the system in a state with energy E is P (E)= Z −1e −βEΓ(E) . (i) Now Γ(E) is related to the entropy by Γ = eS/k,so that P (E)= Z−1e (TS−E)/kT . (ii) In order to obtain the explicit dependence on E we have to substitute for Z the expression (2.5.12) with (2.5.11) and (2.3.13) for S.Note that it is not correct to use the expression for S(T, H) which we obtained in Exercise 5.6, as this expression is obtained under the assumption that E = ⟨E⟩, whereas here we are interested precisely in arbitrary values of E which may be diﬀerent from the average. Recall the warning at the end of Sec. 5.2. As the explicit form of P (E) is complicated and not very helpful, we leave the result in the form of Eq. (ii). It is worth notingthat the probability is maximal not when S is maxi- mal but when the combination TS −E is. More on this in the comingpart. Solution 6 Exercise on page 181 (a) Suppose that out of the N steps made by the drunk N+ were to the right and N− to the left. If the length of each step is L, then he will be located at a distance xN =(N+ − N−)L ≡ qL . (i) We also have N+ + N− = N. (ii) Note that if N is even, then q must also be even, and if N is odd, so is q. Hence q changes in steps of 2 between −N and N .From Eqs. (i) and (ii) we have N+ = N + q 2 ,N− = N − q 2 . (iii) 220 Solutions to self-assessment exercises We are thus interested in the probability of q havinga certain value. This probability is equal to the probability that out of N steps N+ will be to the right [(1/2)N+ ] times the probability for there to be N− steps to the left [(1/2)N− ] times the number of possibilities of distributing N steps into two groups N !/(N+!N−!). Makinguse of Eq. (iii), we ﬁnd P (q)= ( 1 2 )N N ! N+!N−! = N ! 2N ( N +q 2 ) ! ( N −q 2 )! , (iv) and this is the probability for the drunk to be located at a distance x = qL from the initial point. Note that P (q) is diﬀerent from zero only if q is an integer of the same parity as N . (b) We use Stirling’s formula, in the form ln n! ≃ n ln n − n + 1 2 ln(2πn) . (v) We write ln P using(v), without neglecting the last term: ln P =ln N ! − ln N+! − ln N−! − N ln 2 ≃ [ N ln N − N + 1 2 ln(2πN ) ]−[ N+ ln N+ − N+ + 1 2 ln(2πN+) ] − [ N− ln N− − N− + 1 2 ln(2πN−) ] − N ln 2 = ( N + 1 2 ) ln N − ( N+ + 1 2 ) ln N+ − ( N− + 1 2 ) ln N− −N ln 2 − 1 2 ln 2π, (vi) where the fact that N+ + N− = N led to the cancellation of the terms linear in N , N+ and N−.One term 1 2 ln 2π was canceled as well. Now, we use the fact that we are interested in the behavior of P (q)near q =0, which is the average of q. In this case Eq. (iii) implies that N+ and N− are very close to 1 2 N .We thus write ln N± =ln N − ln 2 + ln ( 1 ± q N ) . (vii) Takingonly the ﬁrst two terms in the expansion of the logarithm, we obtain ln N± ≃ ln N − ln 2 ± q N − 1 2 ( q N )2 . (viii) Solutions to self-assessment exercises 221 ln(1 + x)= x − x2 2 + x3 3 − ... We now substitute everythinginto (vi) and obtain ln P ≃ ( N + 1 2 ) ln N − ( N+ + 1 2 ) ( ln N − ln 2 + q N − q2 2N 2 ) − ( N− + 1 2 ) ( ln N − ln 2 − q N − q2 2N 2 ) − N ln 2 − 1 2 ln 2π. (ix) Note that of all the terms proportional to ln N only − 1 2 ln N is left, and, after neglecting 1/2N 2 with respect to 1/N , of all the terms that include q the only ones left are (N− − N+)q N + (N+ + N− +1)q2 2N 2 = ( − 1 2N + 1 2N 2 ) q2 ≃− q2 2N . And of all the terms that contain ln 2, only ln 2 is left. Thus we obtain ln P ≃− q2 2N − 1 2 ln N +ln 2 − 1 2 ln 2π =ln 2 √ 2πN − q2 2N . (x) We have therefore obtained a Gaussian distribution: P (q)= 2 √ 2πN e −q2/2N . (xi) The distribution function of x is obtained by substituting q = x/L and by further dividing(xi) by 2 due to the fact that q changes by steps of 2, so that ∆x =2L∆q.From here f (x)= 1 √ 2πN L2 exp ( − x2 2NL2 ) . (xii) (c) Since ⟨x⟩ =0, (∆x) 2 = ⟨x 2⟩ . We have already calculated such integrals many times along this course, and the result is always one over twice the coeﬃcient of the square of the random variable. Hence ∆x = √ NL2 = L √ N and the relative width is ∆x NL = 1 √ N . This Page Intentionally Left Blank Part III Statistical Physics and Thermodynamics This Page Intentionally Left Blank Introduction In Part II we saw that the canonical ensemble emerges naturally from the ensem- ble that characterizes an isolated system (the microcanonical ensemble). There it was demonstrated in the special case of a simple system the paramagnet, but the argument can be generalized in a natural way to any system. The canonical description is the most useful one, as in most practical cases it is possible to control the temperature and not the energy of the system. Indeed we will use the canonical ensemble, as a starting point in the analysis of most systems we shall consider. In this part we will employ the canonical ensemble to investigate the properties of several simple systems. Instead of deducing from the properties of the canonical ensemble the validity of the description based on the canonical ensemble, we shall accept it as a commandment. As a compensation we will dedicate the first chapter of this part to considerations that will make the transition smoother. First, we will show that the assumption of a canonical ensemble fits well the laws of thermodynamics. We will then deal with a collection of quantum oscillators, in which each degree of freedom has an infinite number of states that are discrete. This is a generalization of the paramagnet in which each degree of freedom has a finite number of states. Next, we go on to discuss gases. As opposed to the paramagnet and the quan- tum oscillator, the degrees of freedom here, the coordinates and momenta of the molecules, are continuous variables. Several generalizations of the methods de- scribed in the preceding part are needed, in order to obtain the familiar results of dilute gases. Here as well we will check the correspondence with known results. We will show that the kinetic theory derives from statistical mechanics. We will deduce the ideal gas law as well as Dalton’s law, and verify the consistency of our results, which will not be an easy matter, as we will find out. Finally, we will deal with fluctuations of thermodynamic quantities and the conditions under which they can be neglected, i.e. the question of the width of the distribution of thermodynamic quantities in the canonical ensemble. 225 Chapter 1 The Canonical Ensemble and Thermodynamics 1.1 The partition function and the internal energy No harm will be done if we repeat once more the rule that an uncompro- misingtest which every description of statistical mechanics must pass is its conformity with the laws of thermodynamics. The status of the latter is much stronger than that of the dynamical models or of the methods we formulate to calculate averages. In the canonical description, the system is described by its microscopic states, which we denote by the index i. The innocent index i may be a state of a paramagnet (one of the 2N values taken by the spins, denoted as {σ} in Part II), or the collection of coordinates and momenta of all gas molecules. Each state i is assigned an energy Ei. The energy can be given by an expression like (2.2.9) for a paramagnet, or by the sum of kinetic and potential energies of all of the molecules in the gas, having coordinates and momenta that characterize the state i. The classical physicist needs all the coordinates and momenta in order to characterize a state (see Chaps. 3 and 4 ahead). The quantum physicist will remark that if coordinates as well as momenta are needed, then a compromise will have to be made in the precision with which they are speciﬁed. “Canonical” means that: (a) In the ensemble all states with the same number of particles and the same volume are allowed. (b) The relative probability for a state i to appear in the ensem- ble is e −βEi , where β =1/kT . 226 1.1 Partition function and internal energy 227 In other words, the ratio of the probabilities for the appearance of two states i and j is P (i) P (j) = e −β(Ei−Ej) . (3.1.1) We are treating i as if it were a discrete index, in order not to complicate the discussion. In a gas, for instance, this is not the case. However, the required generalizations are very simple, and will appear in the following chapters. In Chap. 5 of Part II we mentioned that the partition function has an especially important role. We deﬁne it anew for a gas of particles: partition function Z(T, V, N )= ∑ i e −βEi . (3.1.2) On the left hand side we have emphasized the fact that the sum over states is a function of the temperature, the volume and the number of particles, since these are held ﬁxed. The appearance of these variables and not others hints at a possible relation between Z and the Helmholtz free energy F . See e.g. Sec. 0.3, Part II. But why rush? The volume is a natural variable when one is considering a gas or moving particles (liquid or solid). In the discussion of the paramagnet in Part II, the spins are ﬁxed in their positions and are insensitive to the volume. The partition function there depends on T , H and N, which are held constant when summing over all the states of the system. Exercise 1.1 Explain where is the dependence on V and N on the right hand side of (3.1.2). Solution on page 292 The deﬁnition (3.1.2) holds for every system. Thus, we can express the average energy of the system in terms of its partition function using an expression identical to (2.5.7). That expression was obtained indeed in the special case of the paramagnet. But the same argument can be used again, since the transition from (2.5.6) to (2.5.7) did not depend on any particular feature of the system. Exercise 1.2 Prove that (3.1.2) implies that ⟨E⟩ = − ∂ ln Z ∂β = kT 2 ∂ ln Z ∂T . (3.1.3) Solution on page 292 228 Ch. 1 Canonical Ensemble and Thermodynamics We identify ⟨E⟩ with the internal energy which in the thermodynamic context is denoted by the letter E or sometimes, in other texts, U (see also the remark at the end of Sec. 5.2 of Part II). ⟨E⟩ is of course a state function, in the thermodynamic sense, since if the volume, the number of particles and the temperature are given then ⟨E⟩ is determined. Now, we continue to obtain the rest of the thermodynamic quantities usingequations like (3.1.3). Once we have obtained these quantities, we will have the connection between the microscopic laws of the system and its thermodynamic properties; we will have reached an understandingof the statistical origin of the laws of thermodynamics. 1.2 Thermodynamic work Since we have already found out how to express the internal energy in terms of the partition function, the next step is to obtain an expression for the thermodynamic work in terms of the partition function, and to ﬁnd the correspondence with the ﬁrst law of thermodynamics. Then we go on to identify the entropy and the Helmholtz free energy. In order to identify the thermodynamic work, we ﬁrst note that the work performed by a system is related to the variation of external param- eters. In a gas, for instance, the work is related to the volume. The work can be related to a change in the position of the system, if it is located in an external force ﬁeld. In the example of the paramagnet in Part II: if the external ﬁeld H varies from one spatial position to another, then a change in the system’s position is accompanied by a change of magnitude dH in the ﬁeld, and will therefore involve performingwork according to Eq. (2.1.6). The problem before us, therefore, is to identify and to for- mulate the relationship between the variation of the external parameters and the work performed by the system. Suppose that we have identiﬁed such an external parameter that will, in most cases, depend on an external body, which aﬀects the en- ergies of the system’s states (for example: the walls of a container, the source of a magnetic or a gravitational ﬁeld, etc.). We denote it as X. The work that the system performs will therefore be performed on this body. In the general case the partition function will depend on the variables T, X, N and the right hand side of Eq. (3.1.2) will be Z(T, X, N). The energy of each microscopic state depends, therefore, on X;namely, Ei = Ei(X) . (3.1.4) 1.2 Thermodynamic work 229 This work is related to the existence of a “force”: Fi = − ∂Ei ∂X . (3.1.5) The “force” in Eq. (3.1.5) is a force in a generalized thermodynamic sense and may also be pressure or magnetization. It is important to make sure that the meaningof Eq. (3.1.5) is indeed clear: the system + the external body “tends,” as usual, to reduce the energy. Suppose that the system is in a state i. If the increase in X involves a decrease in its energy, the system will tend to realize this change, i.e. it will apply a “force” Fi on the external body directed along X. Fi will then be positive, and ∂Ei/∂X negative. A similar argument can be performed in the case where Ei is an increasingfunction of X. The body will “want” to move in the direction of −X in order to decrease the energy. That is, a negative “force” will act upon it. Now, if the force is given by (3.1.5), then the work done by the system in a state i on the external body, when the external coordinate changes from X to X + dX, is obtained by the product of the force and dX or, from a diﬀerent point of view, from the change in its energy: δWi = FidX = − ∂Ei(X) ∂X dX . (3.1.6) The thermodynamic work performed by the macroscopic system will be, like every thermodynamic quantity, an average of δWi over the canonical ensemble δW = Z−1 ∑ i (δWi)e −βEi . (3.1.7) Substituting(3.1.6) in (3.1.7), usingthe chain rule for the derivatives and carryingout the summation, we obtain δW = 1 β ∂ ln Z ∂X dX . (3.1.8) Equation (3.1.8) tells us, therefore, that once we have obtained the parti- tion function it is possible to calculate from it the thermodynamic work accompanyingevery change of the external parameter, by multiplying the change dX by the thermodynamic “force” β−1∂ ln Z/∂X.It is important to note that (3.1.8) expresses the work performed by the system in a quasi- static process: we required that the inﬁnitesimal process of varying X be performed, while the system has a deﬁnite temperature and the change dX induces a continuous change in the microscopic states. Only then are we allowed to use the probabilities of the canonical ensemble in order to calculate δW as in Eq. (3.1.7). 230 Ch. 1 Canonical Ensemble and Thermodynamics Exercise 1.3 Prove (3.1.8). Solution on page 293 Note that Eq. (3.1.8) does not imply that δW = − ∂E ∂X dX . Before we proceed, we exemplify the arguments made in the two cases we have already met: the paramagnet and the ideal gas. Paramagnet In this case the energy of a microscopic state i of N spins is given by Ei = −µBH · (σ1 + σ2 + ... + σN ) . (3.1.9) Here i denotes the microscopic states that were denoted in Part II by (σ1,σ2,..., σN ). The “force” is ∂Ei ∂H = −µB · (σ1 + σ2 + ... + σN ) (3.1.10) and this is actually the magnetization in state i, Mi. Thus, the work performed by the system in state i, when the magnetic ﬁeld changes from H to H + dH, will be δWi = − ∂Ei ∂H dH (3.1.11) and the thermodynamic work is obtained by averaging: δW = −Z−1 ∑ i ∂Ei ∂H e −βEidH . (3.1.12) This sum is nothingbut − 1 β ∂Z ∂H ,so that δW = 1 β 1 Z ∂Z ∂H dH = 1 β ∂ ln Z ∂H dH , (3.1.13) and of course this is the result we wanted. In order to identify the meaning of β−1∂ ln Z/∂H we turn to Part II, to ﬁnd that this is precisely the magnetization [see Eq. (2.5.8)]. Hence we can write δW = MdH , (3.1.14) 1.2 Thermodynamic work 231 which is the result (2.1.6), obtained usingsimilar arguments in the previ- ous part. Actually, we could have obtained this result by averaging (3.1.10) using the canonical probabilities Pi: 〈 ∂E ∂H 〉 = ∑ i ∂Ei ∂H Pi = −µB ∑ {σ}(σ1 + ... + σN )P (σ1,... ,σN ) . An ideal gas in a container In spite of its apparent simplicity, this case requires special attention. The reason for this is that the role of the external parameter X is played by the volume whereas the energy of a molecule in the container apparently depends only upon its speed, since ϵ = 1 2 mv2.Now, if Ei is independent of V ,then δWi vanishes [see (3.1.6)], so clearly the thermodynamic aver- age δW also vanishes. This leads to the paradoxical conclusion that the volume change of an ideal gas does not require any work. In order to avoid this trap, we note that the energy of a molecule in the container has an additional term responsible for the conﬁnement of the molecule to the container. This addition may be thought of as a potential that vanishes inside the container and increases sharply to inﬁnity on the sides of the container (see e.g. Fig. 3.4.1 in Sec. 4.4 below). But although it is possible to continue from here in the usual manner, it is more convenient to calculate the thermodynamic work directly with the help of momentum conservation arguments. We, therefore, inquire into the relationship between the volume change of a gas in a container and the resultingwork, and convince ourselves that β−1∂ ln Z/∂V is in fact the pressure. We do this by consideringa piston that can move along x, as depicted in Fig. 3.1.1, and assume, for the sake of simplicity, that the system is one dimensional, so that all the velocities are directed along x. ➤ ➤➤ ➤ m v ∆x x axis Fig. 3.1.1 A gas molecule transferring momentum to a piston. We start by consideringa single particle, of velocity v. The microscopic state of the particle will be characterized by the position of the particle 232 Ch. 1 Canonical Ensemble and Thermodynamics and by its velocity. Clearly, if the particle hits the piston it will recoil and change its velocity, and momentum will be transferred to the piston as well as energy. This momentum and energy transfer will be calculated in the followingway (compare with the calculation of the pressure in Part I and note the diﬀerences): the piston’s position changes by ∆x = u∆t (see Fig. 3.1.1), where u is its speed duringthat interval. If the particle’s recoil is elastic, the momentum it transfers to the piston is ∆p =2m(v − u) . (3.1.15) Exercise 1.4 Prove that a particle that collides with a movingpiston transfers momen- tum to it accordingto (3.1.15), and recoils from it with velocity −v +2u. Solution on page 293 Since the velocity of the recoiled particle is reduced owingto the col- lision, it loses energy of order −∆ϵ = m 2 v2 − m 2 (2u − v) 2 =2mu(v − u) , (3.1.16) and assumingthat the piston’s velocity is not too high (namely u ≪ v), ∆ϵ ≃−2muv . (3.1.17) Observe that when the piston is motionless ϵ does not change. We now want to calculate the total energy loss of the gas as the piston advances by ∆x duringtime ∆t. The energy loss contributed by the molecules of velocity v is obtained, of course, by multiplying∆ϵ by the number of molecules whose distance from the piston is at most v∆t (here as well we assume that u ≪ v). If n(v) is the number of molecules of velocity v per unit volume (see Chap. 1 of Part I), then the energy lost by them is (∆E)v = −(2muv)[n(v)Av∆t]= −2mv2n(v)A∆x. (3.1.18) The contribution of all the molecules (and not only of molecules with velocity v) to the energy loss is obtained by summing over (3.1.18): ∆E = −2m ∑ v2n(v)A∆x, (3.1.19) where the sum is carried out over all velocities whose direction is to- wards the piston, namely over all v> 0. We should stress here the principal diﬀerence between the discussion here and the discussion of 1.3 Entropy, free energy, ﬁrst and second laws 233 the pressure in Part I. Here n(v)is not the Maxwell–Boltzmann distribu- tion but a distribution that characterizes a speciﬁc microscopic state, i. It is therefore proper to add an index i to n(v)and ∆E. If in addition we note that A∆x =∆V ,we obtain ∂Ei ∂V = −2m ∑ v2ni(v) . (3.1.20) The expression on the right is nothing but the pressure of the gas [see Eqs. (1.1.2) and (1.1.3)] in the microscopic state i,so that ∂Ei ∂V = −Pi . (3.1.21) In this way we have overcome the main diﬃculty and found that the vol- ume independence of the energy in the microscopic state i is only apparent, and that actually the fact that the molecules of the gas are conﬁned to move inside a container of volume V gives rise to a volume dependence, as expressed by Eq. (3.1.21). Since the energy of each microscopic state depends on the volume, clearly the partition function must also depend on it. From here the continuation is clear and is carried on precisely as in the previous case: δW = −Z −1 ∑ ∂Ei ∂V e −βEidV = 1 β · ∂ ln Z ∂V dV . (3.1.22) To identify the meaningof β−1∂ ln Z/∂V we note that the middle expres- sion in (3.1.22) may be written, using(3.1.21), in the form Z −1 ∑ Pie −βEi . Since Z −1e−βEi are the canonical probabilities, this expression is the av- erage pressure, P . Hence we obtain, as for the relation between the mag- netization and the partition function, a relation between the the pressure and the partition function: P = 1 β ∂ ln Z ∂V . (3.1.23) 1.3 Entropy, free energy, the ﬁrst and second laws In the previous section we found that the thermodynamic work performed by a system is related to the change of the internal energy in individual microscopic states. The average change of internal energy resulting from a change in an external macroscopic parameter is the thermodynamic work. 234 Ch. 1 Canonical Ensemble and Thermodynamics This is, of course, the thermodynamic generalization of the energy conser- vation law from mechanics. However, in addition to the average change of the internal energy, which we may denote by ⟨dE⟩, we may consider another quantity, the change of the average internal energy, which we de- note by d⟨E⟩ or dE. Even though ⟨dE⟩ + δW = 0 by deﬁnition, in general dE + δW ̸= 0, as in thermodynamics. A mathematical justiﬁcation for the inequality sign is the fact that the canonical probabilities depend, via the energies, on the macroscopic external parameter X,whose variation characterizes the process (see Exercise 1.3 and the remark that follows), and thus ⟨dE⟩ ̸= d⟨E⟩. We identify the sum dE + δW with the heat transferred to the system in a quasistatic process, δQ, and obtain the ﬁrst law of thermodynamics [Eq. (2.0.1)]: dE + δW = δQ . (3.1.24a) The next step is to obtain the entropy in terms of the partition function. To this end we have to verify that it is indeed possible to write δQ of Eq. (3.1.24a) in the form that is required by the second law of thermody- namics: δQ = TdS . (3.1.24b) First, we shall ﬁnd that as a result of a change of the external parameter by dX and a change in temperature expressed by dβ, in a quasistatic process, dE + δW = ( 1 β ∂ ln Z ∂X − ∂2 ln Z ∂β∂X ) dX − ∂2 ln Z ∂β2 dβ . (3.1.25) Exercise 1.5 (a) Prove Eq. (3.1.25). (b) Show that the right hand side of Eq. (3.1.25) cannot be an exact diﬀerential of a state function. Solution on page 294 Now, given (3.1.24), we ask: Is it possible to convert the right hand side of (3.1.25) into an exact diﬀerential by multiplyingby β? And indeed β(dE+δW )= (∂ ln Z ∂X − β ∂2 ln Z ∂β∂X ) dX −β ∂2 ln Z ∂β2 dβ = k−1dS , (3.1.26) 1.3 Entropy, free energy, ﬁrst and second laws 235 where k−1S =ln Z − β ∂ ln Z ∂β (3.1.27) (k is the Boltzmann constant). Exercise 1.6 Show that the right hand side of (3.1.26) is an exact diﬀerential, and prove (3.1.27). Solution on page 295 We have thus identiﬁed the entropy, and obtained its relation with the canonical partition function, Z(T, X, N ). Lastly, we obtain the Helmholtz Helmholtz free energyfree energy F (T, X, N ), deﬁned in thermodynamics (see Part II, Sec. 0.3) by F = E − TS . (3.1.28) To this end we note that the second term on the right hand side of Eq. (3.1.27) is none other than βE [see Eq. (3.1.3)]. Hence, S = k ln Z + E T . (3.1.29) Comparing(3.1.29) with (3.1.28), we obtain F = −kT ln Z = −β−1 ln Z. (3.1.30) Exercise 1.7 As is known from thermodynamics, the entropy is obtained from the free energy by [see Eq. (2.0.27)] S = − ( ∂F ∂T ) X,N . Start from the expression (3.1.30) for F , and verify Eq. (3.1.27). Solution on page 296 We have seen here one of the convincingsuccesses of statistical me- chanics (accordingto Gibbs): statistical mechanics created a link between the conservation of energy in the microscopic theory and the ﬁrst law of thermodynamics. It was then found that the average values of the in- ternal energy, the work and the heat, deﬁned naturally within statistical mechanics and averaged, satisfy the second law of thermodynamics. In this manner we have obtained the internal energy, the work, the heat and the entropy, and ﬁnally the free energy in terms of the canonical partition 236 Ch. 1 Canonical Ensemble and Thermodynamics function. We know from thermodynamics that given F ,a complete de- scription of the macroscopic properties of the system is possible. Since it is possible to calculate F from Z [Eq. (3.1.30)], the calculation of Z in the canonical ensemble provides us with all of the thermodynamic information on the system. 1.4 The paramagnet — revisited To end this chapter we implement the results we obtained in the simple case of the paramagnet. In Chap. 5 of Part II, we saw that the canonical partition function of the paramagnet of spin 1/2, can be written as (2.5.11) and (2.5.12), namely Z(T, H, N )= [ 2cosh ( µBH kT )]N , (3.1.31) where N is the number of spins in the system. The Helmholtz free energy is, therefore, F (T, H, N )= −kT ln Z = −NkT ln (2cosh µBH kT ) (3.1.32) and the entropy S = − ( ∂F ∂T ) H,N = Nk [ ln ( 2cosh µBH kT ) − µBH kT tanh µBH kT ] . (3.1.33) Exercise 1.8 Show that from F and S it is possible to obtain E in Eq. (2.5.13), with the help of thermodynamic relationships. Solution on page 296 Exercise 1.9 Show that from S it is possible to obtain the expression for the speciﬁc heat, at a constant ﬁeld H, given in (2.5.18). Solution on page 296 Exercise 1.10 Is it possible to obtain from F the entropy as a function of the energy, the ﬁeld and the number of spins? That is, is it possible to pass from F (T, H, N )to S(E, H, N ) as given by Eq. (2.3.13)? Solution on page 297 1.5 Statistical meaning of the free energy 237 Exercise 1.11 If the energy of the microscopic states changes by the addition of a con- stant which is independent of the state Ei → Ei + C, how do the partition function, the average energy, the free energy and the magnetization change? Solution on page 298 1.5 On the statistical meaning of the free energy In an isolated system in which the energy is constant, a state of ther- modynamic equilibrium is attained when the entropy is maximal. You have seen an example of this in Part II, Chap. 4, where we discussed two systems a and b (of spins, for example) which are isolated from the rest of the universe but which interact thermally with each other. In this case the entropy of each of the systems is a function of the magnetic ﬁeld, the number of spins and the energy of each system where the fact that the systems are isolated is expressed by the constancy of Ea + Eb. Neverthe- less, the energy of each system is free to change. Equilibrium between the two systems is attained at the most probable macroscopic state of the composite system, where the total entropy attains its maximum. If we choose the energy Ea as a variable that characterizes the partition of the total energy between the two systems, the condition for equilibrium is ∂ ∂Ea [S(Ea,Ha,Na)+ S(E − Ea,Hb,Nb)] = 0 . (3.1.34) Actually this line of argument is completely general, and may be ap- plied to any system, provided the entropy is expressed in terms of the appropriate variables (volume instead of magnetic ﬁeld, pressure instead of magnetization, etc.). Now we ask, what happens in a nonisolated system which instead has a given temperature, namely that is free to exchange energy with a heat bath. What is the quantity that attains its maximum at the most probable state? Clearly the entropy (or the number of states Γ) is related to the answer, since the larger the entropy, the larger the probability of the macroscopic state. But here there is an additional factor actingin the opposite direc- tion, which is the Boltzmann factor, e−βE. This factor expresses the fact that lower energy states have higher probability. 238 Ch. 1 Canonical Ensemble and Thermodynamics Hence the probability for the system to be in a macroscopic state of energy E is P (E)= Z−1e −βEΓ(E) . (3.1.35) Now, we can write Γ = eS/k, and from here it is immediately clear that the most probable state is the one in which the sum S − E/T is max- imal. We have seen therefore that a system that is held at a constant temperature ﬁnds its way to equilibrium subject to two opposingfactors: the entropy’s tendency to increase and the energy’s tendency to decrease. The compromise is that equilibrium is determined by the combination S − E/T . But this is nothing more than the free energy in disguise: S − E T = − F T , (3.1.36) so that the probability for a system coupled to a heat bath to have energy E is P (E)= Z−1e −βF (E) . (3.1.37) Note that we have suppressed the dependence of F and Z on all other variables, such as V, N, T . The most probable state of a system in which all the variables are ﬁxed except for the energy is therefore the state in which −F (E) is maximal or F (E) is minimal. In this case, one has 1 T = ∂S ∂E , (3.1.38) which is the relation we use to pass from the microcanonical ensemble to the canonical one. Exercise 1.12 Prove (3.1.38). Solution on page 298 The free energy is therefore the fundamental function of the canonical ensemble and satisﬁes dF = dE − TdS − SdT = −SdT − δW . (3.1.39) This is the origin of the name “free energy.” In a process that occurs without the transfer of heat, a system can perform work at the expense of its internal energy. But if the process takes place at a constant tempera- ture, it must be accompanied by the transfer of heat, so that the work is performed at the expense of the free energy: δW = −(dF )T . 1.5 Statistical meaning of the free energy 239 At the temperature of absolute zero the free energy becomes identical to the internal energy, so that any changes in the free energy are equivalent to internal energy changes, as expected from a state without any thermal ﬂuctuations. At higher temperatures, the free energy decreases with T , as is easy to see from the relation [obtained from (3.1.39)] ∂F ∂T = −S, (3.1.40) since the entropy is always nonnegative. In order to illustrate the fact that the free energy attains its mini- mum at equilibrium, we return to the paramagnet which is coupled to a heat bath at temperature T . The free energy of a conﬁguration of the paramagnet having energy E is F (E)= E + kT {( N 2 − E 2µBH ) ln ( 1 2 − E/N 2µBH ) + ( N 2 + E 2µBH ) ln ( 1 2 + E/N 2µBH )} , (3.1.41) where we have used Eq. (2.3.13) for S. F (E) as a function of E and the probability P (E) of a conﬁguration of energy E are depicted in Fig. 3.1.2, for a system with N = 200. Note that the minimum of the free energy and the maximum of the probability are attained at the same energy. Exercise 1.13 (a) Verify that the energy at which F (E) attains its minimum in Fig. 3.1.2 is in fact consistent with the known energy of a paramagnet obtained, for example, in Exercise 1.8. (b) Compare the minimum of F (E) as well against Eq. (3.1.32). (c) Show that from the requirement that F (E) be minimal at thermody- namic equilibrium the known expressions for E and F are obtained. Solution on page 299 Another quantity that should be mentioned here is the chemical poten- tial. We reached the concept of temperature in a natural manner through chemical potentialthe requirement that the equilibrium state between two isolated systems, that are in thermal contact and can exchange energy, be the state in which the entropy of the composite system is maximal. In this state the quantity ∂S/∂E must be equal in the two systems. We identiﬁed this quantity as 1/T . 240 Ch. 1 Canonical Ensemble and Thermodynamics F/NkT E/µBHN –0.4621–1.00 1.00 –0.8133 P(E) –0.4621–1.00 1.00 E/µBHN (a) (b) Fig. 3.1.2 (a) The probability of a conﬁguration of energy E, for a paramagnet with N = 200 where µBH/kT =0.5. The units of the vertical axis are arbitrary. (b) The free energy of a conﬁguration of energy E. Note that the minimum free energy is at the most probable energy. 1.5 Statistical meaning of the free energy 241 We now ask the analogous question concerning the number of particles. Suppose that both systems contain particles that are free to move (for instance, gas molecules) and that a partition separates the two systems but allows the transfer of particles between them. We shall also assume, for simplicity, that the two systems contain the same type of particles. The number of states of such a system depends of course on the energy, the volume and the number of particles, and hence so does the entropy S(E, V, N ). The total entropy of the composite system depends on all six variables Ea,Va,Na,Eb,Vb,Nb, but only three will be independent, as the total energy, the total number of particles N and the total volume V remain constant. From the requirement of maximum entropy we obtain not only the condition of equal temperatures (and the condition of equal pressures by diﬀerentiatingwith respect to Va, for example, if Va varies) but also the condition that the chemical potentials of the two systems should be equal, namely µa = µb where µ is deﬁned by [see Eq. (2.0.23)] µ = −T ( ∂S ∂N ) E,V . (3.1.42) Exercise 1.14 Prove that the chemical potentials are equal at equilibrium between the systems. Solution on page 300 We now complicate matters a bit, and assume that both systems are not isolated from the rest of the universe but are at equilibrium with a heat bath at temperature T . In this case equilibrium is attained when the free energy is minimal, and in the same way as for the isolated system we obtain µa = µb, where [see e.g. Eq. (2.0.27)] µ = ( ∂F ∂N ) T,V . (3.1.43) In order to better understand the meaningof the chemical potential, let us also check what happens in a state that is not an equilibrium state. In such a state the free energy of the system is not minimal, and hence the system tends to decrease it by redistributing N between a and b.Suppose that the number of particles in system a changes (increases or decreases) by dNa. The free energy will change by dF = ( ∂Fa ∂Na + ∂Fb ∂Na ) dNa =(µa − µb)dNa . (3.1.44) Recall that since the free energy must decrease, dF < 0. 242 Ch. 1 Canonical Ensemble and Thermodynamics This means that Na increases (dNa > 0) as longas µa <µb.In other words, particles will ﬂow from b to a if the chemical potential of b is larger than that of a. We have therefore found that the chemical potential determines the direction of particle ﬂow between systems just as the temperature determines the direction of energy ﬂow: particles will ﬂow from the higher chemical potential to the lower one. We demonstrate this property with the help of the ideal gas. In Chap. 5, Eq. (3.5.9) below, we ﬁnd that the chemical potential of an ideal gas is given by µ = kT ln  ( h2 2πmkT )3/2 n   = kT ln [ h3 (2πm)3/2 · P (kT )5/2 ] , (3.1.45) where P is the pressure of the gas substituted from the equation of state. It is clear from this that the chemical potential increases with the density of the gas or with its pressure, and thus that molecules of the gas will ﬂow from regions of high density to regions of lower density or from regions of high pressures to those of low pressures. Compare the discussion here to the discussion of self-diﬀusion — Secs. 3.3–3.5 of Part I. Finally, we note that the magnitude of the chemical potential is of no physical signiﬁcance; only the diﬀerences in the chemical potential are meaningful, as is the case for the energy. Chapter 2 Harmonic Oscillator and Einstein Solid 2.1 Microscopic states In Part II we have treated the paramagnet in a magnetic ﬁeld in which each degree of freedom, each spin, had a ﬁnite number of energy levels: two states for spin 1/2, or 2J +1 states for spin J. This kind of quantization is absent in the classical case, where the degrees of freedom have a continuum of values. Before treatingsuch a problem, we treat an intermediate case, in which the degrees of freedom take discrete values, but the number of diﬀerent values is inﬁnite. The case we shall treat here has also some practical applications for the calculation of the speciﬁc heat of solids. For us, the sole importance of the quantum aspect is that the energy levels of the microscopic states take discrete values. It may be worth mentioningonce more that the fact that in quantum theory the energy levels are discrete, makes the statistical interpretation of such systems more natural than their classical counterparts. The degree of freedom, replacing the spin from Part II, is a harmonic oscillator. The system we shall discuss is a lattice which has at each of its sites a harmonic oscillator with angular frequency (or angular veloc- ity) ω in place of the magnetic moment in Part II. You may think of this system as a lattice of masses m, each connected at the lattice site to a springwith springconstant K,so that ω = √ K/m. The interest in such a system stems from the fact that in many respects this is a good approx- imation for a crystal whose atoms are oscillatingaround their equilibrium positions. When the oscillations are small their motion is approximately harmonic. Before turningto calculate the partition function of the canonical en- semble, in accordance with the discussion in Chap. 1 of this part, we must discuss the states of a single oscillator. Because the system we are thinkingof is a lattice of atoms, the oscillators discussed here are quan- tum oscillators. The quantum discussion of the harmonic oscillator may 243 244 Ch. 2 Harmonic Oscillator and Einstein Solid be summarized for our purposes by the fact that the energy levels of the one-dimensional harmonic oscillator are characterized by a nonnegative integer n: ϵn = ( n + 1 2 ) ¯hω, n =0, 1, 2, 3 ... (3.2.1) Note that all the values of ϵn are positive, just as for a classical oscillator, but this is where the similarity ends. The amplitude A of a classical harmonic oscillator can take a continuum of values, and hence its energy, ϵ = 1 2 mω2A2, takes a continuum of values, startingfrom the minimal value ϵ = 0. The energies of the quantum oscillator are quantized in intervals of ¯hω, startingfrom the minimal value, which is not zero but ϵ = 1 2 ¯hω. As n increases, the energy of the oscillator increases. It is thus natural to refer to n as the degree of excitation of the oscillator. n characterizes the state of the oscillator just as the number σ used for the magnetic moment in Part II. Fig. 3.2.1 The energy levels of a harmonic oscillator:Dashed lines — the quantized levels; full line — energy of classical oscillator vs amplitude A. The next step is to investigate the microscopic states of a lattice of N harmonic oscillators as a whole. Since each oscillator is characterized by a degree of excitation n, the microscopic state of N oscillators will be characterized by N degrees of excitation (n1,n2,n3,... ,nN ), similar to the speciﬁcation of all the spin values in terms of the N numbers (σ1,σ2,... ,σN ) in the paramagnet in Part II. The energy of a microscopic state in which oscillator 1 has a degree of excitation n1, the second a degree of excitation n2 and so on, will be the sum of all the oscillator energies: E(n1,n2,... ,nN )= ϵ(n1)+ ϵ(n2)+ ··· + ϵ(nN ) . (3.2.2) 2.2 Partition function for oscillators 245 Fig. 3.2.2 A state of a system of six oscillators: n1 =1,n2 =3,n3 =0,n4 =4,n5 = 3,n6 =2. All this is, of course, based on the assumption that the N oscillators are unaﬀected by each other, and that all are vibratingat the same frequency in an independent manner. Figure 3.2.2 schematically describes a state of asystemwith N =6. 2.2 Partition function for oscillators We now write the partition function and obtain Z = ∑ n1,n2,...,nN e −βE(n1,n2,...,nN ) = ∑ n1,n2,...,nN e −βϵ(n1)e −βϵ(n2) ... e −βϵ(nN ) , (3.2.3) and each summation variable varies between 0 and ∞.We can write the sum of products as a product of sums, in precisely the same way as was done for Eq. (2.5.9): Z =   ∞∑ n1=0 e −β¯hω(n1+1/2)     ∞∑ n2=0 e −β¯hω(n2+1/2)   ×··· ×   ∞∑ nN =0 e −β¯hω(nN +1/2)   . (3.2.4) Since all the factors in the product on the right hand side of (3.2.4) are identical, we write the partition function in the form Z = zN , (3.2.5) where z may be thought of as a partition function of a single oscillator: z = ∞∑ n=0 e −βϵn = ∞∑ n=0 e −β¯hω(n+1/2) . (3.2.6) 246 Ch. 2 Harmonic Oscillator and Einstein Solid Exercise 2.1 In order to demonstrate the equality of (3.2.3) and (3.2.4), let us study the system of three identical oscillators, each of them havingthree energy levels. Verify for this case that (3.2.3) and (3.2.4) are indeed identical. Solution on page 300 Our problem is therefore reduced to calculatingthe partition function of a single oscillator which is nothing more than the summation of a geometric series: z = e −β¯hω/2 ∞∑ n=0 e −β¯hωn = e−β¯hω/2 1 − e−β¯hω . (3.2.7) Reminder:the sum of an inﬁnite geometric series ∞∑ n=0 xn = 1 1 − x ,x < 1 . Now we can use the general formula (3.1.3) to calculate the average energy of an oscillator. The result is ⟨ϵ⟩ = ¯hω 2 + ¯hω e¯hω/kT − 1 . (3.2.8) Exercise 2.2 Prove (3.2.8). Solution on page 302 Another interestingquestion is the average value of n, the degree of excitation of the oscillators. The answer is ⟨n⟩ = 1 e¯hω/kT − 1 , (3.2.9) which is the celebrated Bose–Einstein distribution. More on this in theBose Einstein distribution parts that follow. Exercise 2.3 Prove (3.2.9) in two ways: (a) By a direct calculation of the average. (b) From (3.2.8). Solution on page 302 2.2 Partition function for oscillators 247 Fig. 3.2.3 The temperature dependence of the average degree of excitation of a har- monic oscillator. Analyzingthe temperature dependence of ⟨n⟩ (Fig. 3.2.3), we ﬁnd that ⟨n⟩∼    e−¯hω/kT ,kT ≪ ¯hω (low temperatures) , kT ¯hω ,kT ≫ ¯hω (high temperatures) . (3.2.10) Exercise 2.4 Verify that (3.2.9) has the asymptotic behaviors (3.2.10). Solution on page 303 Namely, at low temperatures ⟨n⟩ vanishes faster than any power of T . This means that the oscillator cannot be excited from its ground state n = 0 since the energy kT supplied by the heat bath is insuﬃcient to overcome the diﬀerence ¯hω to the state n = 1. In contrast, at high temperatures states may be excited up to a certain value of n,given approximately by the thermal energy divided by ¯hω. Thus, we may expect that ⟨n⟩∼ kT ¯hω ,e −¯hω/kT kT /¯hω kT /¯hω which is the relation (3.2.10) for high T . In the professional jargon, instead of saying that the oscillator is excited to degree of excitation n, we say that there are n “bosons” or “phonons,” each with energy ¯hω.The phonons calculation of ⟨n⟩ is described in this language to be the average number of phonons as a function of T . Equation (3.2.10) states that the phonons disappear as T → 0and rapidly grow in number with increasing temperature. 248 Ch. 2 Harmonic Oscillator and Einstein Solid Exercise 2.5 (a) Calculate the free energy of a harmonic oscillator as well as its entropy, and sketch their temperature dependence. (b) If the frequency of the oscillator is 1013 s−1, what is the transition temperature from low temperature behavior to high temperature be- havior? Solution on page 304 The discerningreader will probably have noticed that our discussion in this section began with a system of N oscillators and drifted after Eq. (3.2.5) to a discussion of a single oscillator and to the calculation of its thermal averages, which are, at least at ﬁrst sight, of doubtful sig- niﬁcance. To make things clear we note that the single oscillator upon which our discussion concentrated may be thought of as an oscillator in thermodynamic equilibrium with a heat bath with which it may exchange energy. You may, for example, picture for yourself as a concrete exam- ple a situation in which a single harmonic (quantum) oscillator resides in a container full of gas at a given temperature. The concepts of sin- gle particle partition functions and of thermal averages with respect to such ensembles are to be understood from this point of view. Such a description is made possible by the absence of interaction between the oscillators. 2.3 Einstein’s solid We now describe a model for the vibrations of a solid. If the crystal is made up of N atoms, the motion of each of them has three indepen- dent components. The atoms cannot move freely; instead they vibrate about equilibrium positions, which determine the geometric structure of the crystal. The possible vibrations of each atom are described by a model of three harmonic oscillators, so that N atoms are equivalent to 3N har- monic oscillators. To make things simple, we choose, as Einstein did, the same frequency for all the oscillators. This simplifyingassumption can and must be im- proved, as was done by Debye. However, we shall continue with the sim- pliﬁed model for the time being, namely the model of 3N oscillators, all of which have the same frequency, ω. If the 3N oscillators do not aﬀect one another, we may describe a microscopic state of the system by 3N numbers nα (α =1,... , 3N ), which describe the state of excitation of oscillator number α (or the number of bosons of type α; see Fig. 3.2.2). 2.3 Einstein’s solid 249 From now on we can use the partition function, obtained in the preced- ingsections, for calculating the relevant thermodynamic quantities, such as the average energy, free energy and speciﬁc heat. The only change we will have to make is to change the meaning of N : N , which was the number of oscillators, will here denote the number of atoms in the crystal, so that we replace N by 3N . The partition function of our crystal is Z = z3N , (3.2.11) where z is as given by (3.2.7). Using(3.1.30) we ﬁnd for the free energy F = −kT ln Z = −3NkT ln z =3N [ ¯hω 2 + kT ln(1 − e −β¯hω) ] . (3.2.12) Of course, we could have obtained this result by multiplying f as cal- culated in Exercise 2.5, by 3N . In this way we also obtain the average energy: ⟨E⟩ = − ∂ ln Z ∂β = −3N ∂ ln z ∂β =3N ( ¯hω 2 + ¯hω eβ¯hω − 1 ) . (3.2.13) We now investigate the behavior of the average energy at high tempera- tures and at low temperatures: (a) At high temperatures kT ≫ ¯hω,or β¯hω ≪ 1, so that e β¯hω ≃ 1+ β¯hω + 1 2 (β¯hω) 2 ··· , and expandingthe denominator on the right hand side of Eq. (3.2.13) in powers of β¯hω we ﬁnd, as in (3.2.10), ⟨E⟩≃ 3NkT , (3.2.14) which is the equipartition law of classical kinetic theory (see Secs. 1.3 and 1.6 of Part I): Each degree of freedom of a harmonic oscillator has a kinetic energy term 1 2 mv2, and a potential energy term 1 2 Kx2.As we will ﬁnd in Sec. 4.3, each of these terms contributes 1 2 kT . Hence 3N oscillators have an average energy of 3NkT . It is important to note also that the result (3.2.14) does not involve Planck’s constant, ¯h. Thus, its origin cannot be quantum-mechanical. A diﬀerent way of understandingthis result is to interpret it as the limit ¯h → 0 of the quantum energy Eq. (3.2.13), at constant temperature. If ¯h → 0, the separation between successive energy levels vanishes and the classical continuum returns. Since only the ratio ¯hω/kT determines the behavior (3.2.14), the limit of large T is equivalent to the limit of small ¯h. 250 Ch. 2 Harmonic Oscillator and Einstein Solid (b) At low temperatures kT ≪ ¯hω,or β¯hω ≫ 1. In this case e β¯hω ≫ 1 , so that 1 eβ¯hω − 1 ≃ e −β¯hω . and the average energy is ⟨E⟩≃ 3N ¯hω (e −¯hω/kT + 1 2 ) . (3.2.15) This means that at low temperatures the average energy tends very rapidly to the minimal value, 3N ¯hω 2 , allowed by quantum theory. The excited states are “frozen.” From (3.2.13), with N taken as Avogadro’s number, it is possible to calculate the molar speciﬁc heat: C = ∂⟨E⟩ ∂T = 3R(¯hω)2 (kT )2 e¯hω/kT (e¯hω/kT − 1)2 , (3.2.16) where R is the gas constant. Exercise 2.6 (a) Deduce (3.2.16) from (3.2.13). (b) Deduce (3.2.16) from the entropy. Solution on page 305 We can obtain the behavior of the speciﬁc heat at high temperatures and at low temperatures by checkingthe two limits of (3.2.16) or (simpler) from Eqs. (3.2.14) and (3.2.15), respectively. Thus, at high temperatures C ≃ 3R, (3.2.17) and at low temperatures C ≃ 3R ( ¯hω kT )2 e −¯hω/kT . (3.2.18) The result (3.2.17) is the Dulong–Petit law. Dulong and Petit found (inDulong Petit law 1819) that many solids have a constant molar speciﬁc heat of 3R.The fact, found later, that as the temperature decreases so does the speciﬁc heat, caused grave diﬃculties for classical physics. This phenomenon was also found at intermediate temperatures, but only in hard crystals. These are diﬀerent manifestations of the “heat capacity problem” which we have 2.3 Einstein’s solid 251 already met in Part I (Sec. 1.3) on the molecular level. Einstein’s model, as presented here, explains the decrease of the speciﬁc heat with decreasing temperature — Eq. (3.2.16). The decrease with stiﬀness is also explained, since the frequency ω of a stiﬀer crystal will be higher. But high and low temperatures are determined, as we have seen, by the ratio of kT and ¯hω,so that if ¯hω is large, the crystal reaches the behavior that is characteristic of low temperatures in a temperature range in which a softer crystal behaves classically. Exercise 2.7 (a) If the oscillators have angular frequency ω =107 s−1,how much heat must be supplied to a mole of crystal in order to raise its temperature by 10−2 degrees in the vicinity of 1 K, and in the vicinity of 100 K? A crystal with such a frequency is extremely soft and unrealistic. The crystal appearing in (b) has a realistic frequency. (b) Repeat (a), with ω =1012 s−1. Solution on page 306 The characteristic temperature for each material is the Einstein tem- perature,ΘE = ¯hω k , which we can use to rewrite Eq. (3.2.16) in the form Einstein temperature C =3R ( ΘE T )2 exp(ΘE/T ) [exp(ΘE/T ) − 1]2 . (3.2.19) For lead ΘE ≃ 90 K, whereas for diamond ΘE ≃ 2000 K. Hence at room temperature the speciﬁc heat of lead will behave classically, accordingto the equipartition law, or the Dulong–Petit law. The diamond will behave in a very diﬀerent manner; its speciﬁc heat will be much smaller than the classical value. Both cases can be identiﬁed in Fig. 3.2.4, which depicts the speciﬁc heat as a function of T/ΘE. For lead at room temperature T/ΘE ≃ 3and C/R ≃ 3. In contrast, for diamond at the same temperature T/ΘE ≃ 0.15, and the speciﬁc heat is small. A study of Fig. 3.2.4 reveals that Einstein’s theory indeed gives a qualitative description of the temperature variation of the speciﬁc heat and constitutes an interpolation between the classical, high temperature, value (3R per mole) and zero, as the temperature tends to zero. However, the quantitative correspondence with the experimental results is not very good. The reason for this is the unrealistic assumption that all the oscil- lators have the same frequency. Debye constructed a theory that accounts correctly for the vibrations of the crystal, takinginto account the fact that 252 Ch. 2 Harmonic Oscillator and Einstein Solid the motion of one atom will, necessarily, aﬀect its neighbors. Thus the vi- brations which must be taken into account are the collective vibrations of many atoms, vibrational modes, havingmany diﬀerent frequencies. When the frequency distribution is used to modify Einstein’s theory, the result is in very good quantitative agreement with experiment, as may be seen in Fig. 3.2.4. More on the Debye model in the next part. Debye theory Einstein theory Experiment➤ ➤ 0 0.5 1.0 1.5 T/ΘECV/R 0 1 2 3 Dulong-Petit law Fig. 3.2.4 The speciﬁc heat vs temperature — theory and experimental results. Al- though Einstein’s theory describes the qualitative behavior well, quantitatively it is the Debye theory that is accurate. Finally, we note here that what interested Einstein was not a full quantitative theory of crystals, but the sensational fact that the exten- sion of Planck’s assumption concerningthe quantization of the modes of electromagnetic radiation to the vibrations of matter suﬃces to solve, in principle, the nagging problem of the decrease of the speciﬁc heat of solids with decreasingtemperature. Chapter 3 Statistical Mechanics of Classical Systems 3.1 Statistical mechanics of a single particle So far we have treated quantum systems whose states may be enumerated, so that it was easy to assign them probabilities. When dealing with clas- sical systems (surprisingly!) an extension of these concepts is required, but the extension does not require more than the probability densities introduced in the kinetic theory (Part I, Chap. 1). We open with the followingquestion: What is required in order to characterize the state of a particle? The particle itself is deﬁned by a mass (possibly also an electric charge, nuclear charge, etc.), and might be conﬁned to a box. But it can be any- where inside the box. We therefore need, at least, to know the particle’s position in order to characterize its state. At every point inside the box there may be forces acting(forces of gravity, electric forces, etc.). The particle’s motion will be determined by Newton’s laws, Maxwell’s laws, etc. But even given the particle’s position and the forces actingupon it, its velocity remains undetermined. We know from mechanics that the particle’s initial position and initial velocity must be given in order to determine its motion under the inﬂuence of the given forces. Thus, as part of the characterization of the state of the particle, its velocity must be given. It turns out that the discussion is more symmetrical if instead of the velocity the momentum is used. In the cases we shall treat, this change amounts merely to multiplication by the mass. However, in more complicated cases involving, for example, magnetic forces that depend on the velocity, the relation is less simple. Anyway, the position and momentum at a given instant characterize the particle’s state. The acceleration, for instance, is determined by Newton’s laws: It does not add independent information. 253 254 Ch. 3 Statistical Mechanics of Classical Systems Given the particle’s position and velocity, it is possible to calculate its energy, which is E = 1 2 mv2 + U (r)= p2 2m + U (r) , (3.3.1) i.e. the sum of the kinetic energy mv2/2, or p2/2m, and the potential energy U (r) which depends on the position of the particle. Thus, apparently, we can speak of the canonical ensemble of a single particle in a region with a potential U , i.e. of a particle at equilibrium with a heat bath and under the inﬂuence of a potential U . The probability of ﬁndingthe particle in a state (r, p) (namely at point r with momentum p) would be proportional to the Boltzmann factor: exp { −β [ p2 2m + U (r) ]} . (3.3.2) But how do we sum over states? The answer is that since r and p are continuous variables, we are to discuss the probability density and not the probability. That is, we must say that the probability for the particle to be found in a small volume dV around r, and for its momentum to be found in a small volume dτ around p, is proportional to exp { −β [ p2 2m + U (r) ]} dV dτ . (3.3.3) In Part I dτ denoted the volume element in velocity space. Here it denotes the volume element in momentum space. Hence, instead of summingover states we shall have to integrate over all the values of position and momentum that are allowed by the conditions of the problem. The picture is, therefore, that we have a six-dimensional space (this space is called phase space): three dimensions for position and three forphase space momentum. This space is divided into small cells of size dV dτ ,which is a six-dimensional volume element. The probability for the particle to be in one of the cells is proportional to the volume of the cell and to the Boltzmann factor, correspondingto the total energy of the particle in that cell. It is simpler, of course, to illustrate the phase space when its dimen- sionality is less than 6. If the particle moves in one dimension, it is described by one coordinate x,and onevelocity v, and therefore one mo- mentum p. The phase space of such a particle will be two-dimensional. This space is depicted in Fig. 3.3.1. 3.1 Statistical mechanics of a single particle 255 dx=dV ➤➤ E/mg 2mE dp=dτ p x dVdτ cell constant energy surface Fig. 3.3.1 The phase space of a particle whose motion in a gravitational ﬁeld is conﬁned to one dimension. If the particle has mass m, and is attracted by a gravitational ﬁeld along −x with acceleration g, then its energy is E = p2 2m + mgx . (3.3.4) The parabola in the ﬁgure describes a surface of constant energy. Exercise 3.1 The energy of a classical harmonic oscillator is given by E = p2 2m + 1 2 Kx 2 , (3.3.5) where the time dependence of x is x = x0 cos ωt , (3.3.6) with ω = √ K m . Sketch the phase space, and describe in it the trajectory of a particle that moves accordingto (3.3.6). Solution on page 307 The calculation of the averages will be performed as in Part I. That is, if A(r, p) is some function of the particle’s position and momentum (an observable of its state), then ⟨A⟩ = 1 zc ∫ A(r, p)exp { −β [ p2 2m + U (r) ]} dV dτ , (3.3.7) 256 Ch. 3 Statistical Mechanics of Classical Systems where the normalization constant may be thought of as a partition func- tion of a single particle: zc = ∫ exp { −β [ p2 2m + U (r) ]} dV dτ . (3.3.8) Examples (a) The average kinetic energy of the particle: equipartition. In this case A(r, p)= p2 2m , 〈 p2 2m 〉 = ∫ p2 2m e−βp2/2md3p ∫ e−βU (r)d3r ∫ e−βp2/2md3p ∫ e−βU (r)d3r = − ∂ ∂β ln [∫ e −βp2/2md 3p] = 3 2 kT . (3.3.9) What has happened here? First, we have noticed that for our speciﬁc choice of A, both integrals, in the numerator and in the denominator, can be decomposed as a product — one integral over the position and another over the momentum. We wrote dV = d3r, dτ = d3p, and noted that the integral over the position cancels out. Using the methods we developed in Sec. 1.6, we immediately obtain the result (3.3.9) — the equipartition law for the kinetic energy, namely 1 2 kT per momentum component. Exercise 3.2 Calculate ⟨p2 x/2m⟩. How is this result connected with equipartition? Solution on page 308 (b) The average potential energy A(r, p)= U (r). We ﬁnd that ⟨U (r)⟩ = ∫ U (r)e−βU (r)d3r ∫ e−βU (r)d3r . (3.3.10) Note that this time the integral over the momentum cancels out and we obtain ⟨U (r)⟩ = − ∂ ∂β ln [∫ e −βU (r)d 3r] . (3.3.11) 3.1 Statistical mechanics of a single particle 257 We cannot proceed any further without makingsome assumptions concerning U . However, we can deduce that the right hand side will depend on the temperature, the volume in which the particle is con- ﬁned (since the integral is only over the coordinates inside the vol- ume in which the particle is contained) and the parameters which characterize U . Actually, the volume to which the particle is con- ﬁned is also one of the parameters of the potential, since it is pos- sible to describe the conﬁnement of the particle to a certain region of space with the help of a “step potential,” as already mentioned in Sec. 1.2. Usually, however, it is customary to write explicitly only the potential that is unrelated to the walls of the container and to represent the container by the limits of the integration over the position. If the potential U limits the particle to a spatial region that is very small compared to the size of the container, then it is possible to perform the calculation as if the container extended to inﬁnity. Thus, for example, if U (r)= 1 2 Kr2 , (3.3.12) namely the potential of a harmonic oscillator, then the energy of the particle increases rapidly with its distance from r = 0 (see Fig. 3.3.2). Hence its probability to be far from r = 0 becomes very small, unless the temperature is very high. ➤➤ L/2–L/2 0 x U(x) Fig. 3.3.2 Harmonic potential of a particle in a box. 258 Ch. 3 Statistical Mechanics of Classical Systems Exercise 3.3 A three-dimensional box of length L contains a particle in a harmonic “potential well” (3.3.12), at the center of the box. (a) At what temperature will the particle begin to feel the existence of the walls? (b) What will ⟨U (r)⟩ be if we extend L to inﬁnity? Solution on page 309 In a similar manner, given any function of the particle’s state A(r, p), it is possible to calculate the average ⟨A⟩. The integrals may get more complicated, but the principle remains the same. 3.2 Statistical mechanics of a classical gas Usually there is not much interest in the statistical mechanics of a sin- gle particle, but rather in a system of many particles — a macroscopic system. Suppose, therefore, that in a box of volume V there are N particles. The particles may be under the inﬂuence of some external ﬁeld (other than the container) and they may interact with one another. What is required in order to characterize the macroscopic state of the system? The answer is, of course, that we require the coordinates and momenta of each and every particle of the gas. If we label the particles by num- bers from 1 to N ,we require all N pairs of vectors (r1, p1), (r2, p2),... , (rN , pN ) at a given instant in order to specify a state of a system. Each component of ri can take any value in the conﬁning volume. Each component of pi can vary between −∞ and ∞. We have found, therefore, that it is possible to think of the state of a system of N particles as a point in a 6N -dimensional space — the system’s phase space. The temporal evolution of the system, namely the variation of (r1, p1),... , (rN , pN ) with time, corresponds from this point of view to a continuous transition from point to point in phase space, i.e. to a motion alonga curve in phase space. But here we are not interested in the details of the trajectories but, as already mentioned several times, in various averages along them. To this end we must calculate the energy of a given microscopic state. This will be made up of a kinetic energy, Ek = 1 2 m1v2 1 + 1 2 m2v2 2 + ... + 1 2 mN v2 N = N∑ i=1 1 2mi p2 i , (3.3.13) 3.2 Statistical mechanics of a classical gas 259 where mi is the mass of particle number i, and a potential energy that depends, in most cases, on the positions of the particles: U = N∑ i=1 U1(ri)+ N∑ i,j=1 U2(ri, rj)+ ... (3.3.14) The expression for the potential energy is to be read in the following manner: the potential energy is the sum of potential energies experienced by each particle separately (as a result of external forces), of potential energies originating from the mutual forces between pairs of particles, po- tential energies originating from the mutual interactions of three particles, etc. In order to clarify (3.3.14) we discuss two simple cases. Examples (a) Suppose that N particles, which do not interact with one another, are contained in a box in a gravitational ﬁeld. In this case only the ﬁrst contribution to the potential energy will appear — the single particle potential. What is it composed of? Well, each particle will feel the gravitational force, independently of the position of all other particles andofits ownvelocity. Hence U will have the form U = N∑ i=1 U1(ri)= N∑ i=1 migzi , (3.3.15) wherewehave chosen the z axis to be “up.” (b) Suppose that the particles are charged, and that the charge of the ith particle is qi. In this case, the electrostatic potential energy of particle number j, due to particle number i,is U2(ri, rj)= kqiqj |ri − rj| , (3.3.16) i.e. the product of the charges divided by the distance between then. Here, k is the electrostatic constant. Thus, the total potential energy is U = ∑ i,j (i<j) kqiqj |ri − rj| , (3.3.17) where the sum is organized in such a way that it excludes self-interactions and that the potential of a pair of particles is not counted twice. 260 Ch. 3 Statistical Mechanics of Classical Systems Given the energy of a microscopic state of the system, we can assign to it a probability in phase space, where again the space is partitioned into small cells. Since this time the space has 6N dimensions, the cells are small, 6N -dimensional volumes. The probability for the system to be in a microscopic state, inside the inﬁnitesimal volume around the point (r1, p1), (r2, p2),... , (rN , pN ), is proportional to exp [−βE(r1, p1, r2, p2,... , rN , pN )] dV1dτ1dV2dτ2 ... dVN dτN . (3.3.18) This is the probability for particle 1 to be in the small volume dV1 around the point r1, and for its momentum to be in the volume dτ1 around the momentum vector p1; for particle 2 to be in the volume dV2 around the point r2, and in the volume dτ2 around p2; and so on. Compare with Eq. (1.1.50). The normalization factor of the distribution is of course the partition function of the classical system: Zc = ∫ (dV dτ ) N e −βE(ri,pi) , (3.3.19) where, for brevity, we have written the energy of the microscopic state as E(ri, pi), and the inﬁnitesimal volume as (dV dτ )N . Note:the dimensions of the “classical” single-particle partition function zc are (length × momentum) 3,and those of Zc are (length × momentum) 3N , in contrast to the quantum cases of discrete degrees of freedom, for which the partition function is dimensionless. Now that we have deﬁned the probability density of every microscopic state it is possible to calculate the average of any observable, i.e. of every function of ri and pi. Given such a function, A(ri, pi)= A(r1, p1; r2, p2; ... ; rN , pN ) , (3.3.20) the average of A is ⟨A⟩ = 1 Zc ∫ (dV dτ ) N A(ri, pi)e −βE(ri,pi) . (3.3.21) These are all simple generalizations of Eqs. (3.3.7) and (3.3.8), etc., of the previous section. Chapter 4 Statistical Mechanics of an Ideal Gas 4.1 The ideal gas The classical system that is simplest to treat, usingthe methods formu- lated in Chap. 3, is the ideal gas. This system is deﬁned by the require- ideal gas ment that the collection of particles be conﬁned to a given volume, and the particle energies be purely kinetic. As a second step, it is possible to add external forces, but interactions between particles are still neglected. Such a description is reasonable for a dilute gas of neutral particles. The forces between neutral particles are short-ranged, and when the gas is di- lute the probability for one particle to be found close to another, to feel the force exerted by it, is very small. In a gas at standard conditions the mean free path is much larger than the intermolec- ular distance, and thus also much larger than the characteristic size of a molecule. See Exercise 3.5 of Part I. The ﬁrst important result: If the energy of the system can be written as a sum of energies, each depending only on the state of one particle, then the probability for a given state of the system is given as a product of the probabilities of the separate particles, i.e. if E(r1, p1, r2, p2,... , rN , pN )= N∑ i=1 ϵi(ri, pi) , (3.4.1) then exp[−βE(r1, p1, r2, p2,... , rN , pN )]dV1dτ1 ... dVN dτN =exp[−βϵ1(r1, p1)]dV1dτ1 · exp[−βϵ2(r2, p2)]dV2dτ2 · ... exp[−βϵN (rN , pN )]dVN dτN . (3.4.2) In other words, in the canonical distribution single particle states are independent of each other. 261 262 Ch. 4 Statistical Mechanics of an Ideal Gas As we saw in Part II [Eq. (2.3.11)], in a microcanonical ensemble there can exist de- pendence between the single particle probabilities, even though there are no interaction forces between them. It is, however, negligibly small. The second result: If the particles are identical, the partition function is a power of a single particle partition function. Namely, Zc = zN c , (3.4.3) where zc is as given in Eq. (3.3.8). Equation (3.4.3) will be corrected in Chap. 5 below — Eq. (3.5.3). Exercise 4.1 Prove (3.4.3). Solution on page 309 Given the partition function, the free energy is determined by Eq. (3.1.30). From the free energy it is possible to deduce all the thermo- dynamic properties of the system. That was the moral of Chap. 1. Thus, we now calculate zc from Eq. (3.3.8), for the case of a particle movingfreely in the entire volume of the box. In the calculation the inte- gral separates into a product of an integral over position and an integral over momentum: zc = ∫ dV e −βU (r) · ∫ dτ e −βp2/2m . (3.4.4) Since r is conﬁned to the volume of the box and the particle is free, U = 0, the ﬁrst integral is equal to V —the volume of the box. The second integral is a Gaussian integral, the like of which we calculated in Part I (Exercise 1.13, for instance). Hence zc = V ( 2πm β )3/2 = V (2πmkT ) 3/2 . (3.4.5) Exercise 4.2 Prove (3.4.5). Solution on page 310 Substituting(3.4.5) into the expression for the free energy (3.1.30), we obtain F = − 1 β ln Zc = − N β ln zc = −NkT [ ln V + 3 2 ln(2πmkT ) ] . (3.4.6) 4.2 Mixtures of ideal gases Dalton’s law 263 From F we can immediately obtain the pressure and the entropy, as P = − ( ∂F ∂V ) T,N = NkT V (3.4.7) and S = − ( ∂F ∂T ) V,N = Nk [ ln V + 3 2 ln(2πmkT )+ 3 2 ] . (3.4.8) Note that (3.4.7) is the ideal gas equation of state! It is of interest to recall the way in which the volume enters the par- tition function. As already mentioned in Sec. 1.2, the volume does not appear explicitly in the kinetic energy of the particles; nevertheless the partition function depends upon it. Here it enters into the partition func- tion via the limits of the integration over the particles’ positions. From the expression for S it is possible to obtain the speciﬁc heat at constant volume: CV = T ( ∂S ∂T ) V,N = 3 2 Nk , (3.4.9) and at constant pressure: CP = T ( ∂S ∂T ) P,N = 5 2 Nk . (3.4.10) Exercise 4.3 Prove (3.4.9) and (3.4.10). Solution on page 310 Exercise 4.4 Use the partition function to obtain the average internal energy. How is it related to the speciﬁc heat? Solution on page 311 4.2 Mixtures of ideal gases Dalton’s law Consider a system which is a mixture of M gases, i.e. there are M groups of particles, with diﬀerent masses, for instance. In group number j there are Nj particles, of mass mj. The whole mixture is conﬁned to a box of volume V . The energy of the system is given by Eq. (3.4.1), written in a slightly diﬀerent form. In group number j particle number i will have energy ϵij. 264 Ch. 4 Statistical Mechanics of an Ideal Gas The energy of the jth group will be given by the sum over i of ϵij,from 1to Nj. Therefore, the total energy will be E = M∑ j=1 Nj∑ i=1 ϵij . (3.4.11) All particles of all gases share the same constraint, namely they are con- ﬁned to the box. The diﬀerence is in the kinetic energies: Every particle in group number j, which has momentum p, has kinetic energy p2/2mj . The ﬁrst result that we can deduce is that instead of (3.4.3), Zc =(z1) N1 (z2) N2 · ... · (zM ) NM . (3.4.12) Equation (3.4.12) has a correction in Chap. 5 — Eq. (3.5.4). Exercise 4.5 Prove (3.4.12). Solution on page 311 Hence the free energy, (3.4.6), is replaced by F = −kT (N1 ln z1 + N2 ln z2 + ... + NM ln zM ) . (3.4.13) As we observed, the diﬀerence between the diﬀerent zj is only in the particles’ mass. That is, zj = V (2πmjkT ) 3/2 . (3.4.14) Substitutingin (3.4.13), we obtain F = −kT { N1 [ ln V + 3 2 ln(2πm1kT ) ] + N2 [ ln V + 3 2 ln(2πm2kT ) ] + ··· + NM [ ln V + 3 2 ln(2πmM kT ) ]} = −kT  N ln V + 3 2 M∑ j=1 Nj ln(2πmjkT )   , (3.4.15) where wehaveusedthe fact that M∑ j=1 Nj = N, 4.3 Maxwell Boltzmann distribution and equipartition 265 which is the total number of particles. From the expression for F it is possible to obtain the pressure, as in (3.4.7): P = − ( ∂F ∂V ) T,N = (N1 + N2 + ... NM )kT V = NkT V . (3.4.16) That is, the pressure depends only on the total number of particles in the container and not on the number of particles of each type. However, note the form of the intermediate expression in (3.4.16). This expression is the sum of the pressures of each of the constituents had it ﬁlled the container alone: P = M∑ j=1 Pj ,Pj = NjkT V . (3.4.17) This is Dalton’s law: The total pressure of the mixture is equal to the sum of the partial pressures. See also Exercise 1.5 of Part I. Exercise 4.6 Show that the speciﬁc heat of the mixture is the sum of partial speciﬁc heats. Isthistrueofthe entropy? Solution on page 312 4.3 Maxwell Boltzmann distribution and equipartition In Chap. 1 we have shown that the central relations of thermodynamics can be fully identiﬁed in statistical mechanics. Were we to ask a similar question with respect to the possibility of identifyingthe kinetic theory of gases in the formulation of statistical mechanics, we would not be able to answer in the same generality, since the validity of the kinetic theory is not general but is restricted to dilute gases. It is to be expected that the central results of the kinetic theory be derivable from the statistical mechanics of ideal gases. We shall treat, therefore, an ideal gas that can reside in an external potential ﬁeld U (r). First, we discuss the momentum and position distributions of a single particle. Without limitingthe generality of our discussion, we choose par- ticle number 1. The general distribution of the system’s states is given by (3.4.2), after normalization. In other words, the (joint) probability for par- ticle number 1 to be in dV1dτ1 around (r1, p1), and for particle number 2 to 266 Ch. 4 Statistical Mechanics of an Ideal Gas be in dV2dτ2 around (r2, p2), and so forth, is P (r1, p1; ... ; rN , pN )dV1dτ1dV2dτ2 ... dVN dτN = Z −1 c e −βϵ(r1,p1)e −βϵ(r2,p2) ... e −βϵ(rN ,pN ) ×dV1dτ1dV2dτ2 ... dVN dτN . (3.4.18) Clearly, if we sum the probabilities over all the particle states, namely integrate P over all 6N variable, we will obtain 1. In order to obtain the probability for a given particle (say, number 1) to be in dV1dτ1 around (r1, p1), we must allow all the other particles to be in the whole volume and to possess every possible momentum. Namely, P (r1, p1)= ∫ P (r1, p1; ... ; rN , pN )dV2dτ2 ... dVN dτN . (3.4.19) Exercise 4.7 Prove that P (r1, p1) is a normalized probability distribution. Solution on page 313 In order to calculate P (r1, p1) and to obtain its explicit form, we shall use the fact that the partition function satisﬁes Zc = zN c , so that the right hand side factors into a product of P (r1, p1; ... ; rN , pN )= e−βϵ(r1,p1) zc ... e−βϵ(rN ,pN ) zc . (3.4.20) Thus the integration in (3.4.19) over the N − 1 vectors of position and momentum, of particles 2,... ,N , will factor into a product of N − 1 identical integrals of the form z−1 c ∫ exp[−βϵ(r, p)]dV dτ =1 . (3.4.21) Henceweobtain P (r1, p1)= z−1 c exp { −β [ p2 1 2m + U (r1) ]} , (3.4.22) which is the Maxwell–Boltzmann distribution formulated in terms of mo- menta. [Cf. Eq. (1.1.50).] Another result of the kinetic theory is easily obtained here. This is the equipartition theorem: every variable of phase space on which theequipartition theorem energy depends quadratically, contributes 1 2 kT to the average energy (the 4.3 Maxwell Boltzmann distribution and equipartition 267 variable may be any component of the coordinate or of the momentum of any particle). We have used this theorem without proof in Sec. 1.3 of Part I, referring to the proof to be given here, and to the conclusion to be derived from it. Proof: Let us calculate the average energy contributed by one of the momentum components, p1x, for instance. p1x represents here a variable that appears in the expression for the energy in the form ap2 1x and does not appear anywhere else. The total energy of the state is written therefore as the sum E = ap2 1x + E′ , (3.4.23) where E′ is the rest of the energy and it depends on all the variables of phase space except p1x. We have chosen the momentum as an example because it usually appears in the energy as a separate quadratic term. The constant a is then of course 1/2m. A quadratic dependence of the energy upon the coordinates is less common, and is characteristic only of a harmonic potential. Now, since p1x appears in the energy only once, its probability distri- bution function is proportional to exp(−βap2 1x). It is of course possible to obtain this by integrating the total distribution function over all variables except p1x. The average energy corresponding to p1x is thus ⟨ap2 1x⟩ = ∫ dp1x exp(−βap2 1x)ap2 1x∫ dp1x exp(−βap2 1x) . (3.4.24) Exercise 4.8 Derive (3.4.24) directly from the distribution function in phase space. Solution on page 313 We have already calculated expressions such as the one on the right hand side of (3.4.24) many times (see, for example, Exercise 3.2), and the result is indeed 1 2 kT , as the theorem asserts. Finally we note that, as we have already seen in Solution 4.8, the equipartition theorem is valid for every system provided that we can iden- tify a variable that satisﬁes Eq. (3.4.23). A good example of such a variable is the momentum of an atom of a gas molecule. If the forces acting be- tween this atom and the other atoms are independent of its momentum, then the conditions of the theorem are satisﬁed, and thus the average ki- netic energy of each atom in the molecule is given by the equipartition theorem, namely 1 2 kT per component and a total of 3 2 kT .This was the answer we gave to question (a) in Sec. 1.3 of Part I, and here at last it is justiﬁed. 268 Ch. 4 Statistical Mechanics of an Ideal Gas 4.4 Ideal gas of quantum particles In our discussion of the ensemble of harmonic oscillators in Chap. 2, we treated them as a quantum system but we also dealt with the question of the behavior of an ensemble of classical oscillators. The result is that the classical behavior is obtained from the quantum results in the limit of high temperatures. On the other hand, our discussion of ideal gases has so far completely ignored the possible quantum aspects related to the particle’s motion in the container. We would therefore end this chapter by consideringthe eﬀects that the quantization of energy has on the ideal gas laws. We shall see that apart from a new point of view, the addition of quantization does little, and we obtain again the ideal gas equation (3.4.7).➤➤∞ U –a/2 a/2 ∞ x Fig. 3.4.1 A potential well with height tending to inﬁnity. In light of all our experience so far, it is clear that our problem comes down to calculatingthe partition function of a single particle of mass m that is conﬁned to a container of volume V . For the sake of simplicity we assume that the container is a box of sides a, b and c. The particle’s conﬁnement to the box can be described by a potential that vanishes inside the box and jumps to inﬁnity at the walls. Because the motion of the particle occurs in three independent directions, we start by considering the simple case of a particle executinga one-dimensional motion in an “inﬁnite potential well,” as in Fig. 3.4.1. Then we pass on to the three- dimensional case, just as we did in Chap. 2 in our discussion of the Einstein solid. The quantum states of a particle movingin such a potential are described by standingde Broglie waves that vanish on the sides of the well, x = ±a/2. The allowed wavelengths are quantized according to λn = 2a n ,n =1, 2, 3,... , (3.4.25) 4.4 Ideal gas of quantumparticles 269 and the correspondingenergy values are thus ϵn = h2n2 8ma2 ,n =1, 2, 3 ... , (3.4.26) where m is the particle’s mass and h is the Planck constant. The particle’s states in the well are thus characterized by a natural number n similarly to the states of the harmonic oscillator. The diﬀer- ence is of course in the dependence of ϵ on n. The particle’s motion in the three-dimensional box can be considered as a sum of three indepen- dent one-dimensional motions each takingplace inside a well as the one depicted in Fig. 3.4.1. Thus, the condition (3.4.25) must be satisﬁed in- dependently in each of the directions, and to each direction of motion there will correspond a natural number of its own. The energy values will thus be ϵnpq = h2 8m (n2 a2 + p2 b2 + q2 c2 ) , n,p,q =1, 2, 3,... , (3.4.27) which means that a single particle state in a well is determined by three natural numbers (n, p, q). The next step is of course the calculation of the single particle partition function: z = ∑ npq exp(−βϵnpq) = ∞∑ n=1 exp ( − βh2n2 8ma2 ) ∞∑ p=1 exp ( − βh2p2 8mb2 ) ∞∑ q=1 exp ( − βh2q2 8mc2 ) . (3.4.28) Note again that owing to the independence of the motions in each of the three dimensions, the partition function has factored to a product of three one-dimensional partition functions. We are left with the calculation of a one-dimensional partition func- tion, and we choose the motion alongthe x direction: zx = ∞∑ n=1 exp ( − βh2n2 8ma2 ) . (3.4.29) Calculatingthe sum on the right hand side of (3.4.29) is no simple matter. Fortunately we are mostly interested in the case in which the box is much larger than the thermal de Broglie wavelength, λT , of the atoms of the gas. This quantity is the wavelength, λT , of a gas particle with momentum determined by the average thermal kinetic energy per degree of freedom, 270 Ch. 4 Statistical Mechanics of an Ideal Gas kT /2. If we use the de Broglie relation px = h λ , (3.4.30) then from p2 x/2m = kT /2wehave λT = √ h2 mkT . (3.4.31) Exercise 4.9 (a) Helium atoms are conﬁned to a box with a = 1 cm. Calculate λT /a at 10 K and at 300 K. (b) At what temperature does λT become comparable to the size of the box? Solution on page 314 The exponent in the terms of the sum in Eq. (3.4.29) can be written as λ2 T n2/8a2.Since λT /a is very small, the diﬀerence between successive terms in this sum is also very small and the sum can be approximated by an integral, as we now explain. The terms in the sum can be regrouped as follows: deﬁne a variable s = λT 2a n,where n is the runningindex in the sum. Even in a small interval ∆s there is a very large number of terms of the sum (diﬀerent values of n), since the corresponding∆n = 2a λT ∆s is made large by the enormous value of a/λT . See Exercise 4.9. In each interval ∆s, the terms of the sum are equal to a very good approximation. The sum can therefore be written as zx = ∑ s e − 1 2 s2 ( 2a λT ) ∆s −−−−→ ∆s→0 2a λT ∫ ∞ 0 e − 1 2 s2ds . (3.4.32) The limit in the above equation is the deﬁnition the Riemann integral. Converting s into a momentum variable, via Eq. (3.4.25) and the de Broglie relation (1), we write s = λT λn = λT px h and zx becomes zx = 2a h ∫ ∞ 0 exp ( − λ2 T p2 x 2h2 ) dpx = a h ∫ ∞ −∞ exp ( − βp2 x 2m ) dpx , (3.4.33) where the last transition has been made with the help of the fact that the integrand is an even function. Although px wasdeﬁned asa positive 4.4 Ideal gas of quantumparticles 271 quantity (since n is positive), we have found that the sum over the positive values of n is equivalent to an integral over all values of px, positive as well as negative. That means that a state with a given n is equivalent to two momentum states: one positive and one negative. Hence the partition function of a single quantum-mechanical particle in the three-dimensional box will be [within the approximation which led to (3.4.32) and (3.4.33)] a product of one-dimensional partition functions: z = zxzyzz = abc h3 ∫ ∞ −∞ exp ( − βp2 x 2m ) dpx ∫ ∞ −∞ exp ( − βp2 y 2m ) dpy ∫ ∞ −∞ exp ( − βp2 z 2m ) dpz = V h3 ∫ exp ( − βp2 2m ) d 3p. (3.4.34) In the last transition we have used the fact that the product abc is the volume of the box V , as well as the fact that the product of the three integrals can be written as a three-dimensional integral over all momen- tum space. We have also used the notation d3p = dpxdpydpz instead of dτ . The integral on the right hand side of (3.4.34) is the same integral that appeared in the calculation of the classical partition function, e.g. Eq. (3.4.4) and Exercise 4.2. The quantum-mechanical point of view does not change, therefore, the classical result except for makingthe partition function dimensionless by introducingthe Planck constant, which possesses precisely the dimen- sions required for this purpose. See the remark after Eq. (3.3.19) as well. However, we must stress that what we have done here is restricted to the quantum eﬀects due exclusively to the quantization of the motion of a single particle. As we shall see in Part V, quantum mechanics requires ad- ditional changes that are expressed by the fact that the canonical partition function of an ideal gas cannot be written as the product of independent single particle partition functions. These changes lead to fundamental changes in the laws of ideal gases at low temperatures and/or high den- sities. At regular conditions the results we shall obtain in Part V reduce to the results of the classical treatment, so that all our discussions on ideal gases in this part remain valid in a very wide region of densities and temperatures. Finally, we make several remarks. (a) The fact that we have again obtained the classical partition func- tion should not come as a great surprise, since we calculated the sum in (3.4.28) only in the approximation that the thermal de Broglie 272 Ch. 4 Statistical Mechanics of an Ideal Gas wavelength is very small or, in other words, in the limit in which quan- tum eﬀects are negligible. This is also the limit of high temperatures. (b) Indeed, we obtained (3.4.34) for a box-shaped container, but in fact it is clear that the result cannot depend on the container’s shape as long as the volume is large enough. Hence this result is valid for any shape of the container, precisely as in the classical case. (c) Concerningthe partition function’s dependence on the volume: In Sec. 4.1 we have seen that the volume dependence of the partition function of a classical gas enters through the integration limits. Con- versely, the energies of the quantum states depend explicitly on the volume through the dimensions of the box [Eq. (3.4.27)]. Thus the re- lationship between the thermodynamic work and the volume change, found in Sec. 1.2, is now simpler to analyze and the longdiscussion made there for the calculation of ∂E/∂V in the classical case becomes redundant. Exercise 4.10 Obtain δW arisingfrom a volume change dV of a cube-shaped vessel that contains an ideal gas of quantum particles. Solution on page 314 (d) From the result (3.4.34) it is inferred that also in the quantum case it is possible to formulate the partition function in terms of the classical variables of phase space — position and momentum. Moreover, the canonical probabilities are of the same form as in the classical case. The diﬀerence is that the quantum partition function is in principle a discrete sum and not a continuous integral. Instead of (3.4.28) we may therefore write a sum over cells in phase space: z = ∑ k exp ( − βp2 k 2m ) ∆Vk∆τk h3 , (3.4.35a) where the factor ∆Vk∆τk/h3 describes the number of states (and not their density) in cell number k. This implies that a quantum state of a single particle takes up a volume of h3 in phase space. Hence the quantum state of a system of N particles will take up a volume of h3N . In the classical calculation of Z thesizeof the cellcould be arbitrarily small. Here it must contain at least one quantum state. However, the volume of the cell must still be small enough for the continuum approximation of the sum as an integral to be valid. In this case we can, therefore, turn (3.4.35a) into an integral, and if the 4.4 Ideal gas of quantumparticles 273 particles are aﬀected by an external potential U (r), we obtain for the single particle partition function z = 1 h3 ∫ dV dτ exp { −β [ p2 2m + U (r) ]} . (3.4.35b) This equation is identical to (3.3.8) except for the factor h−3.This is the classical limit of the quantum partition function, and the sole witness to the quantum origin of (3.4.35b) is the factor h−3.Instead of (3.3.19) and (3.3.21) we obtain, therefore, Z = ∫ ( dV dτ h3 )N e −βE(ri,pi) , (3.4.36a) ⟨A⟩ = 1 Z ∫ ( dV dτ h3 )N A(ri, pi)e −βE(ri,pi) . (3.4.36b) (e) The astute reader has probably noticed that in the equations we ob- tained for the free energy and the entropy [(3.4.6) and (3.4.8)] there is a mismatch of units and as a consequence the logarithmic functions appearingin them are not functions of dimensionless arguments. This mismatch stems from the fact that the classical partition function (3.4.4) or (3.4.5) is not dimensionless. The quantum partition func- tion, in contrast, is naturally dimensionless even in the classical limit, as is clear from Eqs. (3.4.35) and (3.4.36), owingto the appearance of the Planck constant in the expression for the volume element in phase space. Usually, this diﬀerence is not signiﬁcant as most thermody- namic quantities are obtained from derivatives of the free energy and entropy, so that the additional terms dependingon Planck’s constant cancel out and disappear. However, this is not always the case, and, moreover, the equations are more “aesthetic” when the logarithmic functions have dimensionless arguments. Thus, from now on we shall write z = V (2πmkT )3/2 h3 (3.4.37) so that F = −NkT ln z = −NkT [ ln V + 3 2 ln ( 2πmkT h2 )] , (3.4.38) S = Nk [ ln V + 3 2 ln ( 2πmkT h2 ) + 3 2 ] . (3.4.39) 274 Ch. 4 Statistical Mechanics of an Ideal Gas We have written ln z as a sum of logarithmic functions, the same as before, but it is always possible to turn these sums into logarithmic functions of a product of dimensionless variables. This is the ﬁrst correction to the form of the free energy and entropy of an ideal gas. In the next chapter we shall see that another correction is required.Chapter 5 The Gibbs Paradox and the Third Law 5.1 Two diﬃculties (a) Extensivity In thermodynamics, the free energy and entropy are extensive quantities. This means that doublingthe system leads to a doubling of the free energy and the entropy. If we now check the expressions obtained for F and S, (3.4.38) and (3.4.39), we ﬁnd that they are not extensive since when V → 2V and N → 2N we obtain F → 2F − 2NkT ln 2 , S → 2S +2Nk ln 2 . This problem, whose solution we discuss in the followingsection, is known as the Gibbs paradox. The same problem appears in a diﬀerent guise in the chemical poten- tial. As recalled [Eq. (3.1.43)], the chemical potential is the derivative of the state function with respect to the number of particles, and must be an intensive variable, i.e. independent of the system’s magnitude. But, calculatingit from (3.4.38) we obtain µ = −kT [ ln V + 3 2 ln ( 2πmkT h2 )] , (3.5.1) which is not an intensive quantity. (b) The third law of thermodynamics One way of statingthe third law of thermodynamics is that the entropy tends to zero as T → 0. (See e.g. Part II, Sec. 0.4) Not only does the entropy Eq. (3.4.39) not tend to zero, it diverges when T → 0. We return 275 276 Ch. 5 The Gibbs Paradox and the Third Law to this problem in Sec. 5.3. Here we only note that this problem ﬁnds its solution in the framework of the quantum theory. Exercise 5.1 Both problems mentioned here do not appear in calculatingthe properties of the paramagnet or of the Einstein solid. Verify this. Solution on page 314 5.2 The Gibbs paradox and its resolution The ﬁrst diﬃculty mentioned in the precedingsection was presented in a dry, formal manner: The entropy of an ideal gas, as obtained from classical statistical mechanics, is not an extensive quantity. But the same problem can be presented in a more intuitive manner. ➤➤ ➤➤➤➤ 2V VV N T N T Fig. 3.5.1 The double container and the Gibbs paradox. Imagine a container divided into two identical parts by a partition (Fig. 3.5.1). On both sides of the partition there is the same number of identical particles and the same temperature. We perform an experiment in which the partition is removed. Such a process is deﬁnitely reversible. The removal of the partition will not change the temperature, and there is no reason for the number of particles to change on either side. Hence, accordingto thermodynamics, the entropy should not change upon the removal of the partition. But the entropy in the presence of the partition is the sum of the entropies of the two sides, which is given by twice (3.4.39), S =2Nk [ ln V + 3 2 ln ( 2πmkT h2 ) + 3 2 ] , (3.5.2a) 5.2 The Gibbs paradox and its resolution 277 but in the absence of the partition, the entropy is obtained from (3.4.39) by replacing V and N with 2V and 2N : S′ =2Nk [ ln 2V + 3 2 ln ( 2πmkT h2 ) + 3 2 ] . (3.5.2b) Hence there is a change in entropy, given by ∆S =2Nk ln 2 ̸=0 , which is the paradox. It is not hard to ﬁnd the origin of the paradox. To this end we shall change the conditions a bit, and assume that there is a diﬀerent type of gas on each side of the partition, but the volumes, the temperatures and the numbers are identical. Removingthe partition this time is not a reversible process, since clearly particles of one type will cross over to the other side and vice versa. The gases will get mixed, and returning the partition to its place will not return the system to its original state. It is, of course, not surprisingthat removing the partition leads to an increase in the entropy. The increase in the entropy is related to the mixing, which increases the disorder. Exercise 5.2 Describe a process by which it is possible to separate two types of mole- cules, each to its original side of the partition. Does this process return the system to its original state? Solution on page 315 It turns out, therefore, that there exists a contradiction between (a) our feelingthat returning the partition to its place, in the case of identical gases on both sides of the container, returns the original state, and (b) the fact that we treat the particles as if it were possible to dis- tinguish between them. Indeed, it is clear that upon the removal of the partition, particles cross from one side to the other, and that upon its return the particles on both sides will not be the same ones as before. Since we stand by (a), based on experience, we have no option but to give up (b). If indeed it is not possible to distinguish between molecules (or atoms) of the same gas, so that doublingthe volume is simply doublingthe en- tropy, then we have not calculated the partition function, Z, correctly. When we integrate over the position and momentum of each of the molecules, alongwith each state there also appears the state in which two molecules have interchanged their position and momentum. In the 278 Ch. 5 The Gibbs Paradox and the Third Law integration, each molecule covers the entire volume, and its momentum assumes all allowed values. Hence, in countingdiﬀerent states in Z there appears the state in which particle number i is in state (ri, pi)and par- ticle number j in (rj, pj), as well as the state in which particle number j has (ri, pi) and particle number i has (rj, pj). In Fig. 3.5.2 two states are depicted, diﬀeringfrom each other only in a permutation of two particles.➤➤➤➤ pj rj pj rj pi ri pi rij i i j Fig. 3.5.2 Two states diﬀering only by the permutation of two particles. But if there is no way of distinguishing between these particles, then two such states must be counted as a single state. This means that we have counted too many states in Z. Alongwith every state (r1, p1; ... ; rN , pN ) there appear all the states in which all the particles have the same list of coordinates and momenta, but the order of particles is diﬀerent. Namely, each microscopic state (r1, p1; ... ; rN , pN )mustbe identiﬁed with the N ! states obtained by changing the order of the particles. Fortunately it is very easy to correct the mistake: two states diﬀering from each other only by changing the position of the particles have the same energy, and hence the same probability. In each microscopic state it is possible to change the positions of the particles in N !ways, where the velocities remain unchanged. Each of these N ! states, which are to be counted as a single state, has contributed to the partition function, as calculated so far, whereas there should have been only one contribution due to all of them. But since all N ! terms are equal, and all terms in the canonical partition function have an equal number of particles, it suﬃces to divide by N ! in order to obtain the corrected partition function. Thus, instead of (3.4.3) we write Z = 1 N ! zN (3.5.3) and instead of (3.4.12) we write Z = (z1)N1 N1! · (z2)N2 N2! · ... (zM )NM NM ! (3.5.4) 5.2 The Gibbs paradox and its resolution 279 in the case where there are M groups of molecules, and it is not possible to distinguish between molecules belonging to the same group, but it is possible to distinguish between molecules of diﬀerent groups. The concept of a microscopic state has thus undergone a signiﬁcant change following this discussion. We can continue to denote a state by the 2N vectors (r1, p1; ... ; rN , pN ) but this notation does not signify that particle number 1 is located at r1 with momentum p1, etc., but the fact that there is one particle in position r1 with momentum p1,etc. Inorder to calculate the partition function employingthe methods that we devised, we imagine that it is possible to distinguish between particles and then correct, dividingby N !. Exercise 5.3 Show that the above change does not aﬀect the calculation of thermal averages. Solution on page 316 Exercise 5.4 Deduce Eq. (3.5.4). Solution on page 317 Exercise 5.5 Explain why there is no need to correct the partition function of the paramagnet and the system of oscillators. Solution on page 317 What will the form of the free energy and entropy be? Well, after substituting(3.5.3) into (3.1.30) and usingthe explicit form of the single particle partition function (3.4.37), we obtain F = −NkT [ ln V + 3 2 ln ( 2πmkT h2 ) − 1 N ln N ! ] . (3.5.5) In the thermodynamic limit, when N is very large, we can approximate the last term on the right hand side of (3.5.5) using Stirling’s formula (2.3.12) to write 1 N ln N ! ≃ ln N − 1 , (3.5.6) and hence Eq. (3.5.5) reduces to F = −NkT [ ln ( V N ) + 3 2 ln ( 2πmkT h2 ) +1 ] . (3.5.7) 280 Ch. 5 The Gibbs Paradox and the Third Law The entropy is derived from the newly found F and instead of (3.4.39) we obtain S = Nk [ ln ( V N ) + 3 2 ln ( 2πmkT h2 ) + 5 2 ] , (3.5.8) both of which are of course extensive, as expected. It is important to note that even though we have shown in Exercise 5.3 that the change in the partition function, (3.5.3), does not aﬀect the thermal averages, the free energy F ,the entropy S and the chemical potential µ (see below) all change. This implies that these quantities cannot be expressed as averages. Exercise 5.6 Prove, by usingthe free energy and the entropy, that the pressure and the speciﬁc heat are not aﬀected by Gibbs’ correction. Solution on page 317 We can also write the chemical potential that replaces (3.5.1). The result is µ = kT [ ln n − 3 2 ln ( 2πmkT h2 )] , (3.5.9) where n (= N/V ) denotes the number of particles per unit volume. This is, of course, an intensive expression. Exercise 5.7 Deduce Eq. (3.5.9). Solution on page 318 And, ﬁnally, in a mixture of M diﬀerent types of molecules, F = −kT M∑ j=1 Nj [ ln ( V Nj ) + 3 2 ln ( 2πmjkT h2 ) +1 ] . (3.5.10) Exercise 5.8 Prove that Dalton’s law remains valid regardless of the changes in F . Solution on page 318 Exercise 5.9 Calculate the expression for the entropy of a mixture of gases. Solution on page 319 5.3 The third law of thermodynamics 281 Exercise 5.10 What is the change in entropy due to the removal of the partition if in Fig. 3.5.1 there are diﬀerent types of gases on both sides of the partition? Consider the case in which the number of molecules and the volume on each side are diﬀerent. Solution on page 319 5.3 Remarks on the third law of thermodynamics The macroscopic formulation of the third law of thermodynamics — Nerst’s law — is sometimes presented in the followingform: It is im- possible to cool a system down to absolute zero. And sometimes in the followingequivalent form: The entropy of a system at zero temperature does not depend on the parameters that characterize the system’s equi- librium state. The assertion that the two forms are equivalent relies on the fact that if the entropy depends on external parameters, it is possible to continue adiabatic coolingand to lower its temperature in ﬁnite steps, even near absolute zero. We have already seen that the entropy we obtained for an ideal gas, (3.4.39), does not obey this law. The corrected entropy accordingto Gibbs, (3.5.8), is no better in this sense. A hint of the direction in which we have to search for the answer is the fact that in a system at low temperatures quantum eﬀects must be taken into account. This hint is supported by the fact that the entropy of the Einstein solid, derived in Exercises 2.5 and 2.6, goes to zero quite fast as T → 0. Consider, therefore, the entropy of a quantum system at temperatures tendingto zero. The fact that the system is quantum-mechanical is expressed by the fact that the microscopic energies of the system are discrete. We denote by Ei the energy of the microscopic state i. Of course, there can be many microscopic states with the same energy. Such a state of aﬀairs is called a degeneracy, and the number of microscopic states with energy E is degeneracy denoted by g(E), and called the “degree of degeneracy,” or simply the number of states at energy E. In Chap. 6 of Part II we saw [Eq. (2.6.7)] that the entropy can be writteninthe form S = −k ∑ i Pi ln Pi , (3.5.11a) 282 Ch. 5 The Gibbs Paradox and the Third Law where Pi = e−βEi ∑ n e−βEn (3.5.11b) is the probability of the microscopic state i. If E0 is the system’s lowest energy, we can also write Pi in the form Pi = e−β(Ei−E0) ∑ n e−β(En−E0) . (3.5.12) Thus for each state not correspondingto the lowest energy, Ei >E0, we ﬁnd in the limit T → 0(β →∞)that Pi → 0, because Ei − E0 is positive. There is, of course, one exception: the states for which Ei = E0. For these states we ﬁnd in the limit T → 0that Pi → 1/g0,where g0 is the degeneracy of E0, i.e. the number of diﬀerent microscopic states with energy E0. This is so since for these states the numerator in (3.5.12) is unity whereas the denominator contains, in addition to the sum of zeros, g0 terms each contributingunity, and a total of g0 in all. We have, therefore, obtained Pi = { 0 ,Ei ̸= E0 ,T → 0 , 1/g0 ,Ei = E0 ,T → 0 . (3.5.13) Now, we can calculate the entropy in the limit T → 0 by direct substitu- tion in (3.5.11a): S → k ln g0 ,T → 0 . (3.5.14) Exercise 5.11 Prove Eq. (3.5.14). Solution on page 319 If the degeneracy of the ground state is not too large, and this is the common case, S/k tends to a value of order unity when T → 0. Such a value is negligible compared to the typical values of S/k at temperatures above absolute zero which are of order N (since S is extensive and pro- portional to N ), and hence we can say that S tends to 0, in such common systems, when T → 0. In doingthis we have identiﬁed the microscopic, statistical source of the third law. We immediately identify two exceptions to the third law: (1) Classical systems, in which Ej − E0 can be arbitrarily small. In such systems when T → 0, or β →∞,there always exists a j such that β(Ej − E0) will be ﬁnite, and then (3.5.13) will no longer be valid, nor will (3.5.14). This actually happens in an ideal gas; see Eq. (3.5.8). 5.4 Summary 283 (2) Quantum systems, in which the degeneracy of the ground state is very high, so that the right hand side of (3.5.14) is of the order of the number of the system’s degrees of freedom. Exercise 5.12 Calculate the entropy of a system of N classical three-dimensional har- monic oscillators (“classical Einstein solid”), and show that it diverges at T → 0 and that quantum considerations “save the situation.” A similar phenomenon occurs in a classical paramagnet (see Self- Assessment Exercise 8). Solution on page 320 5.4 Summary As a result of Gibbs correction we obtain for an ideal gas z = V (2πmkT )3/2 h3 , Z = 1 N ! zN , F = −NkT [ ln ((2πmkT )3/2 nh3 ) +1 ] , S = Nk [ ln ( (2πmkT )3/2 nh3 ) + 5 2 ] , µ = −kT ln [ (2πmkT )3/2 nh3 ] . In spite of the appearance of Planck’s constant, these results are valid only as long as quantum eﬀects are negligible, i.e. far enough from absolute zero. Chapter 6 Fluctuations and Thermodynamic Quantities So far we have assumed in all the calculations that the distributions of the physical quantities are very narrow around the average so that, at thermodynamic equilibrium, these variables always obtain their values at the maximum of the distribution. To justify this assumption, be- yond the pictorial justiﬁcation given in Secs. 3.3 and 4.1–4.3 of Part II, we shall discuss deviations from the average of two typical quantities, the magnetization and the energy, and demonstrate that indeed the rel- ative width of their distributions tends to zero in the thermodynamic limit. 6.1 Paramagnet: ﬂuctuations in the magnetization The average magnetic moment of a paramagnet at equilibrium with a heat bath at temperature T is ⟨M ⟩ = 1 Z ∑ i Mie −βEi = 1 β ∂ ln Z ∂H , (3.6.1) where Mi is the magnetization in the microscopic state i and Ei is the energy of that state [see (2.5.8) and Exercise 5.2 of Part II]. The magnetization varies with the magnetic ﬁeld H.Namely, ⟨M ⟩ is a function of H. The derivative of ⟨M ⟩ with respect to H is the suscep- tibility, χ = 1 N ∂⟨M ⟩ ∂H . (3.6.2) This quantity measures the ease with which the magnetization (per spin) can be aﬀected by varyingthe ﬁeld. It is an example of a whole family ofresponse coeﬃcient quantities that are known as response coeﬃcients. 284 6.1 Paramagnet: ﬂuctuations in the magnetization 285 Equation (3.6.2) is a generalization of the deﬁnition (2.5.15), which was given for small H,where ⟨M ⟩ is a linear function of H.Note: N was denoted there by n. Clearly, when χ is large, small changes in H will lead to large changes in ⟨M ⟩. It is then to be expected that the distribution of M around the average is not narrow. In other words, states with diﬀerent M ’s do not diﬀer signiﬁcantly in their probabilities. Thus one expects that the deviations around the average will be signiﬁcant. Namely, there must be a relationship between the susceptibility and the width of the distribution of M , around the average ⟨M ⟩. This is indeed the case. It turns out that χ is proportional to the average square deviation of M from its average. In order to establish this, we recall that the energy of the microscopic state Ei in (3.6.1) is Ei = −HMi . (3.6.3) Hence, diﬀerentiating(3.6.1) with respect to H we obtain for χ in (3.6.2) Nχ = ∂⟨M ⟩ ∂H = β Z ∑ i M 2 i e −βEi − 1 Z 2 ∂Z ∂H ∑ i Mie −βEi = β(⟨M 2⟩− ⟨M ⟩ 2) and hence Nχ = β⟨(M −⟨M ⟩) 2⟩ = (∆M )2 kT . (3.6.4) Except for the temperature factor, the right hand side measures the av- erage square deviation of the magnetization from its average value. The larger the square deviation, the larger the susceptibility, and vice versa. The quantity ∆M ≡ √ (∆M )2 is also called the ﬂuctuation of M .In ﬂuctuation the language of probability theory, ∆M is the standard deviation of the distribution of M and (∆M )2 is its variance. See also Exercise 3.5 of Part II. Equation (3.6.4) leads to several important conclusions: (a) The susceptibility of a paramagnet must be positive: (∆M )2 is the average of a positive quantity, and hence χ is positive. (b) The relative width of the distribution of the magnetization, namely ∆M/⟨M ⟩, tends to zero in the thermodynamic limit (N →∞), which justiﬁes the assertion that M is always at its average value, ⟨M ⟩. 286 Ch. 6 Fluctuations and Thermodynamic Quantities In order to show that conclusion (b) is indeed valid, we write ∆M ⟨M ⟩ = √ NkT χ ⟨M ⟩ = √ kT χ ⟨µB⟩ · 1 √ N , (3.6.5) where ⟨µB⟩ denotes the average magnetization per spin (Chap. 4, Part II) and we use Eq. (2.2.15), ⟨M ⟩ = µBN ⟨σ⟩.This means that if χ is ﬁnite, then when N →∞, the width of the distribution tends to 0. A word of caution: For a paramagnet at H =0, ⟨σ⟩ =0 and the right hand side of Eq. (3.6.5) diverges. The diﬃculty is not very grave. In the presence of the smallest ﬁeld, ⟨M ⟩ becomes large, proportional to N . [See Eq. (2.5.14), Part II.] But even at H = 0 strictly, what we ﬁnd in Eq. (3.6.4) is that the standard deviation of M is of order √ N , while any thermodynamically signiﬁcant quantity is proportional to N . Hence, this width is irrelevant in the thermodynamic limit. We will meet a similar phenomenon in the next section, for the ﬂuctua- tions in energy, and see that they are proportional to the speciﬁc heat. In a paramagnet, the ﬂuctuations in energy are the same as the ﬂuctuations in the magnetization, because the two are proportional to each other. 6.2 Energy ﬂuctuations and the speciﬁc heat The relationship we found in the previous section between the ﬂuctuation in the magnetization and the susceptibility is one example of the rela- tionship between ﬂuctuations and response coeﬃcients. We will now see another example. The average energy in a canonical system is ⟨E⟩ = 1 Z ∑ i Eie −βEi = − ∂ ln Z ∂β , (3.6.6) which is, of course, extensive. The speciﬁc heat (per particle) measures the energy’s responsiveness to change in the temperature. It is, therefore, a kind of susceptibility of the energy. c = 1 N ∂⟨E⟩ ∂T . (3.6.7) That is, the easier it is to change ⟨E⟩ by changing T , the larger is the speciﬁc heat and it is to be expected that the distribution around the average energy will be wider. We show this explicitly: Nc = ∂⟨E⟩ ∂T = 1 kT 2 (⟨E2⟩− ⟨E⟩ 2) , 6.3 Summary 287 and from here Nc = (∆E)2 kT 2 . (3.6.8) We have found, therefore, that the ﬂuctuations in energy are proportional to the response of the energy to changes in the temperature, namely to the speciﬁc heat, just as the ﬂuctuations in the magnetization are proportional to the response of the magnetization to changes in the magnetic ﬁeld, namely the susceptibility. Exercise 6.1 Complete the deduction of (3.6.8). Solution on page 321 We obtain again a similar dependence as a function of N : ∆E ⟨E⟩ = √ NckT 2 N ⟨ϵ⟩ = √ ckT ⟨ϵ⟩ · 1 √ N , (3.6.9) where ∆E = √ (∆E)2 and ⟨ϵ⟩ is the average energy per degree of freedom. That is, the speciﬁc heat is positive, like the susceptibility, and its ﬂuctu- ations increase with the speciﬁc heat, as expected. In the thermodynamic limit (N →∞) the width of the distribution becomes negligible compared to the average. Almost all of the systems in the canonical ensemble have the same energy, ⟨E⟩. From here also it is inferred that the canonical description is equivalent to the microcanonical description. Exercise 6.2 Calculate the relative energy ﬂuctuation of an ideal gas ∆E/E. Solution on page 321 6.3 Summary (a) The ﬂuctuation of an extensive thermodynamic quantity is propor- tional to the response of this quantity to changes in its conjugate variable. (b) As a result of this relationship it is possible to directly measure the ﬂuctuation. (c) All the response coeﬃcients are positive. (d) In the thermodynamic limit, the widths of the distributions of exten- sive quantities become negligible with respect to the average values (except for extreme cases — a divergence of the response, or the van- ishingof the average). Self-assessment exercises Exercise 1 Solution on page 322 (a) Show that the Gibbs free energy,Gibbs free energy G = E − TS + PV , can be derived from the partition function by G = kT V 2 ∂ ∂V ( ln Z V ) . (b) Show that the enthalpy, H = E + PV , is given by H = 1 β (V ∂ ln Z ∂V − β ∂ ln Z ∂β ) . Exercise 2 Solution on page 322 What is the form of the partition function Z of a crystal, described by a model in which the harmonic oscillators have diﬀerent energies from one another? What is the expression for the free energy? Exercise 3 Solution on page 323 We deﬁne a bounded harmonic oscillator by energy levels like the ones given in Eq. (3.2.1), En = ϵ0 + nϵ , with the additional condition n<n0 . 288 Self-assessment exercises 289 (a) Calculate the average energy and the average degree of excitation of the bounded oscillator at temperature T . (b) Calculate the entropy and the speciﬁc heat of a bounded oscillator. (c) Compare with the harmonic oscillator. When can we expect, from qualitative considerations, a diﬀerence between the two, and when should they behave similarly. (d) What is the asymptotic behavior of the speciﬁc heat at low tempera- tures and at high temperatures? Exercise 4 Solution on page 325 The table below contains values of the speciﬁc heat of crystalline sodium. T (K) 1 2 4 6 8 10 12 16 20 25 CV (cal/mole · K) 0.0001 0.0009 0.0072 0.024 0.058 0.114 0.18 0.46 0.91 1.78 (a) The asymptotic behavior of CV of a solid in the Einstein model, at low temperatures, is given by (3.2.18): CV ≃ 3R ( ¯hω kT )2 e −¯hω/kT . Draw a graph of CV , as a function of kT /¯hω,and ﬁnd ΘE and ω using the value of CV at 10 K. (b) Use the graph from (a) to describe CV as a function of T for the ΘE =¯hω/k you obtained there. Add to the graph the experimental values given in the table. Is it possible to assert that the values in the table can be described by the graph? (c) Do the temperatures in the table justify a low temperature approxima- tion (namely, is T ≪ ΘE?)? Sketch a graph of the ratio CV (Einstein)/ CV (table) as a function of T . Exercise 5 Solution on page 326 In the Debye model (Part IV, Sec. 3.3) it is found that the speciﬁc heat per mole, at low temperatures, is given by CV = 12π4 5 R ( T ΘD )3 . 290 Self-assessment exercises Usingthe table from the previous exercise, determine ΘD from the value of CV at T =10 K. Draw in a single ﬁgure CV of the Debye approximation and CV of the Einstein approximation as a function of T ,for theΘD determined above, and the experimental values in the table. Exercise 6 Solution on page 327 Suppose that the followingexplicit formulas for the partition function were found (say, inanexcavation): (a) Z = V N (2πmkT ) 5N/2 , (b) Z =(V − Nb) N (2πmkT ) 3N/2e aN 2/V kT . For both cases calculate the equation of state and the speciﬁc heat at constant volume. From the results identify the systems described by these partition functions. Exercise 7 Solution on page 330 Calculate the average energy, the equation of state, and the speciﬁc heat of a gas of extremely relativistic particles satisfying ϵ = cp,where c is the speed of light. Exercise 8 Solution on page 331 Classical paramagnet: We return to the system of magnetic ions from Part II. This time we treat the magnetic moment of each ion as a classical vector, with constant magnitude, µ, which can point in any direction. Namely, the tip of the magnetic moment can point in any direction or, in other words, can be found at any point on a sphere. The summation over the diﬀerent states of the system goes over, nat- urally, to an integration over all the directions along which the magnetic moment can point (see ﬁgure). Such a direction is described by the two angles of the spherical system, θ and φ. The integration over all the di- rections is carried out usingthe fact that an inﬁnitesimal surface element on a sphere of radius R is given by da = R2 sin θdθdφ . Self-assessment exercises 291 ➤ ➤➤ ➤x y z φ θ µ (a) Write the energy of a system of N spins in a magnetic ﬁeld H directed alongthe z axis, as a function of the angles. (b) Calculate the canonical partition function. (c) Calculate the average magnetization, the average energy and the en- tropy. (d) Compare with the discrete paramagnet and show that the magnetiza- tion and the energy obtained are identical to the results of the discrete paramagnet in the limit where J →∞. (e) Does the third law of thermodynamics apply here? Exercise 9 Solution on page 334 (a) Show that the work performed by an ideal gas at temperature T as it expands from volume V1 to volume V2 is equal to the decrease ∆F in its free energy. (b) Is ∆F larger or smaller than the decrease in the internal energy of the gas? What is the origin of the diﬀerence? Exercise 10 Solution on page 334 (a) Calculate the speciﬁc heat of a paramagnet and the ﬂuctuations of the energy and show that the relation (3.6.8) indeed holds. (b) If N = 100 and µH =0.01eV, at what temperature will the average energy lose its thermodynamic meaning? Solutions to exercises in the text Solution 1.1 Exercise on page 227 The dependence on N is hidden inside Ei, which is the sum of energies of N particles, and also implicitly in the sum over states ∑ i. The dependence on V is in the summation over all possible positions as well as in the energies of the particles. To the kinetic energy of a classical particle we must add the condition which conﬁnes its motion to the volume V , and this can be done by addinga “step potential” which is zero inside the container and inﬁnite outside. The energy of a quantum particle of mass m inside a three-dimensional box of side d is quantized in quanta of ¯h 2/8md2, which, of course, leads to a dependence on the volume d3. Solution 1.2 Exercise on page 227 ⟨E⟩ is given by deﬁnition as ⟨E⟩ = ∑ i EiPi , (i) where Pi is the probability of microscopic state i. This probability, as we have seen, is proportional to e−βEi. Namely (after normalization), Pi = e−βEi ∑ i e−βEi ≡ e−βEi Z , (ii) where we have used the deﬁnition (3.1.2) of Z. The average of E is thus written as ⟨E⟩ = ∑ i Ei e−βEi Z = 1 Z ∑ i Eie −βEi = 1 Z ( − ∂ ∂β ∑ i e −βEi ) = − 1 Z ∂Z ∂β = − ∂ ln Z ∂β . (iii) 292 Solutions to exercises in the text 293 But β =1/kT or T =1/βk. We replace the diﬀerentiation with respect to β by a diﬀerentiation with respect to T in the followingmanner: ∂ ∂β = dT dβ ∂ ∂T = − 1 kβ2 ∂ ∂T = −kT 2 ∂ ∂T , and obtain from (iii), for the average of E ⟨E⟩ = kT 2 ∂ ln Z ∂T . (iv) Solution 1.3 Exercise on page 230 The work performed by the macroscopic system upon the external body is an average of (3.1.6) over the canonical ensemble. Namely, δW = 1 Z ∑ i ( − ∂Ei ∂X dX) e −βEi . But ∂ ∂X (e −βEi)= −βe −βEi ∂Ei ∂X , so that we may write δW = 1 Z ∑ i 1 β ∂ ∂X (e −βEi)dX . Interchanging the diﬀerentiation and the summation we obtain δW = 1 Z 1 β ∂ ∂X ( ∑ i e −βEi ) dX = 1 β 1 Z ∂Z ∂X dX = 1 β ∂ ln Z ∂X dX . Solution 1.4 Exercise on page 232 We denote by m and M the masses of the molecule and of the piston, respectively, by v and u their respective velocities before the collision, and by v′ and u′ their velocities after. p and P are the momenta of the molecule and of the piston before the collision, and p′ and P ′ after. For an elastic collision the kinetic energy is conserved: p2 2m + P 2 2M = p′2 2m + P ′2 2M (i) or p2 − p′2 2m = − P 2 − P ′2 2M . (ii) Makinguse of the conservation of momentum, p + P = p′ + P ′ ⇒ p − p′ = −(P − P ′) , (iii) 294 Solutions to exercises in the text dividing(ii) by (iii) we obtain another ﬁrst order equation: p + p′ m = − P + P ′ M . (iv) Equations (iii) and (iv) are two equations for the two unknowns p′ and P ′. The quantity of interest is p′,for which we ﬁnd p′ = 2mP − (M − m)p M + m . (v) Now, the momentum ∆p gained by the piston is equal to the momentum lost by the molecule, and thus ∆p = p − p′ = 2m(v − u) 1+ m/M , (vi) and since the mass of the molecule is negligible compared to the mass of the piston m/M ≪ 1, we obtain (3.1.15). The molecule’s velocity after the collision is obtained using(v): v′ = p′ m , (vii) and for m ≪ M , v′ ≃ 2u − v. Solution 1.5 Exercise on page 234 (a) The work performed by the system due to a change dX in the param- eter is given by Eq. (3.1.8): δW = 1 β ∂ ln Z ∂X dX . (i) The internal energy E is given by (3.1.3): E = − ∂ ln Z ∂β . (ii) The energy change dE is made of a part that is due to the change in temperature, and a part that is due to the volume change: dE = ∂E ∂X dX + ∂E ∂β dβ = − ∂2 ln Z ∂β∂X dX − ∂2 ln Z ∂β2 dβ . (iii) From (i) and (iii) we obtain dE + δW = ( 1 β ∂ ln Z ∂X − ∂2 ln Z ∂β∂X ) dX − ∂2 ln Z ∂β2 dβ , (iv) which is Eq. (3.1.25). Solutions to exercises in the text 295 (b) For the right hand side of (3.1.25) to be the change of a state function it should be an exact diﬀerential. The condition for the expression M (x, y)dx + N (x, y)dy to be an exact diﬀerential is ∂M ∂y = ∂N ∂x ⇒ ∂N ∂x − ∂M ∂y =0 . (v) (See e.g. Part II, Chap. 0.) Writing the right hand side of (3.1.25) in the form MdX + Ndβ , (vi) we have to calculate ∂N ∂X − ∂M ∂β = − ∂3 ln Z ∂β2∂X − 1 β ∂2 ln Z ∂β∂X + 1 β2 ∂ ln Z ∂X + ∂3 ln Z ∂β2∂X = − ∂ ∂β ( 1 β ∂ ln Z ∂X ) . This expression does not vanish in general, hence (vi), and conse- quently the right hand side of Eq. (3.1.25), is not an exact diﬀerential. Solution 1.6 Exercise on page 235 First we write (3.1.26) as β(dE + δW )= MdX + Ndβ (i) and calculate ∂N ∂X − ∂M ∂β = −β ∂3 ln Z ∂X∂β2 − ∂2 ln Z ∂β∂X + ∂ ∂β ( β ∂2 ln Z ∂X∂β ) =0 . Thus (i) is an exact diﬀerential, and we must seek the function from which it is derived. We shall denote this function by S/k.We note that N = −β ∂2 ln Z ∂β2 = ∂ ∂β ( ln Z − β ∂ ln Z ∂β ) . (ii) The coeﬃcient M of dX in (3.1.26) can be derived from the same function: M = ∂ ∂X ( ln Z − β ∂ ln Z ∂β ) , (iii) so k−1S is given by Eq. (3.1.27). 296 Solutions to exercises in the text Solution 1.7 Exercise on page 235 S = − ( ∂F ∂T ) X,N = k ∂ ∂T (T ln Z)= k ln Z + kT ∂ ln Z ∂T . Here we change variables from T to β,and as T ∂ ln Z ∂T = −β ∂ ln Z ∂β we obtain S = k ln Z − kβ ∂ ln Z ∂β , which is the required equation. Solution 1.8 Exercise on page 236 The Helmholtz free energy is F = E − TS. Substitutingfor F and S the expressions (3.1.32) and (3.1.33), respectively, we obtain E = F + TS = −NkT ln ( 2cosh µBH kT ) +NkT [ ln ( 2cosh µBH kT ) − µBH kT tanh µBH kT ] = −NµBH tanh µBH kT , as we obtained in (2.5.13). Remark: In (2.5.13) n denotes the number of spins in the system. Solution 1.9 Exercise on page 236 The speciﬁc heat at constant ﬁeld can be found from the energy as in (2.5.17) or, alternatively, with the help of the entropy. Since δQ = TdS, the speciﬁc heat at constant ﬁeld will be [cf. Eq. (2.0.13)] cH = 1 N T ( ∂S ∂T ) H,N . Diﬀerentiating S in Eq. (3.1.33) and substitutingit here, yields cH = kT [ (−µBH/kT 2) sinh(µBH/kT ) cosh(µBH/kT ) + µBH kT 2 tanh µBH kT − µBH kT · −µBH/kT 2 cosh2(µBH/kT ) ] = µ2 BH 2 kT 2 cosh2(µBH/kT ) , which is Eq. (2.5.18). Solutions to exercises in the text 297 Solution 1.10 Exercise on page 236 We ﬁrst obtain S(T, H, N )from F , as in Eq. (3.1.33), and then convert the dependence on T into a dependence on E. To this end we use the relation between E and T as given by (2.5.13); see Solution 1.8 as well. We also use the identity 1+ tanh x 1 − tanh x = e 2x , (i) whichis obtainedby writing tanh x = sinh x cosh x = ex − e−x ex + e−x = e2x − 1 e2x +1 , and solvingfor e2x. Equation (i) implies that x = 1 2 ln(1 + tanh x) − 1 2 ln(1 − tanh x) = 1 2 ln ( 1 2 + 1 2 tanh x ) − 1 2 ln ( 1 2 − 1 2 tanh x ) . (ii) In addition, since cosh2 x − sinh 2 x =1 we can write cosh x =(1 − tanh2 x) −1/2 =(1 + tanh x) −1/2(1 − tanh x) −1/2 , which implies that ln cosh x = − 1 2 ln(1 + tanh x) − 1 2 ln(1 − tanh x) = − 1 2 ln ( 1 2 + 1 2 tanh x ) − 1 2 ln ( 1 2 − 1 2 tanh x ) − ln 2 . (iii) Now, for convenience, we denote x = µBH/kT in the equation for the entropy (3.1.33), obtained from F , and ﬁnd S = Nk[ln(2 cosh x) − x tanh x] = −Nk [ 1 2 ln ( 1 2 + 1 2 tanh x ) + 1 2 ln ( 1 2 − 1 2 tanh x ) + 1 2 ln ( 1 2 + 1 2 tanh x ) tanh x − 1 2 ln ( 1 2 − 1 2 tanh x ) tanh x ] = −Nk [( 1 2 + 1 2 tanh x ) ln ( 1 2 + 1 2 tanh x ) + ( 1 2 − 1 2 tanh x ) ln ( 1 2 − 1 2 tanh x )] , (iv) where we have used the identities (ii) and (iii). 298 Solutions to exercises in the text From the expression for the energy E = −NµBH tanh µBH kT we obtain tanh x = − E/N µBH , (v) and then S in (iv) takes the form S = −k [( N 2 − E 2µBH ) ln ( 1 2 − E/N 2µBH ) + ( N 2 + E 2µBH ) ln ( 1 2 + E/N 2µBH )] , which is Eq. (2.3.13). Solution 1.11 Exercise on page 237 First, we calculate ZC with the shifted energies: ZC = ∑ i e −β(Ei+C) = e −βC ∑ i e −βEi = Ze −βC , where Z is the partition function of the system with the energies Ei. The average energy, (3.1.3), is ⟨E⟩C = − ∂ ln ZC ∂β = − ∂ ∂β (ln Z − βC)= − ∂ ln Z ∂β + C = ⟨E⟩ + C. Namely, the average energy has changed by C, i.e. by the same constant that we added to the microscopic energies. The new free energy FC [Eq. (3.1.30)], FC = − 1 β ln ZC = − 1 β (ln Z − βC)= F + C, and the magnetization (2.5.8) is unchanged: ⟨M ⟩C = 1 β ∂ ln ZC ∂H = − ∂FC ∂H = − ∂F ∂H = ⟨M ⟩ . Solution 1.12 Exercise on page 238 F (E)= E − TS is minimal when ∂F ∂E =0 . Solutions to exercises in the text 299 The dependence on E appears in the ﬁrst linear term and is also hidden in the entropy and thus, since T is constant, ∂F ∂E =1 − T ∂S ∂E =0 , and from here (3.1.38) is immediately obtained. Solution 1.13 Exercise on page 239 (a) Substituting µBH/kT =0.5 into (2.5.13) we obtain ⟨E⟩ µBHN = − tanh(0.5) = −0.4621 , which is exactly the same result as obtained from Fig. 3.1.2. (b) Substitutinginto Eq. (3.1.32) we obtain F NkT = − ln[2 cosh(0.5)] = −0.8133 , and this is exactly the value obtained from the ﬁgure or from direct substitution of ⟨E⟩ of (a) into Eq. (3.1.41). (c) The requirement that F be minimal yields an equation for the energy at the minimum, 0= ∂F ∂E =1 − kT 2µBH ln ( µBHN − E µBHN + E ) , (i) so that µBHN − E µBHN + E =exp ( 2µBH kT ) (ii) or E = −µBHN tanh ( µBH kT ) , (iii) and this is the familiar expression for the average energy of the para- magnetattemperature T . In order to obtain the value of F at equi- librium, we have to substitute into (3.1.41) the expression for E which mimimizes F (E), namely (iii). Denoting µBH kT = x (iv) we can write F in the form F = NkT { −x tanh x + 1 2 (1 − tanh x)ln [ 1 2 (1 − tanh x) ] + 1 2 (1 + tanh x)ln [ 1 2 (1 + tanh x) ]} = NkT { − x tanh x + 1 2 ln [1 4 (1 − tanh 2 x) ] + 1 2 tanh x ln ( 1+tanh x 1 − tanh x )} . (v) 300 Solutions to exercises in the text We now use the identities 1 − tanh2 x = 1 cosh2 x , (vi) 1+ tanh x 1 − tanh x = e 2x , (vii) and obtain F = NkT [ −x tanh x − 1 2 ln(4 cosh2 x)+ x tanh x ] = −NkT ln(2 cosh x) , (viii) and this is exactly Eq. (3.1.32). Solution 1.14 Exercise on page 241 The requirement of maximum entropy implies that ∂ ∂Na [S(Ea,Va,Na)+ S(Eb,Vb,Nb)] = 0 . Performingthe diﬀerentiation and usingthe fact that ∂Nb/∂Na = −1, we obtain ∂Sa ∂Na − ∂Sb ∂Nb =0 or ∂Sa ∂Na = ∂Sb ∂Nb ; namely, the equality of the quantity ∂S/∂N determines the equilibrium between the systems. Now ∂S ∂N = − µ T and since the temperatures must be equal so do the chemical potentials. Solution 2.1 Exercise on page 246 The partition function in our example is obtained from Eq. (3.2.3): Z = ∑ n1,n2,n3 e −βE(n1,n2,n3) , where each of the summation variables takes the values 0, 1 and 2. Now, the energy of a given state described by the triplet (n1,n2,n3) is E(n1,n2,n3)= ¯hω ( 3 2 + n1 + n2 + n3 ) = 3 2 ¯hω +¯hω(n1 + n2 + n3) . Solutions to exercises in the text 301 Note that the ﬁrst term, 3 2 ¯hω, is common to all states and is independent of (n1,n2,n3). Hence e −βE(n1,n2,n3) = e −3βϵ/2e −β(n1+n2+n3)ϵ , where we have denoted ¯hω = ϵ. In order to ﬁnd the partition function, we have to sum over all states of the system: Each oscillator has three possible states. Thus a system of three oscillators has 33 = 27 microscopic states which are described by all the triplets (n1,n2,n3) in the table below. (0,0,0) (0,0,1) (0,1,0) (1,0,0) (0,0,2) (0,2,0) (2,0,0) (0,1,1) (1,0,1) (1,1,0) (0,1,2) (0,2,1) (1,0,2) (1,2,0) (2,0,1) (2,1,0) (1,1,1) (0,2,2) (2,0,2) (2,2,0) (1,1,2) (1,2,1) (2,1,1) (1,2,2) (2,1,2) (2,2,1) (2,2,2) Note that all the states that appear in the same row have the same energy. To conclude, Z = e −3βϵ/2(1 + 3e −βϵ +6e −2βϵ +7e −3βϵ +6e −4βϵ +3e −5βϵ + e −6β) . Let us check if indeed this result is obtained from (3.2.4), i.e. from the cube of the single particle partition function. For a single oscillator z = 2∑ n=0 e −βϵn = e −βϵ/2(1 + e −βϵ + e −2βϵ) , z3 = e−3βϵ/2 ( 1+ e−3βϵ + e−6βϵ +3e−βϵ +3e−2βϵ +3e−2βϵ +3e−4βϵ +3e−4βϵ +3e−5βϵ +6e−3βϵ) = e−3βϵ/2 ( 1+3e−βϵ +6e−2βϵ +7e−3βϵ +6e−4βϵ +3e−5βϵ +e−6βϵ) = Z, where wehaveusedthe identity (1 + x + y) 3 =1 + x 3 + y3 +3x +3y +3x 2 +3y2 +3x 2y +3xy2 +6xy . Equations (3.2.3) and (3.2.4) are indeed equal. 302 Solutions to exercises in the text Solution 2.2 Exercise on page 246 The average energy is given by Eq. (3.1.3): ⟨E⟩ = − ∂ ln Z ∂β = −N ∂ ln z ∂β , where the partition function of a single oscillator, z, is given by Eq. (3.2.7): z = e −β¯hω/2(1 − e −β¯hω) −1 . Hence the average energy per oscillator ⟨E⟩/N can be derived directly from the single particle partition function: ⟨ϵ⟩ = − ∂ ∂β ln e−β¯hω/2 1 − e−β¯hω = − ∂ ∂β [ −β¯hω/2 − ln(1 − e −β¯hω) ] = ¯hω 2 + ¯hω e¯hω/kT − 1 , where we have substituted β =1/kT . Solution 2.3 Exercise on page 246 (a) Direct calculation of ⟨n⟩: First we derive the probability for a given oscillator to be in the nth energy level, in a way similar to the calculation of the probability for a given magnetic moment to be found in state σ =+1or σ = −1 in Part II. To do this we recall that the probability of a microscopic state i, given by the set of excitation numbers (n1,n2,... ,nN ), is P (n1,n2,... ,nN )= Z−1e −βE(n1,n2,...,nN ) . Now, since E is the sum of single oscillator energies ϵn and Z is the product of N identical factors Z = zN , we can write the probability for a microscopic state as the product of N probabilities: P (n1,n2,... ,nN )= P (n1)P (n2) · ... · P (nN ) , where P (n)= z−1e −βϵn . Usingthe excitation probabilities we calculate the average according to ⟨n⟩ = z−1 ∑ n=0 ne −βϵn . Solutions to exercises in the text 303 Substituting ϵn from (3.2.1) and z from (3.2.6) with the notation ϵ =¯hω,we obtain ⟨n⟩ = e−βϵ/2 ∑∞ n=0 ne−βnϵ e−βϵ/2 ∑∞ n=0 e−βnϵ . To calculate the right hand side we use a trick similar to the one used to prove Eq. (3.1.3) (Solution 1.2). Note that the numerator is the derivative of the denominator with respect to the variable x = βϵ.We thus write ⟨n⟩ = ∑∞ n=0 ne−xn ∑∞ n=0 e−xn = − d dx ln ( ∞∑ n=0 e −xn) = − d dx ln ( 1 1 − e−x ) = e−x 1 − e−x = 1 ex − 1 . Substituting x = βϵ, β =1/kT, ϵ =¯hω, we obtain Eq. (3.2.9): ⟨n⟩ = 1 e¯hω/kT − 1 . (b) Calculation of ⟨n⟩ from (3.2.8). Averaging Eq. (3.2.1) for a given oscillator yields ⟨ϵ⟩ = 〈 ¯hω 2 〉 + ⟨n¯hω⟩ = ¯hω 2 +¯hω⟨n⟩ . This result must be equal to (3.2.8), and hence ⟨n⟩ = 1 e¯hω/kT − 1 , as obtained above. Solution 2.4 Exercise on page 247 (a) At low temperatures ¯hω/kT ≫ 1and e¯hω/kT ≫ 1. Hence ⟨n⟩∼ 1 e¯hω/kT = e −¯hω/kT . (b) At high temperatures ¯hω/kT ≪ 1, so it is possible to use the power expansion of the exponential function, e x ≃ 1+ x + x2 2! + ... , 304 Solutions to exercises in the text and to take only the ﬁrst two terms, e ¯hω/kT ≃ 1+ ¯hω kT , so that ⟨n⟩∼ 1 1+¯hω/kT − 1 = kT ¯hω . Solution 2.5 Exercise on page 248 (a) The free energy of a single harmonic oscillator is F/N : f = F N = −kT ln z, where z is the partition function (3.2.7): z = e−β¯hω/2 1 − e−β¯hω . Hence f = ¯hω 2 + kT ln(1 − e −¯hω/kT ) . The entropy of a single harmonic oscillator s = S N = − ∂f ∂T = −k ln(1 − e −¯hω/kT ) − kT (−¯hω/kT 2)e−¯hω/kT 1 − e−¯hω/kT = −k [ ln(1 − e −¯hω/kT ) − ¯hω kT 1 e¯hω/kT − 1 ] . It is worth notingthat we could have obtained the same result by usingthe relation S =(E − F )/T [(3.1.28) or (3.1.29)]. The free energy (in units of ¯hω) of a single harmonic oscillator as a function of the temperature (in units of ¯hω/k). Solutions to exercises in the text 305 The entropy (in units of k) of a single harmonic oscillator as a function of the temper- ature (in units of ¯hω/k). (b) The transition temperature between the two types of behavior is in the regioninwhichthe quantity kT /¯hω is not very large and not very small, namely kT /¯hω ≃ 1. This can also be seen from both graphs above. The transition temperature is thus T ≃ ¯hω k ≃ 10−34 × 1013 × 2π 1.4 × 10−23 ≃ 450 K . Solution 2.6 Exercise on page 250 (a) Diﬀerentiating the average energy with respect to the temperature in Eq. (3.2.13) gives the speciﬁc heat: C = ∂⟨E⟩ ∂T =3N ¯hω ¯hω/kT 2e¯hω/kT (e¯hω/kT − 1)2 . The molar speciﬁc heat is the speciﬁc heat calculated for N = N0 atoms, where N0 is the Avogadro number. Recalling that N0k = R, we obtain C =3R ( ¯hω kT )2 e¯hω/kT (e¯hω/kT − 1)2 . (b) The entropy S can be calculated by diﬀerentiatingthe free energy given in (3.2.12): S = − ( ∂F ∂T ) , or with the help of the relation S =(E − F )/T , but the simplest way is to use the result from Exercise 2.5. S = −3Nk [ ln(1 − e ¯hω/kT ) − ¯hω/kT e¯hω/kT − 1 ] . 306 Solutions to exercises in the text Now, since δQ = TdS, the speciﬁc heat can also be derived from the entropy [Eq. (2.0.14)]. C = T ( ∂S ∂T ) N = − 3NkT [ (−¯hω/kT 2)e−¯hω/kT 1 − e−¯hω/kT + ¯hω/kT 2 e¯hω/kT − 1 − (¯hω/kT )2(1/T )e¯hω/kT (e¯hω/kT − 1)2 ] , in which the ﬁrst two terms cancel. We denote N0k = R,and obtain the molar speciﬁc heat C =3R ( ¯hω kT )2 e¯hω/kT (e¯hω/kT − 1)2 . Solution 2.7 Exercise on page 251 (a) ω =107 s−1: The amount of heat (per mole) required in order to raise the temper- ature of the crystal by ∆T is ∆Q = C∆T, where C is the speciﬁc heat (per mole) of the crystal. Around T =1 K ¯hω kT ≃ 10−34 × 107 1.4 × 10−23 × 1 ≃ 7 × 10 −5 ≪ 1 . This is, therefore, a very high temperature for this crystal, and it is possible to approximate (3.2.16) by (3.2.17): C ≃ 3R ≃ 25 J/K . For ∆T =10−2 K ∆Q =3R∆T ≃ 0.25 J . Around T = 100 K we certainly have ¯hω kT ≪ 1 , so that there as well ∆Q ≃ 0.25 J . In both cases we have used the high temperature approximation. Solutions to exercises in the text 307 (b) ω =1012 s−1: In this case, for T = 100 K, ¯hω kT ≃ 7 × 10 −2 ≪ 1 . Still 100 K is a high temperature. Hence we have again ∆Q = C∆T ≃ 3R∆T ≃ 0.25 J . But, for T =1 K, ¯hω kT ≃ 7 . Hence we must use the low temperature approximation to obtain C ≃ 3R ( ¯hω kT )2 e −¯hω/kT =3R · 49 · e −7 ≃ 1.25 J/K and ∆Q ≃ 1.25 × 10 −2 J . Solution 3.1 Exercise on page 255 The energy of a harmonic oscillator has the form E = p2 2m + 1 2 mω2x 2 . (i) A particle that moves in that potential will conserve its energy, and hence its trajectory will be a curve of constant E. Curves of constant energy in phase space (x, p) are ellipses. We can identify the elliptic structure by rewriting(i) in the form p2 2mE + x2 2E/mω2 =1 . The axes of the ellipse are thus a = √ 2mE , b = √ 2E/mω2 . This description of the ellipse does not expose the time dependence. This is provided by the parametric description of the ellipse, namely writing x and p as functions of a quantity that varies from one point to another alongthe particle’s trajectory in phase space. This variable is of course 308 Solutions to exercises in the text the time, and if we choose the time such that at t =0 x is maximal, we obtain x = x0 cos ωt , p = m ˙x = −mωx0 sin ωt . x0, of course, is not another free variable. It is the axis of the ellipse, determined by the energy. Substituting x and p in (i) gives x0 = b = √ 2E mω2 . The next ﬁgure illustrates several trajectories of the (classical) harmonic oscillator in phase space. Each of ﬁve radial lines intersects all the trajectories at points corre- spondingto one of ﬁve times: (0, 1 8 T, 1 6 T, 1 4 T, 1 2 T ). ➤➤➤➤➤t=T/2 p t=T/4 t=T/6 t=T/8 t=0 x Solution 3.2 Exercise on page 256 The average kinetic energy corresponding to the motion along x is 〈 p2 x 2m 〉 = ∫ (p2 x/2m)e−βp2/2md3p ∫ e−βU (r)d3r ∫ e−βp2/2md3p ∫ e−βU (r)d3r = ∫ (p2 x/2m)e−βp2/2md3p ∫ e−βp2/2md3p = ∫ (p2 x/2m)e−βp2 x/2mdpx ∫ e −βp2 y/2mdpy ∫ e−βp2 z/2mdpz ∫ e−βp2 x/2mdpx ∫ e −βp2 y/2mdpy ∫ e−βp2 z/2mdpz = ∫ (p2 x/2m)e−βp2 x/2mdpx ∫ e−βp2 x/2mdpx . Solutions to exercises in the text 309 We have already calculated such expressions in Chap. 1 of Part I. The result is 〈 p2 x 2m 〉 = 1 2 kT , which is in accord with the equipartition law (an energy of kT /2per degree of freedom). Solution 3.3 Exercise on page 258 (a) The particle’s potential is U (r)= 1 2 Kr2 . As longas the vibrational amplitude of the particle is less than L/2 or, alternatively, its total energy is less than 1 2 K(L/2)2, it will not “feel” the existence of the walls of the box. In order for the particle to reach the wall of the box, it needs at least this amount of energy. If the origin of this energy is thermal, then kT = 1 2 K ( L 2 )2 or T = KL2 8k . (b) If the box becomes inﬁnite, the average of U (r) is given by (3.3.10) or (3.3.11), where the integration over the particle’s position extends from −∞ to +∞, in each of the three spatial directions. ⟨U (r)⟩ = ∫ (Kr2/2)e−βKr2/2dV ∫ e−βKr2/2dV = − ∂ ∂β ln (∫ dV e −βKr2/2) . Since the integration over r is over the entire space, it is possible to cal- culate the last expression as in Chap. 1 of Part I. See also Eq. (1.1.60). The integral has the dimensions of volume or (length)3, and since the only quantity with the dimensions of length in the integral is 1/ √βK, it is clear that the integral is proportional to (βK)−3/2. Diﬀerentiating with respect to β yields ⟨U (r)⟩ = 3 2 kT . Solution 4.1 Exercise on page 262 Since the particles are identical, the functions ϵ1(r1, p1), ϵ2(r2, p2), etc., have the same dependence upon the position of the particles and upon 310 Solutions to exercises in the text their momentum, and hence the partition function will take the form Zc = ∫ dV1dτ1 ... dVN dτN e −β[ϵ(r1,p1)+...+ϵ(rN ,pN )] . The exponent is a product of exponents of the type e−βϵ(r,p),one factor for each particle. As a result the integral is a product of integrals and we can write Zc = ∫ dV1dτ1e −βϵ(r1,p1) ∫ dV2dτ2e −βϵ(r2,p2) · ... · ∫ dVN dτN e −βϵ(rN ,pN ) . All of the integrals in the product are identical, as ri, pi are variables of integration, and thus Zc = [∫ dV dτ e −βϵ(r,p)]N = zN . Solution 4.2 Exercise on page 262 The single particle partition function (3.4.4) is zc = ∫ dV e −βU (r) ∫ dτ e −βp2/2m . The ﬁrst integral is over the volume of the box. Since the particle moves freely within the box, namely U (r) = 0 in the region of integration, we have ∫ dV e −βU (r) = ∫ box dV = V. For the calculation of the second integral we write A = β/2m,and then we have to calculate an integral of the form I = ∫ dpxdpydpze −A(p2 x+p2 y+p2 z) , whose value, as found for instance in Exercise 1.13 of Part I, is (π/A)3/2. Hence I = ( 2πm β )3/2 , so that zc = V ( 2πm β )3/2 = V (2πmkT ) 3/2 . Solution 4.3 Exercise on page 263 The speciﬁc heat at constant volume is obtained directly from the tem- perature derivative of S(T, V, N ) in Eq. (3.4.8): ( ∂S ∂T ) V,N = 3Nk 2T ⇒ CV = 3 2 Nk . Solutions to exercises in the text 311 In contrast, to obtain the speciﬁc heat at constant pressure from the entropy, we ﬁrst have to express the entropy as a function of the pressure instead of the volume. This is done usingthe ideal gas equation (3.4.7). We thus obtain S(T, P, N )= Nk { ln [ (2πm)3/2(kT )5/2N P ] + 3 2 } and from here ( ∂S ∂T ) P,N = 5Nk 2T ⇒ CP = 5 2 Nk . Solution 4.4 Exercise on page 263 The internal energy is obtained from the derivative of the partition func- tion [Eq. (3.1.3)]: ⟨E⟩ = − ∂ ∂β ln Z = −N ∂ ∂β ln z = NkT 2 ∂ ∂T ln z = 3 2 NkT . Since in an isochoric process δE = δQ, CV = ( ∂E ∂T ) N,V . And indeed diﬀerentiation yields the previous result. In contrast, CP cannot be simply related to the energy since δE ̸= δQ in an isobaric process. For the terminology see Part II, Chap. 0. Solution 4.5 Exercise on page 264 The partition function of a mixture of gases is written in the form Zc = ∫ dV1dτ1 ... dVN dτN e −βE , where E is the energy in Eq. (3.4.11). Since the energy is a sum of the energies of each particle separately, and there are no terms connectingthe position variables and the momentum variables, the integral factors into a product as in Solution 4.1, this time of diﬀerent factors: Zc = [∫ dV1dτ1 exp ( − βp2 1 2m1 )]N1 [∫ dV2dτ2 exp ( − βp2 2 2m2 )]N2 ... [∫ dVM dτM exp ( − βp2 M 2mM )]NM . 312 Solutions to exercises in the text Each of the factors in the product can be identiﬁed as the partition func- tion of a single particle of type j raised to the power of the number of particles of that type Nj. Thus we have obtained Zc =(z1) N1(z2) N2 ... (zM ) NM , where zj = ∫ dV dτ exp ( − βp2 2mj ) . Solution 4.6 Exercise on page 265 The free energy of the mixture is F = −kT  N ln V + 3 2 M∑ j=1 Nj ln(2πmjkT )   . and the entropy S = − ( ∂F ∂T ) V,Ni = Nk ( 3 2 +ln V ) + 3 2 k M∑ j=1 Nj ln(2πmjkT ) . The speciﬁc heat at constant volume is CV = T ( ∂S ∂T ) V,Ni = 3 2 kT M∑ j=1 Nj T = M∑ j=1 CVj , where CVj = 3 2 Njk, as we obtained for a monocomponent gas in Eq. (3.4.9); namely, the speciﬁc heat of a mixture of gases is equal to the sum of the partial speciﬁc heats. The speciﬁc heat at constant pressure is obtained in a similar way (see also Solution 4.3), and again CP = T ( ∂S ∂T ) P,Ni = M∑ j=1 CPj , where CPj = 5 2 NjkT . The expression for the entropy can be written in the form S = M∑ j=1 Njk [ 3 2 +ln V + 3 2 ln(2πmjkT ) ] = M∑ j=1 Sj , Solutions to exercises in the text 313 where Sj is the partial entropy of the jth constituent of the gas — the expression we obtained in Eq. (3.4.8). Namely, the entropy of the mixture is equal to the sum of partial entropies. Actually, we could have started from this result to derive the additivity of both speciﬁc heats. Solution 4.7 Exercise on page 266 We have to show that ∫ P (r1, p1)dV1dτ1 =1 . Using(3.4.19) the left hand side can be written as ∫ [∫ P (r1, p1,... , rN , pN )dV2dτ2 ... dVN dτN ] dV1dτ1 = ∫ P (r1, p1,... , rN , pN )dV1dτ1 ... dVN dτN =1 , since P (r1, p1,... , rN , pN ) has been deﬁned in (3.4.18) as normalized over the full N -particle space. Solution 4.8 Exercise on page 267 The probability distribution function of any system, not necessarily an idealgas,is P (r1, p1,... , rN , pN )= Z−1 c exp [−βE(r1, p1,... , rN , pN )] . Now, the assumption (3.4.23) implies that P = Z −1 c exp(−βap 2 1x − βE′) . Hence the average of ap2 1x will be ⟨ap 2 1x⟩ = ∫ dV1dτ1 ... dVN dτN ap2 1x exp(−βp2 1x)exp(−βE′) ∫ dV1dτ1 ... dVN dτN exp(−βp2 1x)exp(−βE′) . In the denominator and the numerator there appears a product of 6N integrals (over 3N position variables and 3N momentum variables). The integrals in the denominator and in the numerator are equal, except for the integral over the x component of the momentum of particle number 1 which factors out. We therefore obtain ⟨ap2 1x⟩ = ∫ dp1xap2 1x exp(−βap2 1x) ∫ dp1x exp(−βap2 1x) , which is Eq. (3.4.24). 314 Solutions to exercises in the text Solution 4.9 Exercise on page 270 (a) We have λT /a = √ h2 mka2 · T − 1 2 .In SI units: h =6.6 × 10−34; k =1.38 × 10−23; mHe =6.7 × 10−27 and a =10−2,we have λT /a =2.17 × 10 −8 × T − 1 2 . Hence: at T = 300 K, λT /a =1.3 · 10−9; at T =10 K, λT /a =7.1 · 10−9. (b) λT /a = 1 implies that T =4.7 · 10−16 K. Solution 4.10 Exercise on page 272 The energy levels of a single particle of mass m inside a cubic container of volume V are ϵnpq = h2 8mV 2/3 (n2 + p2 + q2) and the energy of a microscopic state of N such particles is E(n1,p1,q1,... ,nN ,pN ,qN )= h2 8mV 2/3 (n2 1 +p2 1 +q2 1 +...+n2 N +p2 N +q2 N ) . Since E explicitly depends on the volume, we can repeat precisely the same arguments that brought us from (3.1.6) to (3.1.8) (with X = V ) and write δW = −Z −1 ∑ (n1,p1,q1,...) ∂E(n1,p1,q1,...) ∂V e −βE(n1,p1,q1,...)dV = 1 β ∂ ln Z ∂V dV . Solution 5.1 Exercise on page 276 (a) Paramagnet The free energy of the paramagnet has the form (3.1.32): F = −NkT ln [ 2cosh ( µBH kT )] . F in this case is proportional to N and is independent of the volume. Namely, it is deﬁnitely extensive: F (2N )= 2F (N ) . The same is true of its derivatives with respect to intensive parameters. Amongothers, the entropy S = −(∂F/∂T )H,N must be extensive. This Solutions to exercises in the text 315 may be seen explicitly from the expression we obtained for the entropy, (3.1.33): S = Nk { ln [ 2cosh ( µBH kT )] − ( µBH kT ) tanh ( µBH kT )} , which is also proportional to N and independent of the volume. The behavior of the entropy at low temperatures is obtained by noting that 2 cosh x ∼ ex, tanh x → 1for x →∞, and thus we obtain in this limit S ≃ Nk [ln exp ( µBH kT ) − µBH kT ] =0 . (b) System of oscillators The free energy (3.2.12) is F =3N [ ¯hω 2 + kT ln(1 − e −β¯hω) ] . As in the case of the paramagnet, the extensivity is due to the explicit proportionality to N and the independence of the volume. The same applies to S, which was calculated in Solution 2.6(b): S = −3Nk [ ln(1 − e −¯hω/kT ) − ¯hω/kT e¯hω/kT − 1 ] . Now, at low temperatures the ﬁrst term tends to ln 1 = 0. The second term is of the form xe−x (x =¯hω/kT ) and in the limit x →∞ vanishes as well. Thus, here as well, when T → 0, S → 0. See also the ﬁgure in Solution 2.5. Solution 5.2 Exercise on page 277 We start from a state in which two gases, of type A and type B, are in volumes, VA and VB, respectively at equal pressure, P , and temperature, T . MB MAM BA 316 Solutions to exercises in the text When the partition M is removed, the gases mix and a uniform state forms in the joint volume. This is Joule’s expansion: no work is performed, the energy does not change, and hence the temperature does not change. The pressure of each of the two gases in the combined volume is PA = P VA VA + VB , PB = P VB VA + VB , respectively, and hence the total pressure (accordingto Dalton’s law) re- mains PA + PB = P. We now insert, as described in the ﬁgure, two partitions, MA and MB. MA is only permeable to molecules of type A, and MB is only permeable to molecules of type B. We separate the two gases by bringing the partitions MA and MB to the position of the partition M . Obviously, after the partitions reach this location, each gas will be in its original volume. But work has been performed upon both of them — the work required to decrease the volume of each of the gases and to increase its pressure. This work raises the temperature of both gases, and they do not return to their original state. Solution 5.3 Exercise on page 279 In a canonical ensemble, the probability of the microscopic state i is Pi = 1 Z e −βEi . The partition function is the normalization coeﬃcient of the probability. The average of a physical quantity A is given by (3.4.36b): ⟨A⟩ = Z −1 ∫ ( dV dτ h3 )N A(ri, pi)e −βE(ri,pi) , where the correction that we have introduced necessitates changing the integration region in phase space to the region of states that are not connected by the exchange of identical particles. Since the exchange of identical particles does not change the value of A (if this were not so, they would not be identical), the reduction of the region of integration is equivalent to a division by N ! of the integral performed over the entire phase space. Thus in calculating ⟨A⟩ we can leave the region of integration unchanged and correct for this by dividing the integral by N !. Solutions to exercises in the text 317 The average of A will be given by the ratio between the corrected integral and the corrected Z. But the two are multiplied by an identical factor, and thus the new average is equal to the original one. Solution 5.4 Exercise on page 279 It is possible to distinguish between molecules of diﬀerent groups; how- ever, it is not possible to distinguish between molecules of the same group. That is, in each group j there are Nj particles that are indistinguishable from one another, and thus each microscopic state has Nj! internal per- mutations which are to be considered as a single state. In the calculation of (3.4.12) we counted a total number of states that is N1!N2!N3! ... NM ! times larger than the number of microscopic states. Hence, the corrected partition function is obtained by dividing(3.4.12) by this number: Z = (z1)N1 N1! (z2)N2 N2! ... (zM )NM NM ! . Solution 5.5 Exercise on page 279 The paramagnet is a system of N spins in ﬁxed positions. Hence the position of each spin does not count as a degree of freedom, as witnessed by the fact that the energy of each spin does not include a kinetic term. Such spins cannot exchange positions. Therefore, the summation over the states of the spins does not include a summation over their positions, so that no allowance has to be made for states in which the positions of two spins have been exchanged. The situation in the system of oscillators is similar. Here each oscil- lator does have a kinetic term; however, each oscillator (atom) vibrates around its own center of force, and again it is impossible to exchange two oscillators. Solution 5.6 Exercise on page 280 The pressure is given by the volume derivative of the free energy: P = − ( ∂F ∂V ) T,N . SubstitutingEq. (3.5.7), we obtain again the equation of state of an ideal gas. The reason why there is no change in P is that the additive change in F , due to the Gibbs correction, (3.5.5), is independent of the volume. Similarly, CV = T ( ∂S ∂T ) V,N ,CP = T ( ∂S ∂T ) P,N . 318 Solutions to exercises in the text Substituting(3.5.8) we obtain CV = 3 2 Nk , which is the usual result. In order to calculate CP we have to express S in terms of T , P and N instead of T , V and N , and this we do as in Solution 4.3 usingthe equation of state. S(T, P, N )= Nk { ln [ (2πm)3/2(kT )5/2 Ph3 ] + 3 2 } and thus we obtain CP = 5 2 Nk . The diﬀerence between S in (3.5.8) and S in (3.4.39) is independent of T , and hence CV and CP do not change. Solution 5.7 Exercise on page 280 F = −NkT [ ln ( V N ) + 3 2 ln ( 2πmkT h2 ) +1 ] , µ = ( ∂F ∂N ) T,V = −kT [ ln ( V N ) + 3 2 ln ( 2πmkT h2 ) +1 − 1 ] = −kT [ ln ( V N ) + 3 2 ln ( 2πmkT h2 )] . Denoting n = N/V (the density of molecules) we obtain (3.5.9). Solution 5.8 Exercise on page 280 The free energy of a mixture of M diﬀerent types of molecules (3.5.10) is F = −kT M∑ j=1 Nj [ ln ( V Nj ) + 3 2 ln ( 2πmjkT h2 ) +1 ] and the pressure is P = − ( ∂F ∂V ) T,N = kT M∑ j=1 ( Nj V ) = M∑ j=1 Nj kT V = M∑ j=1 Pj , where Pj is the partial pressure of the gas of type j. Solutions to exercises in the text 319 Solution 5.9 Exercise on page 280 The entropy is obtained from the free energy: S = − ( ∂F ∂T ) V,N = k M∑ j=1 Nj [ ln ( V Nj ) + 3 2 ln ( 2πmjkT h2 ) +1 ] + kT M∑ j=1 3 2 Nj 1 T = k M∑ j=1 Nj [ ln ( V Nj ) + 3 2 ln ( 2πmjkT h2 ) + 5 2 ] . This is of course the sum of the partial entropies of each of the gases. Solution 5.10 Exercise on page 281 The entropy before the removal of the partition is S = k 2∑ j=1 Nj [ ln ( Vj Nj ) + 3 2 ln ( 2πmjkT h2 ) + 5 2 ] , where Vj and Nj represent the volume and the number of molecules on each side of the partition. After the removal of the partition, the volume of each of the gases is V = V1 + V2, and the entropy is S′ = k 2∑ j=1 Nj [ ln ( V Nj ) + 3 2 ln ( 2πmjkT h2 ) + 5 2 ] . The change in entropy is ∆S = S′ − S = k ∑ j Nj ln ( V Vj ) = k ( N1 ln V V1 + N2 ln V V2 ) , and of course ∆S> 0. Solution 5.11 Exercise on page 282 The only contribution to the right hand side of (3.5.11a) is from the g0 states with Ei = E0, all of which have the same probability, 1/g0. Hence the sum consists of g0 identical terms (1/g0)ln g0 so that in the limit T → 0 S →−kg0 [ 1 g0 ln g0 ] = −k ln ( 1 g0 ) = k ln g0 . 320 Solutions to exercises in the text Solution 5.12 Exercise on page 283 First we have to calculate the partition function of the classical (three- dimensional) harmonic oscillator zc. The partition function of N classical oscillators will, of course, be (zc)N . zc can be calculated directly from (3.4.35b): zc = 1 h3 ∫ dV dτ exp [ −β ( p2 2m + mω2 2 r2)] . (i) This integral is a product of two three-dimensional Gaussian integrals (see Solution 4.2). From the integration over the momentum we obtain (2πmkT )3/2 and from the integration over space, (2πkT /mω2)3/2,sothat the overall result is zc = ( 2πkT hω )3 = ( kT ¯hω )3 . (ii) Now, the free energy is Fc = −NkT ln zc = −3NkT ln ( kT ¯hω ) (iii) and the entropy Sc = − ( ∂Fc ∂T ) N =3Nk [ ln ( kT ¯hω ) +1 ] . (iv) This expression, of course, diverges when T → 0. In order to see the behavior of the quantum Einstein solid we use the result of Exercise 2.5: S = −3Nk [ ln(1 − e −¯hω/kT ) − ¯hω kT 1 e¯hω/kT − 1 ] . (v) At high temperatures e ¯hω/kT − 1 ≃ ¯hω kT , 1 − e −¯hω/kT ≃ ¯hω kT , (vi) and we recover the classical result: S ≃−3Nk [ ln ( ¯hω kT ) − 1 ] =3Nk [ ln ( kT ¯hω ) +1 ] . (vii) At low temperatures we ﬁnd this time that the entropy is bounded and tends to zero, as can also be seen in the ﬁgure in Solution 2.5. When T → 0, we have e −¯hω/kT ≪ 1 ,e ¯hω/kT ≫ 1 . (viii) Solutions to exercises in the text 321 Thus, the ﬁrst term in the brackets of (v) vanishes as e−¯hω/kT . The second term becomes S ≃ 3Nk · ( ¯hω kT ) exp ( − ¯hω kT ) , (ix) since the exponential dominates the denominator and when T → 0, S → 0. Solution 6.1 Exercise on page 287 The average energy is ⟨E⟩ = 1 Z ∑ i Eie −βEi and the speciﬁc heat is Nc = ∂⟨E⟩ ∂T = − 1 kT 2 ∂⟨E⟩ ∂β = − 1 kT 2 ( − 1 Z 2 ∂Z ∂β ∑ i Eie −βEi − 1 Z ∑ i E2 i e −βEi ) . We now note that the average energy appears in the ﬁrst term once as an explicit sum and a second time in the form −∂ ln Z/∂β, hence it is proportional to ⟨E⟩2. The second term is ⟨E2⟩. Hence Nc = 1 kT 2 (⟨E2⟩−⟨E⟩ 2)= 1 kT 2 ⟨(E −⟨E⟩) 2⟩ = (∆E)2 kT 2 . Solution 6.2 Exercise on page 287 The average energy per molecule of an ideal gas is ⟨ϵ⟩ = 3 2 kT and the speciﬁc heat per molecule (at constant volume) is c = 3 2 k. Hence the substitution into (3.6.9) yields ∆E E = √ 2 3N . Solutions to self-assessment exercises Solution 1 Exercise on page 288 (a) The Gibbs free energy is G = E − TS + PV = F + PV . Substitutingthe expressions for F and P , (3.1.30) and (3.1.23), we obtain G = −kT ln Z + kT V ∂ ln Z ∂V . Since ln Z appears once with a derivative and once without it, we can write G in the form G = kT (V ∂ ln Z ∂V − ln Z ∂V ∂V ) = kT V 2 ∂ ∂V ( ln Z V ) . (b) The enthalpy: H = E + PV . Substituting(3.1.3) and (3.1.23) we obtain H = − ∂ ln Z ∂β + 1 β V ∂ ln Z ∂V = 1 β ( V ∂ ln Z ∂V − β ∂ ln Z ∂β ) . Solution 2 Exercise on page 288 We denote the frequency of the oscillator number α by ωα. Its energy ϵα takes the followingvalues: ϵα = ( nα + 1 2 ) ¯hωα , (i) A microscopic state of a system of 3N oscillators is described by 3N excitation numbers (n1,n2,... ,n3N ). Its energy is E(n1,n2,... ,n3N )= 3N∑ α=1 ϵα . (ii) 322 Solutions to self-assessment exercises 323 The partition function is the usual sum over all values of all nα.It factors into a product of sums: Z = ∑ n1,n2,...,n3N exp[−βE(n1,n2,... ,n3N )] = ∑ n1,n2,...,n3N exp [ −β¯hω1 ( n1 + 1 2 )] exp [ −β¯hω2 ( n2 + 1 2 )] · ... · × exp [ −β¯hω3N ( n3N + 1 2 )] = z1z2 ... z3N . (iii) Each of the factors zα on the right is a partition function of a single oscillator with frequency ωα, given by (3.2.7): zα = exp(−β¯hωα/2) 1 − exp(−β¯hωα) . (iv) Thefreeenergy will be F = −kT ln Z = −kT 3N∑ α=1 ln zα = ¯h 2 3N∑ α=1 ωα + kT 3N∑ α=1 ln(1 − e −β¯hωα) . (v) Note that the ﬁrst term is the sum of all the zero point (ground state) energies of all the oscillators and is a quantity which does not aﬀect the thermodynamic quantities that are derived from the partition function such as the entropy, speciﬁc heat etc. Solution 3 Exercise on page 288 The energy levels of the bounded oscillator are En = ϵ0 + nϵ , 0 ≤ n<n0 . (i) The partition function of a single oscillator will be z = e −βϵ0 n0−1∑ n=0 e −βnϵ = e −βϵ0 1 − e−βϵn0 1 − e−βϵ , (ii) where this time we have used the expression for the sum of a ﬁnite geo- metric series: n0−1∑ n=0 x n = 1 − xn0 1 − x . Note that the right hand side of (ii) tends to (3.2.7) when n0 →∞. 324 Solutions to self-assessment exercises (a) The average energy of the oscillator ⟨E⟩ = − ∂ ln z ∂β = ϵ0 − ϵn0e−βϵn0 1 − e−βϵn0 + ϵe−βϵ 1 − e−βϵ = ϵ0 + ϵ eβϵ − 1 − ϵn0 eβϵn0 − 1 . (iii) The average degree of excitation is easily calculated from the average energy, since ⟨E⟩ = ϵ0 + ⟨n⟩ϵ. Hence ⟨n⟩ = 1 eβϵ − 1 − n0 eβϵn0 − 1 . (iv) (b) The entropy S = E − F T = E/T + k ln z = k[ln(1 − e −βϵn0) − ln(1 − e −βϵ)] − ϵ T ( n0 eβϵn0 − 1 − 1 eβϵ − 1 ) (v) and the speciﬁc heat c = T ∂S ∂T = −β ∂S ∂β = kβ2ϵ 2 [ eβϵ (eβϵ − 1)2 − n2 0 eβϵn0 (eβϵn0 − 1)2 ] . (vi) Note that all the quantities E, S, c refer here to a single oscillator. (c) All of the expressions (ii)–(vi) give the corresponding quantities for the harmonic oscillator in the limit n0 →∞. When the temperature is very low, the thermodynamic behavior of the oscillator is controlled by the lowest levels. If the number of thermally relevant levels is much smaller than n0, it is expected that there will be no diﬀerence between the bounded oscillator and the regular oscillator. Namely, there is no qualitative diﬀerence when kT ≪ n0ϵ. On the other hand, if the temperature is high, kT ≫ ϵ, all the states are equally important, and then the diﬀerence is signiﬁcant. (d) At low temperatures we obtain from (vi) c ≃ k [( ϵ kT )2 e −ϵ/kT − ( n0ϵ kT )2 e −n0ϵ/kT ] . It is clear that when n0ϵ/kT ≫ 1, the second term is negligible com- pared to the ﬁrst one, and we obtain (3.2.18). At high temperatures, ϵn0/kT ≪ 1, the two terms in (vi) tend to the same limit, which is k, so that the speciﬁc heat tends to 0 instead of the classical value k of an unbounded oscillator. Solutions to self-assessment exercises 325 Remark. If these calculations seem familiar it is because the bounded oscillator has the same structure of energy levels as the spin in a magnetic ﬁeld. The sole diﬀerence is in the location of the zero level. Hence all the results obtained here could have been obtained from our discussion in Sec. 5.4 of Part II. Solution 4 Exercise on page 289 At low temperatures, the asymptotic behavior of CV in the Einstein model of a solid is given by CV ≃ 3R ( ¯hω kT )2 e −¯hω/kT . (i) (a) We denote x = kT /¯hω.A sketch of CV /3R as a function of x is given in the ﬁgure. R ≃ 2cal/K. The temperature scalingof the horizontal axis is discussed in (b) and (c), below.➤ ➤0 0.1 0.2 0.3 0.4 0.1 0.2 0.3 515 2510 20 T(K) x CV/3R For T =10 K, CV =0.114 cal/K, and thus we obtain an equation for x: 1 x2 e −1/x =0.0191 . This equation can be solved numerically, to give x =0.1227. Hence ΘE = 10 x ≃ 81 K 326 Solutions to self-assessment exercises and thus ω ≃ 10 13 s−1 . This frequency is of the order of typical lattice frequencies. (b) Scalingthe horizontal axis accordingto x = T/81 K leads to the graph for CV , now as a function of T , plotted in the ﬁgure. The points in the ﬁgure depict the experimental results given in the table. It is clear that not all the values in the table can be described by the graph. (c) Accordingto our determination, ΘE = 81 K, and thus the tempera- tures in the table justify a low temperature approximation. However, the Einstein approximation does not describe the experimental results well. The ratio of CV in the Einstein approximation to CV in the table, as a function of T , is depicted in the next ﬁgure. We see that when T decreases below 10 K the deviations of the theory from the experiment increase, instead of decreasing, as we would expect from the low temperature approximation. The Einstein approximation yields values that are much smaller than the experi- mental values. Solution 5 Exercise on page 289 In the Debye model (see Part IV, Sec. 3.3), the speciﬁc heat behaves at low temperatures accordingto CV = 12π4 5 R ( T ΘD )3 . Solutions to self-assessment exercises 327 We calculate ΘD from CV in the table at T =10 K: ΘD =10 ( 12π4 5 · 2 · 1 0.114 )1/3 ≃ 160 K . In the next ﬁgure both approximations are depicted along with the experi- mental results. A study of the ﬁgure reveals that the Debye approximation provides a good description of the experimental results. The Einstein ap- proximation does not provide a good quantitative description even if we use the Debye value of 160 K for ΘE. Solution 6 Exercise on page 290 (a) The partition function is Z = V N (2πmkT ) 5N/2 . In order to ﬁnd the equation of state we must calculate the pressure as a function of the volume and temperature. The pressure is given by P = − ∂F ∂V = kT ∂ ln Z ∂V = NkT V . Namely, the equation of state PV = NkT , of an ideal gas. 328 Solutions to self-assessment exercises In order to calculate the speciﬁc heat at constant volume, we ﬁrst calculate the internal energy: E = − ∂ ln Z ∂β = kT 2 ∂ ln Z ∂T = 5 2 NkT . Comparingthis expression to the internal energy obtained in Part I, we can interpret the result as the energy of N particles, as can also be deduced from the equation of state, each having average energy 5 2 kT , and hence ﬁve degrees of freedom. The gas is not monoatomic. A simple argument, that will be extended in the next part, leads to the conclusion that this is a diatomic gas, in which the atoms in the molecule are bound to each other in a rigid manner. A pair of atoms has, as we have seen in Part I, six degrees of freedom. But because the distance between the two atoms in the molecule is constant, one degree of freedom is frozen, leaving ﬁve degrees of freedom. The speciﬁc heat at constant volume is given by CV = ( ∂E ∂T ) V,N = 5 2 Nk . (b) The partition function is Z =(V − Nb) N (2πmkT ) 3N/2e aN 2/V kT . (i) The pressure is given by P = kT ∂ ln Z ∂V = NkT V − Nb − N 2 V 2 a (ii) hence the equation of state, ( P + N 2 V 2 a ) (V − Nb)= NkT , (iii) which is the Van der Waals equation. This equation can be interpreted in the followingmanner: It is a gas of N particles whose “active” volume is less than the total volume V . The decrease in volume can be attributed to the fact that each molecule has a ﬁnite rigid spherical volume of magnitude b. Hence the free volume for each molecule is V − Nb. The pressure factor is also modiﬁed with respect to the ideal gas. The fact that the measured pressure P is smaller than the pressure of free molecules movingin the active volume V − Nb can be explained by the fact that there exist attraction forces between the molecules, beyond their rigid volume. These forces are derived from the potential energy of the molecules, which is depicted qualitatively in the next ﬁgure: Solutions to self-assessment exercises 329 ➤➤ U(r) r0 r r0 is the radius of the rigid sphere of a molecule, which determines b. Beyond r0, the potential is attractive, which decreases the pressure. Next we study how this interpretation is expressed in the internal energy and in the speciﬁc heat. The internal energy is E = − ∂ ln Z ∂β = kT 2 ∂ ln Z ∂T = 3 2 NkT − N 2 V a (iv) and the speciﬁc heat is CV = ( ∂E ∂T ) V = 3 2 Nk . (v) Namely, this is a monoatomic gas — each atom contributes 3 2 k to the speciﬁc heat. The form of the internal energy indicates that there exist attrac- tion forces that decrease the energy below its value for an ideal gas. Is the magnitude of the decrease in energy reasonable? In order to check this we approximate the potential in the ﬁgure as follows: Sup- pose that each molecule produces an equal attraction potential, of magnitude ϵ0, at the position of every other molecule, which is not further away than some constant distance r1. Thus, each molecule feels an average potential of attraction, which is proportional to the depth of the well ϵ0 and to the density N/V . The higher the density, the more molecules there are within range r1 of a certain molecule. Hence the contribution of a given molecule, due to the attraction of its neighbors, to the total energy will be −ϵ0 ( N V ) · r3 1 . 330 Solutions to self-assessment exercises There are a total of N molecules. Hence the total contribution of the attraction to the energy will be − 1 2 Nϵ0 ( N V ) r3 1 = − N 2 V ϵ0r3 1 2 . (vi) The 1/2 appears because we are countingthe attraction energy be- tween each pair of molecules twice. Comparing(vi) to the last term in (iv) we ﬁnd that a has the meaningof the depth of the potential times the volume of its region of attraction. Solution 7 Exercise on page 290 The single particle partition function is z = h −3 ∫ dV dτ e −βcp = Vh −3 ∫ d 3pe −βcp =4πV h −3 ∫ ∞ 0 p2e −βcpdp . (i) The last transition was made after integrating over the angles in momen- tum space, which is equivalent to viewing dτ or d3p as the volume of a spherical shell of thickness dp and radius p,that is4πp2dp.Performinga change of variables to x = βcp,weobtain z = 4πV (βch)3 ∫ ∞ 0 x 2e −xdx . (ii) We still have to ﬁnd the value of the integral on the right hand side of (ii). Lookingit up in tables, or calculating it with the help of integration by parts, we ﬁnd 2. In fact there is no need to calculate it, as the physical variables are not sensitive to the multiplication of the partition function by a constant. In any event we have obtained z = 8πV (βch)3 . (iii) The average energy is E = − ∂ ln Z ∂β = −N ∂ ln z ∂β = 3N β =3NkT . (iv) We have found, therefore, that the average energy of an extremely rel- ativistic particle movingat a speed close to the speed of light is 3kT , compared to 3 2 kT for a nonrelativistic particle. The reason is that the en- ergy of such a particle is not proportional to the square of its momentum but is linear in the momentum. The equation of state is P = − ∂F ∂V = kT ∂ ln Z ∂V = NkT ∂ ln z ∂V = N V kT . (v) Solutions to self-assessment exercises 331 Thus, the equation of state for the relativistic gas is unchanged. (See also Part I, Exercise 1.2.) The speciﬁc heat at constant volume is (∂E/∂T )V , and we again ob- tain, as in (iv), a magnitude which is twice the nonrelativistic magnitude: CV =3Nk . (vi) For the calculation of the speciﬁc heat at constant pressure we shall use the enthalpy H = E + PV and the relation CP =(∂H/∂T )P .We thus obtain H =3NkT + NkT =4NkT ⇒ CP =4Nk . (vii) Solution 8 Exercise on page 290 (a) We denote the magnetic moment by µ and its magnitude by µ.The energy of a single magnetic moment in a ﬁeld H is ϵ = −µ · H . We assumed that all ions have magnetic moments of constant mag- nitude, and that the diﬀerence between them is in the orientation. Namely, the state of ion number i is characterized by φi and θi,which are angles that describe its orientation in space. The ﬁeld is directed alongthe z axis, and the energy of ion number i is ϵi = −µH cos θi and is independent of the azimuthal angle φi. The energy of the sys- tem of N ions, for a given microscopic state (specifying the orientation of every spin), is given by E = −µH N∑ i=1 cos θi . (b) The partition function is written as an integral over all possible values of the 2N angles θi and φi, which factors into a product of integrals because there are no interactions between the diﬀerent spins. Z(β, H, N ) = ∫ 2π 0 dφ1 ∫ π 0 dθ1 sin θ1 ... ∫ 2π 0 dφN ∫ π 0 dθN sin θN e −βE = (∫ 2π 0 dφ ∫ π 0 dθ sin θe βµH cos θ)N =[z(β, H)] N . We shall now calculate z. 332 Solutions to self-assessment exercises The integration over φ simply gives 2π, as there is no dependence upon this angle. Hence z =2π ∫ π 0 dθ sin θe βµH cos θ . In calculating this integral we note that the integrand is a derivative of eβµH cos θ. Hence z =2π eβµH − e−βµH βµH = 4π βµH sinh(βµH) . And hence Z(β, H, N )= [ 4π βµH sinh(βµH) ]N . (i) (c) The average magnetization is, according to Eq. (2.5.8), M = 1 β ∂ ln Z ∂H = Nµ [ coth(βµH) − 1 βµH ] . (ii) The function in the square brackets is called Langevin’s function: L(x) ≡ coth(x) − 1 x , so that we may write M = NµL(βµH) . The average energy of the paramagnet is E = −HM = −NµHL(βµH) . The entropy is derived from the partition function, or from the free energy, using S = − ( ∂F ∂T ) H,N = ∂ ∂T (kT ln Z)H,N . (iii) Substituting Z we obtain S = ∂ ∂T {kT N ln [ 4π βµH sinh(βµH) ]} = Nk {ln [ 4π βµH sinh(βµH) ] +1 − βµH coth(βµH) } . Solutions to self-assessment exercises 333 (d) In order to compare with the discrete paramagnet we check the behav- ior of the magnetization as a function of H or T . At low temperatures, or high ﬁelds, the coth in Eq. (ii) tends to 1 and the second term tends to 0, so the magnetization saturates: M → Nµ,asinthe quantum case. At high temperatures, or low ﬁelds, we must study the Langevin function L(x)for x ≪ 1, just as we studied the Brillouin function in Solution 5.7 of Part II. To this end we use the result obtained in Eq. (viii) in Solution 5.7 of Part II: coth x ≃ 1 x + x 3 ,x ≪ 1 , so L(x) ≃ x 3 , for x ≪ 1 , which is again similar to the behavior of the Brillouin function. We thus ﬁnd that for small µH/kT M = Nµ2 3kT H, χ = µ2 3kT , and this is Curie’s law again. We have found that the dependence of the magnetization upon the variable βµH is rather similar to that obtained in the quantum case, in which each magnetic moment has a ﬁnite number of states. Moreover, it is possible to show that the magnetization found here is the classical limit of the one found in Part II. The classical limit is obtained not when the temperatures is high or when the ﬁeld weak, but when the quantum spin becomes a classical spin, namely when J ≫ 1. The quantum result we obtained was M = NgµB {(J + 1 2 ) coth [( J + 1 2 ) βgµBH] − 1 2 coth ( βgµBH 2 )} . If we compare the expressions for the susceptibility, it is clear that when J is very large it is possible to identify gµBJ with µ. Hence the limit J →∞ must be taken in such a manner that gµBJ remains constant (and equal to µ). Therefore, writing M with the help of µ and J we obtain M = N {(µ + µ 2J ) coth [( µ + µ 2J ) βH] − µ 2J coth ( βµH 2J )} . 334 Solutions to self-assessment exercises In the limit J →∞ we can write M = N [ µ coth(βµH) − µ 2J · 2J βµH ] = N [ µ coth(βµH) − 1 βH ] , and this is the magnetization we found in (c) above. (e) We shall check how S behaves at low temperatures. If x ≡ βµH ≫ 1 then S ≃−Nk ln x. Namely, S →∞ for x →∞, and this is another example in which the third law does not apply to a classical system. (See discussion in Sec. 5.3.) Solution 9 Exercise on page 291 (a) The work performed by the gas in an isothermal expansion is W = ∫ V2 V1 PdV = NkT ∫ V2 V1 dV V = NkT (ln V2 − ln V1) . Since the process is isothermal the work is performed at the expense of the free energy (see Sec. 1.5), and the result must equal the decrease in the free energy. Indeed, using (3.5.7) we obtain −∆F = F1 − F2 = NkT ln ( V2 N ) − NkT ln ( V1 N ) = NkT (ln V2 − ln V1) . (b) The internal energy of the ideal gas depends only on the temperature, and hence it has not changed during the process: ∆E = 0. The origin of the work is therefore the energy extracted from the heat bath, and converted into mechanical energy by the gas. Solution 10 Exercise on page 291 (a) The speciﬁc heat of a paramagnet, calculated in Part II, Eq. (2.5.18), is cH = (µBH)2 kT 2 cosh2(βµBH) . (i) Solutions to self-assessment exercises 335 To calculate the ﬂuctuations we need the diﬀerence: ⟨E2⟩− ⟨E⟩ 2 = Z−1 ∑ {σi=±1} E2(σ1,... ,σN )e −βE(σ1,...,σN ) −  Z −1 ∑ {σi=±1} E(σ1,... ,σN )e −βE(σ1,...,σN )   2 . This expression takes on a simpler form if we note that    ⟨E2⟩ = 1 Z ∂2Z ∂β2 , ⟨E⟩2 = 1 Z 2 ( ∂Z ∂β )2 ⇓ ⟨E2⟩− ⟨E⟩ 2 = 1 Z ∂2Z ∂β2 − 1 Z 2 ( ∂Z ∂β )2 = ∂ ∂β [ 1 Z ( ∂Z ∂β )] = ∂2 ∂β2 (ln Z) . Z, calculated in Part II, Eqs. (2.5.11) and (2.5.12), is Z =[2 cosh(βµBH)]N , and we obtain ⟨E2⟩− ⟨E⟩ 2 = N ∂2 ∂β2 ln[2 cosh(βµBH)] = NµBH ∂ ∂β tanh(βµBH)= N (µBH)2 cosh2(βµBH) . (ii) From (i) and (ii) we obtain (3.6.8), namely ⟨E2⟩−⟨E⟩ 2 = NkT 2cH . (b) The average of the energy will lose its thermodynamic meaning when ⟨E2⟩−⟨E⟩2 ⟨E⟩2 ≃ 1 . Namely, when N (µBH)2 cosh2(βµBH) 1 N 2(µBH)2 tanh2(βµBH) = 1 N sinh 2(βµBH) ≃ 1 or √N sinh(βµBH) ≃ 1 . 336 Solutions to self-assessment exercises With N = 100, µH =0.01eV, we are searchingfor a solution for sinh x =0.1 , where x = µH/kT . One ﬁnds (numerically) that x ≃ 0.1 . The required temperature is thus T = µBH kx ≃ 1160 K. Part IV From Ideal Gas to Photon Gas This Page Intentionally Left Blank Introduction This part is a continuation and extension of Part III and is based on the implemen- tation of the methods presented in the previous parts. In Chap. 1 the subject of ideal gases of molecules devoid of internal structure, analyzed in Part III, is extended to deal with molecules. We learn how to take into account the internal structure of the molecules, and its effects on the properties of the gases. We shall dwell upon the heat capacity problem which we encountered in Part I and resolve it here at last. In Chap. 2 we go one step further and consider the case in which the molecules of the gas disintegrate into their constituents or participate in chemical reactions; also here the theory developed has much to say. In Chap. we return to the problem of the specific heat of solids, and learn how it is possible, with relative ease, to improve the Einstein model and obtain a good correspondence between the theoretical explanation and the experimental results. This chapter will prepare us for the fourth chapter, which deals with the thermodynamics of electromagnetic radiation. Since electromagnetic radiation can be treated as a collection of harmonic oscillators with different frequencies, it is possible to apply to it all the methods developed in Chap. 2 of Part III for systems of oscillators. The principal difficulty overcome in Chap. 4 is the demonstration that the electromagnetic radiation actually behaves as a system of free oscillators. here on the road ahead is clear. 339 Chapter 1 An Ideal Gas of Molecules with Internal Degrees of Freedom 1.1 Center of mass and internal motions In this chapter we continue the discussion of the ideal gas of molecules, i.e. a gas in which it is possible to neglect the forces between molecules. But in order to proceed a step further toward a more realistic description, we now take into account the internal structure of the molecules. We have already seen in Part III that if there are no forces between the molecules, the total energy of the gas is the sum of single molecule energies, and hence the partition function is a product of single molecule partition functions [see, for instance, Eqs. (3.5.3) and (3.5.4)]. Thus we shall concentrate on the energy of a single molecule. The molecule is made up of q constituents — the nuclei of diﬀerent atoms and electrons. We denote their positions by rα and their masses by mα,where α =1,... ,q. The energy of a molecule has the typical form Emol = q∑ α=1 1 2 mαv2 α + 1 2 ∑ α,β α̸=β U (rα − rβ)= q∑ α=1 p2 α 2mα + 1 2 ∑ α,β α̸=β U (rα − rβ) , (4.1.1) where vα and pα are the velocity and momentum, respectively, of the αth particle in the molecule. U (rα − rβ) is the potential energy due to the interaction of the pair of particles α and β inside the molecule — for example, an attractive force between an electron (negatively charged) and a nucleus (positively charged), or a repulsive electric force between two electrons, etc. The potential energies also depend on the types of the interactingparticles, but at this stage we shall refrain from complicating the notations. The factor 1 2 in the potential energy term compensates for double counting, since the sum over all values of α and β counts each pair twice. Note that the summation excludes the terms with α = β, i.e. a particle does not interact with itself. See also Example (b), Sec. 3.2, Part III. 340 1.1 Center of mass and internal motions 341 When in Part III we have treated each molecule as a point, the coor- dinate and momentum of this point corresponded to the center of mass of the molecule it represents. Hence, in turningto treat the eﬀects of the internal structure of the molecules upon the statistical mechanics of the system, it is natural that we distinguish between the center of mass variables which we have already treated and the internal variables (see Sec. 1.3 of Part I). We therefore decompose the total energy of a molecule into two parts: energy related to the motion of the center of mass and internal energy. The center of mass is located at R = 1 M q∑ α=1 mαrα , (4.1.2) where M = ∑q α=1 mα and the momentum associated with the center of mass is given by P = M ˙R = q∑ α pα . (4.1.3) This is the momentum of the entire molecule. The internal coordinates of a particle, namely the ones measured with respect to the center of mass, will be denoted by ρα,so that rα = R + ρα . (4.1.4) The momentum of a particle relative to the center of mass is denoted by πα and is given by πα = mα ˙ρα . (4.1.5) Thus pα = mα M P + πα . (4.1.6) The deﬁnition of the center of mass implies the two identities q∑ α=1 mαρα =0 , (4.1.7a) q∑ α=1 πα =0 . (4.1.7b) InsertingEq. (4.1.6) for pα we obtain for the kinetic energy of the molecule q∑ α=1 p2 α 2mα = P2 2M + q∑ α=1 π2 α 2mα . (4.1.8) The ﬁrst term on the right hand side is the kinetic energy related to the motion of the center of mass of the molecule, whereas the second term is the kinetic energy related to the internal motions of the diﬀerent constituents. 342 Ch. 1 An Ideal Gas of Molecules with... Exercise 1.1 Prove Eqs. (4.1.6)–(4.1.8). Solution on page 406 Next we deal with the potential energy. The potential energies depend only on mutual distances (rα − rβ), and thus do not depend on the coordinate of the center of mass R, but only on the diﬀerence between the internal coordinates, ρα − ρβ. Thus, since there is no potential energy term dependent on R, the molecule’s center of mass moves freely. The energy (4.1.1) therefore takes the form Emol = P2 2M + q∑ α=1 π2 α 2mα + 1 2 ∑ α,β U (ρα − ρβ)= P2 2M + EI , (4.1.9) where EI is the internal energy, i.e. the energy in the frame of reference of the molecule’s center of mass. In all of our previous discussions of ideal gases we assumed that EI =0. Note that as a result of (4.1.7) only q − 1 of the momentum variables πα are inde- pendent. Similarly, only q − 1 spatial variables ρα are independent. 1.2 Kinematics of a diatomic molecule At this stage we increase our resolving power and distinguish between the atoms inside the molecule, but we still do not take the electrons into account. For simplicity we treat a diatomic molecule. The positions of the two atoms will be denoted by r1 and r2, the momenta by p1 and p2,and the potential between them U (r1 − r2) will have the typical form depicted in Fig. 4.1.1. U(r) r r0 Fig. 4.1.1 Illustration of a typical potential in a diatomic molecule. r0 is the equilib- rium distance. The dashed line is the harmonic approximation. 1.2 Kinematics of a diatomic molecule 343 The energy of the molecule (or of the two atoms) is Emol = p2 1 2m1 + p2 2 2m2 + U (r1 − r2) . (4.1.10) The coordinates of the center of mass R = 1 M (m1r1 + m2r2) . (4.1.11a) The relative coordinates (in the center-of-mass reference frame) are ρ1 = r1 − R , (4.1.11b) ρ2 = r2 − R , (4.1.11c) and the relative momenta πα are [see Eqs. (4.1.5) and (4.1.6)] π1 = m1 ˙ρ1 = p1 − m1 ˙R = p1 − m1 M P , (4.1.12a) π2 = p2 − m2 M P , (4.1.12b) where P = p1 + p2 = M ˙R . (4.1.13) Usingthe explicit forms of ρ1, ρ2, π1 and π2 it is easy to verify that Eqs. (4.1.7) are actually satisﬁed, i.e. m1ρ1 + m2ρ2 =0 , (4.1.14a) π1 + π2 =0 . (4.1.14b) In order to separate the center-of-mass variables from the internal vari- ables, we express the energy with the help of P, πα and ρα: Emol = P2 2M + π2 1 2m1 + π2 2 2m2 + U (ρ1 − ρ2) , (4.1.15) and this is a particular case of Eq. (4.1.9). We now perform several operations that are possible due to the two- body nature of the problem. We write π1 and π2 in the form −π2 = π1 = µ( ˙ρ1 − ˙ρ2) , (4.1.16) where µ = m1m2 M is the reduced mass of the system. 344 Ch. 1 An Ideal Gas of Molecules with... Exercise 1.2 Prove Eq. (4.1.16). Solution on page 407 The right hand side of Eq. (4.1.16) is the relative momentum and the argument of U in Eq. (4.1.15) is the relative position. We denote them by π12 and ρ12, respectively, so that π12 = µ ˙ρ12 . (4.1.17) We can now write the energy of the molecule as the sum of the energy of the center of mass and the energy of the relative motion: Emol = P2 2M + π2 12 2µ + U (ρ12) . (4.1.18) We now make three remarks that will be of use in what follows: (a) The kinetic term in the internal energy depends on ˙ρ12.Namely, this is the rate of change of the vector that connects the two atoms. This vector can change in magnitude — molecular vibrations. Or, it can remain of constant magnitude and change its direction, namely a rotation of the molecule. See Fig. 4.1.2. (b) The potential U (ρ12) is usually a central potential, which means that it depends only on the magnitude of the distance between the two nuclei, which we denote by ρ. (c) The vibrations of the interatomic distance will be centered around a certain equilibrium distance, ρ0. When the amplitude of the vibra- tions is small, it is possible to expand U (ρ). Namely, U (ρ)= U (ρ0)+ U ′(ρ0)(ρ − ρ0)+ 1 2 U ′′(ρ0)(ρ − ρ0) 2 + ··· (4.1.19) longitudinal vibrations longitudinal vibrations➤➤➤➤ ➤➤ ➤➤➤ ➤ ➤ M m2m1 ➤ rotations Fig. 4.1.2 Changes in the magnitude of the vector connecting the two atoms represent longitudinal vibrations of the molecule (like those of a spring). Changes in the direction of this vector represent rotations of the molecule relative to its center of mass. 1.2 Kinematics of a diatomic molecule 345 The ﬁrst term is independent of ρ and is simply a constant, which can be ignored. The second term is zero, since we assumed that ρ0 is the equilibrium distance, and the potential energy must be minimal there, and hence U ′(ρ0) = 0. It is possible, therefore, to approximate the potential between the two atoms by a harmonic potential, centered on the equilibrium distance. This is the dashed line in Fig. 4.1.1. Exercise 1.3 Consider a hypothetical molecule in which the potential between the two atoms is of the form U (ρ)= ϵ [( a ρ )2 − 2 a ρ ] . (a) What is the equilibrium distance in the molecule? (b) What is the binding energy (the energy required to separate to inﬁnite distance the two atoms from their equilibrium position)? (c) Calculate the magnitude of the “spring constant,” if a is 2 ˚Aand ϵ is 2.5 eV. (d) How much energy is required to change the interatomic distance by 5% of their equilibrium distance? What temperature is required to produce this change? (e) What is the relative change in the molecular length at room temper- ature? Solution on page 407 Exercise 1.4 Prove that in a diatomic molecule the followingrelationships exist between the relative position and momentum of the particles in the molecule and between their coordinates and momenta with respect to the laboratory frame of reference: r1 = R + m2 M ρ12, r2 = R − m1 M ρ12 , p1 = m1 M P + π12, p2 = m2 M P − π12 . Solution on page 408 Exercise 1.5 Write the total energy of a triatomic molecule as the sum of a free part related to the center-of-mass motion and an internal part. How many variables are required to characterize the molecule’s state? (Disregard the motion of the electrons.) Solution on page 409 346 Ch. 1 An Ideal Gas of Molecules with... 1.3 Gas of general composite molecules We discuss a gas of N molecules, each havingan energy of the form (4.1.9). The energy of the whole system (recall that we assume that there are no forces between the molecules) in a given microscopic state is E = N∑ ν=1 P2 ν 2M + N∑ ν=1 ϵν , (4.1.20) where Pν is the momentum of the center of mass of molecule number ν and ϵν is the internal energy of molecule ν, which was denoted before by EI .Accordingto Eq. (3.4.36a) with the Gibbs’ correction, in a gas of classical molecules, the partition function is Z = 1 h3N N ! ∫ e −βEd 3NRd 3NPd 3N (q−1)ρd 3N (q−1)π, (4.1.21) where E is given by Eq. (4.1.20). This is a sum over all the system’s states, which are described by three coordinates and three momenta of the center of mass of each molecule, alongwith the 3(q − 1) internal coordinates and 3(q − 1) internal momenta of each molecule. A purely classical description leads to the equipartition law and to the diﬃculties in the calculation of the speciﬁc heat which we have en- countered in Sec. 1.3 of Part I. (See also next section.) But we know that to deal with phenomena that are takingplace inside a molecule one must apply quantum theory. The ﬁrst term of Eq. (4.1.20) can still be treated classically, since the molecules are free to move inside a container of macroscopic dimensions. Recall Sec. 4.4 of Part III. The second term must be treated as a sum of discrete internal molecular energies, which are characterized accordingto quantum mechanics by the level number n. The internal energy of a molecule in level n will be denoted by ϵ(n). The values of these energies may in principle be obtained from the quantum- mechanical calculation or, alternatively, from experiment. The state of molecule number ν is therefore characterized by specifyingthe position and momentum of its center of mass, Rν, Pν , and its quantum state, nν. A microscopic state of the gas as a whole will be characterized, therefore, by (R1, P1,n1, R2, P2,n2,... , RN , PN ,nN ) and the energy in this state will be E(R1, P1,n1,... , RN , PN ,nN ) = N∑ ν=1 P2 ν 2M + ϵ1(n1)+ ϵ2(n2)+ ··· + ϵN (nN ) . (4.1.22) 1.3 Gas of general composite molecules 347 The partition function of the system is obtained by summingover the discrete states and integrating over the continuous degrees of freedom: Z = 1 h3N N ! ∫ d 3R1d 3P1 ... d 3RN d 3PN ∑ n1,...,nN × exp[−βE(R1, P1,n1,... , RN , PN ,nN )] . (4.1.23) The right hand side of (4.1.23) may be decomposed into a product of N factors of the form of a single molecule partition function: zν = 1 h3 ∫ d 3Rνd 3Pν e −βP 2 ν /2M ∑ nν e −βϵν (nν ) . (4.1.24) Since the molecules are identical, they all have the same sequence of energy levels. Namely, the energy of a molecule does not depend on the molecule’s number ν but only on the level it occupies (Fig. 4.1.3), so that the right hand side of (4.1.23) decomposes into a product of N identical factors. We can therefore write the partition function as Z = 1 N ! zN . (4.1.25) The single molecule partition function, z, can be further factored into the center-of-mass variables and the internal variables: z(T, V, N )= zc.m.(T, V, N )ζ(T ) , (4.1.26) molecule number 1 2 3 4 5 6 7 12 3n ν ε➤ ➤➤ 0level number Fig. 4.1.3 A collection of identical molecules having the same energy levels. Molecules 1 and 3 in the ﬁgure, for instance, have the same energy, ϵ1(5) = ϵ3(5) = ϵ(5), whereas molecule 2 has ϵ2(3) = ϵ(3). 348 Ch. 1 An Ideal Gas of Molecules with... where zc.m. = 1 h3 ∫ d 3Rd 3P exp ( − βP 2 2M ) = V (2πM kT )3/2 h3 , (4.1.27a) ζ = ∑ n e −βϵ(n) = ∑ n e −ϵ(n)/kT . (4.1.27b) The internal structure of the molecules is expressed by the additional multiplicative factor, ζ, in the single molecule partition function. Since ζ depends only on the molecule’s internal structure, we may refer to it as the internal partition function. In the followingsections we shall calculateinternal partition function it explicitly for some simple cases. We now calculate the free energy, and obtain Eq. (3.5.7) with an ad- ditional term dependingon ζ: F = −kT ln Z = −NkT [ ln V N + 3 2 ln ( 2πM kT h2 ) +1 +ln ζ] . (4.1.28) The equation of state The pressure P is calculated from (4.1.28). The result is P = − ∂F ∂V = NkT V , (4.1.29a) from which we obtain again the equation of state: PV = NkT . (4.1.29b) It appears as if the internal degrees of freedom have no eﬀect at all. But we are again faced with the questions that arose in Sec. 1.3 of Part I. Namely, how is it possible to decide which is the molecule and which are the constituents? After all we could have chosen to treat each nucleus and each electron separately! This time we have an answer at hand: The reason why the equation does not change is that we assumed that ζ depends only on the temper- ature and does not depend on the volume of the container.Namely, the forces actinginside the molecule determine its size, and hence the dis- tances between its diﬀerent parts. When a part of the molecule hits the wall of the container, the other parts are found at a microscopic distance from the wall and do not wander freely in the container. This assumption will lose its validity as the temperature rises, since then the probabil- ity for very high energy states in the molecules to be occupied increases. Among the high energy states there will also be states of the disintegrated molecule, and in these states the energy depends on the volume. It goes without sayingthat in this case the constituents of the molecule come into play. 1.3 Gas of general composite molecules 349 Entropy and internal energy per molecule We use (4.1.28), and write s = S N = − 1 N ( ∂F ∂T ) V,N = k [ ln V N + 3 2 ln ( 2πM kT h2 ) + 5 2 ] + d dT (kT ln ζ) . (4.1.30) Comparingto (3.5.8), we ﬁnd that there is an additional entropy per molecule of magnitude: ∆s = d dT (kT ln ζ) . (4.1.31) The internal energy per molecule ⟨ϵ⟩ = E N = 3 2 kT + kT 2 d dT ln ζ. (4.1.32) Exercise 1.6 Deduce Eq. (4.1.32). Solution on page 410 An important consequence is that although the form of the energy changes, owing to the internal structure of the molecules, the gas will still satisfy Joule’s law of expansion. That is, since E depends only on T , expansion without the performance of work will occur without a change of temperature. Additional results are the expression for the speciﬁc heat at constant volume, CV = 3 2 Nk + Nk d dT ( T 2 d dT ln ζ) , (4.1.33) and the relationship between the speciﬁc heats at constant pressure and at constant volume, CP − CV = Nk , (4.1.34) as in a gas of pointlike molecules. Exercise 1.7 Deduce Eqs. (4.1.33) and (4.1.34). Solution on page 410 350 Ch. 1 An Ideal Gas of Molecules with... ε1 0 ε2 ε3 Fig. 4.1.4 The energy levels of the internal states in a molecular model. Exercise 1.8 A model molecule has states whose energies are depicted in Fig. 4.1.4. The energy of the ground is zero and of the ﬁrst excited state it is ϵ1. Suppose ϵ1 ≪ ϵ2,ϵ3,... . Calculate the corrections to the entropy, the internal energy and the speciﬁc heat, resulting from the internal structure of the molecules. How do these corrections behave when kT ≪ ϵ1? Solution on page 411 The chemical potential µ = ( ∂F ∂N ) T,V = kT [ ln N V − 3 2 ln ( 2πM kT h2 )] − kT ln ζ, (4.1.35) diﬀeringfrom (3.5.9) by the term −kT ln ζ. Monoatomic gas So far we have treated the atoms as the fundamental buildingblocks of the molecules and ignored the internal structure of the atoms themselves. That internal structure, in a monoatomic gas, consists of internal degrees of freedom (electronic or nuclear). To take those into account one repeats the entire discussion from the beginning of this section, with the internal partition function (4.1.27b) now calculated as a sum over the electronic energy levels of the (monoatomic) molecule. Nevertheless, gases such as helium or argon, namely noble gases, are very well described as a gas of particles devoid of internal structure. The reason is that the ﬁrst electronic excitation energy, ϵ1, is about 10 eV above the ground state; namely, it corresponds to a temperature of 105 K. Thus, in a wide range of temperature, which may be considered very low with respect to this 1.3 Gas of general composite molecules 351 temperature, we may take only the ﬁrst terms of Eq. (4.1.27b), which we write in the form ζ(T )= g0e −βϵ0 + g1e −βϵ1 + ··· = e −βϵ0[g0 + g1e −β(ϵ1−ϵ0) + ···] . (4.1.36) Note that room temperature is safely within this range. Here g0 and g1 are the number of diﬀerent atomic states havingenergies ϵ0 and ϵ1,re- spectively. These numbers are called the degrees of degeneracy or, simply, the degeneracies of the levels. degeneracy The degeneracy of the ground state has already been mentioned in Sec. 5.3 of Part III. In the helium atom, g0 =1. Since kT ≪ ϵ1 − ϵ0, the second term of (4.1.36) is negligible, and the internal partition function is a multiplicative factor of e−βϵ0. The sole eﬀect of such a factor is a constant shift of the energy levels, which does not change the thermodynamic quantities, as we have seen in Exercise 1.11 of Part III. If g0 =1, S and CV will, therefore, be as in an ideal gas, and the chemical potential will change by a constant — ϵ0. Exercise 1.9 Prove that S and CV of a monoatomic gas with g0 = 1 are identical to those of a gas of particles with no internal structure, if the temperature is low with respect to the ﬁrst electronic excitation energy. What about µ? Solution on page 413 Exercise 1.10 Consider a monoatomic gas, under the same conditions as in Exercise 1.9, but with a doubly degenerate ground state. Calculate the change in S, CV and in µ relative to their correspondingvalues in a gas of particles with no internal structure. Solution on page 413 We ﬁnd, therefore, that for the monoatomic gas there appears a char- acteristic temperature, of order 104–105 K, such that kΘe = ϵ1 . (4.1.37) Below this temperature the electronic degrees of freedom are frozen — there is not enough thermal energy to excite them. This, of course, is the answer to the heat capacity problem which we raised in Part I. Namely, the question why the electronic degrees of freedom do not contribute to the speciﬁc heat of gases. More on this in the following. 352 Ch. 1 An Ideal Gas of Molecules with... 1.4 Diatomic gas: classical treatment The next example is the diatomic molecule, which is a system composed of two nuclei, two large masses positively charged, and a group of electrons. The stability of the molecule implies that both nuclei “found out” that if they are separated by a distance ρ0, then their energy is at a minimum — any increase or decrease of this distance increases the energy. The calculation leadingto the determination of ρ0 is extremely complicated, since it requires the solution of the quantum-mechanical dynamics of both nuclei and of all the electrons. But, since the nuclei are very heavy compared to the electrons — their mass is several thousand times larger (mp/me ≃ 1840) — it is possible to simplify the problem usingthe Born–Oppenheimer approximation (for more details see standard text on quantum mechanics), which treats the diatomic system (as well as the many-atomic) in two stages: (a) First the nuclei are ﬁxed in their positions, and one calculates the behavior of the system of electrons. A crucial part at this stage is the calculation of the dependence of the energy of the electrons upon the internuclear distance. (b) Then the motion of the nuclei is treated as a slow motion with respect to the rapid motion of the electrons. The electrons always manage to accommodate themselves to the instantaneous state of the slow nuclei. The motion of the nuclei is determined by the dependence of the electronic energy upon the internuclear distance. When performing stage (a) one ﬁnds that only the ground state of the system of electrons is required. The rest of the electronic states have excitation energies of the order of 1 eV and thus are frozen, up to tem- peratures of several thousand degrees. The ground state energy of the electronic system ϵ0 depends on the distance ρ between the nuclei. This leads to the appearance of a potential energy ϵ0(ρ), aﬀectingthe motion of the nuclei, which is the U that appears, for example, in Eq. (4.1.18). If ϵ0 has a sharp minimum at a distance ρ0, it is possible to approx- imate ϵ0(ρ) by the harmonic approximation (4.1.19). The energy of the molecule will then be given by Emol = P2 2M + π2 2µ + 1 2 K(ρ − ρ0) 2 , (4.1.38) where wehaveused the notations π12 = π, ρ12 = ρ, U ′′(ρ0)= K,and dropped ϵ0(ρ0), a constant which determines the ground state energy of the molecule. Note:if ϵ0 depends only on the distance between the nuclei and not on the direction, the potential depends only on |ρ| = ρ. 1.4 Diatomic gas: classical treatment 353 The free energy will thus be, according to Eq. (4.1.28), F = Fc.m. − NkT ln ζ, (4.1.39) where Fc.m. has the same form as the free energy of a monoatomic gas [Eq. (3.5.7)]. The function ζ is given by (4.1.27b): ζ(T )= ∑ n e −βϵn . (4.1.40) n speciﬁes the quantum states of the system, whose energy is given by the last two terms of (4.1.38). That is the energy of internal motions EI : EI = π2 2µ + 1 2 K(ρ − ρ0) 2 . (4.1.41) In other words, after the separation of the center-of-mass energy, we are left with an internal energy of a particle of mass µ, movingin athree- dimensional harmonic potential. The potential energy term causes radial vibrations around the equilibrium point ρ = ρ0. If the vibrations are small their frequency is ω = √ K µ . (4.1.42) In addition rotations are, of course, also allowed and we shall discuss them in the next section. Both types of motion are illustrated in Fig. 4.1.2. The calculation of ζ(T ) passes through a computation of the quantum energy levels of the molecule. We perform the quantum calculation in the next section. First, we note that if the temperature T is high with respect to the energies of the ﬁrst excited states, it is possible to treat the variables π and ρ as classical variables. The condition imposed on the temperature is kT ≫ ¯hω . (4.1.43) A typical value of ω is 1013 s−1;¯h ≃ 10−34 J · s. Hence the classical approximation is justiﬁed for kT ≫ 10−21 Jor T ≫ 100 K. Yet we still assume that the temperature is too low to excite the electronic states. To calculate the internal partition function we ﬁrst write it as an integral over position and momentum: ζ(T )= 1 h3 ∫ d 3πd 3ρ exp { −β [ π2 2µ + 1 2 K(ρ − ρ0) 2]} = ( 2πµkT h2 )3/2 ∫ d 3ρ exp [ − βK 2 (ρ − ρ0) 2] . (4.1.44) 354 Ch. 1 An Ideal Gas of Molecules with... In the second integral the integrand depends only on ρ and not on ρ. Hence ∫ d 3ρ exp [ − βK 2 (ρ − ρ0) 2] =4π ∫ ∞ 0 ρ 2 exp [ − βK 2 (ρ − ρ0) 2] dρ (4.1.45) after performing the angular integrations. The last integral is calculated approximately. Since we know how to calculate the integral when the lower limit is −∞ (instead of 0), we assume that the center of the bell-like curve is very far from the origin (compared to its width; see Fig. 4.1.5). This is the case if ρ 2 0 ≫ 1 βK , (4.1.46a) or kT ≪ Kρ 2 0 . (4.1.46b) Havingassumed this, the integral is well approximated by ∫ ∞ −∞ ρ 2 exp [ − βK 2 (ρ − ρ0) 2] dρ ≃ ρ 2 0 √ 2π βK . (4.1.47) ρo ρ➤ ➤ 1/ √βK<<ρo ➤➤➤ Fig. 4.1.5 When conditions (4.1.46) hold it is possible to treat the bell as if it extended from −∞ to +∞. Exercise 1.11 Prove Eq. (4.1.47). Solution on page 414 Before proceedingto calculate the partition function, we check the range of temperature to which condition (4.1.46) constrains us. Recalling that ρ0 ≃ 10−9 m, ω ≃ 1013 s−1 and µ ≃ 10−26 kg(about 10 proton masses), we obtain Kρ 2 0 = µω2ρ 2 0 ≃ 10 −18 J , (4.1.48) namely kT ≪ 10−18 Jor T ≪ 105 K. 1.4 Diatomic gas: classical treatment 355 We have found that the temperature range for which both of the con- ditions (4.1.43) and (4.1.46) are satisﬁed is 103–104 K. The internal parti- tion function in this temperature range is obtained by substituting (4.1.47) and (4.1.45) into (4.1.44): ζ(T )= ( 2πµkT h2 )3/2 · 4πρ 2 0 √ 2πkT µω2 = 2µρ2 0(kT )2 ¯h 3ω . (4.1.49) Substitutingthe last result into Eq. (4.1.39), we obtain the free energy: F = Fc.m. − 2NkT ln ( kT C ) , (4.1.50) where C is a constant dependingon the properties of the molecules (ω, ρ0,µ) but not on T . Using(4.1.49) we also ﬁnd that the speciﬁc heat at constant volume is given by CV = 7 2 Nk ; (4.1.51) namely, the speciﬁc heat of the gas of N diatomic molecules is larger than the speciﬁc heat of the gas were the atoms free (3Nk). The bond between the atoms increases the speciﬁc heat, as we hinted in Sec. 1.3 of Part I. Exercise 1.12 (a) Calculate the internal energy of a diatomic molecule, in the classical approximation, and show that the speciﬁc heat is indeed given by (4.1.51). (b) If the speciﬁc heat is given by (4.1.51), what is the ratio CP /CV = γ? (c) Compare your result with the experimental values for the diatomic gases in Table 4.1.1. Is agreement to be expected for these gases at room temperature? What about 1000◦C? Table 4.1.1 Experimental values of γ. H2 N2 CO NO O2 T = 273 K 1.410 1.400 1.400 1.384 1.397 T = 1273 K 1.349 1.314 1.310 1.303 1.295 Solution on page 414 356 Ch. 1 An Ideal Gas of Molecules with... Exercise 1.13 (a) For the gas Cl2, ω ≃ 1014 s−1 and the interatomic distance is about 2 ˚A. What is the range of temperatures for which the approximations we made for ζ are justiﬁed? (b) How will the integrand in (4.1.44) look, graphically, at a temperature of 1500 K? Solution on page 415 1.5 Diatomic molecules: vibration and rotation The problem of the discrepancy between the theoretical and experimen- tal values of the speciﬁc heat of a diatomic gas has been solved in the framework of quantum mechanics. Here we shall not enter into a detailed discussion on the quantum method. We shall turn to it only in order to obtain the values of the energies of the diﬀerent states of the internal system, which is characterized by (4.1.41), as well as the degeneracies of the various energy levels, namely the number of diﬀerent states of equal energy. The solution is based, as we have already mentioned several times, on the fact that the internal energy of the molecule is not continuous, but assumes discrete values. In order to “feel” the excited states a high enough temperature is required, otherwise most of the molecules remain in the ground state and the internal degrees of freedom are frozen. But this is not the whole story. The internal energy of a diatomic molecule has two diﬀerent sources. In addition to the molecular vibrations, discussed in the classical context in the previous section, the molecule can also rotate with respect to its center of mass. Hence it is natural to separate the kinetic part of the internal energy, Eq. (4.1.41), into a (one-dimensional) radial part and a part correspondingto the rotational (two-dimensional) motion: π2 2µ = π2 ρ 2µ + ℓ 2 2µρ2 , (4.1.52) where πρ is the (relative) momentum component along ρ and ℓ is the angular momentum of the molecule with respect to its center of mass: πρ = µ ˙ρ = π · ρ ρ , (4.1.53a) ℓ = µρ × ˙ρ = ρ × π . (4.1.53b) This is the standard procedure used in the analysis of the two-body problem in classical mechanics. 1.5 Diatomic molecules: vibration and rotation 357 Exercise 1.14 Usingdeﬁnitions (4.1.53), prove Eq. (4.1.52). Solution on page 416 The internal energy (4.1.41) becomes the sum of a vibrational part and a rotational part: EI = π2 ρ 2µ + K 2 (ρ − ρ0) 2 + ℓ 2 2µρ2 . (4.1.54) The next stage is to ﬁnd the quantum energy levels of the molecule de- scribed by (4.1.54), and to calculate with their help the internal partition function ζ(T ). The diﬃculty is in the fact that the energy in (4.1.54) is not the sum of two independent terms, since the relative distance ρ ap- pears in the vibrational energy as well as in the rotational energy. But, since at reasonable temperatures the stretchingof the molecules does not exceed 10% of ρ0 (cf. Exercise 1.3), and anyway in applyingthe harmonic approximation (4.1.19) we have already restricted ourselves to small vi- brations around ρ0, we can treat the rotations as if they occurred for a molecule of constant ρ,equal to ρ0. Compare to the approximation (4.1.47), which was made for the case where the Boltzmann factor is very concentrated around ρ = ρ0. We may therefore write EI = π2 ρ 2µ + K 2 (ρ − ρ0) 2 + ℓ 2 2I , (4.1.55) where I = µρ2 0 is the molecule’s moment of inertia with respect to its center of mass. Before going on, we consider the orders of magnitude involved. To this end we use several typical values of I which are given in Table 4.1.2. Table 4.1.2 Moments of inertia of simple molecules. Molecule I in units of 10 −47 kg · m 2 H2 0.46 HCl 2.4 Cl2 115 I2 745 358 Ch. 1 An Ideal Gas of Molecules with... Exercise 1.15 (a) Show that µρ2 0 is indeed the moment of inertia of a diatomic molecule with respect to its center of mass. (b) Calculate µ and ρ0 for the four molecules that appear in Table 4.1.2. Solution on page 416 Now, with the expression (4.1.55) for the internal energy of a diatomic molecule at our disposal, we can without much eﬀort ﬁnd the quantum states and their energy levels. Because the energy can be written natu- rally as the sum of two types of energies, i.e. a vibrational energy and a rotational energy, we shall discuss each of them separately. Vibrational levels The ﬁrst two terms of (4.1.55) describe a one-dimensional harmonic os- cillator. We have treated such an oscillator in Part III, and we already know that its states are characterized by the degree of excitation n and that its energies are quantized according to Ev(n)= ( n + 1 2 ) ϵv , (4.1.56) where ϵv is the spacingbetween the vibrational levels: ϵv =¯hω =¯h √ K µ . (4.1.57) For example, in a chlorine molecule Cl2, ω =1014 s−1 and hence the spacingbetween the vibrational levels is 10−20 J, which is about 0.06 eV. To these spacings there corresponds a characteristic temperature: Θv = ϵv k . (4.1.58) Above this temperature the “frozen” vibrational levels can “unfreeze.” For chlorine Θv ≃ 700 K. Rotational states The third term of Eq. (4.1.55) describes the energy of the rotational mo- tion of the molecule with respect to its center of mass, in terms of the internal angular momentum of the molecule, ℓ. Several aspects of the quantum angular momentum have already been mentioned in Part II (Chap. 2), but this is the place to include some additional aspects. Thus, we present a brief summary of the main results of the quantum analysis of the properties of the angular momentum: 1.5 Diatomic molecules: vibration and rotation 359 (a) The quantum angular momentum of a system assumes discrete values only, which are characterized by a nonnegative integer or half-integer J. (b) The absolute value of the angular momentum is given by |J| = √ J(J +1) . (4.1.59) J is dimensionless and measures the angular momentum of the system in units of ¯h (see Sec. 2.1 of Part II). (c) Each of the angular momentum’s components is also quantized, as- sumingonly discrete values. For instance, Jz = −J, −J +1,... ,J − 1,J . (4.1.60) (d) Due to the uncertainty principle it is impossible to obtain more in- formation on the angular momentum than its magnitude |J| and the value of one of its components, which is usually chosen as Jz.Thus each state of a quantum system, for which the angular momentum is conserved, is characterized by two numbers: J and Jz.For a given J there are 2J + 1 diﬀerent possible states (all the allowed values of Jz). We shall now use all of the above in order to ﬁnd the energy levels of the rotational quantum states — the rotational levels. The rotational levels are obtained from the last term on the right hand side of Eq. (4.1.55), which we call rotational energy. Since ℓ is an orbital angular momentum (no spin) we can write ℓ =¯hJ . (4.1.61) Thus we can use (4.1.59) for the allowed values of the angular momentum squared in the notational energy Er(J)= J(J +1)ϵr , (4.1.62) where ϵr, ϵr = ¯h 2 2I , (4.1.63) determines the diﬀerence between the rotational levels. This is the place to stress that since the origin of the angular momentum here is orbital, the allowed values of J are integers, and not half-integers, as may occur in systems in which the energy also depends upon the electronic spins. To obtain some orders of magnitude, we again take the example of the chlorine molecule, whose moment of inertia appears in Table 4.1.2: I = 1.15 × 10−45 kg · m2.The value of ϵr is 4 × 10−24 J, which is 2.5 × 10−5 eV. 360 Ch. 1 An Ideal Gas of Molecules with... The correspondingtemperature above which the rotational levels un- freeze, Θr = Er(1) − Er(0) k = 2ϵr k , (4.1.64) is much lower than Θv. For chlorine this temperature is 0.7 K. Exercise 1.16 Calculate ϵv, Θv,ϵr, Θr for HCl (ω =5.7 · 1014 s−1). Solution on page 417 Exercise 1.17 How many rotational levels ﬁt into one vibrational level spacingin Cl2 andinHCl? Solution on page 417 Having investigated the properties of both types of internal energies of a diatomic molecule, i.e. the vibrational energy and the rotational energy, we can ﬁnd the quantum energy levels of the whole molecule. The energy levels will be characterized by two numbers, n and J, and will be a sum of (4.1.56) and (4.1.62): EI (n, J)= ϵvn + ϵrJ(J +1) ,n, J =0, 1, 2,... , (4.1.65) where we have dropped the ground state vibrational energy, just as we ignored ϵ0(ρ0) on the way to obtaining(4.1.38). To characterize the quantum states of a diatomic molecule, we need to specify the degree of excitation of the vibrational motion as well as that of the rotational state. The energy is determined by n and J, while a state is speciﬁed giving n, J and Jz. The vibrational state is nondegenerate, while the rotational state has a degeneracy of 2J + 1, since its energy does not depend on Jz for a given J. Hence the energy level EI (n, J)has a degeneracy of 2J +1. The next step is, of course, the calculation of the internal partition function. This is, as usual, a sum of the Boltzmann factors of all the quantum states. We get ζ = ∞∑ n=0 ∞∑ J=0 (2J +1) exp{−β[ϵvn + ϵrJ(J +1)]} . (4.1.66) The factor 2J + 1 is the degeneracy of the state with given J and n.It corresponds to the summation over Jz.Since the energy is a sum of two independent terms, the partition function becomes again a product of two 1.6 The equipartition principle and its violation 361 factors, one dependingonly on the vibrational states and the other only on the rotational states: ζ = ζvζr , (4.1.67) where ζv = ∞∑ n=0 e −βϵvn , (4.1.68a) ζr = ∞∑ J=0 (2J +1)e −βϵr J(J+1) . (4.1.68b) 1.6 The equipartition principle and its violation The factorization of the internal partition function into the product of a vibrational factor and a rotational factor is not special to the quantum case. It was possible since the approximations we made rendered the internal energy of the molecule a sum of a vibrational contribution and a rotational contribution. Hence the factorization of (4.1.67) is general. The full single molecule partition function will be a product of three factors, obtained from substitution in Eq. (4.1.26): z = zc.m.ζvζr . (4.1.69) The pedant may multiply (4.1.69) by other factors corresponding to the degrees of freedom of the electrons, the nucleons, etc. The free energy becomes a sum of terms describing the diﬀerent mo- tions: the usual (monoatomic) term Fc.m., correspondingto the center of mass motion, and terms correspondingto the vibrational motion, the rotational motion, etc.: F = Fc.m. − NkT (ln ζv +ln ζr)= Fc.m. + Fv + Fr . (4.1.70a) The energy of the gas, or the average energy per molecule, is written in the same manner: ⟨ϵ⟩ = − ∂ ∂β ln z = − ∂ ∂β (ln zc.m. +ln ζv +ln ζr) = ⟨ϵc.m.⟩ + ⟨ϵv⟩ + ⟨ϵr⟩ . (4.1.70b) The separability of the energy into independent terms lies at the very basis of the equipartition principle (see Part III, Sec. 4.3), accordingto which each degree of freedom appearing quadratically in the energy contributes to the energy an amount 1 2 kT , and thus contributes to the speciﬁc heat an amount 1 2 k. 362 Ch. 1 An Ideal Gas of Molecules with... The center-of-mass motion of a molecule is associated with three de- grees of freedom, which are the three components of P, and thus ⟨ϵc.m.⟩ = 3 2 kT . The vibrational motion has two degrees of freedom — one is the vibrational kinetic energy π2 ρ/2µ, and the other is the harmonic potential term. In total, ⟨ϵv⟩ = kT . The rotational motion of the diatomic molecule as described by ℓ 2/2I has two degrees of freedom (not three), since the diatomic molecule can only rotate around two independent axes. Rotations around the axis that passes through both atoms do not contribute to the energy. In other words, the decomposition of π2/2µ in Eq. (4.1.52) was performed in such a way that the radial component was separated and taken into account in the vibrational energy, and there remain two momentum com- ponents normal to the direction of ρ, which describe the rotational mo- tion. Hence for the rotational motion, ⟨ϵr⟩ = kT . In total we ﬁnd from the equipartition principle that the average energy of a diatomic molecule is 7 2 kT , and that the speciﬁc heat at constant volume of a diatomic gas is 7 2 Nk. We have already obtained this result by direct calculation in (4.1.51). All of the above assertions follow from the equipartition theorem, which is valid only for classical systems. Hence all of the above describes the behavior of a diatomic gas in a limited range of temperatures. The ex- tent of this range is determined by the characteristic temperatures which have appeared in our discussion in Secs. 1.3 and 1.5 — Θe ≃ 104 K, Θv ≃ 103 K, Θr ≃ 10 K — and which determine the range of excitation of the respective degrees of freedom. Since we are not interested in the detailed structure of the atoms which come into play at temperatures above Θe, we shall restrict ourselves to temperatures below Θe. At temperatures Θv <T < Θe all the degrees of freedom that were discussed are excited, so that the speciﬁc heat attains its “equipartition value,” 7 2 Nk. At temperatures below Θv the speciﬁc heat problem begins to emerge: the speciﬁc heat becomes smaller than its classical value. The reason is, of course, thatattemperatures Θr <T < Θv only the rotational degrees of freedom are excited (in addition, of course, to the center-of-mass degrees of freedom, which are never “frozen”). The vibrational degrees of freedom are not excited, and the vibrational contribution to the internal energy and to the speciﬁc heat is negligibly small. At these temperatures we are in the range in which the vibrational contribution to the speciﬁc heat is given by (3.2.18); it is exponentially small. This means that one k out of the 7 2 k of the speciﬁc heat per molecule disappears at these temperatures. Thus CV becomes smaller not only than the classical value of a diatomicfrozen degrees of freedom molecule but even than the classical value of two separate atoms: the vibrational degrees of freedom are frozen. 1.7 Diatomic gas — quantum calculation 363 If we now lower the temperature further, to the range T< Θr,the rotational degrees of freedom freeze as well. In the classical approxima- tion two degrees of freedom correspond to the rotational motion, which contribute a single k to the speciﬁc heat per molecule. When T ≪ Θr, CV → 3 2 Nk, namely at these temperatures the diatomic molecules behave as structureless point particles. We therefore have three temperature scales: (1) Electronic — 1 eV, (2) Vibrational — 0.1 eV, (3) Rotational — 0.001 eV, and correspondingly temperature regions and characteristic temperatures. 1.7 Diatomic gas — quantum calculation We have seen that the internal partition function decomposes into a prod- uct of independent factors, which leads to the appearance of additive con- tributions to the free energy corresponding to each of the diﬀerent factors of the partition function. We are left with the task of calculatingthe separate parts of the internal partition function. The vibrational part (4.1.68a) has in fact already been calculated in the previous part, and is exactly the partition function of a single harmonic oscillator Eq. (3.2.7) without the ground state energy term. It reads ζv = 1 1 − e−Θv /T , (4.1.71) and its contribution to the speciﬁc heat is obtained by the appropriate substitutions in (3.2.16): (∆CV )v N = k ( Θv T )2 eΘv/T (eΘv /T − 1)2 . (4.1.72) Note that unlike the case of the Einstein solid, where the fact that all the atoms have the same frequency is only an approximation, here all the molecules do indeed have an identical vibrational frequency. In order to complete the discussion we have to calculate ζr.The summation in (4.1.68b) is hard to perform, and hence we shall treat it in two limits: (a) Low temperatures — T ≪ Θr. It suﬃces to take the ﬁrst two terms in the sum, namely those with J =0 and J =1: ζr ≃ 1+ 3e −Θr /T , (4.1.73) 364 Ch. 1 An Ideal Gas of Molecules with... and the contribution to the speciﬁc heat will be accordingto (4.1.33): (∆CV )r N = k d dT ( T 2 d dT ln ζr ) ≃ 3k ( Θr T )2 e −Θr/T ; (4.1.74) the derivation is left to Exercise 1.18. The right hand side of (4.1.74) tends to zero as T → 0, namely the two rotational degrees of freedom freeze. (b) High temperatures — T ≫ Θr. It is possible to approximate the sum (4.1.68b) by an integral, since the terms in the sum change almost continuously. See, for example, the derivation of Eq. (3.4.33). ζr ≃ ∫ ∞ 0 dJ(2J +1)e −J(J+1)Θr /2T = 2T Θr (4.1.75) and the contribution to the speciﬁc heat will be k as for two classical degrees of freedom. Exercise 1.18 (a) Obtain the right hand side of Eq. (4.1.74). (b) Prove (4.1.75). (c) Prove that (4.1.75) implies a contribution of k to the speciﬁc heat per molecule. Solution on page 418 The behavior of the speciﬁc heat as a function of the temperature is depicted in Fig. 4.1.6. Note that our explanation is still incomplete, and that there are still regions in the graph that are not “covered.” Further study of this topic will take us too far aﬁeld.➤ ➤ CV/Nk 7/2 5/2 3/2 Θr Θv T electronic degress of freedom unfreeze vibrational degrees of freedom unfreeze rotational degrees of freedom unfreeze experiment (logarithmic scale) theory Fig. 4.1.6 The behavior of the speciﬁc heat of a diatomic gas as a function of the temperature. 1.7 Diatomic gas — quantum calculation 365 In summary: (1) The free energy of a gas of molecules with internal structure is a sum of a free energy related to the center-of-mass motion and of a free energy related to the internal motions in the molecules: F = Fc.m. + FI. (2) The internal motion comprises the motion of the electrons and the motion of the heavy nuclei. The motion of the nuclei may be further reduced to notations and vibrations. (3) The treatment of the internal motions must be quantum-mechanical (if we are interested in temperatures which are not exceptionally high). There appear diﬀerent scales of energy spacings. Each energy spacing — electronic, vibrational, rotational or other — determines a charac- teristic temperature. (4) If the temperature is very high, the speciﬁc heat can be calculated classically. The intramolecular forces increase the speciﬁc heat above its value for a gas of unbonded (free) atoms. (5) As the temperature decreases, each time it crosses a characteristic temperature of one of the internal motions, the corresponding degree of freedom freezes, and ceases to contribute to the speciﬁc heat or to the internal energy. Chapter 2 Gases in Chemical Reactions 2.1 Conditions for chemical equilibrium So far we have discussed gases whose basic building blocks are molecules. First (Chaps. 3 and 4 of Part III) we described the molecules as pointlike objects without any internal structure, and obtained the laws of ideal gases. In the second stage (Chap. 1 of this part) we took into account the internal structure of the molecules and the internal degrees of freedom — rotation and vibration — and mentioned the possibility of electronic excitations. We still have not considered the possibility of a molecule disintegrating into its constituent atoms, or its participating in a chemical reaction. In real gases collisions between molecules occur incessantly at diﬀerent energies. In some cases, due to highly energetic collisions at least one of the molecules involved will disintegrate. On the other hand, of course, the opposite process can also occur, i.e. two free atoms which have lost their partners will meet and recombine to form a molecule. More often than not, no free atoms are left. Instead new types of molecules are created. A typical example is the process of the formation and dissociation of water molecules, as described by the reaction between molecules (not between atoms): 2H2 +O2 ⇀↽ 2H2O . In the system in which this reaction is takingplace there are three types of molecules. There are molecules that disappear in the reaction, and there are others that appear. The molecules appear and disappear at constant proportions. Thus, if an oxygen molecule disappears, then twice as many hydrogen molecules must disappear, and as many water molecules must appear, etc. Let dN1 denote the change in the number of hydrogen molecules, dN2 the change in the number of oxygen molecules, and dN3 the change in the number of water molecules. The reaction must satisfy the relations dN1 =2dN2,dN3 = −dN1 (4.2.1a) 366 2.1 Conditions for chemical equilibrium 367 or dN1 dN2 =2 , dN1 dN3 = −1 . (4.2.1b) We can write a general formula for a chemical reaction of molecules of types B1,... ,BM in the followingmanner: b1B1 + b2B2 + ... + brBr ⇀↽ br+1Br+1 + ... bM BM , where Bi are the chemical formulae of the molecules that appear and disappear, and bi are the smallest integers for which there are no leftovers from the reaction. In the above example, B1 =H2 ,b1 =2 , B2 =O2 ,b2 =1 , B3 =H2O ,b3 =2 . The generalization of (4.2.1) will be a relationship between the changes in the number of molecules of the diﬀerent types. If dNi (i =1,... ,M )is the change in the number of molecules of type Bi, then the relationship that guarantees that the total number of atoms, of all types, does not change in the reaction is dNi dNj = νi νj , (4.2.2) where νi = −bi,i =1,... ,r , νi =+bi,i = r +1,... ,M . In the above example, ν1 = −2 , ν2 = −1 , ν3 =2 . Note that we assume here that the atoms do not disintegrate in the collisions. Let us suppose that the reaction takes place under conditions of con- stant temperature and constant volume. In this case, equilibrium will be attained when the free energy F is minimal. Thus, changes in the num- ber of molecules will occur only if they reduce F . When the system has reached a state where the number of molecules of type Bi is such that F is minimal, no more changes will occur. The condition dF = 0 (4.2.3) 368 Ch. 2 Gases in Chemical Reactions determines the relationship between the number of molecules of diﬀerent types. Since we are assumingconstant T and V and are only allowingthe number of molecules Ni to change, dF is the change in the free energy resultingfrom the changes dNi in the numbers of molecules, i.e. dF = M∑ i=1 ( ∂F ∂Ni ) T,V dNi = M∑ i=1 µidNi =0 , (4.2.4) where µi is the chemical potential of the molecules of type Bi. If we now substitute into Eq. (4.2.4) the relation which balances the reaction, Eq. (4.2.2), we obtain the condition for equilibrium: M∑ i=1 νiµi =0 . (4.2.5) Exercise 2.1 Prove Eq. (4.2.5). Solution on page 419 The νi are constant integers (positive and negative). µi depend on the number (per unit volume) of molecules of each type. Therefore, (4.2.5) provides a relation between the densities of molecules in a state of equi- librium, and the temperature. Exercise 2.2 Consider the followingreactions: (a) 4NH3 +3O2 ⇀↽ 2N2 +6H2O, (b) 2C4H10 + 13O2 ⇀↽ 8CO2 + 10H2O. What is the form of Eq. (4.2.5) in each case? Solution on page 419 2.2 The law of mass action In order to obtain the explicit form of the relationship between the densi- ties of molecules and the temperature, we substitute into Eq. (4.2.5) the explicit form of the chemical potential, Eq. (4.1.35): kT M∑ i=1 νi [ ln ni − 3 2 ln ( 2πMikT h2 ) − ln ζi ] =0 , (4.2.6) 2.2 The law of mass action 369 where ni is the density of molecules of type i,and Mi is their mass. ζi contains the information about the internal structure of the molecules, namely, to what extent they tend to participate in chemical reactions. From here we can immediately obtain the law of mass action: law of mass action nν1 1 ··· nνM M = n|νr+1| r+1 ··· n|νM | M n|ν1| 1 ··· n|νr| r = K(T ) . (4.2.7) The right hand side, which is called the chemical equilibrium constant, is given by chemical equilibrium constant K(T )= M∏ i=1 [( 2πMikT h2 )3/2 ζi(T ) ]νi , (4.2.8) Note that for a given reaction the equilibrium constant depends only on the temperature. Exercise 2.3 Deduce (4.2.7) and (4.2.8) from (4.2.6). Solution on page 420 The law of mass action is a very important tool in physical chemistry (it was discovered by Guldbergand Waage in 1867). For instance, if the equilibrium constant in (4.2.7) K(T ) is known, then it is possible to obtain the concentrations of materials in the system at any temperature. Larger K(T ) implies higher product concentrations. In the example of the formation of water from hydrogen and oxygen, we obtain from Eq. (4.2.7) n2 3 n2 1n2 = K(T ) , (4.2.9) where n1,n2,n3 are respectively the densities of the hydrogen molecules, oxygen molecules and water molecules. Equation (4.2.9) is a single equa- tion with three unknowns. But the total amounts of hydrogen and oxygen in the system are known. If we denote the number of hydrogen atoms per unit volume by nH and the number of oxygen atoms per unit volume by nO, then the two additional equations will be nH =2n3 +2n1 , (4.2.10a) nO = n3 +2n2 , (4.2.10b) and now we have three equations with three unknowns. 370 Ch. 2 Gases in Chemical Reactions Exercise 2.4 (a) Obtain the law of mass action for the ﬁrst reaction in Exercise 2.2. (b) Show that it is possible to obtain enough equations in order to ﬁnd all the constituents of this reaction at equilibrium. (c) Calculate the equilibrium constant, assumingthat the internal parti- tion functions are known. Solution on page 420 The functions ζi may be determined from experiment. There exist precise measurements of the emission spectrum and absorption spectrum of various molecules. The spectrum reﬂects the energy diﬀerences between the diﬀerent levels of the molecule which are needed for calculatingthe internal partition function. Actually, for the calculation only the low levels of the molecule are required, i.e. levels whose energies are not large with respect to kT . In other words, spectroscopic measurements make it possible, with the help of (4.2.8) [and (4.1.27b)], to predict the equilibrium constant of a chemical reaction! Before proceeding, we note that in calculating the functions ζi for the diﬀerent types of molecules participatingin the reaction it is not possible to ignore the minimal value of the internal energy, as we have done in obtainingEq. (4.1.38). The reason is that the formation or dissociation of molecules in the reaction involves energy changes. For instance, the dissociation of water into hydrogen and oxygen requires energy. Therefore a water molecule must have a lower internal energy than free hydrogen and oxygen molecules. This fact is accounted for by choosing the ground state energy in a consistent manner for all the molecules. A simple example is presented in the next section. In order to comprehend the meaningof the law of mass action, and especially the meaningof the equilibrium constant, we shall now show that chemical equilibrium is actually determined by the free energy change in the reaction. The startingpoint is Eq. (4.2.5) with the chemical potential of the molecule of type i written in the general form µi = ∂F ∂Ni = − ∂ ∂Ni kT ln Z. (4.2.11) Recall that the partition function is the product of the partition functions of all the types of molecules [Eq. (3.5.4)]: Z = M∏ i=1 (zi)Ni Ni! . (4.2.12) 2.2 The law of mass action 371 Diﬀerentiatingwith respect to Ni, and usingStirling’s approximation ln n! ≃ n ln n − n, we obtain the followinguseful expression for the chem- ical potential: µi = −kT ∂ ∂Ni [Ni ln zi − ln(Ni!)] = −kT ln ( zi Ni ) . (4.2.13) Substitutingthis expression into (4.2.5) we obtain kT M∑ i=1 νi ln ( zi Ni ) = 0 (4.2.14) or −kT M∑ i=1 νi ln Ni = −kT M∑ i=1 νi ln zi . (4.2.15) The expression −kT ln zi may be thought of as the free energy of a single molecule of type i [cf. (3.5.10)]. Hence the right hand side of (4.2.15) is nothingbut the sum of all the free energies involved in a given reaction multiplied by the number of molecules of each type. It describes, therefore, the free energy change in the reaction, and hence we shall denote it by ∆F0.Thus we obtain ∑ i ln(N νi i )= − ∆F0 kT . (4.2.16) Recallingthat Ni = Vni and comparingwith Eq. (4.2.7) we arrive at N ν1 1 ··· N νM M =exp ( − ∆F0 kT ) = K(T ) · V ν1+...+νM . (4.2.17) Equation (4.2.17) clariﬁes the connection between the equilibrium con- stant and the free energy change in the reaction, ∆F0. This quantity determines the “degree of expedience” for the reactants to turn into prod- ucts. Negative ∆F0 describes a decrease in the free energy due to the reaction, and thus K will be large and at equilibrium the density of the products will be high. Conversely, positive ∆F0 describes a reaction which leads to an increase in the free energy, and is thus disadvantageous ener- getically. In this case the product density is low. Exercise 2.5 What would the law of mass action look like if we had not introduced the correction implied by Gibbs’ paradox? Solution on page 421 372 Ch. 2 Gases in Chemical Reactions Another point worth consideringis the system’s response to tempera- ture changes, as determined by the temperature dependence of the equi- librium constant. To this end it is convenient to express K in terms of the single molecule partition functions of all the types of participating molecules. In order to do this we return to (4.2.17). Expressing Ni in terms of the densities and the volume we obtain (4.2.7) again, where K or ln K is given in terms of the single molecule partition functions: ln K = M∑ i=1 νi ln ( zi V ) . (4.2.18) Note that in spite of the explicit appearance of the volume on the right hand side, K remains volume-independent, since zi is proportional to the volume. We obtain an interestingresult for the temperature dependence of K. Diﬀerentiating(4.2.18) we obtain d ln K dT = M∑ i=1 νi ∂ ln zi ∂T . (4.2.19) ∂ ln zi/∂T is the average energy per molecule of type Bi apart from a factor kT 2 [see (3.1.3)], and hence d ln K dT = ∆E0 kT 2 . (4.2.20) ∆E0 is the energy increase when the reaction is performed in a given direction. If ∆E0 is positive, the reaction absorbs heat (the energy of the products is higher than the energy of the reactants). In this case K increases as the temperature rises, since the right hand side is positive, and the equilibrium will tend in the direction of the products. Hence, as the temperature is increased, the reaction proceeds in the direction in which heat is absorbed and the temperature change is canceled. This is an example of Le Chatelier’s principle. Exercise 2.6 What happens if ∆E0 < 0? Solution on page 421 Le Chatelier’s principle may be formulated in a more general mannerLe Chatelier’s principle in the followingform: If the external conditions change, the equilibrium state of a chemical reaction will change in a manner that decreases the external change. 2.3 Dissociation in a diatomic gas 373 2.3 Dissociation in a diatomic gas To end this chapter, and as a “concludingexercise” for our discussion of diatomic gases, we apply the law of mass action to the calculation of the degree of dissociation of a diatomic gas, namely to the calculation of the relative part of the dissociated molecules in the gas. We suppose that the degree of dissociationgas molecules are composed of identical atoms (like Cl2), and the gas is at a temperature in the range Θr ≪ T ≪ Θe. If we denote the atoms of the gas by A, the reaction of formation and dissociation of the molecules will be given by 2A ⇀↽ A2 . Hence at equilibrium the gas consists of free atoms at density n1 and molecules at density n2,sothat b1 =2,b2 =1 , ν1 = −2,ν2 =1 , and by Eq. (4.2.7) n2 n2 1 = K(T ) . (4.2.21) There is an additional equation, relatingthe total density of atoms, nA, to the density of molecules and of free atoms. It reads nA = n1 +2n2 . (4.2.22) Substituting(4.2.22) into (4.2.21) we obtain a quadratic equation for n1: 2Kn2 1 + n1 − nA =0 , (4.2.23) whose positive solution is n1 = √ 1+ 8KnA − 1 4K . (4.2.24) The density of disintegrated molecules is of course 1 2 n1, as each molecule is composed of two atoms. The density of molecules, were they all to remain bound, would be, for the same reason, 1 2 nA. Hence the degree of dissociation will be α = 1 2 n1 1 2 nA = √ 1+ 8KnA − 1 4KnA . (4.2.25) Note that when K is very small, α → 1, hence n1 → nA,which means that most of the molecules dissociate. When K is very large, α → 0, hence most of the gas is diatomic. 374 Ch. 2 Gases in Chemical Reactions The temperature dependence of K is obtained from Eq. (4.2.8): K = h3 (2πkT )3/2 M 3/2 2 ζ2 M 3 1 ζ 2 1 . (4.2.26) We substitute the internal partition functions of the atoms and of the molecules. Because the temperature is much lower than the electronic excitation energy, we may write ζ1 =1. Regarding ζ2, weﬁrstwriteit as a product of a rotational part and a vibrational part: ζ2 = ζrζv . (4.2.27) Since T ≫ Θr, we can use the expression (4.1.75): ζr = 2T Θr = 2IkT ¯h 2 , (4.2.28) where I is the moment of inertia of the molecule. The vibrational part requires some thought: The initial tendency is to use (4.1.71) as it stands. But we must recall that ignoring the dependence on the ground state energy was legitimate only when the gas was com- posed entirely of molecules. When there are also single atoms, we must ﬁx a common ground state for the energies of the atoms as well as the energies of the molecules. The fact that we have already written ζ1 =1 is equivalent to havingchosen the potential energy of a free atom to be zero. Hence we must add to the energies of the harmonic oscillators the minimal potential energy U (ρ0) [Eq. (4.1.19)], which is negative, as well as the quantum ground state energy 1 2 ϵv [Eq. (4.1.56)]. Designating their sum as the dissociation energy, −ϵD = U (ρ0)+ 1 2 ϵv , (4.2.29) we can write the vibrational partition function in the form ζv = ∞∑ n=0 e −β(−ϵD+ϵvn) = e βϵD ∞∑ n=0 e −βϵvn , (4.2.30) which is, of course, the partition function (4.1.68a) multiplied by a factor which translates the zero point of the energy. The result of the summation is given by (4.1.71), so that ζv = eϵD/kT 1 − e−Θv/T (4.2.31) 2.3 Dissociation in a diatomic gas 375 and ζ2 = 2IkT ¯h 2 eϵD/kT 1 − e−¯hω/kT , (4.2.32a) where wehavewritten ¯hω instead of kΘv [Eqs. (4.1.57) and (4.1.58)]. Yet there is another factor which we have ignored so far: It is the fact that the molecules A2 are composed of two identical atoms. As a result we summed over too many states in the partition function, and therefore we must correct Eq. (4.2.32a) in the spirit of Gibbs’ correction, namely divide by 2. Thus the correct expression is ζ2 = IkT ¯h 2 eϵD/kT 1 − e−¯hω/kT . (4.2.32b) Actually one must already divide by 2 the classical internal partition function — Eq. (4.1.49) for such molecules. Substitutingeverything into Eq. (4.2.26), and noting that M2 =2M1,we obtain K(T )=4hI √ π M 3 1 kT eϵD/kT 1 − e−¯hω/kT . (4.2.33) Finally, we check the behavior of the equilibrium constant in two lim- its. At temperatures much below Θv (kT ≪ ¯hω) the vibrational degrees of freedom freeze and the denominator in (4.2.33) is very close to unity. Hence K(T ) ≃ 4hI √ π M 3 1 kT e ϵD/kT ,T ≪ Θv . (4.2.34a) In this range K(T ) decreases with T and, consequently, the degree of dissociation increases. At high temperatures (kT ≫ ¯hω) the vibrational degrees of freedom unfreeze, as can be checked by the fact that (4.2.32b) yields (4.1.49), divided by 2 accordingto Gibbs. Since K is a directly measurable quantity, we expect that at these temperatures for which the classical approximation applies, Planck’s constant will disappear from the equations, and indeed we obtain K ≃ 8πI ω √ πkT M 3 1 e ϵD/kT ,T ≫ Θv . (4.2.34b) This equation is valid for temperatures that are not too high, since T must be much below Θe and must be low enough to justify the harmonic approximation. Chapter 3 Phonon Gas and the Debye Model 3.1 Sound waves in a crystal In this chapter and in the next one we deal with thermodynamic prop- erties of waves, and our ﬁnal goal will be to reach Planck’s distribution for black body radiation in the next chapter. But before discussingthe thermodynamics of electromagnetic radiation, we return to a system we have already met in the previous part, namely the crystal of N atoms. Describingthe crystal as a collection of 3N independent harmonic oscil- lators gives us a qualitative understanding of its speciﬁc heat, provided that we take into account the laws of quantum mechanics. However, we have seen that the quantitative correspondence is not satisfactory (see Fig. 3.2.4). Although the crucial step in the right direction was made by Einstein, there is still room for improvement. We ﬁrst analyze Einstein’s assumption that all the harmonic oscillators have identical frequencies. The energy of the crystal according to Einstein is E = 1 2 N∑ α=1(m˙r 2 α + Kr 2 α)= N∑ α ( p2 α 2m + K 2 r 2 α ) , (4.3.1) where rα describes the motion of atom number α relative to its equilibrium position. This expression does not take into account the fact that the potential energy of an atom in the crystal depends on the distance from its neighbors or, more precisely, on its motion relative to its neighbors. Hence in order to correct (4.3.1), we replace rα by the separation between atom number α and atom number β, rα − rβ.We thus obtain E = N∑ α=1 p2 α 2m + 1 2 ∑ α,β K 2 |rα − rβ| 2 . (4.3.2) Note that we could have obtained the above expression for the energy from the harmonic approximation to the energy of N atoms whose 376 3.1 Sound waves in a crystal 377 potential energy depends on the relative distance between each pair of atoms: E = N∑ α=1 p2 α 2m + 1 2 ∑ α,β U (rα − rβ) . (4.3.3) Since the potential energy of a pair of atoms usually depends only on the absolute value of their relative distance from each other, we can expand U as in (4.1.19) to second order in |rα − rβ| and reach (4.3.2) after dropping the minimum energy, which anyway is a shift by a constant. Compare with Eq. (4.1.1). Actually, you may think of the crystal as a sort of macro- scopic molecule. The factor 1 2 in front of U also appears for the same reason as in (4.1.1). The expression (4.3.2) for the energy, unlike (4.3.1), is not a sum of single-particle energies. Thus, the calculation of the partition function maylookratherdiﬃcult. But asystem of N coupled three-dimensional oscillators is equivalent to a system of 3N independent one-dimensional oscillators. The price to be paid is that the free oscillators that are ob- tained are not of equal frequency; instead each oscillator has a frequency of its own. An additional complication is the fact that the indepen- dent oscillators are not related to the motions of single atoms, but to the collective motions of all the atoms of the crystal about their equi- librium positions — vibrational modes. The vibrational modes are just vibrational modessound waves in the crystal. Each vibrational mode of frequency ω in the crystal behaves exactly as a single free harmonic oscillator of that frequency. Consult a textbook on classical mechanics for a fuller account. In order to see this consider the simple case in which the atoms in the crystal vibrate alonga single direction, say, x. The equation of motion of atom α is m¨xα = K(xα+1 − xα) − K(xα − xα−1)= K(xα+1 − 2xα + xα−1) . (4.3.4) Note that this model neglects all the forces exerted upon this atom by atoms that are not its nearest neighbors. α+1α–1 α Fig. 4.3.1 One-dimensional crystal. 378 Ch. 3 Phonon Gas and the Debye Model We stress once more that xα is the deviation of atom α from its equi- librium position and not the distance from a ﬁxed point that was chosen to be the origin, since if the atoms are at their equilibrium positions, they do not exert forces on each other. Here we shall only show that Eq. (4.3.4) has solutions which describe standingwaves of frequencies between zero and 2 √ K/m. The solutions are xα = a sin(qbα)sin ωt , (4.3.5a) where a is the amplitude, b the equilibrium distance between neighbor- ingatoms, q is the wave number (q =2π/λ)and ω is the frequency. When (4.3.5a) is substituted in (4.3.4), one obtains a relation between ω and q: ω(q)= 2 √ K M ∣ ∣ ∣ ∣ sin ( qb 2 ) ∣ ∣ ∣ ∣, 0 ≤ q ≤ π b . (4.3.5b) Exercise 3.1 Show that Eqs. (4.3.5) are indeed solutions to (4.3.4). Solution on page 422 Since the solutions are standingwaves with deﬁnite frequencies, we may treat each wave (or vibrational mode) as an independent oscillator characterized by the wave number q. If the number of atoms in the chain is N , the length of the chain is L = Nb. The requirement that the waves be standingimplies that the vibrations vanish at the two boundaries (α =0 and α = N ). This implies that the allowed values of q satisfy qbN = qL = nπ,where n is an integer between 1 and N .Thus, q changes in steps of π/L up to the maximal value of π/b and hence takes N discrete values. Similarly, the original three-dimensional crystal will be equivalent to 3N independent harmonic oscillators that are characterized by a wave vector, q.Each q determines the frequency, which in the simple case of a cubic crystal of identical atoms is still given by an equation similar to (4.3.5b). The total energy of the crystal (4.3.2) will thus be given by a sum of 3N terms, each describing the energy of a single harmonic oscillator. The followingexercise is intended to give an indication of the type of procedure that converts (4.3.2) into a sum over independent oscilla- tors. It is a coordinate transformation into the normal modes of the system. 3.2 Vibrational modes, phonons and enumeration of states 379 Exercise 3.2 The energy of the “toy crystal,” in Fig. 4.3.2, is given in terms of the distances of the three “atoms,” x1,x2,x3, from their equilibrium positions, as E = m 2 (˙x 2 1 +˙x 2 2 +˙x 2 3)+ K 2 [x 2 1 +(x2 − x1) 2 +(x3 − x2) 2 + x 2 3] . Show that the change of variables x1 = 1 2 (u1 + √ 2u2 − u3) , x2 = 1 √ 2 (u1 + u3) , x3 = 1 2 (u1 − √2u2 − u3) transforms the expression for the energy of the triatomic crystal into a sum of energies of three free oscillators. Find the frequencies of the oscillators. mm m KK K K Fig. 4.3.2 A “toy crystal” of three “atoms.” Solution on page 423 3.2 Vibrational modes, phonons and enumeration of states Since the vibrations of the crystal have to be treated quantum- mechanically, we write down the quantum expression for the energy of the 3N oscillators in a given microscopic state: E(n1,n2,... ,n3N )= 3N∑ α=1 ¯hωαnα , (4.3.6) where we have dropped the zero point energy of the oscillators. It should be mentioned that we are now usingthe letter α to denote not the atoms of the crystal but the diﬀerent standingwaves generated in it, namely the oscillators. It is common practice to think of the excited states of these oscillators as particles, and then instead of sayingthat oscillator number α has a degree of excitation nα, we say that there are nα phonons phonon of type α (or with frequency ωα). Figure 4.3.3, for example, describes 380 Ch. 3 Phonon Gas and the Debye Model n1 n2 n3 n4 n5 n6 1 234 56 α 1 2 3 4 n➤ ➤ Fig. 4.3.3 Distribution of phonon numbers. a system in which there is one phonon of type α = 1, three phonons of type α = 2, no phonon of type α = 3, four phonons of type α =4, and so on. From Eq. (4.3.6) it is clear that increasingthe excitation number nα by unity, or the addition of a phonon of type α, increases the energy of the system by ¯hωα. Hence it may be said that a phonon of type α has energy ¯hωα. A given microscopic state of the crystal is thus speciﬁed by listing all the excitation numbers of all the oscillators, or listingthe phonon numbers of all types that are in the crystal. In thermodynamic equilibrium it is thus possible to say that the vibrations of the crystal are, in fact, an ideal gas of phonons at temperature T . The partition function of such a system will be a product of single oscillator partition functions, but the factors in the product, zα, will not be equal, but will change with α. The ﬁrst stage in the calculation of the partition function is the calculation of zα for a given α, by summingover all the excitation numbers nα.Then the 3N diﬀerent partition functions have to be multiplied together in order to obtain the partition function of the whole system. Actually it is more convenient in this case to directly calculate the free energy,which is a sum rather than a product. We have met precisely such a calculation in Self-Assessment Exer- cise 2 of Part III, where we found that after summingover all excita- tion numbers the free energy is given by a sum over all 3N diﬀerent oscillators: F = kT 3N∑ α=1 ln(1 − e −β¯hωα) , (4.3.7) leaving out the ground state energy. But here there is an additional complication: While the energy is a sum of independent terms for each oscillator and for each of its components, the enumeration of the number of states must take into account the nature of the vibrational normal modes. Each three-dimensional oscillator is 3.2 Vibrational modes, phonons and enumeration of states 381 characterized by a wave vector q. If the crystal is a cube of side L,the allowed values of the components of q are qx = π L nx; qy = π L ny,qz = π L nz , (4.3.8) with nx, ny, nz nonnegative integers. For every vector q, there are three possible independent oscillatingmodes: One in which the oscillation am- plitude is longitudinal (in the direction of q) and two in which it is trans- verse (perpendicular to q). Hence, to sum over all states we must sum over all allowed wave vectors and for each wave vector over three polar- izations. Yet the total number of terms must equal the total number of degrees of freedom, 3N . The summation over α thus transforms into a summation over these three variables: F =3kT ∑ nx,ny,nz ln(1 − e −β¯hω(nx,ny,nz)) , (4.3.9) where the factor 3 comes from the summation over the three possible polarizations, assumingthat the frequencies of the standingwaves, ω,do not depend on polarization. Successive terms in the sum correspond to q’s which diﬀer by π/L.For L macroscopically large and temperatures that are not extremely low, the diﬀerence between successive terms in the sum will be inﬁnitely small and (as in Part III, Sec. 4.4) the sum can be approximated by an integral over the region D of the positive values of the wave vectors’ components: F = 3kT V π3 ∫ D ln(1 − e −β¯hω(q))d 3q. (4.3.10a) We have written V for L3. The region of integration in wave vector space is depicted in Fig. 4.3.4. The points of the three-dimensional lattice repre- sent the allowed values of q. If the frequency of vibration ω is independent of the direction of the wave vector q, we can replace the integration over positive qx, qy, qz (1/8 of the sphere) in Eq. (4.3.10a) by an integration over the entire sphere of radius qD, provided we correct for this by multi- plyingby 1/8. Hence, F = 3kT V (2π)3 ∫ |q|≤qD ln(1 − e −β¯hω(q))d 3q. (4.3.10b) This substitution represents the fact that a standingwave along the x di- rection contains, in fact, two waves that are movingin opposite directions with wave vectors +qx and −qx (see the remark at the end of Answer 3.1). The same applies to standing waves movingalongthe y and z directions. 382 Ch. 3 Phonon Gas and the Debye Model π/L π/L ➤ qy qx qz dq qx qy➤ ➤➤ ➤➤➤ π/L➤➤ ➤ ➤ (a) (b) Fig. 4.3.4 The wave vectors of the vibrational modes are represented by points in wave vector space. (a) Three-dimensional representation; (b) two-dimensional section. Each of the points represents three free waves moving with all possible polarizations. Altogether a standing wave with (a positive) wave vector q comprises eight traveling waves with wave vectors (±qx, ±qy, ±qz). Note that the replacement of the sum over all oscillators ∑ α,by an integral over the components of q, which appears in (4.3.10b), implies that inside a volume d3q in wave vector space there are 3Vd3q/(2π)3 crystal vibrational modes. We could have arrived at this result from a slightly diﬀerent direction. So far we have calculated the number of phonon states by treatingthe phonons as waves. But in the quantum context it is possible to consider them as particles with de Broglie momentum given by ¯hq (and energy ¯hω). We can now think of these phonons as particles conﬁned to a box of volume V (the volume of the crystal). We have found (in Sec. 4.4 of Part III) that each state of a particle occupies a volume of h3 in phase space. In addition there are three independent vibrational directions. Therefore, inside a volume dV d3p of phase space there are 3dV d3p/(h)3 states and in terms of wave vectors 3dV d3q/(2π)3 states. Integration over the whole volume of the crystal will give us 3Vd3q/(2π)3 states to a volume of d3q in wave vector space. It is highly recommended at this stage to return to Sec. 4.4 of Part III, and to compare the considerations made in the two instances. 3.3 The Debye model In order to calculate the free energy of the crystal (4.3.10), we have to know the form of the function ω(q). Actually we have calculated it explicitly in the one-dimensional situation in Eq. (4.3.5b), but that case is too speciﬁc. The general case is three-dimensional, and the crystal structure is not always cubic and the crystal does not always consist of one type of atoms. 3.3 The Debye model 383 All these factors indicate that in the typical general case ω(q)may be a fairly complicated function. Nevertheless, Debye found that it is possible to describe the speciﬁc heat of many solids quite well, if we assume a usual free wave relationship between ω and q: ω = vq,where v is the sound velocity in the crystal, provided we limit the region of integration to contain exactly 3N states. The integrand in (4.3.10b) depends only on the absolute value of the wave vector, and the region of integration is a sphere of radius qD.Thus it is possible to perform the integration as a summation over spherical shells of thickness dq (see Fig. 4.3.4a), to obtain from (4.3.10b) F = 3kT V 2π2 ∫ qD 0 ln(1 − e −β¯hvq)q2dq , (4.3.11) following the angular integration, as a result of which d3q =4πq2dq.To ﬁnd the integration limit qD, we use the fact that the number of states in a region of phase space conﬁned by qD should be 3N .The number of states in an inﬁnitesimal volume d3q is,as we have seen,3Vd3q/(2π)3, and altogether we want 3N states inside a sphere of radius qD. This leads to qD = ( 6π2N V )1/3 (4.3.12a) or for the correspondingfrequency, called the Debye frequency: Debye frequency ωD = v ( 6π2N V )1/3 . (4.3.12b) Exercise 3.3 Prove Eq. (4.3.12a). Solution on page 424 The practical aim of this whole discussion is to obtain an improved calculation of the average energy and of the speciﬁc heat of a crystal, especially in the low temperature range, where the Einstein model deviates very signiﬁcantly from the experimental results (see Fig. 3.2.4). An expression for the average energy is readily obtained from (4.3.11): E = − ∂ ln Z ∂β = 3V 2π2v3 ∫ ωD 0 ¯hω eβ¯hω − 1 ω2dω . (4.3.13) Exercise 3.4 Obtain Eq. (4.3.13). Solution on page 424 384 Ch. 3 Phonon Gas and the Debye Model Equation (4.3.13) may be interpreted in the followingmanner: each phonon of frequency ω has energy ¯hω. The average number of phonons of frequency ω is the average degree of excitation found in Eq. (3.2.9): ⟨n⟩ =1/(eβ¯hω − 1). It is possible to identify the additional multiplicative factor as the number of microscopic states per unit frequency of a single phonon (or the density of states): g(ω)= 3V 2π2v3 ω2 , (4.3.14) and then the energy density per unit frequency is the product of all these factors. We may also deﬁne an energy density per unit frequency per unit volume,which is ρ(ω)= 3 2π2v3 ¯hω3 eβ¯hω − 1 ,ω ≤ ωD . (4.3.15) The speciﬁc heat (at constant volume) of the crystal is obtained from Eq. (4.3.13) as C = 3kV 2π2v3 ∫ ωD 0 (¯hω/kT )2e¯hω/kT (e¯hω/kT − 1)2 ω2dω . (4.3.16) This integral cannot be expressed in terms of elementary functions, and generic values must be obtained numerically. Nevertheless, at low tem- peratures, for which kT ≪ ¯hωD, it is possible to extend the region of integration up to inﬁnity without changing the result of the integration, since near ωD the integrand is vanishingly small. The physical reason for this is that at low temperatures only low frequency phonons are excited, and hence only they contribute signiﬁcantly to the speciﬁc heat. We thus ﬁnd that at low temperatures C = Nk 12π4 5 ( kT ¯hωD )3 . (4.3.17) Note that the exponential temperature dependence of the Einstein model has been replaced by a power dependence. Deﬁningthe Debye tempera- ture, ΘD =¯hωD/k,we may write C = Nk 12π4 5 ( T ΘD )3 ,T ≪ ΘD . (4.3.18) Exercise 3.5 Prove Eq. (4.3.17). Solution on page 425 Chapter 4 Thermodynamics of Electromagnetic Radiation 4.1 General considerations of radiation at thermal equilibrium Inside an empty cavity of matter (Fig. 4.4.1) there usually exists elec- tromagnetic radiation since in the material of the walls, at tempera- ture T , there are movingcharges and these radiate. Moreover, radia- tion in the cavity is absorbed in the walls and re-emitted, until the sys- tem of matter + radiation reaches equilibrium, characteristic of the given temperature. cavity matter at temperature T Fig. 4.4.1 Radiation inside a cavity in matter — the average energy does not depend on either the shape of the cavity or the type of matter surrounding it, but depends only on the temperature. The radiation in the cavity is characterized by diﬀerent frequencies, or diﬀerent wavelengths. The amount of radiation at each frequency may be speciﬁed by the energy density around this frequency. Namely, there exists a function ρ(ω) such that ρ(ω)dω is the amount of energy of radiation per unit volume with frequency between ω and dω at temperature T . In what follows we shall refer to ρ also as the radiation density, even though it is actually the energy density of the radiation. 385 386 Ch. 4 Thermodynamics of Electromagnetic Radiation The goal of statistical mechanics is to calculate ρ(ω), which is the analogof the Maxwell–Boltzmann distribution for material particles. This calculation would have been impossible were it not for the fact that: At equilibrium ρ(ω) is independent of the structure of the cavity or of the surrounding material. In order to clarify this far-reachingproperty, we note that it is a special case of a more general independence. Apriori we should have expected the energy density to be a function of the position inside the cavity, of the wave vector q, or of the polarization. It is possible to show that if the radiation in the cavity is at equilibrium at a uniform temperature, then the second law of thermodynamics implies that: (a) The distribution of the radiation in the cavity is uniform — indepen- dent of position. (b) The distribution of the radiation in the cavity is independent of the direction of the wave vector of the radiation or of its polarization — ρ depends only on |q|. The frequency of electromagnetic radiation is proportional to |q|: ω = c|q| = cq , (4.4.1) where c is the speed of light. From (b) above it is inferred that ρ depends only on ω. As a demonstration we shall bringhere the argument that leads to the conclusion that ρ(ω) is independent of the shape of the cavity, its size, or the material it is made of. We shall discuss the independence of the radiation density of the position and the direction of the radiation in Sec. 4.4. Suppose that there are two cavities A and B at the same temperature T , which diﬀer from each other in shape and are made of diﬀerent mate- rials. We shall connect the two cavities by a small hole, such that a small amount of energy may pass from one cavity to the other (see Fig. 4.4.2). If as a result of the passage of radiation through the hole more radia- tion has passed from A to B than in the opposite direction, for instance, then the radiation will not be at equilibrium with the walls of the cavity on both sides. After a while the cavities will reach a new equilibrium, and the temperatures of the walls will change. The result will be that heat will pass between two systems at the same temperature, without performing work — in contradiction to the second law of thermodynamics. The same consideration applies to each and every frequency separately, since it is possible to insert a ﬁlter inside the hole, so that only radiation of a certain frequency ω is able to pass (the other frequencies will be 4.2 Radiation density 387 T A T B Fig. 4.4.2 Two cavities, diﬀering from each other in shape and in the surrounding material, both at the same temperature. reﬂected). Namely, the second law of thermodynamics ensures that if the two cavities are at equal temperatures, then the amount of radiation energy transferred from A to B must be equal to that transferred from B to A, at each and every frequency. But the amount of radiation energy with frequency between ω and ω + dω, which is transferred from side to side, can be calculated exactly as for gas particles escaping from a container through a tiny aperture (see Secs. 3.2, 3.7 and Self-Assessment Exercise 4, Part I). This amount is given by I(ω)dω = c 4 ρ(ω)dω . (4.4.2) I(ω) is called the emissivity and represents the amount of radiation energy emissivity with frequency between ω and ω + dω transferred per unit time through a unit element of the aperture. This implies that the energy density ρ(ω) of one cavity is equal to that of the other cavity at every frequency. Because we have chosen two arbitrary cavities, the form of the function ρ(ω) is independent of the shape of the cavity, its size, or the material it is made of. Exercise 4.1 Prove Eq. (4.4.2). Solution on page 425 4.2 Radiation density If indeed ρ(ω) is independent of the shape of the container and of the material it is made of, we may choose a cubic container of side L,and whose faces are made of an arbitrary material. Whatever the material, the charges within it perform thermal vibrations and emit electromagnetic radiation. The latter is emitted into the cavity between the walls and repeatedly hits them, causingthe charges within them to vibrate, and so on and so forth. As a result of these exchanges an equilibrium is 388 Ch. 4 Thermodynamics of Electromagnetic Radiation established between the radiation and the walls, which, as we have seen, is independent of the structure of the walls or their composition. The electromagnetic radiation in the cavity can be described as a collection of standingwaves, with various frequencies, which are characterized by their wave vector q. The frequency is determined by the wave vector according to the usual relationship, Eq. (4.4.1). Each of these standingwaves with a given wave vector is a vibration of the electromagnetic ﬁeld in the cavity, which is sinusoidal in time. Hence it is possible to think of it as a vibrational mode of the electromagnetic ﬁeld, namely as a harmonic oscillator with frequency ω = cq, precisely in the same manner as standingsound waves in a crystal are its vibrational modes. The next step is to take into account the quantum theory. The quantization of the vibrational modes of the crystal led us to the concept of phonons, which are the excited states of these oscillators. We may also treat the vibrational modes of the electromagnetic ﬁeld as quantum oscillators. The result is similar: Each oscillator α can be excited to the state nα. In particle language this state is described as a state in which there are nα photons of type α.photon Each of these oscillators has energy states which are given by Eq. (3.2.1), and hence each photon carries energy of magnitude ¯hωα. However, there exists a basic diﬀerence between the phonons and the photons: The frequency of the phonons has an upper bound (ωD in the Debye model) due to the fact that there exists a minimal wavelength de- termined by the distance between two neighboring atoms in the lattice or, alternatively, by the fact that the number of vibrational modes of the crystal is ﬁnite. In contrast, there is no such limit for the electromagnetic waves; hence the range of frequencies is unbounded and, correspondingly, the number of vibrational modes is inﬁnite. We therefore treat the electromagnetic radiation in the container as a gas of photons. At equilibrium, at temperature T , the probability of a given microscopic state speciﬁed by the collection of nα for all α will be P (n1,n2,...)= 1 Z exp ( −β ∑ α nα¯hωα ) , (4.4.3) where Z is the partition function: Z = ∞∑ n1=0 ∞∑ n2=0 ... exp ( −β ∑ α nα¯hωα ) = ∏ α ( ∑ nα e −βnα¯hωα) = ∏ α ( 1 1 − e−β¯hωα ) . (4.4.4) 4.2 Radiation density 389 This argument is identical to the one applied to phonons in the previous chapter. Thus, the free energy is F = −kT ln Z = kT ∑ α ln(1 − e −β¯hωα) . (4.4.5) But what of the summation over α? The summation over α is a summation over all the vibrational modes of the electromagnetic ﬁeld or over all possible photon states. The photon, which is the electromagnetic ray, is characterized by the wave vector q. A second quantity characterizingthe radiation is the polarization. The electric ﬁeld, for example, oscillates perpendicular to q, but there are two independent directions perpendicular to q. Thus two diﬀerent photons correspond to each q. Note the contrast with phonons which had three possible polarizations. Exercise 4.2 Show that a sinusoidal electromagnetic wave is a transverse wave. Use Maxwell’s equations in vacuum. Solution on page 426 The number of vibrational modes with wave vectors in a region d3q around q can be found exactly as for the phonons in the previous chapter. One way is to count the number of diﬀerent standingwaves in a certain region in wave vector space — or, alternatively, to calculate the volume occupied by a single state in wave vector space. Reexamining Fig. 4.3.4, we note that the volume of an elementary cell is (π/L)3 = π3/V . Hence the number of standingwaves in the region d3q is Vd3q/π3.But the electromagnetic waves can have two polarization states, and hence the number of standingwaves in d3q is 2Vd3q/π3. As we have already seen for phonons, it is more convenient to count moving wave states, for which the components of q may also be negative, and hence the volume d3q contains eight times too many moving waves. Thus, we have to divide by 8 to obtain the ﬁnal result, that the number of movingwave states in the region d3q in wave vector space is 2Vd3q/(2π)3.This result can also be obtained by a direct inspection of the phase space of the photons, precisely as we have done for the phonons. The free energy Eq. (4.4.5) is written as an integral over q: F = 2kT V (2π)3 ∫ ln(1 − e −β¯hcq)d 3q. (4.4.6) Since the “terms of the sum” (the integrand) depend only on q = |q| and not on the direction or the polarization, we can perform the integration over spherical layers, as illustrated in Fig. 4.3.4(a). Inside the layer the 390 Ch. 4 Thermodynamics of Electromagnetic Radiation terms have identical values: There is no dependence on the angle, and dq is very small. Hence ∫ ln(1 − e −β¯hcq)d 3q =4π ∫ ∞ 0 ln(1 − e −β¯hcq)q2dq . (4.4.7) The right hand side of (4.4.7) can be written, using (4.4.1), as an integral over the frequencies: 4π c3 ∫ ∞ 0 ω2 ln(1 − e −β¯hω)dω , (4.4.8) and from here we can obtain the free energy as F = kT V π2c3 ∫ ∞ 0 ω2 ln(1 − e −β¯hω)dω . (4.4.9) For the average energy we ﬁnd that E = − ∂ ln Z ∂β = V ¯h π2c3 ∫ ∞ 0 ω3dω eβ¯hω − 1 . (4.4.10) This expression for the average energy may be interpreted precisely in the manner in which we interpreted the correspondingexpression in the Debye model, Eq. (4.3.13). The average degree of excitation of the quantum oscillator appears also here and the multiplyingfactor can be identiﬁed as the number of microscopic states per unit frequency (density of states) of a single photon: g(ω)= V π2c3 ω2 . (4.4.11) The energy density per unit volume and unit frequency stored in the electromagnetic radiation in the box will be ρ(ω)= 1 π2c3 · ¯hω3 eβ¯hω − 1 . (4.4.12) To be compared to Eq. (4.3.15). Dividing ρ(ω) by the energy of a photon of frequency ω, we obtain the photon number density per unit volume and unit frequency: n(ω)= 1 π2c3 ω2 eβ¯hω − 1 . (4.4.13) 4.3 Black body radiation In order to verify that indeed we have an expression that describes well the radiation density in the container, we consider the radiation emitted through a small aperture in it. The hole has to be small, so that the 4.3 Black body radiation 391 amount of radiation escaping from it will be negligible, otherwise it will be impossible to maintain the state of thermodynamic equilibrium. Such an aperture at the side of the container is an example of a black black body body. The reason for this name is that any ray incident from the outside on the hole is absorbed by the container. The probability for it to return and exit the hole is vanishingly small. Nevertheless, a black body is in no way black. In addition to beinga perfect absorber, it emits radiation. As we have seen in Sec. 4.1, if the container is full of photons movingto and fro, then clearly some of them will be emitted through the hole, according to Eq. (4.4.2) and (4.4.12). A black body is therefore characterized by the power emitted by it per unit area per unit frequency (emissivity), given by I(ω)= 1 4π2c2 ¯hω3 eβ¯hω − 1 . (4.4.14) This equation, as well as Eq. (4.4.12), is called Planck’s formula, and its discovery by Planck in 1900 marks the birth of quantum theory. Fig- ure 4.4.3 illustrates the power distribution emitted from a black body. Note that the horizontal axis is an axis of the frequency (ν) and not angular frequency (ω). Note that the units of time have disappeared from I. The fact that Planck’s constant appears in Eq. (4.4.14) immediately explains the failure of all the attempts to explain the phenomenon of black body radiation on the basis of classical physics. Nevertheless, (4.4.12) and (4.4.14) have a classical limit which is obtained when β¯hω ≪ 1. ν (1014sec–1)➤ 0 1 2 3 4 5 12 3 4 I(103J/m2) T=2000K T=1000K ➤ Fig. 4.4.3 The emissivity, or the emission rate of radiation per unit area of the black body, according to Planck’s law. 392 Ch. 4 Thermodynamics of Electromagnetic Radiation Exercise 4.3 (a) Prove that in the classical limit the energy distribution has the form ρ(ω)= kT ω2 π2c3 . (b) To what physical conditions does this limit correspond? Solution on page 427 The expression obtained in the last exercise is called the Rayleigh– Jeans law and is as far as classical physics could go. The original classical calculation was not performed as a limit of the quantum result, but in the followingmanner: Electromagnetic radiation is equivalent to an ensemble of harmonic oscillators, and accordingto the equipartition law each one contributes an average energy of kT . Hence the energy per unit frequency in the cavity is obtained by multiplyingthe density of states (4.4.11) by kT . In order to obtain the energy per unit volume we have to divide by V . The Rayleigh–Jeans formula is yet another indication for the limita- tions of the equipartition law. From Eq. (4.4.14) it is possible to obtain two important characteristics of black body radiation. (a) Wien’s law: The emissivity of a black body has a maximum at a frequency νmax that increases with temperature accordingto νmax T =5.88 × 10 10 s−1K−1 . (4.4.15) See for example the location of the maxima in Fig. 4.4.3. (b) The Stefan–Boltzmann law: The total power emitted per unit area of a black body (namely a sum over all frequencies) is proportional to the fourth power of the temperature: I = σT 4,σ = 2π5k4 15h3c2 =5.67 × 10 −8 Js−1m −2K−4 . (4.4.16) Both of these laws were discovered experimentally many years before Planck found the theoretical explanation for the properties of black body radiation. Exercise 4.4 (a) UsingPlanck’s formula, Eq. (4.4.14), prove (4.4.15). (b) Prove (4.4.16). Solution on page 427 4.3 Black body radiation 393 Another interestingquantity is the energy density per unit volume u(T ) in the black body radiation, which we can readily obtain from energy densitythe expression for the total energy of the radiation in the container, i.e. Eq. (4.4.10). A procedure analogous to the one used for obtaining the Stefan–Boltzmann law (Exercise 4.4) leads to a direct proportionality to the fourth power of the temperature: u(T )= 4σ c T 4 . (4.4.17) The proportionality constant 4σ/c is 7.57 × 10−16 Jm−3K−4. To end this section let us check the thermodynamic properties of the radiation gas conﬁned to a container. Exercise 4.5 (a) Calculate the entropy and the speciﬁc heat of the radiation. (b) Calculate the radiation’s chemical potential. Explain your result in terms of the number of photons. Solution on page 429 Exercise 4.6 (a) Calculate the pressure of the radiation and its relation to the energy density. Compare with the relationship obtained in the kinetic theory in Part I, Eq. (1.1.7). (b) The diﬃculty, or the ease, of compressinga system is measured by the compressibility, which is deﬁned as compressi- bility K = −V ( ∂P ∂V ) T . Calculate K for the radiation gas. Compare your result to the one obtained for a gas of particles. Solution on page 430 Exercise 4.7 (a) At what temperature will the pressure of the radiation gas be equal to one atmosphere (1 atm = 1.013 × 105 N/m2)? (b) At what temperature will the pressure of the radiation be equal to 10−10 atm? (c) The temperature at the sun’s center is 107 K. What is the pressure of the radiation? Compare it to the pressure of the gas at the center of the sun, which is 1011 atm. 394 Ch. 4 Thermodynamics of Electromagnetic Radiation (d) Calculate the pressure of the sun’s radiation on the earth’s surface, given that the power of the radiation reaching earth from the sun is 1400 W/m2. Solution on page 431 As a ﬁnal note we show in Fig. 4.4.4 the astounding correspondence between Planck’s formula and the experimental results for the energy den- sity, performed by Coblentz in 1916. Observe that the horizontal axis is the wavelength and that ρ is the energy per unit volume per unit wave- length, and hence its dimensions are [E]/[L]4. Regarding the relationship between ρ(λ)and ρ(ν), see Self-Assessment Exercise 6. 0 λ(104Å)ρ(λ)(J/m4) T=1595K 250 500 750 1000 1250 1500 1750 24 6 Fig. 4.4.4 Black body radiation — experimental results vs. Planck’s formula. 4.4 Absorption and emission of radiation Kirchhoﬀ’s law The relatively simple considerations that we applied to a volume of space with radiation in equilibrium, at a given temperature, allow us to reach some surprisingconclusions concerning the behavior of bodies that absorb and emit radiation at nonequilibrium conditions. First, usingphysical considerations alone, without any calculations, it is possible to show that inside a cavity containingradiation at equilibrium at temperature T , the radiation density is independent of position. See also Sec. 4.1, where we have shown that the radiation density is independent of the shape of the cavity or of the surrounding material. Suppose that at frequency ω, ρ(ω) is diﬀerent at two locations inside the cavity. In these locations we shall place two identical bodies whose 4.4 Absorption and emission of radiation — Kirchhoﬀ’s law 395 temperature is T . They are coated by a material which is transparent only to radiation with frequency ω (a ﬁlter). The body around which the radiation density is higher will absorb more energy than the one around which the radiation density is lower. As a consequence heat will be trans- ferred between the two bodies whose temperatures are equal, in violation of the second law of thermodynamics. In a similar manner it is possible to show that the radiation density is independent of the direction of q, or of the polarization of the radiation. The proofs are left to Self-Assessment Exercise 5. Any body, not necessarily a black body, can be characterized by its emissive power function L(q,T ), expressingthe intensity of radiation emissive poweremitted by the body per unit area per unit time directed along q with frequency ω = c|q|: ∆Eem = L(q,T )cos θ∆ω∆Ω , (4.4.18) where θ is the angle between q and the normal to the surface and dΩisthe solid angle into which the radiation is emitted. The factor cos θ projects the unit area of the body in the direction perpendicular to q (Fig. 4.4.5). Note that we assume that L does not vary from point to point over the surface. L depends only on the properties of the radiatingbody and on its temperature. This does not mean that the radiation must have the same temperature as the body. In fact this is a case in which the radiation is not at equilibrium with the body but is emitted by it in a continuous manner as, for instance, the radiation emitted by the ﬁlament of a light bulb. Similarly, it is possible to characterize a body by its absorbingpower A(q,T ), which is also dependent upon the properties of the body and on its temperature. A(q,T ) gives the fraction of the intensity of the radi- dAcosθ dΩ dA θ q ➤ Fig. 4.4.5 Geometry of radiation emission: θ is the angle between the normal to the area element and q. φ is measured in the plane of dA. dΩ= sin θdθdφ is the solid angle corresponding to the inﬁnitesimal elements dθ and dφ.An area dA is seen to be of magnitude dA cos θ if viewed at an angle θ. 396 Ch. 4 Thermodynamics of Electromagnetic Radiation ation, with wave vector q and frequency ω(q), incident on the body at temperature T , that is absorbed by it. Note that A(q,T ) is a dimension- less quantity. L has the dimensions of energy per unit area. Kirchhoﬀ’s law, which we now prove, states that the ratio of L and A depends only on ω and T :Kirchhoﬀ ’s law L(q,T ) A(q,T ) = c 4π ρ(ω, T ) , (4.4.19) where ρ(ω, T ) is the radiation density in equilibrium inside a cavity at temperature T , namely (4.4.12). This means that L/A is actually inde- pendent of the properties of the body! In order to emphasize the temperature dependence of the radiation density, we write here ρ(ω, T ). We conclude the treatment of the properties of radiation by presenting the arguments that prove Kirchhoﬀ’s law: First, we calculate the intensity of radiation with wave vector q which is incident per unit time on the unit surface area of a body that is placed inside a cavity, in which there is radiation in equilibrium at temperature T . To do this, we repeat an argument identical to the one in Sec. 3.7 of Part I; however, here the density of the particles is spatially uniform and they all have velocity c (see also Solution 4.1). The amount of energy arriving from a region dΩ around the direction q, and which is incident upon the unit area ∆A in unit time ∆t, will be the same expression obtained in Solution 4.1 but without the angular integration: ∆Ein = cρ(ω, T )∆ω ∆Ω 4π cos θ. (4.4.20) Only a fraction A(q,T ) of this radiation is absorbed. The intensity ab- sorbed is A(q,T ) · ∆Ein. The intensity absorbed per unit area per unit time, from radiation directed along q with frequency ω = c|q|,is ∆Eabs = A(q,T )cρ(ω, T ) cos θ 4π ∆ω∆Ω . (4.4.21) A body that is in equilibrium at temperature T will remain at equi- librium (at the same temperature) if placed in a cavity in which there is radiation in equilibrium at the same temperature T . Hence the energy ﬂux absorbed by the body while it is in the cavity must equal the ﬂux emitted by the body. Moreover, the balance must be maintained in full detail. Namely, the amount of energy absorbed at every frequency and from every direction per unit time, must be identical 4.4 Absorption and emission of radiation — Kirchhoﬀ’s law 397 to the amount emitted per unit time in the same direction and with the same frequency. Exercise 4.8 Show that the balance must be detailed. Solution on page 432 The energy absorbed for a certain q is simply given by (4.4.21) and the energy emitted with the same q is given by (4.4.18). The fact that the balance is detailed implies that ∆Eabs =∆Eem, and hence L(q,T )= c 4π A(q,T )ρ(ω, T ) , which is Kirchhoﬀ’s law. We re-emphasize that even though we have obtained it makinguse of an equilibrium state, the law is also valid out of equilibrium. Exercise 4.9 (a) Show that the emissive power of a black body is LB(q,T )= c 4π ρ(ω, T ) . (4.4.22) (b) Explain the relationship between the emissive power L and the emis- sivity I. Solution on page 432 In addition to the fact that the ratio of L and A of a certain body is independent of the body’s properties, we can further deduce from (4.4.19) the surprisingfact that a material that is a better absorber of radiation is also a better emitter. Thus, a black body is a better emitter than any other body! The reason why a black body usually appears to be black is that at the temperatures at which we encounter black bodies the wavelength of most of the emitted radiation is too large for the radiation to be seen. Exercise 4.10 Calculate the frequencies for which the emissive power of a black body is maximal at 100 K, 1000 K, 10,000 K, 100,000 K and the values of the maximum emissive power for these temperatures. Solution on page 433 398 Ch. 4 Thermodynamics of Electromagnetic Radiation 4.5 Role of black body radiation in modern physics The phenomenon of thermal radiation has had great importance in the evolution of modern physics. In addition it has a wide range of practical applications. Its most important contribution has been that it pointed out the inadequacy of classical physics and brought Max Planck to propose in 1900 the idea of quantization of electromagnetic radiation — more precisely, the quantization of the energy of a harmonic oscillator in units of ¯hω. As we have seen in the previous sections, this assumption is the basis for obtainingthe spectral distribution of black body radiation as given in Eq. (4.4.14), and hence the year 1900 is considered to be the year of the birth of quantum theory. However, in spite of the success of Planck’s explanation, initially its physical signiﬁcance and its generality were not totally clear. Only after Einstein had shown in 1905 that the same as- sumption is suﬃcient for explainingthe photoelectric eﬀect and in 1907 that it also leads to an explanation of the temperature dependence of the heat capacities of solids (see Part III), were the importance and generality of Planck’s idea of quantization recognized. Planck’s formula has many practical applications related to the mea- surement of the temperatures of hot bodies which are hard to approach (extremely hot bodies such as steel furnaces, distant bodies such as ce- lestial objects, etc.). By measuringthe body’s spectrum of radiation and comparingit to Planck’s law it is possible to determine its temperature. In this way it is possible to measure, for instance, the heat production of an atomic reactor and to reach conclusions on its output, from measurements made from a high-ﬂying surveillance aircraft. Astronomers often compare the spectrum of radiation emitted by dis- tant celestial objects to Planck’s formula in order to measure their tem- peratures and to verify if the radiation emitted by them is black body ra- diation. Since usually the spectrum of the radiation does not ﬁt Planck’s law, they conclude that this radiation is not thermal radiation (or that it is not all thermal radiation). The study of the spectrum is bound, in this case, to shed light on the processes that are taking place in the distant object. In other words, the thermal radiation in this case amounts to a “background noise”and the detailed knowledge of its behavior allows sub- traction of the background from the signal and to remain with its relevant part. These astronomical measurements are currently possible in a wide spectral range, from radio-frequency waves up to X-rays and γ-rays. Another interestingphenomenon that was discovered as a result of astronomical measurements of electromagnetic radiation is the “cosmic background radiation,” also known as the “three-degree radiation.” In 1965 Penzias and Wilson discovered electromagnetic radiation with 4.5 Role of black body radiation in modern physics 399 wavelengths ranging from several millimeters to several centimeters and whose spectrum corresponded to black body radiation at a temperature of 2.7 K. This radiation is incident from all directions of space at uniform intensity, from which it was concluded that it probably ﬁlls the universe uniformly, just as if the universe were residinginside a huge “oven” whose walls were at a temperature of 2.7 K. The currently accepted explanation for the origin of this radiation is that it was created at the time of the bigbang, which is assumed to have occurred about 1010 years ago. The whole universe was cre- ated then in a huge explosion of a compressed and very hot ball of par- ticles and radiation. Since then the universe has been in a perpetual state of expansion, and its energy density has been decreasing. The tem- perature of the radiation ﬁllingthe universe has decreased, therefore, to the value observed today, about 3 K. The whole phenomenon ﬁts other available evidence concerning the bigbangand the expansion of the uni- verse, and is considered an important veriﬁcation of this cosmological theory. In April 1992 it was reported that the satellite COBE (Cosmic Background Explorer), which was launched to carry out precise measure- ments of the cosmic background radiation, had detected a slight nonuni- formity in it, manifested as variations of order 15 µK around the average temperature of 2.7 K. These ﬂuctuations imply that not longafter the big bangthere began to appear deviations from the state of uniform density in the universe. These deviations are probably responsible for the large scale structure of the universe today. Another area in which black body radiation plays a central role is the physics of black holes. A black hole is a region in space from which no black hole material or radiation can escape; in contrast, there is no restriction on enteringit and thus it serves as a perfect trap. The existence of such regions is predicted by Einstein’s general theory of relativity around stars which were so heavy (above about ﬁve solar masses) that they eventually collapsed under their own gravitational attraction, to scales that were so small that the escape velocity from them became larger than the velocity of light. This prevents any possibility of escape from the entire region for which the escape velocity is larger than c. A nonrelativistic calculation shows that if M is the mass of the star, then the black hole extends over the region for which c< √ 2GM/r or r< 2GM/c2. An exact relativistic calculation yields the same result. Namely, the radius of a black hole is determined by its mass as 2GM/c2. Surprisingly, Hawking discovered in 1974 that if the laws of quantum theory are also taken into account then the black hole is no blacker than a black body: It emits particles and electromagnetic radiation with an energy or frequency distribution of a black body at a temperature which is also determined by the mass: 400 Ch. 4 Thermodynamics of Electromagnetic Radiation T = hc3/16π2kGM . For a black hole of ﬁve solar masses this temperature is about 10−8 K and hence the phenomenon is rather marginal. But there may also exist much smaller black holes in the universe (that were created not as a result of the collapse of stars but in other ways). Their temperatures could be much higher. Such a small black hole is unstable as a result of the Hawking eﬀect: The more energy it loses by radiating, the more its mass decreases, then its temperature increases and accordingto the Stefan–Boltzmann law (4.4.16) its radiated power increases (in spite of the decrease of the radius and the surface area) and so on, till it is totally dissipated in one last energy burst. Appendix Calculation of Some Integrals In the course of this part we needed integrals of the form Iℓ = ∫ ∞ 0 xℓdx ex − 1 , (4.A.1) where ℓ is an integer. In order to calculate them we start with integrals that represent the factorial function: ∫ ∞ 0 xe −xdx =1 , ∫ ∞ 0 x 2e −xdx = − ∫ ∞ 0 x 2 d dx (e −x)dx =2 ∫ ∞ 0 xe −xdx =2 , ∫ ∞ 0 x 3e −xdx = − ∫ ∞ 0 x 3 d dx (e −x)dx =3 ∫ ∞ 0 x 2e −xdx =6 , ∫ ∞ 0 x ne −xdx = ℓ ∫ ∞ 0 x ℓ−1e −x dx , and hence ∫ ∞ 0 x ℓe −xdx = ℓ! . (4.A.2) Returning to the original integral (4.A.1), we note that the expression 1/(ex − 1) is a geometric sum: 1 ex − 1 = e−x 1 − e−x = e −x + e −2x + e −3x + ... = ∞∑ m=1 e −mx . Substitutingin the integral (4.A.1), we obtain ∫ ∞ 0 xℓ ex − 1 dx = ∞∑ m=1 ∫ ∞ 0 x ℓe −mx dx = ∫ ∞ 0 yℓe −ydy ∞∑ m=1 1 mℓ+1 = ℓ! ∞∑ m=1 1 mℓ+1 , (4.A.3) 401 402 Appendix: Calculation of Some Integrals where we have performed the change of variables y = mx and used (4.A.2). The sum is a known function in mathematical literature and is called the Reimann zeta function: ζ(ℓ)= ∞∑ m=1 1 mℓ . (4.A.4) Actually this function is deﬁned by (4.A.4) also for nonintegral values of ℓ and even complex ones. The zeta function has been studied extensively and its values appear in numerical tables. The followingtable contains useful values. ℓ 2345 6 7 8 ζ(ℓ) π2 6 ≃ 1.645 1.202 π4 90 ≃ 1.082 1.037 π6 945 ≃ 1.017 1.008 π8 9450 ≃ 1.004 We have therefore obtained ∫ ∞ 0 xℓdx ex − 1 = ℓ!ζ(ℓ +1) . (4.A.5) Self-assessment exercises Exercise 1 Solution on page 434 The hydrogen atom has a spectral line whose wavelength is 21 cm (this line is of extreme importance in astrophysics). The ground state is nondegen- erate, and the ﬁrst excited level, from which the line is emitted, is triply degenerate. The next level is found 10 eV above the ground state. (a) What is the excitation energy of the ﬁrst excited level? (b) What is ζ at a temperature of 0.1 K? In atomic chlorine the ﬁrst spectral line corresponds to a photon with an energy of 0.11 eV. The ground level is four times degenerate, and the ﬁrst excited level is doubly degenerate. The second level is higher than the ﬁrst level by 1 eV. (c) What is the characteristic temperature of the ﬁrst excited level? (d) Calculate ζ at very low temperatures, with respect to the character- istic temperature of the second level. (e) Calculate the contribution of the atomic levels to the speciﬁc heat. Sketch it in detail. Have we already seen a speciﬁc heat with such a structure? Why is there nevertheless a diﬀerence? Exercise 2 Solution on page 436 Consider a given monoatomic gas. The ﬁrst three electronic levels are at a distance of 1 eV from one another. In addition, each atom has a magnetic moment, whose projection along the direction of the ﬁeld can take ﬁve values: µ = −2µ0, −µ0, 0,µ0, 2µ0,where µ0 =2 × 10−20 erg/gauss. Calculate the changes in the chemical potential and in the speciﬁc heat resultingfrom this structure in a magnetic ﬁeld of 106 gauss, and illustrate their temperature dependence graphically. Exercise 3 Solution on page 439 For a reaction described by 2NaOH + H2SO4 ⇀↽ Na2SO4 +2H2O , 403 404 Self-assessment exercises (a) Write the law of mass action. (b) Write the additional equations. (c) Is the system solvable? Explain. Exercise 4 Solution on page 440 Calculate the equilibrium constant in the gaseous reaction: Cl2 +H2 ⇀↽ 2HCl . The vibrational angular frequencies are: For chlorine 1014 s−1, for hydro- gen 8.3 × 1014 s−1 and for HCl 5.7 × 1014 s−1. The moments of inertia are given in Table 4.1.2. Exercise 5 Solution on page 442 At the beginning of Sec. 4.4 we showed that the radiation density in a cavity in equilibrium at temperature T is independent of position. In a similar way: (a) Prove that ρ(q,T ) is independent of the direction of q. (b) Prove that ρ(q,T ) is independent of the radiation’s polarization. (c) Is it possible to prove that ρ is independent of ω? Exercise 6 Solution on page 443 (a) Prove that the radiation emitted per unit surface area per unit time by a black body, for wavelengths ranging between λ and λ + dλ,is ˜I(λ)dλ = 2πhc2 λ5 dλ eβhc/λ − 1 . (b) Calculate the wavelength λmax for which the emitted energy is maxi- mal. (c) The intensity of the radiation emitted by the sun has a maximum at around λ =5×10−7 m. What is the temperature of the sun’s surface? Exercise 7 Solution on page 445 (a) What is the average number of photons per unit volume in a cav- ity at temperature T ? How many photons per cm3 does the cosmic background radiation contain? (b) What is the ratio between the average number of photons and the average number of gas particles at the same pressure, volume and temperature as that of the three-degree radiation? (c) Is the ratio you found in (b) valid at any temperature? Self-assessment exercises 405 (d) Calculate the speciﬁc heat at constant volume per photon. Compare it to the speciﬁc heat per molecule of an ideal gas. (e) A student calculated CV /N for the photon gas discussed in (d) in the followingmanner: Using the result of Exercise 4.6 (a) he wrote E =3PV , and usingEq. (xi) in the solution of (b) of the present exercise he wrote E =3PV = 3NkT 1.1106 =2.7NkT . The speciﬁc heat at constant volume is the derivative of E with respect to T , and hence CV N = 1 N ( ∂E ∂T ) N,V =2.7k. This result diﬀers, of course, from that obtained in (d). Where is the error? Exercise 8 Solution on page 447 Bodies whose color is black are bodies that absorb most of the radiation incident upon them, and those are also what we technically deﬁned as black bodies (see Secs. 4.3 and 4.4). But there we stated that a black body emits radiation better than any other kind of body. (a) How would you settle the contradiction? (b) In what conditions will a black body appear to be yellow? (c) How is it possible, at regular conditions, to convince the sceptic that indeed a black body is not all that black? Exercise 9 Solution on page 447 The law of mass action is useful not only for chemical reactions but also for reactions of any other kind, such as reactions between nuclei or between elementary particles at high energies. A typical process is the creation and annihilation of electron–positron pairs, which we may think of as a chemical reaction: e + + e − ⇀↽ γ. Such a gas of electrons, positrons and photons is actually hard to come by, but it could be created at extreme temperature conditions such as those not longafter the bigbang or inside stars. Calculate the density of electrons and positrons in such a gas at nonrel- ativistic temperatures (kT ≪ mc2,where m is the electron mass). Assume that the whole gas is electrically neutral. Solutions to exercises in the text Solution 1.1 Exercise on page 342 (a) To obtain (4.1.6) we write pα = mα ˙rα = mα( ˙Rα + ˙ρα)= mα M (M ˙R)+ mα ˙ρα = mα M P + πα , where we have used (4.1.3), (4.1.4) and (4.1.5). (b) In order to obtain (4.1.7) we rewrite (4.1.4) in the form ρα = rα − R and then multiply it by mα and sum over α: q∑ α=1 mαρα = q∑ α=1 mαrα − q∑ α=1 mαR = q∑ α=1 mαrα − M R . Using(4.1.2), we obtain (4.1.7a): q∑ α=1 mαρα =0 . Diﬀerentiatingthe last equation, we obtain (4.1.7b): 0= d dt q∑ α=1 mαρα = q∑ α=1 mα ˙ρα = q∑ α=1 πα . (c) To prove (4.1.8) we use (4.1.6) and write q∑ α=1 p2 α 2mα = q∑ α=1 1 2mα ( mα M P + πα )2 = P2 2M 2 q∑ α=1 mα + P M · q∑ α=1 πα + q∑ α=1 π2 α 2mα . The middle term is zero by (4.1.7b), and thus we obtain (4.1.8): q∑ α=1 p2 α 2mα = P2 2M + q∑ α π2 α 2mα . 406 Solutions to exercises in the text 407 Solution 1.2 Exercise on page 344 Multiplying(4.1.12b) by m1 and (4.1.12a) by m2 and subtractingwe have m2π1 − m1π2 = m2p1 − m1p2 . Equation (4.1.14b) implies that the left hand side of the last equation is M π1. We can write its right hand side as m2p1 − m1p2 = m2m1(˙r1 − ˙r2)= m2m1( ˙ρ1 − ˙ρ2) and from here π1 = µ( ˙ρ1 − ˙ρ2) and with the help of (4.1.14b) we can also obtain π2 as −π1. Solution 1.3 Exercise on page 345 The potential between the two atoms is U (ρ)= ϵ [( a ρ )2 − 2 a ρ ] , (i) where ρ is the distance between the two atoms, and a and ϵ are parameters that determine the equilibrium point and the depth of the potential. (a) When the distance between the atoms is the equilibrium distance, the potential energy is minimal. We thus diﬀerentiate (i) and equate the derivative to zero: dU dρ = ϵ ( −2 a2 ρ3 +2 a ρ2 ) = 0 (ii) ⇓ ρ = a, namely the equilibrium distance is a. In order to verify that ρ = a is indeed the minimum point, one can diﬀerentiate U a second time and verify that at ρ = a, U ′′ > 0. See (c) below. (b) The bindingenergy is obtained by substitutingthe equilibrium dis- tance ρ = a into (i): U (ρ = a)= −ϵ. (iii) (c) The harmonic approximation to U (ρ) will be U (ρ)= U (a)+ 1 2 U ′′(a)(ρ − a) 2 . (iv) The linear term does not appear because at the equilibrium distance U ′(ρ0)= U ′(a)= 0. 408 Solutions to exercises in the text The value of the second derivative at the equilibrium distance U ′′(a)= ϵ ( 2 · 3 a2 ρ4 − 2 · 2 a ρ3 ) ρ=a = 2ϵ a2 . (v) Equation (iv) will therefore take the form U (ρ)= −ϵ + ϵ a2 (ρ − a) 2 . (vi) The “springconstant” is twice the coeﬃcient of the square deviation from equilibrium: K =2 ϵ a2 = 2 × 2.5 × 1.6 × 10−19 (2 × 10−10)2 =20 N/m . (vii) (d) The energy needed to increase the distance between the atoms from a to 1.05a may be calculated in the harmonic approximation: ∆U = ϵ a2 (0.05a) 2 = 1 400 ϵ. (viii) If ϵ =2.5eV, ∆U =0.25 × 10−3 eV and the correspondingtempera- ture is of order T = ∆U k = 0.25 × 10−3 × 1.6 × 10−19 1.38 × 10−23 ≈ 70 K . (ix) (e) Similar arguments show that ρ increases by 10% at room temperature. Solution 1.4 Exercise on page 345 From Eq. (4.1.11) we obtain { M R = m1r1 + m2r2 , ρ12 = r1 − r2 , and in order to express r1 and r2 in terms of R and ρ12 we solve the two equations with two unknowns. We multiply the second equation by m2 and to add it to the ﬁrst equation: M R + m2ρ12 = m1r1 + m2r1 , and from here r1 = R + m2 M ρ12 . Then we multiply the second equation by m1 and subtract it from the ﬁrst equation we obtain M R − m1ρ12 = m2r2 + m1r2 Solutions to exercises in the text 409 and from here r2 = R − m1 M ρ12 . In a similar manner we obtain from Eqs. (4.1.12) and (4.1.13), the mo- mentum variables, { P = p1 + p2 , M π12 = m2p1 − m1p2 . Actually, there is no need to solve these equations. It is possible to simply use the previous solution, substituting p2 for r1, −p1 for r2, P for ρ12 and −π12 for R. We then obtain p2 = −π12 + m2 M P , p1 = π12 + m1 M P . Solution 1.5 Exercise on page 345 The energy of a triatomic molecule will be, according to (4.1.9) Emol = P2 2M + π2 1 2m1 + π2 2 2m2 + π2 3 2m3 + U12(ρ12)+ U23(ρ23)+ U31(ρ31) , (i) where we have denoted the potential between atoms α and β by Uαβ,and ραβ = ρα − ρβ . (ii) We now note that Emol is expressed in terms of too many variables, but there is a dependence between them: π1 + π2 + π3 =0 , (iii) ρ12 + ρ23 + ρ31 =0 . (iv) It is possible to transform to relative coordinates and to write the kinetic energy as a sum of P2/2M with the two correspondingkinetic energy terms, for example the relative motion between atoms 1 and 2 and the motion of atom number 3 with respect to the center of mass of 1 and 2. In contrast, the potential energies will not separate into a sum of three independent terms since ρ12, for example, depends on the other two, and since the potentials are not linear, U12(ρ12)= U12(−ρ23 − ρ31) does separate into a sum. 410 Solutions to exercises in the text Solution 1.6 Exercise on page 349 The internal energy E is given by (3.1.3): E = − ∂ ln Z ∂β or by the thermodynamic relation [see (2.0.25) or (3.1.28)]: E = F + TS . Since F and S have already been given explicitly in Eqs. (4.1.28) and (4.1.30), we prefer to calculate E from the thermodynamic relation: E = −NkT [ ln V N + 3 2 ln ( 2πM kT h2 ) +1 +ln ζ] +NkT [ ln V N + 3 2 ln ( 2πM kT h2 ) + 5 2 ] + NkT d dT (T ln ζ) . Diﬀerentiatingterms, collectingand dividing by N , we obtain (4.1.32). Solution 1.7 Exercise on page 349 The speciﬁc heat at constant volume is given by the derivative of the internal energy with respect to the temperature. Using (4.1.32) we obtain CV = ( ∂E ∂T ) N,V = 3 2 Nk + Nk d dT ( T 2 d dT ln ζ) , which is exactly (4.1.33). The speciﬁc heat at constant pressure is given by the derivative with respect to T of the enthalpy: CP = ( ∂H ∂T ) N,P , where H = E + PV . From (4.1.29) we obtain H = E + NkT and hence CP = ( ∂H ∂T ) N,P = Nk + ∂E ∂T = Nk + CV ⇓ CP − CV = Nk . Solutions to exercises in the text 411 Solution 1.8 Exercise on page 350 In order to calculate the corrections, implied by the internal structure of the molecule, to the entropy, the internal energy and the speciﬁc heat, we have to calculate the partition function ζ(T ). Because ϵ1 ≪ ϵ2,ϵ3,... it suﬃces, at temperatures that are not too high, to take only the ﬁrst two levels. Assuming that there is a single state at energy ϵ1 (no degeneracy), ζ(T )=1 + e −βϵ1 . (i) The correction to the entropy per molecule is given by (4.1.31). Writing for short ϵ instead of ϵ1 we obtain ∆s = d dT (kT ln ζ)= d dT [kT ln(1 + e −βϵ)] (ii) ⇓ ∆s = k [ ln(1 + e −βϵ)+ βϵ 1+ eβϵ ] . (iii) The following ﬁgure illustrates graphically the temperature dependence of ∆s:➤ T ➤ ln2 ∆s/k If the temperature is very low (kT ≪ ϵ), then ζ → 1 and from (ii) it is clear that ∆s → 0. The approach to zero is given by the power expansion of (iii): ∆s = k(e −βϵ + βϵe −βϵ + ···) ≈ ϵ kT e −ϵ/kT . (iv) The correction to the internal energy is given by (4.1.32) ∆E N = kT 2 d dT ln ζ = ϵ eβϵ +1 . (v) 412 Solutions to exercises in the text The followingﬁgure illustrates the temperature dependence of ∆E/N :➤∆E/Nε 1/2 ➤ T At low temperatures the correction to the internal energy per molecule will behave in the followingmanner: ∆E N ≈ ϵe −βϵ = ϵe −ϵ/kT , and tends to zero when T → 0. Finally, the correction to the speciﬁc heat per molecule is obtained from (4.1.33): ∆CV N = k d dT ( T 2 d dT ln ζ) = d dT ∆E N = k(βϵ)2eβϵ (1 + eβϵ)2 = k(βϵ)2 4cosh2(βϵ/2) , which at low temperatures behaves in the followingmanner: ∆CV N ∼ k(βϵ) 2e −βϵ = k ( ϵ kT )2 e −ϵ/kT . A graphical illustration of ∆CV N is given in the following ﬁgure:➤ ➤ ∆CV Nk T 0.4 0.8ε1/k Solutions to exercises in the text 413 Note the similarity between these results and the correspondingquantities of the paramagnet (Part II, Sec. 5.3). The reason is, of course, that we considered molecules with only two molecular states, as for the single spin of the paramagnet. Solution 1.9 Exercise on page 351 The internal partition function, when kT ≪ ϵ1 − ϵ0, is obtained from (4.1.36): ζ(T ) ≈ g0e −βϵ0 (i) or ln ζ =ln g0 − βϵ0 . (ii) Substituting(ii) into Eq. (4.1.31) we obtain ∆s = d dT (kT ln ζ)= d dT (kT ln g0 − ϵ0)= k ln g0 . When g0 = 1, namely when the ground level is nondegenerate, ∆S =0. Since CV is derived from S,also ∆CV = 0, as is obtained by substi- tution of (i) into Eq. (4.1.33): ∆CV = Nk d dT ( T 2 d dT ( −ϵ0 kT )) =0 . We have therefore found that, for the conditions of the exercise, S and CV of a monoatomic gas are identical to their values for a gas of particles devoid of internal structure. The change in the chemical potential is obtained from (4.1.35), and is ∆µ = −kT ln ζ = ϵ0 , which is equivalent to a constant addition to all the energies of the prob- lem. Solution 1.10 Exercise on page 351 If the ground level is doubly degenerate, we substitute into Eq. (i) of the precedingsolution g0 =2, and obtain ζ(T )= 2e −βϵ0 . The extra entropy per molecule is obtained using(4.1.31): ∆s = d dT (kT ln ζ)= k ln 2 , which is independent of the temperature, so again there is no change in the speciﬁc heat. 414 Solutions to exercises in the text The change in the chemical potential is obtained from (4.1.35): ∆µ = kT ln ζ = −kT ln 2 + ϵ0 . Solution 1.11 Exercise on page 354 We change the variables to x = ρ − ρ0,toobtain ∫ ∞ −∞ ρ 2e −βK(ρ−ρ0)2/2dρ = ∫ ∞ −∞(ρ0 + x) 2e −βKx2/2dx = ρ 2 0 ∫ ∞ −∞ e −βKx2/2dx + ∫ ∞ −∞ x 2e −βKx2/2dx . The mixed term (with xρ0) vanishes upon integration due to the anti- symmetry of the integrand. The ﬁrst term gives ρ 2 0 √ 2π βK . See e.g. Exercise (1.13), Part I. The second is proportional to (βK)−3/2. See e.g. Exercise (1.14), Part I. It is negligible relative to the ﬁrst, because ρ2 0 ≫ 1/βK. Solution 1.12 Exercise on page 355 (a) The internal partition function in the classical approximation is given by Eq. (4.1.49). To calculate the internal energy we substitute (4.1.49) into (4.1.32) and obtain ⟨ϵ⟩ = 3 2 kT + kT 2 d dT ln ζ = 3 2 kT + kT 2 d dT (2 ln T ) = 3 2 kT +2kT = 7 2 kT . The speciﬁc heat at constant volume is CV = ∂E ∂T = 7 2 Nk , as in (4.1.51). (b) From (4.1.34) CP − CV = Nk and from (4.1.51) CV = 7 2 Nk , Solutions to exercises in the text 415 hence γ = CP CV = Nk + CV CV = 9 7 =1.286 . (c) Room temperature is not in the range of temperatures for which our approximations are valid and indeed γ is quite far from 1.286. On the other hand, at T = 1273 K we expect a better agreement, and indeed the values of γ decrease and for oxygen we obtain a value that diﬀers from the classical value by only 0.6%. Solution 1.13 Exercise on page 356 (a) In order for the classical approximation to be justiﬁed we required that ¯hω ≪ kT ≪ Kρ2 0. To a good approximation µ of Cl2 molecules is half the mass of the chlorine nucleus, since the mass of the electrons is negligible compared to the mass of the nucleus. The mass of the most common isotope of chlorine is 35 atomic mass units (1 amu = 1.66 × 10−27 kg), namely to a good approximation µ = 1 2 × 35 × 1.66 × 10 −27 kg ≈ 2.9 × 10 −26 kg . Hence Kρ2 0 = µω2ρ2 0 =2.9 × 10−26 × 1028 × 4 × 10−20 =1.16 × 10−17 J , ¯hω =1.05 × 10−34 × 1014 =1.05 × 10−20 J . And the correspondingtemperature range is 750 K ≪ T ≪ 8.5 × 10 5 K . (b) A graphical illustration of the integrand in Eq. (4.1.44) is given in the followingﬁgure. The bell approximation is justiﬁed, since except for a very narrow region of ρ, the integrand is negligible everywhere.➤ ρ(Å) ➤ 1 0.5 1.8 2.0 2.2 416 Solutions to exercises in the text Solution 1.14 Exercise on page 357 To prove (4.1.52) we write ℓ using(4.1.53b): ℓ 2 =(ρ × π) 2 = ρ 2π2 − (ρ · π) 2 . (i) It is possible to prove (i) usingidentities relating vector products with scalar products or directly: ℓ 2 =(ρπ sin θ) 2 = ρ 2π2(1 − cos2 θ)= ρ 2π2 − (ρ · π) 2 , (ii) where θ is the angle between the directions of ρ and π. DividingEq. (i) by ρ2 and using(4.1.53a), we obtain ℓ 2 ρ2 = π2 − ( π · ρ ρ )2 = π2 − π2 ρ , (iii) DividingEq. (iii) by 2µ we arrive at (4.1.52). Solution 1.15 Exercise on page 358 (a) The moment of inertia with respect to the center of mass of the molecule is I = m1ρ 2 1 + m2ρ 2 2 . (i) Using(4.1.11) and the relation between the relative coordinates and those of the laboratory frame (see Exercise 1.4), we obtain ρ1 = r1 − R = m2 M ρ , (ii) ρ2 = r2 − R = − m1 M ρ , (iii) where we have written ρ12 = ρ. Substituting(ii) and (iii) into (i), we ﬁnd I = m1 ( m2 M )2 ρ 2 + m2 ( m1 M )2 ρ 2 = µρ 2 , and if ρ = ρ0, the moment of inertia is equal to µρ2 0. (b) The values of µ and ρ0 for the molecules in Table 4.1.2 are summarized in the followingtable: Molecule µ (amu) µ (10 −27 kg) I (10 −47 kg · m 2) ρ0 (10 −10 m) H2 1/2 0.83 0.46 0.7 HCl 35/36 1.60 2.40 1.2 Cl2 35/2 29 115 2.0 I2 127/2 105 745 2.7 Solutions to exercises in the text 417 Solution 1.16 Exercise on page 360 For HCl I =2.4 × 10 −47 kg · m2 , ω =5.7 × 10 14 s−1 , ϵv =¯hω =(1.05 × 10 −34)(5.7 × 10 14)= 6 × 10 −20 J=0.37 eV , Θv = ϵv k = 4300 K , ϵr = ¯h2 2I = (1.05 × 10−34)2 2(2.4 × 10−47) =2.3 × 10 −22 J=1.44 × 10 −3 eV , Θr = 2ϵr k =33 K . Solution 1.17 Exercise on page 360 The spacingbetween the vibrational levels is constant and for Cl2 is equal to 0.06 eV, as we have already calculated. In order to ﬁnd out how many rotational levels “ﬁt” into this spacingwe have to ﬁnd the value of J for which Er(J)= ϵv,ortosolve J(J +1)ϵr = ϵv . We have also calculated ϵv for Cl2,and obtained 2.5 × 10−5 eV. Hence J(J +1) = ϵv ϵr = 0.06 2.5 × 10−5 = 2400 , and the positive solution of this equation is J ∼= 48.5. That is, one has to go up 49 rotational levels in order to cross the ﬁrst vibrational spacing. For HCl we use the results we obtained in the solution to the preceding exercise for ϵv and ϵr. J(J +1) = 0.37 1.44 × 10−3 = 257 and J ≈ 16 . Namely, one has to go up 16 rotational levels of HCl in order to reach the ﬁrst vibrational level. 418 Solutions to exercises in the text Solution 1.18 Exercise on page 364 (a) T 2 d dT ln ζr = T 2 d dT ln(1 + 3e −Θr/T )= T 2 3e−Θr/T 1+3e−Θr/T Θr T 2 = 3Θr 3+ eΘr/T , and diﬀerentiatingonce more, we obtain (∆CV )r N =3kΘr d dT 1 3+ eΘr/T =3k ( Θr T )2 eΘr/T (3 + eΘr/T )2 ≈ 3k ( Θr T )2 e −Θr/T , where we have reached the last expression by neglecting the factor of 3 in the denominator compared to the exponential, which is dominant for T → 0. (b) We shall again write the continuum approximation to the partition function at high temperatures: ζr ≈ ∫ ∞ 0 dJ(2J +1)e −J(J+1)Θr /2T . We now perform a change of variables: x = J(J +1) , so that dx =(2J +1)dJ . Hence the integral becomes ζr = ∫ ∞ 0 dxe −xΘr/2T = 2T Θr . (c) Accordingto (4.1.33), (∆CV )r N = k d dT ( T 2 d dT ln 2T Θr ) = k. Solutions to exercises in the text 419 Solution 2.1 Exercise on page 368 We choose to express all of the diﬀerentials in Eq. (4.2.2) in terms of dN1, so that dN2 = ν2 ν1 dN1,dN3 = ν3 ν1 dN1,... ,dNM = νM ν1 dN1 . Substitutingall these expressions into (4.2.4) we obtain µ1dN1 + µ2 ν2 ν1 dN1 + µ3 ν3 ν1 dN1 + ··· + µM νM ν1 dN1 =0 , and after dividingby dN1 and multiplyingby ν1 we obtain (4.2.5). Solution 2.2 Exercise on page 368 (a) 4NH3 +3O2 ⇀↽ 2N2 +6H2O , B1 =NH3 , b1 =4 , ν1 = −4, B2 =O2 , b2 =3 , ν2 = −3, B3 =N2 , b3 =2 , ν3 =2 , B4 =H2O, b4 =6 , ν4 =6 . And the form of Eq. (4.2.5) becomes −4µ1 − 3µ2 +2µ3 +6µ4 =0 . (b) 2C4H10 + 13O2 ⇀↽ 8CO2 + 10H2O , B1 =C4H10, b1 =2 , ν1 = −2, B2 =O2, b2 =13 , ν2 = −13, B3 =CO2, b3 =8 , ν3 =8, B4 =H2O, b4 =10 , ν4 = 10, and Eq. (4.2.5) reads −2µ1 − 13µ2 +8µ3 +10µ4 =0 . 420 Solutions to exercises in the text Solution 2.3 Exercise on page 369 We substitute the expression for the chemical potential (4.1.35) into the equilibrium equation of the reaction and obtain (4.2.6): 0= M∑ i=1 νiµi = M∑ i=1 νikT [ ln ni − 3 2 ln ( 2πMikT h2 ) − ln ζi ] ⇓ M∑ i=1 νi ln ni = M∑ i=1 [ 3 2 νi ln ( 2πMikT h2 ) + νi ln ζi ] ⇓ M∑ i=1 ln(ni) νi = M∑ i=1 ln [( 2πMikT h2 )3/2 ζi ]νi ⇓ ln [ M∏ i=1 (ni) νi] =ln { M∏ i=1 [( 2πMikT h2 )3/2 ζi ]νi} ⇓ M∏ i=1 (ni) νi = M∏ i=1 [( 2πMikT h2 )3/2 ζi ]νi , and denotingthe right hand side by K(T ), we obtain both (4.2.7) and (4.2.8). Solution 2.4 Exercise on page 370 (a) The law of mass action for the reaction 4NH3 +3O2 ⇀↽ 2N2 +6H2O is obtained usingthe table we constructed in the solution to Exer- cise 2.2. We use n1 up to n4 to denote the densities of the constituents of the reaction, respectively from left to right. The law of mass action reads n2 3n6 4 n4 1n3 2 = K(T ) . (i) A single relationship is obtained between the four densities for a given K(T ). Solutions to exercises in the text 421 (b) The reaction conserves the number of atoms of each element. Denoting by nN, nH and nO the densities of nitrogen, hydrogen and oxygen atoms, the reaction equation implies nN = n1 +2n3 , nH =3n1 +2n4 , nO =2n2 + n4 namely a total of four equations with four unknowns. (c) We shall ﬁnd K(T ) usingEq. (4.2.8) with M =4: K(T )= M 3 3 M 9 4 M 6 1 M 9/2 2 ( 2πkT h2 )3/2 ζ 2 3 ζ 6 4 ζ 4 1 ζ 3 2 , where we have used the fact that here 4∑ i=1 νi =1 . Solution 2.5 Exercise on page 371 Without the Gibbs correction the chemical potential of the ith constituent is given by Eq. (3.5.1), with the last term coming from the internal par- tition function: µi = −kT [ ln V + 3 2 ln ( 2πMikT h2 )] − kT ln ζi . The condition for equilibrium, Eq. (4.2.5), takes the form M∑ i=1 νiµi = −kT ln V M∑ i=1 νi − 3 2 kT M∑ i=1 νi ln ( 2πMikT h2 ) − kT M∑ i=1 νi ln ζi =0 , or ( 1 V )∑ νi = [( 2πM1kT h2 )3/2 ζ1 ]ν1 · ... · [( 2πMM kT h2 )3/2 ζM ]νM , which is a meaningless relation between the temperature and the volume. Solution 2.6 Exercise on page 372 When ∆E0 < 0, d ln K dT < 0 , namely K decreases with increasingtemperature. 422 Solutions to exercises in the text The reaction releases heat, and hence an increase in temperature will lead to the reverse reaction, which absorbs heat and tends to cancel the change in temperature. Thus, equilibrium will tend towards the original composition. Solution 3.1 Exercise on page 378 (a) We write (4.3.4) in the form ¨xα =Ω2(xα+1 − 2xα + xα−1) , with Ω2 = K/M , and substitute (4.3.5a) in order to check if it is a solution. Diﬀerentiatingtwice with respect to t is equivalent to multiplyingby −ω2, and thus we ﬁnd that (4.3.4) is satisﬁed provided: −ω2a sin(qbα)sin ωt =Ω2a[sin qb(α+1)−2sin qbα+sin qb(α−1)] sin ωt . The expression in the square brackets can be written, usingidentities between trigonometric functions, in the form 2sin(qbα)cos(qb) − 2sin(qbα)= −2sin(qbα)(1 − cos qb) = −4sin(qbα)sin2 ( qb 2 ) , sin x +sin y =2 sin x+y 2 cos x−y 2 . and the right hand side becomes −4Ω2a sin(qbα)sin2 ( qb 2 ) sin ωt . Comparingthis expression to the left hand side we ﬁnd that (4.3.5a) is a solution provided that ω2 =4Ω2 sin 2 ( qb 2 ) , from which ω(q) is obtained. The range of q values in Eq. (4.3.5b) can be obtained by studyingthe form of the solution (4.3.5a). Since the function sin(qbα)is periodic and α is an integer, the function with a wave number q +2π/b is identical to that with q.Moreover, a solution with q + π/b is equivalent to a solution with q − π/b.It is therefore clear that we will not get any new solutions from wave numbers outside the range 0 ≤ q ≤ π/b. Solutions to exercises in the text 423 Solution 3.2 Exercise on page 379 First, we shall perform the change of variables in the kinetic energy part Ek = m 2 [ 1 4 (˙u1 + √ 2˙u2 − ˙u3) 2 + 1 2 (˙u1 +˙u3) 2 + 1 4 (˙u1 − √ 2˙u2 − ˙u3) 2] = m 2 (˙u 2 1 +˙u 2 2 +˙u 2 3) , (i) where all of the mixed terms cancel out. The potential part can be written as the sum Ep = K(x 2 1 + x 2 2 + x 2 3) − K(x1x2 + x2x3) . (ii) The ﬁrst term assumes a form similar to that of the kinetic energy, since it involves exactly the same coeﬃcients: K(x 2 1 + x 2 2 + x 2 3)= K(u 2 1 + u 2 2 + u 2 3) . (iii) The second part of the potential also reduces to a sum of squares: K(x1x2 + x2x3)= K(x1 + x3)x2 = K √ 2 (u1 − u3)(u1 + u3)= K √ 2 (u 2 1 − u 2 3) , (iv) so that overall Ep = ( 1+ 1 √ 2 ) Ku 2 1 + Ku 2 2 + ( 1 − 1 √ 2 ) Ku 2 3 . (v) The total energy of the three coupled oscillators transforms, therefore, to an expression that looks exactly like the sum of the energies of three free oscillators, where each of the new variables is a linear combination of the original variables. The energy can be written as E = ϵ1 + ϵ2 + ϵ3 , (vi) with ϵ1 = m 2 ˙u 2 1 + ( 1+ 1 √ 2 ) Ku 2 1 , (vii) ϵ2 = m 2 ˙u 2 2 + Ku 2 2 , (viii) ϵ3 = m 2 ˙u 2 3 + ( 1 − 1 √ 2 ) Ku 2 3 . (ix) Each of these free oscillators has a diﬀerent frequency. DenotingΩ2 = K/m we obtain ω2 1 =(2 + √2)Ω2,ω2 2 =2Ω2,ω2 3 =(2 − √ 2)Ω2 . (x) 424 Solutions to exercises in the text Comment The change of variables performed in this solution may seem to be a deus ex machina, but this is not so. This is a simple example of the general way of dealingwith harmonic vibrations of systems of N particles. The general result is that Eq. (4.3.1) is written as a sum over single oscillator energies ϵα,where ϵα = m 2 (˙u 2 α + ω2 αu 2 α) . Solution 3.3 Exercise on page 383 Since the total number of states inside a sphere of radius qD is 3N ,we obtain the condition 3V (2π)3 ∫ d 3q =3N. Integrating over the angles in wave vector space, we obtain 3V 2π2 ∫ qD 0 q2dq =3N, and after integrating over q, Vq3 D 2π2 =3N ⇒ qD = (6π2N V )1/3 . Solution 3.4 Exercise on page 383 Since F = −kT ln Z and F is given in Eq. (4.3.11), we can write ln Z = − F kT = −βF , so that E = − ∂ ln Z ∂β = ∂(βF ) ∂β = 3V 2π2 ∂ ∂β ∫ qD 0 ln(1 − e −β¯hvq)q2dq , where in the last step have substituted (4.3.11). We change the variable of integration to ω, diﬀerentiate with respect to β and obtain E = 3V 2π2v3 ∂ ∂β ∫ ωD 0 ln(1 − e −β¯hω)ω2dω = 3V 2π2v3 ∫ ωD 0 e−β¯hω¯hω 1 − e−β¯hω ω2dω . Multiplyingthe numerator and the denominator in the integrand by eβ¯hω, we obtain (4.3.13). Note that we could diﬀerentiate under the integration sign because the limit of the integration, ωD is independent of β. Solutions to exercises in the text 425 Solution 3.5 Exercise on page 384 To calculate the speciﬁc heat, namely the integral in Eq. (4.3.16), we change variable to x =¯hω/kT . We have to replace the upper integration limit by xD = ¯hωD kT , so that C = 3kV 2π2 ( kT ¯hv )3 ∫ xD 0 x4ex (ex − 1)2 dx . Using(4.3.12b) we write ( kT ¯hv )3 = ( kT ¯hωD )3 · 6π2N V and then C =9Nk ( kT ¯hωD )3 ∫ xD 0 x4ex (ex − 1)2 dx . This is where the low temperature approximation enters. When T is very small, xD ≫ 1, and then we can approximate the integral by I ≡ ∫ ∞ 0 x4ex (ex − 1)2 dx . The value of this integral can be looked up in tables. See also the appendix at the end of this part. We write I = − ∫ ∞ 0 x 4 d dx [ 1 ex − 1 ] dx =4 ∫ ∞ 0 x3dx ex − 1 , and using(4.A.5) we ﬁnd the value of the integral to be I =4π4/15. Then by substitutingin the expression for C, we obtain (4.3.17). Solution 4.1 Exercise on page 387 The present problem is a simpliﬁed version of the argument made in Sec. 3.7 (the appendix) of Part I. There are three simpliﬁcations on our side: (a) The distribution of radiation is position independent. (b) All the photons have the same speed — c. (c) The mean free path is inﬁnite. We can use Fig. 1.3.7. The amount of radiation energy with frequency between ω and ω + dω in a volume element dV (= r2dr sin θdθdφ)is ρ(ω)dωdV . The radiation propagates from dV in all directions at a speed c. The part ∆A cos θ/4πr2 (the ratio between the solid angle spanned 426 Solutions to exercises in the text by the area element and the whole sphere) of the radiation is directed towards the surface element which concerns us. The energy of the radiation between ω and ω + dω, which will cross the unit area duringunit time ∆t, will be the sum of all the contributions comingfrom all the volume elements which are found in half a sphere of radius c∆t.Namely, ∆E = ∫ c∆t 0 dr ∫ π/2 0 dθ ∫ 2π 0 dφr2 sin θρ(ω)∆ω ∆A cos θ 4πr2 = 1 2 ∆A∆ωρ(ω) ∫ c∆t 0 dr ∫ π/2 0 sin θ cos θdθ , where we have performed the integration over φ. We are thus left with elementary integrals over r and θ whose result is 1 2 c∆t. Hence ∆E = c 4 ρ(ω)∆ω∆t∆A and the amount of energy per unit time per unit area and per unit fre- quency is given by (4.4.2). Solution 4.2 Exercise on page 389 A sinusoidal electromagnetic wave is an electric ﬁeld and a magnetic ﬁeld of the form E = E sin(q · r − ωt) , B = B sin(q · r − ωt) , where E and B describe the wave’s amplitude and the direction of its polarization. We shall now use the two Maxwell equations ∇· E =0 , ∇· B =0 . The calculation of the divergence is the same for the two ﬁelds. For example, ∇· E = ∂Ex ∂x + ∂Ey ∂y + ∂Ez ∂z = ( Ex ∂ ∂x + Ey ∂ ∂y + Ez ∂ ∂z ) sin(q · r − ωt) = q · E cos(q · r − ωt) , and since the divergence vanishes at every point at all times, q · E =0 , namely E is perpendicular to q, and hence E is also perpendicular to q. Solutions to exercises in the text 427 In exactly the same manner it is possible to show that B is perpen- dicular to q, which shows that this is a transverse wave. Solution 4.3 Exercise on page 392 (a) When β¯hω ≪ 1 , (i) we can expand the exponential function in the denominator of (4.4.12): e β¯hω ≈ 1+ β¯hω , (ii) and then ρ(ω) ≈ 1 π2c3 ¯hω3 β¯hω = kT ω2 π2c3 . (iii) (b) In the Einstein model, condition (i) can be interpreted as a condition for high temperatures (see Sec. 2.3 of Part III). This is so since in the Einstein model all the oscillators have the same frequency ω.In contrast, for a black body, all the frequencies from zero up to inﬁnity appear. Hence there is no temperature that satisﬁes condition (i) for all the oscillators. On the other hand the condition is satisﬁed by the low frequency modes, once the temperature is given. The Rayleigh–Jeans law therefore describes the Planck distribution in the low frequency range. Solution 4.4 Exercise on page 392 (a) First we write the frequency (and not the angular frequency) dis- tribution by changing variables in (4.4.14) and using the fact that I(ν)dν = I(ω)dω: I(ν)dν = 2πh c2 ν3 eβhν − 1 dν . (i) In order to ﬁnd the frequency at which the emissivity is maximal we diﬀerentiate with respect to ν and obtain dI dν = 2πhν2 c2 3eβhν − βhνeβhν − 3 (eβhν − 1)2 . (ii) The sign of the derivative is determined by the numerator of the second fraction in (ii), which we write after the change of variables x = βhν in the form A(x)= 3e x − xe x − 3 . (iii) This function is positive between x =0 and x = xmax and negative for x>xmax (check this). It vanishes at the point x = xmax which is a 428 Solutions to exercises in the text solution of the equation A(x) = 0. This is a transcendental equation to be solved numerically. Equation (iii) can be written in the form x = f (x) , (iv) with f (x) ≡ 3(1 − e−x). It can be iterated accordingto xn+1 = f (xn)(v) until |xn+1 − xn| becomes less than a desired precision. We choose arbitrarily x0 =2.5 and iterate accordingto (v). The results are summarized in the table below. n 012 34 x 2.500000 2.753745 2.808933 2.819192 2.821038 56 78 2.821368 2.821427 2.821437 2.821439 Hence x converges to the value xmax =2.8214 and from here hνmax kT =2.8214 . (vi) Substitutingthe values of Planck’s constant and Boltzmann’s constant we obtain (4.4.15). (b) In order to ﬁnd the total power emitted from a unit surface area of a black body, we have to integrate over Eq. (i): I = ∫ ∞ 0 I(ν)dν = 2π c2h3β4 ∫ ∞ 0 x3 ex − 1 dx , after the change of variable to x = βhν. In the solution to Exercise 3.5, we found that this integral is equal to π4/15. Hence I = 2π5(kT )4 15c2h3 = σT 4 . Note that by integrating the Rayleigh–Jeans distribution we obtain a diverging result that implies an emission of inﬁnite power. This is the well-known ultraviolet catastrophe. Solutions to exercises in the text 429 Solution 4.5 Exercise on page 393 (a) The free energy, for the case of electromagnetic radiation, is given by (4.4.9): F = kT V π2c3 ∫ ∞ 0 ω2 ln(1 − e −β¯hω)dω . (i) With x = β¯hω =¯hω/kT it becomes F = (kT )4V π2c3¯h 3 ∫ ∞ 0 x 2 ln(1 − e −x)dx . (ii) The integral in (ii) is a numerical constant whose value is found after integration by parts using the integral in the preceding exercise: ∫ ∞ 0 x 2 ln(1 − e −x)dx = − 1 3 ∫ ∞ 0 x3 1 − e−x dx = − π4 45 , (iii) and from here F (T, V )= − π2V (kT )4 45(¯hc)3 = − 4σ 3c VT 4 , (iv) S = − ( ∂F ∂T ) V = 16σ 3c VT 3 , (v) CV = T ( ∂S ∂T ) V = 16σ c VT 3 . (vi) (b) The chemical potential is µ = ( ∂F ∂N ) T,N =0 . (vii) The reason is that the free energy is independent of the number of photons in the container, which is not a constant (conserved) quantity. Photons are created and annihilated freely as a result of absorption and emission by the walls of the container. The meaningful quantity in this context is the average number of photons [see Eq. (4.4.13) and Self-Assessment Exercise 7 (a)]: ⟨N ⟩ = V π2c3 ∫ ∞ 0 ω2 eβ¯hω − 1 dω = ( kT ¯hc )3 V π2 ∫ ∞ 0 x2 ex − 1 dx . (viii) The integral is a dimensionless number, and hence ⟨N ⟩ is proportional to VT 3,as are S and CV . 430 Solutions to exercises in the text Solution 4.6 Exercise on page 393 (a) In the solution to the precedingexercise we have calculated the free energy of electromagnetic radiation: F = − 4σ 3c VT 4 . (i) The radiation pressure is therefore P = − ( ∂F ∂V ) T = 4σ 3c T 4 . (ii) Usingthe expression for the energy density Eq. (4.4.17), u = 4σ c T 4 , (iii) we can rewrite (ii) in the form P = 1 3 u (iv) and obtain the equation of state PV = 1 3 E, (v) which is exactly Eq. (1.1.7), obtained in Part I for particles moving at the speed of light and satisfying ϵ = pc. (b) The compressibility is K = −V ( ∂P ∂V ) T =0 (vi) since P , at constant T , is independent of thevolume[seeEq. (ii)]. In an ideal gas, on the contrary, P = NkT V , (vii) and from here K = −V ( ∂P ∂V ) T = NkT V = P. (viii) The bigdiﬀerence is due to the fact that when the volume of the gas decreases at constant temperature, the number of particles remains constant, and the pressure increases. In contrast, when the volume of radiation decreases at constant T , the number of photons decreases [see Eq. (viii) in the solution of the precedingexercise], and the pres- sure remains constant. Solutions to exercises in the text 431 Solution 4.7 Exercise on page 393 In Solution 4.6 we obtained the pressure of radiation: P = 4σ 3c T 4 , (i) hence T = ( 3cP 4σ )1/4 . (ii) (a) For P =1 atm, T = (3(3 × 108)(1.013 × 105) 4(5.67 × 10−8) )1/4 =1.4 × 10 5 K . (b) For P =10−10 atm, T = ( 3(3 × 108)(10−10 × 1.013 × 105) 4(5.67 × 10−8) )1/4 = 450 K . (c) The pressure of radiation at the center of the sun (T =107 K) is P = 4(5.67 × 10−8)(107)4 3(3 × 108) =2.5 × 10 12 N/m2 =2.5 × 10 7 atm . Since the pressure of the gas there is 1011 atm, the pressure of radiation in the sun is still negligible in the balance for mechanical equilibrium. (d) From Eq. (iv) in Solution 4.6, P = 1 3 u, (i) and by comparing(4.4.16) to (4.4.17) we ﬁnd that u = 4 c I, (ii) and hence P = 4I 3c . (iii) The radiation pressure on Earth’s surface is P = 4 × 1400 3 × 3 × 108 =6.22 × 10 −6 N/m2 =6 × 10 −11 atm . 432 Solutions to exercises in the text Solution 4.8 Exercise on page 397 Were the detailed balance not to hold separately for each frequency, we would be able to ﬁnd a frequency in which the body absorbs more radi- ation than it emits. As a result, the energy density inside the container would decrease at this frequency. The radiation distribution would devi- ate from Planck’s distribution and as a result thermodynamic equilibrium would be violated, even though initially the temperature of the body was equal to the temperature of the radiation. A similar situation would have occurred were detailed balance not to hold for each direction of q separately. Since it is impossible for the system, once it has reached thermo- dynamic equilibrium, to leave it, our assumption regarding the detailed balance must be wrong. Solution 4.9 Exercise on page 397 (a) A black body has been deﬁned as a body that absorbs all the radiation incident upon it. The absorbingpower of body A was deﬁned as the ratio between the intensity of radiation absorbed by the body and the intensity of radiation incident upon it. Hence, for a black body A =1 and (4.4.19) implies that LB = c 4π ρ. (b) The emissivity has been deﬁned as the total power emitted per unit area per unit frequency, whereas the emissive power is the power emit- ted by a unit area in a certain direction (determined by the direction of the wave vector) per unit solid angle per unit frequency. The rela- tion between the two quantities is, therefore, dI = L cos θdΩ . For a black body, L is independent of the angle and is given by (4.4.22). Thus, I(ω)= c 4π ρ(ω) ∫ cos θdΩ= c 4 ρ(ω) , which is Eq. (4.4.2). We have performed the integration only in the directions that describe emission, namely 0 ≤ θ ≤ π/2. Solutions to exercises in the text 433 Solution 4.10 Exercise on page 397 We shall write the emissive power as a function of the frequency ν using Eq. (4.4.22): LB(q,T )= c 4π ρ(ω, T )= 1 4π3c2 ¯hω3 eβ¯hω − 1 = 1 πc2 · hν3 eβhν − 1 . The maximum of LB satisﬁes Wien’s law, (4.4.15), which we derived from the emissivity I, and hence we can calculate νmax at each of the tempera- tures from Wien’s law and substitute in the function LB.It is somewhat simpler to ﬁrst substitute (4.4.15) into LB and express LBmax as a function of the temperature only: LBmax = LB(ν = νmax)= (kT )3 πc2h2 · x3 max exmax − 1 . If we substitute the physical constants (and xmax =2.8214) and if T is measured in K and LB in J m −2,then LBmax =3.018 × 10 −20T 3 . The numerical results are summarized in the followingtable: T (K) 100 1,000 10,000 100,000 νmax (Hz) 5.88 × 10 12 5.88 × 10 13 5.88 × 10 14 5.88 × 10 15 LBmax (J m −2)3.018 × 10 −14 3.018 × 10 −11 3.018 × 10 −8 3.018 × 10 −5 Solutions to self-assessment exercises Solution 1 Exercise on page 403 (a) The scheme of the low levels that interest us is ε2 = 10eV ε1 ; g1=3 0➤ε The wavelength of the emitted line in the transition from ϵ1 to the ground state is 21 cm. Hence ϵ1 =¯hω = hc λ = (6.626 × 10−34)(3 × 108) 0.21 ≈ 9.5 × 10 −25 J ≈ 5.9 × 10 −6 eV . (b) Because ϵ2 =10 eV, β(ϵ2 − ϵ1) ≈ βϵ2 ≈ 1.6 × 10−18 (1.38 × 10−23)T ≈ 1.2 × 105 T , so that for T ≪ 105 K we may use the approximation (4.1.36). Taking ϵ0 =0, we have ζ =1 + g1e −βϵ1 . Speciﬁcally for 0.1 K, ζ(0.1K) = 1 + 3e −βϵ1 =1 + 3 exp ( − ϵ1 kT ) =1 + 3 exp ( − 9.5 × 10−25 1.38 × 10−24 ) ≈ 2.5 . 434 Solutions to self-assessment exercises 435 (c) The characteristic temperature of the ﬁrst excited level is Θ1 = ϵ1 k ≈ 0.11 × 1.6 × 10−19 1.38 × 10−23 ≈ 1, 250 K . (d) The level scheme is: ε2 = 1.11eV ε1=0.11eV; g1=2 0; go=4➤ε The characteristic temperature of the second excited level is Θ2 = ϵ2 k ≈ 1.11 × 1.6 × 10−19 1.38 × 10−23 ≈ 1.3 × 10 4 K . Namely, we are lookingfor ζ for T ≪ 1.3 × 104 K, where the term containing ϵ2 is negligible. We thus have ζ(T )= g0 + g1e −βϵ1 =4 + 2e −Θ1/T . (e) The contribution of the atomic levels to the speciﬁc heat is derived from ζ usingEq. (4.1.33): ∆CV N = k d dT ( T 2 d dT ln ζ) . Substituting ζ(T )weobtain T 2 d dT ln ζ = T 2 d dT ln(2 + e −Θ1/T )= Θ1e−Θ1/T 2+ e−Θ1/T = Θ1 2eΘ1/T +1 . Substitutingthis in the expression for CV yields CV N = 3 2 k + k d dT Θ1 2eΘ1/T +1 = 3 2 k + 2k(Θ1/T )2eΘ1/T (2eΘ1/T +1)2 . The graph describes the speciﬁc heat as a function of temperature, where the temperature is measured in units of Θ1. Only the con- tribution due to the internal structure, above the ideal gas value, is depicted. We have seen a speciﬁc heat of similar structure for the paramagnet (see Exercise 1.8 in this part and Fig. 2.5.2). 436 Solutions to self-assessment exercises The similarity is due to the fact that the atoms of the gas have two (active) electronic energy levels, as does the paramagnetic moment. But in contrast the two levels have diﬀerent degeneracies, and thus the speciﬁc heat does not look exactly like that of the paramagnet. In addition, in the gas there are degrees of freedom related to trans- lational motion of the molecules. As a result, the speciﬁc heat of the gas will not vanish when T → 0, nor when T →∞.➤ T/Θ1 ➤1.5 12 3 4 1.6 1.7 CV/Nk Only in a narrow range of temperatures will a maximum appear whose origin is similar to that in the paramagnetic case. If T is less than the energy spacing between the two levels, it is impossible to excite the atoms to the second level, and the heat must be absorbed by translation. When the temperature equals the spacing, the system can absorb energy in a much more eﬃcient manner than by translation — the atoms pass from the ground level to the excited one. And later on, when there are no more molecules to excite, translation is again the only option. Solution 2 Exercise on page 403 The electronic levels: the ground level is at ϵ0 = 0, the ﬁrst excited level at ϵ1 = 1 eV, and the second excited state ϵ2 =2 eV. The correspondingcharacteristic electronic temperature Θe = 1.6 × 10−19 1.38 × 10−23 ≈ 11, 600 K . (i) The distances between the magnetic levels are of order µ0H,and they deﬁne a characteristic magnetic temperature: ΘM = µ0H k = (2 × 10−27 Jgauss−1) × 106 gauss 1.38 × 10−23 JK −1 ≈ 145 K ≪ Θe . (ii) Solutions to self-assessment exercises 437 The contributions to the partition function can be written as ζe =1 + e −ϵ1/kT + e −ϵ2/kT =1 + e −Θe/T + e −2Θe/T , (iii) ζM = 2∑ σ=−2 e −σµ0H/kT =1 + e ΘM /T + e −ΘM /T + e 2ΘM /T + e −2ΘM /T =1 + 2 cosh ( ΘM T ) +2 cosh ( 2ΘM T ) . (iv) The change in the chemical potential will be calculated using (4.1.35): ∆µ = −kT ln ζ = −kT (ln ζe +ln ζM ) = −kT { ln [ 1+ exp (− Θe T ) +exp ( − 2Θe T )] +ln [1+ 2 cosh ( ΘM T ) +2 cosh ( 2ΘM T )] } . (v) At very low temperatures (T ≪ ΘM ) the ﬁrst ln is negligible, whereas the second one behaves as ln [ cosh ( 2ΘM T )] ≈ 2ΘM T , so that there ∆µ ≈−2kΘM . At very high temperatures (T ≫ ΘM ) both terms in the braces are con- stant, and hence ∆µ decreases linearly with the temperature. The fol- lowingﬁgure illustrates ∆µ as a function of T . The temperature scale is logarithmic. –2ΘM➤ ➤ ∆µ/k TΘeΘM The change in the speciﬁc heat (per atom) will be calculated using (4.1.33): ∆cV k = ∆CV Nk = d dT [ T 2 ( d dT ln ζ)] . (vi) 438 Solutions to self-assessment exercises Even without calculatingthe derivatives we can obtain an idea of the nature of the dependence of ∆cV upon T . Since ln ζ is a sum of two terms, the speciﬁc heat ∆cV will also be a sum of a magnetic part and a part originating in the atomic levels. The speciﬁc heat originating from the magnetic moment “unfreezes” at temperatures around ΘM . Hence it behaves as the speciﬁc heat of a paramagnet whose general features are depicted in Fig. 2.5.2 (in Part II). The speciﬁc heat originating in the atomic levels unfreezes at temperatures around Θe, and looks like the one illustrated in the solution of the precedingexercise, which also resembles that of a paramagnet. Overall we therefore obtain a speciﬁc heat with two high peaks: one at T ≈ ΘM and the other at T ≈ Θe, as illustrated in the followingﬁgure:➤ ΘM ➤ 0.8 TΘe 0 ∆cV/k Note that here as well the temperature scale is logarithmic. In order to obtain the values of ∆cV around the points of the maxima (T ≈ ΘM , Θe), we have to calculate explicitly each of the contributions. We can obtain the ﬁrst directly from Eq. (vi), but it is much simpler to use Exercise 5.7(d) in Part II: (∆cV )M k =(βµ0H) 2   1 4sinh2 ( 1 2 βµ0H) − 25 4sinh2 ( 5 2 βµ0H)   , (vii) where we have substituted J =2 (for which 2J +1 = 5) and µ0 = gµB. Equation (vii) can be written usingΘM : (∆cV )M k = ( ΘM 2T )2 [ 1 sinh 2(ΘM /2T ) − 25 sinh 2(5ΘM /2T ) ] (viii) and for T =ΘM : (∆cV )M k =0.75 . (ix) Solutions to self-assessment exercises 439 A more detailed study, which we shall not reproduce here, reveals that the maximum of (∆cV )M is not attained at exactly T =ΘM but at T ≈ 0.75ΘM , and that (∆cV )M /k ≈ 0.8. The second contribution to the speciﬁc heat can again be calculated directly from Eq. (vi). However, it is again preferable to use the known results for the paramagnet from Exercise 5.7 of Part II, since the atomic excitations behave here exactly like a paramagnet with spin J =1. Re- placing βgµBH by Θe/T we write (∆cV )e k = ( Θe 2T )2 [ 1 sinh 2(Θe/2T ) − 9 sinh 2(3Θe/2T ) ] (x) andthenfor T =Θe (∆cV )e k =0.42 . (xi) Again the maximum of (∆cV )e is not attained exactly at T =Θe but at T =0.53Θe,and (∆cV )e/k =0.64 at the maximum. The reason why the speciﬁc heat contributed by the atomic excitations is smaller than that originating from the magnetic moment is that the number of atomic levels is smaller than the number of the magnetic levels. Solution 3 Exercise on page 403 (a) The reaction: 2NaOH + H2SO4 ⇀↽ Na2SO4 +2H2O , (i) B1 =NaOH, B2 =H2SO4, B3 =Na2SO4, B4 =H2O, b1 =2, b2 =1, b3 =1, b4 =2, ν1 = −2, ν2 = −1, ν3 =1, ν4 =2 . The law of mass action reads n3n2 4 n2 1n2 = K(T ) . (ii) (b) The additional equations are nNa = n1 +2n3 , (iii) nO = n1 +4n2 +4n3 + n4 , (iv) nH = n1 +2n2 +2n4 , (v) nS = n2 + n3 . (vi) There are four additional equations, since four types of atoms appear in the reaction. Overall there will be ﬁve equations for determining the densities. Hence it appears that if the atomic densities are given arbitrary values, it will be impossible to ﬁnd a solution for all ﬁve equations. 440 Solutions to self-assessment exercises (c) The solution of the mystery is the fact that the four equations (iii)– (vi) are not independent, as you will ﬁnd if you try to solve them and to calculate the four densities n1,n2,n3,n4 in terms of the atomic densities. The dependence between the equations is also reﬂected in the fact that nH + nNa +6nS − 2nO =0 . Namely, any three of the densities determine the fourth density. This is of course a special property of reaction (i). As a result, we have only three independent accompanyingequations and together with Eq. (ii) we can obtain a single solution for the densities of the molecules. Solution 4 Exercise on page 404 In the reaction Cl2 +H2 ⇀↽ 2HCl , B1 =Cl2, B2 =H2, B3 =HCl, b1 =1, b2 =1, b3 =2, ν1 = −1, ν2 = −1, ν3 =2 . We calculate K usingEq. (4.2.8): K(T )= 3∏ i=1 [( 2πMikT h2 )3/2 ζi(T ) ]νi = ( 2πkT h2 )3/2 ∑ i νi 3∏ i=1[M 3/2 i ζi(T )] νi = Mζ 2 3 ζ1ζ2 , (i) where M = ( M3 M1M2 )3/2 . (ii) Note that since ∑ i νi = 0 the temperature dependence of K enters only through the internal partition functions. In the approximation of our calculation, it is possible to write for each of the diatomic gases ζ = ζr · ζv , (iii) so that K(T )= M ζ 2 3r ζ1rζ2r · ζ 2 3v ζ1vζ2v . (iv) Solutions to self-assessment exercises 441 ζv cannot be obtained from (4.1.68a), because we have to take into ac- count the diﬀerent dissociation energies (binding energies) of each of the molecules. Thus we take the corrected equation (4.2.31): ζv = eϵD/kT 1 − e−Θv /T . (v) From here we calculate the second (vibrational) term in the equilibrium constant (iv): ζ 2 3v ζ1vζ2v = e∆ϵ/kT (1 − e−Θ1v /T )(1 − e−Θ2v/T ) (1 − e−Θ3v /T )2 , (vi) where ∆ϵ is the diﬀerence between the dissociation energies of the re- actants and the products in the reaction — in other words, the energy released in the reaction: ∆ϵ =2ϵ3D − ϵ1D − ϵ2D . (vii) The ﬁrst factor in Eq. (iii), ζr, is obtained from (4.1.68b) as ζr = ∞∑ J=0 (2J +1) exp[−βϵrJ(J +1)] = ∞∑ J=0 (2J +1) exp [ − J(J +1)Θr 2T ] , (viii) where we have also used in Eq. (4.1.64). But, the ﬁrst (rotational) term in the equilibrium constant cannot be calculated exactly, since, as we have seen, the summation in (viii) is diﬃcult to perform. It can instead be studied in the ranges of high and low temperatures. In order to get an idea of the temperature scales, we calculate Θr and Θv. The results appear in the followingtable: ωI Θv =¯hω/k Θr =¯h 2/kI (10 14 s −1)(10 −47 kg · m 2)(K) (K) Cl2 1.0 115 725 0.7 H2 8.3 0.46 6014 175.0 HCl 5.7 2.4 4130 33.5 From this data it is clear that due to the low rotational temperature of chlorine, we can use the approximation (4.1.73) only for very low tem- peratures (below 0.1 K, T ≪ Θ1r). On the other hand, at temperatures above 1000 K (T ≫ Θ2r) we can already write, using(4.1.75), ζ 2 3r ζ1rζ2r = Θ1rΘ2r Θ2 3r , (ix) 442 Solutions to self-assessment exercises so that at these temperatures K(T )= M Θ1rΘ2r Θ2 3r e∆ϵ/kT (1 − e−Θ1v /T )(1 − eΘ2v /T ) (1 − e−Θ3v /T )2 . (x) Solution 5 Exercise on page 404 (a) We assume that ρ(q,T ) depends on the direction of q;then it is possible to ﬁnd two directions for which ρ(q1,T ) <ρ(q2,T ) , where |q1| = |q2| = ω c . We take two identical bodies which are originally at equilibrium with the cavity at temperature T . We coat each of them with reﬂecting mirrors on all sides but one. The side without a mirror we cover with a ﬁlter that transmits radiation with frequency ω only and reﬂects all other frequencies. We place the two bodies so that the ﬁlter of body No. 1 is perpendicular to q1 and the ﬁlter of body No. 2 perpendicular to q2, makingsure that only radiation directed along q1 be incident on body No. 1 and only radiation directed along q2 be incident on body No. 2. We can achieve this by placinga collimator made of two slits in front of each ﬁlter alongthe corresponding direction. In addition we ensure that the bodies be positioned with the same orientation with respect to their respective collimators. The system is illustrated in the followingﬁgure. q1 q2 ➤ ➤➤➤ (1) (2)➤ ➤ mirror collimator Now, since the two bodies absorb radiation with the same frequency, ω, and the radiation incident on each is perpendicular to the ﬁlter- coated side, the two absorb the same fraction of the radiation incident Solutions to self-assessment exercises 443 upon them. Hence if ρ(q1,T ) <ρ(q2,T ), then body No. 2 absorbs more energy than body No. 1. As a result, its temperature increases and heat will be transferred from one region to another without any work performed, in contradiction to the second law. Note that we have ignored the radiation emitted by the bodies. Emission of radiation actually occurs, but since the bodies are identi- cal and are at the same temperature, they emit radiation of the same intensity. Thus our conclusion, that body No. 2 will absorb more energy than body No. 1, remains valid. (b) We now consider a radiation cavity at temperature T ,in which ρ depends on the polarization of the radiation. Namely, we assume that the density of radiation with polarization n2 is greater than the density of radiation with polarization n1. We place two identical bodies at temperature T , ﬁlter-coated as before. Instead of collimators, we shall place a polarizingﬁlter with polarization n1 in front of one of them and a ﬁlter with polarization n2 in front of the other. In addition we rotate the bodies so that they be oriented in the same way with respect to the axis of their polarizers. Body No. 2 will heat up more than body No. 1, since it will have more radiation incident upon it, in contradiction to the second law. (c) So far we have managed to prove, using the second law of thermody- namics, that ρ is independent of position, the radiation’s direction of propagation, and its polarization. We try to prove in a similar manner that ρ is independent of ω. Namely, we shall attempt to show that a dependence of ρ upon ω leads to a transfer of heat between regions with the same temperature, without performingwork. We assume that the density of radiation with ω2 is higher than that with ω1. We take two bodies which were at equilibrium with the radiation in the cavity at temperature T . We coat one with a ﬁlter which only transmits radiation with frequency ω1, and coat the other with a ﬁlter that only transmits radiation with frequency ω2.Using a line of argument similar to the one used above, we can seemingly conclude that body No. 2 will now heat up, as there is more energy at ω2. However, the absorbingpower and the emittance both depend on the frequency, so that we may not reach such a conclusion. The fact that the energy density depends on the frequency does not, therefore, contradict the second law. Solution 6 Exercise on page 404 (a) The emissivity per unit angular frequency of a black body is given by Eq. (4.4.14): I(ω)= 1 4π2c2 ¯hω3 eβ¯hω − 1 . 444 Solutions to self-assessment exercises In order to obtain the emissivity per unit wavelength, ˜I(λ), it is not enough to “naively” substitute ω =2πc/λ. We must also ensure that the same power (per unit surface area) be emitted in the frequency range dω around ω, as in the range dλ around the corresponding λ. In mathematical terms, I(ω)dω = ˜I(λ)dλ . This implies that in order to obtain ˜I(λ) we should not only express ω in terms of λ in the function I(ω), but also multiply it by the derivative dω/dλ. Actually, it is the absolute value of the derivative that must be taken, since the energy distribution must remain positive. Thus ˜I(λ)= I ( 2πc λ ) ∣ ∣ ∣ ∣ dω dλ ∣ ∣ ∣ ∣ = 1 4π2c2 · ¯h(2πc/λ)3 eβ¯h2πc/λ − 1 · 2πc λ2 = 2πhc2 λ5 1 eβhc/λ − 1 . (b) In order to ﬁnd λmax we diﬀerentiate with respect to λ, like in Exer- cise 4.4, and obtain d ˜I dλ = 2πhc2 λ6 (βhc/λ)eβhc/λ − 5eβhc/λ +5 (eβhc/λ − 1)2 . The sign of the derivative is determined by the numerator of the sec- ond fraction, which, after the change of variables x = βhc/λ,we rewrite in the form B(x)= 5 + xe x − 5e x . This function is positive from x =0 up to x = xmax, and is negative for x>xmax. It vanishes once for x = xmax. Hence, in general, ˜I(λ) has a form similar to that of I(ω) (see Fig. 4.4.4). In order to ﬁnd the maximum, namely xmax, we again use the iter- ative method of Exercise 4.4. We write the equation B(x)= 0 in the form x = f (x) ≡ 5(1 − e −x) . The result of the iterations is summarized in the followingtable: n 012 34 5 x 4.500000 4.944455 4.964386 4.965089 4.965113 4.965114 We see that x converges to the value xmax =4.9651, so that hc kT λmax =4.9651 , Solutions to self-assessment exercises 445 or λmaxT =2.898 × 10 −3 mK = 0.2898 cmK . This relationship is also referred to as Wien’s law, like Eq. (4.4.15). Note that λmaxνmax = c is not satisﬁed. (c) The temperature on the surface of the sun is, accordingto (b) above, T ≈ 0.3 5 × 10−5 ≈ 6, 000 K . Solution 7 Exercise on page 404 (a) We treat the radiation as the excited states of quantum harmonic oscillators with frequencies ωα. The energy levels of such an oscillator are integral multiples of ¯hωα. Inside the cavity, in which there are oscillators of all frequencies, there will be nα photons with energy ¯hωα, which contribute nα¯hωα to the total energy. The average number of photons with energy ¯hωα will be calculated in exactly the same way in which we calculated the number of phonons with energy ω (Exercise 2.3a of Part III): ⟨nα⟩ = ∑∞ nα=0 nαe−β¯hωαnα ∑∞ nα=0 e−β¯hωαnα = ∑∞ nα=0 nαe−xnα ∑∞ nα=0 e−xnα , (i) where we have denoted x = β¯hωα. The expression on the right hand is calculated by notingthat ⟨nα⟩ = − d dx ln ∞∑ nα=0 e −xnα = − d dx ln 1 1 − e−x = e−x 1 − e−x = 1 ex − 1 , (ii) or ⟨nα⟩ = 1 eβ¯hωα − 1 . (iii) The average number of photons per unit volume is a sum over all frequencies — over all the vibrational modes, namely ⟨n⟩ = ⟨N ⟩ V = 1 V ∑ α ⟨nα⟩ = 1 V ∑ α 1 eβ¯hωα − 1 , (iv) where N is the total number of photons in the cavity. Because the frequencies are very dense, it is possible to pass from the sum to an integral. To this end we multiply ⟨nα⟩ by the number of states in the region d3q: dN = 2Vd3q (2π)3 = Vq2dq π2 = V π2c3 ω2dω , (v) 446 Solutions to self-assessment exercises and then ⟨n⟩ = ∫ ∞ 0 ω2 π2c3 dω eβ¯hω − 1 , (vi) which is the integral of Eq. (4.4.13). After changing variables to x = β¯hω we obtain ⟨n⟩ = ( kT ¯hc )3 1 π2 ∫ ∞ 0 x2dx ex − 1 = 2.404 π2 ( kT ¯hc )3 , (vii) where the integral has been calculated using Eq. (4.A.5) with ℓ =2. Equation (vii) can also be written in the form ⟨n⟩ = 144.24 π4 σT 3 kc . (viii) Substituting T = 3K we obtain about 550 photons per cm3. (b) In order to ﬁnd the relationship between the density of photons and the pressure, we calculate the equation of state. We have P = − ( ∂F ∂V ) N,T . (ix) Actually we have already calculated this in Solution 4.6 and obtained P = 4σ 3c T 4 . (x) Dividingthis equation by Eq. (viii) from (a) above, we obtain Np V = 108.18 π4 P kT =1.1106 P kT , (xi) where we have denoted the average number of photons by Np. The number of molecules in an ideal gas satisﬁes Nm V = P kT , (xii) so that Np Nm ≈ 1.11 . (xiii) (c) Suppose that we want to emulate an ideal gas whose pressure is 1 atm by a photon gas. From Eq. (x) it is clear that there exists a single temperature for which this is possible: It is 1.4 × 105 K. Once we have ﬁxed the temperature, the density of molecules is ﬁxed by the equation of state (xii), and the density of photons is ﬁxed by the equation of state (xi) to be 1.11 times larger. This ratio is satisﬁed, therefore, only for the special temperature for which the pressure of the radiation equals the pressure of the gas. Solutions to self-assessment exercises 447 (d) We have calculated the speciﬁc heat of a photon gas in Exercise 4.5, and obtained CV = 16σ c VT 3 . (xiv) Taking N from Eq. (viii), we ﬁnd that the speciﬁc heat per photon is CV Np = π4k 9.015 =10.8k (xv) and is independent of temperature, as in the case of an ideal gas. Each photon contributes to the speciﬁc heat about 11k,compared to 1.5k per molecule in an ideal gas. Nevertheless, we must emphasize that the ratio CV /N is to be interpreted diﬀerently in each case, since in the case of a gas of photons, their number increases with temper- ature. Hence not only does each photon contribute to the speciﬁc heat more than a molecule of an ideal gas, but the number of photons changes as well. (e) This question remains unsolved. Make sure that you know the answer. Solution 8 Exercise on page 405 (a) There exists an ambiguity in the language. In order for a body to be called black in everyday language, it should be a body that does not reﬂect the radiation incident upon it and does not emit radiation in the visible range. Thus an object can be black in terms of everyday language if it absorbs all the radiation in the visible range and emits most of the radiation in the invisible range [see (c) below]. (b) The black body (in the technical sense) will appear yellow if we heat it to a temperature at which the energy emission is maximal in the yellow wavelengths. As we found in the solution of Exercise 6, this temperature is ﬁxed by Wien’s law and is around 6,000 K. An example of such an object is the sun. (c) In order to get convinced that the black body is not black, it must be observed through an instrument that is sensitive to the wavelengths in which the radiation emission is concentrated. At room temperature this wavelength is (according to Wien’s law) about 10−3 cm, which is in the infrared region. Solution 9 Exercise on page 405 We cannot use Eqs. (4.2.7) and (4.2.8) directly, since they were obtained for a Boltzmann gas, whereas here we must treat at least the photons diﬀerently, since they obey Planck’s distribution. However, we can begin from the basic condition for chemical equilibrium, Eq. (4.2.5), which gives in this case µ+ + µ− − µγ =0 , (i) 448 Solutions to self-assessment exercises where µ± are, respectively, the chemical potential of e± and µγ is the chemical potential of the photons. From Exercise 4.5 we have µγ =0 and hence µ+ + µ− =0 . (ii) The chemical potential of a relativistic electron gas can be obtained from Eq. (4.2.13), where the partition function of a single electron is z = 2V h3 ∫ d 3p exp [ −β√ (mc2)2 +(cp)2] . (iii) The factor 2 originates from the two spin states of the electron. The Boltz- mann factor has been generalized to contain the relativistic expression for the energy. As we shall see in the next part, electrons do not obey Boltzmann statistics. Boltzmann statistics applies only in the limit in which the electron density is very low and our calculation is to be interpreted in this light. The low density is guaranteed by the fact that the temperature of the gas is assumed to be nonrelativistic (kT ≪ mc2)sothatpair creation is quite rare. In Part V we discuss such a gas in the opposite limit, kT ≫ mc2. The integral appearing in Eq. (iii) cannot be calculated explicitly. However, for nonrelativistic particles for which mc2 ≫ cp it is possible to expand the energy and to obtain ϵ = mc 2 + p2 2m , (iv) which is the nonrelativistic expression for the energy plus the rest energy mc2. We can now calculate the integral and obtain the usual nonrelativis- tic expression, Eq. (3.4.37), with a correction originating from the spin and the rest mass: z = 8πV h3 ∫ ∞ 0 dpp2 exp [ −β ( mc 2 + p2 2m )] = 2e−βmc2V (2πmkT )3/2 h3 , (v) and usingEq. (4.2.13) the chemical potential becomes µ = kT ln   n 2 ( h2 2πmkT )3/2  + mc 2 . (vi) Solutions to self-assessment exercises 449 This is the chemical potential of an ideal gas with a correction which we may think of as a shift of the energy scale. The factor 1 2 inside the logarithmic function originates from the spin states of the electron. Note that there is no room here for the internal partition function, since the electron (at least as far as we know today) is a particle devoid of internal structure. Even if it had such structure, it does not come into play at the energies discussed. UsingEq. (vi) for the chemical potential of the electrons and the positrons in Eq. (ii), we obtain kT ln   n+n− 4 ( h2 2πmkT )3  +2mc 2 =0 , (vii) where n+, n− are the densities of positrons and electrons, respectively. From here we obtain the law of mass action, which will contain only the densities of the electrons and the positrons: n+n− =4 ( 2πmkT h2 )3 e −2mc2/kT . (viii) If the gas is electrically neutral, then n+ = n− so that n+ = n− =2 ( 2πmkT h2 )3/2 e −mc2/kT . (ix) Note that the rest energy mc2 determines the scale of temperatures at which pair creation becomes signiﬁcant. For instance, at a temperature for which kT /mc2 =0.1(T ≈ 6 × 109 K), which is found at the edge of the approximation’s region of validity, n± =1.6 × 10 24 cm−3 . The density of photons at such a temperature, Eq. (viii) in the solution to Exercise 7, is much higher. We ﬁnd nγ =4.2 × 10 30 cm−3 . This Page Intentionally Left Blank Part V Of Fermions and Bosons This Page Intentionally Left Blank Introduction In the preceding parts we analyzed the thermodynamic properties of systems in the canonical ensemble. In this part we will get acquainted with a generalization of the canonical ensemble to systems that can exchange particles with their surroundings. This generalization, the grand canonical ensemble, which we present in Chap. 1, is of double importance. On the one hand it contributes to a deeper understanding of the statistical physics of classical particles. On the other hand, the new ensemble is the natural tool for the development of statistical mechanics of systems of identical particles in quantum conditions. This is not because a system of (nonrelativistic) quantum-mechanical particles does not conserve the number of particles. It is merely of great technical convenience and is analogous to the application of the canonical ensemble to isolated systems, which have a constant energy. Using the grand canonical ensemble we develop, in Chap. 2, the tools for the statistical mechanics of systems of identical quantum particles. Some of the ele- ments have been laid down in Part IV, in the discussion of the model and black body radiation, and upon this we shall expand and build the structure. The importance of the applications of the statistical physics of identical particles cannot be overstated. We will get acquainted with some of them in different degrees of detail. The main application we shall meet in Chap. 3 concerns electrons, which obey the principle and therefore are subject to the Fermi-Dirac statistics. They are responsible for the properties of metals and especially the various con- ductivity phenomena. Chapter 4 is devoted to the quantum statistical mechanics of bosons, particles subject to the Bose-Einstein statistics, and to the associated phenomenon of superfluidity. It concludes with the spectacular manifestation of electrical conductivity superconductivity. 453 Chapter 1 Grand Canonical Ensemble 1.1 Deﬁnitions and motivation In the precedingparts we have seen that the canonical ensemble (and the free energy) is a most useful description of a system, since in most cases the temperature of the thermodynamic system (and not its energy) is the controlled quantity. Moreover, even when the system is isolated, it is more convenient to think of it as beingin contact with a heat bath, to calculate its free energy and from it to derive the properties of the isolated system. See, for instance, how this was accomplished for the paramagnet in Sec. 1.4 of Part III. We now introduce the grand canonical ensemble, which allows us togrand canonical ensemble relax the constraint of a ﬁxed number of particles in the system. This would have been the natural thingto do in dealingwith chemical reac- tions, or with systems that can exchange particles with a reservoir. But here our motivation for introducingthis ensemble, as mentioned in the in- troduction, is purely technical, so we move directly to the formal aspects. The grand canonical ensemble is deﬁned as a set of systems all with the same type of degrees of freedom and the same energy function. Each system is deﬁned by a state α which is speciﬁed by the number of par- ticles it contains, N , and by the microscopic state i of its N particles. The probability of a state is a generalization of the Gibbs probability, Eq. (3.1.35). It is given by Pα ∼ e −β(Ei−µN ) . (5.1.1) and the grand partition function is deﬁned asgrand partition function Z(T, V, µ)= ∑ α e −β(Ei−µN ) . (5.1.2) Z is again the normalization of the probabilities Pα. The summation consists of two parts: a sum over the particle number N and for each particle number, over all microscopic states i of a system with that number 454 1.2 Connection to thermodynamics 455 of particles. This second sum is the same as in a canonical ensemble with N particles and it gives the canonical partition function for N particles. Thus Z(T, V, µ)= ∑ N e βµN ∑ i e −βEi = ∑ N e βµN Z(T, V, N )= ∑ N e β[µN −F (T,V,N )] , (5.1.3) where the appearance of the free energy is due to the relation Z = e−βF [Eq. (3.1.30)]. Averages of physical quantities (observables) are computed as expecta- tions with the probability distribution (5.1.1), normalized by Z, summing over all values of N and for each value of N , over all microscopic states i.If Aα,or A(N, i), is an observable giving a value for each state in the ensemble, a value that depends on the number of particles N as well as on the microscopic state i of the system, then the average of A in the ensemble is ⟨A⟩ = ∑ α AαPα = Z −1 ∞∑ N =0 ∑ i A(N, i)e −β(Ei−µN ) . (5.1.4) Exercise 1.1 Prove that Z→ 1 in the limit where µ →−∞. Solution on page 514 To justify the choice of this probability distribution we follow the logic of Chap. 1 of Part III, showingthat these probabilities lead to average quantities which can be identiﬁed with thermodynamic quantities satisfy- ingthe thermodynamic laws. 1.2 Connection to thermodynamics The identiﬁcation of the thermodynamic work follows closely the discus- sion in Sec. 1.2 of Part III. For any state i of N particles δWi = −∂Ei/∂X and the thermodynamic work is the average of this quantity. Namely, δW = −Z −1 ∑ N,i e β(µN −Ei) ∂Ei ∂X dX = 1 β ∂ ln Z ∂X dX . (5.1.5) Thus, for a volume change δW = PdV and then P = 1 β ∂ ln Z ∂V = ∂ ∂V (kT ln Z) . (5.1.6) 456 Ch. 1 Grand Canonical Ensemble Z depends on V ,on T (or β) and also on µ. Hence we have N = ∂ ∂µ (kT ln Z) , (5.1.7) where N on the left hand side is the average number of particles. Exercise 1.2 Prove (5.1.7). Solution on page 514 Comparing(5.1.6) and (5.1.7) to the rightmost Eq. (2.0.31), we expect that it be possible to identify the potential Ω with −kT ln Z. Consider the function Ω ≡−kT ln Z , (5.1.8) which is our candidate for a generalization of the relation between the free energy and the canonical partition function, F = −kT ln Z.Calculating the derivative of Ω with respect to T we have ( ∂Ω ∂T ) V,µ = −k ln Z− kT dβ dT ( ∂ ln Z ∂β ) V,µ = Ω T − E T + µ T N, (5.1.9) where E and N are the averages of the energy and the particle num- ber. Now if Ω is identiﬁed as the grand potential, then its temperatureGrand potential derivative, at constant V and µ, should be the entropy. See for example Eq. (2.0.31). Indeed, Eq. (5.1.9) corresponds to the thermodynamic rela- tion Eq. (2.0.29), expressingthe fact that Ω is the potential providingthe thermodynamic information in terms of V, T and µ. Exercise 1.3 Complete the derivation of Eq. (5.1.9). Solution on page 515 Exercise 1.4 Another way of obtainingthe identiﬁcation Ω = −kT ln Z is to use the expression for the entropy in terms of the probabilities of the microscopic states [Eq. (2.6.7)]: S = −k ∑ α Pα ln Pα . Perform this identiﬁcation. Solution on page 515 1.2 Connection to thermodynamics 457 Given the potential Ω we derive all the familiar thermodynamic quan- tities via Eq. (2.0.31) ∂Ω ∂T = −S, ∂Ω ∂V = −P, ∂Ω ∂µ = −N, (5.1.10) where we keep in mind that the independent variables are T, V and µ, and each derivative is calculated with the two unspeciﬁed variables kept constant. We can also write dΩ= −SdT − PdV − Ndµ . (5.1.11) But there is a slight complication, as we shall see in detail in chap- ters 3 and 4: The appearance of µ as a variable, while computationally very convenient, is not natural. Thermodynamic properties of systems are eventually measured with a given number of particles, or density. How- ever, in the grand canonical framework quantities like pressure (equation of state), or the speciﬁc heat, are given as functions of T , V and µ.Thus, we must ﬁrst use the rightmost of Eqs. (5.1.10), to eliminate µ in terms of T, V and N , or rather in terms of T and n = N/V . Chapter 2 Statistical Mechanics of Identical Quantum Particles 2.1 Classiﬁcation of states occupation numbers The passage to the statistical mechanics of systems of identical quan- tum particles is achieved in two steps. The ﬁrst step was already pre- sented in Sec. 4.4 of Part III. It concerns the appearance of quantum states. The second is quantum statistics. In the ﬁrst step one takes intoquantum statistics consideration the fact that quantum particles cannot be described by a full speciﬁcation of their coordinates and momenta, because of the un- certainty principle. Instead, particles are described by wave functions which satisfy boundary conditions imposed by the container to which they are conﬁned. If the particles are noninteracting, then they are in- dependent of each other and each particle is described by its own wave function. As we have seen in Sec. 4.4 of Part III, the wave function of a particle in a rectangular box is a standing (de Broglie) wave in each of the three perpendicular directions. Such a state is speciﬁed by three integers n, p, q, which determine the allowed (quantized) wavelengths, or wave numbers, in the three perpendicular directions and the correspondingthree compo- nents of the quantized de Broglie momentum. (See Part IV Sec. 3.2.) The set of three integers, specifying the wave function of the single particle, we denote schematically by a single index k. The energy of a particle in the state k is ϵk and in the case of a particle in a box, ϵk is given by Eq. (3.4.27). This scheme can be extended to any quantum system of non- interactingparticles, with k interpreted as a label of the single particle states. A state of a system of many noninteractingparticles can be speciﬁed by listingwhich particle is in which of the accessible single particle states, as we have done in Sec. 4.4 of Part III. The energy of such a many-particle 458 2.1 Classiﬁcation of states occupation numbers 459 state can be written as the sum of the single particle energies, i.e. E = N∑ j=1 ϵkj , (5.2.1) where kj is the state of particle j. In each microscopic state we can identify the number of particles in a given single particle state k. This number, which is called the occupation occupation numbernumber, of state k, is denoted by nk. Clearly, ∑ k nk = N, (5.2.2) where N is the total number of particles. Exercise 2.1 What is the largest value that nk can have (for each k) in a system of N particles? Solution on page 515 The energy of the N -particle state is written as E = ∑ k nkϵk . (5.2.3) At this stage, a large number of microscopic states share the same set of occupation numbers. We return to this issue below. Note also that the number of sets k is cubically inﬁnite, hence for a given N most occupation numbers are zero. Exercise 2.2 How many individual microscopic states have the same set of occupation numbers nk? Solution on page 516 Exercise 2.3 Justify Eq. (5.2.3). Solution on page 516 The canonical partition function is, as usual, the sum Z = ∑ states e −βE . 460 Ch. 2 Statistical Mechanics of Identical QuantumParticles As longas the only constraint is the total number of particles, the partition sum can be carried out as in Sec. 4.4 of Part III, i.e. by summingover all triplets of integers corresponding to the index k for each particle. This sum, over N vectors of integers, becomes a product of identical sums. For a box of macroscopic size, if the temperature is not extremely low, each of these sums is very well approximated by an integral, which is essentially the classical result. Temperatures at which the sum deviates signiﬁcantly from the integral are so low as to be beyond any experimental interest. See for example Exercise 4.10. In conclusion, the quantization of the single particle wave functions is not a quantum eﬀect of great impact, until we get to discussing Bose–Einstein condensation in Chap. 4, below. Hence we turn to the second step. 2.2 Quantum statistics many-particle states The principal eﬀect of quantum mechanics on the thermodynamic prop- erties of systems of identical particles is brought about by the quantum- mechanical constraints on the identiﬁcation of allowed, distinguishable microscopic states of the system. Such constraints follow from symmetry properties that must be obeyed by wave functions of many identical parti- cles. Here we pass directly to the implications for the microscopic states. The discussion of the underlyingwave functions is a subject for a more advanced course. It turns out that all possible particles divide into two types: (1) Fermi–Dirac particles (or fermions) — no single particle state canfermion be occupied by more than one particle. This goes by the name of the Pauli principle. Hence the states are characterized by occupationPauli principle numbers that can be either 0 or 1. To any set of (0,1) occupation num- bers corresponds a single microscopic state of the system. Fermions are found to possess half-integer spin (in units of ¯h). (2) Bose–Einstein particles (or bosons) — single particle states can beboson occupied by any number of particles, but for any distribution of oc- cupation numbers there is a single microscopic state of the system. Bosons possess integer spin (in units of ¯h). Since atoms are composed of diﬀerent combinations of protons, neu- trons and electrons, all of which are fermions, there are two possibili- ties: atoms that are composed of an odd number of fermions have half- integral spins, and are fermions, while atoms made up of an even number of fermions have integral spin, and are bosons. Thus, for example, the (neutral) atoms H1,He4 and Li 7 are bosons whereas H2,He3 and Li 6 are fermions. 2.2 Quantumstatistics many-particle states 461 Exercise 2.4 (a) Why is there no need to take into account the orbital angular momen- tum of the electrons in order to determine if an atom is a boson or a fermion? (b) Show that if a neutral atom contains an odd number of neutrons then it is a fermion, and if it contains an even number of neutrons then it is a boson. Solution on page 516 Before proceedinglet us clarify the relation between two ways of spec- ifyingmicroscopic states of noninteracting identical particles. Both ways use the single particle states denoted symbolically by {k}. The ﬁrst way has been employed since Part II to describe states of distinguishable par- ticles. Accordingly, the microscopic states are speciﬁed by the N numbers {kj} with j =1,... ,N . It leads to a partition function that is the N th power of the single particle partition function. This way is incompatible with the indistiguishability of identical particles and leads to the Gibbs paradox. The error is corrected introducingthe factor 1/N ! in the parti- tion function, as we have done in Chap. 5 of Part III. The alternative way of specifyingmicroscopic states uses occupation numbers {nk}, as in the previous section. The partition sum would then be over all sets of occupation numbers for all possible single particle states, {k}, respectingthe constraint Eq. (5.2.2). This sum can be carried out, to reproduce the classical result for the partition function, provided one keeps in mind that the number of N -particle states that correspond to a given distribution of nk’s (Exercise 2.2) is N ! n1!n2! ··· nk! ··· . This may be considered as an unoﬃcial exercise for the enterprising student. On the other hand, in quantum statistics a state with a given set of {nk} corresponds to a single N -particle quantum state. This makes computing the canonical partition sum for systems of particles impossible. It is important to contrast this case with that of the analyses of the Debye model and black body radiation in Part IV. There the degree of excitation played exactly the role of the present occupation number. But there were no underlyingparticles to those “occupation numbers.” The reason we could perform the sum over states in the case of the phonons or photons was that their total number was not ﬁxed. Phonons and photons can be created and annihilated freely and so the sum over their occupation 462 Ch. 2 Statistical Mechanics of Identical QuantumParticles numbers became simple. It is precisely for this reason that we employ the grand canonical ensemble in the calculation of the partition function of quantum many particle systems. 2.3 Thermodynamics of fermions and bosons The partition function of an ideal gas of identical particles is a sum over all the values of nk, as follows: Z = ∑ n1,n2,...,nk... e −βE(n1,n2,...,nk,...) . (5.2.4) If we neglect the forces between the particles, the total energy of a state is a sum of the single particle energies and is given by Eq. (5.2.3). Thus we have Z = ∑ n1,n2,... exp[−β(n1ϵ1 + n2ϵ2 + ... + nkϵk + ...)] . (5.2.5) We would have liked to write this sum as a product of independent sums over each of the occupation numbers separately, as we did for the Einstein solid (Sec. 2.2 of Part III). But here we are faced with a problem that did not arise in the previous cases, namely the values of the occupation numbers are not independent of each other since ∑ k nk = N [Eq. (5.2.2)] is ﬁxed. It is the total number of particles in the system. Thus Z ̸= ( ∑ n1 e −βϵ1n1 )( ∑ n2 e −βϵ2n2) ... ( ∑ nk e −βϵknk ) ··· Exercise 2.5 Explain why we succeeded in factorizingthe partition function of the paramagnet and the Einstein solid while here this step fails. Solution on page 516 Since what is blockingthe factorization of the canonical partition func- tion, Eq. (5.2.5), is the constraint (5.2.2), implied by the ﬁxed number of particles, we turn to the grand canonical ensemble. The constraint is removed at the expense of introducingthe chemical potential µ.We cal- culate the grand canonical partition function, in which all possible values of N enter. We turn to Eq. (5.1.2), where a microscopic state α is characterized by all the occupation numbers {nk}.The set of {nk} determines, via Eqs. (5.2.2) and (5.2.3), the number of particles as well as the energy of 2.3 Thermodynamics of fermions and bosons 463 the state. Hence, Z(T, V, µ)= ∑ α exp[β(µN − Ei)] = ∑ {nk} exp [ β ∞∑ k=1 nk(µ − ϵk) ] . (5.2.6) Now there is no constraint on the occupation numbers. They take on in- dependent values, provided those are consistent with the particles’ statis- tics. Hence it is possible to write Z as a product of “single state” partition functions: Z = ∏ k ∑ nk e β(µ−ϵk)nk . (5.2.7) Exercise 2.6 Prove Eq. (5.2.7). Solution on page 517 All that is left is to calculate the summations in the product (5.2.7) for a given k: Zk = ∑ nk e β(µ−ϵk)nk . (5.2.8) Quantum statistics dictates only two options, either nk = 0,1 for a gas of fermions or nk =0, 1,... , ∞ for bosons. In the case of fermions there are only two terms on the right hand side of (5.2.8). Thus, Z (F ) k = 1∑ nk=0 e β(µ−ϵk)nk =1 + e β(µ−ϵk) , (5.2.9a) while for bosons the right hand side is an inﬁnite geometric series: Z (B) k = ∞∑ nk=0 e β(µ−ϵk)nk =(1 − e β(µ−ϵk)) −1 . (5.2.9b) Note that the summation in (5.2.9b) converges only when µ is lower than all the energy levels of the system, including the ground level. If the ground level is ϵ1 = 0 the chemical potential must be negative. Conversely, the summation in (5.2.9a) consists of only two terms, and thus there is no such constraint on the chemical potential of a gas of fermions. We continue by calculatingthe thermodynamic potential Ω =−kT ln Z [Eq. (5.1.8)], which for fermions and bosons, respectively, reads Ω(F ) = −kT ∑ k ln(1 + e β(µ−ϵk)) , (5.2.10a) Ω(B) = kT ∑ k ln(1 − e β(µ−ϵk)) . (5.2.10b) 464 Ch. 2 Statistical Mechanics of Identical QuantumParticles Recall that the summation is over all a single particle states denoted schematically by k. From these expressions for Ω, and given the energy, ϵk, of the sin- gle particle state k, we can proceed to calculate all the thermodynamic properties of the system, as functions of T, V and µ. 2.4 Average occupation numbers In the grand canonical ensemble the number of particles, N ,is not ﬁxed, but the probability distribution of the diﬀerent states is such that the number actually ﬂuctuates very little around an average number that is determined by T, V and µ. This average is obtained from Eq. (5.1.7). Substitutingfor Ω the expressions we obtained in Eqs. (5.2.10), we obtain, for fermions and bosons respectively, N (F ) = − ( ∂Ω(F ) ∂µ ) V,T = ∑ k 1 eβ(ϵk−µ) +1 , (5.2.11a) N (B) = − ( ∂Ω(B) ∂µ ) V,T = ∑ k 1 eβ(ϵk−µ) − 1 . (5.2.11b) Note the inversion of the sign in the exponent compared to (5.2.10). N (F ) and N (B) are the average number of particles in a state of thermo- dynamic equilibrium, and should have been denoted by ⟨N ⟩.But where the meaningis clear we drop the braces, as we have been doing all along. Since N is a sum over all the single particle states, each term of the sum, corresponding to a given single particle state k, is the average number of particles in that state. For a state k with energy ϵk we ﬁnd that there are on average ⟨n(F ) k ⟩ =(e β(ϵk−µ) +1) −1 (5.2.12a) fermions and ⟨n(B) k ⟩ =(e β(ϵk−µ) − 1) −1 (5.2.12b) bosons. Equation (5.2.12b) should look familiar. In Part III we found that the average degree of excitation of a harmonic oscillator is given by exactly such an expression with µ = 0 [see Eq. (3.2.9)]. The connection between the two becomes clear if the excited states of the harmonic oscillators are considered as particles — phonons with energy ¯hω, as explained in Chap. 3 of Part IV. The average number of phonons with frequency ω in the crystal is the average degree of excitation of the oscillator that was discussed in Part III. 2.4 Average occupation numbers 465 ➤➤ 1.00 5.00–5.00 <n> <n(B)><n(F)> β(ε−µ) Fig. 5.2.1. The average occupation numbers of a single particle state as a function of β(ϵ − µ). The index k has been omitted. Consideringmore closely the these average occupation numbers, we observe that the average occupation number for fermions is consistent with the Pauli principle: If the variable n(F ) k can take the value 0 or 1 only, then its (thermal) average must be less than 1. And, indeed, since the exponential function is always positive, the denominator in (5.2.12a) is larger than 1 and hence the average ⟨n(F ) k ⟩ < 1. Bosons do not satisfy the Pauli principle, and at low T tend to accumulate at the low energy levels. Only the thermal ﬂuctuations stop them from all endingup in the ground level. Equation (5.2.12b) reveals that indeed ⟨n(B) k ⟩ increases with decreasing ϵk and diverges for ϵk → µ. The implications of this divergence will be discussed later on. Figure 5.2.1 describes the energy dependence of the two average occu- Fermi–Dirac distributionpation numbers. These are the Fermi–Dirac distribution and the Bose– Einstein distribution. Plottingthe average occupation numbers as a func- tion of β(ϵ − µ) allows us to consider the graphs as expressing the depen- Bose– Einstein distribution dence of ⟨n(F ) k ⟩ and ⟨n(B) k ⟩ on ϵ, at constant T , or, alternatively, as the dependence on the temperature (β) at ﬁxed single particle energy. For large values of β(ϵ − µ) the two graphs in Fig. 5.2.1 merge, since the exponential dominates the denominator. This is where both distribu- tions tend toward the classical approximation — the Maxwell–Boltzmann distribution, for which ⟨nk⟩∼ e−βϵk. Thus, we have found that a consistent discussion of systems of iden- tical particles, together with the fact that only two kinds of occupation numbers are allowed, yields the Boltzmann distribution only as an approx- imation. The fundamental distributions (5.2.12) are diﬀerent from the Boltzmann distribution and the results obtained from them are in many cases signiﬁcantly diﬀerent from the results obtained using the Boltzmann distribution. Chapter 3 Electrical Conductivity in Metals 3.1 The Drude model An important application of the Fermi–Dirac distribution is the clariﬁca- tion of the electrical conductivity and other physical properties of metals. The comprehensive discussion of this subject is a matter for an entire course. We will limit ourselves to a presentation of the basic conclusions obtained in simpliﬁed conditions. For many years electrical conductivity was considered a mystery, and only the discovery of the electron by J. J. Thomson in 1897 pointed to a possible mechanism for electrical conductivity in metals: The electric cur- rent is a current of electrons. Because the application of even the smallest potential on a metal wire gives rise to a signiﬁcant electric current, metals must contain a huge (macroscopic) number of electrons that are moving essentially freely. This was the startingpoint for the ﬁrst attempt to ex- plain the conductivity in metals, made by Drude in 1900. Macroscopic numbers of electrons immediately bringto mind a statistical treatment, and indeed to this day this is the accepted approach to analyzingthis problem. Since the only tools available to Drude, at the turn of the 20th century, were the kinetic theory and the Boltzmann distribution, he ap- plied them to the electrons in metals. To this end he asserted that the conduction electrons in a metal behave as an ideal gas. In contemporary terms this assertion would be based on the followingassumptions: • When many atoms of a metal create a crystalline structure, the external electrons (valence electrons) of the atoms detach from them and move freely in the metal. The atoms that are left behind become positive ions. The rigid lattice of the crystalline metal is made up of these ions. • Although the electrons are charged, the interactions between them are negligible and they do not aﬀect one another’s motion. This assumption will be justiﬁed in Sec. 4.7. • The electrons are in a state of thermodynamic equilibrium as a result of collisions with the ions in the metal. Between collisions the electrons 466 3.1 The Drude model 467 move in a straight line and at constant speed and the forces applied to them by the ions are neglected. Note the similarity to photons of a black body, where equilibrium is not attained by the mutual interactions but by interactions with the walls of the container. Between collisions the photons move as free particles. Exercise 3.1 Calculate the number of conduction electrons per cubic centimeter of sodium and potassium. Solution on page 517 Based on these assumptions and applyingthe kinetic theory, we derive Ohm’s law: Consider a segment of a metal wire along which there exists a uniform electric ﬁeld. The wire contains a very large number of elec- trons that are movingabout with diﬀerent speeds in diﬀerent directions. See e.g. Fig. 5.3.1. The velocity of an electron between two collisions is determined by Newton’s second law: m dv dt = −eE , (5.3.1) i.e. v = v0 − e m Et, (5.3.2) where v0 is its velocity immediately after the last collision. t, therefore, is the time elapsed from the last collision. A L E➤➤ ➤➤➤➤➤➤ ➤ ➤ Fig. 5.3.1. Conduction in a metal wire. Note that an electric current exists only if the number of electrons moving to the right (against the ﬁeld) is diﬀerent from the number of electrons movingto the left. The relevant quantity is the average velocity, ⟨v⟩, of all the (free) electrons at a given moment. We have to average Eq. (5.3.2) over all the free electrons in the wire. Each of them has undergone its last collision at a diﬀerent time and has come out of it with a diﬀerent velocity. We thus obtain ⟨v⟩ = − eτ m E , (5.3.3) where τ is the mean free time of the electrons. 468 Ch. 3 Electrical Conductivity in Metals Exercise 3.2 Justify Eq. (5.3.3). Solution on page 517 This is a typical transport problem, with a drift velocity proportional to the force. The mobility coeﬃcient is τ/m, as in Part I, Sec. 3.4. The ﬁnal stage is the calculation of the electric current density, namely the current that crosses a unit area per unit time. All the electrons with velocity v, whose number per unit volume is n(v), contribute a factor of −en(v)v to the current density. Hence the current density due to all the electrons in the wire is a sum over all the velocities: J = −e ∑ v n(v)v = −ne⟨v⟩ , (5.3.4) where n is the volume density of all the electrons in the wire (calculated in Exercise 3.1) and ⟨v⟩ is their average velocity. The negative sign corre- sponds to the negative charge of the electrons, and will cancel out against the negative sign in Eq. (5.3.3). Substituting Eq. (5.3.3) into Eq. (5.3.4) yields the local form of Ohm’s law:Ohm’s law J = σE , (5.3.5a) where the electrical conductivity σ is given byelectrical conductivity σ = ne2τ m . (5.3.5b) The inverse of the electrical conductivity is called the electrical resistivity: ρ =1/σ. Note the similarity between ρ and the “friction coeﬃcient” µ ofelectrical resistivity Sec. 2.4 of Part I. Both are inversely proportional to the mobility and in fact both describe the resistance to the motion of the particles due to the many collisions they undergo during their motion. Exercise 3.3 Show that when the electric ﬁeld is uniform alongthe wire’s length, Eq. (5.3.5a) is equivalent to Ohm’s law, I = V/R. Solution on page 518 Exercise 3.4 In Part I we discussed the isothermal atmosphere, which is analogous to the conductingwire in that a constant force acts on the particles. Explain why a constant current of particles, proportional to the acceleration of gravity, does not arise in the isothermal atmosphere. Solution on page 518 3.1 The Drude model 469 An additional success of Drude’s model was in providingan explana- tion for the experimental law that was discovered in the middle of the 19th century by Wiedemann and Franz, relatingthe electrical conductiv- ity of metals to their thermal conductivity, ¯K (for ¯K see Part I, Sec. 3.6). Wiedemann– Franz lawAccordingto the Wiedemann–Franz law the ratio of the thermal conduc- tivity and the electrical conductivity is proportional to the temperature with a proportionality coeﬃcient that is approximately independent of the material. This law applies to a large number of metals. Several examples appear in the followingtable: Table 5.3.1. Thermal conductivity, resistivity ρ =1/σ and the proportionality constant in the Wiedemann–Franz law. Sodium and potassium are liquids at a temperature of 373 K. Li Be Na Mg Al K Cu Ag Sb Au ¯K(100 W/mK) 0.71 2.3 1.38 1.5 2.38 1.0 3.85 4.18 0.18 3.1 273 K ρ(10−8 Ωm) 8.55 2.8 4.2 3.9 2.45 6.1 1.56 1.51 39 2.04 ¯K/σT (10−8 WΩ/K 2) 2.22 2.36 2.12 2.14 2.14 2.23 2.20 2.31 2.57 2.32 ¯K(100 W/mK) 0.73 1.7 — 1.5 2.30 — 3.82 4.17 0.17 3.1 373 K ρ(10−8 Ωm) 12.4 5.3 — 5.6 3.55 — 2.24 2.13 59 2.84 ¯K/σT (10−8 WΩ/K2) 2.43 2.42 — 2.25 2.19 — 2.29 2.38 2.69 2.36 To obtain an explanation for this law Drude assumed that the thermal conductivity of a metal originates principally from the gas of free electrons which can transfer heat with greater ease than the ions which are bound to their positions. Support for this assumption is found in the large diﬀerence between the thermal conductivities of metals and insulators. Since the diﬀerence between the two types lies in the density of free electrons, which in metals is many orders of magnitude greater than in insulators, it is natural to assume that the larger thermal conductivity is due to the same phenomenon which gives rise to a higher electrical conductivity. Hence we can also calculate the thermal conductivity of a metal by the kinetic theory, as we have done in Sec. 3.6 of Part I, and use the result (1.3.51): ¯K = 1 3 n¯vℓc = 1 3 n¯v2τc , (5.3.6) where ¯v is the thermal velocity and c is the speciﬁc heat per electron. If we now divide (5.3.6) by (5.3.5b) we obtain ¯K σ = m¯v2c 3e2 . (5.3.7) So far all the arguments have been completely general, independent of the form of the velocity distribution of the electrons. If we assume, accordingto the Drude model, that the distribution is Boltzmannian, we may write 3kT for m¯v2, and instead of the speciﬁc heat per electron we 470 Ch. 3 Electrical Conductivity in Metals can use the ideal gas expression 3 2 k.Thus ¯K σ = 3k2T 2e2 , (5.3.8) and this is exactly the form of the Wiedemann–Franz law, where the proportionality constant is expressed in terms of the fundamental physical constants e and k. 3.2 A critique of the Drude model In order to estimate the extent of the Drude model’s success we must check its quantitative accord with experiment. First we confront with ex- periment the relation (5.3.8). We calculate the proportionality coeﬃcient and obtain 3k2 2e2 =1.11 × 10 −8 WΩ/K2 . (5.3.9) This is about one half of the typical value in Table 5.3.1, but it can be considered a success in light of the rough assumptions made. But what actually casts doubt on the validity of the calculation is the problem of the speciﬁc heat. In derivingEq. (5.3.8) we took 3k/2 for the speciﬁc heat per electron. In metals the number of electrons is at least equal to the number of ions. The contribution of the electrons to the speciﬁc heat is expected to be very signiﬁcant. But the experimental speciﬁc heat of solids does not surpass the Dulong–Petit value, which is 3R per mole and does not approach 4.5R per mole — the sum of the contribution of the crystal and the expected electronic contribution. In other words, free electrons do not obey the equipartition law. This fact puts in doubt the validity of our calculation, since it turns out that experimentally there is no support for the validity of the equipartition law for electrons in a metal. Another diﬃculty shows up upon a deeper examination of Ohm’s law (5.3.5). Actually we cannot calculate from ﬁrst principles the electrical conductivity and compare it to experimental results, because we do not know themean freetime, τ , which depends on the details of the micro- scopic structure of the metal. However, we can use known values of the resistivity ρ to calculate τ , or the mean free path ℓD, accordingto the Drude model: ℓD ≈ √ 3mkT ne2ρ . (5.3.10) Exercise 3.5 (a) Show that the right hand side of (5.3.10) has the dimensions of length. (b) Prove (5.3.10). Solution on page 518 3.3 The Sommerfeld model 471 Table 5.3.2. Values of ℓD for several metals at three diﬀerent temperatures. The valence v, the atomic mass A and the density d are required for the calculation. The weak temperature dependence of the density is not taken into account and the densities appearing are at room temperature. Li Be Na MgAl K Cu Ag Sb Au v 1 2 1 231 1 151 A 6.941 9.012 22.99 24.305 26.982 39.098 63.55 107.87 121.75 196.97 d(gr/cm3) 0.53 1.85 0.97 1.74 2.70 0.86 8.96 10.50 6.62 19.3 77 K ρ(10−8 Ωm) 1.04 — 0.8 0.62 0.3 1.38 0.2 0.3 8 0.5 ℓD (˚A) 44.0 — 104 39.4 38.8 115 124 120 8.03 71.3 273 K ρ(10 −8 Ωm) 8.55 2.8 4.2 3.9 2.45 6.1 1.56 1.51 39 2.04 ℓD (˚A) 10.1 5.7 37.2 11.8 8.9 49.0 29.9 44.8 0.62 33.0 373 K ρ(10 −8 Ωm) 12.4 5.3 — 5.6 3.55 — 2.24 2.13 59 2.84 ℓD (˚A) 8.1 3.6 — 9.6 7.2 — 24.4 37.1 0.48 27.7 Table 5.3.2 gives the values of the mean free paths for several metals accordingto the Drude model, using Eq. (5.3.10). Exercise 3.6 Obtain the values of ℓD that appear in Table 5.3.2. Solution on page 519 From Table 5.3.2 it appears that around room temperature the values of the mean free path are reasonable, since the interatomic separation in all the metals listed in the table is 3–5 ˚A. A mean free path of this magnitude corresponds well to the assumption that the resistivity originates from electrons collidingwith the ions of the crystal. However, the values of ℓD at low temperature, 77 K, pose a problem. The interatomic distances are almost unaﬀected by the decrease in temperature, but the mean free path is 10–20 times larger. This ratio of the two quantities raises the question: How can an electron pass without hindrance over 10–20 ions in the crystal? These two diﬃculties, the problem of the speciﬁc heat and the problem of the mean free path, alongwith other diﬃculties which we have not mentioned here, remained unresolved for 25 years until the appearance of quantum theory and the discovery of the Pauli principle and the ensuing conclusions regarding the statistical properties of electrons. We discuss these in the comingsections. 3.3 The Sommerfeld model The discovery of the Pauli principle and the Fermi–Dirac distribution, given in Eq. (5.2.12a), provided Sommerfeld with the tools for explaining the electrical conductivity as well as the thermal conductivity of metals which were left unexplained within the framework of classical physics. Sommerfeld replaced the Maxwell–Boltzmann distribution of the Drude 472 Ch. 3 Electrical Conductivity in Metals model by a velocity distribution of electrons that obey Fermi–Dirac statis- tics. This is similar to what Planck had done, replacingthe classical dis- tribution function with his own to explain the properties of black body radiation. We start by calculatingthe thermodynamic potential Ω for electrons in a metal. We already have the general expression for this potential as a sum over single particle states, i.e. Eq. (5.2.10a), and what remains is to identify the single particle states and to calculate the sum. The single par- ticle states are states of free electrons conﬁned to move inside the metal. Their energy is p2/2m. They are quantum particles, so that in principle we should perform the summation over all the quantum states of a parti- cle in a three-dimensional box, as in Sec. 4.4 of Part III (see Sec. 3.2 of Part IV as well). For the temperatures of interest, in a macroscopic vol- ume V , the summation can be replaced by an integration. Schematically we make the replacement ∑ k → V ∫ d3p h3 , (5.3.11) where p is the de Broglie momentum. But we should keep in mind that the electron has spin 1 2 , and thus a complete speciﬁcation of its state must also include the spin: + 1 2 or − 1 2 . Since to any p, specifyinga single particle state, correspond two spin states, and since the single particle energy is independent of the spin direction, the sum over the spins contributes an overall factor of 2. The thermodynamic potential is, therefore, Ω= −2kT V ∫ ln { 1+exp [ β ( µ − p2 2m )]} d3p h3 , (5.3.12) and carryingout the integration over all the directions of momentum we obtain Ω= − 8πV kT h3 ∫ ∞ 0 ln { 1+exp [ β ( µ − p2 2m )]} p2dp . (5.3.13) From this expression for the thermodynamic potential we can obtain the average number of electrons using Eq. (5.1.11): N = 8πV h3 ∫ ∞ 0 p2dp exp [β ( p2 2m − µ )] +1 . (5.3.14) The same result could have been obtained from Eq. (5.2.10a). 3.3 The Sommerfeld model 473 In principle, given the expression for Ω(T, V, µ), Eq. (5.3.13), the ther- modynamic properties of the system follow by applyingEqs. (5.1.10). In practice, things are more complicated, since usually it is the number (or density) of the electrons and not the chemical potential that is the con- trolled variable. Hence we must re-express the chemical potential in terms of the number of particles (as well as the temperature and the volume), and this is done usingEq. (5.3.14), which expresses this relation implic- itly. The integral must be calculated as best we can. Then inverting the resultingrelation N (T, V, µ), or better still N/V = n(T, µ), one obtains µ(T, n), which replaces the dependence on µ by a dependence on n in all the thermodynamic quantities. The two-dimensional analog of Eq. (5.3.14) is an integral which can be calculated explicitly, and it is possible to ﬁnd the exact relationship between µ and n.See Self- Assessment Exercise 3. Next we calculate the probability density function in velocity space for the electrons. It is given by f (v)d 3v = 2m3 nh3 1 exp [ β ( mv2 2 − µ)] +1 d 3v, (5.3.15) where n is the number of electrons per unit volume. This function is the Fermi–Dirac analogof the Maxwell–Boltzmann velocity distribution function (1.1.49). Exercise 3.7 (a) Derive (5.3.15). (b) Is f (v) normalized? Explain. Solution on page 520 Usingthe Fermi–Dirac velocity distribution function we can calculate the average energy of an electron in the metal: ⟨ϵ⟩ = ∫ m 2 v2f (v)dτ = 4πm4 nh3 ∫ ∞ 0 v4dv exp [ β ( mv2 2 − µ )] +1 . (5.3.16) An alternative way of obtaining the same result is found in Self-Assessment Exercise 2(b). Equation (5.3.16) may also be written as an integral over all the ener- gies after changing variables to ϵ = 1 2 mv2, and then deﬁningan energy distribution function: fϵ(ϵ)= 4π(2m)3/2ϵ1/2 nh3 · 1 eβ(ϵ−µ) +1 , (5.3.17a) 474 Ch. 3 Electrical Conductivity in Metals so that ⟨ϵ⟩ = ∫ ∞ 0 ϵfϵ(ϵ)dϵ . (5.3.17b) Exercise 3.8 (a) Prove (5.3.17). (b) Verify that fϵ(ϵ) is normalized. Solution on page 474 As implied by the form in which (5.3.17a) is written, the energy dis- tribution function of the electrons can be interpreted as a product of two factors: The ﬁrst is called the degeneracy, or the density of states per unit energy. It is the number of quantum states in the energy range between ϵ and ϵ + dϵ: g(ϵ)= 4πV (2m)3/2ϵ1/2 h3 . (5.3.18) This factor is quite general, and is independent of the statistical nature of the particles. The second is the average number of electrons with energy ϵ as in Eq. (5.2.12a), and we write it once more, now without the braces, nϵ(ϵ)= {exp[β(ϵ − µ)+1]} −1 . (5.3.19) The information that the electrons are fermions is contained in (5.3.19). In order to transform the electron numbers into probabilities, ⟨nϵ⟩ must further be divided by N . 3.4 Electrons at high and low temperatures To proceed we calculate the various integrals approximately. In each range of parameters we introduce approximations valid for that range. This is how we proceeded also in calculatingthe internal partition function of a diatomic gas (Secs. 1.4 and 1.7 of Part IV). We will study the behavior of the electron gas at high temperatures and at low temperatures. Hence we need to know how the distribution functions of the velocities or of the energies behave in these limits. But here a diﬃculty arises: The dependence on the temperature (or on β) in (5.3.19) is more complicated than may seem. The chemical potential µ, once replaced by the density n, becomes dependent on the temperature (as well as on n). To clarify how the chemical potential depends on the temperature, we use Eq. (5.3.14). Dividingboth sides by V and changing variables to 3.4 Electrons at high and low temperatures 475 ϵ = p2/2m we have for the density n = 4π(2m)3/2 h3 ∫ ∞ 0 ϵ1/2dϵ eβ(ϵ−µ) +1 . (5.3.20) In the limit in which the electron density is very low, i.e. n → 0, the value of the integral must become very small. The right hand side is a monotonic increasingfunction of βµ, since the integrand is at every ε. Hence, the integral decreases as βµ decreases, and for it to become very small, we must have βµ →−∞. Consequently, for low electron density, it is possible to approximate nϵ(ϵ) by the Boltzmann factor: nϵ(ϵ)= Ce −βϵ,C = e βµ , (5.3.21) where we have dropped the braces again. The same classical behavior is obtained also in the high temperature limit. If as β → 0, βµ approaches a ﬁnite limit, the integrand in (5.3.20) becomes independent of ϵ and the integral diverges. For a given value of n this leads to a contradiction, unless, again, βµ →−∞ in the limit of high T . One arrives again at the classical Boltzmann distribution. Observe that βµ →−∞ as T →∞ is indeed the property of the chemical potential of an ideal gas — Eq. (3.5.9). At low temperatures the behavior is quite diﬀerent. When T → 0, or β →∞,the factor eβ(ϵ−µ) depends on the energy ϵ in the following manner: If ϵ< µ the exponent is negative, and eβ(ϵ−µ) → 0. If ϵ> µ the exponent is positive, and eβ(ϵ−µ) →∞. Thus, in the limit T → 0, nϵ(ϵ)= { 1,ϵ < µ , 0,ϵ > µ . (5.3.22) In this limit the integral in Eq. (5.3.20) is elementary, and the following relation is obtained between the chemical potential at absolute zero, µ0, and the density of electrons: µ0 = h2 2m ( 3n 8π )2/3 ≡ ϵF . (5.3.23) The chemical potential at absolute zero is called the Fermi energy and is denoted by ϵF . Fermi energy Exercise 3.9 Derive (5.3.23). Solution on page 521 476 Ch. 3 Electrical Conductivity in Metals The meaningof ϵF is clear from Eq. (5.3.22). Even at absolute zero, the electrons must have kinetic energy. This is the crucial diﬀerence with respect to the Maxwell–Boltzmann distribution for which, as the tem- perature decreases, the number of low energy particles increases and at T = 0 all the particles are concentrated at the ground level ϵ =0. This can also be deduced from the equipartition law: ⟨ϵ⟩∼ kT . The reason for the diﬀerent behavior of the electrons is, of course, the Pauli princi- ple, which forbids the accumulation of many electrons in the same state. Hence the electrons have no alternative but to stack one above the other, in energy, and to ﬁll out all the allowed low energy states. The last among them, with the highest energy, are at ϵF . Such a state of a gas is called adegenerate Fermi gas degenerate Fermi gas. Thus, we could have obtained the Fermi energy simply as an answer to the followingquestion: What energy will be reached by N electrons occupyingthe N lowest single particle states? Exercise 3.10 Show that the N electrons ﬁll out in momentum space a sphere of radius pF which satisﬁes p2 F 2m = ϵF . Solution on page 521 The surface of the sphere described in Exercise 3.10 is called theFermi sphere Fermi momentum Fermi velocity Fermi sphere and pF is called the Fermi momentum. Hence we will say that at T → 0 the electrons ﬁll out the Fermi sphere, i.e. all the states up to the Fermi momentum or up to the Fermi energy. The “top” electrons, those with Fermi energy, move at the Fermi velocity, vF =(pF /m). In order to get an idea of the orders of magnitude involved, we present in Table 5.3.3 the values of the Fermi energy and the Fermi velocity of several metals. Table 5.3.3. Values of the Fermi energy, Fermi velocity and Fermi temperature for several metals. For the last row, the Fermi wavelength, see Exercise 3.18. Li Be Na Mg Al K Cu Ag Sb Au ϵF (eV) 4.7 14.3 3.2 7.1 11.7 2.1 7.0 5.5 10.9 5.5 vF (10 6 ms −1) 1.3 2.25 1.1 1.6 2.0 0.85 1.6 1.4 2.0 1.4 TF (10 4 K) 5.5 16.6 3.8 8.2 13.6 2.5 8.2 6.4 12.7 6.4 λF (˚A) 3.4 Electrons at high and low temperatures 477 Exercise 3.11 Obtain some of the values of ϵF and vF that appear in Table 5.3.3. Solution on page 522 Note the energy values reached by the electrons at temperature T =0. For electrons in a classical ideal gas to attain kinetic energies of this order, their temperature must obey kTF = ϵF . (5.3.24) This temperature, which is diﬀerent for each material, is called the Fermi Fermi temperaturetemperature and appears in the third row of Table 5.3.3. It reaches tens of thousands of degrees. As we shall see later on, the Fermi temperature determines the scale for high versus low temperatures of electrons. For T ≫ TF the electrons behave as a classical gas, whereas for T ≪ TF the system becomes degenerate. Ordinary metals melt way before reaching TF . Exercise 3.12 Show that the average kinetic energy of an electron at T =0 is 3 5 ϵF . Solution on page 523 The Fermi energy plays a double role: One as the maximal (kinetic) energy state occupied by electrons at T = 0; the other is the value of the chemical potential at T = 0. The relation between the two is clear. The chemical potential describes the increase in the system’s free energy at constant volume and temperature upon addition of a single particle. At T = 0 the free energy is equal to the internal energy, and hence the chemical potential is the excess internal energy due to the addition of the particle. Since at T = 0 all the levels below ϵF are occupied, a particle that is added to the system must have energy ϵF . This is therefore also the value of the chemical potential at T =0. Exercise 3.13 (a) How much energy is added to an electron gas at T = 0 if an electron with kinetic energy ϵ larger than ϵF is added? (b) How much energy does an electron gas at T = 0 lose if we remove from it an electron with kinetic energy ϵ less than ϵF ? Solution on page 523 We have found that as T → 0 the chemical potential tends to a pos- itive constant, ϵF , and that at T →∞ it decreases to −∞. Hence it is 478 Ch. 3 Electrical Conductivity in Metals reasonable to expect that µ decreases as a function of temperature. We will verify this in the next section. 3.5 Metals at room temperature Now that we have found that an electron gas behaves at high tempera- tures as a classical Boltzmann gas and at low temperatures as a degenerate Fermi gas, we will apply it to realistic systems, i.e. to metals. We ﬁrst clarify whether one of the two limits is valid for metals at room tempera- ture. Actually, the diﬃculties of the Drude model, discussed in Sec. 3.2, indicate that an electron gas does not behave as a classical gas already at room temperature. We will thus check at what temperature does the degenerate gas approximation become valid; in particular, up to what temperature does µ = ϵF still hold approximately. To this end we return to Eq. (5.3.20), which implicitly determines the dependence of the chemical potential upon T and n. In terms of the Fermi energy we rewrite Eq. (5.3.20) in the form 2 3 ϵ 3/2 F = ∫ ∞ 0 ϵ1/2dϵ eβ(ϵ−µ) +1 (5.3.25) (see also Exercise 3.12). We change the integration variable by ϵ = xϵF (x is a dimensionless variable that measures the energy in units of ϵF ). Equation (5.3.25) becomes 2 3 = ∫ ∞ 0 x1/2dx exp [ ϵF kT (x − µ ϵF )] +1 . (5.3.26) From Eq. (5.3.23) we know that ϵF depends only on the density and not on the temperature. Hence, in the low temperature limit, kT ϵF ≪ 1 , (5.3.27a) or, in terms of the Fermi temperature, (5.3.24), T ≪ TF . (5.3.27b) As longas (5.3.27b) holds, we see that for x satisfying x>µ/ϵF the integrand vanishes and for x<µ/ϵF the exponential term vanishes and the denominator is approximately 1. Hence at temperatures that are much lower than the Fermi temperature it is possible to write 2 3 = ∫ µ/ϵF 0 x 1/2dx , (5.3.28) which leads to µ = ϵF . We found, therefore, that the Fermi temperature does indeed set the scale with respect to which the temperature T is considered low. Because the Fermi temperature of metals is well above 3.6 Thermodynamics of the Sommerfeld model 479 ➤➤ 0 0 0.2 0.4 0.6 0.8 1.0 1.2 1.4 1.6 0.2 0.4 0.6 0.8 1.0 nε (ε) ε/εF 2TF TF 0.5TF 0.2TF 0.1TF 0.01TF Fig. 5.3.2. The Fermi–Dirac occupation function at diﬀerent temperatures as a function of the dimensionless variable ϵ/ϵF . 104 K (see Table 5.3.3), it is possible to treat an electron gas at room temperature, or even well above it, as a degenerate Fermi gas. To illustrate the situation, we depict in Fig. 5.3.2 the Fermi–Dirac occupation function nϵ(ϵ)atdiﬀerenttemperatures. The graphs take into account the temperature dependence of µ, implicit in Eq. (5.3.20). The ﬁgure makes it clear that at temperatures up to several hundredths of TF the degenerate gas approximation is excellent, since the curve with T =0.01TF is very close to the step function. From this ﬁgure it is also possible to learn about the temperature dependence of the chemical potential. From Eq. (5.3.19) we see that at ϵ = µ, nϵ = 1 2 . Thus, the chemical potential, at any temperature, can be read from the corresponding graph as the energy for which nϵ = 1 2 .Since the intersection of the graph with the line nϵ = 1 2 moves to the left as the temperature increases, we conclude that the chemical potential decreases with temperature. We already anticipated such a behavior at the end of the precedingsection. Exercise 3.14 Calculate the temperature at which the chemical potential of an electron gas vanishes. Solution on page 523 3.6 Thermodynamics of the Sommerfeld model We ﬁrst apply what we have learned about the properties of the Fermi- Dirac distribution to the calculation of the speciﬁc heat: While the Boltz- mann distribution predicts that each electron will contribute 3 2 kT to the 480 Ch. 3 Electrical Conductivity in Metals speciﬁc heat of the metal, there is no experimental evidence for such a con- tribution; actually the Debye model explains the speciﬁc heat of metals very nicely, based on the vibrations of the ions alone. We thus calculate the speciﬁc heat of an electron gas with the hope that its contribution at room temperature be indeed negligible. The speciﬁc heat, CV , of an electron gas is obtained by diﬀerentiating E(T, V, N ) with respect to T . The total energy of the gas is N ⟨ϵ⟩,where ⟨ϵ⟩ is given by Eq. (5.3.17b). Actually we will also need averages of powers of the energy higher than 1, and thus we write ⟨ϵ l⟩ = 3 2ϵ 3/2 F ∫ ∞ 0 ϵl+1/2dϵ eβ(ϵ−µ) +1 , (5.3.29) where we have used the results of Exercise 3.12 to simplify the form of the energy distribution function. The integral on the right hand side cannot be calculated explicitly. But, fortunately, the temperature range of interest will be always much smaller than the Fermi temperature, and hence we may expand the integral in Eq. (5.3.29) in powers of the temperature. Such an expansion is made possible by the fact that at low temperatures the Fermi–Dirac function is very similar to a step function (see Fig. 5.3.2) so that the main contribution to the integral is ∫ µ 0 ϵ l+1/2dϵ = 2 2l +3 µ l+3/2 . This is the lowest order term in a series and the corrections will contain higher powers of the temperature. The ﬁrst two terms will suﬃce for our needs: ⟨ϵ l⟩≈ 3 2l +3 µl+3/2 ϵ 3/2 F + ( l + 1 2 ) π2 4 · µl−1/2(kT )2 ϵ 3/2 F . (5.3.30) The proof of (5.3.30) is lengthy. It is contained in the solution to the next exercise and may be skipped altogether on ﬁrst reading. Exercise 3.15 Derive Eq. (5.3.30). Hint: Integrate by parts, and note that the derivative of the Fermi–Dirac function diﬀers signiﬁcantly from zero only in a narrow range around ϵ = µ. Solution on page 524 3.6 Thermodynamics of the Sommerfeld model 481 We now proceed with the calculation of the speciﬁc heat. We use Eq. (5.3.30) with l = 1. But the temperature derivative of E or ⟨ϵ⟩ must be calculated at constant N and V rather than constant µ and V ,and thus we have to express µ in terms of N (as well as T and V ). We do this usingEq. (5.3.30) with l = 0, which is also equivalent to the normalization condition for fϵ resultingfrom (5.3.20) or (5.3.25). For l = 0, to second order in T ,we have 1 ≈ µ3/2 ϵ 3/2 F + π2 8 (kT )2 ϵ 3/2 F µ1/2 . (5.3.31) This is an equation for µ in terms of the electron density contained in ϵF . It does not have a simple solution, but since µ is very close to ϵF we can replace µ1/2 by ϵ 1/2 F in the second term on the right hand side, which is already small due to the explicit factor T 2. Hence we ﬁnd an expression for the dependence of the chemical potential on the temperature up to the second order: µ(T, V, N ) ≈ ϵF [ 1 − π2 12 ( kT ϵF )2] . (5.3.32) Note that µ decreases with T ,asexpected. Usingthis expression, we calculate the temperature dependence of the average energy up to second order in T .It reads ⟨ϵ⟩ = 3 5 ϵF [ 1+ 5π2 12 ( kT ϵF )2] . (5.3.33) As T → 0 the result of Exercise 3.12 is obtained. Moreover, unlike the ideal gas, the average energy depends on the density. Exercise 3.16 (a) Show that (5.3.32) is a solution of (5.3.31) to order T 2. (b) Derive (5.3.33). Solution on page 526 We see, therefore, that the energy of an electron gas increases quadrat- ically with temperature. By diﬀerentiating(5.3.33) with respect to T we ﬁnd that the speciﬁc heat at low temperatures is linear in the temperature: CV ≈ π2 2 Nk T TF . (5.3.34) As already mentioned, this expression is valid also at room temperature, since the typical values of the Fermi temperature are of order 104 K. 482 Ch. 3 Electrical Conductivity in Metals Hence, the contribution of the electrons to the speciﬁc heat of metals at room temperature is not 3 2 k per electron, but about 0.05k per electron, which is the behavior we were hopingto ﬁnd. It should further be noted that the contribution of the electrons to the speciﬁc heat of metals is not negligible at every temperature. As we saw in Part IV, the contribution of the phonons to the speciﬁc heat at low temperatures is proportional to T 3 [Eq. (4.3.18)], and hence at low enough temperatures the contribution of the phonons becomes much smaller than that of the electrons, and the speciﬁc heat will behave accordingto Eq. (5.3.34). Such a behavior has in fact been observed experimentally and provided additional support for the Sommerfeld model. Exercise 3.17 Lithium has a Debye temperature of 400 K. Find at what temperature the phonon and electron contributions to the speciﬁc heat are equal. Solution on page 527 We now return to the Wiedemann–Franz law to test the implications of the Sommerfeld model for the ratio of the thermal conductivity to the electrical conductivity. The result obtained from the Drude model for this ratio was reasonable and we should hope that the result of the Sommerfeld model for the speciﬁc heat would not damage this agreement. The thermal conductivity of the metal is given by Eq. (5.3.6). How- ever, we have to reinterpret the quantities appearingin it. c is the spe- ciﬁc heat per electron, whose correct value is given by Eq. (5.3.34). τ is the mean free time, and is related to the electrical conductivity via Eq. (5.3.5b). We are left with the average velocity ¯v.This velocity can- not be the average velocity of the Maxwell–Boltzmann distribution, which at room temperature is of the order 105 ms−1, but a velocity of the order of the Fermi velocity, which is 10 times larger. In the ratio of the thermal conductivity to the electrical conductivity, given in Eq. (5.3.7), the spe- ciﬁc heat per electron decreases by a factor of about 30, and the average velocity increases by a factor of about 10 and its square by a factor of 100. These two changes, which more or less cancel each other out, leave the Wiedemann–Franz law valid even though the pictures of the electrical and thermal conductivities have changed drastically. To perform a quantitative study of the ratio ¯K/σ one should clarify which velocity to substitute for ¯v. We note that not all free electrons in the metal can participate in the thermal conduction but only those with energy very near the Fermi energy. Electrons with energy signiﬁcantly smaller than the Fermi energy (0.5ϵF , for instance) cannot change their kinetic energy by collisions, since the states are occupied up to the Fermi energy. The Pauli principle implies that for an electron to change its 3.6 Thermodynamics of the Sommerfeld model 483 momentum it must ﬁnd an empty state to go into. Thus to change its momentum, the deep electron must “jump,” as a result of a collision, to the neighborhood of the Fermi energy. For the latter to occur it has to collide with an electron with kinetic energy of at least 1.5ϵF , but such an electron is very rare, as follows from Fig. 5.3.2, for example. The “eﬀective” electrons that can absorb and transfer energy are, therefore, those found near the Fermi energy, at a range of energies of width kT . Hence, the electrons that participate in the thermal conduc- tion, which involves the transfer of kinetic energy, are with energies very near to the Fermi energy. They all have the Fermi velocity, namely ¯v = vF . If we now substitute this into (5.3.7) alongwith (5.3.34), we obtain ¯K σ = mv2 F 3e2 · π2 2 · kT TF = π2k2 3e2 T, (5.3.35) and this is once more the Wiedemann–Franz law with a diﬀerent coeﬃcient. Note that the temperature dependence has remained the same in spite of all the transformations. But there is a diﬀerence: In the Drude model the linear dependence originates from the fact that the average velocity is proportional to T 1/2; in contrast, in the Sommerfeld model the average velocity does not depend on the temperature (for T/TF ≪ 1) but as a compensation the speciﬁc heat is proportional to the temperature! When we calculate the coeﬃcient, we obtain π2k2 3e2 =2.44 × 10 −8 WΩ/K2 , (5.3.36) which agrees well with the experimental values that appear in Table 5.3.1. Another diﬃculty of the Drude model was the problem of the mean free path, which attains puzzlingvalues of 10–20 interatomic distances. We thus check what values are obtained in the Sommerfeld model. To this end we write the relation between the mean free path and the resistivity in theform (seeExercise3.5) ℓ = m¯v ne2ρ , (5.3.37) where ¯v is the average velocity of the electrons. The Drude model assumes that ¯v is of order of the thermal velocity of a Boltzmann electron gas, which at room temperature is of order 105 ms−1. In the Sommerfeld model we use the Fermi–Dirac distribution to obtain ¯v, leadingto a velocity of the order of the Fermi velocity. Since the Fermi velocity is of order 106 ms−1, the mean free path becomes much larger. Already at room temperature the mean free path is 10 times larger than 484 Ch. 3 Electrical Conductivity in Metals the values in the Drude model, and at lower temperatures it can reach 1000 ˚A. It appears, therefore, that the problem of the mean free path, which in the Drude model was limited to fairly low temperatures (see Table 5.3.2), worsened in the Sommerfeld model, in which it is present already at room temperature and above. To understand how it is possible that the elec- trons in a metal almost do not feel the existence of the ions, we ﬁrst note that so far we have not taken into account the fact that the electrons have wavelike properties. The de Broglie wavelength of a typical electron in the metal, namely the wavelength of an electron with Fermi energy, called the Fermi wavelength, λF , is about 2–10 ˚A. See Exercise 3.18.Fermi wavelength Exercise 3.18 Insert the values of λF missingfrom Table 5.3.3. Solution on page 527 This value of the Fermi wavelength implies that the electrons in the metal cannot collide with the ions as if they (the electrons) were pointlike particles. Moreover, it seems that the fact that the wavelength is some 10 times larger than the atomic sizes, supports the intuition that the electrons do not “see” the ions, just as waves with wavelength λ are of no use for observingobjects of a size less than λ. At this point a consistent quantum-mechanical treatment of the dy- namics of the electrons that are movingin a potential due to the periodic ionic lattice of the metal is called for. Here we leave this subject. We shall only remark that a quantum analysis of the motion of the electrons in a periodic potential was actually carried out in the 1930’s by F. Bloch. Surprisingly, the result of that analysis is that the electrical resistivity of a perfectly periodic crystal is zero! Hence the origin of the electrical resis- tivity cannot be the collisions between the electrons and the ions and the mean free path that we calculated does not correspond to the scattering of the electrons by the ions. It turns out, however, that other scattering mechanisms exist: electrons are scattered by the deviations from perfect periodicity of the crystal. Such deviations exist in any real metal in the form of phonons (at ﬁnite temperature), missingions, impurities of for- eign materials and other defects. It is the scattering oﬀ such defects that gives rise to electrical resistivity. Chapter 4 Boson Gas 4.1 Bose–Einstein distribution We turn to the properties of systems of bosons, whose (average) number in a state with energy ϵ is given by the Bose–Einstein distribution: Bose– Einstein distribution⟨nϵ(ϵ)⟩ = {exp[β(ϵ − µ)] − 1} −1 . (5.4.1) Actually we have already seen in Parts III and IV that it is possible to treat the phonons in a crystal and the photons of a black body as bosons. Since phonons and photons are created and annihilated freely, their chemical potential is zero. In contrast, a gas of identical atoms with integral spin is a system of bosons with a given number of particles, so its chemical potential will not be zero. We discuss, therefore, a gas of N bosons in a container of volume V at temperature T . As we saw in Chaps. 1 and 2, it is best to use the grand canonical ensemble in which the chemical potential µ is a controlled variable instead of the number of particles, as a technically natural way of dealingwith constraints imposed by quantum statistics. The thermodynamic potential for a gas of bosons is given by Eq. (5.2.10b) as a sum over single particle states and may be written as an integral over all possible particle momenta, just as we did for the fermion gas, Eqs. (5.3.12) and (5.3.13). If we restrict our discussion to bosons with spin 0, we obtain the Bose–Einstein analogof Eq. (5.3.13) as Ω= 4πV kT h3 ∫ ∞ 0 ln { 1 − exp [ β ( µ − p2 2m )]} p2dp , (5.4.2) and diﬀerentiatingthis with respect to µ we obtain the average number of bosons: N = 4πV h3 ∫ ∞ 0 p2dp exp [β ( p2 2m − µ)] − 1 , (5.4.3) as a function of T, V and µ. For bosons with nonzero spin J, these expres- sions have to be multiplied by 2J + 1. As for the fermion gas, Eq. (5.4.3) 485 486 Ch. 4 Boson Gas is used to express µ in terms of N , or better still, in terms of the average density n. We write the energy distribution function in the form fϵ(ϵ)= 1 N g(ϵ)nϵ(ϵ) , (5.4.4) where nϵ is given now by (5.4.1) (without the braces) and g(ϵ) describes the number of quantum states in the range between ϵ and ϵ + dϵ: g(ϵ)= 2πV (2m)3/2ϵ1/2 h3 = V ¯g(ϵ) , (5.4.5) where ¯g is introduced to make the volume dependence explicit. Note that between this function and the density of electronic states [Eq. (5.3.18)] there is a factor of 2 originating in the spin. The derivation of these expressions is the same as for fermions. The average density takes on a form analogous to Eq. (5.3.20): n = N V = 2π(2m)3/2 h3 ∫ ∞ 0 ϵ1/2dϵ eβ(ϵ−µ) − 1 , (5.4.6) and just as for fermions, the Boltzmann limit is obtained at low densities (n → 0) or high temperatures (T →∞) and in these limits βµ →−∞. 4.2 Chemical potential at low temperatures We are interested in the behavior of the boson gas at low temperatures. Since the Pauli principle does not apply to bosons, they tend to concen- trate at the lowest energy levels and only the thermal ﬂuctuations prevent them from accumulating all in the ground level (see Fig. 5.2.1). At low temperatures, where the thermal ﬂuctuations are small, we may expect a concentration of a macroscopic number of bosons in the ground level ϵ = 0. Substitutinginto the Bose–Einstein distribution Eq. (5.4.1), ϵ =0, we ﬁnd that at low temperatures, if a number of the order of N bosons are in the ground level, then N ≈ 1 e−βµ − 1 , (5.4.7) or µ ≈ −kT N . (5.4.8) Exercise 4.1 Prove (5.4.8). What are typical values of the chemical potential at low temperatures? Solution on page 527 4.2 Chemical potential at low temperatures 487 At ﬁrst sight such a behavior is quite reasonable, because it is con- sistent with the tendency of the chemical potential to decrease at high temperatures and is also consistent with the requirement that the chem- ical potential should be negative. However, a more discerning inspection reveals that all is not well with our understandingof the Bose–Einstein distribution: The occupation of the the ground level, which at low temper- atures is expected to be very large, does not appear at all in the expression for the density of particles, Eq. (5.4.6). This equation gives the density of particles as a sum of contributions from all energies. But the contribu- tion of the ground level, namely the region near ϵ =0, to the integral is zero. This diﬃculty leads to an apparent paradox, which is a consequence of the relation between the density of particles and the chemical potential, Eq. (5.4.6). The integral on the right hand side is an increasing function of µ, since the integrand at every value of ϵ is an increasingfunction of µ. But the integral cannot become larger than its value at µ =0, since µ cannot become positive. Consequently, the right hand side of Eq. (5.4.6) has an upper bound, which is its value at µ = 0. This would imply that the density, n, at a given temperature, of our noninteracting boson gas cannot rise above a certain maximum value, determined by the maximum of the right hand side. For densities above that value, there is no solution for µ.This value is n∗ = 2.612(2πmkT )3/2 h3 . (5.4.9) It corresponds to a maximal number of particles, in a given volume V , N∗ = Vn∗. Note that the maximal density decreases when T decreases. Exercise 4.2 (a) Show that n is an increasingfunction of µ. (b) Derive Eq. (5.4.9). Solution on page 528 This conclusion is, of course, unreasonable, since it is impossible for there to be a restriction on the number of noninteractingbosons in a given volume. Even fermions which obey the Pauli principle do not resist the addition of fermions; they only force the “new” fermions to occupy higher energy levels. Supposing that the system is prepared at a density and temperature for which there exists a solution for µ,as T is lowered the solution disappears. Moreover, at T = 0 the equation will allow only zero density, which is clearly absurd. What went wrong? 488 Ch. 4 Boson Gas 4.3 Bose–Einstein condensation In order to clarify the reason for the inconsistency we return to basics: The calculation of the thermodynamic potential Ω and its derivatives. Equations (5.4.2) and (5.4.5) were obtained from (5.2.10b) by replacing the summation over the discrete quantum states k by an integration over a continuous momentum. But in doingso we lost the contribution of the ground level, just because g(0) = 0. If the temperature is not too low (or the density not too high) the occupation of the ground level does not diﬀer greatly from that of the other levels. In such conditions, each of the terms in the sum (5.2.10b) or (5.2.11b) is of order 1, while the sums are at least of order N . Hence the error introduced in neglecting the ground level is insigniﬁcant. But at low temperatures the chemical potential tends to zero as 1/N , Eq. (5.4.8), and the term correspondingto the ground level in the various sums must be examined more closely. In the sum for Ω, Eq. (5.2.10b), this term is Ω0 = kT ln(1 − e βµ) ≈ kT ln(1 − e −a/N ) ≈ kT ln(a/N ) , where we wrote [Eq. (5.4.8)] βµ ≈−a/N with a of order 1. This term can still be neglected, since ln N is negligible compared to N as N →∞.In con- trast, at low T , the ground level term in the sum for N in Eq. (5.2.11b) is N0 = 1 e−βµ − 1 ≈ 1 ea/N − 1 ≈ N a . This term is of the same order of magnitude as the entire sum, despite the fact that it originates from the (negligible) ground level term in Ω. Neglecting it leads to the contradiction we encountered. Thus we split the expression for Ω into two parts: Ω=Ω0 + kT V ∫ ∞ 0 ¯g(ϵ)ln(1 − e β(µ−ϵ))dϵ , (5.4.10) where ¯g [Eq. (5.4.5)] has been introduced to make the extensive character of the second term explicit. By the same reasoningwe rewrite Eq. (5.4.3), divided by N as n = n0 + ∫ ∞ 0 ¯g(ϵ)dϵ eβ(µ−ϵ) − 1 , (5.4.11a) with n0 = 1 V 1 e−βµ − 1 . (5.4.11b) Here the role of ¯g in the second term of (5.4.11a) is to render it of order 1 (independent of the volume), as the ﬁrst term. 4.3 Bose–Einstein condensation 489 As longas the density n is low compared to n∗ (or the temperature high enough), µ is not very small, and the density of particles in the ground level, n0, is negligible compared to the total density n. n is then essentially due to the second term of (5.4.10), which we may designate by ne. The addition of bosons causes an increase in the chemical potential, which becomes less negative and at the same time the integral (i.e. ne) tends to its maximal value n∗.When n becomes larger than n∗,there is no more room in the excited states and the remainingbosons occupy the ground level. n∗ is thus the density of bosons occupyingthe excited states when µ =0, when also ne = n∗. The fact that all the additional bosons occupy the ground level is a reﬂection of the vanishing of the chemical potential: The addition of a particle does not add energy to the system. A boson gas in such a state is called a degenerate Bose gas,and the degenerate Bose gasphenomenon of the aggregation of bosons in the ground level is called Bose–Einstein condensation. Note the contrast with the degenerate Fermi gas in which any additional particle piles up at the top of the distribution. Bose– Einstein condensation Conversely, in a degenerate Bose gas any additional particle goes straight to the bottom. The same phenomenon occurs while a Bose gas is cooled: At a suﬃ- ciently high temperature the overwhelming majority of bosons occupy the excited levels and only a negligible minority occupy the ground level. A decrease in temperature (at constant N , V ) causes the chemical potential to adjust itself and to increase (to become less negative). Since the chem- ical potential is bounded by zero, there appears a critical temperature Tc, which is the temperature at which the chemical potential (ﬁrst) vanishes. In order to ﬁnd this temperature we can use Eq. (5.4.9) with n∗ = n, which yields Tc = h2 2πmk ( n 2.612 )2/3 . (5.4.12) Exercise 4.3 (a) Show that the chemical potential increases as the temperature de- creases, namely that µ increases with β. (b) Obtain Eq. (5.4.12). (c) Show that the maximal density of particles occupyingthe excited states can be written in the form n∗ = n ( T Tc )3/2 . (d) Explain the relation between ne and n∗ when T< Tc and when T> Tc. Solution on page 529 490 Ch. 4 Boson Gas Any further coolingbelow Tc leaves the chemical potential at µ =0. As implied by Eq. (5.4.9), or by Exercise 4.3, the density of particles occu- pyingthe excited states decreases with decreasingtemperature. Because the number of particles is constant, the diﬀerence is concentrated in the ground level, and as the temperature decreases, the density of bosons in the ground level n0 increases: n0 = n − n∗ = n [ 1 − ( T Tc )3/2] . (5.4.13) Figure 5.4.1 illustrates the temperature dependence of n0 and ne.At temperatures T< Tc Bose–Einstein condensation takes place. 0 0 1.0 1.0 ➤➤ ne (T)/n (T/TC ) n0 (T)/n Fig. 5.4.1. The density of bosons in the ground state n0, and the density in the excited states ne as a function of temperature. 4.4 Superﬂuidity After havingfound that an ideal boson gas behaves at low temperatures very diﬀerently from a Boltzmann gas, the following question arises: In what physical conditions does this behavior manifest itself? The ﬁrst quantity we consider is the critical temperature, Tc.In order to obtain an estimate of Tc we calculate the critical temperature of 1022 atoms in a volume of 1 cm3. Assumingthat the mass is that of a hydrogen atom, 1.7 × 10−24 gr, we obtain a critical temperature of 7 K. For heavier atoms we obtain even lower critical temperatures. This may seem a very disappointingresult, because at such low tem- peratures almost all substances are already either solid or liquid (at at- mospheric pressure). The lowest freezingpoints are of nitrogen, which freezes at 63 K; neon, at 25 K; and hydrogen, at 14 K. Helium (He 4)is exceptional, in that it liqueﬁes at 4.2 K and does not freeze even at T =0. This has delayed the discovery of superﬂuidity in regular gases until very recently. Nevertheless, we may place some hope in liquid helium, or speciﬁcally in He4, whose atoms are bosons (the atoms of He 3 are fermions). The 4.4 Superﬂuidity 491 fact that liquid He4 does not freeze even at the lowest temperatures im- plies that the interatomic forces in it are very weak. Its low density — 0.14 gr/cm3 — and its exceptionally low viscosity — 40 µP — indicate that its properties are closer to those of a dense gas than of a liquid. At room temperature water has a viscosity of 0.01 P, and typical gases such as nitrogen and helium have a viscosity of 2 × 10−4 P. Since the viscosity is proportional to T 1/2 (see Exercise 3.14 of Part I), a typical viscosity for gases at 4 K would have been (if there existed such gases) of order 10−5 P. The viscosity of gaseous helium in this region is indeed about 20 µP. More- over, since the experiments of Keesom and Kapitza of the twenties and thirties, it has been known that liquid He4 drastically changes it prop- erties at a temperature of 2.17 K. The change is so signiﬁcant that each of the phases has been given a name of its own: He I is the name of the liquid above 2.17 K, and He II, below 2.17 K. The most pronounced property of He II is its ability to ﬂow through capillaries without any friction. The measurement of the viscosity of He II in such ﬂows suggests a value not in excess of 10−11 of that of He I. This is the property of superﬂuidity of He II. Another of its prominent properties superﬂuidity is an extraordinarily large thermal conductivity of order 104–105 W/mK. Compare with the thermal conductivities of metals appearing in Table 5.3.1. These two properties manifest themselves in a series of spectacular phe- nomena, such as the fact that the liquid can “crawl” on the sides of an empty vessel immersed in a bath of He II and ﬁll it up (Fig. 5.4.2a) or crawl out of it when the vessel is taken out of the bath (Fig. 5.4.2b), or the fact that He II boils without bubbles. (a) (b) Fig. 5.4.2. (a) An empty vessel immersed in a bath of He II is ﬁlled up by the liquid crawling on its sides until the heights become equal. (b) If the vessel is taken out of the bath, the liquid crawls out of it and drips back into the bath. All of the above led F. London in 1938 to interpret the phase tran- sition from He I to He II as a Bose–Einstein condensation. According to this explanation, at temperatures below the transition temperature a macroscopic number of helium atoms (a ﬁnite density) occupy the ground level and a macroscopic number of atoms are in the excited levels. These 492 Ch. 4 Boson Gas two populations behave as two diﬀerent liquids — one “normal,” He I- like, and the other superﬂuid — that coexist in the same vessel. London identiﬁed the atoms of the normal liquid with the atoms occupyingthe ex- cited states, whereas the superﬂuid atoms were identiﬁed with the atoms occupyingthe ground level. The existence of two liquids is actually conﬁrmed experimentally, and a good example of this is the fact that diﬀerent methods of measuring the viscosity yield diﬀerent results. One way is to measure the rate of liquid ﬂow in a capillary. This rate is inversely proportional to the viscos- ity. Measurements of this kind yield the extremely small viscosity values mentioned above and have led to the term “superﬂuidity.” On the other hand, measurements of the viscosity of He II by the method of the rotat- ingcylinder, which is illustrated in Fig. 5.4.3, yield values very close to thoseofHeI. Fig. 5.4.3. Viscosity measurement by the method of the rotating cylinder. The inner cylinder rotates due to the pull of the weight and creates a velocity gradient in the liquid ﬁlling the space between the inner and outer cylinders. The reason for this is that the viscosity of the “normal” component of He II prevents it from participatingin the ﬂow through capillaries, and thus that ﬂow is totally superﬂuid. In contrast, in the rotatingcylinder the whole liquid participates. The superﬂuid component does not con- tribute, of course, but the macroscopic number of “normal” atoms which participate in this ﬂow give rise to a viscosity like that of He I. Note that we do not explain here why Bose–Einstein condensation implies a zero viscosity. We will return to this later. The superﬂuid component is also responsible for the phenomenon of the crawlingof liquid helium. A thin layer of helium atoms, originating from the helium vapor around the vessel, accumulates on its inner and outer surfaces and gives rise to a continuous connection between the inside of the vessel and the bath. Since the superﬂuid component ﬂows without viscosity there is no resistance to its atoms’ tendency to decrease their 4.5 Bose–Einstein condensation in helium 493 energy by moving along the layer from the higher liquid surface towards the lower liquid surface, as gasoline is pumped out of the tank of a car and into an external container with the help of a rubber pipe. In our case the pipe is created spontaneously by the helium layer. The huge thermal conductivity is also a reﬂection of the fact that He II consists of two diﬀerent components. The heatingof a certain region A with respect to a nearby region B leads to a diﬀerence in the concentration of the atoms of the superﬂuid component, since their number decreases with increasingtemperature, accordingto Eq. (5.4.13). Hence the con- centration of the superﬂuid component in region A is lowered, and as a result a current of the superﬂuid component is set up from B to A, in order to equate the concentrations. This current causes an increase in the total density and the total pressure of the helium in region A, which in turn gives rise to a current of the normal component from A to B. In a steady state in which a temperature gradient is created between A and B (TA >TB), there will appear, therefore, a current of the superﬂuid com- ponent from B to A and a current of the normal component from A to B. Since the atoms of the superﬂuid component are all in the ground level, they cannot carry heat. On the other hand, the normal component carries heat, so that the temperature diﬀerence we created is accompanied by a ﬂow of heat from the hot region to the cold region. This mechanism of heat conduction is very eﬃcient. It leads to the fact that He II boils without bubbles: Any local temperature rise near the boilingpoint does not lead to the evaporation of the region and to the appearance of a bubble, but is instead immediately carried to the edge of the liquid, causing its surface to evaporate. Thus, we have described qualitatively the manner in which Bose– Einstein condensation is related to the phenomenon of superﬂuidity in He II. The description of liquid helium as an ideal boson gas must be con- sidered no more than a rough approximation, on which we will improve in Sec. 4.6. But before doingthat we shall see that several properties of liquid helium can nevertheless be captured within this description. 4.5 Bose–Einstein condensation in helium The ﬁrst point we discuss is the critical temperature. If the phase transi- tion from He I to He II is indeed a Bose–Einstein condensation, then the critical temperature given by (5.4.12) must correspond to the transition temperature 2.17 K, at least approximately (since, after all, liquid helium is not an ideal gas). And, indeed, substituting the appropriate quantities for helium we obtain a critical temperature of about 3 K, which is close enough to the transition temperature to be considered as supporting our explanation. 494 Ch. 4 Boson Gas Exercise 4.4 (a) Calculate the critical temperature for Bose condensation of He 4. (b) Calculate the critical temperature for Bose condensation of diatomic hydrogen H2 if the density of liquid hydrogen is 0.06 gr/cm3.Would you expect superﬂuidity in liquid hydrogen as well? Solution on page 530 ➤ T (K) C V /R 6➤ 5 4 3 2 1 0 1.2 1.4 1.6 1.8 2.0 2.2 2.4 2.6 Fig. 5.4.4. The molar speciﬁc heat of liquid He 4. CV is measured in units of the gas constant R =8.3J K −1. The next issue is the speciﬁc heat. Measurements of the speciﬁc heat around the transition temperature 2.17 K reveal a sharp increase at this temperature, which is evidence for a sharp change in the properties of the liquid. We shall presently see that the speciﬁc heat of the Bose gas increases with T for T< Tc and decrease for T> Tc.At T = Tc there is a cusp (see Fig. 5.4.5). The quantitative diﬀerence between the ex- perimental and theoretical curves reﬂects the fact that the description of liquid helium as an ideal gas is too coarse. To obtain better agreement, the interactions between the atoms must be taken into account, which we will not do here. The calculation of the speciﬁc heat, CV , of a boson gas below the crit- ical temperature is quite simple, since the chemical potential is constant (µ = 0) and the energy is due entirely to the atoms in the excited states: E = 2.012V (2πm)3/2(kT )5/2 h3 . (5.4.14) Exercise 4.5 (a) Derive Eq. (5.4.14). (b) Show that the average energy per particle (when T< Tc)is E N =0.770kTc ( T Tc )5/2 . Solution on page 530 4.5 Bose–Einstein condensation in helium 495 Diﬀerentiatingthe energy with respect to T we obtain the speciﬁc heat for T< Tc: CV = 5.030V (2πmkT )3/2 h3 · k =1.925Nk ( T Tc )3/2 . (5.4.15) The speciﬁc heat of a boson gas below the critical temperature thus be- haves like T 3/2 compared to that of a degenerate fermion gas which is linear in T . It reaches a maximum of 1.925k per particle, compared to 3 2 k for a classical gas. We further emphasize that the speciﬁc heat and the energy do not depend on the number of particles! The reason for this is that below Tc all the additional particles accumulate in the ground level, and do not contribute to the energy. We now calculate the speciﬁc heat above the critical temperature. To this end we need the temperature dependence of the energy, but now the chemical potential is also temperature-dependent. Hence we ﬁrst obtain the temperature dependence of the chemical potential. We do this, ap- proximately, for temperatures near Tc and hence for values of µ near zero, as we did for the fermion gas near T = 0. The details of the calculation are, of course, diﬀerent. For T> Tc the occupation of the ground level is negligible, and hence it is possible to use Eq. (5.4.6), which is an implicit relation between µ, T and n. To calculate the integral on the right hand side of (5.4.6), as an expansion for small values of µ, we write the diﬀerence between the maximal density in the excited states, n∗,and n: n∗ − n = 2π(2m)3/2 h3 ∫ ∞ 0 [ 1 eβϵ − 1 − 1 eβ(ϵ−µ) − 1 ] ϵ 1/2dϵ . (5.4.16) Though n∗ is known, Eq. (5.4.9), the advantage of this form is that the integral on the right hand side of (5.4.16) can now be calculated when µ is close to zero. Its magnitude is πkT √ −µ. (See solution to Exercise 4.6.) Recall that µ< 0. Thus µ ≈− h6 32π4m3 ( n∗ − n kT )2 = − { 2.612 [ 1 − ( Tc T )3/2]}2 kT 4π . (5.4.17) Note that since n∗ increases with T , µ becomes more negative with in- creasingtemperature above Tc. 496 Ch. 4 Boson Gas Exercise 4.6 Derive Eq. (5.4.17). Solution on page 531 Next we calculate the energy E at temperatures near Tc (but above it). We calculate the diﬀerence between the energy E∗,for µ =0, and the actual E, in analogy with the calculation of n∗ − n. E∗ is given by the right hand side of Eq. (5.4.14). We have E∗ − E = 2πV (2m)3/2 h3 ∫ ∞ 0 [ 1 eβϵ − 1 − 1 eβ(ϵ−µ) − 1 ] ϵ 3/2dϵ , (5.4.18) and for small µ we ﬁnd that E ≈ E∗ + 3 2 N∗µ. (5.4.19) Since µ is negative, the energy is actually smaller than the maximal value E∗, which it can attain at temperature T . Exercise 4.7 Derive (5.4.19). Solution on page 532 The temperature dependence of the energy is quite complicated even in this approximation: The temperature dependence of E∗ is given by (5.4.14), the temperature dependence of n∗ by (5.4.9), and the tempera- ture dependence of µ by (5.4.17), and in all E ≈    0.770 − 0.814 [ 1 − ( Tc T )3/2]2   ( T Tc )3/2 NkT . (5.4.20) Diﬀerentiating, we ﬁnd the speciﬁc heat at temperatures near Tc: CV ≈ [ 1.629 + 0.407 ( Tc T )3/2 − 0.111 ( T Tc )3/2] Nk . (5.4.21) This is a function that attains a maximum value of 1.925Nk at T = Tc and decreases with T . Far from T = Tc, Eq. (5.4.21) is no longer valid. It is clear that when T ≫ Tc the boson gas behaves like an ideal gas, and hence CV → 3 2 Nk. Figure 5.4.5 illustrates the behavior of the speciﬁc heat as a function of temperature. The similarity to Fig. 5.4.4 is not complete, but it is quite signiﬁcant. 4.6 Viscosity of a superﬂuid 497 0 1.925 ➤➤ (T/TC ) C /RV 1.5 01 23 Fig. 5.4.5. The speciﬁc heat of a boson gas as a function of temperature. 4.6 Viscosity of a superﬂuid In describingthe properties of liquid helium below 2.17 K, we mentioned that when it behaves as an inviscid ﬂuid, it is the superﬂuid component, namely the atoms occupyingthe ground level ϵ = 0, that is responsible for all the observed spectacular phenomena. But we did not explain why a liquid whose atoms are all in the ground state is inviscid. The ﬁrst explanation of this was given in the 1940’s by Landau. We start by consideringthe motion of a body in a liquid under the inﬂuence of an external force. The viscosity of the liquid is expressed as a frictional force actingon the movingbody, originating in the collisions between the body and the molecules of the liquid (see Secs. 2.4 and 3.6 of Part I). We have seen that it is possible to give a satisfactory account of the viscosity of gases considering their molecules as free particles colliding from time to time with the body. This assumption cannot underlie a quantitative analysis of the vis- cosity of a liquid. The molecules of a liquid cannot be considered free particles: The special properties of the liquid are due to forces between its molecules. Hence it is not possible to describe the collisions of the body with the molecules of the liquid as a sequence of independent collisions with free particles. A collision with one particle necessarily involves the nearby molecules. Another aspect of this is the fact that the total energy of the liquid cannot be considered as a sum of single molecule energies, since there is a signiﬁcant contribution due to the intermolecular potential energy. It is, therefore, impossible to deﬁne single particle states of the molecules of a liquid. Hence a body movingthrough a liquid and losing energy does not transfer it to single molecules but to the liquid as a whole. The energy states of a liquid are states of the collective motion of all the molecules. In this sense there is a great similarity between the liquid and the solid crystal discussed in Chap. 3 of Part IV. There we have seen that the description of a crystal as N coupled three-dimensional harmonic 498 Ch. 4 Boson Gas oscillators can be replaced by a description in terms of 3N independent one-dimensional harmonic oscillators. Each of these oscillators has a well- deﬁned frequency, and it describes a collective vibration of the molecules of the crystal, namely a sound wave. This is also the case in a liquid: A body movingthrough it will excite sound waves, which are collective motions of the liquid. The energy of these excitations originates in energy losses of the movingbody. The advantage of the crystal over the liquid is its periodic structure, which allows a precise calculation of the disper- sion relation, namely the relation between the frequency of the sound waves and their wave number. In a liquid it is not possible to calculate the dispersion relation in a simple manner and it has to be found from experiment. Another ingredient is that liquid helium is a quantum liquid. The sound waves excited in it should be treated as excited states of quan- tum harmonic oscillators where each oscillator (phonon) is characterized by its wave vector, q, and its angular frequency, ω. We thus describe liquid helium at very low temperatures, as collective excitations above a quantum-mechanical ground state, in which the energy of the liquid is minimal. These excitations, which are themselves free bosons, are at ther- modynamic equilibrium, and all the information regarding the properties of the liquid is contained in the dispersion relation ω(q)or ϵ(q)ofthese excitations. Thus, a body movingthrough liquid helium at T =0 does not excite single atoms from the ground level but rather excites quanta such as phonons, for example. These excitations carry momentum and energy. If the body movingthrough the liquid excites a phonon with mo- mentum ¯hq and energy ϵ(q), it is at the expense of the body’s motion. Momentum and energy conservation imply that    p = p′ +¯hq , p2 2M = p′2 2M + ϵ(q) , (5.4.22) where M is the mass of the body, p is its initial momentum and p′ is its momentum after the excitation of the phonon. It turns out, as we proceed, that the two equations in (5.4.22) can be satisﬁed simultaneously only in a narrow range of p or, equivalently, only in a narrow range of velocities of the body. This means that in the range of velocities in which the two equations in (5.4.22) are not satisﬁed, the body movingthrough the liquid cannot give rise to an excitation. Hence it cannot lose energy and will move through the liquid without friction. This is equivalent to zero viscosity, or superﬂuidity. In order to see when the two equations in (5.4.22) are satisﬁed simultaneously, we substitute p′ = p − ¯hq in the 4.6 Viscosity of a superﬂuid 499 second equation (5.4.22) and obtain ¯hq · v = (¯hq)2 2M + ϵ(q) , (5.4.23) where v(= p/M ) is the initial velocity of the body. Exercise 4.8 (a) Prove Eq. (5.4.23). (b) Show that if the body has a macroscopic mass, then to a good ap- proximation the condition for phonons to be excited is ¯hq · v = ϵ(q) . Use 240 m s−1 for the speed of sound in liquid He. Solution on page 533 Therefore, in order to give rise to an excitation with momentum ¯hq the velocity of the body must satisfy (5.4.23). The right hand side of this equation is positive. Hence, the angle θ between v and q must be acute. Furthermore, the most “eﬃcient” state is that in which θ =0, namely the excited phonon, propagates in the same direction as the body. In this case the velocity of the body attains the minimum value which still allows the excitation of a phonon with momentum ¯hq. All other angles require a larger velocity. The minimal velocity required for the excitation of a phonon with momentum ¯hq thus depends on q as follows: vmin = ϵ(q) ¯hq . (5.4.24) The question now is: What is the form of ϵ(q)? ϵ(q)could describe ordinary sound waves propagating at a speed vs.Measurements of the propagation of sound waves in liquid helium yield vs = 237 m s−1.For sound waves, ϵ(q)= ¯hω(q)= ¯hvs|q| , (5.4.25) and if we substitute this into Eq. (5.4.24) we ﬁnd that the minimal speed required for the excitation of a phonon of any wavelength is the sound velocity in helium, vs. Hence any body which moves through liquid helium at T = 0 with a speed lower than vs, will move without viscosity. But this conclusion does not ﬁt the experimental results, which give a much smaller critical speed. The reason for the discrepancy is that the dispersion relation is not simply that of phonons, Eq. (5.4.25), but is more complicated. The dis- persion relation has been measured experimentally by scatteringslow neu- trons from liquid helium. It is depicted in Fig. 5.4.6. The measurement 500 Ch. 4 Boson Gas ➤➤ 0 0 0.6 1.2 1.8 2.4 3.0 8 16 24 (K) ε k q (A-1) Fig. 5.4.6. The dispersion relation ϵ(q) for excitations in liquid helium at a temperature of 1.12 K, measured using neutrons with wavelength 4.04 ˚A. The wave number is given in units of ˚A −1 and the energy in units of K. For instance, ϵ/k = 32 K corresponds to an energy of 4.4 × 10 −22 Jor 2.8 × 10 −3 eV. The minimum of ϵ is attained at q =1.94 ˚A −1, ϵ/k =8.67 K. D. G. Henshaw &A.D.B.Woods, Phys. Rev. 121, 1260 (1961). is based on the fact that slow neutrons give rise to a single excitation in each scatteringevent, so that by measuring their energy and momentum loss, Eq. (5.4.22), it is possible to deduce ϵ(q). At small wave numbers (large wavelengths) the dispersion relation looks indeed like that of ordinary sound waves, namely like (5.4.25), and is represented by the dashed line in the ﬁgure. But at larger wave numbers the trend changes and ϵ(q) begins to decrease, attains a minimum at q =1.94 ˚A −1, ϵ/k =8.67 K, and then increases again. In order to understand how such a dispersion relation aﬀects the min- imum speed required to create an excitation in the liquid, we shall use a graphical approach: From Eq. (5.4.24) we conclude that the minimum speed required in order to create an excitation with wave number q is the slope of the straight line connecting the point on the dispersion curve correspondingto the wave number q and the origin — see Fig. 5.4.7. A diﬀerent minimal speed is required for each q and, as is made clear by the ﬁgure, due to the deviation of the dispersion relation from the straight line, an increase of q decreases vmin. Hence vmin has a minimal value which is obtained when the straight line is tangent to the dispersion curve. In this state the body moves through the liquid at the critical speed vc, and it can only produce ex- citations correspondingto the tangent point which is (almost exactly) the minimum point of the dispersion curve. If the body’s speed is less than vc, the body will produce no excitations, since momentum and energy conservation cannot be simultaneously satisﬁed. If the body’s 4.6 Viscosity of a superﬂuid 501 Fig. 5.4.7. A graphical solution of Eq. (5.4.24). speed is larger than vc there can be additional excitations at other values of q. To come back to the case in which it is liquid helium that ﬂows across a stationary body, we observe that the creation of excitations in the liquid can only depend on the relative velocity between the liquid and the body. Hence we obtain the same criterion for the critical speed for superﬂuidity, this time for the ﬂow velocity of liquid helium past a body at rest. Note that our considerations apply to a body of arbitrary shape, across which the liquid is ﬂowing. Such a body can also be a capillary tube. In a coor- dinate frame movingwith the liquid (in which the liquid is at rest), we can use Eqs. (5.4.22) and proceed in the same way which led to Eq. (5.4.24). Then we return to the coordinate frame in which the liquid is ﬂowingand the capillary is at rest and obtain the condition for the critical speed for superﬂuid ﬂow: vc =min [ ϵ(q) ¯hq ] . (5.4.26) As we have seen, the graphical meaning of this condition is, ﬁnding the slope of the line which passes through the origin and is tangent to the dispersion curve. This condition is called Landau’s condition. Landau’s condition Exercise 4.9 (a) Calculate the speed of sound in He II from the graph in Fig. 5.4.6. (b) Calculate Landau’s critical speed. Solution on page 533 A critical speed of about 60 m s−1, as resulted in the previous exercise, is attained in very special circumstances. Under ordinary circumstances a much lower speed is obtained, on the order of 1 cm/s. In light of our discussion, this implies that there exist excitations which are of a diﬀerent type, and are not included in the dispersion relation in Fig. 5.4.6. These excitations are also created by the motion of the body through He II, and 502 Ch. 4 Boson Gas are the cause for the low critical speed which is observed. It turns out that these excitations are vortices. It is possible to excite them in a controlled manner and to study their properties in experiments performed in He II, in a rotatingvessel. But we leave the subject at this point. Before concludingwe emphasize that the phenomenon of superﬂuidity can be understood only by takinginto account the interatomic forces between the helium atoms, since their existence is responsible for the existence of the collective excitations in the liquid. In the absence of interatomic forces the liquid would behave as a gas of free particles and its excitations would be the excitations of the free atoms themselves. The dispersion relation of a free particle is the usual ϵ(q)=(¯hq)2/2m,and applyingthe Landau condition (5.4.26) to it, we would ﬁnd vc =0, since the minimum of the function ϵ(q)/q for free particles satisﬁes min [ ϵ(q) q ] =min [ ¯h 2q 2m ] =0 . (5.4.27) Alternatively, it is possible to see that the tangent to the dispersion curve ϵ =(¯hq)2/2m, which passes through the origin, is the q axis itself, whose slope is zero. This means that, in the absence of forces between the atoms, the creation of excitations in liquid helium at T = 0 is possible at any ﬂow speed, and thus the system will not behave as a superﬂuid. The discussion so far has regarded superﬂuidity at absolute zero. As noted already, at T> 0 it is possible to treat liquid helium as a collection of excitations above the ground state. Hence a body moving through liquid helium at T> 0 will lose energy in one of two ways. The ﬁrst is by creatingexcitations from the ground state, exactly as at T =0, and this can occur only above the critical speed. The second is by collidingwith existingexcitations in the liquid due to the thermal ﬂuctuations. These latter excitations disappear at T → 0, and have thus been ignored till now. The thermal excitations behave as an ideal gas of phonons (with its particular dispersion relation) which propagate against a background of helium atoms in the ground state of the liquid. The motion of a body through the gas, which involves collisions with the phonons, cannot occur without energy loss. In this picture the origin of the viscosity of liquid helium at temperatures above absolute zero are the excitations themselves, not the helium atoms occupyingthe single particle excited states. The latter lost their meaningthe moment we took into account the interatomic forces. The two-component description of He II takes, therefore, a diﬀerent meaning. The superﬂuid component is composed of the atoms themselves, whereas the normal component is composed of the phonon gas, which propagates against the background of the ground state of the atoms. 4.7 Fermi liquid and superconductivity 503 In superﬂuid ﬂow at T> 0, such as the ﬂow of liquid helium through a capillary out of a container, helium atoms ﬂow through the tube without carryingexcitations alongwith them. Most of the phonons remain behind inside the container, since their viscosity does not allow them to pass through the tube. Exercise 4.10 Would you expect the speciﬁc heat of He4 at very low temperatures to be proportional to T 3/2, like in a condensed boson gas? Solution on page 534 4.7 Fermi liquid and superconductivity Helium has two stable isotopes: He4 atoms, with spin 0, are bosons and He3 atoms, with spin 1/2, are fermions. Liquid He 4 exhibits, as we have seen, quantum behavior on a macroscopic scale. The followingquestion, therefore, arises: Will He 3 also exhibit at low temperatures a behavior determined by the fermionic nature of its atoms? First we mention that it is possible to obtain macroscopic amounts of He 3, which enable the measurement of the physical properties of He3. It turns out that they are signiﬁcantly diﬀerent from those of He4.He3 liqueﬁes at atmospheric pressure at a temperature of 3.2 K (compared to 4.2 K in He4), and like He4 it does not freeze at T = 0. The density of He3 is 0.07 gr/cm3, which is half of that of He4, and its viscosity around 1 K is 25 µP, about half of that of He 4. To a ﬁrst approximation it is possible to think of liquid He 3 as an ideal fermion gas, as we did for liquid He4 in Sec. 4.5, which we treated as an ideal boson gas. The ﬁrst question is: What is the degree of degeneracy of liquid He3? In order to answer this we calculate its Fermi temperature, and ﬁnd that it is quite low — 4.5 K! Exercise 4.11 Calculate the Fermi temperature of He3. Solution on page 534 From the discussion of the Fermi system in Chap. 3 we know that T must be much below TF for the gas of fermions to be degenerate. Hence, at temperatures at which He 4 behaves as a degenerate boson gas, He3 is far from beingdegenerate. The temperatures at which the fermionic nature of He3 will begin to appear are expected to be at least 10 times lower (see Fig. 5.3.2). A phenomenon characteristic of a degenerate Fermi gas that is actually exhibited by He 3 at temperatures below 0.5 K, is the rapid increase of the mean free time between collisions with decreasing 504 Ch. 4 Boson Gas temperature. The reason is again the Pauli principle, which limits, when T ≪ TF , the number of atoms that can participate in collisions to those found in an energy range kT around the Fermi level. Recall that we used an identical argument to obtain the ratio of the thermal to the electrical conductivity in the Sommerfeld model, in Sec. 3.6. An estimate of the relative number of atoms in the range ∆ϵ = kT around the Fermi level is obtained from the energy distribution function fϵ(ϵ) (see Solution 3.12): fϵ(ϵF )kT ≈ kT ϵF . (5.4.28) In a collision two such atoms must be involved, and the probability (per unit length) for a He 3 atom to collide decreases by a factor of (kT /ϵF )2. Since the probability per unit length is given by 1 over the mean free path [see Sec. 3.2 of Part I and especially Eq. (1.3.14)], it follows that the mean free path in a degenerate fermion gas increases by a factor of (ϵF /kT )2, compared to that calculated in Part I for Boltzmann particles. Hence, ℓ ≈ 1 nσ ( ϵF kT )2 , (5.4.29a) where n is the density of fermions (He3 atoms or electrons, etc.) and σ is their cross section, which we took in Part I to be 4πa2.All numerical factors of order unity have been suppressed. The mean free time is obtained by dividing ℓ by the typical velocity of the particles that participate in collisions, namely the Fermi velocity: τ ≈ 1 nσvF ( ϵF kT )2 . (5.4.29b) This sharp increase in the mean free path with decreasingtemperature aﬀects the transport coeﬃcients, such as the viscosity and the thermal conductivity, which are proportional to ℓ or τ . The viscosity, for instance, will be given by Eq. (1.3.47) with ¯v = vF : η ≈ 1 3 mvF ℓn . (5.4.30) When the density n is constant, so are vF and ϵF , and by (5.4.29a) η ∝ 1 T 2 . (5.4.31) 4.7 Fermi liquid and superconductivity 505 Exercise 4.12 (a) How will the viscosity of a degenerate fermion gas vary with the mass of the fermions? (b) How will the viscosity vary with density, at constant T ? Solution on page 534 Such variation of the viscosity with temperature has actually been measured experimentally and indicates that it is possible, at least ap- proximately, to describe liquid He 3 as a fermion gas, and that the approx- imation improves as the temperature decreases. A very longmean free path is not only characteristic of He 3 but ap- pears also in metals, as we have already mentioned. It is also consistent with the fact that the electric forces between the conduction electrons in metals are neglected in the Drude model. The justiﬁcation for Drude’s assumption is, of course, the good agreement with experiment of the re- sults obtained by applyingthe kinetic theory to the conduction electrons. Later on we will see that this analogy between the properties of liquid He3 and the properties of electrical conductivity does not end here but persists at lower temperatures and promises several surprises. To better understand the properties of liquid He 3 we have to take into account the interatomic forces, which our description of an ideal fermion gas has ignored. We must, therefore, clarify what are the fundamental excitations of the liquid above its ground state, as we did for He4.These excitations, which describe collective motions of He3 atoms, will them- selves be fermions this time, namely they will satisfy the Pauli principle. The properties of the liquid will depend on their dispersion relation ϵ(q), which is determined by the forces between the atoms. Such a liquid has been given the name of “Fermi liquid.” Using this description Landau Fermi liquid succeeded in 1956 in explainingthe low temperature properties of liquid He3 down toafew mK (10−3 K). At the beginning of the seventies it was discovered that He3 changes its properties drastically at a temperature of about 1 mK, and that this change is accompanied by a sharp change in the speciﬁc heat which is very similar to the one of He4 at 2.17 K. The similarity is not only superﬁcial — it turned out that indeed He3 behaves below the transition temperature of 1 mK as a superﬂuid! To understand how superﬂuidity, a phenomenon characteristic of a boson liquid, is made possible in He 3 one postulates a mechanism that correlates the motion of pairs of He3 atoms. The pair forms a sort of diatomic molecule which obeys Bose–Einstein statistics, and a macroscopic number of such pairs is equivalent to a boson liquid. If the pairs were stable, a liquid of such pairs would undergo a Bose–Einstein 506 Ch. 4 Boson Gas condensation at a critical temperature of a Bose gas with a mass double that of He3, which is about 1 K. It would behave as a superﬂuid below that temperature. But He3 becomes superﬂuid only below 1 mK. Exercise 4.13 Calculate the critical temperature of Bose–Einstein condensation for pairs of He 3 atoms. Solution on page 535 One concludes, therefore, that the temperature of 1 mK, below which ordinary He3 becomes superﬂuid, cannot be interpreted as the critical temperature for Bose–Einstein condensation and the analogof He I does not exist in He3. The reason is that above this temperature there are no bosons in the liquid. This transition temperature is the temperature below which it becomes “advantageous” for the He3 atoms to move in pairs. The mechanism, which is indirect and complicated, gives rise to an eﬀective attraction between atoms with energies near the Fermi energy, due to an interaction of the magnetic moment of each atom with its surroundings, and the back reaction of the surroundings on another atom. The forces induced in this way are very weak, and the resultingpairs are loose and extended; they can survive only at very low temperature, where almost all thermal ﬂuctuations are eliminated. For the sake of completeness we mention that actually there exist two phases of superﬂuid He 3. They diﬀer in their magnetic properties, and are called He3Aand He3B. He3A appears at pressures between 21 and 34 atm for temperatures ranging between 2.2 mK and 2.8 mK. He 3B appears for the entire pressure range between 0 and 34 atm (above this pressure He3 solidiﬁes). At zero pressure He3B appears at a temperature of 1 mK, and increasingthe pressure increases the transition temperature up to 2.5 mK. Electrons are also fermions, hence one would expect the phenomenon of superﬂuidity in He3 to have an electronic analog. The electronic analog of the superﬂuidity of He 3, known as superconductivity, was discovered by Kamerlingh–Onnes in 1911. As implied by its name, superconductivity is the ability of materi- als to maintain a current without resistivity. In fact, current can ﬂow in superconductingrings for months or even years with no observable loss. Superconductivity is much more common than superﬂuidity. About 30 metallic elements and a countless number of compounds and alloys are known to be superconductors. Superconductivity appears at temperatures below a critical temperature that depends on the speciﬁc material. Until 1987 superconductivity was considered a low temperature phenomenon. Its discovery in 1911 was in mercury and the critical temperature mea- sured was about 4 K. All the superconductors that followed had critical 4.7 Fermi liquid and superconductivity 507 temperatures of similar magnitude, except for a few that reached 20 K. In 1987 this barrier was broken, and materials with critical temperatures above 100 K have been discovered. A full theoretical explanation for superconductivity, which was given in 1957 by Bardeen, Cooper and Schrieﬀer (BCS theory), is quite compli- cated and deserves an entire course. A mere “shadow” of this explanation may be brought here: Superconductivity is interpreted as the superﬂu- idity of the electronic Fermi liquid. Just as in He3 below the transition temperature, there exists in superconductors a mechanism that creates a net attraction between pairs of electrons with energies close to the Fermi energy. The electric charge of an electron induces a charge density in its surroundings, and the latter exerts a force on another electron. In this way electron pairs (Cooper pairs) are created. The electrons in such a pair move in a correlated manner, even if the distance between them is large and there are many other electrons between them, some of which Cooper pairs belongto other Cooper pairs. Due to this correlated movement which exists in the ground state, it is diﬃcult to create excitations in the system and hence the electron pairs can move without friction, like in a boson superﬂuid. Since a Cooper pair has a charge, of 2e, the motion of the pairs is an electric current, and their superﬂuid ﬂow is an electric current without resistivity, namely superconductivity. Superconductors exhibit not only a spectacular electrical behavior, they also have some extraordinary magnetic properties. A good exam- ple is perfect diamagnetism, called the Meissner eﬀect. Diamagnetism is dia- magnetismthe induction of magnetization opposing the external magnetic ﬁeld. It implies a negative susceptibility: M = χH,χ < 0 , (5.4.32) where M is the magnetization density [see Chap. 1 and Sec. 5.3 of Part II; note that χ in Eq. (2.5.15) is deﬁned in terms of the total magnetization and not in terms of the magnetization density]. Perfect diamagnetism in a superconductor is the fact that the magne- tization totally cancels the magnetic ﬁeld inside the material, i.e. B =0, or M = − 1 4π H . (5.4.33) See Eq. (2.1.3). The magnetization is induced by permanent screening currents on the surface of the superconductor which appear immediately upon the application of the magnetic ﬁeld. This phenomenon is limited to low magnetic ﬁelds. Above a critical value, Hc, of the ﬁeld, which depends on the material and on the temperature, the magnetic ﬁeld penetrates the bulk material. At that point superconductivity disappears. 508 Ch. 4 Boson Gas Another unusual phenomenon is observed when coolingtakes place in the presence of a magnetic ﬁeld, from a temperature T> Tc to a temperature T< Tc.Above Tc the ﬁeld penetrates the material, as usual. When the external ﬁeld is turned oﬀ at a temperature T< Tc, the induced magnetization is trapped in the material and a macroscopic magnetic ﬁeld is felt outside the superconductor. One can go on to describe many additional fascinating aspects of su- perconductivity, but for us this is a good point to end our discussion of superconductivity, and indeed the entire course. Appendix Calculation of Some Integrals In the course of this part we needed integrals of the form Jν = ∫ ∞ 0 xν−1 ex +1 dx , (5.A.1) where ν is an integer or half-integer. Note that the expression 1/(ex +1) is the sum of the geometric series with alternating signs: 1 ex +1 = e−x 1+ e−x = e −x −e −2x +e −3x −··· = ∞∑ m=1(−1) m+1e −mx , (5.A.2) and substitutinginto (5.A.1) we obtain in a similar manner to (4.A.3) ∫ ∞ 0 xν−1 ex +1 dx = ∞∑ m=1 (−1) m+1 ∫ ∞ 0 x ν−1e −mxdx = ∫ ∞ 0 yν−1e −ydy ∞∑ m=1 (−1)m+1 mν . (5.A.3) We are thus left with the calculation of the sum and the integral appearing on the right hand side of (5.A.3), and both are quite similar to the ones calculated in the appendix to Part IV. We ﬁrst calculate the integral for integer values of ν.It is identical to the one we calculated in (4.A.2). Denote the integral by Γ(ν), Γ(ν)= ∫ ∞ 0 x ν−1e −xdx . (5.A.4) Integrating by parts for arbitrary ν we obtain ∫ ∞ 0 x ν−1e −xdx =(ν − 1) ∫ ∞ 0 x ν−2e −xdx , (5.A.5) or Γ(ν)=(ν − 1)Γ(ν − 1) . (5.A.6) 509 510 Calculation of Some Integrals Using the fact that Γ(2) = 1 and iterating (5.A.6) we regain for integer ν Eq. (4.A.2): Γ(ν)=(ν − 1)! . (5.A.7) For half-integer ν we can repeat the iteration since the recursion relation (5.A.6) still holds. But we need the value of Γ(1/2). This integral is calculated via the change of variable x = z2: Γ ( 1 2 ) = ∫ ∞ 0 x −1/2e −xdx =2 ∫ ∞ 0 exp(−z2)dz = √ π, (5.A.8) where the last integral has been calculated in Part I. Thus, for example, we have Γ ( 3 2 ) = 1 2 √ π, Γ ( 5 2 ) = 3 4 √ π, Γ ( 7 2 ) = 15 8 √ π. (5.A.9) We are left with the calculation of the inﬁnite sum in (5.A.3): S = ∞∑ m=1 (−1)m+1 mν =1 − 1 2ν + 1 3ν − 1 4ν + 1 5ν − 1 6ν + ··· , (5.A.10) which we now express in terms of the zeta function, deﬁned for every ν> 1 by Eq. (4.A.4). Separatingthe even and odd terms in the sum we ﬁnd that S = S1 − S2,where S1 =1 + 1 3ν + 1 5ν + ··· , (5.A.11a) S2 = 1 2ν + 1 4ν + 1 6ν +··· = 1 2ν (1+ 1 2ν + 1 3ν + ···) =2 −νζ(ν) . (5.A.11b) S1 can also be expressed in terms of ζ(ν): S1 = ζ(ν) − S2 =(1 − 2 −ν )ζ(ν) , and then S = S1 − S2 = ζ(ν) − 2S2 =(1 − 2 1−ν )ζ(ν) . (5.A.12) We have thus found that for ν> 1 ∫ ∞ 0 xν−1 ex +1 dx =(1 − 2 1−ν )Γ(ν)ζ(ν) , (5.A.13) and for the sake of completeness we rewrite Eq. (4.A.5) in a form that emphasizes the similarities and the diﬀerences: ∫ ∞ 0 xν−1 ex − 1 dx =Γ(ν)ζ(ν) . (5.A.14) Actually both these equations are valid not only for integer and half- integer values of ν but for any real ν satisfying ν> 1. Calculation of Some Integrals 511 Finally, we list some useful values of ζ(ν)and Γ(ν): ν 1 2 1 3 2 2 5 2 3 7 2 4 ζ(ν) −1.460 — 2.612 π2 6 1.341 1.202 1.127 π4 90 Γ(ν) √ π 1 1 2 √ π 1 3 4 √ π 2 15 8 √ π 6 Self-assessment exercises Exercise 1 Solution on page 536 A classical (Boltzmann) ideal gas is enclosed in a container of volume V , and can exchange energy and particles with a bath of temperature T and chemical potential µ. (a) Prove that the average number of particles in the container ⟨N ⟩ is related to the thermodynamic potential Ω by ⟨N ⟩ = −βΩ(T, V, µ) . (b) Prove that the probability of ﬁndingexactly N particles inside the container is given by PN = e −⟨N ⟩ ⟨N ⟩N N ! , where ⟨N ⟩ = −βΩ. This is the Poisson distribution. Exercise 2 Solution on page 537 (a) In Sec. 2.4 it is stated that the chemical potential of a phonon gas is zero, and that hence it is possible to obtain the average number of phonons in a crystal with frequency ω by substituting µ =0 into Eq. (5.2.11b). Explain how it is possible that µ = 0, if the free energy of an Einstein solid explicitly depends on N [Eq. (3.2.12)] and also the free energy in the Debye model, as given in Eq. (4.3.11), depends on it through qD [Eq. (4.3.12a)]. (b) Show directly from the partition function that the average energy of a gas of fermions or bosons can be written in terms of its average occupation numbers: E = ∑ k ⟨nk⟩ϵk . 512 Self-assessment exercises 513 Exercise 3 Solution on page 538 Calculate the chemical potential of a two dimensional fermion gas as a function of the temperature T and the density of particles per unit area n = N/A. (Assume that each fermion has a single spin state.) Exercise 4 Solution on page 539 (a) Calculate the pressure of a degenerate electron gas, and ﬁnd the rela- tion between the pressure and the energy density, E/V . (b) Calculate the pressure of the electron gas in aluminum. Exercise 5 Solution on page 540 (a) Calculate the energy density of an extremely relativistic gas of de- generate fermions with spin 1/2. Compare to the nonrelativistic case and determine under what conditions this description of an extremely relativistic degenerate fermion gas is valid. (b) Calculate the pressure of the gas in (a) and ﬁnd the relation between the pressure and the energy density. Exercise 6 Solution on page 542 (a) Calculate the pressure of a boson gas below the condensation temper- ature Tc, and explain why it does not depend on the volume. (b) Explain why there is no need to correct the expression for the ther- modynamic potential Ω of a degenerate fermion gas by adding a con- tribution of the ground state, as required for a degenerate boson gas. Exercise 7 Solution on page 543 Check if the phenomenon of Bose–Einstein condensation occurs in a two- dimensional boson gas. Exercise 8 Solution on page 544 Show that the energy density of a gas of massless fermions with spin 1/2 and zero chemical potential at temperature T , is 7/8 that of black body radiation at the same temperature. This may serve as an approximation to the gas of cosmic neutrino particles. Exercise 9 Solution on page 545 Solve Self-Assessment Exercise 9 of Part IV, for extremely relativistic temperatures: kT ≫ mc2. Solutions to exercises in the text Solution 1.1 Exercise on page 455 We write the grand canonical partition function (5.1.2) as a sum of two contributions: One from a state denoted by α =0, in which there are no particles in the system, and the other from all the other states. In the state α =0 N =0,E =0 . (i) Hence Z =1 + ∑ N>0 ∑ i e β(µN −Ei(N )) . (ii) Becauseall thenumbers N are positive, if µ →−∞, all the terms in the sum must vanish since lim µ→−∞ e βµN =0 . (iii) Thus, only the 1 remains on the right hand side of (ii) and indeed lim µ→−∞ Z =1 . (iv) Solution 1.2 Exercise on page 456 The average number of particles is calculated using the grand canonical probabilities: N = Z −1 ∞∑ N =0 ∑ i Ne β(µN −Ei) = Z −1 1 β ∂ ∂µ ∑ α e β(µN −Ei) = 1 β ∂ ∂µ ln Z = ∂ ∂µ (kT ln Z) , which is Eq. (5.1.7). 514 Solutions to exercises in the text 515 Solution 1.3 Exercise on page 456 To complete the derivation of Eq. (5.1.9) we must compute kT dβ dT ( ∂ ln Z ∂β ) V,µ . Since dβ dT = − 1 kT 2 , we can write kT dβ dT ( ∂ ln Z ∂β ) V,µ = − 1 T 1 Z ( ∂Z ∂β ) V,µ . Substitutingthe partition function from (5.1.2) and taking the derivative with respect to β,we can write 1 Z ( ∂Z ∂β ) V,µ = 1 Z ∞∑ N =0 ∑ i (µN − Ei)e β(µN −Ei) = µ⟨N ⟩− ⟨E⟩ , where use has been made of the deﬁnition of the average values, Eq. (5.1.4). This leads to Eq. (5.1.9), once the brackets have been dropped. Solution 1.4 Exercise on page 456 Substitutingthe grand canonical probabilities only into the logarithms of ∑ α Pα ln Pα gives S = −k ∑ α Pα[β(µN − Ei) − ln Z] . After performingthe summation, we obtain S = −kβ(µ⟨N ⟩− ⟨E⟩)+ k ln Z = − µ⟨N ⟩−⟨E⟩ T + k ln Z. Multiplyingby T , dropping the average braces and rearranging, it becomes TS + µN − E = kT ln Z , and using(2.0.29), we ﬁnd that Ω= −kT ln Z . Solution 2.1 Exercise on page 459 Since nk is the number of particles in state k, it is impossible for it to be larger than N . In an extreme case all the particles may be in the same state k0 and then nk0 = N ,and all other nk are zero. 516 Solutions to exercises in the text Solution 2.2 Exercise on page 459 The number of states with the same set of nk is the number of ways the N particles can be distributed in groups of nk each. It is the combinatorial factor that expresses the fact that all N particles can be interchanged, but interchanges of particles within each group do not produce new states. Hence the number is N ! n1!n2! ··· nk! ··· Solution 2.3 Exercise on page 459 The n1 particles in the state with energy ϵ1 contribute n1ϵ1 to the total energy. In the same way, for each k we obtain a contribution of nkϵk,and overall we obtain (5.2.3). Solution 2.4 Exercise on page 461 (a) The orbital angular momentum of the electrons is always an integer. Hence the addition of the orbital angular momentum cannot change an integer spin into a half-integer spin, and vice versa. (b) In a neutral atom the number of electrons is equal to the number of protons, and hence their total spin is always an integer. There are still the neutrons. Since each has half-integer spin, an odd number of neutrons contribute a half-integer to the total spin and an even num- ber of the neutrons will contribute integer spin, so that the neutrons determine the statistical behavior of the atom. Solution 2.5 Exercise on page 462 The diﬀerence stems from the fact that the paramagnet and the Einstein solid are not gases. Consequently each particle has a constant position distinguishing it from its neighbors. Hence, even though the spins of the paramagnet are identical, and so are the oscillators of the Einstein solid, the method of characterizingthe macroscopic states is not by using occupation numbers but by specifyingthe quantum state of each of the spins or the oscillators. For the paramagnet, there is one state in which all the spins are pointingalong the ﬁeld and N diﬀerent states in which a single spin points opposite to the ﬁeld and all the others point along the ﬁeld. In contrast, if we think of the spins as identical particles which are indistinguishable, then we have to count all of these N possibilities as a single quantum state. This diﬀerence in points of view allows us to write the partition func- tion of the paramagnet and the Einstein solid as a product of single par- ticle partition functions, but does not allow us to do it for the partition function of a gas of identical particles. Solutions to exercises in the text 517 Solution 2.6 Exercise on page 463 We write (5.2.6) in more detail as ∑ n1,...,nk,... exp{β[(µ − ϵ1)n1 + ... +(µ − ϵk)nk + ...]} . Since the summation is over all possible values of the occupation numbers in an independent manner, it is possible to replace the sum of products by a product of sums: Z (T, V, µ)= ( ∑ n1 e β(µ−ϵ1)n1 ) · ... · ( ∑ nk e β(µ−ϵk)nk ) · ... , and this is exactly Eq. (5.2.7). Solution 3.1 Exercise on page 467 The valence of sodium and potassium is 1, namely each of the atoms has a single outer electron. Hence the density of conduction electrons is equal to the number of atoms per unit volume. Sodium has an atomic weight of 23, namely 23 grams contain an Avogadro number of atoms. Its density is 0.97g/cm3, and hence nc(Na) = 6.02 × 1023 × 0.97 23 =2.5 × 10 22 cm−3 =2.5 × 10 28 m −3 . The atomic weight of potassium is 39 and its density is 0.86 g/cm3, hence nc(K) = 1.3 × 10 22 cm−3 =1.3 × 10 28 m −3 . Solution 3.2 Exercise on page 468 In averaging (5.3.2) we have to calculate the sum of averages: ⟨v⟩ = ⟨v0⟩− e m E⟨t⟩ . ⟨v0⟩ is the average of all the electron velocities immediately after their last collision. Because the motions of the electrons are independent of each other, and their collisions with the ions are random, ⟨v0⟩ must vanish. In the second term we must calculate the average time elapsed since the last collision. This is exactly the mean free time τ , of Part I (Sec. 3.2). This leads to Eq. (5.3.3). 518 Solutions to exercises in the text Solution 3.3 Exercise on page 468 When the electric ﬁeld is uniform alongthe wire, the potential diﬀerence between the edges of a segment of length L is V = E · L. Since the ﬁeld is uniform, Eq. (5.3.5a) implies that the current density is also uniform, and the current crossingthrough the entire section, of area A,is I = JA. By substitutinginto (5.3.5a) we obtain I A = σV L ⇒ I = ( σA L ) V. We can identify the prefactor of the potential as the conductance, and thus the resistance is R = L σA = ρL A . ρ is the resistivity of the material. Solution 3.4 Exercise on page 468 Suppose we “mix” the isothermal atmosphere until a uniform density is obtained and then allow it to evolve spontaneously. In this case a down- ward current will be created, in exactly the same way that an electron current results when an electric ﬁeld is applied. In contrast to the electric case, the molecular current cannot continue indeﬁnitely, since the atmo- sphere has a bottom. As a result more molecules accumulate near the bottom, giving rise to a density gradient, which in turn creates an upward diﬀusive current. This drives the system towards equilibrium where the two currents must be equal, as we have seen in Part I (Sec. 3.5). In contrast, the electrons arriving at the edge of the segment of the wire can cross it and continue alongthe electrical circuit, eventually returning from the other side of the wire by way of the voltage source. Hence no density gradients appear along the wire, and no diﬀusive currents. Solution 3.5 Exercise on page 470 (a) The numerator on the right hand side has the dimensions of momen- tum: [ √mkT ]=[M ][v]= kg · ms −1 =J · sm−1 . Resistivity has the dimensions of resistance × length, or [ρ]= Ω · m= V · m A = J · m C · A = J · m · s C2 . The whole denominator has the dimensions of [ne 2ρ]=J · sm −2 . Solutions to exercises in the text 519 Hence, the dimensions of the right hand side are J · sm−1 J · sm−2 =m . (b) The mean free path is given approximately by the product of the average speed between collisions, ¯v, and the mean free time. The average speed according to the Drude model is the thermal speed obtained from the Boltzmann distribution: 1 2 m¯v2 ≈ 3 2 kT , and using(5.3.5b), ℓ ≈ ¯vτ ≈ m¯v ne2ρ = √ 3mkT ne2ρ . Solution 3.6 Exercise on page 471 We use Eq. (5.3.10) to calculate ℓD. One must ﬁrst calculate the density of conduction electrons, n. Since an amount of A grams contains an Avogadro number, N0, of atoms, the density of atoms per unit volume is N0d/A,where the mass density d is expresseding/cm3. Since each atom contributes v conduction electrons, n = vN0d A , where n is in units of cm−3. Hence, substitutingin Eq. (5.3.10), we obtain ℓD ≈ A √ 3mkT vN0de2ρ . For Li at T = 77 K we substitute A =6.941×10 −3 kg,m =9.11×10 −31 kg,k =1.38×10 −23 JK −1,v =1 , N0 =6.02×10 23,d = 530 kgm −3,e =1.6×10 −19 C,ρ =1.04×10 −8 Ωm , and obtain ℓD =4.40 × 10 −9 m=44.0 ˚A . Note that we have expressed all the quantities in SI units in order to refrain from expressingthe electron charge and the resistivity in electrostatic units. The calculation of the remainingquantities in the table is carried out in exactly the same way, and there is no point in bringing it here. Do check for yourself several more values. 520 Solutions to exercises in the text Solution 3.7 Exercise on page 473 (a) Reconstitutingthe angular factor of 4π to the integral in (5.3.14) or calculating N directly from (5.3.12) usingEq. (5.1.11), we obtain N = 2V h3 ∫ d3p exp [β ( p2 2m − µ )] +1 . Since the number of electrons is an integral over all momenta, the number of electrons with momentum in the region d3p around p is given by the integrand [compare with the transition from Eq. (5.2.11) to Eq. (5.2.12)]. The probability for a given electron to have momen- tum in the region d3p around p is the number of electrons in this region divided by the total number of electrons, N : fp(p)d 3p = 2 nh3 d3p exp [ β ( p2 2m − µ)] +1 , where n = N/V . Substituting p = mv we obtain (5.3.15). (b) The normalization of f (v) is not automatic. It implies a relation between T, V, N and µ, e.g. Eq. (5.3.14). This is an expression of the fact that the independent variables we started with were T, V, µ.Once we have the thermodynamic potential and the average N is expressed in terms of T, V, µ, it is possible to invert the relation and, in principle, to express µ in terms of T, V and N . If we think of Eq. (5.3.14) as an equation from which it is possible to obtain such a relation, then it also serves as a normalization condition, 8π nh3 ∫ ∞ 0 p2dp exp [ β ( p2 2m − µ)] +1 =1 , and after the variable change p = mv we ﬁnd that f (v)isalso nor- malized. Solution 3.8 Exercise on page 474 (a) The variable change ϵ = mv2/2leads to dϵ = mvdv. Hence we obtain from (5.3.16) ⟨ϵ⟩ = 4π nh3 ∫ ∞ 0 (mv(ϵ))3dϵ eβ(ϵ−µ) +1 = 4π(2m)3/2 nh3 ∫ ∞ 0 ϵ3/2dϵ eβ(ϵ−µ) +1 . To bring the integral to the standard form of an average, ∫ ∞ 0 ϵfϵ(ϵ)dϵ , we deﬁne the energy distribution function according to Eq. (5.3.17a). Solutions to exercises in the text 521 (b) In order to verify that fϵ(ϵ) is normalized we calculate its integral, performingthe variable change ϵ = p2/2m: ∫ ∞ 0 fϵ(ϵ)dϵ = 4π(2m)3/2 nh3 ∫ ∞ 0 ϵ1/2dϵ eβ(ϵ−µ) +1 = 8π nh3 ∫ ∞ 0 p2dp exp [ β ( p2 2m − µ )] +1 , and the expression we obtained is indeed equal to 1 if Eq. (5.3.14) is satisﬁed. Solution 3.9 Exercise on page 475 In the limit T → 0 the integrand in (5.3.20) becomes ϵ1/2 for ϵ< µ0 and 0for ϵ>µ0. Hence, the region of integration is 0 ≤ ϵ<µ0,so that n = 4π(2m)3/2 h3 ∫ µ0 0 ϵ 1/2dϵ = 8π(2mµ0)3/2 3h3 , and Eq. (5.3.23) is obtained. Solution 3.10 Exercise on page 476 The energy of an electron is given by ϵ = 1 2m (p2 x + p2 y + p2 z) , and each of the momentum components is quantized. Since the energy depends only on the magnitude of p, the state with the lowest energy of the N electrons will be that in which the electrons are closest to the origin (of momentum space). In this state the electrons occupy all the states inside a sphere (the Fermi sphere) whose radius, pF , is determined by their number. ➤ px➤ ➤ py pF 522 Solutions to exercises in the text A two-dimensional projection of the three-dimensional case is illus- trated in the ﬁgure. The volume of this sphere is 4 3 πp3 F ,and the energy of the extremal states with momentum pF is p2 F /2m. If we show that this energy is equal to ϵF , as deﬁned in Eq. (5.3.23), we arrive at the required result. To this end we note that since a single state occupies a volume of h3 in phase space, the volume of a single state in momentum space (see ﬁgure) is h3/V . The number of states contained in the Fermi sphere is given by the ratio of its volume and the volume of a single state. But this is still to be multiplied by 2 in order to take into account the two spin states correspondingto each momentum state. Hence 2 4 3 πp3 F h3/V = N, which leads to the Fermi momentum, pF = ( 3n 8π )1/3 h, and the relationship to the Fermi energy ϵF = p2 F 2m is indeed satisﬁed. Solution 3.11 Exercise on page 477 To calculate ϵF usingEq. (5.3.23) we need the density of conduction elec- trons n, which was calculated in Solution 3.6 to be n = vN0d A . v is the number of conduction electrons contributed by each atom in the metal, N0 is Avogadro’s number, d is the mass density of the metal and A is the atomic weight. We thus obtain ϵF = h2 2m ( 3vN0d 8πA )2/3 . The values of v, A and d are given in Table 5.3.2 in cgs units, so we also express h, m and n in these units. We ﬁnd for Li ϵF = (6.626 × 10−27)2 2 × 9.11 × 10−28 (3 × 1 × 6.02 × 1023 × 0.53 8π × 6.941 )2/3 =7.5 × 10 −12 erg= 4.7eV . Solutions to exercises in the text 523 Note that in calculating the chemical potential at T = 0 we have used values of the density at room temperature, introducing an error of 1–2%. The Fermi velocity is vF = √ 2ϵF m = √ 2 × 7.5 × 10−12 9.11 × 10−28 =1.3 × 10 8 cm/s= 1.3 × 10 6 m/s . The calculation of ϵF and v for the other metals is performed in the same way. Do check out several more values for yourself. Solution 3.12 Exercise on page 477 We can calculate ⟨ϵ⟩ directly using(5.3.17). It is possible to write fϵ(ϵ) in a simpler form in terms of the Fermi energy: fϵ(ϵ)= 3 2ϵ 3/2 F · ϵ1/2 eβ(ϵ−µ) +1 . Usingthe approximation (5.3.22), we obtain ⟨ϵ⟩ = 3 2ϵ 3/2 F ∫ ϵF 0 ϵ 3/2dϵ = 3 2ϵ 3/2 F · 2 5 ϵ 5/2 F = 3 5 ϵF . Solution 3.13 Exercise on page 477 (a) At T = 0 all the lowest energy levels are ﬁlled with electrons, and hence there can be no electron with energy higher than ϵF . An elec- tron that is artiﬁcially inserted with an energy that is too high will thermalize and lose its excess energy, ϵ − ϵF , which will eventually reach the heat bath that maintains the electron gas at T =0. The energy added to the gas will thus be equal to ϵF . (b) Asin (a), itisimpossibleat T = 0 for there to be a “hole” at energy ϵ below ϵF . Hence, in order to maintain the temperature at T =0, the hole will be ﬁlled by an electron from above which will create a new hole which will be ﬁlled by an electron above it, and so on. The net result is the ﬁlling-out of the hole by an electron dropping down from the Fermi level to ﬁll the hole. The excess energy, ϵF − ϵ, eventually reaches the heat bath. Thus, the gas loses energy ϵF . Solution 3.14 Exercise on page 479 Substitute µ = 0 into (5.3.25) to obtain 2 3 ϵ 3/2 F = ∫ ∞ 0 ϵ1/2 eβϵ +1 dϵ . 524 Solutions to exercises in the text Perform the variable change x = βϵ to obtain 2 3 (βϵF ) 3/2 = ∫ ∞ 0 x1/2dx ex +1 , and this equation determines the required temperature in terms of ϵF . The integral is read in Eq. (5.A.13) of the appendix with ν =3/2. Its value is ( 1 − 1 √ 2 ) Γ ( 3 2 ) ζ ( 3 2 ) =0.678 , and hence βϵF =1.01 , or T =0.989TF . Solution 3.15 Exercise on page 480 At low temperatures the Fermi–Dirac occupation function (5.3.19) looks like a step function, and its derivative is signiﬁcantly diﬀerent from zero only in a narrow range around ϵ = µ (see ﬁgure). Note that we do not assume that µ = ϵF . ➤➤ µ ε d <nε > d ε – ➤➤ <nε> µ ε In order to use this fact we integrate (5.3.29) by parts so that instead of nϵ its derivative will appear. The integral on the right hand side of (5.3.29) becomes Il = 2 2l +3 ∫ ∞ 0 nϵ [ d dϵ ϵ l+3/2] dϵ = − 2 2l +3 ∫ ∞ 0 dnϵ dϵ ϵ l+3/2dϵ , (i) where wehaveusedthe fact that nϵ vanishes fast for ϵ →∞. Clearly, the principal contribution to the integral in (i) comes from the region around ϵ = µ. Hence we expand the function ϵl+3/2 around this point and take the ﬁrst terms. A Taylor expansion around ϵ = µ yields, to Solutions to exercises in the text 525 the second order, ϵ l+3/2 = µ l+3/2 + (l + 3 2 ) µ l+1/2(ϵ − µ) + 1 2 ( l + 3 2 )( l + 1 2 ) µ l−1/2(ϵ − µ) 2 + ... (ii) Substitutingthis into (i) we obtain to the second order Il ≈− 2 2l +3 µ l+3/2 ∫ ∞ −∞ dnϵ dϵ dϵ − µ l+1/2 ∫ ∞ −∞ dnϵ dϵ (ϵ − µ)dϵ − 1 2 ( l + 1 2 ) µ l−1/2 ∫ ∞ −∞ dnϵ dϵ (ϵ − µ) 2dϵ . (iii) In addition to substituting(iii), for mathematical convenience we extended the range of integration to negative values of ϵ, justiﬁed by the fact that dnϵ/dϵ vanishes for ϵ ≪ µ. The next step is to perform the variable change x = β(ϵ − µ) , which renders the function dnϵ/dϵ symmetric around x =0, and the “step” in nϵ is translated to x = 0. Explicitly nϵ(x)= 1 ex +1 , (iv) dnϵ dx = − ex (ex +1)2 = − 1 4cosh2(x/2) . (v) Equation (iii) is rewritten in the form Il ≈− 2 2l +3 µ l+3/2 ∫ ∞ −∞ dnϵ dx dx − µ l+1/2(kT ) ∫ ∞ −∞ dnϵ dx xdx − 1 2 ( l + 1 2 ) µ l−1/2(kT ) 2 ∫ ∞ −∞ dnϵ dx x 2dx . (vi) We now note the following: • The integral in the ﬁrst term in (vi) is actually the diﬀerence between the values of nϵ at x →∞ and at x →−∞,which is −1. This is the principal contribution to Il. • The integrand in the second term is an odd function, whereas the region of integration is symmetric with respect to the origin. Hence the second term vanishes. • Makinguse of the fact that the integrand in the third term is an even function, and integrating by parts, yield ∫ ∞ −∞ dnϵ dx x 2dx =2 ∫ ∞ 0 dnϵ dx x 2dx = −4 ∫ ∞ 0 nϵxdx = −4 ∫ ∞ 0 x ex +1 dx = − π2 3 . The value of the last integral is found from the appendix. 526 Solutions to exercises in the text Substitutingin (vi) we obtain Il ≈ 2 2l +3 µ l+3/2 + (l + 1 2 ) π2 6 µ l−1/2(kT ) 2 , (vii) which, when substituted in (5.3.29), gives (5.3.30). We summarize the stages of the calculation of Il: (1) Integration by parts. (2) The expansion of ϵl+1/2 around ϵ = µ up to the second order. (3) Extension of the range of integration to −∞ <ϵ< ∞. (4) The variable change x = β(ϵ − µ). (5) Calculation of the ﬁrst integral in (vi). (6) Notingthat the second integral vanishes (parity). (7) Calculation of the third integral with the help of parity properties and the appendix. Solution 3.16 Exercise on page 481 (a) Equation (5.3.31) implies that (µ/ϵF )3/2 is somewhat smaller than 1: ( µ ϵF )3/2 ≈ 1 − π2 8 (kT )2 ϵ 3/2 F µ1/2 . In order to obtain the ﬁrst correction in the temperature we substitute µ = ϵF on the right hand side. Any correction to µ in the denominator will produce terms of higher order than T 2. Invertingthe power in the above equation and expandingaccording to (1 − x)p ≃ 1 − px,we have µ ϵF ≈ [ 1 − π2 8 ( kT ϵF )2]2/3 ≈ 1 − π2 12 ( kT ϵF )2 . This leads to Eq. (5.3.32). (b) Substituting n = 1 in (5.3.30) we obtain ⟨ϵ⟩≈ 3 5 µ5/2 ϵ 3/2 F + 3π2 8 µ1/2(kT )2 ϵ 3/2 F . In order to obtain the T 2 correction we insert Eq. (5.3.32) for µ.In the second term on the right hand side it suﬃces to substitute µ = ϵF , since any correction to µ will produce terms of order higher than T 2. In the ﬁrst term we must include in µ5/2 also the term with T 2 and then expand in T , i.e. µ 5/2 ≈ ϵ 5/2 F [ 1 − 5π2 24 ( kT ϵF )2] . Solutions to exercises in the text 527 Overall we obtain ⟨ϵ⟩≈ 3 5 ϵF [ 1 − 5π2 24 ( kT ϵF )2] + 3π2 8 (kT )2 ϵF = 3 5 ϵF + π2 4 (kT )2 ϵF , which is Eq. (5.3.33). Solution 3.17 Exercise on page 482 The phonon contribution to the speciﬁc heat is given by (4.3.18) as Cph = Nk · 12π4 5 ( T ΘD )3 , while that of the electrons is Cel = Nk · π2 2 T TF . Equatingthe two contributions we obtain T = √ 5 24π2 Θ 3 D TF . The Fermi temperature of lithium is 5.5 × 104K (Table 5.3.3), and the equality is obtained at a temperature of 5 K. Solution 3.18 Exercise on page 484 The Fermi wavelength is the de Broglie wavelength corresponding to an electron with Fermi energy: λF = h pF = h √ 2mϵF . We ﬁrst calculate λF for ϵF =1eV: λF (1 eV) = 6.626 × 10−34 √ 2 × 9.11 × 10−31 × 1.6 × 10−19 =12.27 ˚A , and then, if ϵF is in units of eV, λF is obtained in ˚A, by λF = 12.27 √ ϵF . Thus, for example for Li, we obtain λF =5.66 ˚A. Do calculate the other values yourself and ﬁll out the table. Solution 4.1 Exercise on page 486 From (5.4.7) we obtain e −βµ − 1 ≈ 1 N , 528 Solutions to exercises in the text or βµ ≈− ln ( 1+ 1 N ) , and since N is macroscopic, we can expand the right hand side and obtain βµ ≈− 1 N , andthisisEq. (5.4.8). Substituting T =1 K,N =1022 yields µ ≈−1.4 × 10 −45 J= −8.6 × 10 −27 eV . Solution 4.2 Exercise on page 487 (a) To show that n increases with µ we calculate the derivative from (5.4.6): ∂n ∂µ = 2π(2m)3/2β h3 ∫ ∞ 0 eβ(ϵ−µ) · ϵ1/2dϵ [eβ(ϵ−µ) − 1]2 . The integrand on the right hand side is everywhere positive, and hence ∂n ∂µ > 0 . The maximum of n at µ = 0 is attained at the edge of the region of allowed values of µ. We further remark that the fact that n increases with µ is general, and is a manifestation of the fact that µ increases with n at constant T , expressingthe fact that particles tend to ﬂow from a high density region to a low density region. See, for example, Part III, Sec. 1.5. (b) Substituting µ = 0 into (5.4.6) we obtain n∗ = 2π(2m)3/2 h3 ∫ ∞ 0 ϵ1/2dϵ eβϵ − 1 = 2π(2mkT )3/2 h3 ∫ ∞ 0 x1/2dx ex − 1 , where x = βϵ. The integral can be calculated using Eq. (5.A.14) of the appendix, to give 1.306 √π.From here n∗ = 2.612(2πmkT )3/2 h3 , which is the result we sought. Solutions to exercises in the text 529 Solution 4.3 Exercise on page 489 (a) To obtain the dependence of µ on β we write Eq. (5.4.6) with x = βϵ: n = 2π h3 ( 2m β )3/2 ∫ ∞ 0 x1/2dx ex−βµ − 1 , (i) or nh3 2π ( β 2m )3/2 = ∫ ∞ 0 x1/2dx ex−βµ − 1 . (ii) When n is constant, the left hand side increases with β and so the integral on the right hand side must also increase with β.The right hand side is a monotonic increasingfunction of βµ, since the integrand is increasingat every point. Hence, βµ must become less negative as β increases. Since β itself increases, µ must increase with β and become less negative. (b) Substituting µ = 0 into Eq. (i) we obtain the same integral as in calculating n∗ in Exercise 4.2, and thus n = 2.612(2πmkT )3/2 h3 , (iii) and from here Eq. (5.4.12) is immediately obtained. Note the physical distinction between the two cases. In the previous exercise the density changed as a result of a change in the chemical potential. Here the density is constant, and it is the change in tem- perature that causes the change in the chemical potential. (c) UsingEq. (5.4.12) it is possible to express n in terms of Tc: n = 2.612(2πmkTc)3/2 h3 , (iv) and from Eq. (5.4.9) n∗ = 2.612V (2πmkT )3/2 h3 . (v) By dividingthe two we obtain n∗ n = ( T Tc )3/2 . (vi) (d) ne is the density of bosons occupyingthe excited states, and cannot be larger than the maximum n∗.When T< Tc, n∗ <n and therefore ne = n∗ and all other (n − n∗) bosons condensate in the ground state. When T> Tc, n∗ >n and only a tiny fraction of the bosons occupy the ground state and thus ne = n. 530 Solutions to exercises in the text Solution 4.4 Exercise on page 494 (a) In order to calculate Tc for helium we have to ﬁnd its atomic density. This can be obtained from its mass density, d,which is 0.14 g/cm3, and the atomic mass, which is four atomic mass units. Hence Tc = h2 2πmk ( d 2.612m )2/3 = h2 2πkm5/3 ( d 2.612 )2/3 = (6.626 × 10−27)2 2π × 1.38 × 10−16 × (4 × 1.66 × 10−24)5/3 ( 0.14 2.612 )2/3 =3.1K . (b) Instead of substitutingall the numerical values again, we note that the mass of a hydrogen molecule is half that of a helium atom and the mass density of hydrogen is 3/7 that of helium. Hence, to obtain the critical temperature of liquid hydrogen we have to multiply the critical temperature of He4 by 25/3 × (3/7)2/3,toobtain5.6 K. Since hydrogen liqueﬁes around 20 K and freezes at 14 K, this tem- perature range is too far from the value of 5.6 K, and we do not expect superﬂuidity in liquid hydrogen. Solution 4.5 Exercise on page 494 (a) The total energy of a boson gas can be calculated using the energy distribution function, (5.4.4). We write E = N ⟨ϵ⟩ = N ∫ ∞ 0 ϵf (ϵ)dϵ = 2πV (2m)3/2 h3 ∫ ∞ 0 ϵ3/2dϵ eβ(ϵ−µ) − 1 . Below the critical temperature µ =0, and with x = βϵ,we obtain E = 2πV (2m)3/2(kT )5/2 h3 ∫ ∞ 0 x3/2dx ex − 1 . The integral on the right hand side is calculated using the appendix [Eq. (5.A.14)], and its value is Γ ( 5 2 ) ζ ( 5 2 ) =1.006 √π. Substituting, we obtain E = 2.012V (2πm)3/2(kT )5/2 h3 . Solutions to exercises in the text 531 (b) First we calculate the average energy per particle in the excited levels (ϵ> 0) by dividingEq. (5.4.14) by Ne = N∗ = Vn∗ [with n∗ given by Eq. (5.4.9)]: E N∗ =0.770kT . Next, we express the relation between the number of excited parti- cles and the total number of particles usingSolution 4.3(c) for the correspondingdensities, to obtain E =0.770N ( T Tc )3/2 kT , which leads directly to the average energy per particle, E/N . Solution 4.6 Exercise on page 496 Writingthe integrand in Eq. (5.4.16) as one fraction we obtain n∗ − n = 2π(2m)3/2(e−βµ − 1) h3 ∫ ∞ 0 eβϵϵ1/2dϵ (eβϵ − 1)(eβ(ϵ−µ) − 1) . Since µ is small, the major contribution to the integral comes from regions of small ϵ. We expand the exponentials in the integrand to linear order, and obtain n∗ − n ≈−µkT · 2π(2m)3/2 h3 ∫ ∞ 0 dϵ ϵ1/2(ϵ − µ) . Substituting ϵ = u2, ∫ ∞ 0 dϵ ϵ1/2(ϵ − µ) =2 ∫ ∞ 0 du u2 − µ = 2 √ −µ tan−1 ( u √ −µ )∣ ∣ ∣ ∣ ∞ 0 = π √ −µ . Hence n∗ − n = 2π2kT (2m)3/2√ −µ h3 . Solvingfor µ, the middle expression in Eq. (5.4.17) is obtained. In order to express the temperature dependence in terms of Tc,to obtain the rightmost expression of Eq. (5.4.17), we write n∗ = n ( T Tc )3/2 532 Solutions to exercises in the text (see Exercise 4.3). Hence µ ≈− h6 32π4m3 ( n kT )2 [( T Tc )3/2 − 1 ]2 . We note that [see (5.4.12)] h6n2 8π3m3 =2.612 2(kTc) 3 , and hence we can write µ ≈− (kTc)3 4π · ( 2.612 kT )2 [( T Tc )3/2 − 1 ]2 = − kT 4π [ 2.612 ( Tc T )3/2]2 [( T Tc )3/2 − 1 ]2 , which leads to the the rightmost expression in (5.4.17). Solution 4.7 Exercise on page 496 From Eq. (5.4.18) we obtain E∗ − E = 2πV (2m)3/2(e−βµ − 1) h3 ∫ ∞ 0 eβϵϵ3/2dϵ (eβϵ − 1)(eβ(ϵ−µ) − 1) . Since µ is small we expand the exponential in front of the integral. But we cannot expand the factors in the denominator of the integrand, as was done in the solution of the previous exercise, since the integral obtained in this way does not converge. To calculate the integral we use the fact that it converges for µ = 0. After thevariablechange x = βϵ we obtain E∗ − E ≈−µ 2πV (2mkT )3/2 h3 ∫ ∞ 0 exx3/2dx (ex − 1)2 . Denotingthe integral by I and integrating by parts, we obtain I = − ∫ ∞ 0 x 3/2 d dx [ 1 ex − 1 ] dx = 3 2 ∫ ∞ 0 x1/2dx ex − 1 = 3 2 · 1.306 √π, where the last integral was calculated in Solution 4.2 using (5.A.14). We arrive at E∗ − E ≈− 3 2 µ · [ 2.612V (2πmkT )3/2 h3 ] , where the expression in the square brackets is N∗(= Vn∗) [Eq. (5.4.9)]. From here Eq. (5.4.19) is immediately obtained. Solutions to exercises in the text 533 Solution 4.8 Exercise on page 499 (a) Substituting p′ = p − ¯hq into the energy equation we obtain p2 2M = p2 − 2¯hq · p +(¯hq)2 2M + ϵ(q) . The initial kinetic energy term drops out of both sides. Writing p = M v,weobtain 0= −¯hq · v + (¯hq)2 2M + ϵ(q) , which leads to Eq. (5.4.23). (b) q is the wave number of a phonon in liquid helium. It can be at most 2π/a,where a is the interatomic distance, which is of the order of 1 ˚A. Hence, q< 6˚A−1. Next we show that indeed (¯hq)2 2M ≪ ϵ(q) . We substitute M ∼ 1g,toﬁnd that (¯hq)2 2M ≈ 10 −67erg ∼ 10 −55 eV . This energy is smaller by many orders of magnitude than typical phonon energies, which are ϵ ≈ ¯hvsq ∼ 10 −14 erg ∼ 10 −2 eV , where vs, the speed of sound in liquid helium, is about 240 m s−1. Hence, for a macroscopic body, even a thousand times lighter, ¯hq · v = ϵ(q) . Solution 4.9 Exercise on page 501 (a) Measuringthe slope near the origin we obtain ∆q =0.6 ˚A −1 , ∆ϵ k =10.77 K , and since the slope of the graph of ϵ versus q is ¯hvs, ¯hvs = ∆ϵ ∆q ⇒ vs = ∆ϵ ¯h∆q = 10.77 × 1.38 × 10−23 1.05 × 10−34 × 0.6 × 1010 = 236 m s −1 , and this value is very close to the speed of sound in liquid helium. 534 Solutions to exercises in the text (b) The critical speed is obtained from the solution of Eq. (5.4.26), which is equivalent to the solution of (5.4.24) for the value at the minimum point of the dispersion curve: vc = 8.67 × 1.38 × 10−23 1.05 × 10−34 × 1.94 × 1010 =59 m s−1 . Solution 4.10 Exercise on page 503 The description of He II as a boson gas below its condensation temper- ature is not very accurate. In a description that takes into account the interatomic forces, He II behaves as a phonon gas. As we have seen in Part IV, the speciﬁc heat of a phonon gas at low temperatures is propor- tional to T 3 and not to T 3/2. Thus we expect the speciﬁc heat of He4 at low temperatures to behave this way. And indeed experiments show that this is the case below a temperature of 0.6 K. Solution 4.11 Exercise on page 503 Substitutingthe mass density of liquid He 3, d, and its atomic mass, Eqs. (5.3.23) and (5.3.24) give TF = h2 2mk ( 3n 8π )2/3 = h2 2m5/3k ( 3d 8π )2/3 =4.5K . Solution 4.12 Exercise on page 505 Substituting(5.4.29a) into (5.4.30), we obtain η ≈ mvF 3σ ( ϵF kT )2 , and usingthe expression for the Fermi energy, Eq. (5.3.23), we have η ≈ h5 12σm2(kT )2 ( 3n 8π )5/3 . Namely, (a) η ∝ 1/m2; (b) At constant T , η ∝ n5/3. Note the signiﬁcant diﬀerence between this behavior and the behavior of the viscosity of a classical gas; see Exercise 3.14 of Part I. Solutions to exercises in the text 535 Solution 4.13 Exercise on page 506 Since the bosons in this case are pairs of He 3 atoms, we substitute into Eq. (5.4.12) the mass of two He3 atoms, which we shall denote by 2m, and for the density, one half that of ordinary He 3.We thus obtain Tc = h2 25/3 · 2πmk ( n 2.612 )2/3 = h2 (2m)5/32πk ( d 2.612 )2/3 , where d is the mass density of liquid He 3 and m is the mass of a He3 atom. Substitutingthe numerical values we obtain Tc =0.98 K . Solutions to self-assessment exercises Solution 1 Exercise on page 512 (a) The grand canonical partition function given in Eq. (5.1.3) can be written usingthe general form of the canonical partition function of an ideal gas (with the Gibbs correction), i.e. Eq. (3.5.3): Z = ∞∑ N =0 e βµN zN N ! . (i) This equation can also be written in the form Z = ∞∑ N =0 (zeβµ)N N ! =exp[z exp(βµ)] . (ii) The thermodynamic potential is obtained from (5.1.8): Ω= −kT ln Z = −kT ze βµ , (iii) and the average number of particles is obtained from (5.1.10): ⟨N ⟩ = − ∂Ω ∂µ = ze βµ = − Ω kT , (iv) andthisisthe required relation. (b) The probability for there to be exactly N particles in the container can be obtained from an inspection of (5.1.3), since the partition function is the sum of all the (unnormalized) probabilities, or from (5.1.1), and a summation over all the microscopic states with a constant number of particles, N . In both ways we obtain PN = Z −1e β(µN −F ) = Z −1e βµN Z(T, V, N ) . (v) If we write    Z = e−βΩ , Z = zN N ! , (vi) 536 Solutions to self-assessment exercises 537 we obtain from (v) PN = eβΩ(zeβµ)N N ! , (vi) and with the help of (iv) we obtain the required result. Solution 2 Exercise on page 512 (a) Indeed, the free energy depends on N . However, N is not the number of phonons in the crystal but the number of molecules in it as well as the number of its diﬀerent modes of vibration. When we describe the vibrations of the crystal as a gas of phonons, the number of phonons is arbitrary and is not subject to any restriction. Hence we can calcu- late the free energy from the canonical partition function, Eq. (5.2.5), without the constraint (5.2.2): Z =   ∞∑ n1=0 e −βϵ1n1   · ... ·   ∞∑ nk=0 e −βϵknk   · ... (i) Each occupation number nk is the number of phonons with that k and it varies between zero and inﬁnity, since phonons are bosons. The free energy is, therefore, the sum over all the vibration modes {k},exactly as in calculatingΩ: F = −kT ln Z = kT ∑ k ln(1 − e −βϵk) . (ii) This sum cannot depend on the number of phonons, which we will here denote by NP , but it does depend on the number of molecules in the crystal, N . Hence the chemical potential of the phonon gas is µP = ∂F ∂NP =0 . (iii) (b) In order to calculate the energy from the grand canonical partition function, it is not enough to diﬀerentiate ln Z with respect to β as we did in the canonical case, since ∂ ln Z ∂β = µN − E. (iv) But, if we also express N in terms of the partition function, we obtain our goal. We do this using Eq. (5.1.7), to obtain E = µN − ∂ ln Z ∂β = µ β ∂ ln Z ∂µ − ∂ ln Z ∂β . (v) 538 Solutions to self-assessment exercises We now use Ω, for a boson gas: ln Z (B) = −βΩ(B) = − ∑ k ln(1 − e −β(µ−ϵk)) , (vi) and substitutingthis into (v) we obtain E = µ β ∑ k βeβ(µ−ϵk) 1 − eβ(µ−ϵk) − ∑ k (µ − ϵk)eβ(µ−ϵk) 1 − eβ(µ−ϵk) = ∑ k ϵkeβ(µ−ϵk) 1 − e−β(µ−ϵk) = ∑ k ϵk eβ(ϵk−µ) − 1 , (vii) which is exactly the required expression for bosons. For a fermion gas we use ln Z (F ) = −βΩ(F ) = ∑ k ln(1 + e β(µ−ϵk)) , (viii) and substitutinginto (v) we obtain this time E = µ β ∑ k βeβ(µ−ϵk) 1+ eβ(µ−ϵk) − ∑ k (µ − ϵk)eβ(µ−ϵk) 1+ eβ(µ−ϵk) = ∑ k ϵkeβ(µ−ϵk) 1+ eβ(µ−ϵk) = ∑ k ϵk eβ(ϵk−µ) +1 , (ix) which is the required result. Solution 3 Exercise on page 513 First we calculate the thermodynamic potential Ω from Eq. (5.2.9a), as a sum over single particle states, which are eigenstates of momentum. For three-dimensional motion d3p includes Vd3p/h3 states and for the volume element of a two-dimensional motion d2p includes Ad2p/h2 states. We thus obtain the two-dimensional analogof Eq. (5.3.12): Ω= −kT A ∫ ln { 1+exp [ β ( µ − p2 2m )]} d2p h2 . (i) Integrating over all directions in momentum space using polar coordinates we obtain Ω= − 2πAkT h2 ∫ ∞ 0 ln { 1+ exp [ β ( µ − p2 2m )]} pdp . (ii) From (5.1.10) N = − ∂Ω ∂µ = 2πA h2 ∫ ∞ 0 pdp exp [β ( p2 2m − µ )] +1 , (iii) Solutions to self-assessment exercises 539 and with the usual change of variables, x = βϵ = βp2 2m ,dx = βp m dp , (iv) we have, for the two-dimensional density n, n = N A = 2πmkT h2 ∫ ∞ 0 dx ex−βµ +1 . (v) This equation is an implicit relation between n and µ. In the present case it is possible to calculate the integral as ∫ ∞ 0 dx ex−βµ +1 = ∫ ∞ 0 eβµ−x 1+ eβµ−x dx = − ln(1 + e βµ−x) ∣ ∣ ∣ ∣ ∣ ∞ 0 =ln(1 + e βµ) . From here n = 2πmkT h2 ln(1 + e βµ) , (vi) and invertingwe have 1+exp(βµ)= exp ( nh2 2πmkT ) , from which we ﬁnd µ(T, n): µ = kT ln [ exp ( nh2 2πmkT ) − 1 ] . (vii) Solution 4 Exercise on page 513 (a) The pressure is obtained by diﬀerentiatingthe thermodynamic poten- tial with respect to the volume. From Eq. (5.1.6) with Eq. (5.3.13) we obtain P = 8πkT h2 ∫ ∞ 0 ln { 1+exp [ β ( µ − p2 2m )]} p2dp . If the gas is degenerate, there are no electrons above the Fermi energy ϵF , or above the Fermi momentum pF . In order to use this and the fact that the occupation function behaves like a step function, we integrate by parts to ﬁnd that P = 8πkT 3h3 ∫ ∞ 0 p3 d dp ln { 1+ exp [ β ( µ − p2 2m )]} dp (i) = 8π 3h3m ∫ ∞ 0 p4dp exp [β ( p2 2m − µ )] +1 . (ii) 540 Solutions to self-assessment exercises Now, we use the fact that the occupation number appearingin the integrand vanishes above pF and is equal to unity below pF so that P = 8π 3mh3 ∫ pF 0 p4dp = 8πp5 F 15mh3 . (iii) Using(5.3.23) we express the Fermi momentum in terms of the density and obtain P = 8π 15mh3 [ h 5 ( 3n 8π )5/3] = ( 3 8π )2/3 h2n5/3 5m . (iv) Asimpler way of obtainingthesameresultis to use thefreeenergy F = E − TS.At T =0, F = E and we can calculate the pressure from the energy: P = − ( ∂F ∂V ) N = − ( ∂E ∂V ) N , (v) and we obtain the energy using the average energy at T = 0 calculated in Exercise 3.12: E = 3 5 NϵF = ( 3 8π )2/3 3h2 10m N 5/3 V 2/3 . (vi) By diﬀerentiating E we obtain the pressure as in Eq. (ii). Note that the pressure and the energy density E/V satisfy the usual nonrelativistic relation [Eq. (1.1.6)]: P = 2 3 E V . (vii) (b) The electron density in aluminum is obtained usingthe data appearing in Table 5.3.2 (see Solutions 3.1 and 3.6 as well): n = vN0d A =1.8 × 10 23 cm−3 =1.8 × 10 29 m −3 , (viii) and substitutinginto Eq. (iv) we obtain P =1.4 × 10 11 N/m2 ≈ 1.4 × 10 6 atm. (ix) Solution 5 Exercise on page 513 (a) For extremely relativistic particles, ϵ(p)= cp. Thus we cannot use the energy distribution function obtained in Eq. (5.3.17a). We begin, therefore, from Eq. (5.2.11a). The number of states per unit volume in phase space does not change when the particles become relativistic. Solutions to self-assessment exercises 541 The only change is in the relation between the momentum and the energy. Thus we obtain from (5.2.11a) N = 2V h3 ∫ d3p exp{β[ϵ(p) − µ]} +1 = 8πV h3 ∫ ∞ 0 p2dp exp{β[ϵ(p) − µ]} +1 . This is, after integrating over all angles, the generalization of Eq. (5.3.14). Writing cp = ϵ, n = 8π (hc)3 ∫ ∞ 0 ϵ2dϵ eβ(ϵ−µ) +1 , (i) and the energy distribution function is identiﬁed as fϵ(ϵ)= 8πϵ2 n(hc)3 · 1 eβ(ϵ−µ) +1 . (ii) When the gas is degenerate the occupation number is a step function [like (5.3.22)], and the relativistic Fermi energy, ϵR,is obtained from n = 8π (hc)3 ∫ ϵR 0 ϵ 2dϵ = 8πϵ3 R 3(hc)3 , hence ϵR = hc ( 3n 8π )1/3 . (iii) We can write fϵ(ϵ)interms of ϵR in the form fϵ(ϵ)= 3ϵ2 ϵ3 R 1 eβ(ϵ−µ) +1 . (iv) The average energy is, in the degenerate case, ⟨ϵ⟩ = ∫ ∞ 0 ϵfϵ(ϵ)dϵ = 3 ϵ3 R ∫ ϵR 0 ϵ 3dϵ = 3 4 ϵR , (v) and the energy density, E V = n⟨ϵ⟩ = ( 3 8π )1/3 × 3 4 hcn4/3 . (vi) The energy density in the relativistic case is proportional to n4/3,in contrast to the nonrelativistic case, in which it is proportional to n5/3. Such a relativistic treatment is required when the average energy per particle is much larger than its rest energy. Since the average energy is of the same order of magnitude as ϵR we can write ϵR ≫ mc 2 , 542 Solutions to self-assessment exercises and from here h mc ≫ ( 8π 3n )1/3 . (vii) The left hand side is the wavelength that characterizes the quantum motion of the relativistic particle and is called the Compton wave- length. Condition (vii) requires, therefore, that the average distance between particles in the gas be much smaller than their Compton wavelength. For an electron, the Compton wavelength is 0.02 ˚A, and the relativistic correction appears only at very high electron densities (above 1030 cm−3). Such densities do not exist on earth. It is possible to ﬁnd such densities in dense stars, such as white dwarfs, whose mass is the same as the sun’s and whose radius is a hundredth of its radius. In fact such stars do not collapse under their self-gravity even though their nuclear fuel has run out, precisely due to the pressure of the degenerate electron gas. (b) The pressure can be calculated by diﬀerentiatingthe thermodynamic potential Ω with respect to V ,but at T = 0 it is simpler to use E. From (vi) E = 3 4 ( 3 8π )1/3 hcN 4/3 V 1/3 , (viii) and then P = − ( ∂E ∂V ) N = 1 4 ( 3 8π )1/3 hcn4/3 . (ix) Comparingthis to (vi) we obtain the regular relativistic relation be- tween the pressure and the energy density, (1.1.7): P = 1 3 E V . Solution 6 Exercise on page 513 (a) To calculate the pressure we write the potential Ω of Eq. (5.4.10) using(5.4.5): Ω=Ω0 + 2πV kT (2m)3/2 h3 ∫ ∞ 0 ϵ 1/2 ln(1 − e β(µ−ϵ))dϵ , and then P = − ( ∂Ω ∂V ) T,µ = − 2πkT (2m)3/2 h3 ∫ ∞ 0 ϵ 1/2 ln(1 − e β(µ−ϵ))dϵ . Solutions to self-assessment exercises 543 Note that the ﬁrst term, which represents the contribution of the bosons occupyingthe ground level, does not contribute to the pres- sure since these bosons have zero kinetic energy. Below the critical temperature, µ = 0 and we obtain P = − 2π(2m)3/2(kT )5/2 h3 ∫ ∞ 0 x 1/2 ln(1 − e −x)dx , where x = βϵ. We integrate by parts and use Eq. (5.A.14) to ﬁnd that∫ ∞ 0 x 1/2 ln(1 − e −x)dx = − 2 3 ∫ ∞ 0 x3/2dx ex − 1 = − 2 3 Γ ( 5 2 ) ζ ( 5 2 ) = −0.67 √π, (i) and P = 1.341(2πm)3/2(kT )5/2 h3 . (ii) The fact that the pressure is independent of the volume is because the system is below the critical temperature. In this case decreasing the volume does not increase the pressure but reduces the density of bosons in the excited states, n∗ [see (5.4.9)], transferringthem to the ground state. Comparison with the expression for the energy (5.4.14) gives once more P = 2 3 · E V . (iii) (b) Even when the fermion gas is fully degenerate the occupation of the ground level cannot become macroscopic as in the case of the boson gas, since the Pauli principle forbids this. Hence the relative error due to the fact that the contribution of the ground level is not included in Eq. (5.3.14), for instance, is negligible: of relative order 1/N . Solution 7 Exercise on page 513 To determine if the phenomenon of Bose–Einstein condensation occurs, we have to check the relation between the density of particles (per unit area) in the excited states ne and the chemical potential µ.If ne is bounded from above and hence also Ne = neA, particles added above the maximum of Ne will accumulate in the ground state, and Bose–Einstein condensation will occur. From Eq. (5.4.3) or (5.4.2), we obtain in the two-dimensional case ne = Ne A = 1 h2 ∫ ∞ 0 d2p exp [ β ( p2 2m − µ )] − 1 , 544 Solutions to self-assessment exercises and after integrating over the angles and changing to the energy variable, we obtain ne = 2πm ¯h 2 ∫ ∞ 0 dϵ eβ(ϵ−µ) − 1 . (ii) The right hand side is again a monotonic increasing function of µ. When µ → 0 the denominator vanishes in the low energy region and the integral diverges. To see this we note that at µ = 0, the integrand behaves as 1 eβϵ − 1 ∼ 1 βϵ , (iii) for small ϵ. The integral of such a function diverges. The reason why the corresponding integral in three dimensions does not diverge is that there is an additional factor of ϵ1/2 in the numerator, which causes the integrand to behave like ϵ−1/2 near ϵ → 0. The integral of ϵ−1/2 converges. This implies that ne is unbounded, and hence additional particles can be accommodated in the excited levels, and the ground level will not be occupied by a macroscopic number of bosons. It is true that as the energy ϵ decreases, the occupation number in- creases as implied by (ii), but this is not Bose–Einstein condensation, since for any ﬁnite number of particles µ< 0. In order to see the explicit dependence of µ upon ne, which is actually n, we calculate the integral as in Self-Assessment Exercise 3: n = 2πmkT h2 ∫ ∞ 0 dx ex−βµ − 1 = 2πmkT h2 ∫ ∞ 0 eβµ−x 1 − eβµ−x dx = − 2πmkT h2 ln(1 − e βµ) , and hence µ = kT ln [ 1 − exp ( − nh2 2πmkT )] . (iv) Note that µ (as well as βµ) is always negative and only vanishes in the limit n →∞ or T → 0. Solution 8 Exercise on page 513 Since the fermions are massless and have zero chemical potential, they can be created and destroyed freely like photons, and their number is not conserved. The average number of fermions at temperature T is obtained by substituting µ = 0 in the general expression for n which was obtained for extremely relativistic fermion gas in the solution of Self-Assessment Exercise 5: n = 8π (hc)3 ∫ ∞ 0 ϵ2dϵ eβϵ +1 . (i) Solutions to self-assessment exercises 545 The number of fermions per unit volume and per unit energy is thus nϵ(ϵ)= 8π (hc)3 ϵ2 eβϵ +1 . (ii) We transform to a frequency variable, using ϵ =¯hω,and write Eq.(i) as n = 1 π2c3 ∫ ∞ 0 ω2dω eβ¯hω +1 , (iii) and their density per unit frequency: nω(ω)= 1 π2c3 ω2 eβ¯hω +1 . (iv) It is instructive to compare with the correspondingexpression for photons, Eq. (4.4.13). The energy density of the fermions per unit frequency is obtained by multiplying nω(ω) by the fermion energy, ¯hω: ρ(ω)= 1 π2c3 ¯hω3 eβ¯hω +1 , (v) and we ﬁnd that the total energy density is an integral over all frequencies: u = 1 π2c3 ∫ ∞ 0 ¯hω3dω eβ¯hω +1 = (kT )4 π2(¯hc)3 ∫ ∞ 0 x3dx ex +1 . (vi) For the calculation of the integral we use Eq. (5.A.13) from the appendix. It gives the value 7 8 Γ(4)ζ(4) = 7 8 · π4 15 , (vii) and hence u = 7π5k4 15(hc)3 T 4 . The radiation density of a black body satisﬁes a similar law: uBB = 8π5k4 15(hc)3 T 4 [see Eqs. (4.4.16) and (4.4.17)] and their ratio is 7/8. Solution 9 Exercise on page 513 We begin from the condition µ+ + µ− =0 , (i) where µ± are the chemical potentials of e±, given implicitly by Eq. (i) or (ii) in the solution of Self-Assessment Exercise 5. If the gas is electrically 546 Solutions to self-assessment exercises neutral, the densities of the electrons and the positrons are equal and so are their chemical potentials: µ+ = µ− . (ii) Hence, µ± =0 . (iii) At extremely relativistic temperatures it is possible to neglect the mass of the particles and then we can use Eq. (i) in the solution of Self-Assessment Exercise 5 with µ = 0. The result is n± = 8π (hc)3 ∫ ∞ 0 ϵ2dϵ eβϵ +1 = 8π (hc)3 (kT ) 3 ∫ ∞ 0 x2dx ex +1 , (iv) with x = βϵ. The integral can be calculated using Eq. (5.A.13), and its value is 3 2 ζ(3). The density of electrons and positrons is, therefore, n± = 12πζ(3) (hc)3 (kT ) 3 . (v) Index absolute zero, 133, 239, 281, 283, 476 absorber, perfect, 391 absorbing power, 395, 443 absorption, 429 spectrum, 370 acceleration, 61, 255 average, 62 adiabatic, 187, 189 compression, 189 cooling, 281 equation, 127, 186 expansion, 17, 20 process, 126, 185 system, 214 Adkins, 133 aluminum, 513 angular deviations, 47 frequency, 243, 391 angular momentum, 138–141, 143, 359 component, 359 internal, 139, 358 of molecule, 356 orbital, 143, 177, 461, 516 quantum, 139, 358, 359 total, 177 annihilation, 405, 429, 485 antiquarks, 17 argon, 350 astronomical measurements, 398 atmosphere, isothermal, 20, 23, 29, 64, 468, 518 atom, neutral, 461, 516 atomic assumption, 35 level, 435, 438 structure of matter, 32 atoms, 121 free, 366, 373 identical, 373, 375, 378, 485 in ground level, 491, 497 number of, 421 of metal, 466 attraction, 330 eﬀective, 506 electron pairs, 507 energy, 330 force, 328, 340 region of, 330 average, 3, 8, 27, 28, 30, 37, 71, 85, 122, 137, 143, 144, 169, 195, 455 of a physical quantity, 316 of observable, 145, 167, 260 of v2 x,8 averaging time, 121 Avogadro’s law, 6, 8 Avogadro’s number, 10, 43, 250, 305, 517, 522 balance, detailed, 397 Bardeen, Cooper and Schrieﬀer (BCS theory), 507 big bang, 399 binding energy, 407, 441 black body, 391, 395, 397, 405, 427, 443, 447, 545 radiation, 376, 391, 394, 398, 453, 472, 513 spectral distribution of, 398 black hole, 399, 400 Bloch, F., 484 Bohr magneton, 139 Boltzmann, 4, 49, 125, 153, 167 constant, 10, 33, 43, 162, 235, 428 distribution, 6, 158, 165, 166, 464–466, 475, 479, 519 electron gas, 483 factor, 20, 123, 165, 179, 237, 254, 357, 360, 448, 475 formula, 164 gas, 447, 478, 490 limit, 486 statistics, 448 Born–Oppenheimer approximation, 352 547 548 Index Bose–Einstein analog, 485 condensation, 460, 489–493, 506, 513, 544 distribution, 246, 464, 485–487 particle, 460 statistics, 453, 505 boson(s), 247, 248, 453, 460–464, 486, 503 addition of, 489 atom, 461 average number of, 485 condensate, 529 free, 498 gas, 486, 489, 506, 534, 538 ideal, 490, 493, 503 in excited states, 489 in ground level, 489, 543 noninteracting, 487 two-dimensional, 513 liquid, 505 noninteracting, number of, 487 superﬂuid, 507 density of, 490 box, three-dimensional, 258, 269, 271, 292 Brillouin function, 208, 209, 333 Brown, Robert, 32, 33 Brownian motion, 32, 37, 39, 43, 45–47, 61, 62, 122 particle, 43, 49, 63 canonical ensemble, 166, 167, 176, 179, 214, 225, 229, 243, 254, 287, 293, 316, 453, 454, 461 distribution, 166, 261 partition function, 235, 278, 291, 455, 456, 459, 462, 536, 537 probabilities, 231, 233 system, 286 capacitor, 47, 48 capillary tube, 501 cavity, 386–388, 396, 445 at temperature, 443 of matter, 385 shape of, 387 center of mass, 11, 14–16, 18, 20, 37, 341, 344, 356–358 degrees of freedom, 362 energy, 80, 353 motion, 345, 361, 362, 365 of molecule, 416 variables, 347 velocity, 15 charge, 48, 259 density, 507 ﬂuctuations, 48 moving, 385 chemical equilibrium, 370, 448 constant, 369 formulae, 367 reaction, 6, 130, 339, 366, 367, 369, 405, 454 work, 130 chemical potential, 130–132, 187–189, 239, 241, 242, 280, 300, 351, 368, 370, 371, 403, 413, 420, 421, 429, 437, 448, 462, 473, 474, 478, 481, 487, 489, 513, 529 at T = 0, 475, 477, 523 change in, 414 constant, 494 constraint on, 463 decreases, 479 for monoatomic gas, 130 increases, 489 negative, 463 of phonon gas, 512, 537 of ideal gas, 449 of electrons, 449 of photon gas, 132, 448 temperature dependence of, 475, 495 tends to zero, 488 zero, 485, 489, 544 chlorine atomic, 403 isotope of, 415 nucleus, 415 classical approximation, 353, 375, 415, 464 behavior, 475 continuum, 249 gas, 272, 477 limit, 391, 392 mechanics, 18–20, 121, 125 statistics, 461 system, 260, 282, 334, 362 thermodynamics, 3 Clausius, 49, 128 COBE, 399 Coblentz, 394 collimator, 442, 443 collision(s), 10, 14, 18, 35, 39–41, 43, 46, 49, 51, 55, 56, 61, 93, 467, 468, 483, 497, 504 between molecules, 366 elastic, 7, 13, 15, 34, 88 ﬁrst, 50 Index 549 number of, 3 number per unit length, 55 of electrons, 47 random, 62, 80 time between, 3, 56, 61 with free particles, 497 with ions, 466, 517 with phonons, 502 with wall, average rate of, 51 compressibility, 393 Compton wavelength, 542 concentration gradients, 50 conductance, 518 conduction electrons, 505, 517, 522 number of, 467 conductivity, 453 conﬁguration(s), 24, 27, 141, 204, 239 number of, 192 of coordinates, 28 space, 143 conﬁnement, 231 conservation laws, 88, 122, 147 of energy, 124, 147, 179, 235 of momentum, 293 number of particles, 453 constituent, 18, 340, 341, 421 of molecule, 348 of gas, 313 constraints, 122, 147 continuity equation, 59 continuous degrees of freedom, 347 distribution, 75 energy, 18 momentum, 488 variable, 225 continuum approximation, 418 controlled quantity, 166, 454 variable, 473 Cooper pairs, 507 coordinate, 4, 28, 121, 226, 278, 341, 345, 458 and momenta, 225 distribution, 27 frame moving with liquid, 501 internal, 341, 346 of center of mass, 343 of particles, 24 relative, 343, 409, 416 copper, 140 correlation, 80, 151 cosmic background radiation, 398, 399, 404 cosmic neutrino particles, 513 covariance, 151, 152 creation of excitations, 501 critical speed, 499, 500, 502, 534 low, 502 critical temperature, 489, 490, 493, 506, 530, 543 above 100 K, 507 below, 494, 543 of Bose condensation, 494, 506 of He 4, 530 of liquid hydrogen, 530 for superﬂuidity, 501 cross section, 34, 51, 504 crystal, 140, 248, 251, 288, 306, 376, 377, 380, 381, 471, 512 cubic, 378 hard, 250 ionic, 140 perfectly periodic, 484 three-dimensional, 378 triatomic, 379 crystalline structure, 466 Curie, P., 171 Curie’s law, 171, 181, 217, 218, 333 current, 46, 47, 50, 56, 59, 66, 69, 134 circular, 138 density, 56, 57, 468, 518 direction of, 58 drift, 64 ﬂows, 57 of electrons, 466 of particles, 64 of the normal component, 493 without resistivity, 506 Dalton’s law, 12, 77, 225, 265, 280, 316 damping, 61 de Broglie momentum, 382, 458, 472 relation, 270 wavelength, 269, 527 of electron, 484 thermal, 271 waves, 268 Debye, 248, 251, 382, 384 approximation, 290, 327 frequency, 383 model, 252, 289, 326, 388, 390, 453, 480, 512 temperature, 482 degeneracy, 281, 282, 356, 360, 474 of ground state, 283 550 Index degenerate boson gas, 489, 503, 513 doubly, 403 electron gas, 476, 513 approximation, 479 Fermi gas, 478, 479, 489, 503, 513 ground state, 351 degrees of freedom, 4, 9, 16–19, 32, 80, 88, 121, 141, 153, 178, 225, 243, 249, 260, 283, 309, 317, 328, 362, 454 classical, two, 364 freeze, 365 internal, 348, 350, 366 frozen, 328, 356 per molecule, 125 total number of, 381 two, 362 unfreeze, 375 density, 3, 7, 21–23, 33, 50, 51, 64, 82, 242, 271, 439, 440, 474, 475, 478, 487, 488, 540 at room temperature, 523 average, 486 distribution, 64 gradient, 61, 64 high, 57 in isothermal atmosphere, 20 of atoms, 373, 439,440 of conduction electrons, 519 of constituents, 420 of electronic states, 486 of electrons, 449, 469, 475 and positrons, 405 low, 57, 448, 486, 489, 491, 528 of excited states, 490 of fermions, 504 of gas, 81 of He 3, 503 of hydrogen molecules, 369 of molecules, 56 74, 75, 318, 369, 373, 440 of particles, 487, 513 in ground level, 489 of photons, 446 of radiation, 443 of states, 474 two-dimensional, 539 uniform, 66, 67 zero, 488 diamagnetic, 138 diamagnetism, 507 diamond, 251 diatomic gas, 328, 362, 373, 440 molecule, 14, 19, 339, 342, 352, 362, 505 dielectric, 135 diﬀusion, 50, 61, 63 coeﬃcient, 49, 57 current, 64 equation, 59, 60 slow, 49 speed, 49 dimensional analysis, 30, 51, 87 dimensionless, 29, 83, 86 arguments, 273 variable, 170, 274 dimensions, 24, 29, 38, 57, 61, 75, 86, 87, 93 of energy, 157 of force, 89 of length, 86, 309, 470 of momentum, 518 of pressure, 25, 83 of space, 31, 42, 43 of volume, 309 dipole moment, 134, 135, 138 Dirac, 140 disorder, 174, 211, 277 dispersion curve, 534 ϵ(q), 498–502, 505 of a free particle, 502 dissipation, 33 dissociation, 366 degree of, 373, 375 energy, 374, 441 of diatomic gas, 373 of molecules, 370 of water, 370 distance, average, 56 distribution, 30, 56 Boltzmann, 469 function, 85, 87, 221, 474 classical, 472 in phase space, 267 moments of, 30 of directions, 76 of electron, 472 of radiation, 386, 425 of velocity, 24, 52 drag, 62 Drude, 466, 469 model, 469–472, 478, 482–484, 505, 519 Dulong–Petit law, 250, 251 value, 470 dynamical evolution, 3 model, 4, 121, 226 Index 551 dynamics, 156 laws of, 3 Newtonian, 4, 9 Einstein, Brownian motion, 32, 35, 37 general theory of relativity, 399 model of a solid, 251, 268, 276, 281, 289, 290, 325–327, 339, 363, 376, 383, 384, 398, 427, 461, 462, 516 temperature, 251 theory, modify, 252 solid, classical, 283 solid, quantum, 320 electric, 135 charge, 253 of electron, 507 conductivity, 466, 468, 469, 482, 504, 505 current, 56, 466, 467, 507 density, 468 dipole, 134 ﬁeld, 136, 389, 426, 518 uniform, 467, 468 force, 253, 505 repulsive, 340 polarization, 136 resistivity, 468, 484 electromagnetic ﬁeld, 388, 389 radiation, 9, 385, 390, 392, 429 theory, 134, 136 electromagnetism, 4 electron(s), 3, 17, 121, 138, 139, 340, 348, 352, 449, 453, 460, 461, 476, 504, 506, 527, 546 as fermion, 474 at high temperature, 474 average number of, 472 charge, 519 colliding with ions, 471 Compton wavelength, 542 deep, 483 density, 475, 481 eﬀective, 483 free, 467 gas, 477–480 relativistic, 448 in metal, 472 nonmagnetic, 178 number of, 470 outer, 517 pairs, 507 spin 1 2 , 472 statistical properties of, 471 velocities, 517 electron–positron pairs, 405 electronic, 350, 363, 365 degrees of freedom, 80 frozen, 351 energy level, 350, 436 excitation energy, 351, 366 levels, 403, 436 spins, 359 states, 19, 352 electrostatic constant, 259 units, 519 elementary particles, 405 emission, 429 of inﬁnite power, 428 rate of radiation, 391 spectrum, 370 emissive power, 397, 433 function, 395 emissivity, 387, 391, 397, 427, 443 per unit wavelength, 444 emittance, 443 emitted energy, maximal, 404 energy, 12, 13, 42, 75, 125, 131, 141, 144, 150, 157, 162, 165–167, 174, 175, 187–189, 192, 203, 219, 229, 235–239, 254, 255, 257, 258, 263, 278, 284, 296, 298, 308, 316, 317, 322, 330, 346, 357, 377, 379, 380, 384, 423, 454, 463, 496, 498, 500, 541 absorbed, 396, 397, 436 at equilibrium, 213 at minimum, 299 average, 67, 72, 122, 163, 167, 170, 181, 205, 212, 227, 237, 249, 250, 267, 289, 291, 298, 302, 305, 321, 324, 328, 330, 335, 383, 385, 390, 392, 456, 481, 512, 541 at T = 0, 540 of electron, 473 internal, 234, 263 kinetic, 8–11, 13–16, 18, 20, 27, 32, 77– 79, 84, 93, 256, 308 of oscillator, 246 of paramagnet, 332 per degree of freedom, 287 per molecule, 13, 88, 321, 361, 372 per particle, 494, 531 per spin, 217 changes, 370 characteristic, 172 552 Index conserved, 122 constant, 166, 167, 178, 453 surface, 255, 307 current, 67 decreases, 38 density, 384, 385, 387, 393, 394, 430, 513, 540–542 per unit volume, 390 dissipation, 38 distribution function, 13, 392, 444, 473, 480, 486, 504, 520, 530, 540, 541 erosion of, 33 exchange, 14, 153, 165, 167, 239, 248, 512 excitation, 80 ﬂow, 242 ﬂuctuation of ideal gas, 287 ﬂux, absorbed, 396 function, 454 function of state, 184 increase, 136, 163 internal, 189, 228, 234, 235, 238, 239, 291, 294, 311, 328, 329, 341, 342, 344, 346, 350, 353, 357, 360, 410, 411, 414 correction to, 411, 412 of diatomic molecule, 355, 356, 358 of ideal gas, 334 of molecule, 346, 349, 356 kinetic, 8, 16, 19, 20, 48, 163, 249, 254, 258, 263, 264, 292, 341, 409, 476, 483 level, 243, 244, 249, 314, 323, 347, 350, 351, 356, 358, 359, 445, 463, 523 lowest, 282 loss, 232, 502 maximal, 150 mechanical, 124, 334 minimal, 150, 153, 172 minimum, 377 most probable, 71, 240 near Fermi energy, 506 of triatomic molecule, 345 of center of mass, 16, 344 of crystal, 376 of electromagnetic ﬁeld, 137 of electron, 352, 521 of excitations, 498 of gas, 361, 481 of harmonic oscillator, 307, 374, 378 of internal motions, 16, 353 of ion, 331 of magnetic moment, 214, 217 of microscopic state, 230, 244, 260, 314 of molecule, 231, 352, 374 of microscopic state, 228, 237, 285, of oscillator, 244 of paramagnet, 299 of particle, 458 of quantum particle, 292 of radiation, 385 of reactants, 372 of reaction products, 372 of relative motion, 344 of single spin, 180 of state, 167, 462 of subsystem, 143 per degree of freedom, 213 range kT , 504 relativistic, 448 released in reaction, 441 rest, 541 scale, 449 separability of, 361 shifted, 298 single particle, 377, 459, 464, 472 molecule, 340 oscillator, 302, 424 sum of, 461 spacing, 365, 436 spectrum, 163 states of a liquid, 497 states low, 476 subnuclear, 19 susceptibility of, 286 thermal, 22, 33, 171, 172, 211, 247, 351 total, 14, 17, 28, 38, 78, 142, 166, 241, 264, 309, 341 kinetic, 80 of boson gas, 530 of liquid, 497 of particle, 254 of radiation, 393 of state, 461 transfer, 483 variation of, 129 zero point, 323, 374, 379 engine, 128 ensemble, 39, 143, 156, 226 averaging, 122 grand canonical, 453, 454, 461–463, 485 microcanonical, 122, 164, 166, 167, 178, 225, 238, 262 of harmonic oscillators, 392 state in, 455 enthalpy, 129, 133, 187, 214, 288, 322, 331, 410 entropy, 128, 129, 131, 158, 159, 162, 164, 172, 179, 190, 219, 228, 234–236, 239, Index 553 241, 248, 250, 263, 265, 273–275, 277, 280, 282, 289, 291, 296, 299, 306, 312, 314, 315, 319, 320, 323, 324, 332, 393, 411, 456 behavior of, 315 bounded, 320 change, 137, 158, 162, 190, 281, 319 correction to, 350 decrease, 163 diﬀerences, 128 extensive, 160 function of pressure, 311 increase, 128, 277 magnitude of, 174 maximal, 237 maximum, 159, 241, 300 of harmonic oscillator, 304, 305 of ideal gas, 128, 129, 188, 276 of mixture of gases, 280, 313 of paramagnet, 206 of photon gas, 132 of quantum system, 281 partial, 313, 319 per molecule, 411 additional, 349 per spin, 207 equation of motion, 89, 93, 377 equation of state, 6, 21, 125, 131, 183–185, 214, 242, 290, 317, 318, 327, 328, 330, 430, 446, 457 of relativistic gas, 331 equilibrium, 10, 11, 14, 20, 32, 33, 38, 39, 42–44, 47, 48, 53, 56, 78, 79, 156, 164, 179, 241, 284, 300, 367, 371–373, 385– 387, 422, 443, 467 at temperature T , 404 condition for, 64, 368, 421 constant, 370–372, 375, 441 deviation from, 49, 50 distance, 342, 345, 378, 407, 408 equation of reaction, 420 mechanical, 431 position, 248, 376–379 state, 4, 5, 8, 10, 12, 13, 18, 25, 61, 64, 75, 76, 157, 165, 281, 368, 372, 397 thermal, 13, 20, 21, 23, 33, 46, 71, 77, 148, 156, 158, 165 with cavity, 442 with heat bath, 254 equipartition, 256 energy, 80 law, 249, 309, 346, 392, 470, 476 for electrons, 470 of thermal energy, 13, 33 principle, 42, 44, 361 theorem, 14, 266, 267, 362 value, 362 ergodic hypothesis, 39, 63, 122 escape, rate, 53 velocity, 399 exact diﬀerential, 126, 186, 234, 235, 295 excitation, 501 atomic, 439 degree of, 244, 246, 384, 390 average, 247, 324, 464 collective, 498 in liquid, 502 creating, 501, 502 electronic, ﬁrst, 350 fundamental, 505 in liquid helium, 500 internal, 18 intranuclear, 80 momentum, 499 number, 322, 380 single, 500 expansion, isothermal, 334 Joule’s, 316, 349 extensive quantity, 130, 275, 287, 314 entropy, 153 variable, 125, 128, 130, 136, 214 external coordinate, 229 parameter, 164, 228 change of, 234 extremely relativistic gas, 513 Fermi, 133 energy, 475–478, 482–484, 522, 523, 527, 534, 539 close to, 507 relativistic, 541 level, 504, 523 liquid, 505 momentum, 476, 522, 539, 540 sphere, 476, 521, 522 system, 503 temperature, 476–478, 480, 481, 503 of lithium, 527 of metal, 478 velocity, 476, 477, 482, 483, 504 wavelength, 484, 527 Fermi–Dirac, 473 distribution, 464, 466, 471, 479, 483 function, 480 554 Index occupation, 479 function, 524 particle, 460 statistics, 453, 472 velocity distribution, 473 fermion(s), 460, 461, 463, 464, 486, 487, 503, 505, 506 occupation numbers of, 464 average number of, 544 energy, 545 gas, 485, 486, 538 ideal, 503, 505 two dimensional, 513 massless, 513, 544 ferromagnet, 138 Feynman, 63 ﬁeld, 135, 137, 216, 331 constant, 171, 172, 180, 207, 217, 218, 236 critical, Hc, 507 direction of, 173, 211 external, 135, 136, 170, 215, 217, 228, 258, 508 gravitational, 38, 228, 255, 259 small, 210 weak, 217, 218 ﬁlter, 386, 395, 442 ﬁlter-coated, 443 ﬂow inviscid, 497 liquid helium, 503 through capillaries, 491, 492 ﬂuctuation, 44, 225, 239, 285, 335 in resistor, 47, 48 of energy, 286, 291 thermal, 33, 47, 486, 502 focalplane,43 force, 6, 7, 12, 14, 39, 64, 82, 121, 122, 229, 267, 377 between atoms, absence of, 502 between molecules, 497 constant, 44, 65 elastic, 45 external, 49, 56, 61, 62, 89, 259, 261, 49749, 56, 61, 62, 89, 259, 261, 497 ﬁeld, 20, 81,228 interatomic, 491, 502, 505, 534 internal, 19, 20 mutual, 259 per unit area, 7 random, 4, 37, 39–41, 46 restoring, 46, 47 restraining, 37, 38 Fourier equation, 73 free energy, 131, 132, 188, 237–239, 241, 249, 262, 264, 273–275, 280, 288, 298, 305, 315, 319, 320, 323, 332, 334, 348, 353, 355, 361, 363, 380, 389, 390, 429, 455, 456, 477, 537, 540 minimal, 367 change, 368 in reaction, 370, 371 decrease, 239, 371 Helmholtz, 131, 227, 228, 235, 236, 296 independent of number of photon, 429 minimum, 239, 240 of crystal, 382 of electromagnetic radiation, 430 of gas of molecules, 365 of harmonic oscillator, 248, 304 of mixture, 312, 318 of monoatomic gas, 353 of paramagnet, 314 of photon gas, 132 of single molecule, 371 volume derivative of, 317 free path, 35 frequency, 248, 251, 252, 326, 353, 377, 378, 381, 385–388, 390, 391, 394, 397, 433, 444 distribution, 252 of oscillator, 322 of phonons, 388 of photon, 390 low, 427 friction, 37, 38, 46, 491, 498, 507 coeﬃcient, 37 force, 497 negligible, 12 phenomena, 33 function of state, 125, 128, 129 fundamental function, 238 gadolinium, 141, 177 galvanometer, 33, 46, 47 gas, 4, 8, 65, 71, 121, 136, 225, 227, 228, 339 constant, 250, 496 dense, 491 density, 82 dilute, 6, 72, 225, 265 degenerate, 539, 541 dilute, 51, 261 equation, 17 helium, 73 interstellar, 72 law, 14, 16 molecule, 3, 7, 226 Index 555 monoatomic, 8, 14, 17, 19, 329, 351, 413 noble, 50, 350 of bosons, 485 of diatomic molecules, 355 of electrons, positrons and photons, 405 of fermions, 462, 463, 512 degenerate, 503 of free electron, 469 of molecules, 71 of particles, 387 of phonons, 537 of photons, 388, 447 rare, 19 reaction, 404 Gaussian distribution, 154, 160, 182, 221 integral, 262 three-dimensional, 320 Gibbs, Willard, 4, 122, 235, 281 correction, 280, 283, 317, 375, 421, 536 free energy, 288, 322 paradox, 275, 371, 461 probability, 454 grand potential, 132, 456, 457 gravitation, 20, 21, 73 gravitational ﬁeld earth’s, 81 Newtonian, 83 uniform, 21 gravity, 253 ground level, 463, 476, 486, 490, 493, 498, 544 accumulate in, 495 doubly degenerate, 413 nondegenerate, 413 ground state, 247, 350, 356, 403, 434, 502, 505, 507, 513, 529 energy, 352, 363, 374 of electrons, 352 quantum-mechanical, 498 Guldberg, 369 gyromagnetic factor, 140, 143 harmonic approximation, 342, 352, 357, 376, 407, 408 oscillator, 243, 249, 269, 288, 308, 320, 324, 376, 388, 464 classical, 244, 255, 268 damped, 44 independent, 378 three-dimensional, 283, 497 potential, 31, 87, 267, 345 attraction, 329, 362 three-dimensional, 353 vibration, 424 Hawking, 399 He 3 atoms, 503, 504 pairs of, 505, 506, 535 He I, 491 He II, 491, 502 boils without bubbles, 491 two-component description of, 502 heat, 179, 235 absorbed, 372, 422 bath, 165, 167, 179, 237, 239, 241, 247, 248, 284 capacity, 19, 20, 127, 128, 218 at constant pressure, 349 at constant volume, 133 of solids, 398 per spin, 205 problem, 17, 250 ﬂow, 67, 493 reservoir, 122 transfer, 124, 126, 129, 136, 234, 238 helium, 350, 490, 491 atom, 351, 502 thin layer of, 492, 493 vapor, 492 Henshaw, 500 hydrogen, 421, 490 atom, 403 free, 370 molecule, 366, 530 ideal gas, 6, 27, 28, 125, 127, 180, 187, 214, 230, 242, 265, 268, 272, 274, 281–283, 313, 321, 327, 328, 351, 446, 447, 466, 470, 496, 536 classical (Boltzmann), 512 equation of state, 311, 263 law, 158, 225, 268 monoatomic, 72, 187 of molecules, 340 of phonons, 502 impurities, 484 induction, 47, 48 information, 174, 176 infrared region, 447 initial condition, 3, 42, 90, 93 insulator, 469 intensive parameters, 314 quantity, 157 variable, 125, 130, 136, 214, 275 interaction, 147, 340, 466 energy, 211 556 Index of magnetic moment, 506 interatomic distance, 356, 471, 483, 533 intermolecular distance, 20, 21, 54, 81 internal energy average change of, 233 excess, 477 internal motions in molecule, 365 internal structure, 13, 14, 339, 351, 365, 435 of atoms, 350 of molecule, 340, 341, 348–350, 366, 369, 411 internuclear distance, 352 ions, positive, 466 iron, 177 isobaric process, 183 isochoric process, 126, 128, 183, 184, 311 isothermal, 128, 184 isotopes, stable, 503 isotropy, 53 Johnson noise, 47, 48 Kamerlingh–Onnes, 506 Kapitza, 491 Kappler, 47 Keesom, 491 Kelvin, 128 kinetic energy change by collisions, 482 conserved, 293 part, 423 per degree of freedom, 270 term, 317 transfer of, 483 zero, 543 kinetic theory, 4, 5, 23, 35, 123, 165, 225, 253, 265, 266, 466, 469, 505 classical, 249 Kirchhoﬀ’s law, 396, 397 laboratory frame, 416 Landau, 497, 505 condition, 501, 502 critical speed, 501 Langevin, Pierre, 37, 40 equation, 37, 40, 41, 48, 63, 91 function, 333 lattice, 244 frequencies, 326 vibrations, 178 law of mass action, 369, 370, 373, 404, 405, 420, 439, 449 Le Chatelier’s principle, 372 Legendre transformation, 131, 132, 137 level excited, 435, 436, 531 low, 434 scheme, 435 vibrational, frozen, 358 liquid, 136, 490, 498 layers, 38 liquid helium, 490, 493, 497–499, 501, 502, 533 at atmospheric pressure, 503 crawling, 492 ﬂow in capillary, 491, 492 He I, 491 He 3, 505, 534 degree of degeneracy of, 503 He 4, 491, 503 normal component, 502 viscosity, origin of, 502 lithium, 482 London, F., 491 longitudinal vibrations, 344, 381 macroscopic, 178 dimensions, 346 mass, 499 number of bosons, 486, 544 number of electrons, 466 number of helium atoms, 491 number of pairs, 505 number of particles, 63 parameter, 233 properties, 4, 235 state, 148, 238, 258 system, 3, 81, 229, 258, 293 variables, 124 volume, 472 magnetic, 156, 228, 243, 438 energy, 172 ﬁeld, 135, 136, 138, 140, 141, 147, 150, 157, 164, 173, 178, 181, 291, 230, 237, 403, 426 cancels, 507 external, 180 forces, 253 induction, 135 ions, 141, 290 levels, 436 number of, 439 moment, 121, 137–143, 162, 173, 180, 181, 243, 244, 290, 331, 333, 403 average, 144 intrinsic, 138 Index 557 of electron, 139 total, 142 properties, 506, 507 susceptibility, 181 magnetization, 136, 138, 149, 162, 169–172, 177, 195, 203, 215, 216, 218, 229, 230, 237, 284, 298, 333, 334 at saturation, 177, 333 average, 168, 173, 178, 180, 204, 216, 218, 291, 332 per spin, 208, 286 density, 507 per degree of freedom, 149 trapped, 508 manganese, 140 mass, 6, 253, 255, 259, 314, 340 double of He 3, 506 of molecule, 3, 21 of nucleus, 415 reduced, 343 rest, 448 Maxwell, 4, 49, 65 distribution, 30, 52 equation, 426 in vacuum, 389 law, 253 relations, 131–133, 189–191 Maxwell–Boltzmann distribution, 24, 69, 83, 122, 233, 386, 464, 472, 473, 476, 482 Maxwell distribution, 54 mean free path, 34, 49, 50, 54, 57, 66, 470, 471, 483, 484, 504 inﬁnite, 425 long, 505 problem of, 471 mean free time, 35, 49, 50, 54, 470, 482, 517, 519 between collisions, 503 of electrons, 467 Meissner eﬀect, 507 mercury, 506 metal, 3, 466, 469, 470, 476, 484, 505, 522, 523 properties of, 453 wire, 466 microcanonical description, 287 microscopic, 6, 143, 282 energies, 281, 298 evolution, 121 laws, 228 scale, 3 state, 121, 141–143, 147, 151, 156, 165, 173, 223, 226, 231, 243, 244, 258, 278, 281, 284, 292, 301, 317, 322, 331, 346, 379, 388, 454, 455, 459, 462, 536 of crystal, 380 single, 460 states, number of, 149, 317, 384, 390 theory, 235 mirror, ideal, 75 mixing, 277 mixture, 56, 77 of gases, 10, 12, 54, 263 mobility, 49, 63, 468 coeﬃcient, 32, 61, 468 molecular chaos, 74 current, 518 level, 251 mass, 27 velocities, 33 vibrations, 344, 356 molecule(s), 11, 17, 121, 124, 225, 341, 373, 375 center of mass, 342 energetic, 12 identical, 347 moment of inertia, 357 number of, 6, 367, 371, 537 of ideal gas, 447 of liquid, 497 parts of, 15 translational motion of, 436 triatomic, 16, 409 moment of inertia, 46, 359, 404, 416 of diatomic molecule, 358 momentum, 7, 9, 15, 65, 75, 121, 226, 253, 256, 264–267, 270, 272, 278, 279, 293, 310, 330, 340–342, 345, 353, 458, 483, 498, 520, 541 transfer, 232 component, 7, 267, 356 quantized, 521 conservation, 231, 498, 500 current, 66 distribution function, 486 eigenstates of, 538 exchange, 13, 18, 39 of center of mass, 346 of entire molecule, 341 imparted, 15 initial, 498 integration over, 320 internal, 346 loss, 500 relative, 343, 344 558 Index space, 254, 330, 521, 522, 538 variable, 270, 311, 313, 409 motion, 356 collective, 377, 497 of He 3, 505 of liquid, 498 of center of mass, 341 of electrons, 365, 484 of heavy nuclei, 365 of nuclei, 352 random, 33, 63 thermal, 33, 66 nearest neighbors, 377 neon, 490 Nerst’s law, 281 neutrons, 17, 460, 500, 516 wavelength of, 500 Newton, 61 law, 6–8, 61, 253 second law, 467 nitrogen, 421, 491 noise, 33 nonequilibrium, 394 nonrelativistic, 453 particles, 448 normal mode equation, 380 normalization, 85, 151, 155 coeﬃcient, 316 condition, 27, 83, 201, 481, 520 constant, 159, 204, 256 factor, 260 of f (v), 520 of probabilities, 454 nuclear, 19, 350 nucleus, 138, 340, 348, 352 observable, 169, 255, 455 occupation function, 539 number, 459, 461, 462, 464, 516, 517, 537, 540, 544 average, 464, 465, 512 step function, 541 of ground level, 487, 488, 491 negligible, 495 Ohm’s law, 467, 468, 470 one-dimensional, 44, 59, 82, 90, 231 harmonic oscillator, 244, 358, 498 motion, 268, 269 partition function, 269, 271 system, 38 oscillator, 323, 388, 516 bounded, 289, 323 damped, 45 excitation of, 248 free, 377, 423 independent, 378 three, coupled, 423 three-dimensional coupled, 377 oxygen, 54, 415, 421 molecules, 366, 369, 370 pair creation, 405, 448 pairs, stable, 505 paramagnet, 141, 178, 180, 181, 214, 217, 225–228, 230, 236, 239, 240, 243, 276, 286, 317, 413, 435, 436, 454, 462, 516 classical, 283, 290 ionic salts, 177 isolated, 158, 161, 165 moment, 436 with spin 1, 439 paramagnetism, 138, 141, 436 particle(s), 4 addition of, 477 average number of, 456, 463, 464, 512, 536 classical, 292, 453 density, 24, 68 description, 4 exchange, 453, 454 extremely relativistic, 330, 540 ﬂow, 242 free, 42, 49 identical, 262, 309, 316, 453, 460, 461 independent, 24 indistinguishable, 317 interacting, 340 mass, 269 material, 386 momenta, 485 noninteracting, 458 number of, 226, 241, 265, 455, 456, 459, 460, 462, 463 given, 454, 485 maximal, 487 excited, 531 constant, 536 pointlike, 363, 484 position, 254 relativistic, 290, 542 state, 253, 258, 269, 459 trajectory, 307 transfer of, 241 quantum-mechanical, 271, 453 Index 559 partition function, 167, 173, 180, 207, 208, 214, 217, 218, 227–229, 233, 234, 237, 243, 245, 246, 249, 260, 262, 263, 266, 268, 271, 272, 276–280, 288, 290, 298, 301, 304, 310–312, 316, 320, 323, 327, 328, 332, 340, 346, 347, 354, 370, 375, 377, 380, 388, 411, 437, 455, 462, 512, 516 at high temperatures, 418 classical, 271 corrected, 317 dimensionless, 271 grand canonical, 462, 536 internal, 350, 351, 353, 355, 357, 360, 363, 370, 374, 375, 440, 413, 414, 421 of ideal gas, 271, 461 of mixture of gases, 311 of paramagnet, 279 of single electron, 448 of single molecule, 340, 347, 348, 372 of single oscillator, 302, 323, 380 of single particle, 217, 248, 256, 269, 273, 279, 301, 310, 330 of single state, 462 quantum, 272, 273 Pauli principle, 453, 460, 464, 471, 482, 487, 504, 505, 543 does not apply, 486 Penzias, 398 periodic ionic lattice, 484 periodic structure, 498 periodicity, deviations from perfect, 484 permeable, 316 permutations, internal, 317 Perrin, 43 phase space, 254, 255, 258, 267, 272, 273, 307, 308, 522 of photons, 389 phase transition, 491 He I to He II, 493 phonon(s), 247, 380, 384, 388, 389, 482, 484, 498, 499, 512 as particles, 382 as waves, 382 contribution to speciﬁc heat, 527 energy, 464, 533 excited, 499 gas, 502, 534 in crystal, 485 states, number of, 382 phonons, number of, 380, 537 average, 247, 384, 464 photoelectric eﬀect, 398 photon(s), 9, 75, 189, 388, 390, 391, 403, 425, 485, 544, 545 created, 429 density, 76 energy, 445 gas, 188, 189, 446 adiabatics of, 132 number density, 390 number of, 430, 447 average, 404, 429, 445, 446 of black body, 467, 485 states, 389 Pippard, 133 piston, 6, 7, 12, 13, 15, 74, 75, 78, 79, 232, 293, 294 Planck, Max, 391, 392, 398, 472 assumption, 252 constant, 18, 139, 249, 269, 273, 283, 375, 391, 428 distribution, 376, 427, 447 formula, 391, 394, 398 polarization, 383, 386, 389, 443 density, 135 of radiation, 443 saturates, 170 three, 381 position, 265, 272, 353 average of, 36 of particles, 309 relative, 344 variables, 311, 313 positrons, 449, 546 potassium, 467, 469 potential, 23, 24, 28, 30, 39, 64, 81, 82, 91, 231, 254, 409, 466 attractive, 329 between two atoms, 407 central, 71, 344 depth of, 407 energy, 17, 19, 20, 22, 24, 39, 46, 48, 134, 226, 249, 254, 259, 328, 340, 342, 352, 353, 374, 376, 377 average, 71, 93, 256 electrostatic, 259 minimal, 345, 374, 407 external, 265 gravitational, 82 in diatomic molecule, 342 intermolecular, 497 of harmonic oscillator, 257, 377, 423 well, inﬁnite, 268 power, 444 emitted, 391 560 Index total, 428 of radiation, 394 precipitation rate, 73 pressure, 4, 6, 12, 21, 54, 66, 68, 72, 74, 78– 81, 124, 131, 136, 188, 229, 231, 233, 237, 242, 263, 265, 317, 327–329, 446, 457, 513, 540, 542 atmospheric, 73 average, 233 balance, 13 constant, 58, 129, 263 equal, 241, 315 increase, 430, 316 independent of volume, 543 of boson gas, 513 of gas, 15, 47, 431, 446, 513 of radiation, 431 of photon gas, 132 of radiation, 393, 446 of sun’s radiation, 394 partial, 77, 318 total, 76, 316 probability, 23–25, 27, 28, 55, 69, 83, 89, 122, 143, 149, 156, 158, 164–167, 170, 175, 192, 201, 211, 215, 219, 220, 238, 239, 253, 254, 257, 265, 266, 278, 292, 319, 348, 504, 512 density, 24, 253, 254, 260 function, 473 distribution, 176, 455 equal, 178 function, 313 normalized, 266 of magnetic moment, 302 of oscillator, 302 in canonical ensemble, 229 in phase space, 260 in velocity space, 27 maximal, 219, 239 of conﬁguration, 240 of microscopic state, 302, 316 of state, 167, 216, 454 relative, 226, 227 sum of, 212 process, 234 inﬁnitesimal, 229 isobaric, 126, 184, 311 isothermal, 126, 183 quasistatic, 229, 234 reversible, 276, 277 product concentrations, 369, 441 projection, 164 along H, 143 average, 170 of spin, 142, 173 proper modes, 378 protons, 17, 121, 460, 516 quantization, 243 of electromagnetic radiation, 398 of energy, 18, 268 of motion, 271 of particle wave functions, 460 quantized, 139 momentum, 458 wavelength, 458 quantum, 243 analysis, 484 behavior on macroscopic scale, 503 condition, 453 electrodynamics, 140 energy, 249 levels, 353, 357 ground state energy, 374 harmonic oscillators, 225, 244, 390, 498 liquid, 498 mechanics, 4, 17, 121, 139, 346, 356 motion, 542 particles, 272, 458, 472 identical, 458 state, 268, 272, 358, 516 discrete, 488 number of, 486 of diatomic molecule, 360 statistics, 458, 485 system, 253, 283 theory, 18, 19, 243, 250, 276, 346, 391, 399, 471 wave function, 458 of identical particles, 460 quantum-mechanical, 3, 249, 271, 365, 379 eﬀect, 460 treatment, 484 quark, 17 degrees of freedom, 80 radiation, 75, 391, 426, 445 absorbed, 396, 442, 447 amount of, 385 chemical potential of, 393 density, 390, 395, 404, 545 emission, 391, 395, 404, 443, 447 energy, 425 amount of, 387 frequency, 442 gas, 393 Index 561 in equilibrium, 394, 396 incident, 442, 447 intensity of, 396, 404 pressure, 430, 431 spectrum of, 398 thermal, 398 transmited, 443 random walk, 35, 181 randomness, 36 Rayleigh–Jeans distribution, 428 law, 392, 427 reactants, 371 reaction, 371, 372, 403, 421, 439 absorbs heat, 372 between nuclei, 405 equation, 421 releases heat, 422 reverse, 422 recoil, 232 Reimann zeta function, 402 relativistic correction, 542 eﬀects, 140 mechanics, 121 resistance, 47 resistivity, 469, 471, 483, 518, 519 resonant frequency, 47, 48 response coeﬃcients, 284, 286 response to temperature changes, 372 rigid bodies, 18 rotating cylinder, 492 rotation, 9, 16, 17, 344, 353, 366 of molecule, 344 rotational, 18, 356, 358, 363, 365, 374 degrees of freedom, 362 freeze, 363, 364 energy, 357–360 level, 359, 360, 417 motion, 361–363 state, 359, 360, 361 scattering of electrons, 484 of slow neutrons, 499 second law, violation of, 395, 443 self-interaction, 259 sensitivity, limits on, 33 short time behavior, 45 sinusoidal electromagnetic wave, 426 sky diver, 38, 90 sodium, 467, 469, 490, 497 solid angle, 69 Sommerfeld, 471 model, 482–484, 504 sound waves, 377, 498–500 space, D-dimensional, 88 6N-dimensional, 258 six-dimensional, 254 two dimensions, 35, 87 speciﬁc heat, 80, 171, 173, 180, 181, 236, 249, 251, 280, 286, 287, 289, 305, 306, 321, 323, 324, 326, 329, 339, 350, 351, 361–365, 376, 383, 403, 425, 435, 436, 438, 439, 457, 481–483, 494, 495, 505 above critical temperature, 495 change, 437 constant ﬁeld, 210, 213, 296 constant pressure, 127, 311, 312, 331, 410 constant volume, 67, 127, 263, 290, 310, 312, 328, 331, 349, 355, 405, 410, 414, 494 asymptotic behavior of, 289, 325 per photon, 405 low temperature, 481 molar, 250, 305, 306 near Tc, 496 of atomic levels, 403 of Bose gas, 494 of crystalline sodium, 289 of diatomic gas, 356 of electrons, 482 of gases, 351 of ground level, 488 of He 4, 496, 503, 534 of lead, 251 of metal, 480, 482 of mixture, 265 of paramagnet, 291, 334, 438 of phonon gas, 534 of photon gas, 447 of radiation, 393 of solids, 243 partial, 265, 312 per degree of freedom, 213 per electron, 469, 470, 482 per molecule, 321, 412 of ideal gas, 405 per photon, 447 per spin, 217 problem, 362, 470, 471 spectral line, 403 spectroscopic measurements, 370 speed, 3, 88 between collisions, average, 519 562 Index constant, 467 of light, 75, 290, 386, 430 of sound in liquid He, 499, 501, 533 thermal, 49 spin, 139, 147, 150, 156, 157, 165, 172, 175, 177, 192–194, 211, 236, 243, 317 aligned, 215 classical, 333 ﬂip, 171 freeze, 171 half-integer, 460 integer, 460, 485, 516 independent, 203 nonzero, 486 number of, 296 of electron, 140 of ions, 178 of paramagnet, 516 partition function, 215 projection, 162 average, 171 quantum, 333 states of electron, 448 total, 516 spring constant, 243, 345, 408 square deviation average, 29, 86, 285 standard conditions, 21, 33, 54 standard deviation, 160 standing wave(s), 378, 379, 381, 388, 389, 458 number of, 389 state, allowed, 143 discrete, 347 empty, 483 equally probable, 147 function, 228, 234, 295 states, 353, 435, 436, 489, 490, 529 internal, 15 in molecule, 350 many-particle, 459 microscopic distinguishable, 460 individual, 233, 459 most probable, 237, 238 microscopic, 153 macroscopic, 237 N-particle, 459 number of, 157, 158, 161, 176, 178, 180, 192–194, 197, 199, 241, 272, 317, 380, 424 ﬁnite number of, 333 inﬁnite number of, 225 with energy, 154, 164 of given J, 360 one-particle, 216 quantum, single, 516 single particle, 269, 458, 460, 463, 464, 472, 476, 485, 538 accessible states, 458 single spin, 217, 513 space, 124 uniform, 316 statistical mechanics, 4, 6, 9, 23, 29, 162, 225, 226, 235, 258, 265, 341, 386 classical, 276 Stefan–Boltzmann law, 392, 393 step function, 524 stifness, 251 Stirling, approximation, 199, 371 formula, 153, 154, 182, 198, 220, 279 Stokes, 38 law, 43 subsystem, 164, 166, 180, 191 sum of pressures, 12, 265 sum over states, 227, 254 sun, center of, 431 superconducting ring, 506 superconductivity, 453, 506, 507 superﬂuid, 491, 492, 505, 506 He 3, 506 component, 492, 497, 502 concentration of, 493 ﬂow, 503, 507 superﬂuidity, 453, 498, 502, 506 at absolute zero, 502 in He II, 491, 493 in liquid hydrogen, 494 of electronic Fermi liquid, 507 susceptibility, 173, 177, 210, 284, 285, 287, 333 negative, 507 of paramagnet, 285 symmetry, 215 constraint, absence of, 461 properties, 460 system combined, 157 composite, 160, 239, 241 insulated, 122 isolated, 151, 160, 164, 166, 178, 225, 237, 239, 453, 454 of electrons, 352 of oscillators, 279, 301, 317 of bosons, 485 of identical particles, 464 state of, 124, 258 Index 563 temperature, 4, 8, 11, 13, 20, 22, 23, 27, 46, 54, 57, 63, 66, 71, 80, 81, 122, 126, 129, 131, 156, 157, 162–164, 166, 170, 177, 178, 181, 184, 186, 203, 207, 214, 227, 228, 237, 241, 242, 248, 251, 257, 258, 271, 282, 284, 289, 299, 305, 315, 316, 324, 327, 333, 348, 350, 351, 353 356, 360, 362, 373, 374, 385, 393, 395, 397, 403, 404, 435, 441–443, 446, 454, 460, 469, 472, 473, 478, 488, 526 1 mK, 506 2.7 K, 399 above absolute zero, 502 absolute, 9, 125, 158, 162, 164 at sun’s center, 393 change, 234, 349, 529 characteristic, 171, 251, 351, 358, 362, 363, 365, 403, 435 condensation, 513, 534 constant, 58, 66, 72, 166, 170, 172, 183, 207, 238, 249, 367, 430 control, 225 dependence, 247, 248, 403, 483 of µ, 479 of energy, 495, 496 of equilibrium constant K, 372, 374, 440 of radiation density, 396 diﬀerences, 78 electronic characteristic, 436 equal, 241 extremely relativistic, 513 ﬁnite, 484 ﬁxed, 165 gradient, 50, 67, 493 high, 19, 171, 172, 247–249, 268, 271, 289, 303, 306, 307, 320, 324, 333, 375, 427, 437, 475, 486, 487, 489 identiﬁcation of, 187 independence of, 447 increase, 422, 443 inﬁnite, 163 low, 3, 18, 19, 172, 247–249, 250, 289, 303, 315, 320, 324–326, 333, 334, 363, 383, 384, 403, 412, 437, 441, 471, 474, 475, 477, 480, 482, 484, 486, 487, 490, 498, 503, 524 approximation, 307, 326 behavior, 503 limit, 478 magnetic, characteristic, 436 negative, 163 of gas, 72, 448 of liquid He 3, 505 of sun’s surface, 404 of walls, 386 range, 354, 355, 415, 436 relative, 156 relativistic, 546 room, 10, 76, 251, 351, 355, 415, 447, 471, 478, 479, 481, 482, 484, 491 rotational, low, 441 scale, logarithmic, 437 scales, 363, 441 T< Tc, 490, 508, 530 tending to zero, 281 transition, 248, 305, 491, 494, 505 uniform, 20, 386 very high, 211, 365 very low, 506 zero, 281 thermal average, 44, 248, 279, 280 conduction, 483 conductivity, 49, 50, 64, 469, 482, 504 large, 491, 493 of metals, 491 ratio of, 482 contact, 165, 239 ﬂuctuations, eliminated, 506 interaction, 10, 156, 237 velocity, average, 62 thermodynamic, 4, 10, 123, 124, 136, 137, 169, 174, 228, 234, 235, 275, 276 average, 231 behavior, 324 equilibrium, 71, 83, 124, 160, 161, 163, 166, 237, 239, 248, 284, 380, 391, 466, 498 state of, 463 functions, 166 information, 130, 131, 456 limit, 152, 160, 197, 198, 284–287 measurement, 17 potential, 129, 137, 485, 520, 536, 539 Ω, 132, 463, 472, 488, 512, 538, 542 properties, 228, 262, 376, 453, 457, 460, 463 quantities, 156, 225, 249, 273, 323, 351, 455, 457 relation, 410, 456 system, 169 variable, 130 work, 228–231, 233, 272, 455 thermodynamics, laws of, 4, 9, 134, 225, 226, 228, 455 ﬁrst law of, 124, 234, 235 second law of, 234, 235, 386, 387 564 Index third law of, 281, 291 does not apply, 334 thermodynamics of electromagnetic radiation, 339, 376 Thomson, J. J., 466 time, characteristic, 42, 47, 91, 121 torque, 134 trajectory, 143, 258, 308 of particle, 255 translation, 436 transport, coeﬃcients, 5, 49, 504 problem, 468 ultraviolet catastrophe, 428 uncertainty principle, 359, 458 unfreezing, 19 units, 8 valence, electrons, 466, 471 of sodium, 517 Van der Waals equation, 328 variable classical, 353 conjugate, 287 intensive, 130 independent, 4 random, 169, 221 velocity, 4, 14, 28, 34, 38, 40, 54, 71, 232, 253, 259, 278, 293, 340, 499 range of, 498 average, 40, 50, 61, 63, 67, 72, 467, 468, 482 changes, 89 distribution, 21, 23, 27, 28, 53, 57, 79 isotropic, 52 Maxwellian, 53 of electrons, 469 drift, 61, 62, 468 gradient, 65, 492 initial, 90 minimal, 499 most probable, 71 relative, 11, 15, 53 space, 25, 83, 254, 473 thermal, 43, 72, 469, 483 typical, 33 volume, 24 vibration, 9, 16, 17, 19, 344, 366, 381 collective, 252, 498 modes of, 537 of crystal, 251, 379 of ions, 480 of solid, 248 radial, 353 thermal, 387 vibrational, 18, 357, 363, 365, 374 amplitude, 309 angular frequencies, 404 degrees of freedom, 362 frozen, 362, 375 energy, 357, 358, 360 average, 88 frequency, 363 kinetic energy, 362 level, 360 spacing, 358, 417 mode, 252, 377, 378, 382, 383, 388, 389, 445, 537 motion, 360, 361 partition function, 374 state, 361 state, nondegenerate, 360 viscosity, 4, 32, 37, 38, 43, 49, 50, 62, 64, 497, 503, 504 coeﬃcient, 38, 73 low, 491 measurement, 492 of classical gas, 534 of degenerate fermions, 505 of gaseous helium, 491 of gases, 497 of He II, 491 of normal component, 492 typical, 491 zero, 492, 498 voltage ﬂuctuations, 48 volume, 4, 136, 227, 237, 257, 327, 473 active, 328 change, 272 conﬁning, 258 constant, 129, 321, 367, 384 D-dimensional, 87 dependence, 233 element, 24 free, 328 independence of, 314, 315, 317 of gases, 6 vortices, 502 Waage, 369 walls of container, 228 structure of, 388 water, 43 molecules of, 366, 369 wave, 376, 427 amplitude, 426 Index 565 frequencies, 378 moving, 389 numbers, small, 500 number, 378, 422, 498 of phonon, 533 vector, 378, 381–383, 386, 388, 389 space, 383, 389, 424 transverse, 387 wavelength, 270, 385, 394, 404, 542 21 cm, 403 large, 500 minimal, 388 of electron, 484 of emitted line, 434 yellow, 447 width of distribution, 225, 284 Wiedemann and Franz, 469, 470, 482, 483 Wien’s law, 433, 445 Wilson, 398 Woods, 500 work, 44, 124, 136, 189, 231, 235, 238, 316 performed by gas, 334","libVersion":"0.3.2","langs":""}