{"path":"Books and Papers/Astrophysics and Cosmology/Bayesian Methods in Cosmology.pdf","text":"Bayesian Methods in Cosmology Roberto Trotta Abstract These notes aim at presenting an overview of Bayesian statistics, the un- derlying concepts and application methodology that will be useful to astronomers seeking to analyse and interpret a wide variety of data about the Universe. The level starts from elementary notions, without assuming any previous knowledge of statis- tical methods, and then progresses to more advanced, research-level topics. After an introduction to the importance of statistical inference for the physical sciences, el- ementary notions of probability theory and inference are introduced and explained. Bayesian methods are then presented, starting from the meaning of Bayes Theo- rem and its use as inferential engine, including a discussion on priors and posterior distributions. Numerical methods for generating samples from arbitrary posteriors (including Markov Chain Monte Carlo and Nested Sampling) are then covered. The last section deals with the topic of Bayesian model selection and how it is used to assess the performance of models, and contrasts it with the classical p-value ap- proach. A series of exercises of various levels of difﬁculty are designed to further the understanding of the theoretical material, including fully worked out solutions for most of them. Roberto Trotta Imperial College London, Imperial Centre for Inference and Cosmology & Data Science Institute, Blackett Laboratory, Prince Consort Road, London SW7 2AZ www.robertotrotta.com 1arXiv:1701.01467v1 [astro-ph.CO] 5 Jan 2017 Contents Bayesian Methods in Cosmology . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1 Roberto Trotta 1 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 3 2 Elementary notions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 5 2.1 The notion of probability . . . . . . . . . . . . . . . . . . . . . . . . . . . 5 2.2 Random variables, parent distributions and samples . . . . . 6 2.3 The Central Limit Theorem . . . . . . . . . . . . . . . . . . . . . . . . . 8 2.4 The likelihood function . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 8 2.5 The Maximum Likelihood Principle . . . . . . . . . . . . . . . . . . 10 2.6 Conﬁdence intervals (frequentist) . . . . . . . . . . . . . . . . . . . . 13 2.7 Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 16 2.8 Solutions to exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 19 3 Bayesian parameter inference . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 25 3.1 Bayes theorem as an inference device . . . . . . . . . . . . . . . . . 25 3.2 Advantages of the Bayesian approach . . . . . . . . . . . . . . . . . 27 3.3 Considerations and caveats on priors . . . . . . . . . . . . . . . . . 29 3.4 A general Bayesian solution to inference problems . . . . . . 32 3.5 The Gaussian linear model . . . . . . . . . . . . . . . . . . . . . . . . . . 33 3.6 Markov Chain Monte Carlo methods . . . . . . . . . . . . . . . . . 35 3.7 Practical and numerical issues . . . . . . . . . . . . . . . . . . . . . . . 40 3.8 Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 41 3.9 Solutions to selected exercises . . . . . . . . . . . . . . . . . . . . . . . 49 4 Bayesian model selection . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 55 4.1 The three levels of inference . . . . . . . . . . . . . . . . . . . . . . . . 55 4.2 The Bayesian evidence . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 56 4.3 Computation of the evidence . . . . . . . . . . . . . . . . . . . . . . . . 61 4.4 Example: model selection for the inﬂationary landscape . 65 4.5 Open challenges . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 66 4.6 Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 68 4.7 Solutions to selected exercises . . . . . . . . . . . . . . . . . . . . . . . 70 Appendix . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 73 2 Bayesian Methods 3 5 Introductory and background material . . . . . . . . . . . . . . . . . . . . . . . . 73 5.1 The uniform, binomial and Poisson distributions . . . . . . . 73 5.2 Expectation value and variance . . . . . . . . . . . . . . . . . . . . . . 76 5.3 The exponential distribution . . . . . . . . . . . . . . . . . . . . . . . . . 79 5.4 The Gaussian (or Normal) distribution . . . . . . . . . . . . . . . . 80 5.5 The Chi-Square distribution . . . . . . . . . . . . . . . . . . . . . . . . . 83 References . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 84 1 Introduction The purpose of physics is to learn about regularities in the natural phenomena in the world, which we call “Laws of Physics”. Theoretical models expressed in math- ematical form (e.g., Newton’s theory of gravitation) have to be validated through experiments or observations of the phenomena they aim to describe (e.g., measure- ment of the time it takes for an apple to fall). Thus an essential part of physics is the quantitative comparison of its theories (i.e., models, equations, predictions) with observations (i.e., data, measurements). This leads to conﬁrm theories or to refute them. Measurements often have uncertainties associated with them. Those could orig- inate in the noise of the measurement instrument, or in the random nature of the process being observed, or in selection effects. Statistics is the tool by which we can extract information about physical quantities from noisy, uncertain and/or in- complete data. Uncertainties however are more general than that. There might be uncertainty in the relationship between quantities in a model (as a consequence of limited information or true intrinsic variability of the objects being studied); uncer- tainty in the completeness of the model itself; and uncertainty due to unmodelled systematics (to name but a few). The purpose of these lectures is to provide an appreciation of the fundamental principles underpinning statistical inference, i.e., the process by which we recon- struct quantities of interest from data, subject to the various sources of uncertainty above. The lectures will also endeavour to provide the conceptual, analytical and numerical tools required to approach and solve some of the most common inference problems in the physical sciences, and in particular in cosmology. References are provided so that the reader can further their understanding of the more advanced topics, at research level and beyond. Probability theory, as a branch of mathematics, is concerned with studying the properties of sampling distributions, i.e., probability distributions that describe the relative frequency of occurrence of random phenomena. In this sense, probability theory is “forward statistics”: given the properties of the underlying distributions, it predicts the outcome of data drawn from such distributions. Statistical inference, by contrast, asks the question of what can be learnt about the underlying distributions from the observed data. It therefore is sometimes called 4 Bayesian Methods “inverse probability”, in that it seeks to reconstruct the parameters of the distribu- tions out of which the data are believed to have been generated. Statistics addresses several relevant questions for physicists: (i) How can we learn about regularities in the physical world given that any mea- surement is subject to a degree of randomness? (ii) How do we quantify our uncertainty about observed properties in the world? (iii) How can we make predictions about the future from past experience and theoret- ical models?. Inference and statistics are today at the heart of the scientiﬁc process, not merely an optional nuisance. Ernest Rutherford is reported to have said, over a century ago: “If you need statistics, you did the wrong experiment”. While this might have had some merit at the time, it completely misses the point of what science has become today. All scientiﬁc questions at the forefront of research involve increasingly com- plicated models that try to explain subtle effects in complex, multidimensional data sets. The sheer amount of data available to astrophysicists and cosmologists has increased by orders of magnitudes in the last 20 years. Correspondingly, the sophis- tication of our statistical analysis tools has to keep up: increasingly, the limiting factor of our knowledge about the Universe is not the amount of data we have, but rather our ability of analyse, interpret and make sense of them. To paraphrase Rutherford, in 21st Century astrophysics f you do not need statis- tics, it’s because you are doing the wrong kind of physics! There are (at least) ﬁve good reasons why every professional astrophysicist and cosmologist ought to have a solid training in advanced statistical methods: (i) The complexity of the modelling of both our theories and observations will al- ways increase, thus requiring correspondingly more reﬁned statistical and data analysis skills. In fact, the scientiﬁc return of the next generation of surveys will be limited by the level of sophistication and efﬁciency of our inference tools. (ii) The discovery zone for new physics is when a potentially new effect is seen at the 2–3σ level, i.e., with a nominal statistical signiﬁcance somewhere in the region of 95% to 99.7%. This is when tantalizing suggestions for an effect start to accumulate but there is no ﬁrm evidence yet. In this potential discovery region a careful application of statistics can make the difference between claiming or missing a new discovery. (iii) If you are a theoretician, you do not want to waste your time trying to explain an effect that is not there in the ﬁrst place. A better appreciation of the interpretation of statistical statements might help in identifying robust claims from spurious ones. (iv) Limited resources mean that we need to focus our efforts on the most promising avenues. Experiment forecast and optimization will increasingly become promi- nent as we need to use all of our current knowledge (and the associated uncer- tainty) to identify the observations and strategies that are likely to give the highest scientiﬁc return in a given ﬁeld. (v) Sometimes we don’t have the luxury to be able to gather better or further data. This is the case for the many problems associated with cosmic variance limited Bayesian Methods 5 measurements on large scales, for example in the cosmic background radiation, where the small number of independent directions on the sky makes it impossible to reduce the error below a certain ﬂoor. 2 Elementary notions 2.1 The notion of probability There are two different ways of understanding what probability is. The classical (so-called “frequentist”) notion of probability is that probabilities are tied to the frequency of outcomes over a long series of trials. Repeatability of an experiment is the key concept. The Bayesian outlook1 is that probability expresses a degree of belief in a propo- sition, based on the available knowledge of the experimenter. Information is the key concept. Bayesian probability theory is more general than frequentist theory, as the former can deal with unique situations that the latter cannot handle (e.g., “what is the probability that it will rain tomorrow?). Let A, B,C, . . . denote propositions (e.g., that a coin toss gives tails). Let Ω de- scribe the sample space (or state space) of the experiment, i.e., Ω is a list of all the possible outcomes of the experiment. Example 1. If we are tossing a coin, Ω = {T, H}, where T denotes “tails” and H denotes “head”. If we are rolling a regular die, Ω = {1, 2, 3, 4, 5, 6}. If we are draw- ing one ball from an urn containing white and black balls, Ω = {W, B}, where W denotes a white ball and B a black ball. Frequentist deﬁnition of probability: The number of times an event occurs divided by the total number of events in the limit of an inﬁnite series of equiprobable trials. Deﬁnition 1. The joint probability of A and B is the probability of A and B happen- ing together, and is denoted by P(A, B). The conditional probability of A given B is the probability of A happening given that B has happened, and is denoted by P(A|B). The sum rule: P(A) + P(A) = 1, (1) where A denotes the proposition “not A”. The product rule: 1 So-called after Rev. Thomas Bayes (1701(?)–1761), who was the ﬁrst to introduce this idea in a paper published posthumously in 1763, “An essay towards solving a problem in the doctrine of chances” [3]. 6 Bayesian Methods P(A, B) = P(A|B)P(B). (2) By inverting the order of A and B we obtain that P(B, A) = P(B|A)P(A) (3) and because P(A, B) = P(B, A), we obtain Bayes theorem by equating Eqs. (2) and (3): P(A|B) = P(B|A)P(A) P(B) . (4) The marginalisation rule follows from the two rules above and it reads: P(A) = P(A, B1) + P(A, B2) + · · · = ∑ i P(A, Bi) = ∑ i P(A|Bi)P(Bi), (5) where the sum is over all possible outcomes for proposition B. Deﬁnition 2. Two propositions (or events) are said to be independent if and only if P(A, B) = P(A)P(B). (6) 2.2 Random variables, parent distributions and samples Deﬁnition 3. A random variable (RV) is a function mapping the sample space Ω of possible outcomes of a random process to the space of real numbers. Example 2. When tossing a coin once, the RV X can be deﬁned as X = { 0, if coin lands T 1, if coin lands H. (7) When rolling a regular, 6-sided die, the RV X can be deﬁned as X =    1, if a 1 is rolled 2, if a 2 is rolled 3, if a 3 is rolled 4, if a 4 is rolled 5, if a 5 is rolled 6, if a 6 is rolled. (8) When drawing one ball from an urn containing black and white balls, the RV X can be deﬁned as X = { 0, if the ball drawn is white 1, if the ball drawn is black. (9) Bayesian Methods 7 A RV can be discrete (only a countable number of outcomes is possible, such as in coin tossing) or continuous (an uncountable number of outcomes is possible, such as in a temperature measurement). It is mathematically subtle to carry out the passage from a discrete to a continuous RV, although as physicists we won’t bother too much with mathematical rigour here. Heuristically, we simply replace summation sums over discrete variables with integrals over continuous variables. Deﬁnition 4. Each RV has an associated probability distribution to it. The proba- bility distribution of a discrete RV is called probability mass function (pmf), which gives the probability of each outcome: P(X = xi) = Pi gives the probability of the RV X assuming the value xi. In the following we shall use the shorthand notation P(xi) to mean P(X = xi). Example 3. If X is the RV of Eq. (8), and the die being tossed is fair, then Pi = 1/6 for i = 1, . . . , 6, where xi is the outcome “a the face with i pips comes up”. The probability distribution associated with a continuous RV is called the proba- bility density function (pdf), denoted by p(X). The quantity p(x)dx gives the prob- abilty that the RV X assumes the value between x and x + dx. The choice of probability distribution to associate to a given random process is dictated by the nature of the random process one is investigating (a few examples are given below). For a discrete pmf, the cumulative probability distribution function (cdf) is given by C(xi) = i ∑ j=1 P(x j). (10) The cdf gives the probabilty that the RV X takes on a value less than or equal to xi, i.e. C(xi) = P(X ≤ xi). For a continuous pdf, the cdf is given by P(x) = ∫ x −∞ p(y)dy, (11) with the same interpretation as above, i.e. it is the probability that the RV X takes a value smaller than x. When we make a measurement, (e.g., the temperature of an object, or we toss a coin and observe which face comes up), nature selects an outcome from the sample space with probability given by the associated pmf or pdf. The selection of the outcome is such that if the measurement was repeated an inﬁnite number of times the relative frequency of each outcome is the same as the the probability associated with each outcome under the pmf or pdf. This is another formulation of the frequentist deﬁnition of probability given above. Outcomes of measurements realized by nature are called samples2. They are a se- ries of real (or integer) numbers, { ˆx1, ˆx2, . . . , ˆxN}. In this notes, I will denote samples (i.e., measured values) with a hat symbol, ˆ. 2 The probability theory notion of sample encountered here is not to be confused with the idea of MCMC (posterior) samples, which we will introduce later in section 3.6. 8 Bayesian Methods Deﬁnitions and background material on some of the most important and most commonly-encountered sampling distributions (the uniform, Poisson, Binomial, ex- ponential and Gaussian distributions) are given in Appendix 4.7. 2.3 The Central Limit Theorem The Central Limit Theorem (CLT) is a very important result justifying why the Gaussian distribution is ubiquitous. Theorem 1. Simple formulation of the CLT: Let X1, X2, . . . , XN be a collection of independent RV with ﬁnite expectation value µ and ﬁnite variance σ 2. Then, for N → ∞, thir sum is Gaussian distributed with mean Nµ and variance Nσ 2. Note: it does not matter what the detailed shape of the underlying pdf for the individual RVs is! Consequence: whenever a RV arises as the sum of several independent effects (e.g., noise in a temperature measurement), we can be conﬁdent that it will be very nearly Gaussian distributed. Theorem 2. More rigorous (and more general) formulation of the CLT: Let X1, X2, . . . , XN be a collection of independent RV, each with ﬁnite expectation value µi and ﬁnite variance σ 2 i . Then the variable Y = ∑N i=1 Xi − ∑N i=1 µi ∑ N i=1 σ 2 i (12) is distributed as a Gaussian with expectation value 0 and unit variance. 2.4 The likelihood function The problem of inference can be stated as follows: given a collection of samples, { ˆx1, ˆx2, . . . , ˆxN}, and a generating random process, what can be said about the prop- erties of the underlying probability distribution? Example 4. You toss a coin 5 times and obtain 1 head. What can be said about the fairness of the coin? Example 5. With a photon counter you observe 10 photons in a minute. What can be said about the average photon rate from the source? Example 6. You measure the temperature of an object twice with two different in- struments, yielding the following measurements: T = 256 ± 10 K and T = 260 ± 5 K. What can be said about the temperature of the object? Bayesian Methods 9 Schematically, we have that: pdf - e.g., Gaussian with a given (µ, σ ) → Probability of observation Underlying (µ, σ ) ← Observed events (13) The connection between the two domains is given by the likelihood function. Deﬁnition 5. Given a pdf or a pmf p(X|θ ), where X represents a random variable and θ a collection of parameters describing the shape of the pdf3 and the observed data ˆx = { ˆx1, ˆx2, . . . , ˆxN}, the likelihood function L (or “likelihood” for short) is deﬁned as L (θ ) = p(X = ˆx|θ ). (14) On the right-hand side of the above equation, the probability (density) of observing the data that have been obtained (X = ˆx) is considered as a function of the parame- ters θ . A very important – and often misunderstood! – point is that the likelihood is not a pdf in θ . This is why it’s called likelihood function! It is normalised over X, but not over θ . Example 7. In tossing a coin, let θ be the probability of obtaining heads in one throw. Suppose we make N = 5 ﬂips and obtain the sequence ˆx = {H, T, T, T, T }. The likelihood is obtained by taking the binomial, Eq. (199), and replacing for r the number of heads obtained (r = 1) in N = 5 trials, and looking at it as a function of the parameter we are interested in determining, here θ . Thus L (θ ) = ( 5 1 ) θ 1(1 − θ ) 4 = 5θ (1 − θ ) 4, (15) which is plotted as a function of θ in Fig. 1. If instead of r = 1 heads we had obtained a different number of heads in our N = 5 trials, the likelihood function would have looked as shown in Fig. 2 for a few different choices for r. This example leads to the formulation of the Maximum Likelihood Principle: if we are trying to determine the value of θ given what we have observed (e.g., the sequence of H/T in coin tossing), we should choose the value that maximises the likelihood, because this maximises the probability of obtaining the data that we got. Notice that this is not necessarily the same as maximising the probability of θ . Doing so requires the use of Bayes theorem, see section 3. 3 For example, for a Gaussian θ = {µ, σ }, for a Poisson distribution, θ = λ and for a binomial distribution, θ = p, the probability of success in one trial. 10 Bayesian Methods Fig. 1 The likelihood function for the probability of heads (θ ) for the coin tossing example, with N = 5, r = 1. Fig. 2 The likelihood function for the probability of heads (θ ) for the coin tossing example, with n = 5 trials and different values of r. 2.5 The Maximum Likelihood Principle The Maximum Likelihood Principle (MLP): given the likelihood function L (θ ) and seeking to determine the parameter θ , we should choose the value of θ in such a way that the value of the likelihood is maximised. Deﬁnition 6. The Maximum Likelihood Estimator (MLE) for θ is θML ≡ max θ L (θ ). (16) Bayesian Methods 11 It can be shown that the MLE as deﬁned above has the following properties: it is asymptotically unbiased (i.e., θML → θ for N → ∞, i.e., the ML estimate con- verges to the true value of the parameters for inﬁnitely many data points) and it is asymptotically the minimum variance estimator, i.e. the one with the smallest errors. To ﬁnd the MLE, we maximise the likelihood by requiring its ﬁrst derivative to be zero and the second derivative to be negative: ∂ L (θ ) ∂ θ ∣ ∣ ∣ θML = 0, and ∂ 2L (θ ) ∂ θ 2 ∣ ∣ ∣ θML < 0. (17) In practice, it is often more convenient to maximise the logarithm of the likelihood (the “log-likelihood”) instead. Since log is a monotonic function, maximising the likelihood is the same as maximising the log-likelihood. So one often uses ∂ ln L (θ ) ∂ θ ∣ ∣ ∣ θML = 0, and ∂ 2 ln L (θ ) ∂ θ 2 ∣ ∣ ∣ θML < 0. (18) Example 8. MLE of the mean of a Gaussian. Imagine we have N independent mea- surements of a Gaussian-distributed quantity, and let’s denote them by { ˆx1, ˆx2, . . . , ˆxN}. Here the parameters we are interested in determining are µ (the mean of the distribution) and σ (the standard deviation of the distribution), hence we write θ = {µ, σ }.Then the joint likelihood function is given by L (µ, σ ) = p( ˆx|µ, σ ) = N ∏ i=1 1 √ 2πσ exp ( − 1 2 ( ˆxi − µ)2 σ 2 ) , (19) Often, the expression above is written as L = L0 exp ( −χ 2/2 ) (20) where the so-called “chi-squared” is deﬁned as χ 2 = N ∑ i=1 ( ˆxi − µ)2 σ 2 . (21) We want to estimate the (true) mean of the Gaussian. The MLE for the mean is obtained by solving ∂ ln L ∂ µ = 0 ⇒ µML = 1 N N ∑ i=1 ˆxi, (22) i.e., the MLE for the mean is just the sample mean (i.e., the average of the measure- ments). Example 9. MLE of the standard deviation of a Gaussian. If we want to estimate the standard deviation σ of the Gaussian, the MLE for σ is: 12 Bayesian Methods ∂ ln L ∂ σ = 0 ⇒ σ 2 ML = 1 N N ∑ i=1 ( ˆxi − µ) 2. (23) However, the MLE above is “biased”, i.e. it can be shown that E(σ 2 ML) = ( 1 − 1 N ) σ 2 ̸= σ 2, (24) where E(˙) denotes the expectation value. I.e., for ﬁnite N the expectation value of the ML estimator is not the same as the true value, σ 2. In order to obtain an unbiased estimator we replace the factor 1/N by 1/(N −1). Also, because the true µ is usually unknown, we replace it in Eq. (23) by the MLE estimator for the mean, µML. Therefore, the unbiased MLE estimator for the variance is ˆσ 2 = 1 N − 1 N ∑ i=1( ˆxi − µML) 2. (25) In general, you should always use Eq. (25) as the ML estimator for the variance, and not Eq. (23). Example 10. MLE for the success probability of a binomial distribution. We go back to the coin tossing example, but this time we solve it in all generality. Let’s deﬁne “success” as “the coin lands heads” (H). Having observed H heads in a number N of trials, the likelihood function of a binomial is given by Eq. (199), where the unknown parameter is θ (the success probability for one trial, i.e., the probability that the coin lands H): L (θ ) = P(H|θ , N) = (N H ) θ H (1 − θ ) N−H , (26) The Maximum Likelihood Estimator the success probability is found by maximising the log likelihood: ∂ ln L (θ ) ∂ θ = ∂ ∂ θ ( ln (N H ) + H ln θ + (N − H) ln(1 − θ ) ) = H θ − N − H 1 − θ ! = 0 ⇔ θML = H N . (27) Thus the MLE is simpy given by the observed fraction of heads, which is intuitively obvious. Example 11. MLE for the rate of a Poisson distribution. The likelihood function is given by Eq. (201), using the notation θ = λ (i.e., the parameter θ we are interested in is here the rate λ ): L (λ ) = P(n|λ ) = (λt)n n! exp(−λt), (28) Bayesian Methods 13 The unknown parameter is the rate λ , while the data are the observed counts, n, in the amount of time t. The Maximum Likelihood Estimate for λ is obtained by ﬁnding the maximum of the log likelihood as a function of the parameter (here, the rate λ ). Hence we need to ﬁnd the value of λ such that: ∂ ln P(n|λ ) ∂ λ = 0. (29) The derivative gives ∂ ln P(n|λ ) ∂ λ = ∂ ∂ λ (n ln(λt) − ln n! − λt) = n t λt − t = 0 ⇔ λMLE = n t . (30) So the maximum likelihood estimator for the rate is the observed average number of counts. We can thus summarise the MLE recipe: (i) Write down the likelihood. This depends on the kind of random process you are considering. Identify what is the parameter that you are interested in, θ . (ii) Find the “best ﬁt” value of the parameter of interest by maximising the likelihood L as a function of θ . This is your MLE, θML. (iii) Evaluate the uncertainty on θML, i.e. compute the conﬁdence interval (see next section). 2.6 Conﬁdence intervals (frequentist) Consider a general likelihood function, L (θ ) and let us do a Taylor expansion of the log-likelihood ln L around its maximum, given by θML: ln L (θ ) = ln L (θML)+ ∂ ln L (θ ) ∂ θ ∣ ∣ ∣ θML (θ −θML)+ 1 2 ∂ 2 ln L (θ ) ∂ θ 2 ∣ ∣ ∣ θML(θ −θML) 2 +. . . (31) The second term on the RHS vanishes (by deﬁnition of the Maximum Likelihood value), hence we can approximate the likelihood as L (θ ) ≈ L (θML) exp ( − 1 2 (θ − θML)2 Σ 2 θ ) + . . . , (32) with 1 Σθ 2 = − ∂ 2 ln L (θ ) ∂ θ 2 ∣ ∣ ∣ θML. (33) A general likelihood function can be approximated to second order as a Gaussian around the ML value, as shown by Eq. (32). Therefore, to the extent that this second order Taylor expansion is sufﬁciently accurate, the uncertainty around the ML value, Σθ , is approximately given by Eq. (33). 14 Bayesian Methods Example 12. Let’s go back to the Gaussian problem of Eq. (19). We have seen in Eq. (22) that the sample mean is the MLE for the mean of the Gaussian. We now want to compute the uncertainty on this value. Applying Eq. (33) to the likelihood of Eq. (19) we obtain Σ 2 µ = σ 2/N. (34) This means that the the uncertainty on our ML estimate for µ (as expressed by the standard deviation Σµ ) is proportional to 1/√ N, with N being the number of measurements. As the likelihood function can be approximated as a Gaussian (at least around the peak), we can use the results for a Gaussian distribution to approximate the probability content of an interval around the ML estimate for the mean. The interval [µmin, µmax] is called a 100α% conﬁdence interval for the mean µ if P(µmin < µ < µmax) = α. Example 13. For example, the interval [µML − Σµ < µ < µML + Σµ ] is a 68.3% con- ﬁdence interval for the mean (a so-called “1σ interval”), while [µML − 2Σµ < µ < µML + 2Σµ ] is a 95.4% conﬁdence interval (a “2σ interval”). Example 14. In the temperature measurement example of Eq. (39), the 68.3% conﬁ- dence interval for the mean is 198.0K < µ < 201.2K. The 95.4% conﬁdence interval is 196.4K < µ < 202.8K. Generally, the value after the “±” sign will usually give the 1σ (i.e., 68.3%) re- gion. Sometimes you might ﬁnd a notation like 50±1 (95% CL), where “CL” stands for “Conﬁdence Level”. In this case, ±1 encompasses a region of 95% conﬁdence (rather than 68.3%), which corresponds to 1.96 σ (see Table 4). In the multi-dimensional case, additional parameters are eliminated from the like- lihood by proﬁling over them, i.e., maximising over their value. Deﬁnition 7. The proﬁle likelihood for the parameter θ1 (without loss of generality) is deﬁned as L (θ1) ≡ max θ2,...,θN L (θ ), (35) where in our case L (θ ) is the full likelihood function. Thus in the proﬁle likelihood one maximises the value of the likelihood along the hidden dimensions, rather than integrating it out as in the marginal posterior (see Eq. (79) below). The proﬁle likelihood can be directly interpreted as a if it were a genuine likeli- hood function, except that it does account for the effect of the hidden parameters. Conﬁdence intervals from the proﬁle likelihood can be obtained via the likeli- hood ratio test as follows. Classical conﬁdence intervals based on the Neyman construction are deﬁned as the set of parameter points in which some real-valued function, or test statistic, t evaluated on the data falls in an acceptance region Wθ = [t−,t+]. Likelihood ratios are often chosen as the test statistic on which frequentist intervals are based. When Bayesian Methods 15 θ is composed of parameters of interest, θ , and nuisance parameters, ψ, a common choice of test statistic is the proﬁle likelihood ratio λ (θ ) ≡ L (θ , ˆˆψ) L ( ˆθ , ˆψ) . (36) where ˆˆψ is the conditional maximum likelihood estimate (MLE) of ψ with θ ﬁxed and ˆθ , ˆψ are the unconditional MLEs. Under certain regularity conditions4, Wilks showed [62] that the distribution of −2 ln λ (θ ) converges to a chi-square distribution with a number of degrees of freedom given by the dimensionality of θ . This leads to the following prescription. Starting from the best-ﬁt value in pa- rameter space, an α% conﬁdence interval encloses all parameter values for which minus twice the log–likelihood increases less than ∆ χ 2(α, n) from the best ﬁt value. The threshold value depends on α and on the number n of parameters one is simul- taneously considering (usually n = 1 or n = 2), and it is obtained by solving α = ∫ ∆ χ 2 0 χ 2 n (x)dx, (37) where χ 2 n (x) is the chi–square distribution for n degrees of freedom, Eq. (235). One has to be careful with the interpretation of conﬁdence intervals as this is often misunderstood! Interpretation: if we were to repeat an experiment many times, and each time report the observed 100α% conﬁdence interval, we would be correct 100α% of the time. This means that (ideally) a 100α% conﬁdence intervals contains the true value of the parameter 100α% of the time. In a frequentist sense, it does not make sense to talk about “the probability of θ ”. This is because every time the experiment is performed we get a different realization (different samples), hence a different numerical value for the conﬁdence interval. Each time, either the true value of θ is inside the reported conﬁdence interval (in which case, the probability of θ being inside is 1) or the true value is outside (in which case its probability of being inside is 0). Conﬁdence intervals do not give the probability of the parameter! In order to do that, you need Bayes theorem. 4 One important and often-overlooked condition for the validity of Wilks’ theorem is that the parameter it is being applied to cannot lie at the boundary of the allowed parameter space. In this case, one ought to employ Chernoff’s theorem instead [12]. A modern discussion of the regularity conditions necessary for the asymptotic distribution of the likelihood ratio test statistics to be valid can be found in [48]. 16 Bayesian Methods 2.7 Exercises These exercises are designed to help you put into practice the above introductory concepts. Please make sure you are familiar with these notions before moving on to the next section. Exercises that are a little more challenging are denoted with a †. (i) Gaussian 1D problem. The surface temperature on Mars is measured by a probe 10 times, yielding the following data (units of K): 191.9, 201.6, 206.1, 200.4, 203.2, 201.6, 196.5, 199.5, 194.1, 202.4 (38) a. Assume that each measurement is independently Normally distributed with known variancee σ 2 = 25 K2. What is the likelihood function for the whole data set? b. Find the Maximum Likelihood Estimate (MLE) for the surface temperature, TML, and express your result to 4 signiﬁcant ﬁgures accuracy. c. Determine symmetric conﬁdence intervals at 68.3%, 95.4% and 99% around TML (4 signiﬁcant ﬁgures accuracy). d. How many measurements would you need to make if you wanted to have a 1σ conﬁdence interval around the mean of length less than 1 K (on each side)? (ii) The surface temperature on Mars is measured by a probe 10 times, yielding the following data (units of K): 197.2, 202.4, 201.8, 198.8, 207.6, 191.4, 201.4, 198.2, 195.7, 201.2. (39) a. Assuming that each measurement is independently Gaussian distributed with known variance σ 2 = 25 K2, what is the likelihood function for the whole data set? b. What is the MLE of the mean, TML? c. What is the uncertainty on our MLE for the mean? (iii) A laser beam is used to measure the deviation of the distance between the Earth and the Moon from its average value, giving the following data, in units of cm: 119, 119, 122, 121, 116. (40) a. Assuming that each measurement above follows an independent Gaussian dis- tribution of known standard deviation σ = 3 cm, write down the joint likeli- hood function for ∆ , the deviation of the Earth-Moon distance from its average value. b. Compute the maximum likelihood estimate for ∆ and its uncertainty, both to 3 signiﬁcant ﬁgures. c. How would you report the measurement of ∆ (giving a 1-σ conﬁdence inter- val)? (iv) You ﬂip a coin n = 10 times and you obtain 8 heads. Bayesian Methods 17 a. What is the likelihood function for this measurement? Identify explicitly what are the data and what is the free parameter you are trying to estimate. b. What is the Maximum Likelihood Estimate for the probability of obtaining heads in one ﬂip, p? c. Approximate the likelihood function as a Gaussian around its peak and derive the 1σ conﬁdence interval for p. How would you report your result for p? d. With how many σ conﬁdence can you exclude the hypothesis that the coin is fair? (Hint: compute the distance between the MLE for p and p = 1/2 and express the result in number of σ ). e. You now ﬂip the coin 1000 times and obtain 800 heads. What is the MLE for p now and what is the 1σ conﬁdence interval for p? With how many σ conﬁdence can you exclude the hypothesis that the coin is fair now? (v) An experiment counting particles emitted by a radioactive decay measures r par- ticles per unit time interval. The counts are Poisson distributed. a. If λ is the average number of counts per per unit time interval, write down the appropriate probability distribution function for r. b. Now we seek to determine λ by repeatedly measuring for M times the number of counts per unit time interval. This series of measurements yields a sequence of counts ˆr = {ˆr1, ˆr2, ˆr3, ..., ˆrM}. Each measurement is assumed to be inde- pendent. Derive the joint likelihood function for λ , L (λ ) = P(ˆr|λ ), given the measured sequence of counts ˆr. c. Use the Maximum Likelihood Principle applied to the the log likelihood ln L (λ ) to show that the Maximum Likelihood estimator for the average rate λ is just the average of the measured counts, ˆr, i.e. λML = 1 M M ∑ i=1 ˆri . d. By considering the Taylor expansion of ln L (λ ) to second order around λML, derive the Gaussian approximation for the likelihood L (λ ) around the Max- imum Likelihood point, and show that it can be written as L (λ ) ≈ L0 exp ( − 1 2 M λML (λ − λML) 2) , where L0 is a normalization constant. e. Compare with the equivalent expression for M Gaussian-distributed measure- ments to show that the variance σ 2 of the Poisson distribution is given by σ 2 = λ . (vi) An astronomer measures the photon ﬂux from a distant star using a very sensi- tive instrument that counts single photons. After one minute of observation, the instrument has collected ˆr photons. One can assume that the photon counts, ˆr, 18 Bayesian Methods are distributed according to the Poisson distribution. The astronomer wishes to determine λ , the emission rate of the source. a. What is the likelihood function for the measurement? Identify explicitly what is the unknown parameter and what are the data in the problem. b. If the true rate is λ = 10 photons/minute, what is the probability of observing ˆr = 15 photons in one minute? c. Find the Maximum Likelihood Estimate for the rate λ (i.e., the number of photons per minute). What is the maximum likelihood estimate if the observed number of photons is ˆr = 10? d. Upon reﬂection, the astronomer realizes that the photon ﬂux is the superpo- sition of photons coming from the star plus “background” photons coming from other faint sources within the ﬁeld of view of the instrument. The back- ground rate is supposed to be known, and it is given by λb photons per minute (this can be estimated e.g. by pointing the telescope away from the source and measuring the photon counts there, when the telescope is only picking up background photos). She then points to the star again, measuring ˆrt photons in a time tt . What is her maximum likelihood estimate of the rate λs from the star in this case? Hint: The total number of photons ˆrt is Poisson distributed with rate λ = λs + λb, where λs is the rate for the star. e. What is the source rate (i.e., the rate for the star) if ˆrt = 30, tt = 2 mins, and λb = 12 photons per minute? Is it possible that the measured average rate from the source (i.e., ˆrt /tt ) is less than λb? Discuss what happens in this case and comment on the physicality of this result. (vii) This problem generalizes the Gaussian measurement case to the case where the measurements have different uncertainties among them. You measure the ﬂux F of photons from a laser source using 4 different instru- ments and you obtain the following results (units of 104 photons/cm2): 34.7 ± 5.0, 28.9 ± 2.0, 27.1 ± 3.0, 30.6 ± 4.0. (41) a. Write down the likelihood for each measurement, and explain why a Gaussian approximation is justiﬁed in this case. b. Write down the joint likelihood for the combination of the 4 measurements. c. Find the MLE of the photon ﬂux, FML, and show that it is given by: FML = ∑ i ˆni ˆσ 2 i / ¯σ 2 , (42) where 1 ¯σ 2 ≡ ∑ i 1 ˆσ 2 i . (43) d. Compute FML from the data above and compare it with the sample mean. e. Find the 1σ conﬁdence interval for your MLE for the mean, and show that it is given by: Bayesian Methods 19 ( ∑ i 1 ˆσ 2 i )−1/2 . (44) Evaluate the conﬁdence interval for the above data. How would you summa- rize your measurement of the ﬂux F? 2.8 Solutions to exercises (i) a. The measurements are independent, hence the joint likelihood is the product of the likelihoods for each measurement: Ltot(T ) = 10 ∏ i=1 1 √ 2πσ exp ( − 1 2 ( ˆTi − T )2 σ 2 ) (45) where ˆTi are the data given, T is the temperature we are trying to determine (unknown parameter) and σ = 5 K. b. The MLE for the mean of a Gaussian is given by the mean of the sample, see Eq. (22), hence TML = 1 10 10 ∑ i=1 Ti = 199.7K. (46) c. The variance of the mean is given by σ 2/N, see Eq. (34). Therefore the stan- dard deviation of our estimate TML is given by ΣT = σ / √ N = 5/ √ 10 = 1.58 K, which corresponds to the 68.3% interval: 199.7 ± 1.6 K, i.e. the range [198.1, 201.3] K (4 s.f. accuracy). Conﬁdence intervals at 95.4% and 99% corresponds to symmetric intervals around the mean of length 2.0 and 2.57 times the standard deviation ΣT . Hence the required conﬁdence intervals are [196.5, 202.9] K (95.4%) and [195.6, 203.8] K (99%). d. A 1σ conﬁdence interval lenght 1 K means that the value of ΣT should be 1 K. Using that the standard deviation scales as 1/ √ N, we have 1 = 5/ √ N ⇒ N = 25. (47) You would need N = 25 measurements to achieve the desired accuracy. (ii) a. The measurements are independent, hence the joint likelihood is the product of the likelihoods for each measurement, see Eq. (19): L (T ) = 10 ∏ i=1 1 √ 2πσ exp ( − 1 2 ( ˆTi − T )2 σ 2 ) (48) b. the MLE for the mean of a Gaussian is given by the mean of the sample, see Eq. (22), hence 20 Bayesian Methods TML = 1 10 10 ∑ i=1 ˆTi = 199.6K. (49) c. The variance of the mean is given by Σ 2 µ = σ 2/N, where σ 2 = 25 K2 and N = 10. Therefore the standard deviation of our temperature estimate TML is given by ΣT = 5/ √ 10 = 1.6 K. The measurement can thus be summarized as T = 199.6 ± 1.6 K, where the ±1.6 K gives the range of the 1σ (or 68.3%) conﬁdence interval. (iii) a. The joint Gaussian likelihood function for ∆ is given by P(∆ |d) ≡ L (∆ ) = 5 ∏ i=1 1 √ 2πσ exp ( − 1 2 (∆ − di)2 σ 2 ) , (50) where σ = 3 cm and di are the measurements given in the question. b. The maximum likelihood estimate for ∆ is found by maximising the log- likelihood function wrt ∆ : ∂ ln L ∂ ∆ = − 5 ∑ i=1 ∆ − di σ 2 = 0 → ∆MLE = 1 N 5 ∑ i=1 di (51) The numerical value is ∆MLE = 119.4 cm ≈ 119 (cm, 3 s.f.). The uncertainty Σ on ∆ is estimated from the inverse curvature of the log likelihood function at the MLE point: − ∂ 2 ln L ∂ ∆ 2 = N σ 2 → Σ = ( − ∂ 2 ln L ∂ ∆ 2 )−1/2 = σ √ N (52) Numerically this gives Σ = 3/ √ 5 = 1.34 ≈ 1 cm. c. The measurement of ∆ would be reported as ∆ = (119 ± 1) cm. (iv) a. The likelihood function is given by L (p) = P(r = H|p, n) = ( n H )p H (1 − p) n−H , (53) where the unknown parameter is p and the data are the number of heads, H (for a ﬁxed number of trials, n = 10 here). b. The Maximum Likelihood Estimator (MLE) for the success probability p is found by maximising the log likelihood: ∂ ln L (p) ∂ p = ∂ ∂ p ( ln ( n H ) + H ln p + (n − H) ln(1 − p) ) = H p − n − H 1 − p ! = 0 ⇔ pML = H n . (54) Therefore the ML value for p is pML = 0.8. Bayesian Methods 21 c. We approximate the likelihood function as a Gaussian, with standard deviation given by minus the curvature of the log-likelihood at the peak: L (p) ≈ Lmax exp ( − 1 2 (pML − p)2) Σ 2 ) , (55) where Σ −2 = − ∂ 2 ln L (p) ∂ p2 ∣ ∣ ∣p=pML = − ∂ ∂ p ( H p − n − H 1 − p ) ∣ ∣ ∣p=pML = H − 2H p + p2n p2(1 − p)2 ∣ ∣ ∣p=pML = n H n ( 1 − H n ) . (56) The 1σ conﬁdence interval for p is given by Σ = 0.13. Therefore the result would be reported as p = 0.80 ± 0.13. d. Following the hint, the number of σ conﬁdence with which the hypothesis that the coin is fair can be ruled out is given by |pML − 1 2 | Σ = 0.8 − 0.5 0.13 = 2.31. (57) Therefore the fairness hypothesis can be ruled out at the ∼ 2.3 σ level. e. Using above equations, the MLE for the success probability is still pML = 0.8, as before. However, the uncertainty is now much reduced, because of the large number of trials. In fact, we get Σ = 0.013 (notice how the uncertainty has de- creased by a factor of √ n, as expected. I.e., 100 times more trials correspond to a reduction in the uncertainty by a factor of 10). The fairness hypothesis can now be excluded with much higher conﬁdence:s of p = 1/2, expressed in number of sigmas: number of sigmas = |pML − 1 2 | Σ = 0.8 − 0.5 0.013 = 23.1 ≈ 23. (58) This constitutes very strong evidence against the hypothesis that the coin is fair. Notice however that the Gaussian approximation to the likelihood we em- ployed will most probably not be accurate so far into the tails of the likelihood function (i.e., the Taylor expansion on which it is based is a local expansion around the peak). (v) a. The discrete PMF for the number of counts r of a Poisson process with average rate λ is (assuming a unit time, t = 1 throughout) P(r) = λ r r! e −λ . b. In this case P(ˆri| λ ) = λ ˆri ˆri! e −λ , 22 Bayesian Methods for each independent measurement ˆri. So the joint likelihood is given by (as measurements are independent) L (λ ) = M ∏ i=1 P(ˆri| λ ) = M ∏ i=1 λ ˆri ˆri! e−λ . (59) c. The Maximum Likelihood Principle states that the estimator for λ can be derived by ﬁnding the maximum of the likelihood function. The maximum is found more easily by considering the log of the likelihood ln L (λ ) = M ∑ i=1 [ˆri ln(λ ) − ln(ˆri!) − λ ] . with the maximum given by the condition dln L /dλ = 0. We have dln L dλ = M ∑ i=1 [ ˆri λ − 1 ] = 1 λ M ∑ i=1 ˆri − M . So the Maximum Likelihood (ML) estimator for λ is λML = 1 M M ∑ i=1 ˆri , which is just the average of the observed counts. d. The Taylor expansion is ln L (λ ) = ln L (λML)+ dln L dλ ∣ ∣ ∣ ∣ λ =λML (λ −λML)+ 1 2 d2ln L dλ 2 ∣ ∣ ∣ ∣ λ =λML (λ −λML) 2 +. . . . By deﬁnition the linear term vanishes at the maximum so we just need the curvature around the ML point d2ln L dλ 2 = − M ∑ i=1 ˆri λ 2 , such that d2ln L dλ 2 ∣ ∣ ∣ ∣ λ =λML = − 1 λ 2 ML M ∑ i=1 ˆri = − MλML λ 2 ML = − M λML . Putting this into the Taylor expansion gives Bayesian Methods 23 ln L (λ ) = ln L (λML) − 1 2 M λML (λ − λML) 2 , which gives an approximation of the likelihood function around the ML point L (λ ) ≈ L0 exp ( − 1 2 M λML (λ − λML) 2) , (the normalisation constant L0 is irrelevant). So the likelihood is approximated by a Gaussian with variance Σ 2 = λML M . e. Comparing this with the standard result for the variance of the mean for the Gaussian case, i.e. Σ 2 = σ 2 M , where M is the number of measurements and σ is the standard deviation of each measurement, we can conclude that the variance of the Poisson distribu- tion itself is indeed σ 2 = λ . (vi) a. The likelihood function is given by the Poisson distribution evaluated as a function of the parameter, λ : L (ˆr) = P(ˆr|λ ) = (λt)ˆr ˆr! exp(−λt), (60) where t is the time of observation in minutes. The unknown parameter is the source strength λ (in units of photons/min), while the data are the observed counts, ˆr. b. We can compute the requested probability by substituting in the Poisson dis- tribution above the values for ˆr and λ , obtaining: P(ˆr = 15|λ = 10,t = 1 min) = 0.0347. (61) c. The maximum likelihood estimate is obtained by ﬁnding the maximum of the log likelihood as a function of the parameter (here, the rate λ ). Hence we need to ﬁnd the value of λ such that: ∂ ln L (ˆr) ∂ λ = 0. (62) The derivative gives ∂ ln L (ˆr) ∂ λ = ∂ ∂ λ (ˆr ln(λt) − ln ˆr! − λt) = ˆr t λt − t = 0 ⇔ λMLE = ˆr t . (63) 24 Bayesian Methods So the maximum likelihood estimator for the rate is the observed number of counts divided by the time, in agreement with Eq. (212). In this case, t = 1 min so the MLE for λ is 10 photons per minute. d. The likelihood function now needs to be modiﬁed to account for the fact that the observed counts are the superposition of the background rate and the source rate (the star). According to the hint, the likelihood for the total number counts, ˆrt , is Poisson with rate λ = λs + λb, and thus P(ˆrt |λ = λs + λb) = (λtt )ˆrt ˆrt ! exp(−λtt ). (64) Similarly to what we have done above, the MLE estimate for λs is found by setting to 0 the derivative of the log likelihood wrt λs: ∂ ln P(ˆrt |λ = λs + λb) ∂ λs = ˆrt tt (λs + λb)tt − tt = 0 ⇔ λs = ˆrt tt − λb. (65) So the MLE for the source is given by the observed average total rate ( ˆrt tt ) minus the background rate. e. Inserting the numerical results, we have that λs = 3. The MLE estimate for λs gives a negative rate if ˆrt /tt < λb, which is clearly non-physical. However, this can deﬁnitely happen because of downwards ﬂuctuations in the number counts due to the Poisson nature of the signal (even if the background is assumed to be known perfectly). So this is an artefact of the MLE estimator (nothing to do with physics! We know that the actual physical source rate has to be a non-negative quantity!). The solution is to use Bayes theorem instead. (vii) a. The photon counts follow a Poisson distribution. We know that the MLE for the Poisson distribution is the observed number of counts (n) and its standard deviation is √ n. However, for large n (≫ 20) the Poisson distribution is well approximated by a Gaussian of mean n and standard deviation √ n. In this case, n is of order 105, hence the standard deviation intrinsic to the Poisson process (the so-called “shot noise”) is of order √ 105 ≈ 3 · 102. The quoted ex- perimental uncertainty is much larger than that (of order 104 for each datum), hence we can conclude that the statistical error is dominated by the noise in the detector rather than by the Poisson variance. Therefore we can approximate the likelihood for each observation as a Gaus- sian with mean given by the observed counts ˆni and standard deviation given by the quoted error, ˆσi: Li(F) = 1 √ 2π ˆσi exp ( − 1 2 (F − ˆni)2 ˆσ 2 i ) (i = 1, . . . , 4). (66) b. Since the measurements are independent, the joint likelihood is the product of the 4 terms: L (F) = 4 ∏ i=1 Li(F). (67) Bayesian Methods 25 c. To estimate the mean of the distribution, we apply the MLE procedure for the mean (F), obtaining: ∂ ln L (F) ∂ F = −∑ i F − ˆni ˆσ 2 i ! = 0 ⇔ FML = ∑ i ˆni ˆσ 2 i / ¯σ 2 , (68) where 1 ¯σ 2 ≡ ∑ i 1 ˆσ 2 i . (69) We thus see that the ML estimate for the mean is the mean of the observed counts weighted by the inverse error on each on them (verify that Eq. (68) re- verts to the usual expression for the sample mean for ˆσi = ˆσ for (i = 1, . . . , 4), i.e., if all observations have the same error). This automatically gives more weight to observations with a smaller error. From the given observations, one thus obtains FML = 29.2 × 104 photons/cm2. By comparison the sample mean is ¯F = 30.3 × 104 photons/cm2. d. The inverse variance of the mean is given by the second derivative of the log- likelihood evaluated at the ML estimate: Σ −2 = − ∂ 2 ln L (F) ∂ F 2 ∣ ∣ ∣ F=FML = ∑ i 1 ˆσ 2 i . (70) (again, it is simple to verify that the above formula reverts to the usual N/ ˆσ 2 expression if all measurements have the same error). Therefore the variance of the mean is given by Σ 2 = 2.16×108 (photons/cm2)2, and the standard deviation is Σ = 1.47 × 104 photons/cm2. Our measurement can thus be summarized as F = (29.2 ± 1.5) × 104 photons/cm2. 3 Bayesian parameter inference In this section we introduce the meaning and practical application of Bayes Theo- rem, Eq. (4), which encapsulates the notion of probability as degree of belief. 3.1 Bayes theorem as an inference device As a mathematical result, Bayes Theorem is elementary and uncontroversial. It be- comes interesting for the purpose of inference when we replace in Bayes theorem, Eq. (4), A → θ (the parameters) and B → d (the observed data, or samples), obtain- ing 26 Bayesian Methods P(θ |d) = P(d|θ )P(θ ) P(d) . (71) On the LHS, P(θ |d) is the posterior probability for θ (or “posterior” for short), and it represents our degree of belief about the value of θ after we have seen the data d. On the RHS, P(d|θ ) = L (θ ) is the likelihood we already encountered. It is the probability of the data given a certain value of the parameters. The quantity P(θ ) is the prior probability distribution (or “prior” for short). It represents our degree of belief in the value of θ before we see the data (hence the name). This is an essential ingredient of Bayesian statistics. The Bayesian school is divided between “subjectivists” (who maintain that the prior is a reﬂection of the subject state of knowledge of the individual researcher adopting it) and “ob- jectivists” (who argue for the use of “standard” priors to enforce inter-subjectivity between different researchers). However formulated, the posterior distribution usu- ally converges to a prior-independent regime for sufﬁciently large data sets. In the denominator, P(d) is a normalizing constant (often called “the evidence” or “marginal likelihood”), than ensures that the posterior is normalized to unity: P(d) = ∫ dθ P(d|θ )P(θ ). (72) The evidence is important for Bayesian model selection (see section 4). Interpretation: Bayes theorem relates the posterior probability for θ (i.e., what we know about the parameter after seeing the data) to the likelihood and the prior (i.e., what we knew about the parameter before we saw the data). It can be thought of as a general rule to update our knowledge about a quantity (here, θ ) from the prior to the posterior. Remember that in general P(θ |d) ̸= P(d|θ ), i.e. the posterior P(θ |d) and the likelihood P(d|θ ) are two different quantities with different meaning! Example 15. We want to determine if a randomly-chosen person is male (M) or fe- male (F)5. We make one measurement, giving us information on whether the person is pregnant (Y) or not (N). Let’s assume we have observed that the person is preg- nant, so d = Y . The likelihood is P(d = Y |θ = F) = 0.03 (i.e., there is a 3% probability that a randomly selected female is pregnant), but the posterior probability P(θ = F|d = Y ) = 1.0, i.e., if we have observed that the person is pregnant, we are sure she is a woman. This shows that the likelihood and the posterior probability are in general different! This is because they mean two different things: the likelihood is the probability of making the observation if we know what the parameter is (in this example, if we know that the person is female); the posterior is the probability of the parameter 5 This example is due to Louis Lyons. Bayesian Methods 27 given that we have made a certain observation (in this case, the probability of a person being female if we know she is pregnant). The two quantities are related by Bayes theorem (prove this in the example given here). Bayesian inference works by updating our state of knowledge about a parameter (or hypothesis) as new data ﬂow in. The posterior from a previous cycle of observa- tions becomes the prior for the next. 3.2 Advantages of the Bayesian approach Irrespectively of the philosophical and epistemological views about probability, as physicists we might as well take the pragmatic view that the approach that yields demonstrably superior results ought to be preferred. In many real–life cases, there are several good reasons to prefer a Bayesian viewpoint: (i) Classic frequentist methods are often based on asymptotic properties of estima- tors. Only a handful of cases exist that are simple enough to be amenable to analytic treatment (in physical problems one most often encounters the Normal and the Poisson distribution). Often, methods based on such distributions are em- ployed not because they accurately describe the problem at hand, but because of the lack of better tools. This can lead to serious mistakes. Bayesian inference is not concerned by such problems: it can be shown that application of Bayes’ The- orem recovers frequentist results (in the long run) for cases simple enough where such results exist, while remaining applicable to questions that cannot even be asked in a frequentist context. (ii) Bayesian inference deals effortlessly with nuisance parameters. Those are pa- rameters that have an inﬂuence on the data but are of no interest for us. For example, a problem commonly encountered in astrophysics is the estimation of a signal in the presence of a background rate The particles of interest might be photons, neutrinos or cosmic rays. Measurements of the source s must account for uncertainty in the background, described by a nuisance parameter b. The Bayesian procedure is straightforward: infer the joint probability of s and b and then integrate over the uninteresting nuisance parameter b (“marginalization”, see Eq. (94)). Frequentist methods offer no simple way of dealing with nuisance parameters (the very name derives from the difﬁculty of accounting for them in classical statistics). However neglecting nuisance parameters or ﬁxing them to their best–ﬁt value can result in a very serious underestimation of the uncertainty on the parameters of interest. (iii) In many situations prior information is highly relevant and omitting it would result in seriously wrong inferences. The simplest case is when the parameters of interest have a physical meaning that restricts their possible values: masses, count rates, power and light intensity are examples of quantities that must be positive. Frequentist procedures based only on the likelihood can give best–ﬁt estimates that are negative, and hence meaningless, unless special care is taken 28 Bayesian Methods (for example, constrained likelihood methods). This often happens in the regime of small counts or low signal to noise. The use of Bayes’ Theorem ensures that relevant prior information is accounted for in the ﬁnal inference and that physi- cally meaningless results are weeded out from the beginning. (iv) Bayesian statistics only deals with the data that were actually observed, while frequentist methods focus on the distribution of possible data that have not been obtained. As a consequence, frequentist results can depend on what the exper- imenter thinks about the probability of data that have not been observed. (this is called the “stopping rule” problem). This state of affairs is obviously absurd. Our inferences should not depend on the probability of what could have hap- pened but should be conditional on whatever has actually occurred. This is built into Bayesian methods from the beginning since inferences are by construction conditional on the observed data. The cosmology and astrophysics communities have been embracing Bayesian meh- ods since the turning of the Millennium, spurred by the availability of cheap com- putational power that has ushered in an era of high-performance computing, thus allowing for the ﬁrst time to deploy the power of Bayesian statistics thanks to nu- merical implementations (in particular, MCMC and related techniques). The steep increase in the number of Bayesian papers in the astrophysics literature is shown in Fig. 3. YearNumber of papers normalized to 1980 \"Bayesian\" papers All astrophysics papers The rise of Bayesian methods in astrophysics 1980 1985 1990 1995 2000 2005 2010 10 0 10 1 10 2 Fig. 3 Number of articles in astronomy and cosmology with “Bayesian” in the title, as a function of publication year (upper data points) and total number of articles (lower data points) as a func- tion of publication year. Numbers are normalized to 1980 levels for each data series. The number of Bayesian papers doubles every 4.3 years, while the total number of papers doubles “only” ev- ery 12.6 years. At the present rate, by 2060 all papers on the archive will be Bayesian. (source: NASA/ADS). Bayesian Methods 29 3.3 Considerations and caveats on priors Bayesian inference works by updating our state of knowledge about a parameter (or hypothesis) as new data ﬂow in. The posterior from a previous cycle of observations becomes the prior for the next. The price we have to pay is that we have to start somewhere by specifying an initial prior, which is not determined by the theory, but it needs to be given by the user. The prior should represent fairly the state of knowledge of the user about the quantity of interest. Eventually, the posterior will converge to a unique (objective) result even if different scientists start from different priors (provided their priors are non-zero in regions of parameter space where the likelihood is large). See Fig. 4 for an illustration. (a) (b) (c) (d) Fig. 4 Converging views in Bayesian inference. Two scientists having different prior believes p(θ ) about the value of a quantity θ (panel (a), the two curves representing two different priors) observe one datum with likelihood L (θ ) (panel (b)), after which their posteriors p(θ |d) (panel (c), ob- tained via Bayes Theorem, Eq. (4)) represent their updated states of knowledge on the parameter. This posterior then becomes the prior for the next observation. After observing 100 data points, the two posteriors have become essentially indistinguishable (d). There is a vast literature about how to select a prior in an appropriate way. Some aspects are fairly obvious: if your parameter θ describes a quantity that has e.g. to be strictly positive (such as the number of photons in a detector, or an amplitude), then the prior will be 0 for values θ < 0. A standard (but by no means harmless, see below) choice is to take a uniform prior (also called “ﬂat prior”) on θ , deﬁned as: P(θ ) = { 1 (θmax−θmin) for θmin ≤ θ ≤ θmax 0 otherwise (73) With this choice of prior in Bayes theorem, Eq. (71), the posterior becomes func- tionally identical to the likelihood up to a proportionality constant: P(θ |d) ∝ P(d|θ ) = L (θ ). (74) In this case, all of our previous results about the likelihood carry over (but with a different interpretation). In particular, the probability content of an interval around 30 Bayesian Methods the mean for the posterior should be interpreted as a statement about our degree of belief in the value of θ (differently from conﬁdence intervals for the likelihood). Example 16. Let’s look once more to the temperature estimation problem of Eq. (39). The Bayesian estimation of the temperature proceeds as follows. We ﬁrst need to specify the likelihood function – this is the same as before, and it is given by Eq. (39). If we want to estimate the temperature, we need to compute the posterior probability for T , given by (up to a normalization constant) P(T |d) ∝ L (T )P(T ) (75) where the likelihood L (T ) is given by Eq. (39). We also need to specify the prior, P(T ). For this particular case, we know that T > 0 (the temperature in K of an object needs to be positive) and let’s assume we know that the temperature cannot exceed 300 K. Therefore we can pick a ﬂat prior of the form P(T ) = { 1 300 for 0K ≤ T ≤ 300K 0 otherwise. (76) The posterior distribution for T then becomes P(T |d) ∝ { L (T ) 300 for 0K ≤ T ≤ 300K 0 otherwise. (77) So the posterior is identical to the likelihood (up to a proportionality constant), at least within the range of the ﬂat prior. Hence we can conclude that the posterior is going to be a Gaussian (just like the likelihood) and we can immediately write the 68.3% posterior range of T as 198.0K < µ < 201.2K. This is numerically identical to our results obtained via the MLE. However, in this case the interpretation of this interval is that “after seeing the data, and given our prior as speciﬁed in Eq. (76), there is 68.3% probability that the true value of the temperature lies within the range 198.0K < µ < 201.2K”. Under a change of variable, Ψ = Ψ (θ ), the prior transforms according to: P(Ψ ) = P(θ ) ∣ ∣ ∣det ( ∂ θ ∂Ψ ) ∣ ∣ ∣. (78) In particular, a ﬂat prior on θ is no longer ﬂat in Ψ if the variable transformation is non-linear. It is important to realize that a ﬂat prior is far from harmless, especially in param- eter spaces of high dimensionality. This is the so-called “concentration of measure” phenomenon. Sampling uniformly (i.e., with a uniform prior) along each dimension xi ∈ [0, 1] of a D-dimensional hypercube leads to the radius r = ( ∑ D i=1 x2 i )1/2 of the samples to concentrate around the value ⟨r⟩ = (D/3)1/2 with constant variance. As a consequence, all of the samples are found on a thin shell (see Fig. 5 for an illustra- tion). Even worse, in D dimensions the volume of the hypercube is much larger than the volume of the hypersphere, hence most of the volume is in the corners of the hy- Bayesian Methods 31 DimensionsRadius Concentration of measure Theoretical maximum Observed samples (flat prior on coordinates) 10 20 30 40 50 60 70 80 90 100 0 1 2 3 4 5 6 7 8 9 Fig. 5 Illustration of the phenomenon of the concentration of measure in parameter spaces with a large number of dimensions. The coloured band represents the density of samples (as a function of the number of dimensions sampled) obtained with a ﬂat prior on the axis coordinates of a D- dimensional hypercube. It can be seen that samples from the prior concentrate in a thin shell of constant variance, leaving most of the parameter space unexplored. The radius of the shell is given in the vertical axis. percube which are not sampled. This means that an MCMC in D dimensions (where D is large) has a prior distribution that is far from being uniformly distributed in the volume of the hypercube – although any 2-dimensional projection will apparently belie this. A sensitivity analysis should always be performed, i.e., change the prior in a reasonable way and assess how robust the ensuing posterior is. Unfortunately, this is seldom done in the astrophysics and cosmology literature. There is a vast body of literature on different types of priors, when to use them and what they are good for. It is a good idea to browse the literature when faced with a new problem, as there is no point in re-inventing the wheel every time. There are essentially two schools of thought: one maintains that priors should be chosen according to subjective degree of belief; the other, that they should be selected ac- cording to some formal rule, i.e. priors should be chosen by convention. None of the two approaches is free from difﬁculties. To give but some relevant examples: • reference priors: the idea is to deﬁne a prior so that the contribution of the data to the posterior is maximised. This is achieved by choosing a prior with maximum entropy. For example, in the case of a Gaussian likelihood this leads to the con- clusion that the proper prior for the mean µ is ﬂat on µ, while for the standard deviation σ is should be ﬂat in log σ (with appropriate cutoffs of course). • ignorance priors: in 1812 Laplace set forth the principle that when nothing else is known priors should be chosen so as to give equal probability to all alterna- tives (“the principle of indifference”). Unfortunately this is very difﬁcult to do in the case of continuous parameters: part of the reason is that the notion of “indif- ference” is not invariant under non-linear reparameterizations. In some relatively simple cases, ignorance priors can be derived using symmetry or invariance ar- guments, see for examples [27]. 32 Bayesian Methods • conjugate priors: a prior is said to be conjugate to the likelihood if the result- ing posterior is of the same family as the likelihood. The convenience of having conjugate priors is that the likelihood updates the prior to a posterior which is of the same type (i.e., same distributional family). For example, Gaussian distribu- tions are self-conjugate, i.e., a Gaussian prior with a Gaussian likelihood leads to a Gaussian posterior; the conjugate prior to both the Poisson and the expo- nential likelihood is the Gamma distribution; the conjugate prior to a Binomial likelihood is the Beta distribution. 3.4 A general Bayesian solution to inference problems The general Bayesian recipe to inferential problems can be summarised as follows: (i) Choose a model containing a set of hypotheses in the form of a vector of param- eters, θ (e.g., the mass of an extra–solar planet or the abundance of dark matter in the Universe). (ii) Specify the priors for the parameters. Priors should summarize your state of knowledge about the parameters before you consider the new data, including an relevant external source of information. (iii) Construct the likelihood function for the measurement, which usually reﬂects the way the data are obtained (e.g., a measurement with Gaussian noise will be represented by a Normal distribution, while γ–ray counts on a detector will have a Poisson distribution for a likelihood). Nuisance parameters related to the measurement process might be present in the likelihood, e.g. the variance of the Gaussian might be unknown or the background rate in the absence of the source might be subject to uncertainty. Such nuisance parameters are included in the likelihood (with appropriate prior). If external measurements are available for the nuisance parameters, they can be incorporated either as an informative prior on them, or else as additional likelihood terms. (iv) Obtain the posterior distribution (usually, up to an overall normalisation constant) either by analytical means or, more often, by numerical methods (see below for MCMC and nested sampling algorithms to this effect). The posterior pdf for one parameter at the time is obtained by marginalization, i.e., by integrating over the uninteresting parameters. E.g., assume the the vector of parameters is given by θ = {φ , ψ}, then the 1D posterior pdf for φ alone is given by p(φ |d) ∝ ∫ L (φ , ψ)p(φ , ψ)dψ. (79) The ﬁnal inference on φ from the posterior can then be communicated by plotting p(φ |d), with the other components marginalized over. From an MCMC chain, one can also obtain the proﬁle likelihood, Eq. (35), by maximising the value of the likelihood in each bin. The proﬁle likelihood is expected to be prior-independent, as long as the scan has gathered a sufﬁcient number of sam- Bayesian Methods 33 ples in the favoured region, which is in general a difﬁcult task for multi-dimensional parameter spaces. It is also typically much more expensive to compute as it requires a much larger number of samples than the posterior. The proﬁle likelihood and the Bayesian posterior ask two different statistical questions of the data: the latter evaluates which regions of parameter space are most plausible in the light of the measure implied by the prior; the former singles out regions of high quality of ﬁt, independently of their extent in parameter space, thus disregarding the possibility of them being highly ﬁne tuned. The information con- tained in both is relevant and interesting, and for non-trivial parameter spaces the two different approaches do not necessarily lead to the same conclusions6. 3.5 The Gaussian linear model As idealised a case as it is, the Gaussian linear model is a great tool to hone your computational skills and intuition. This is because it can be solved analytically, and any numerical solution can be compared with the exact one. Furthermore, it applies in an approximate way to many cases of interest. Here we solve analytically the gen- eral problem in n dimensions. An application to the 2-dimensional case is then given in the Exercises, section 3.9.2. For a more complete discussion, see [31], where the general case is treated (including errors on the independent variable, general cor- relations, missing data, upper limits, selection effects and the important subject of Bayesian hierarchical modelling). We consider the following linear model y = Fθ + ε (80) where the dependent variable y is a d-dimensional vector of observations (the data), θ = {θ1, θ2, . . . , θn} is a vector of dimension n of unknown parameters that we wish to determine and F is a d × n matrix of known constants which specify the rela- tion between the input variables θ and the dependent variables y (so-called “design matrix”). In the following, we will specialize to the case where observations yi(x) are ﬁtted with a linear model of the form f (x) = ∑ n j=1 θ jX j(x). Then the matrix F is given by the basis functions X j evaluated at the locations xi of the observations, Fi j = X j(xi). Notice that the model is linear in θ j, not necessarily in X j, i.e. X j can very well be a non-linear function of x. Furthermore, ε is a d-dimensional vector of random variables with zero mean (the noise). We assume for simplicity that ε follows a multivariate Gaussian distri- bution with uncorrelated covariance matrix C ≡ diag(τ 2 1 , τ 2 2 , . . . , τ 2 d ). The likelihood function takes the form 6 In the archetypal case of a Gaussian likelihood and uniform prior, the posterior pdf and the proﬁle likelihood are identical (up to a normalisation constant) and thus the question of which to choose does not arise. 34 Bayesian Methods p(y|θ ) = 1 (2π)d/2 ∏ j τ j exp [ − 1 2 (b − Aθ ) t (b − Aθ ) ] , (81) where we have deﬁned Ai j = Fi j/τi and bi = yi/τi where A is a d × n matrix and b is a d-dimensional vector. This can be re-cast with some simple algebra as p(y|θ ) = L0 exp [ − 1 2 (θ − θ0) t L(θ − θ0) ] , (82) with the likelihood Fisher matrix L (a n × n matrix) given by L ≡ A t A (83) and a normalization constant L0 ≡ 1 (2π)d/2 ∏ j τ j exp [ − 1 2 (b − Aθ0) t (b − Aθ0) ] . (84) Here θ0 denotes the parameter value which maximises the likelihood (i.e., the max- imum likelihood value for θ ), given by θ0 = L−1A t b. (85) We assume as a prior pdf a multinormal Gaussian distribution with zero mean and the n × n dimensional prior Fisher information matrix P (recall that that the Fisher information matrix is the inverse of the covariance matrix), i.e. p(θ ) = |P|1/2 (2π)n/2 exp [ − 1 2 θ t Pθ ] , (86) where |P| denotes the determinant of the matrix P. It can be shown that the posterior distribution for θ is given by multinormal Gaussian with Fisher information matrix F F = L + P (87) and mean ¯θ given by ¯θ = F −1Lθ0. (88) Finally, the model likelihood (or “Bayesian evidence”, i.e., the normalizing con- stant in Bayes theorem) is given by p(y) = L0 |F |−1/2 |P|−1/2 exp [ − 1 2 θ t 0(L − LF −1L)θ0 ] = L0 |F |−1/2 |P|−1/2 exp [ − 1 2 (θ t 0Lθ0 − ¯θ t F ¯θ ) ] . (89) Bayesian Methods 35 3.6 Markov Chain Monte Carlo methods 3.6.1 General theory The purpose of a Markov chain Monte Carlo algorithm is to construct a sequence of points (or “samples”) in parameter space (called “a chain”). The crucial property of the chain is that the density of samples is proportional to the posterior pdf. This allows to construct a map of the posterior distribution. A Markov chain is deﬁned as a sequence of random variables {X (0), X (1), . . . , X (M−1)} such that the probability of the (t + 1)–th element in the chain only depends on the value of the t–th element. The crucial property of Markov chains is that they can be shown to converge to a stationary state (i.e., which does not change with t) where successive elements of the chain are samples from the target distribution, in our case the posterior p(θ |d). The generation of the elements of the chain is probabilistic in nature, and is de- scribed by a transition probability T (θ (t), θ (t+1)), giving the probability of moving from point θ (t) to point θ (t+1) in parameter space. A sufﬁcient condition to obtain a Markov Chain is that the transition probability satisfy the detailed balance condition p(θ (t)|d)T (θ (t), θ (t+1)) = p(θ (t+1)|d)T (θ (t+1), θ (t)). (90) This is perhaps clearer when recast as follows: T (θ (t), θ (t+1)) T (θ (t+1), θ (t)) = p(θ (t+1)|d) p(θ (t)|d) , (91) i.e.˙ratio of the transition probabilities is inversely proportional to the ratio of the posterior probabilities at the two points. Once samples from the posterior pdf have been gathered, obtaining Monte Carlo estimates of expectations for any function of the parameters becomes a trivial task. The posterior mean is given by E[θ ] = ∫ P(θ |d)θ dθ ≈ 1 M M−1 ∑ t=0 θ (t), (92) where the (approximate) equality with the mean of the samples from the MCMC follows because the samples θ (t) are generated from the posterior by construction. One can easily obtain the expectation value of any function of the parameters f (θ ) as E[ f (θ )] ≈ 1 M M−1 ∑ t=0 f (θ (t)). (93) It is usually interesting to summarize the results of the inference by giving the 1– dimensional marginal probability for the j–th element of θ , θ j, obtained by inte- grating out all other parameters from the posterior: 36 Bayesian Methods P(θ1|d) = ∫ P(θ |d)dθ2 . . . dθn, (94) where P(θ1|d) is the marginal posterior for the parameter θ1. While this would usu- ally require an n − 1-dimensional integration (which can be numerically difﬁcult), it is easily obtained from the Markov chain. Since the elements of the Markov chains are samples from the full posterior, P(θ |d), their density reﬂects the value of the full posterior pdf. It is then sufﬁcient to divide the range of θ1 in a series of bins and count the number of samples falling within each bin, simply ignoring the co- ordinates values θ2, . . . , θn. A 2–dimensional posterior is deﬁned in an analogous fashion. A 1D 2–tail symmetric α% credible region is given by the interval (for the pa- rameter of interest) within which fall α% of the samples, obtained in such a way that a fraction (1 − α)/2 of the samples lie outside the interval on either side. In the case of a 1–tail upper (lower) limit, we report the value of the quantity below (above) which α% of the sample are to be found. Credible regions for a given probability content α can be deﬁned in an inﬁnite number of ways. Two deﬁnitions are commonly used. The ﬁrst is “symmetric credi- ble interval” (in 1D) given above. The second deﬁnition is that of Highest Posterior Density (HPD) regions. They are obtained by starting from the maximum of the posterior and reducing the level until the desired fraction α of the posterior proba- bility mass is included. Such a deﬁnition delimits a region so that every point inside it has by construction a higher posterior density than any point outside it. For a given probability content α, the HPD region is also the shortest interval. For a Normal 1D posterior, the HPD is identical to the symmetric credible region. 3.6.2 The Metropolis-Hastings algorithm The simplest (and widely used) MCMC algorithm is the Metropolis-Hastings algo- rithm [43, 24]: (i) Start from a random point θ (0), with associated posterior probability p0 ≡ p(θ (0)|d). (ii) Propose a candidate point θ (c) by drawing from the proposal distribution q(θ (0), θ (c)). The proposal distribution might be for example a Gaussian of ﬁxed width σ cen- tered around the current point. For the Metropolis algorithm (as opposed to the more general form due to Hastings), the distribution q satisﬁes the symmetry condition, q(x, y) = q(y, x). (iii) Evaluate the posterior at the candidate point, pc = p(θ (c)|d). Accept the candi- date point with probability α = min ( pcq(θ (c), θ (0)) p0q(θ (0), θ (c)) , 1 ) . (95) For the Metropolis algorithm (where q is symmetric), this simpliﬁes to Bayesian Methods 37 α = min ( pc p0 , 1) . (96) This accept/reject step can be performed by generating a random number u from the uniform distribution [0, 1) and accepting the candidate sample if u < α, and rejecting it otherwise. (iv) If the candidate point is accepted, add it to the chain and move there. Otherwise stay at the old point (which is thus counted twice in the chain). Go back to (ii). Notice from Eq. (96) that whenever the candidate sample has a larger posterior than the previous one (i.e., pc > p0) the candidate is always accepted. Also, in order to evaluate the acceptance function (96) only the unnormalized posterior is required, as the normalization constant drops out of the ratio. It is easy to show that the Metropo- lis algorithm satisﬁes the detailed balance condition, Eq. (90), with the transition probability given by T (θ (t), θ (t+1)) = q(θ (t), θ (t+1))α(θ (t), θ (t+1)). Ref [20] shows that an optimal choice of the proposal distribution is such that it leads to an acceptance rate of approximately 25% (where acceptance rate is the ratio of the number of accepted jumps to the total number of likelihood evaluations). The optimal scale of the proposal distribution is approximately 2.4/ √ d times the scale of the target distribution, where d is the number of dimensions of the parameter space. The choice of proposal distribution q is crucial for the efﬁcient exploration of the posterior. If the scale of q is too small compared to the scale of the target distribution, exploration will be poor as the algorithm spends too much time locally. If instead the scale of q is too large, the chain gets stuck as it does not jump very frequently. To improve the exploration of the target, it is advisable to run an exploratory MCMC, compute the covariance matrix from the samples, and then re-run with this covariance matrix (perhaps rescaled by a factor 2.4/√ d as recommended by [20]) as the covariance of a multivariate Gaussian proposal distribution. This process can be iterated a couple of times. The afﬁne invariant ensemble sampler proposed by [22] evolves a series of “walkers” rather than just one sampler at the time, and uses the position of the other points in the ensemble to generate a move with greatly reduced auto-correlation length. This also largely dispenses with the need to ﬁne-tune the proposal distribution to match the target density. An algorithm that includes a suit- able parallelization of this sampling scheme is described in [19], and is implemented in a publicly available Python package, emcee7. 3.6.3 Gibbs sampling The Gibbs sampler is a particularly good choice when it is simple (and computa- tionally non-expensive) to sample from the conditional distribution of one of the parameters at the time. It has been shown to work well in a large (∼ 105) number of dimensions. 7 Available from: http://dan.iel.fm/emcee (accessed Jan 5th 2017). 38 Bayesian Methods In Gibbs sampling, each of the parameters is updated in turn by drawing the proposal distribution from the univariate conditional distribution of that variable (conditional on all the others). This is best explained in a simple example, where the parameter space is 2-dimensional and θ = {x, y}. In order to obtain the t-th sample, one draws x(t) ∼ p(x|y = y(t−1)) (97) y (t) ∼ p(y|x = x(t)). (98) (99) Notice that in the second step, when drawing y we condition on a value of x that has been updated to the latest draw of x, namely x(t). In the above, p denotes the target distribution, i.e. the posterior density (where we have omitted explicit conditioning on the data for ease of notation). In a higher number of dimensions of parameter space, one always draws the k- th variable from the conditional distribution p(θk|θ(−k)), where θ(−k) denotes the vector of variables without the k-th variable. It is perhaps slightly bafﬂing that one can obtain samples from the joint posterior merely from knowledge of the conditional distributions (although this is not gener- ally true). An explanation of why this is the case (under only very mild conditions) can be found in [11]. The Gibbs sampler can thus be seen as a special case of Metropolis-Hastings, with one-dimensional proposal distributions and an acceptance rate of 1. The above can also be generalised to blocks of variables, that are all updated si- multaneously conditional on all the others. In the so-called “blocked Gibbs sampler” one draws two (or more) variables simultaneously from p(θk, j|θ(−k, j)). This can be useful in improving the convergence if the two variables k, j are strongly correlated. A collapsed Gibbs sampler refers to the case when one of the variables has been marginalised out in one of the sampling steps, i.e. one draws from p(θk|θ(−k, j)), where the j-th variable has been marginalised from the joint. More sophisticated sampling strategies can also be employed to reduced auto-correlation and improve sampling, see [46, 46] for the Partially Collapsed Gibbs sampler, and [63] for the ancillarity-sufﬁciency interweaving strategy. 3.6.4 Hamiltonian Monte-Carlo Hamiltonian Monte Carlo is particularly appealing for physicists, as it is built on the formalism of Hamiltonian dynamics (as the name implies). Only a very sketchy introduction is possible here. Refer to [45] for further details. A Python implemen- tation of HMC can be found at: mc-stan.org. The idea is to augment the vector containing the variable of interest, q (rep- resenting position), by another vector of the same dimensionality, p (representing momentum). We then deﬁne the potential energy U(q) as the negative log of the unnormalized posterior we wish to sample from, Bayesian Methods 39 U(q) = − log(π(q)L (q)), (100) where π(q) is the prior and L (q) the likelihood function. The Hamiltonian of this ﬁctitious system is then given by H(q, p) = K(p) +U(q) (101) where K(p) represents kinetic energy, K(p) = ∑ i p2 i 2mi . (102) Here, the sum runs over the dimensionality of the parameter space, and mi are “mass values” that are chosen for convenience. If we look at the kinetic energy term as the negative log of a probability distribution, then it deﬁnes a multivariate Gaussian of 0 mean with variance along each direction given by m2 i . From analytical mechanics, we know that physical solutions are obtained by solv- ing the Hamiltonian equations: dqi dt = ∂ H ∂ pi (103) d pi dt = − ∂ H ∂ qi . (104) Such solutions have the useful properties of preserving energy (i.e., dH/dt = 0) and conserving the phase space volume (in virtue of Liouville’s theorem). Those properties are crucial in ensuring that the Hamiltonian MC (HMC) algorithm leaves the desired distribution invariant. In order to obtain a Markov Chain from the target distribution, the Hamiltonian MC algorithm performs the following steps in each iteration: (i) resample the momentum variables, pi ∼ N (0, m2 i ); (ii) obtain a new candidate location (qc, pc) in phase space by evolving the system via approximate Hamiltonian dynamics (e.g. via the leapfrog method); (iii) take a Metropolis accept/reject step at the candidate location (this is necessary as in practice numerical approximation schemes mean that the energy of the system is only approximately conserved). The Hamiltonian dynamics preserves energy, but it changes the value of both the momentum (in step (1)) and position variables (in step (2)), thus accomplishing a large jump in the parameters of interest, namely q. The key advantages of HMC is that it produces samples that are much less corre- lated than ordinary Metropolis-Hastings (in virtue of the large distance travelled via the Hamiltonian dynamics step), and that it scales well with the number of dimen- sions of the parameter space. 40 Bayesian Methods 3.6.5 Importance sampling Importance sampling is a useful technique when we want to sample from a target distribution p(x) (usually the posterior), but we have samples from another distri- bution q(x) (perhaps because the latter is simpler to sample from). In some appli- cations, q(x) could be the posterior from a certain data set, and we then want to add another data set on top of it, thus obtaining p(x). As long as p(x) is not too dissimilar from q(x), it can be obtained by importance sampling. The expectation value under p of any function f (x) of the RV x can be written as Ep[ f (x)] = ∫ f (x)p(x)dx = ∫ f (x)q(x) p(x) q(x) dx = Eq[ p(x) q(x) f (x)]. (105) This shows that we can obtain the expectation value under p by computing the expectation value under q but re-weighting the function of interest by the factor p(x)/q(x). In terms of the sampling estimate, we can write µ f ≈ 1 M ∑ M i=0 wi f (xi) ∑ M i=0 wi (106) where wi = p(xi)/q(xi) are the importance sampling weights and xi ∼ q(x). Notice that only the unnormalized values of p and q are necessary in Eq. (106), since the normalisation cancels in the ratio. 3.7 Practical and numerical issues It is worth mentioning several important practical issues in working with MCMC methods. Poor exploration of the posterior can lead to serious mistakes in the ﬁ- nal inference if it remains undetected – especially in high–dimensional parameter spaces with multi–modal posteriors. It is therefore important not to use MCMC techniques as a black box, but to run adequate tests to ensure insofar as possible that the MCMC sampling has converged to a fair representation of the posterior. Some of the most relevant aspects are: (i) Initial samples in the chain must be discarded, since the Markov process is not yet sampling from the equilibrium distribution (so–called burn–in period). The length of the burn–in period can be assessed by looking at the evolution of the posterior density as a function of the number of steps in the chain. When the chain is started at a random point in parameter space, the posterior probability will typically be small and becomes larger at every step as the chain approaches the region where the ﬁt to the data is better. Only when the chain has moved in the neighborhood of the posterior peak the curve of the log posterior as a function Bayesian Methods 41 of the step number ﬂattens and the chain begins sampling from its equilibrium distribution. Samples obtained before reaching this point must be discarded, see Fig. 6 (ii) A difﬁcult problem is presented by the assessment of chain convergence, which aims at establishing when the MCMC process has gathered enough samples so that the Monte Carlo estimate (93) is sufﬁciently accurate. Useful diagnostic tools include the Raftery and Lewis statistics [49] and the Gelman and Rubin criterion [21]. (iii) One has to bear in mind that MCMC is a local algorithm, which can be trapped around local maxima of the posterior density, thus missing regions of even higher posterior altogether. Considerable experimentation is sometimes required to ﬁnd an implementation of the MCMC algorithm that is well suited to the exploration of the parameter space of interest. Experimenting with different algorithms (each of which has its own strength and weaknesses) is highly recommended. (iv) Successive samples in a chain are in general correlated. Although this is not prej- udicial for a correct statistical inference, it is often interesting to obtain indepen- dent samples from the posterior. This can be achieved by “thinning” the chain by an appropriate factor, i.e. by selecting only one sample every K. The auto- correlation is a good measure of the number of steps required before the chain has “forgotten” its previous state. It can be estimated from the MCMC samples as ˆγ(k) = ∑M−k i=0 (θi − ¯θ )(θi+k − ¯θ ) ∑ M−k i=0 (θi − ¯θ )2 , (107) where k is called the lag and ¯x is the sample mean (the above equation should be understood component by component if the parameter vector θ is multi- dimensional). A plot of ˆγ versus lag k is called “autocorrelation function” (ACF) and the value of the lag after which it drops close to 0 provides an estimate of the thinning factor K required to obtain approximate independent samples from the chain. A discussion of samples independence and how to assess it can be found in [16], along with a convergence test based on the samples’ power spectrum. 3.8 Exercises 3.8.1 Bayesian reasoning (i) A batch of chemistry undergraduates are screened for a dangerous medical con- dition called Bacillum Bayesianum (BB). The incidence of the condition in the population (i.e., the probability that a randomly selected person has the disease) is estimated at about 1%. If the person has BB, the test returns positive 95% of the time. There is also a known 5% rate of false positives, i.e. the test returning positive even if the person is free from BB. One of your friends takes the test and 42 Bayesian Methods Fig. 6 Illustration of the burn-in period. Left panel: the logarithm of the log-likelihood, − ln P(d|θ ), as a function of the step number for four Monte Carlo chains. After the burn-in period (dotted, vertical lines), the value ﬂattens and the chains are sampling from the target distribution. Right panel: the four chains (in different colors) are started in different points of a 6-dimensional parameter space and all converge to the same region after the burn-in. The vertical axis gives the number of steps. it comes back positive. Here we examine whether your friend should be worried about her health. a. Translate the information above in suitably deﬁned conditional probabilities. The two relevant propositions here are whether the test returns positive (de- note this with a + symbol) and whether the person is actually sick (denote this with the symbol BB = 1. Denote the case when the person is healthy as BB = 0). b. Compute the conditional probability that your friend is sick, knowing that she has tested positive, i.e., ﬁnd P(BB = 1|+). c. Imagine screening the general population for a very rare desease, whose inci- dence in the population is 10−6 (i.e., one person in a million has the disease on average, i.e. P(BB = 1) = 10−6). What should the reliability of the test (i.e., P(+|BB = 1)) be if we want to make sure that the probability of actually having the disease after testing positive is at least 99%? Assume ﬁrst that the false positive rate P(+|BB = 0) (i.e, the probability of testing positive while healthy), is 5% as in part (a). What can you conclude about the feasibility of such a test? d. Now we write the false positive rate as P(+|BB = 0) = 1 − P(−|BB = 0). It is reasonable to assume (although this is not true in general) that P(−|BB = 0) = P(+|BB = 1), i.e. the probability of getting a positive result if you have the disease is the same as the probability of getting a negative result if you don’t have it. Find the requested reliability of the test (i.e., P(+|BB = 1)) so that Bayesian Methods 43 the probability of actually having the disease after testing positive is at least 99% in this case. Comment on whether you think a test with this reliability is practically feasible. (ii) In a game, you can pick one of three doors, labelled A, B and C. Behind one of the three doors lies a highly desirable price, such as for example a cricket bat. After you have picked one door (e.g., door A) the person who is presenting the game opens one of the remaining 2 doors so as to reveal that there is no prize behind it (e.g., door C might be opened). Notice that the gameshow presenter knows that the door he opens has no prize behind it. At this point you can either stick with your original choice (door A) or switch to the door which remains closed (door B). At the end, all doors are opened, at which point you will only win if the prize is behind your chosen door. a. Given the above rules (and your full knowledge of them), should you stick with your choice or is it better to switch? b. In a variation, you are given the choice to randomly pick one of doors B or C and to open it, after you have chosen door A. You pick door C, and upon opening it you discover there is nothing behind it. At this point you are again free to either stick with door A or to switch to door B. Are the probabilities different from the previous scenario? Justify your answers. (iii) In a TV debate, politician A afﬁrms that a certain proposition S is true. You trust politician A to tell the truth with probability 4/5. Politician B then agrees that what politician A has said is indeed true. Your trust in politician B is much weaker, and you estimate that he lies with probability 3/4. After you have heard politician B, what is the probability that statement S is indeed true? You may assume that you have no other information on the truth of proposition S other than what you heard from politicians A and B. Hint: Start by denoting by AT the statement “politician A tells the truth”, and by BT the statement “politician B tells the truth”. What you are after is the proba- bility of the statement “proposition S is true” after you have heard politician B say so. (iv) A body has been found on the Baltimore West Side, with no apparent wounds, although it transpires that the deceased, a Mr Fuzzy Dunlop, was a heavy drug user. The detective in charge suggests to close the case and to attribute the death to drugs overdose, rather than murder. Knowing that, of all murders in Baltimore, about 30% of the victims were drug addicts, and that the probability of a dead person having died of overdose is 50% (without further evidence apart from the body) estimate the probability that the detective’s hunch is correct. (For this problem, you may assume that the possible only causes of death are overdose or murder). 44 Bayesian Methods 3.8.2 Bayesian parameter inference (v) This problem takes you through the steps to derive the posterior distribution for a quantity of interest θ , in the case of a Gaussian prior and Gaussian likelihood, for the 1-dimensional case. Let us assume that we have made N independent measurements, ˆx = { ˆx1, ˆx2, . . . , ˆxN} of a quantity of interest θ (this could be the temperature of an object, the distance of a galaxy, the mass of a planet, etc). We assume that each of the measurements in independently Gaussian distributed with known experimental standard devia- tion σ . Let us denote the sample mean by ¯x, i.e. ¯x = 1 N N ∑ i=1 ˆxi. (108) Before we do the experiment, our state of knowledge about the quantity of in- terest θ is described by a Gaussian distribution on θ , centered around 0 (we can always choose the units in such a way that this is the case). Such a prior might come e.g. from a previous experiment we have performed. The new experiment is however much more precise, i.e. Σ ≫ σ . Our prior state of knowledge be written in mathematical form as the following Gaussian pdf: p(θ ) ∼ N (0, Σ 2). (109) a. Write down the likelihood function for the measurements and show that it can be recast in the form: L (θ ) = L0 exp ( − 1 2 (θ − ¯x)2 σ 2/N ) , (110) where L0 is a constant that does not depend on θ . b. By using Bayes theorem, compute the posterior probability for θ after the data have been taken into account, i.e. compute p(θ | ˆx). Show that it is given by a Gaussian of mean ¯x Σ 2 Σ 2+σ 2/N and variance [ 1 Σ 2 + N σ 2 ]−1. Hint: you may drop the normalization constant from Bayes theorem, as it does not depend on θ . c. Show that as N → ∞ the posterior distribution becomes independent of the prior. (vi) We already encountered the coin tossing problem, but this time you’ll do it in the Bayesian way. A coin is tossed N times and heads come up H times. a. What is the likelihood function? Identify clearly the parameter, θ , and the data. b. What is a reasonable, non-informative prior on θ ? Bayesian Methods 45 c. Compute the posterior probability for θ . Recall that θ is the probability that a single ﬂip will give heads. This integral will prove useful: ∫ 1 0 dθ θ N(1 − θ ) M = Γ (N + 1)Γ (M + 1) Γ (N + M + 2) . (111) d. Determine the posterior mean and standard deviation of θ . e. Plot your results as a function of H for N = 10, 100, 1000. f. † Generalize your prior to the Beta distribution, p(θ |ν1, ν2) = 1 B(ν1, ν2) θ ν1−1(1 − θ ) ν2−1 (112) where B(ν1, ν2) = Γ (ν1)Γ (ν2)/Γ (ν1 + ν2) is the beta function and the “hy- perparameters” ν1, ν2 > 0. Clearly, a uniform prior is given by the choice (ν1, ν2) = (1, 1). Evaluate the dependency of your result to the choice of hy- perparameters. g. † What is the probability that the (N + 1)-th ﬂip will give heads? (vii) Prove Eqs. (82), (87) and (89) in the notes for the Gaussian linear model given by y = Fθ + ε. (113) Hint: recall this standard result for Gaussian integrals: ∫ exp [ − 1 2 (x − m) t Σ −1(x − m) ] dx = √ det(2πΣ ) (114) (viii) Now we specialize to the case n = 2, i.e. we have two parameters of interest, θ = {θ1, θ2} and the linear function we want to ﬁt is given by y = θ1 + θ2x. (115) (In the formalism above, the basis vectors are X 1 = 1, X 2 = x). Table 1 gives an array of d = 10 measurements y = {y1, y2, . . . , y10}, together with the values of the independent variable xi8. Assume that the uncertainty in the same for all measurements, i.e. τi = 0.1 (i = 1, . . . , 10). You may further assume that measurements are uncorrelated. The data set is shown in the left panel of Fig. 7. a. Assume a Gaussian prior with Fisher matrix P = diag ( 10−2, 10−2) for θ . Find the posterior distribution for θ given the data, and plot it in 2 dimensions in the (θ1, θ2) plane (see right panel of Fig. 7). Use the appropriate contour levels to demarcate 1, 2 and 3 sigma joint credible intervals of the posterior. 8 This data set is also provided with this arxiv submission as an ancillary data ﬁle called LinearModelData.txt. It can be downloaded from a link below the usual article download links. 46 Bayesian Methods Table 1 Data sets for the Gaussian linear model exercise. You may assume that all data points are independently and identically distributed with standard deviation of the noise σ = 0.1. x y 0.8308 0.9160 0.5853 0.7958 0.5497 0.8219 0.9172 1.3757 0.2858 0.4191 0.7572 0.9759 0.7537 0.9455 0.3804 0.3871 0.5678 0.7239 0.0759 0.0964 xy Example data set 0 0.5 1 −2 −1 0 1 2 True model 12 Present posterior, 1−2−3 contours −0.5 0 0.5 0.5 1 1.5 2 2.5 Fig. 7 Left panel: data set for the Gaussian linear problem. The solid line shows the true value of the linear model from which the data have been generated, subject to Gaussian noise. Right panel: 2D credible intervals from the posterior distribution for the parameters. The the blue diamond is the Maximum Likelihood Estimator, from Eq. (85), whose value for this data set is x = −0.0136, y = 1.3312. b. In a language of your choice, write an implementation of the Metropolis- Hastings Markov Chain Monte Carlo algorithm, and use it to obtain samples from the posterior distribution. Plot equal weight samples9 in the (θ1, θ2) space, as well as marginalized 1- dimensional posterior distributions for each parameter. 9 Posterior samples obtained via MCMC have a weight associated with them, given by the num- ber of times the samplers has failed to jump from that particular location (i.e., the number of repeat counts of the same coordinate location in parameter space). Producing a scatter plot of such weighted samples would fail to reproduce visually their actual density, for each sample would have a different weight associated to it. Equal weight samples are obtained from the MCMC chain by normalizing all weights to unity (i.e, replacing weights wi by ui ≡ wi/maxiwi, where i = 1, . . . , N is the number of samples in the chain) and retaining each sample with probability given by ui. Bayesian Methods 47 c. Compare the credible intervals that you obtained from the MCMC with the analytical solution. (ix) Supernovae type Ia can be used as standardizable candles to measure distances in the Universe. This series of problems explores the extraction of cosmological information from a simpliﬁed SNIa toy model. The cosmological parameters we are interested in constraining are C = {Ωm, ΩΛ , h} (116) where Ωm is the matter density (in units of the critical energy density) and ΩΛ is the dark energy density, assumed here to be in the form of a cosmological constant, i.e. w = −1 at all redshifts. In the following, we will ﬁx h = 0.72, where the Hubble constant today is given by H0 = 100h km/s/Mpc, since the value of H0 is degenerate with the (unknown) absolute magnitude of the SNIas, M. In an FRW cosmology deﬁned by the parameters C , the distance modulus µ (i.e., the difference between the apparent and absolute magnitudes, µ = m − M) to a SNIa located at redshift z is given by µ(z, C ) = 5 log [ DL(z, Ωm, ΩΛ , h) Mpc ] + 25, (117) where DL denotes the luminosity distance to the SNIa. Recalling that DL = cdL/H0, we can rewrite this as µ(z, C ) = η + 5 log dL(z, Ωm, ΩΛ ), (118) where η = −5 log 100h c + 25 (119) and c is the speed of light in km/s. We have deﬁned the dimensionless luminosity distance dL(z, Ωm, ΩΛ ) = (1 + z) √ |Ωκ | sinn{ √|Ωκ | ∫ z 0 dz′[(1+z ′) 3Ωm +ΩΛ +(1+z ′) 2Ωκ ] −1/2}. (120) The curvature parameter is given by the constraint equation Ωκ = 1 − Ωm − ΩΛ (121) and the function sinn(x) =    x for a ﬂat Universe (Ωκ = 0); sin(x) for a closed Universe (Ωκ < 0); sinh(x) for an open Universe (Ωκ > 0). (122) 48 Bayesian Methods We now assume that from each SNIa in our sample we have a measurement of its distance modulus with Gaussian noise10, i.e., that the likelihood function for each SNIa i (i = 1, . . . , N) is of the form Li(zi, C , M) = 1 √ 2πσi exp ( − 1 2 ( ˆµi − µ(zi, C ))2 σ 2 i ) . (123) The observed distance modulus is given by ˆµi = ˆmi −M, where ˆmi is the observed apparent magnitude and M is the intrinsic magnitude of the SNIa. We assume that each SN observation is independent of all the others. The provided data ﬁle11 (SNIa SimulatedData) contains simulated obser- vations from the above simpliﬁed model of N = 300 SNIa. The two columns give the redshift zi and the observed apparent magnitude ˆmi. The observational error is the same for all SNe, σi = σ = 0.4 mag for i = 1, . . . , N. A plot of the data set is shown in the left panel of Fig. 8. The characteristics of the simulated SNe are designed to mimic currently available datasets (see [33, 1, 32, 50, 6]). a. We assume that the intrinsic magnitude12 is known and ﬁx M = M0 = −19.3 and that h = 0.72. We also assume that the observational error is known, given by the value above. Using a language of your choice, write a code to carry out an MCMC sampling of the posterior probability for (Ωm, ΩΛ ) and plot the resulting 68% and 95% posterior regions, both in 2D and marginalized to 1D, using uniform priors on (Ωm, ΩΛ ) (be careful to deﬁne them explicitly). You should obtain a result similar to the 2D plot shown in the right panel of Fig. 8. b. † Add the quantity σ (the observational error) to the set of unknown param- eters and estimate it from the data along with C . Notice that since σ is a “scale parameter”, the appropriate (improper) prior is p(σ ) ∝ 1/σ (see [7] for a justiﬁcation). c. The location of the peaks in the CMB power spectrum gives a precise mea- surement of the angular diameter distance to the last scattering surface, di- vided by the sound horizon at decoupling. This approximately translates into an effective constraint (see [54], Fig. 20) on the following degenerate combi- 10 We neglect the important issue of applying the empirical corrections known as Phillip’s relations to the observed light curve. This is of fundamental important in order to reduce the scatter of SNIa within useful limits for cosmological distance measurements, but it would introduce a technical complication here without adding to the fundamental scope of this exercise. Furthermore, the cor- rect likelihood function is not of the Gaussian form given here. For a fully Bayesian treatment, see e.g. [52]. 11 The dataﬁle is provided with this arxiv submission as ancillary data ﬁle. It can be downloaded from a link below the usual article download links. 12 In reality the SNIas intrinsic magnitude is not the same for all of the objects, but there is an “intrinsic dispersion” (even after Phillips’ corrections) reﬂecting perhaps intrinsic variability in the explosion mechanism, or environmental parameters which are currently poorly understood. Bayesian Methods 49redshift, z observed magnitude, mSNe data 2 (fixed σi)00.511.5121416182022242628Student Version of MATLAB Ω ΛΩMSNe data 2 (fixed σi)00.20.40.60.811.21.400.20.40.60.811.21.4Student Version of MATLAB Fig. 8 Left: Simulated SNIa dataset, SNe simulated.dat. The solid line is the true underlying cosmology. Right: constraints on Ωm, ΩΛ from this dataset, with contours delimiting 2D joint 68% and 95% credible regions (uniform priors on the variables Ωm, ΩΛ , assuming M = M0 ﬁxed and h = 0.72). The red cross denotes the true value. nation of Ωm and ΩΛ : 1.41ΩΛ + Ωm = 1.30 ± 0.04. (124) Add this constraint (assuming a Gaussian likelihood, with the above mean and standard deviation) to the SNIa likelihood and plot the ensuing combined 2D and 1D limits on (Ωm, ΩΛ ). d. The measurement of the baryonic acoustic oscillation scale in the galaxy power spectrum at small redshift gives an effective constraint on the angular diameter distance DA out to z ∼ 0.6. This measurement can be summarized as [2]: DA(z = 0.57) = (1408 ± 45) Mpc. (125) Add this constraints (again assuming a Gaussian likelihood) to the above CMB+SNIa limits and plot the resulting combined 2D and 1D limits on (Ωm, ΩΛ ). Hint: recall that DL(z) = (1 + z)2DA(z). 3.9 Solutions to selected exercises 3.9.1 Bayesian reasoning (i) a. Let BB = 1 denote the proposition that your friend has the virus, and BB = 0 that she does not. We use + (−) to denote the test returning a positive (nega- 50 Bayesian Methods tive) result. We know from the reliability of the test that P(+|BB = 1) = 0.95 (126) P(+|BB = 0) = 0.05 hence (127) P(−|BB = 0) = 0.95. (128) Given that 1% of the population has the virus, the probability of being one of them (before taking the test) is P(BB = 1) = 0.01, while P(BB = 0) = 0.99. b. The probability of your friend having the virus after she has tested positive is thus P(BB = 1|+) = P(+|BB = 1)P(BB = 1) P(+) . (129) We can compute the denominator as follows, by combining the marginaliza- tion rule with the product rule (a procedure that is sometimes called “expand- ing the discourse”): P(+) = P(+|BB = 1)P(BB = 1) + P(+|BB = 0)P(BB = 0) (130) = 0.95 · 0.01 + 0.05 · 0.99 = 0.059. (131) Therefore the probability that your friend has the virus is much less than 95%, namely P(BB = 1|+) = 0.95 · 0.01 0.059 = 0.16 = 16%. (132) c. From the above, we have that P(BB = 1|+) = P(+|BB = 1)P(BB = 1) P(+|BB = 1)P(BB = 1) + P(+|BB = 0)P(BB = 0) . (133) We want to achieve 99% probability that the person has BB given that they tested positive, i.e., P(BB = 1|+) = 0.99, and we need to solve the above equation for the reliability, i.e. P(+|BB = 1). We ﬁrst assume that P(+|BB = 0) = 0.05, as in part (a). Since P(BB = 1) = 10−6, it follows that P(BB = 0) = 1−P(BB = 1) ≈ 1. Then Eq. (133) becomes 0.99 = P(+|BB = 1)10−6 P(+|BB = 1)10−6 + 0.05 × 1 ≈ P(+|BB = 1)10−6 0.05 . (134) It is clear that this equation has no solution for P(+|BB = 1) ≤ 1. This means that for a 5% false positive rate and for the given incidence P(BB = 1) it is impossible to obtain a test that is 99% reliable. Therefore in order to achieve 99% reliability, the false positive rate, P(+|BB = 0), has to be reduced, as well. d. Let us denote by x = P(+|BB = 1) = P(−|BB = 0) the reliability of the test. Then requiring a value of 99% for P(BB = 1|+) amounts to solving for x the following equation: Bayesian Methods 51 0.99 = P(BB = 1|+) = xP(BB = 1) xP(BB = 1) + (1 − x)P(BB = 0) (135) where P(BB = 1) = 10−6 and P(BB = 0) = 1 − 10−6 ≈ 1. This gives for x x ≈ 1 1 + 10−8 , (136) which means that the the reliability of the test ought to be in excess of 1 in 108. This is obviously not feasible and hence it is important to screen people before administering the test, i.e., to only test people who already show symptoms of the condition. (ii) a. Let’s assume that you have chosen door A. If the prize is indeed behind that door, than the presenter opens randomly one of B or C (with probability 1/2). If the prize is behind door B, then he must open door C (and viceversa). This means: P(B open|prize behind A) = 1 2 P(C open|prize behind A) = 1 2 (137) P(B open|prize behind B) = 0 P(C open|prize behind B) = 1 (138) P(B open|prize behind C) = 1 P(C open|prize behind C) = 0 (139) If the presenter opens door C, we obtain the probability that the prize is behind each of the doors by inverting the order of conditioning as follows: P(prize behind A|C open) = P(C open|prize behind A)P(A) P(C open) (140) and P(prize behind B|C open) = P(C open|prize behind B)P(B) P(C open) (141) At the beginning of the show, the probability that the prize is behind one of the 3 doors is the same: P(A) = P(B) = P(C) = 1 3 . (142) We can compute the denominator in Eqs. (140) and (141) using again the rules of probability (in particular, the marginalisation rule): P(C open) = P(C open|prize behind A)P(A) +P(C open|prize behind B)P(B) +P(C open|prize behind C)P(C) = 1 2 · 1 3 + 1 · 1 3 + 0 · 1 3 = 1 2 . (143) 52 Bayesian Methods From Eqs. (140) et (141) it follows P(prize behind A|C open) = 1 3 , P(prize behind B|C open) = 2 3 . (144) Therefore you should switch in order to increase your probability of winning (from 1/3 to 2/3). If you are still unconvinced, here is a variant to hone your intuition: there are 1000 doors, and you pick one at the beginning. The presenter then opens 998 doors, revealing that there is no prize behind them (and he knew this when he opened them). At this point you can either switch to the last remaining closed door, or stick with the one you had originally chosen. Which way to go is at this point a no-brainer! b. In the second scenario, you choose between doors B and C randomly, and therefore the amount of information in the problem changes (in the previous case, the presenter knew behind which door the prize is). Eqs. (138) et (139) are modiﬁed as follows: P(B open|prize behind B) = 1 2 P(C open|prize behind B) = 1 2 (145) P(B open|prize behind C) = 1 2 P(C open|prize behind C) = 1 2 (146) In this case, the probability of winning is not modiﬁed by you opening a fur- ther door at random, and in fact: P(prize behind A|C open) = 1 2 , P(prize behind B|C open) = 1 2 . (147) Another, more formal argument goes as follows. The prior is given by Eq. (142) and P(C open) = ∑ i=A,B,C P(i open|prize behind i)P(prize behind i) (148) = 1 2 1 3 + 1 2 1 3 + 0 1 3 = 1 3 (149) This is because P(C open|prize behind A) = P(C open|prize behind B) = 1 2 (150) but P(C open|prize behind C) = 0 (151) since this statement is incompatible with the evidence (when C is opened at random by you, you discover that the price is not there!). So: Bayesian Methods 53 P(prize behind A|C open) = P(C open|prize behind A)P(prize behind A) P(C open) (152) = (1/2)(1/3) (1/3) = 1 2 (153) as claimed. (iii) Let ST denote the proposition “statement S is true”. Let AT denote the statement “politician A tells the truth, AL denote the statement “politician A lies” and simi- larly for BT and BL. Under your prior, P(AT ) = 4/5, P(AL) = 1/5, P(BT ) = 1/4 and P(BL) = 3/4. Let “BST“ denote the statement “Politician B says S is true“. Then using Bayes theorem: P(ST |BST ) = P(BST |ST )P(ST ) P(BST ) . (154) In the above equation, P(ST ) = P(AT ) = 4/5, as you don’t know anything else about statement S except what you heard from politician A, whom you trust to be truthful with probabilty P(AT ). Also, P(BST |ST ) = P(BT ) = 1/4, for politician B will say that statement S is true (if this is indeed the case) with probability P(BT ). It remains to compute P(BST ) = P(BST |ST )P(ST ) + P(BST |not ST )P(not ST ) = P(BT )P(AT ) + P(BL)P(AL). (155) So the posterior probability for S to be true after you have heard both politicians is P(ST |BST ) = P(BT )P(AT ) P(BT )P(AT ) + P(BL)P(AL) = 1 1 + P(BL) P(BT ) P(AL) P(AT ) = 1 1 + 3 4 = 4/7 ≈ 57%. (156) (iv) Let us denote by od = 1 the statement “Mr Dunlop died because of drugs over- dose”; by Dd = 1 the statement “Mr Dunlop is dead” and by u = 1 the statement “Mr Dunlop used drugs”. We are looking for the posterior probability that Fuzzy Dunlop died of overdose, given that he was a drug addict (u = 1) and that he is dead (Dd = 1): P(od = 1|Dd = 1, u = 1) = P(u = 1|od = 1, Dd = 1)P(od = 1|Dd = 1) P(u = 1|od = 1, Dd = 1)P(od = 1|Dd = 1) + P(u = 1|od = 0, Dd = 1)P(od = 0|Dd = 1) From the problem, we have that the probability of being a drug user and having been murdered (assuming that people only die of either overdose or murder in Baltimore) is P(u = 1|od = 0, Dd = 1) = 0.3. Also, the probability of the person 54 Bayesian Methods having died of overdose (given that we have the body) is 50%, hence P(od = 1|Dd = 1) = 50% so P(od = 0|Dd = 1) = 50%. Finally, we need to estimate the probability that Mr Dunlop was a drug user, given that he died of overdose, P(u = 1|od = 1, Dd = 1). It seems highly unlikely that somebody would die of overdose the ﬁrst time they try drugs, so perhaps we can assign P(u = 1|od = 1, Dd = 1) = 0.9. So we have that P(od = 1|Dd = 1, u = 1) = 1 1 + P(u=1|od=0,Dd=1)P(od=0|Dd=1) P(u=1|od=1,Dd=1)P(od=1|Dd=1) = 1 1 + 3/9 = 75%. How sensitive is this conclusion to our guess for P(u = 1|od = 1, Dd = 1)? Changing this to P(u = 1|od = 1, Dd = 1) = 0.5 (we are agnostic as to whether a drug overdose is more likely for usual drugs consumers or for novices) gives a posterior P(od = 1|Dd = 1, u = 1) = 62%, while increasing it to P(u = 1|od = 1, Dd = 1) = 0.99 (most people overdosing are drugs users) gives P(od = 1|Dd = 1, u = 1) = 77%. So even looking at the two extreme cases we can still bracket our conclusion to be in the range from 62% to 77%. 3.9.2 Bayesian parameter inference (v) a. The likelihood is given by L (θ ) = N ∏ i=1 1 √ 2πσ exp ( − 1 2 (θ − ˆxi)2 σ 2 ) . (157) Consider now the exponential term: 1 2 ∑ i (θ − ˆxi)2 σ 2 = 1 2σ 2 ( Nθ 2 − 2∑ i ˆxiθ +∑ i ˆx2 i ) = N 2σ 2 ( θ 2 − 2θ ¯x + ¯x2 − ¯x2 + 1 N ∑ i ˆx2 i ) = N 2σ 2 (θ − ¯x) 2 + N 2σ 2 ( 1 N ∑ i ˆx2 i − ¯x2) (158) So the likelihood can be written as L(θ ) = L0 exp ( − 1 2 (θ − ¯x)2 σ 2/N ) , (159) where L0 is a constant that does not depend on θ . Bayesian Methods 55 b. The posterior pdf for θ is proportional to the likelihood times the prior (drop- ping the normalization constant in Bayes’ Theorem): p(θ | ˆx) ∝ L (θ )p(θ ) ∝ exp ( − 1 2 (θ − ¯x)2 σ 2/N ) exp ( − 1 2 θ 2 Σ 2 ) , (160) where we have dropped normalization constants which do not depend on θ and we have used the Gaussian form of the prior. Collecting terms that depend on θ in the exponent and completing the square we get p(θ | ˆx) ∝ exp   − 1 2 (θ − ¯x Σ 2 Σ 2+ σ 2 N )2 [ 1 Σ 2 + N σ 2 ]−1    , (161) which shows that the posterior for θ is a Gaussian with the mean and variance as given in the question. c. When N → ∞, we have that the variance [ 1 Σ 2 + N σ 2 ]−1 → σ 2/N (as N σ 2 ≫ 1 Σ 2 ) and the mean ¯x Σ 2 Σ 2+ σ 2 N → ¯x (as Σ 2 ≫ σ 2 N and the fraction goes to unity). Thus the posterior pdf becomes p(θ | ˆx) → exp ( − 1 2 (θ − ¯x)2 σ 2/N ) , (162) which shows that the posterior converges to the likelihood and the prior de- pendence disappears. d. From the above result, we can use the posterior pdf to compute the posterior mean of θ : ⟨θ ⟩ = ∫ θ p(θ | ˆx)dθ = ¯x. (163) Therefore the posterior mean tends to the sample mean, ¯x, which as we know is also the MLE for the mean. 4 Bayesian model selection 4.1 The three levels of inference For the purpose of this discussion, it is convenient to divide Bayesian inference in three different levels: (i) Level 1: We have chosen a model M0, assumed true, and we want to learn about its parameters, θ0. E.g.: we assume Λ CDM to be the true model for the Universe and try to constrain its parameters. This is the usual parameter inference step. 56 Bayesian Methods (ii) Level 2: We have a series of alternative models being considered (M1, M2, . . . ) and we want to determine which of those is in best agreement with the data. This is a problem of model selection, or model criticism. For example, we might want to decide whether a dark energy equation of state w = −1 is a sufﬁcient description of the available observations or whether we need an evolving dark energy model, w = w(z). (iii) Level 3: Of the N models considered in Level 2, there is no clear “best” model. We want to report inferences on parameters that account for this model uncer- tainty. This is the subject of Bayesian model averaging. For example, we want to determine Ωm independently of the assumed dark energy model. The Frequentist approach to model criticism is in the form of hypothesis testing (e.g., “chi-squared-per-degree-of-freedom“ type of tests). One ends up rejecting (or not) a null hypothesis H0 based on the p-value, i.e., the probability of getting data as extreme or more extreme than what has been observed if one assumes that H0 is true. Notice that this is not the probability for the hypothesis! Classical hypothesis testing assumes the hypothesis to be true and determines how unlikely are our observations given this assumption. This is arguably not the quantity we are actually interested in, namely, the probability of the hypothesis itself given the observations in hand. Ref. [51] is a highly recommended read on this topic. The Bayesian approach takes the view that there is no point in rejecting a model unless there are speciﬁc alternatives available: it takes therefore the form of model comparison. The key quantity for model comparison is the Bayesian evidence. Bayesian model comparison automatically implements a quantitative version of Oc- cam’s razor, i.e., the notion that simpler models ought to be preferred if they can explain the data sufﬁciently well. 4.2 The Bayesian evidence 4.2.1 Deﬁnition The evaluation of a model’s performance in the light of the data is based on the Bayesian evidence. This is the normalization integral on the right–hand–side of Bayes’ theorem, Eq. (72), which we rewrite here conditioning explicitly on the model under consideration, M , with parameter space ΩM : p(d|M ) ≡ ∫ ΩM p(d|θ , M )p(θ |M )dθ (Bayesian evidence). (164) The Bayesian evidence is the average of the likelihood under the prior for a spe- ciﬁc model choice. From the evidence, the model posterior probability given the data is obtained by using Bayes’ Theorem to invert the order of conditioning: p(M |d) ∝ p(M )p(d|M ), (165) Bayesian Methods 57 where we have dropped an irrelevant normalization constant that depends only on the data and p(M ) is the prior probability assigned to the model itself. Usually this is taken to be non–committal and equal to 1/Nm if one considers Nm different models. When comparing two models, M0 versus M1, one is interested in the ratio of the posterior probabilities, or posterior odds, given by p(M0|d) p(M1|d) = B01 p(M0) p(M1) . (166) Deﬁnition 8. The Bayes factor B01 is the ratio of the models’ evidences: B01 ≡ p(d|M0) p(d|M1) (Bayes factor). (167) A value B01 > (<) 1 represents an increase (decrease) of the support in favour of model 0 versus model 1 given the observed data (see [30] for more details on Bayes factors). Bayes factors are usually interpreted against the Jeffreys’ scale [28] for the strength of evidence, given in Table 2. This is an empirically calibrated scale, with thresholds at values of the odds of about 3 : 1, 12 : 1 and 150 : 1, representing weak, moderate and strong evidence, respectively. | ln B01| Odds Probability Strength of evidence < 1.0 ∼ < 3 : 1 < 0.750 Inconclusive 1.0 ∼ 3 : 1 0.750 Weak evidence 2.5 ∼ 12 : 1 0.923 Moderate evidence 5.0 ∼ 150 : 1 0.993 Strong evidence Table 2 Empirical scale for evaluating the strength of evidence when comparing two models, M0 versus M1 (so–called “Jeffreys’ scale”). Threshold values are empirically set, and they occur for values of the logarithm of the Bayes factor of | ln B01| = 1.0, 2.5 and 5.0. The right–most column gives our convention for denoting the different levels of evidence above these thresholds. The probability column refers to the posterior probability of the favoured model, assuming non– committal priors on the two competing models, i.e., p(M0) = p(M1) = 1/2 and that the two models exhaust the model space, p(M0|d) + p(M1|d) = 1. 4.2.2 The Occam’s razor effect We begin by considering the example of two nested models. Consider two compet- ing models: M0 predicting that a parameter θ = 0 with no free parameters, and M1 which assigns to it a Gaussian prior distribution with 0 mean and variance Σ 2. As- sume we perform a measurement of θ described by a normal likelihood of standard deviation σ , and with the maximum likelihood value lying λ standard deviations away from 0, i.e. |θmax/σ | = λ . Then the Bayes factor between the two models is 58 Bayesian Methods given by, from Eq. (167) B01 = √1 + (σ /Σ )−2 exp ( − λ 2 2(1 + (σ /Σ )2) ) . (168) For λ ≫ 1, corresponding to a detection of the new parameter with high signiﬁ- cance, the exponential term dominates and B01 ≪ 1, favouring the more complex model with a non–zero extra parameter, in agreement with what one would get us- ing Frequentist hypothesis testing. But if λ ∼ < 1 and σ /Σ ≪ 1 (i.e., the likelihood is much more sharply peaked than the prior and in the vicinity of 0), then the pre- diction of the simpler model that θ = 0 has been conﬁrmed. This leads to the Bayes factor being dominated by the Occam’s razor term, and B01 ≈ Σ /σ , i.e. evidence ac- cumulates in favour of the simpler model proportionally to the volume of “wasted” parameter space. If however σ /Σ ≫ 1 then the likelihood is less informative than the prior and B01 → 1, i.e. the data have not changed our relative belief in the two models. In the above example, if the data are informative with respect to the prior on the extra parameter (i.e., for σ /Σ ≪ 1) the logarithm of the Bayes factor is given approximately by ln B01 ≈ ln (Σ /σ ) − λ 2/2, (169) where as before λ gives the number of sigma away from a null result (the “signiﬁ- cance” of the measurement). The ﬁrst term on the right–hand–side is approximately the logarithm of the ratio of the prior to posterior volume. We can interpret it as the information content of the data, as it gives the factor by which the parameter space has been reduced in going from the prior to the posterior. This term is posi- tive for informative data, i.e. if the likelihood is more sharply peaked than the prior. The second term is always negative, and it favours the more complex model if the measurement gives a result many sigma away from the prediction of the simpler model (i.e., for λ ≫ 0). We are free to measure the information content in base–10 logarithm (as this quantity is closer to our intuition, being the order of magnitude of our information increase), and we deﬁne the quantity I10 ≡ log10 (Σ /σ ). Figure 9 shows contours of | ln B01| = const for const = 1.0, 2.5, 5.0 in the (I10, λ ) plane, as computed from Eq. (169). The contours delimit signiﬁcative levels for the strength of evidence, according to the Jeffreys’ scale (Table 2). For moderately informative data (I10 ≈ 1 − 2) the measured mean has to lie at least about 4σ away from 0 in order to robustly disfavor the simpler model (i.e., λ ∼> 4). Conversely, for λ ∼< 3 highly informative data (I10 ∼> 2) do favor the conclusion that the extra parameter is indeed 0. In general, a large information content favors the simpler model, be- cause Occam’s razor penalizes the large volume of “wasted” parameter space of the extended model. An useful properties of Figure 9 is that the impact of a change of prior can be easily quantiﬁed. A different choice of prior width (i.e., Σ ) amounts to a horizontal shift across Figure 9, at least as long as I10 > 0 (i.e., the posterior is dominated by the likelihood). Picking more restrictive priors (reﬂecting more predictive theoreti- cal models) corresponds to shifting the result of the model comparison to the left of Bayesian Methods 59 Figure 9, returning an inconclusive result (white region) or a prior–dominated out- come (hatched region). Notice that results in the 2–3 sigma range, which are fairly typical in cosmology, can only support the more complex model in a very mild way at best (odds of 3 : 1 at best), while actually being most of the time either inconclu- sive or in favour of the simpler hypothesis (pink shaded region in the bottom right corner). Notice that Bayesian model comparison is usually conservative when it comes to admitting a new quantity in our model, even in the case when the prior width is chosen “incorrectly” (whatever that means!). In general the result of the model comparison will eventually override the “wrong” prior choice (although it might take a long time to do so), exactly as it happens for parameter inference. Bayesian model selection does not penalize parameters which are unconstrained by the data. This is easily seen from Eq. (169): if a parameter is unconstrained, its posterior width σ is approximately equal to the prior width, Σ , and the Occam’s razor penalty term goes to zero. In such a case, consideration of the Bayesian model complexity might help in judging model performance, see [34] for details. Fig. 9 Illustration of Bayesian model comparison for two nested models, where the more complex model has one extra parameter. The outcome of the model comparison depends both on the infor- mation content of the data with respect to the a priori available parameter space, I10 (horizontal axis) and on the quality of ﬁt (vertical axis, λ , which gives the number of sigma signiﬁcance of the measurement for the extra parameter). Adapted from [56]. 4.2.3 Comparison with p-values Classical hypothesis testing relies on comparing the observed value of some test statistics, T (X) (where X is a RV with density p(X|θ )) with its the expected dis- tribution under a null hypothesis (usually denoted by H0). The hypothesis test is to 60 Bayesian Methods compare H0 : θ = θ0 vs an alternative H1 : θ ̸= θ0. The test statistics is so chosen that more extreme values denote a stronger disagreement with the null. Deﬁnition 9. The p-value (or observed signiﬁcance level) is given by the probabil- ity under the null that T achieves values as extremes or more extremes that have been observed (assuming here that the larger the value of T , the stronger the dis- agreement): ℘ = p(T (X) ≥ T obs|H0). (170) As an example, consider the case where under H0, xi ∼ N (θ0, σ ) for ﬁxed θ0 (the null hypothesis), while under the alternative H1, x ∼ N (θ , σ ) and n data sam- ples are available (with σ known). The usual test statistics is then given by T (X) = √ n | ¯X − θ0| σ . (171) The p-value is then given by ℘ = 2(1 − erf(T obs)) (172) where the observed value of the test statistics is T obs = √ n | ¯x − θ0| σ (173) and ¯x is the sample mean. The classical procedure of reporting the observed ℘ leads to a gross misrepresen- tation of the evidence against the null (this is in contrast with the Neyman-Person procedure of setting a threshold p-value before the experiment is performed, and then only reporting whether or not that threshold has been exceeded). This is be- cause it does not obey the frequentist principle: in repeated use of a statistical pro- cedure, the long–run average actual error should not be greater than the long–run average reported error [4]. This means that, for example, of all reported 95% con- ﬁdence results, on average many more than 5% turn out to be wrong, and typically more than 50% are wrong. Jeffreys famously criticised the use of p-values thus ([29] cited in [5]): I have always considered the arguments for the use of [p-values] absurd. They amount to saying that a hypothesis that may or may not be true is rejected because a greater departure from the trial value was improbable; that is, that it has not predicted something that has not happened. An interesting illustration is given in [5]. Consider the case described above, and let us generate data from a random sequence of null hypothesis (H0) and alternatives (H1), with θ0 = 0, σ = 1 and θ ∼ N (0, 1). Suppose that the proportion of nulls and alternatives is equal. We then compute the p-value using Eq. (172) and we select all the tests that give ℘ ∈ [α − ε, α + ε], for a certain value of α and ε ≪ α (the exact value of ε is unimportant). Among such results, which rejected the null hypothesis at the 1 − α level, we then determine the proportion that actually came from the Bayesian Methods 61 null, i.e. the percentage of wrongly rejected nulls. The results are shown in Table 3. We notice that among all the “signiﬁcant” effects at the 95% level about 50% are wrong, and in general when there is only a single alternative at least 29% of the 95% conﬁdence level results will be wrong. p-value sigma fraction of true nulls lower bound 0.05 1.96 0.51 0.29 0.01 2.58 0.20 0.11 0.001 3.29 0.024 0.018 Table 3 Proportion of wrongly rejected nulls among all results reporting a certain p-value (simu- lation results). The ”lower bound” column gives the minimum fraction of true nulls (derived in [5]). This illustrates that the reported p-value is not equal to the fraction of wrongly rejected true nulls, which can be considerably worse. The root of this striking disagreement with a common misinterpretation of the p-value (namely, that the p-value gives the fraction of wrongly rejected nulls in the long run) is twofold. While the p-value gives the probability of obtaining data that are as extreme or more extreme than what has actually been observed assuming the null hypothesis is true, one is not allowed to interpret this as the probability of the null hypothesis to be true, which is actually the quantity one is interested in assessing. The latter step requires using Bayes theorem and is therefore not deﬁned for a frequentist. Also, quantifying how rare the observed data are under the null is not meaningful unless we can compare this number with their rareness under an alternative hypothesis. A useful rule of thumb is obtained by [5]: it is recommended to think of a nσ result as of a (n − 1)σ result. Reducing the number of sigma signiﬁcance brings the naive p-value interpretation in better alignment with the above results. All these points are discussed in greater detail in [5, 51, 4, 39, 15]. 4.3 Computation of the evidence 4.3.1 Nested sampling A powerful and efﬁcient alternative to classical MCMC methods has emerged in the last few years in the form of the so–called “nested sampling” algorithm, out forward by John Skilling [53]. Although the original motivation for nested sampling was to compute the evidence integral of Eq. (164), the development of the multi–modal nested sampling technique [18] (and more recently the PolyChord algorithm [23], as well as diffusive nested sampling, implemented in the DNest4 code [8]) provides 62 Bayesian Methods a powerful and versatile algorithm that can sample efﬁciently from complex, multi- modal likelihood surfaces, see Fig. 10. Fig. 10 Example of posterior reconstruction using Nested Sampling. Left panel: target likelihood in a 2D parameter space (x, y). Right panel: reconstructed posterior (with ﬂat priors) using Nested Sampling. From Ref. [18]. The gist of nested sampling is that the multi–dimensional evidence integral is recast into a one–dimensional integral, by deﬁning the prior volume X as dX ≡ p(θ |M )dθ so that X(λ ) = ∫ L (θ )>λ p(θ |M )dθ (174) where L (θ ) ≡ p(d|θ , M ) is the likelihood function and the integral is over the parameter space enclosed by the iso–likelihood contour L (θ ) = λ . So X(λ ) gives the volume of parameter space above a certain level λ of the likelihood. The Bayesian evidence, Eq. (164), can be written as p(d|M ) = ∫ 1 0 L (X)dX, (175) where L (X) is the inverse of Eq. (174). Samples from L (X) can be obtained by drawing uniformly samples from the likelihood volume within the iso–contour sur- face deﬁned by λ . This is the difﬁcult part of the algorithm. Finally, the 1–dimensional integral of Eq. (175) can be obtained by simple quadrature, thus p(d|M ) ≈ ∑ i L (Xi)Wi, (176) where the weights are Wi = 1 2 (Xi−1 − Xi+1), see [53, 44] for details13. 13 Publicly available software implementing nested sampling can be found at http://www.mrao.cam.ac.uk/software/cosmoclust/ (MultiNest) and https://github.com/eggplantbren/DNest4/ (DNest4) (accessed Jan 5th 2017). Bayesian Methods 63 4.3.2 Thermodynamic integration Thermodynamic integration computes the evidence integral by deﬁning E(µ) ≡ ∫ ΩM L (θ )µ p(θ |M )dθ , (177) where µ is an annealing parameter and L (θ ) ≡ p(d|θ , M ). Obviously the desired evidence corresponds to E(1). One starts by performing a standard MCMC sam- pling with µ = 0 (i.e., sampling from the prior), then gradually increases µ to 1 according to some annealing schedule. The log of the evidence is then given by ln E(1) = ln E(0) + ∫ 1 0 d ln E dµ dµ = ∫ 1 0 ⟨ln L ⟩µ dµ, (178) where the average log-likelihood is taken over the posterior with annealing parame- ter µ, i.e. ⟨ln L ⟩µ = ∫ ΩM (ln L )L (θ )µ p(θ |M )dθ ∫ ΩM L (θ )µ p(θ |M )dθ . (179) The drawback is that the end result might depend on the annealing schedule used and that typically this methods takes 10 times as many likelihood evaluations as parameter estimation. For an overview of so-called “population Monte Carlo” algo- rithms and annealed importance sampling, see [26, 9]. 4.3.3 Laplace approximation An approximation to the Bayesian evidence can be obtained when the likelihood function is unimodal and approximately Gaussian in the parameters. Expanding the likelihood around its peak to second order one obtains the Laplace approximation p(d|θ , M ) ≈ Lmax exp [ − 1 2 (θ − θmax) t L(θ − θmax) ] , (180) where θmax is the maximum–likelihood point, Lmax the maximum likelihood value and L the likelihood Fisher matrix (which is the inverse of the covariance matrix for the parameters). Assuming as a prior a multinormal Gaussian distribution with zero mean and Fisher information matrix P one obtains for the evidence, Eq. (164) p(d|M ) = Lmax |F|−1/2 |P|−1/2 exp [ − 1 2 (θmaxt Lθmax − θ t Fθ ) ] , (181) where the posterior Fisher matrix is F = L + P and the posterior mean is given by θ = F −1Lθmax. 64 Bayesian Methods 4.3.4 The Savage-Dickey density ratio A useful approximation to the Bayes factor, Eq. (167), is available for situations in which the models being compared are nested into each other, i.e. the more complex model (M1) reduces to the original model (M0) for speciﬁc values of the new pa- rameters. This is a fairly common scenario when one wishes to evaluate whether the inclusion of the new parameters is supported by the data (e.g., do we need isocurvature contributions to the initial conditions for cosmological perturbations, or whether a curvature term in Einstein’s equation is needed, or whether a non–scale invariant distribution of the primordial ﬂuctuation is preferred). Writing for the extended model parameters θ = (φ , ψ), where the simpler model M0 is obtained by setting ψ = 0, and assuming further that the prior is separable (which is usually the case), i.e. that p(φ , ψ|M1) = p(ψ|M1)p(φ |M0), (182) the Bayes factor can be written in all generality as B01 = p(ψ|d, M1) p(ψ|M1) ∣ ∣ ∣ ∣ ψ=0 . (183) This expression is known as the Savage–Dickey density ratio (see [56] and ref- erences therein). The numerator is simply the marginal posterior under the more complex model evaluated at the simpler model’s parameter value, while the denom- inator is the prior density of the more complex model evaluated at the same point. This technique is particularly useful when testing for one extra parameter at the time, because then the marginal posterior p(ψ|d, M1) is a 1–dimensional function and normalizing it to unity probability content only requires a 1–dimensional inte- gral, which is simple to do using for example the trapezoidal rule. 4.3.5 Information criteria for approximate model selection Sometimes it might be useful to employ methods that aim at an approximate model selection under some simplifying assumptions that give a default penalty term for more complex models, which replaces the Occam’s razor term coming from the different prior volumes in the Bayesian evidence [35]. Akaike Information Criterion (AIC): the AIC is an essentially frequentist crite- rion that sets the penalty term equal to twice the number of free parameters in the model, k: AIC ≡ −2 ln Lmax + 2k (184) where Lmax ≡ p(d|θmax, M ) is the maximum likelihood value. Bayesian Information Criterion (BIC): the BIC follows from a Gaussian approx- imation to the Bayesian evidence in the limit of large sample size: Bayesian Methods 65 BIC ≡ −2 ln Lmax + k ln N (185) where k is the number of ﬁtted parameters as before and N is the number of data points. The best model is again the one that minimizes the BIC. Deviance Information Criterion (DIC): the DIC can be written as DIC ≡ −2DKL + 2Cb. (186) In this form, the DIC is reminiscent of the AIC, with the ln Lmax term replaced by the estimated KL divergence DKL and the number of free parameters by the effective number of parameters, Cb (see [57] for deﬁnitions). The information criteria ought to be interpreted with care when applied to real situations. Comparison of Eq. (185) with Eq. (184) shows that for N > 7 the BIC pe- nalizes models with more free parameters more harshly than the AIC. Furthermore, both criteria penalize extra parameters regardless of whether they are constrained by the data or not, unlike the Bayesian evidence. In conclusion, what makes the in- formation criteria attractive, namely the absence of an explicit prior speciﬁcation, represents also their intrinsic limitation. 4.4 Example: model selection for the inﬂationary landscape The inﬂationary model comparison carried out in Ref. [42, 41] is an example of the application of the above formalism to the problem of deciding which theoretical model is the best description of the available observations. Although the technical details are fairly involved, the underlying idea can be sketched as follows. The term “inﬂation” describes a period of exponential expansion of the Universe in the very ﬁrst instants of its life, some 10−32 seconds after the Big Bang, during which the size of the Universe increased by at least 25 orders of magnitude. This huge and extremely fast expansion is required to explain the observed isotropy of the cosmic microwave background on large scales. It is believed that inﬂation was powered by one or more scalar ﬁelds. The behaviour of the scalar ﬁeld during inﬂa- tion is determined by the shape of its potential, which is a real-valued function V (φ ) (where φ denotes the value of the scalar ﬁeld). The detailed shape of V (φ ) controls the duration of inﬂation, but also the spatial distribution of inhomogeneities (per- turbations) in the distribution of matter and radiation emerging from inﬂation. It is from those perturbations that galaxies and cluster form out of gravitational collapse. Hence the shape of the scalar ﬁeld can be constrained by observations of the large scale structures of the Universe and of the CMB anisotropies. Theories of physics beyond the Standard Model motivate certain functional forms of V (φ ), which however typically have a number of free parameters, θ . The fundamental model selection question is to use cosmological observations to dis- criminate between alternative models for V (φ ) (and hence alternative fundamental theories). The major obstacle to this programme is that very little if anything at all 66 Bayesian Methods is known a priori about the free parameters θ describing the inﬂationary potential. What is worse, such parameters can assume values across several orders of magni- tude, according to the theory. Hence the Occam’s razor effect of Bayesian model comparison can vary in a very signiﬁcant way depending on the prior choices for Ψ . Furthermore, a non-linear reparameterization of the problem (which leaves the physics invariant) does in general change the Occam’s razor factor, and hence the model comparison result. In Ref. [42] inﬂationary model selection was considered from a principled point of view. The Bayesian evidence and complexity of 198 slow-roll single-ﬁeld models of inﬂation was computed, using the Planck 2013 Cosmic Microwave Background data. The models considered represented an almost complete and systematic scan of the entire landscape of inﬂationary scenarios proposed so far (More recently, this works has been extended to more complex scenarios with more than one scalar ﬁeld [60]). The analysis singled out the most probable models (from an Occam’s ra- zor point of view) that are compatible with Planck data. The resulting Bayes factors (normalised to the case of Higgs Inﬂation) are displayed in Fig. 11. 4.5 Open challenges I conclude by listing what I think are some of the open questions and outstanding challenges in the application of Bayesian model selection to cosmological model building. • Is Bayesian model selection always applicable? The Bayesian model compar- ison approach as applied to cosmological and particle physics problems has been strongly criticized by some authors. E.g., George Efstathiou [17] and Bob Cousins [13, 14] pointed out (in different contexts) that often insufﬁcient atten- tion is given to the selection of models and of priors, and that this might lead to posterior model probabilities which are largely a function of one’s unjustiﬁed as- sumptions. This draws attention to the difﬁcult question of how to choose priors on phenomenological parameters, for which theoretical reasoning offers poor or no guidance (as in the inﬂationary model comparison example above). • How do we deal with Lindley’s paradox? It is simple to construct examples of situations where Bayesian model comparison and classical hypothesis testing disagree (Lindley’s paradox [37]). This is not surprising, as frequentist hypoth- esis testing and Bayesian model selection really ask different questions of the data [51]. Furthermore, as the scaling with the number of data points is different, there isn’t even a guarantee that the two approaches will agree in the asymptotic regime of large data sample size. As Louis Lyons aptly put it: Bayesians address the question everyone is interested in by using assumptions no–one believes, while frequentists use impeccable logic to deal with an issue of no interest to anyone [38]. Bayesian Methods 67 Fig. 11 Bayes factors (bars) and absolute upper bound to the Bayes factors (arrows) for inﬂationary scenarios, with Higgs inﬂation as the reference model (see [42] for further details). However, such a disagreement is more likely to occur in situations where the sig- nal is weak, which are precisely the kind of “frontier science” cases which are the most interesting ones (e.g., discovery claims). Is there a way to evaluate e.g. the loss function from making the “wrong” decision about rejecting/accepting a model? In this context, perhaps a decision theoretical approach would be beneﬁ- cial: the loss function of making the wrong decision has to be explicitly formu- lated, thus helping putting the user’s subjective biases and values in the open. • How do we assess the completeness of the set of known models? Bayesian model selection always returns a best model among the ones being compared, even though that model might be a poor explanation for the available data. Is there a principled way of constructing an absolute scale for model performance in a 68 Bayesian Methods Bayesian context? (for example, along the lines of the notion of Bayesian doubt, introduced in [40]). • Is Bayesian model averaging useful? Bayesian model averaging can be used to obtain ﬁnal inferences on parameters which take into account the resid- ual model uncertainty (examples of applications in cosmology can be found in [36, 47, 59, 25]). However, it also propagates the prior sensitivity of model selection to the level of model-averaged parameter constraints. Is it useful to pro- duce model-averaged parameter constraints, or should this task be left to the user, by providing model-speciﬁc posteriors and Bayes factors instead? • Is there such a thing as a “correct” prior? In fundamental physics, models and pa- rameters (and their priors) are supposed to represent (albeit in an idealized way) the real world, i.e., they are not simply useful representation of the data (as they are in other statistical problems, e.g. as applied to social sciences). In this sense, one could imagine that there exist a “correct” prior for e.g. the parameters θ of our cosmological model, which could in principle be derived from fundamen- tal theories such as string theory (e.g., the distribution of values of cosmological parameters across the landscape of string theory [55]). This raises interesting sta- tistical questions about the relationship between physics, reality and probability. 4.6 Exercises (i) A coin is tossed N = 250 times and it returns H = 140 heads. Evaluate the evi- dence that the coin is biased using Bayesian model comparison and contrast your ﬁndings with the usual (frequentist) hypothesis testing procedure (i.e. testing the null hypothesis that pH = 0.5). Discuss the dependency on the choice of priors. (ii) In 1919 two expeditions sailed from Britain to measure the light deﬂection from stars behind the Sun’s rim during the solar eclipse of May 29th. Einstein’s Gen- eral Relativity predicts a deﬂection angle α = 4GM c2R , where G is Newton’s constant, c is the speed of light, M is the mass of the grav- itational lens and R is the impact parameter. It is well known that this result it exaclty twice the value obtained using Newtonian gravity. For M = M⊙ and R = R⊙ one gets from Einstein’s theory that α = 1.74 arc seconds. The team led by Eddington reported 1.61 ± 0.40 arc seconds (based on the po- sition of 5 stars), while the team headed by Crommelin reported 1.98 ± 0.16 arc seconds (based on 7 stars). What is the Bayes factor between Einstein and Newton gravity from those data? Comment on the strength of evidence. (iii) Assume that the combined constraints from CMB, BAO and SNIa on the density parameter for the cosmological constant can be expressed as a Gaussian posterior Bayesian Methods 69 distribution on ΩΛ with mean 0.7 and standard deviation 0.05. Use the Savage- Dickey density ratio to estimate the Bayes factor between a model with ΩΛ = 0 (i.e., no cosmological constant) and the Λ CDM model, with a ﬂat prior on ΩΛ in the range 0 ≤ ΩΛ ≤ 2. Comment on the strength of evidence in favour of Λ CDM. (iv) If the cosmological constant is a manifestation of quantum ﬂuctuations of the vacuum, QFT arguments lead to the result that the vacuum energy density ρΛ scales as ρΛ ∼ c¯h 16π k4 max (187) where kmax is a cutoff scale for the maximum wavenumber contributing to the energy density (see e.g. [10]). Adopting the Planck mass as a plausible cutoff scale (i.e., kmax = c/¯hMPl) leads to “the cosmological constant problem”, i.e., the fact that the predicted energy density ρΛ ∼ 1076GeV 4 (188) is about 120 orders of magnitude larger than the observed value, ρobs ∼ 10−48GeV4. a. Repeat the above estimation of the evidence in favour of a non-zero cosmolog- ical constant, adopting this time a ﬂat prior in the range 0 ≤ ΩΛ /Ω obs Λ < 10120. What is the meaning of this result? What is the required observational accu- racy (as measured by the posterior standard deviation) required to override the Occam’s razor penalty in this case? b. It seems that it would be very difﬁcult to create structure in a universe with ΩΛ ≫ 100, and so life (at least life like our own) would be unlikely to evolve. How can you translate this “anthropic” argument into a quantitative statement, and how would it affect our estimate of ΩΛ and the model selection problem? (v) This problem follows up the cosmological parameter estimation problem from supernovae type Ia (for a more thorough treatment, see [58, 59]). a. Adopt uniform priors Ωm ∼ U(0, 2) and ΩΛ ∼ U(0, 2). Produce a 2D marginalised posterior pdf in the (Ωm, ΩΛ ) plane. b. Produce a 1D marginalised posterior pdf for the curvature parameter, Ωκ = 1 − ΩΛ − Ωm, paying attention to normalising it to unity probability content. What is the shape of the prior on Ωκ implied by your choice of a uniform prior on Ωm, ΩΛ ? c. Use the Savage-Dickey density ratio formula to estimate from the above 1D posterior the evidence in favour of a ﬂat Universe, Ωκ = 0, compared with a non-ﬂat Universe, Ωκ ̸= 0, with prior P(Ωκ ) = U(−1, 1). Discuss the dependency of your result on the choice of the above prior range. 70 Bayesian Methods 4.7 Solutions to selected exercises (i) This is a model comparison problem, where we are comparing model M0 that the coin is fair (i.e., pH = 0.5) with a model M1 where the probability of heads is ̸= 0.5. We begin by assigning under model 1 a ﬂat prior to pH between 0 and 1. The Bayes factor (or ratio of the two models’ evidences) is given by B = P(H = 140|M1) P(H = 140|M0) = H!(N−H)! (H+1)! (1/2)N ∣ ∣ ∣ N=250,H=140 = 140!110! 251! (1/2)250 ≈ 0.48 ∼ 2 : 1 (189) (notice that we have cancelled the “choose” terms in the numerator and denomi- nators above). So there is not even weak evidence in favour of the model that the coin is biased. The log of the Bayes factor is plotted as a function of H in Fig. 12. By inspection it is apparent that values 107 ≤ H ≤ 143 favour the fair coin model (ln B < 0). In order to obtain “strong evidence” in favour of the biased coin model (ln B > 5), it is necessary that either H < 94 or H > 31. The usual Frequentist hypothesis testing procedure would be to compute the tail probability of obtaining data as extreme or more extreme than have been ob- served under the null hypothesis, i.e., that the coin is fair. This gives the p-value: p-value = ( 1 2 )N N ∑ H=Hobs (N H ) ≈ 0.033 (190) Fig. 12 Natural log of the Bayes factor between the model “the coin is biased” (with ﬂat prior) and the model ”the coin is fair”, as a function of the number of heads (H) in 250 ﬂips, see Eq. (189). Values ln B > 0 favour the biased coin model. The Jeffreys’ threshold for “strong evidence” is at ln B = 0 Bayesian Methods 71 So for a Frequentist, the data would exclude the null hypothesis that the coin is fair at more than the 95% CL. How does the Bayesian result depend on the choice of prior for the alternative hypothesis? Above we have given to pH a ﬂat prior between 0 and 1. If we wanted to give the maximum possible advantage to a model where the coin is not fair, we could put all of its prior probability in a delta-function concentrated at the value of pH that maximizes the probability of what has been observed. So under this maximally advantageous model for the unfairness hypothesis (let’s call this M2), we would select a “prior” (in quotation marks, for this prior is actually selected after the data have been gathered, so we are effectively using the data twice here!) of the form P(pH ) = δ (pH − H/N). In this case the odds in favour of this new model are B = P(H = 140|M2) P(H = 140|M0) = (H/N)H (1 − H/N)N−H (1/2)250 ∣ ∣ ∣ H=140,H=250 ≈ 6.1. (191) Even in this most favourable setup for the hypothesis that the coin is biased, we ﬁnd only weak evidence (odds of 6 to 1) against the model of a fair coin. Therefore we can safely conclude that the data do not warrant to conclude that the coin is unfair. (ii) We are comparing here two models which both make exact predictions for the deﬂection angle, with no free parameters. If you prefer, you might consider the prior on α under each theory to be a delta-function centered at the predicted value. This of course neglects the uncertainty associated with M⊙ and R⊙. In this case, the evidence is thus simply the likelihood function for the observed data under each theory (you can convince yourself that this is correct by explicitly computing the evidence for each model assuming the delta-function prior above). This gives for the Bayes factor in favour of Einstein gravity vs Newton (assuming Gaussian likelihoods) B = L0 exp ( − 1 2 ( ˆα−αE )2 σ 2 ) L0 exp ( − 1 2 ( ˆα−αN )2 σ 2 ) (192) where αE = 1.74′′, αN = 87′′, ˆα is maximum likelihood value of the experiment and σ is the standard deviation. Using the supplied data from Eddington, one obtains B ∼ 5, so “weak evidence” in favour of Einstein theory according to the Jeffreys’ scale for the strength of evidence. The Crommelin data instead give B ∼ 1010, so very strong evidence for Einstein. Notice that this comes about because the measurement from Crommelin is on the high side (i.e., higher than Einstein prediction, even), and therefore the assumed Gaussian tail becomes tiny for α = αN. It is worth noticing that, although the above calculation is formally correct, it is likely to overestimate the evidence against Newton, because the Gaussian approximation made here is certain to break down that far into the tails (i.e, αN is ∼ 11σ away from the value measured by Crommelin. No distribution is exactly valid that far into the tails!). 72 Bayesian Methods (iii) Here we are comparing two nested model, M0 with ΩΛ = 0 and a more compli- cated model, M1,where ΩΛ ≤ 0 and a ﬂat prior P(ΩΛ |M1) = 1/2 for 0 ≤ ΩΛ ≤ 2 and 0 elsewhere (notice that the prior needs to be normalized, hence the factor 1/2). We can therefore use the Savage-Dickey density ratio to compute the Bayes factor between M0 and M1: B01 = P(ΩΛ = 0|CMB+BAO+SN, M1) P(ΩΛ = 0|M1) = 1√ 2πσ exp ( − 1 2 (0− ˆΩΛ )2 σ 2 ) 1/2 , (193) where we have assumed thart the posterior under M1 can be approximated as a Gaussian of mean ˆΩΛ = 0.7 and standard deviation σ = 0.05. Numerical evalua- tion gives B01 ∼ 10−42, so with this prior the model that ΩΛ = 0 can be ruled out with very strong evidence. Another way of looking at this result is the follow- ing: if, after having seen the data, you remain unconvinced that indeed ΩΛ > 0, this means that the ratio in your relative degree of prior belief in the two models should exceed P(M0)/P(M1) > 1042. (iv) a. The calculation of the Bayes factor proceeds as above, but this time with a much larger prior range for the alternative model, ΩΛ > 0. This means that the prior height, P(ΩΛ = 0|M1) , appearing in the denominator of Eq. (193) is very small, i.e. P(ΩΛ = 0|M1) = 10−120, as the prior needs to be normalized. Repeating the above calculation, we get for the Bayes factor in favour of M0 (i.e., that ΩΛ = 0) B01 ∼ 10−42 10−120 ∼ 1088. (194) Now the Bayes factor is positive (and huge), a reﬂection of the enormous amount of prior range wasted by M1. Therefore under this new prior, the Bayesian model comparison favour the hypothesis that there is no cosmolog- ical constant despite the fact that the likelihood peaks about 0.7/0.05 ∼ 14σ away from ΩΛ = 0. This is an extreme example of Occam’s penalty. In order for the Occam’s factor to be overruled by the likelihood, we require that B01 = 1 (i.e., equal odds for the two models). This translates in the ap- proximate condition for the number of sigma detection, λ : exp ( − 1 2 λ 2) ∼ 10−120, (195) where we have dropped the term 1/σ in front of the likelihood for simplic- ity (as the likelihood is going to be dominated by the exponential anyhow). Solving for λ gives λ ∼ √ 240 ln 10 ≈ 23. (196) So we would need a ∼ 23σ detection of ΩΛ > 0 to override completely the Occam’s razor penalty. b. The outcome of the model comparison changes dramatically if one is willing to impose a much more stringent upper cutoff to the prior range of ΩΛ , based Bayesian Methods 73 e.g. on anthropic arguments. The observations that structures cannot form if ΩΛ ≫ 100 (and therefore there would be no observers to measure dark en- ergy, see e.g. the original argument by Weinberg [61]) can be approximately translated in a prior range extending perhaps to ΩΛ ∼ 103. With this choice of range, the Bayes factor becomes B01 ∼ 10−42 10−3 ∼ 10 −39, (197) thus swinging back to support M1 with enormous odds. This illustrate that Bayesian model comparison can be difﬁcult (and strongly dependent on the theoretical prior range adopted) in cases where there is no compelling (or unique) argument to deﬁne the prior. Acknowledgements I would like to thank the many colleagues who provided invaluable input and discussions over the years: Bruce Bassett, Jim Berger, Bob Cousins, Eric Feigelson, Farhan Feroz, Alan Heavens, Mike Hobson, Andrew Jaffe, Martin Kunz, Andrew Liddle, Louis Lyons, Daniel Mortlock, John Peacock and David van Dyk. Many thanks to the Organizers of the 44th Saas Fee Advanced Course on Astronomy and Astrophysics, “Cosmology with wide-ﬁeld surveys” (held in March 2014) for inviting me to present these lectures, and to the students for their piercing and stimulating questions. I am grateful to many cohorts of students, at Imperial College London and in various advanced schools, for their valuable feedback and comments on earlier versions of these notes. Any remaining mistake is of course fully my own. Appendix 5 Introductory and background material 5.1 The uniform, binomial and Poisson distributions The uniform distribution: for n equiprobable outcomes between 1 and n, the uni- form discrete distribution is given by P(r) = { 1/n for 1 ≤ r ≤ n 0 otherwise (198) It is plotted in Fig. 13 alongside with its cdf for the case of the tossing of a fair die (n = 6). The binomial distribution: the binomial describes the probability of obtaining r “successes” in a sequence of n trials, each of which has probability p of success. Here, “success” can be deﬁned as one speciﬁc outcome in a binary process (e.g., H/T, blue/red, 1/0, etc). The binomial distribution B(n, p) is given by: 74 Bayesian Methods Fig. 13 Left panel: uniform discrete distribution for n = 6. Right panel: the corresponding cdf. P(r|n, p) ≡ B(n, p) = ( n r )pr(1 − p) n−r, (199) where the “choose” symbol is deﬁned as ( n r ) ≡ n! (n − r)!r! (200) for 0 ≤ r ≤ n (remember, 0! = 1). Some examples of the binomial for different choices of n, p are plotted in Fig. 14. The derivation of the binomial distribution proceeds from considering the prob- ability of obtaining r successes in n trials (pr), while at the same time obtaining n − r failures ((1 − p)n−r). The combinatorial factor in front is derived from con- siderations of the number of permutations that leads to the same total number of successes. The Poisson distribution: the Poisson distribution describes the probability of ob- taining a certain number of events in a process where events occur with a ﬁxed average rate and independently of each other. The process can occur in time (e.g., number of planes landing at Heathrow, number of photons arriving at a photomul- tiplier, number of murders in London, number of electrons at a detector, etc . . . in a certain time interval) or in space (e.g., number of galaxies in a patch on the sky). Let’s assume that λ is the average number of events occuring per unit time or per unit length (depending on the problem being considered). Furthermore, λ = constant in time or space. Example 17. For example, λ = 3.5 busses/hour is the average number of busses passing by a particular bus stop every hour; or λ = 10.3 droplets/m2 is the aver- age number of drops of water hitting a square meter of the surface of an outdoor swimming pool in a certain day. Notice that of course at every given hour an integer number of busses actually passes by (i.e., we never observe 3 busses and one half passing by in an hour!), but that the average number can be non-integer (for exam- Bayesian Methods 75 Fig. 14 Some examples of the binomial distribution, Eq. (199), for different choices of n, p, and its corresponding cdf. ple, you might have counted 7 busses in 2 hours, giving an average of 3.5 busses per hour). The same holds for the droplets of water. For problems involving the time domain (e.g., busses/hour), the probability of r events happening in a time t is given by the Poisson distribution: P(r|λ ,t) ≡ Poisson(λ ) = (λt)r r! e −λt . (201) If the problem is about the spatial domain (e.g., droplets/m2), the probability of r events happening in an area A is given by: 76 Bayesian Methods P(r|λ , A) ≡ Poisson(λ ) = (λ A)r r! e−λ A. (202) Notice that this is a discrete pmf in the number of events r, and not a continuous pdf in t or A. The probability of getting r events in a unit time interval is obtained by setting t = 1 in Eq. (201); similarly, the probability of getting r events in a unit area is obtained by setting A = 1 in Eq. (202) Example 18. A particle detector measures protons which are emitted with an aver- age rate λ = 4.5/s. What is the probability of measuring 6 protons in 2 seconds? Answer: P(6|λ = 4.5s −1,t = 2s) = (4.5 · 2)6 6! e −4.5·2 = 0.09. (203) So the probability is about 9%. The Poisson distribution of Eq. (201) is plotted in Fig. 15 as a function of r for a few choices of λ (notice that in the ﬁgure t = 1 has been assumed, in the appropri- ate units). The derivation of the Poisson distribution follows from considering the probability of 1 event taking place in a small time interval ∆t, then taking the limit ∆t → dt → 0. It can also be shown that the Poisson distribution arises from the bi- nomial in the limit pn → λ for n → ∞, assuming t = 1 in the appropriate units (see lecture). Example 19. In a post ofﬁce, people arrive at the counter at an average rate of 3 customers per minute. What is the probability of 6 people arriving in a minute? Answer: The number of people arriving follows a Poisson distribution with average λ = 3 (people/min). The probability of 6 people arriving in a minute is given by P(n = 6|λ ,t = 1 min) = (λt)n n! e−λt ≈ 0.015 (204) So the probability is about 1.5%. The discrete distributions above depend on parameters (such as p for the bino- mial, λ for Poisson), which control the shape of the distribution. If we know the value of the parameters, we can compute the probability of an observation (as done it the examples above). This is the subject of probability theory, which concerns it- self with the theoretical properties of the distributions. The inverse problem of mak- ing inferences about the parameters from the observed samples (i.e., learning about the parameters from the observations made) is the subject of statistical inference, addressed later. 5.2 Expectation value and variance Two important properties of distributions are the expectation value (which controls the location of the distribution) and the variance or dispersion (which controls how Bayesian Methods 77 Fig. 15 Some examples of the Poisson distribution, Eq. (201), for different choices of λ , and its corresponding cdf. much the distribution is spread out). Expectation value and variance are functions of a RV. Deﬁnition 10. The expectation value E[X] (often called “mean”, or “expected value”14) of the discrete RV X is deﬁned as E[X] = ⟨X⟩ ≡ ∑ i xiPi. (205) 14 We prefer not to use the term “mean” to avoid confusion with the sample mean. 78 Bayesian Methods Example 20. You toss a fair die, which follows the uniform discrete distribution, Eq. (198). What is the expectation value of the outcome? Answer: the expectation value is given by E[X] = ∑i i · 1 6 = 21/6. Deﬁnition 11. The variance or dispersion Var(X) of the discrete RV X is deﬁned as Var(X) ≡ E[(X − E[X]) 2] = E(X 2) − E[X] 2. (206) The square root of the variance is often called “standard deviation” and is usually denoted by the symbol σ , so that Var(X) = σ 2. Example 21. For the case of tossing a fair die once, the variance is given by Var(X) = ∑ i (xi − ⟨X⟩) 2Pi = ∑ i x2 i Pi − ( ∑ i xiPi )2 = ∑ i i 2 1 6 − ( 21 6 )2 = 105 36 . (207) For the binomial distribution of Eq. (199), the expectation value and variance are given by: E[X] = np, Var(X) = np(1 − p). (208) Example 22. A fair coin is tossed N times. What is the expectation value for the number of heads, H? What is its variance? For N = 10, evaluate the probability of obtaining 8 or more heads. Answer: The expectation values and variance are given by Eq. (208), with p = 1/2 (as the coin is fair), thus E(H) = N p = N/2 and Var(H) = N p(1 − p) = N/4. (209) The probability of obtaining 8 or more heads is given by P(H = 8 = 10 ∑ H=8 P(H heads|N, p = 1/2) = 1 210 10 ∑ H=8 ( 10 H ) = 56 1024 ≈ 0.055. (210) So the probability of obtaining 8 or more heads is about 5.5%. For the Poisson distribution of Eq. (201), the expectation value and variance are given by: E[X] = λt, Var(X) = λt, (211) while for the spatial version of the Poisson distribution, Eq. (202), they are given by: E[X] = λ A, Var(X) = λ A. (212) As we did above for the discrete distribution, we now deﬁne the following prop- erties for continuous distributions. Deﬁnition 12. The expectation value E[X] of the continuous RV X with pdf p(X) is deﬁned as E[X] = ⟨X⟩ ≡ ∫ xp(x)dx. (213) Bayesian Methods 79 Deﬁnition 13. The variance or dispersion Var(X) of the continuous RV X is deﬁned as Var(X) ≡ E[(X − E[X]) 2] = E(X 2) − E[X] 2 = ∫ x2 p(x)dx − (∫ xp(x)dx)2 . (214) 5.3 The exponential distribution The exponential distribution describes the time one has to wait between two con- secutive events in a Poisson process, e.g. the waiting time between two radioactive particles decays. If the Poisson process happens in the spatial domain, then the ex- ponential distribution describes the distance between two events (e.g., the separation of galaxies in the sky). In the following, we will look at processes that happen in time (rather than in space). To derive the exponential distribution, one can consider the arrival time of Pois- son distributed events with average rate λ (for example, the arrival time particles in a detector). The probability that the ﬁrst particle arrives at time t is obtained by considering the probability (which is Poisson distributed) that no particle arrives in the interval [0,t], given by P(0|λ ,t) = exp(−λt) from Eq. (201), times the proba- bility that one particle arrives during the interval [t,t + ∆t], given by λ ∆t. Taking the limit ∆t → 0 it follows that the probability density (denoted by a symbol p()) for observing the ﬁrst event happening at time t is given by p(1st event happens at time t|λ ) = λ e −λt , (215) where λ is the mean number of events per unit time. This is the exponential distri- bution. Example 23. Let’s assume that busses in London arrive according to a Poisson dis- tribution, with average rate λ = 5 busses/hour. You arrive at the bus stop and a bus has just departed. What is the probability that you will have to wait more than 15 minutes? Answer: the probability that you’ll have to wait for t0 = 15 minutes or more is given by ∫ ∞ t0 p(1st event happens at time t|λ )dt = ∫ ∞ t0 λ e−λt dt = e−λt0 = 0.29, (216) where we have used λ = 5busses/hour = 1/12 busses/min. If we have already waited for a time s for the ﬁrst event to occur (and no event has occurred), then the probability that we have to wait for another time t before the ﬁrst event happens satisﬁes p(T > t + s|T > s) = p(T > t). (217) 80 Bayesian Methods This means that having waited for time s without the event occuring, the time we can expect to have to wait has the same distribution as the time we have to wait from the beginning. The exponential distribution has no “memory” of the fact that a time s has already elapsed. For the exponential distribution of Eq. (215), the expectation value and variance for the time t are given by E(t) = 1/λ , Var(t) = 1/λ 2. (218) 5.4 The Gaussian (or Normal) distribution The Gaussian pdf (often called “the Normal distribution”) is perhaps the most im- portant distribution. It is used as default in many situations involving continuous RV, since it naturally ﬂows from the the Central Limit Theorem, section 2.3. The Gaussian pdf is a continuous distribution with mean µ and standard deviation σ is given by p(x|µ, σ ) = 1 √ 2πσ exp ( − 1 2 (x − µ)2 σ 2 ) , (219) and it is plotted in Fig. 16 for two different choices of {µ, σ }. The Gaussian is the famous bell-shaped curve. Fig. 16 Two examples of the Gaussian distribution, Eq. (219), for different choices of µ, σ , and its corresponding cdf. The expectation value µ controls the location of the pdf (i.e., when changing µ the peak moves horizontally, without changing its shape), while the standard deviation σ controls its width (i.e., when changing σ the spread of the peak changes but not its location). For the Gaussian distribution of Eq. (219), the expectation value and variance are given by: E[X] = µ, Var(X) = σ 2. (220) It can be shown that the Gaussian arises from the binomial in the limit n → ∞ and from the Poisson distribution in the limit λ → ∞. As shown in Fig. 17, the Gaussian Bayesian Methods 81 approximation to either the binomial or the Poisson distribution is very good even for fairly moderate values of n and λ . Fig. 17 Gaussian approximation to the binomial (left panel) and the Poisson distribution (right panel). The solid curve gives in each case the Gaussian approximation to each pmf. The probability content of a Gaussian of standard deviation σ for a given sym- metric interval around the mean of width κσ on each side is given by P(µ − κσ < x < µ + κσ ) = ∫ µ+κσ µ−κσ 1 √ 2πσ exp ( − 1 2 (x − µ)2 σ 2 ) dx (221) = 2 √ π ∫ κ/√ 2 0 exp ( −y2) dy (222) = erf(κ/ √ 2), (223) where the error function erf is deﬁned as erf(x) = 2 √ π ∫ x 0 exp ( −y 2) dy, (224) and can be found by numerical integration (also often tabulated and available as a built-in function in most mathematical software). Also recall the useful integral: ∫ ∞ −∞ exp ( − 1 2 (x − µ)2 σ 2 ) dx = √ 2πσ . (225) Eq. (221) allows to ﬁnd the probability content of the Gaussian pdf for any sym- metric interval around the mean. Some commonly used values are given in Table 4. Example 24. Measurements are often reported with the notation T = (100 ± 1) K (in this case, we assume we have measured a temperature, T ). If nothing else is 82 Bayesian Methods κ P(−κ < x−µ σ < κ) Usually called “number of sigma” Probability content 1 0.683 1σ 2 0.954 2σ 3 0.997 3σ 4 0.9993 4σ 5 1 − 5.7 × 10−7 5σ 1.64 0.90 90% probability interval 1.96 0.95 95% probability interval 2.57 0.99 99% probability interval 3.29 0.999 99.9% probability interval Table 4 Relationship between the size of the interval around the mean and the probability content for a Gaussian distribution. speciﬁed, it is usually implied that the error follows a Gaussian distribution. In the example above, ±1 K is the so-called “1σ interval”. This means that 68.3% of the probability is contained within the range [99, 101] K. A “2σ interval” would have a length of 2 K on either side, so 95.4% of the probability is contained in the interval [98, 102] K. If one wanted a 99% interval, one would need a 2.57σ range (see Table 4). Since in this case the 1σ error is 1 K, the 2.57σ error is 2.57 K and the 99% interval is [97.43, 102.57] K. A heuristic derivation of how the Gaussian arises follows from this example in- volving darts throwing. Suppose we are throwing darts towards a target (located at the center of the coordinate system, at the position x = 0, y = 0), with the following rules: (i) Throws are independent. (ii) Errors in the x and y directions are independent. (iii) Large errors are less probable than small ones. The probability of a dart landing in an inﬁnitesimal square located at coordinates (x, y) and of size (∆ x, ∆ y) (i.e., the dart landing in the interval [x, x + ∆ x] and [y, y + ∆ y]) is given by: p(x)∆ x · p(y)∆ y = f (r)∆ x∆ y, (226) where p(x) is the probability density of landing at position x (and similarly for p(y)), which is what we are trying to determine. On the l.h.s. of this equation, we can multiply the probabilities of landing in the x and y direction because of rule number (1) and (2). On the l.h.s., f (r) is a function that only depends on the radial distance from the center, because of rule (2). We now differentiate the above equation w.r.t. the polar coordinate φ : (p(x) d p(x) dφ + p(y) d p(y) dφ ) ∆ x∆ y = 0. (227) (Note that the r.h.s. becomes 0 as it does not depend on φ ). In polar coordinates, x = r cos φ , y = r sin φ , hence Bayesian Methods 83 d p(x) dφ = ∂ p ∂ x ∂ x ∂ φ = − ∂ p ∂ x y, (228) d p(y) dφ = ∂ p ∂ y ∂ y ∂ φ = ∂ p ∂ y x. (229) Eq. (227) becomes ( −p(x) ∂ p ∂ x y + p(y) ∂ p ∂ y x) ∆ x∆ y = 0, (230) which implies p(x) x ∂ p ∂ x = p(y) y ∂ p ∂ y . (231) Since each side only depends on one of the variables, they must both equal a constant C, and we obtain the differential equation: ∂ p ∂ x = Cxp(x) (232) (and similarly for y). Integration gives the solution p(x) = Ae C 2 x2 (233) and C < 0 because of rule (3). We thus deﬁne C = −1/σ 2. Requiring that the distri- bution is normalized gives A = 1√ 2πσ , and therefore p(x) has the shape of a Gaussian (similarly for p(y)). 5.5 The Chi-Square distribution We deﬁne the RV χ 2 as the sum of the squares of n standardised independent iden- tically distributed Gaussian RV, x1, . . . , xn, where xi ∼ N (µ, σ ): χ 2 = n ∑ i ( xi − ν σ )2 (234) The the RV χ 2 is distributed according to the Chi-Square distribution with n degrees of freedom, p(χ 2) = 1 Γ (n/2)2n/2 (χ 2) n 2 −1 exp(− 1 2 χ 2). (235) For the Chi-Square distribution of Eq. (235), the expectation value and variance are given by: E[X] = n Var(X) = 2n. (236) 84 Bayesian Methods References 1. Amanullah, R., Lidman, C., Rubin, D., Aldering, G., Astier, P., et al.: Spectra and Light Curves of Six Type Ia Supernovae at 0.511 ¡ z ¡ 1.12 and the Union2 Compilation. Astrophys.J. 716, 712–738 (2010). DOI 10.1088/0004-637X/716/1/712 2. Anderson, L., et al.: The clustering of galaxies in the SDSS-III Baryon Oscillation Spectro- scopic Survey: measuring DA and H at z = 0.57 from the baryon acoustic peak in the Data Release 9 spectroscopic Galaxy sample. Mon. Not. Roy. Astron. Soc. 439(1), 83–101 (2014). DOI 10.1093/mnras/stt2206 3. Bayes, T., Price, R.: An essay towards solving a problem in the doctrine of chances. by the late rev. mr. bayes, communicated by mr. price, in a letter to john canton, m. a. and f. r. s. Phil. Trans. Roy. Soc. 53(0), 370–418 (1763). Reproduced in: Biometrika, 45, 293-315 (1958) 4. Berger, J.: Could ﬁsher, jeffreys and neyman have agreed on testing? Statistical Science 18(1), 1–12 (2003). Rejoinder: ibid., 28-32 5. Berger, J., Sellke, T.: Testing a point null hypothesis: The irreconcilability of p values and evidence. J. Am. Stat. Assoc. 82(397), 112–122 (1987). Rejoinder: ibid., 135–139 6. Betoule, M., et al.: Improved cosmological constraints from a joint analysis of the SDSS-II and SNLS supernova samples. Astron. Astrophys. 568, A22 (2014). DOI 10.1051/0004-6361/ 201423413 7. Box, G.E.P., Tiao, G.C.: Bayesian Inference in Statistical Analysis. John Wiley & Sons, Chicester, UK (1992) 8. Brewer, B.J., Foreman-Mackey, D.: DNest4: Diffusive Nested Sampling in C++ and Python (2016) 9. Capp´e, O., Guillin, A., M., M., Robert, C.: Population monte carlo. Journal of Computa- tional and Graphical Statistics 13(4), 907–929 (2004). URL http://www.jstor.org/ stable/27594084 10. Carroll, S.M., Press, W.H., Turner, E.L.: The Cosmological constant. Ann.Rev.Astron.Astrophys. 30, 499–542 (1992). DOI 10.1146/annurev.aa.30.090192.002435 11. Casella, G., Edwards, I.: Explaining the Gibbs sampler. Am. Stat. 46, 167–174 (1992) 12. Chernoff, H.: On the distribution of the likelihood ratio. The Annals of Mathematical Statistics 25, 573–578 (1954) 13. Cousins, R.D.: Comment on ’Bayesian Analysis of Pentaquark Signals from CLAS Data’, with Response to the Reply by Ireland and Protopopsecu,. Phys. Rev. Lett. . 101, 029,101 (2008) 14. Cousins, R.D.: The Jeffreys-Lindley Paradox and Discovery Criteria in High Energy Physics. ArXiv e-prints (2013) 15. Demortier, L., Lyons, L.: Testing Hypotheses in Particle Physics: Plots of p 0 Versus p 1. ArXiv e-prints (2014) 16. Dunkley, J., Bucher, M., Ferreira, P.G., Moodley, K., Skordis, C.: Fast and reliable MCMC for cosmological parameter estimation. Mon. Not. Roy. Astron. Soc. 356, 925–936 (2005) 17. Efstathiou, G.: Limitations of Bayesian Evidence applied to cosmology. Mon. Not. Roy. As- tron. Soc. 388, 1314–1320 (2008). DOI 10.1111/j.1365-2966.2008.13498.x 18. Feroz, F., Hobson, M.P.: Multimodal nested sampling: an efﬁcient and robust alternative to Markov Chain Monte Carlo methods for astronomical data analyses. Mon. Not. Roy. Astron. Soc. 384, 449–463 (2008). DOI 10.1111/j.1365-2966.2007.12353.x 19. Foreman-Mackey, D., Hogg, D.W., Lang, D., Goodman, J.: emcee: The MCMC Hammer. Pub. Astron. Soc. Pac. 125, 306–312 (2013). DOI 10.1086/670067 20. Gelman, A., Roberts, G., Gilks, W.: Efﬁcient Metropolis Jumping Rules. In: J. Bernardo, J. Berger, A. Dawid, A. Smith (eds.) Bayesian statistics 5, vol. 30, pp. 599–607. Oxford Uni- versity Press (1996) 21. Gelman, A., Rubin, D.: Inference from iterative simulation using multiple sequences (with discussion). Statistical Science 7, 457–511 (1992) 22. Goodman, J., Weare, J.: Ensemble samplers with afﬁne invariance. Comm. App. Math. Comp. Sci. 5, 65 (2010) Bayesian Methods 85 23. Handley, W.J., Hobson, M.P., Lasenby, A.N.: PolyChord: nested sampling for cosmology. Mon. Not. Roy. Astron. Soc. 450(1), L61–L65 (2015). DOI 10.1093/mnrasl/slv047 24. Hastings, W.K.: Monte Carlo sampling methods using Markov chains and their applications. Biometrika 57, 97–109 (1970) 25. Hee, S., Handley, W., Hobson, M.P., Lasenby, A.N.: Bayesian model selection without evi- dences: application to the dark energy equation-of-state. Mon. Not. Roy. Astron. Soc. 455(3), 2461–2473 (2016). DOI 10.1093/mnras/stv2217 26. Iba, Y.: Population Monte Carlo algorithms. Transactions of the Japanese Society for Artiﬁcial Intelligence 16, 279–286 (2001). DOI 10.1527/tjsai.16.279 27. Jaynes, E.T.: Probability Theory. The logic of science. Cambridge University Press, Cam- bridge, UK (2003) 28. Jeffreys, H.: Theory of probability, 3rd edn edn. Oxford Classics series (reprinted 1998). Oxford University Press, Oxford, UK (1961) 29. Jeffreys, H.: Some general points in probability theory. In: A. Zellner (ed.) Bayesian analysis in econometrics and statistics. North-Hollands, Amsterdam (1980) 30. Kass, R.E., Raftery, A.E.: Bayes factors. J. Am. Stat. Ass. 90(430), 773–795 (1995) 31. Kelly, B.C.: Some Aspects of Measurement Error in Linear Regression of Astronomical Data. ApJ 665(2), 1489–1506 (2007) 32. Kessler, R., Becker, A., Cinabro, D., Vanderplas, J., Frieman, J.A., et al.: First-year Sloan Digital Sky Survey-II (SDSS-II) Supernova Results: Hubble Diagram and Cosmological Pa- rameters. Astrophys.J.Suppl. 185, 32–84 (2009). DOI 10.1088/0067-0049/185/1/32 33. Kowalski, M., et al.: Improved Cosmological Constraints from New, Old and Combined Su- pernova Datasets. Astrophys.J. 686, 749–778 (2008). DOI 10.1086/589937 34. Kunz, M., Trotta, R., Parkinson, D.: Measuring the effective complexity of cosmological mod- els. Phys. Rev. D74, 023,503 (2006) 35. Liddle, A.R.: How many cosmological parameters? Mon. Not. Roy. Astron. Soc. 351, L49– L53 (2004) 36. Liddle, A.R., Mukherjee, P., Parkinson, D., Wang, Y.: Present and future evidence for evolving dark energy. Phys. Rev. D74, 123,506 (2006) 37. Lindley, D.: A statistical paradox. Biometrika 44, 187–192 (1957) 38. Lyons, L.: A particle physicist’s perspective on astrostatistics. In: Statistical Challenges in Modern Astronomy IV Conference, 371, pp. 361–372. Astronomical Society of the Paciﬁc, San Francisco (2007) 39. Lyons, L.: Bayes and Frequentism: a Particle Physicist’s perspective. Contemp. Phys. 54, 1 (2013). DOI 10.1080/00107514.2012.756312 40. March, M., Starkman, G., Trotta, R., Vaudrevange, P.: Should we doubt the cosmological con- stant? Mon.Not.Roy.Astron.Soc. 410, 2488–2496 (2011). DOI 10.1111/j.1365-2966.2010. 17614.x 41. Martin, J., Ringeval, C., Trotta, R., Vennin, V.: Compatibility of Planck and BICEP2 results in light of inﬂation. Phys. Rev. D 90(6), 063501 (2014). DOI 10.1103/PhysRevD.90.063501 42. Martin, J., Ringeval, C., Trotta, R., Vennin, V.: The Best Inﬂationary Models After Planck. JCAP 1403, 039 (2014). DOI 10.1088/1475-7516/2014/03/039 43. Metropolis, N., Rosenbluth, A.W., Rosenbluth, M.N., Teller, A.H., Teller, E.: Equation of state calculations by fast computing machines. J. Chem. Phys. 21, 1087–1092 (1953) 44. Mukherjee, P., Parkinson, D., Liddle, A.R.: A nested sampling algorithm for cosmological model selection. Astrophys. J. 638, L51–L54 (2006) 45. Neal, R.: Mcmc using hamiltonian dynamics. In: S. Brooks, A. Gelman, G. Jones, X.L. Meng (eds.) Handbook of Markov Chain Monte Carlo. Chapman and Hall/CRC Press (2011) 46. Park, T., van Dyk, D.A.: Partially collapsed Gibbs samplers: Illustrations and applications. Journal of Computational and Graphical Statistics 18, 283–305 (2009) 47. Parkinson, D., Liddle, A.R.: Application of Bayesian model averaging to measurements of the primordial power spectrum. Phys.Rev. D82, 103,533 (2010). DOI 10.1103/PhysRevD.82. 103533 86 Bayesian Methods 48. Protassov, R., van Dyk, D.A., Connors, A., Kashyap, V.L., Siemiginowska, A.: Statistics: han- dle with care, detecting multiple model components with the likelihood ratio test. The Astro- physical Journal 571, 545–559 (2002) 49. Raftery, A.: Bayesian model selection in sociological research. Sociological Methodology 25, 111–163 (1995) 50. Rest, A., et al.: Cosmological Constraints from Measurements of Type Ia Supernovae discov- ered during the ﬁrst 1.5 yr of the Pan-STARRS1 Survey. Astrophys. J. 795(1), 44 (2014). DOI 10.1088/0004-637X/795/1/44 51. Sellke, T., Bayarri, M., Berger, J.O.: Calibration of p values for testing precise null hypotheses. American Statistician 55(1), 62–71 (2001) 52. Shariff, H., Jiao, X., Trotta, R., van Dyk, D.A.: BAHAMAS: New Analysis of Type Ia Su- pernovae Reveals Inconsistencies with Standard Cosmology. Astrophys. J. 827(1), 1 (2016). DOI 10.3847/0004-637X/827/1/1 53. Skilling, J.: Nested sampling. In: R. Fischer, R. Preuss, U. von Toussaint (eds.) Bayesian Inference and Maximum Entropy Methods in Science and Engineering, 735, pp. 395–405. Amer. Inst. Phys. conf. proc. (2004) 54. Spergel, D.N., et al.: Wilkinson Microwave Anisotropy Probe (WMAP) three year results: implications for cosmology. Astrophys. J. Suppl. 170, 377 (2007). DOI 10.1086/513700 55. Tegmark, M.: What does inﬂation really predict? JCAP 0504, 001 (2005). DOI 10.1088/ 1475-7516/2005/04/001 56. Trotta, R.: Applications of bayesian model selection to cosmological parameters. Mon. Not. Roy. Astron. Soc. 378, 72–82 (2007) 57. Trotta, R.: Bayes in the sky: Bayesian inference and model selection in cosmology. Contemp. Phys. 49, 71–104 (2008) 58. Vardanyan, M., Trotta, R., Silk, J.: How ﬂat can you get? A model comparison perspective on the curvature of the Universe. Mon.Not.Roy.Astron.Soc. 397, 431–444 (2009). DOI 10.1111/ j.1365-2966.2009.14938.x 59. Vardanyan, M., Trotta, R., Silk, J.: Applications of Bayesian model averaging to the curvature and size of the Universe. Mon.Not.Roy.Astron.Soc. 413, L91–L95 (2011) 60. Vennin, V., Koyama, K., Wands, D.: Encyclopædia curvatonis. JCAP 1511, 008 (2015). DOI 10.1088/1475-7516/2015/11/008 61. Weinberg, S.: Anthropic Bound on the Cosmological Constant. Phys. Rev. Lett. 59, 2607 (1987). DOI 10.1103/PhysRevLett.59.2607 62. Wilks, S.: The large-sample distribution of the likelihood ratio for testing composite hypothe- ses. Ann. Math. pp. 60–62 (1938) 63. Yu, Y., Meng, X.L.: To center or not to center: that is not the question—An ancillarity- sufﬁciency interweaving strategy (ASIS) for boosting MCMC efﬁciency (with discussion). Journal of Computational and Graphical Statistics 20, 531–570 (2011)","libVersion":"0.3.2","langs":""}