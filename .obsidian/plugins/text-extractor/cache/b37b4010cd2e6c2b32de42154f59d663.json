{"path":"Books and Papers/Masters Points of Interest/Lorenza Saitta, Attilio Giordana, Antoine Cornuéjols - Phase Transitions in Machine Learning-Cambridge University Press (2011).pdf","text":"This page intentionally left blank Phase Transitions in Machine Learning Phase transitions typically occur in combinatorial computational problems and have important consequences, especially with the current spread of statistical relational learning and of sequence learning methodologies. In Phase Transi- tions in Machine Learning the authors begin by describing in detail this phe- nomenon and the extensive experimental investigation that supports its presence. They then turn their attention to the possible implications and explore appropri- ate methods for tackling them. Weaving together fundamental aspects of computer science, statistical physics, and machine learning, the book provides sufﬁcient mathematics and physics background to make the subject intelligible to researchers in the artiﬁ- cial intelligence and other computer science communities. Open research issues, suggesting promising directions for future research, are also discussed. L ORENZA S AITTA is Full Professor of Computer Science at the University of Piemonte Orientale, Italy. A TTILIO G IORDANA is Full Professor of Computer Science at the Univer- sity of Piemonte Orientale, Italy. A NTOINE C ORNU ´EJ O L S is Full Professor of Computer Science at the AgroParisTech Engineering School, Paris. Phase Transitions in Machine Learning LORENZA SAITTA University of Piemonte Orientale, Italy ATTILIO GIORDANA University of Piemonte Orientale, Italy ANTOINE CORNU ´EJOLS AgroParisTech Engineering School, Paris, France CAMBRIDGE UNIVERSITY PRESS Cambridge, New York, Melbourne, Madrid, Cape Town, Singapore, S˜a o Paulo, Delhi, Tokyo, Mexico City Cambridge University Press The Edinburgh Building, Cambridge CB2 8RU, UK Published in the United States of America by Cambridge University Press, New York www.cambridge.org Information on this title: www.cambridge.org/9780521763912 C⃝ L. Saitta, A. Giordana and A. Cornu´ejols 2011 This publication is in copyright. Subject to statutory exception and to the provisions of relevant collective licensing agreements, no reproduction of any part may take place without the written permission of Cambridge University Press. First published 2011 Printed in the United Kingdom at the University Press, Cambridge A catalogue record for this publication is available from the British Library ISBN 978-0-521-76391-2 Hardback Cambridge University Press has no responsibility for the persistence or accuracy of URLs for external or third-party internet websites referred to in this publication, and does not guarantee that any content on such websites is, or will remain, accurate or appropriate. Contents Preface page ix Acknowledgments xiii Notation xiv 1 Introduction 1 2 Statistical physics and phase transitions 12 2.1 Basic notions of statistical physics 12 2.2 Ensemble of states 19 2.3 Phase transitions 23 2.4 Ising models 26 2.5 Mean ﬁeld theory 32 2.6 Quenched disorder and self-averaging 33 2.7 Replica method 37 2.8 Cavity method 39 2.9 Comments 42 3 The satisﬁability problem 43 3.1 General framework 43 3.2 Random graphs 45 3.3 The SAT problem 49 3.4 The random (2 + p)-SAT 62 3.5 Solving the SAT problem 63 3.6 Comments 68 4 Constraint satisfaction problems 70 4.1 Algorithms for solving CSPs 73 4.2 Generative models for CSPs 79 4.3 Phase transition in a CSP 81 4.4 Comments 89 v vi Contents 5 Machine learning 92 5.1 Concept learning 93 5.2 Representation languages 106 5.3 Comments 122 6 Searching the hypothesis space 124 6.1 Guiding the search in the hypothesis space 125 6.2 FOIL: information gain 131 6.3 SMART+: beam search 132 6.4 G-Net: genetic evolution 133 6.5 PROGOL: exhaustive search 134 6.6 Plateaus 135 6.7 Comments 139 7 Statistical physics and machine learning 140 7.1 Artiﬁcial neural networks 140 7.2 Propositional learning approaches 152 7.3 Relational learning 163 7.4 Comments 167 8 Learning, SAT, and CSP 168 8.1 Reducing propositional learning to SAT 168 8.2 Phase transitions and local search in propositional learning 175 8.3 The FOL covering test as a CSP 178 8.4 Relation between CSP and SAT 179 8.5 Comments 183 9 Phase transition in FOL covering test 184 9.1 Model RL 185 9.2 The search algorithm 195 9.3 Experimental analysis 198 9.4 Comparing model RL with other models for CSP generation 202 9.5 Smart algorithms for the covering test 214 9.6 Comments 217 10 Phase transitions and relational learning 220 10.1 The experimental setting 221 10.2 Experimental results 229 10.3 Result interpretation 235 10.4 Beyond general-to-speciﬁc learning strategies 247 10.5 Comments 255 Contents vii 11 Phase transitions in grammatical inference 258 11.1 Learning grammars 258 11.2 Grammatical inference by generalization 269 11.3 A phase transition in learning automata? 274 11.4 The covering test: random sampling in H 275 11.5 Learning, hypothesis sampling, and phase transitions 278 11.6 Consequences of the behavior of the learning algorithms: how bad is it? 293 11.7 Comments 298 12 Phase transitions in complex systems 300 12.1 Complex systems 301 12.2 Statistical physics and the social sciences 304 12.3 Communication and computation networks 309 12.4 Biological networks 310 12.5 Comments 311 13 Phase transitions in natural systems 313 13.1 Comments 317 14 Discussion and open issues 319 14.1 Phase transitions or threshold phenomena? 320 14.2 Do phase transitions occur in practice? 327 14.3 Blind spot 329 14.4 Number of examples 331 14.5 Machine learning and SAT or CSP solvers 331 14.6 Relational learning and complex networks 333 14.7 Relational machine learning perspective 334 Appendix A Phase transitions detected in two real cases 339 A.1 Mutagenesis dataset 339 A.2 Mechanical troubleshooting datasets 347 Appendix B An intriguing idea 351 References 355 Index 375 Preface From its inception in the 1930s, the rich and vigorous ﬁeld of computer science has been concerned with the resources, both in time and in memory, needed to carry out a computation. A number of fundamental theorems were discovered that resorted to a worst-case analysis. The central question was whether a given algorithm could be guaranteed to terminate a computation in ﬁnite time what- ever the inputs, and, if so, in which class of complexity it lay, given the control parameters: polynomial, exponential, and so on. Therefore, in 1991, a paper by Cheeseman, Kaneefsky, and Taylor came as a bolt from the blue. Indeed, while its title, “Where the really hard problems are”, was not altogether disturbing, its content was. Broadly speaking, the authors argued that even if it was important to analyze worst cases, it was just as essential to look for the typical complex- ity of computations, the complexity encountered when solving typical problems. And there lies a gem: the transition from the region of problems that are hard, in terms of algorithmic complexity, to the region of problems that are easy can be quite sharp. Moreover, these regions and transitions are not related to the worst cases. We remember that this 1991 paper, presented at the International Joint Con- ference on Artiﬁcial Intelligence (IJCAI), started a commotion, though how pro- found this would be was not at ﬁrst apparent. We were among those who felt that this paper and others that promptly followed, from physicists in particular, were signiﬁcant beyond the obvious. However, this event did not alter the course of machine learning, our ﬁeld, for many years. In machine learning too the theoret- ical analysis that was at that time taking shape dealt with a type of worst-case study; this new statistical theory of learning was sweeping the ﬁeld and gain- ing momentum as new learning algorithms, inspired in part by its lessons, were devised. Thus, it was only in 1999 that M. Botta and two of us1 ﬁnally published a paper that took in the new perspective opened by Cheeseman and others and 1Attilio Giordana and Lorenza Saitta (Botta et al., 1999). ix x Preface examined its impact on machine learning or, to be more speciﬁc, on the match- ing problem that is at the heart of learning. And here again, as with hindsight could have been suspected, a phase transition came into view. Over the follow- ing years we, and others, carried out thorough empirical investigations, which all conﬁrmed and elaborated this ﬁnding. Even though the mainstream of ma- chine learning was still under the spell of the statistical and worst-case-analysis perspective, it was becoming apparent that these results, which could not be ac- counted for by the dominant view, had a quite signiﬁcant potential impact on the very feasibility of learning. Indeed, some known failures in the learning of large-scale problems could be explained thanks to this new point of view. The fact is that, at least for some learning problems, there exists a sharp dis- continuity between easy and hard matching problems. This severely hinders, at the very least, the assessment of candidate hypotheses considered during learn- ing, therefore making the exploration of solutions all but blind. It is no wonder that the consequences can be quite serious. While a complete understanding of the phase transition in learning still eludes us as a community of researchers, we feel that the wealth of results ob- tained in recent years and their known links with other ﬁelds in computer science and physics are now sufﬁciently mature to deserve a wide encompassing presen- tation, one that would describe as large a part as possible of the phase transition phenomena relevant to machine learning and would stimulate further research on this important subject. This book is the result of our conviction that the study of phase transitions in machine learning is important for the future of machine learning, and it presents us with the opportunity to establish profound connec- tions with other natural sciences. The book deals with the border between statistical physics, complex sys- tems, and machine learning: it explores emergent properties in relational ma- chine learning using techniques derived from statistical physics. More generally, the book is concerned with the emergence, in learning, of a phase transition, a phenomenon typically occurring both in many-body systems and in combinato- rial problems. This phenomenon is described in detail, and the extensive experimental in- vestigation that supports its presence is reported. Then the results and the impli- cations that the appearance of a phase transition may have on the scalability of relational learning and on the quality of the acquired knowledge are discussed in depth. With the current spread of statistical relational learning methodologies this topic is assuming an increasingly strong relevance. The idea behind the book is to stimulate synergic research interests in the ﬁelds of both statistical physics and machine learning. Researchers in the former may ﬁnd in machine learning a rich, appealing ﬁeld, where their theories and Preface xi methods can be applied whereas researchers in the latter may ﬁnd new tools for investigating and explaining learning processes in depth. The identiﬁcation of a phase transition in a computational problem may have important consequences in practice. In fact, as mentioned above, the standard notion of the computational complexity of a class of problems is a pessimistic evaluation based on a worst-case analysis. The investigation of phase transitions can provide information on single instances of the class, shifting the focus of the complexity analysis from the maximum complexity to a typical complexity. Relational learning is a task particularly affected by the problem of high compu- tational complexity. In this book, we are only concerned with supervised learning for classiﬁcation, within the paradigm of learning from examples. A theoretical approach, inspired by statistical physics, and a supporting set of experiments have uncovered that, in relational learning, the expected phase transition occurs inside a range of parameter values that is relevant for practical learning problems. It is thus sensible to investigate the phenomenon and to try to propose possible ways around it, since the emergence of a phase transition in relational learning can have a large negative impact on a task’s feasibility. In order to underline that the emergence of a phase transition is far from exceptional, we have widened the scope of the book to include grammar induc- tion and an overview of related topics in neural networks and other propositional learning approaches showing the ubiquity of the phenomenon. Moving outside the machine learning area, we also describe the emergence of phase transitions in complex networks and in natural systems, including human cognition. Again, the links between the ﬁndings observed in such a variety of systems may stimulate cross-correlations and convergence. We hope that the deep interactions that we will discuss between the theoreti- cal issues and the experimental ﬁndings will provide a rather complete landscape of the ﬁeld, including both the foundational aspects and the practical implica- tions. Our intention is that the novelty of the topic, the analysis of foundational issues in machine learning, and our attention to practical solutions and applica- tions will make the book appeal to a variety of readers. The detailed explana- tions of ﬁndings should facilitate understanding of the various viewpoints even for readers not within the ﬁeld. Even though the book mainly targets a readership familiar with artiﬁcial in- telligence and machine learning, its foundational aspects will also be of interest to cognitive scientists, and even philosophers, looking for the emergence and the epistemological impact of similar phenomena in nature. The book may be of particular interest to researchers working on complex systems, as we make an explicit effort to link the phenomena investigated to the theory of these systems. Likewise, researchers in statistical physics who are interested in its computa- tional aspects may be attracted by the book. xii Preface The approach taken is primarily quantitative and rigorous. Nevertheless, we have provided intuitive and qualitative illustrations and explanations of the issues and results. The idea is that even non-technical readers should be able to under- stand the main issues. For a qualitative understanding, the basic notions of artiﬁ- cial intelligence (especially knowledge representation and search) and computer science (especially computational complexity) are necessary. For a quantitative understanding, probability theory and advanced calculus are required. Reading the book should allow a researcher to start work in the ﬁeld without searching, reading, and linking many articles found dotted about in a variety of journals. Also, the book should be of help for those wanting to understand some of the philosophical problems underlying computation. Above all else we would be happy to see new research themes originating from this book. Acknowledgments Several friends and colleagues have contributed to this book, directly or indi- rectly, and we are indebted to them all. We want to thank in particular Mich`ele Sebag: long and pleasant discussions with her greatly contributed to our understanding and broadened our horizons; working with her was an enriching pleasure. Also many thanks go to Erick Alphonse and Omar Osmani, who followed our ﬁrst steps in the ﬁeld with enthusiasm, contributing many new ideas and results. In this book we have reported the work of many researchers, and their per- mission to reprint graphics from their papers has spared us a lot of additional work; hearty thanks to them as well. Finally, we are very grateful to Enrico Scalas, a colleague physicist who carefully checked our introduction to statistical physics and took the time to provide us with detailed and insightful comments. xiii Notation P Probability (for a ﬁnite set) p Probability density G Graph G Ensemble of graphs E[x] Expectation of x V[x] Variance of x O(·) “Big O” notation: describes the limiting behavior of a function when the argument tends towards inﬁnity R The real numbers Rn The space of real numbers of dimension n N The natural numbers Bn = {0, 1}n Boolean space of dimension n ⃗x = ⎛ ⎜ ⎝ x1 ... xn ⎞ ⎟ ⎠ A column vector ⃗x⊤ =(x1 ··· xn) A row vector || ⃗x || L2 norm of the vector x ∂/∂xf (x, y) Partial derivative of function f (x, y) with respect to x ˙x or dx/dt Total time derivative of x df (x) dx Total derivative of function f (x) with respect to x X Input or description space of the examples Y Output or label space SL Learning set xiv Notation xv P Set of positive training examples N Set of negative training examples ST Test set e An example ⃗xk An example description ⃗zk =(⃗xk,yk) A labeled example (description, class) yk ∈Y The true label of an example provided by an “oracle” C Space of possible target concepts c : X→ Y A target concept H Hypothesis space h ∈H A hypothesis considered by the learner y = h(⃗x) ∈Y Prediction of the hypothesis h about example ⃗x Φ A set of logical formulas ϕ ∈ Φ A logical formula ϕ belonging to the set Φ ℓ ( c(⃗x),h(⃗x)) The loss incurred when h(⃗x) is predicted instead of the true label c(⃗x) E Energy S Entropy xj:a Variable xj is bound to the constant a xj:a Variable xj is not bound to the constant a m Number of literals in a formula to be matched n Number of variables in a formula to be matched N Number of goods in each table in an example L Number of constants occurring in the tables of an example 1 Introduction Learning involves vital functions at different levels of consciousness, starting with the recognition of sensory stimuli up to the acquisition of complex notions for sophisticated abstract reasoning. Even though learning escapes precise deﬁ- nition there is general agreement on Langley’s idea (Langley, 1986) of learning as a set of “mechanisms through which intelligent agents improve their behavior over time”, which seems reasonable once a sufﬁciently broad view of “agent” is taken. Machine learning has its roots in several disciplines, notably statistics, Machine learning’s rootspattern recognition, the cognitive sciences, and control theory. Its main goal is to help humans in constructing programs that cannot be built up manually and pro- grams that learn from experience. Another goal of machine learning is to provide computational models for human learning, thus supporting cognitive studies of learning. Among the large variety of tasks that constitute the body of machine learn- Classiﬁcation ing, one has received attention from the beginning: the acquiring of knowledge for performing classiﬁcation. From this perspective machine learning can be de- scribed roughly as the process of discovering regularities from a set of available data and extrapolating these regularities to new data. Over the years, machine learning has been understood in different ways. At Machine learning as an algorithmﬁrst it was considered mainly as an algorithmic process. One of the ﬁrst ap- proaches to automated learning was proposed by Gold in his “learning in the limit” paradigm (Gold, 1967). This type of learning provides an inﬁnite sequence Gold’s paradigm of pieces of data to the learner, who generates a model that explains the data. At each new input the learner updates its current model (the “hypothesis”), hoping, but never knowing for sure, that it is closer to the “correct” one. A fundamental change in machine learning was the recognition of its nature Machine learning as searchas a search problem (Mitchell, 1982). Given a set of data and some language(s) for describing the data and the target knowledge, learning consists in the explo- ration of a hypothesis space, guided by a heuristic, until a speciﬁed termination 1 2 Introduction condition is met; as the search space is usually too large to be explored exhaus- tively, the learner must have a criterion to evaluate and compare hypotheses. In order to facilitate the search the hypothesis space is usually internally structured according to a generality relation. Just as learning is a fundamental task in any living organism, machine learn- ing is a fundamental task in artiﬁcial intelligence as well. It is impossible to conceive a truly intelligent agent that is not provided with the ability to extend its knowledge and improve its performance over time. Appealing as it may be, machine learning encounters severe difﬁculties, which even today hinder its full exploitation. The main obstacle to be overcome is that most machine learning algorithms are very demanding in terms of compu-Computational complexity of learning tational resources, especially those that are closer to the human process of learn- ing. This concept of computational complexity in learning is the core around which this book is constructed. For hundreds of years the abstract nature of mathematical truths required advances through proving theorems. Existence or constructive proofs were con- cerned with the logical soundness of the derived results, without any atten- tion to their concrete attainability. The same was true for algorithms: the only relevant aspect was their correctness, not their practical execution. Mathematical knowledge appeared to scientists as only limited by human skill in discovering or inventing it. With the advent of information science, things changed radically. In fact, logician Kurt G¨odel’s work provided clear evidence that the discovery of someG¨odel’s incompleteness theorem mathematical truths may be intrinsically limited (G¨odel, 1931). In fact, with his famous incompleteness theorem he proved that Hilbert’s belief in the existence of an effective procedure determining the truth or falsity of any mathematical proposition was illfounded: thus the notion of undecidability was born. In order to understand this fundamental notion better we have to be more precise about the concept of an algorithm. The word “algorithm” derives from the name of the Persian mathematician Abu Abdullah Muhammad ibn Musa al-Khwarizmi, whose work introduced Arabic numerals and algebraic concepts to the western world. He worked in Baghdad in the ninth century, when the city was a centre of scientiﬁc studies. The ancient word algorism originally referred only to the rules of performing arithmetic using Arabic numerals but evolved via the Latin translation of al-Khwarizmi’s name into algorithm by the 18th century. In its more intuitive formulation, an algorithm is a precise and unambiguous sequenceAlgorithm of steps that, given a problem to be solved and some input data, provides the solution thereof.1 1Actually, one may clarify the difference between procedures and algorithms by reserving the latter name for procedures that terminate. As we are concerned only with the halting case, we will use the two terms interchangeably. Introduction 3 In general, a particular problem to be solved is a speciﬁc instance of a class of problems. For example, the problem of sorting in ascending order the elements of a vector ⃗x of n integer numbers belongs to a class Π of similar problems containing all such vectors, each with a different length n and different content. Decidability The notion of decidability refers to the class of problems as a whole, not to a single instance. More precisely, given a class of problems Π, we will say that the class is decidable if there exists an algorithm that, given as an input any instance of the problem class, provides a solution. Then, undecidability does not prevent any single instance from being solved but, rather, it limits the generality of the algorithm for ﬁnding the solution in any instance. In other words, for a decidable class a single algorithm is able to solve any instance of the class whereas for an undecidable class every problem instance must be solved with, in principle, a different algorithm.2 In order to prove that a problem class is undecidable one has to show that no unique algorithm solves all its instances. This is usually done by reducing the problem (class) to a known undecidable problem. A basic undecidable prob- lem is the halting problem, proved undecidable by Alan Turing in 1936 (Turing, 1936). The halting problem consists of writing a general algorithm that, taking Halting problem as input any algorithm A and some input data, outputs YES or NO, depending on whether A halts or continues ad inﬁnitum. Clearly, given a speciﬁc algorithm it is usually possible, with more or less ease, to decide whether it will stop for any speciﬁc input. However, there is no general algorithm that is able to provide this decision for any input algorithm. Even though undecidability may be interesting from a philosophical point of view, in that it might be considered as a limiting factor to human knowledge, this notion is not a subject of this book, in which we are concerned only with decidable problem classes. But, even limiting the study to decidable problems, difﬁculties of another na- ture come up. These difﬁculties have been again brought to our attention in recent times by computer science, which stresses a concept that was not previously con- Efﬁcient algorithms sidered important in mathematics. As already mentioned, mathematical results are achieved by proving theorems or by designing abstract algorithms to solve problems. In computer science this is not sufﬁcient: the algorithm for solving a problem must be efﬁcient, i.e., it must run on a computer in reasonable time. In order to deﬁne what “reasonable” time means, the concept of the computational complexity of an algorithm must be introduced. Givenanalgorithm A, working on some data, its computational complexity is related to its run time. However, the run time depends on the programming language used to implement the algorithm and on the speciﬁc machine on which 2In the following we will use, for the sake of simplicity and where no ambiguity may arise, the terms “class of problems” and “problem” interchangeably. 4 Introduction the program is run. In order to make its deﬁnition more precise, and indepen- dent of the speciﬁc implementation, the complexity is evaluated in terms of the number of elementary steps performed by the algorithm and not in terms of the time it takes to execute them. But, even so, there are uncertainties about what has to be considered an elementary “step” in an algorithm, because this depends on the granularity of the observation. To overcome this difﬁculty an ideal, abstract, computer model is used, for which the notion of a “step” is precisely deﬁned. There is more than one “ideal” computer, but one of the simplest and bestTuring machine known is the Turing machine, an abstract computational device introduced by Alan Turing in the late 1930s (Turing, 1936), long before the ﬁrst actual com- puter was built. The simplest version of the Turing machine consists of a tape, a read−write head, and a control unit. The tape, inﬁnite in both directions, is divided into squares which contain a “blank” symbol and at least one other sym- bol belonging to an alphabet Σ. A square numbered 0 separates the left and right parts of the tape. The head can read or write these symbols onto the tape. The control unit of the machine speciﬁes a ﬁnite set of states in which the machine can be; at any point in time a Turing machine is in exactly one of these states. The control unit can be thought of as a ﬁnite state automaton. This automaton encodes the “program”. The computation proceeds in steps: at each step the head reads the content of the square in which it is positioned and, according to this content and the current state of the automaton, it writes another symbol on the same square and then moves one square to the left or to the right. At the be- ginning the input data are written on the right-hand part of the tape, starting at position 0, and the rest of the tape is ﬁlled with “blanks”. When the computation is over the machine stops, and the output can be read on the tape. Notwithstanding the simplicity of its mechanism, the Turing machine is be- lieved to be able to compute any computable algorithm that one can conceive. This assertion was hypothesized by Alonzo Church (1936) through the deﬁnition of the λ-calculus and the introduction of the notion of effective calculability: a function is said to be effectively calculable if its values can be found by some purely mechanical process. Later, Turing showed that his computation model (the Turing machine) and the λ-calculus are equivalent, so the assertion is now known as Church−Turing thesis. This thesis is almost universally accepted now,Church−Turing thesis even though the extent of its applicability is still a subject of debate. Implementing an algorithm on a Turing machine allows the notion of com- putational complexity to be precisely deﬁned. A “step” in an algorithm is a cycle <read a symbol, write a symbol, move the head> and the execution of any pro- gram is a sequence of such steps. Given a (decidable) class Π of problems, let T be the particular Turing machine used to ﬁnd the solution. If we take an instance I belonging to Π,let CT (I) be the exact number of steps T uses to solve I. Clearly, however, CT (I) is too detailed a measure, impossible to evaluate before Introduction 5 the program is executed. Thus we need a less detailed measure; to this end let n be an integer characterizing the size of the problem at hand. For instance, coming back to the sorting problem, n can be the length of the vector to be sorted. We can partition the class Π into subclasses Πn, each containing only instances In of length n. Even so, running the algorithm on the In requires different num- bers of steps, depending on the speciﬁc instance. As we want a safe measure of complexity, we take the pessimistic approach of attributing to the subclass Πn Formal deﬁnition of computational complexity the highest complexity found in the In, i.e., the complexity of the worst case. Formally, we deﬁne the complexity as CT (n)= Max In ∈Πn {CT (I n)}. As it can be proved that the complexity CT (n) is independent of the abstract Turing machine used and that it is the same for any concrete computer, we will drop the subscript T from the complexity and simply write CT (n)= C(n). The complexity C(n) deﬁned above is called the time complexity, because it refers to the time resource consumption of the algorithm. In a similar way, the space complexity can be deﬁned as the maximum amount of memory simultane- ously occupied during the program’s run. In this book, the word “complexity” will always refer to the time complexity unless otherwise speciﬁed. The introduction of the subclasses Πn is fundamental because the very goal of computational complexity theory is to estimate how the time complexity of an algorithm scales up with increasing n. In order to better understand this idea, let us consider two functions f and g from the integers to the integers: f : N+ → N+,g : N+ → N+. What we are interested in is the relative order of magnitude of the two functions rather than their actual values. So, let us consider the ratio of f (n) and g(n). There are three cases: lim n→∞ f (n) g(n) = ∞; (1.1) lim n→∞ f (n) g(n) = a ̸=0, ∞; (1.2) lim n→∞ f (n) g(n) =0. (1.3) In the ﬁrst case f (n) is of an order of magnitude greater than g(n); in the second case it is of the same order; and in the third case it is of a lower order of magni- tude. Introducing the O (“big O”) notation, we will say that f (n)= O(g(n)) in 6 Introduction the second and third cases, namely: f (n)= O(g(n)) ↔ lim n→∞ f (n) g(n) = a ̸= ∞. (1.4) From deﬁnition (1.4) we deduce that in f (n) and g(n) all terms of lower orders of magnitude can be omitted, as well as multiplicative constants. It is worth not- ing explicitly that the O notation tells us only that f (n) is of order of magnitudeO notation not greater than that of g(n), not that f (n) and g(n) have the same order in the mathematical sense. If f (n) and g(n) have exactly the same order of magni- tude (case (1.2)), we will say that f (n)=Θ(g(n)).If f (n) has order of magni- tude strictly greater than g(n), we will write f (n)=Ω(g(n)). EXAMPLE We give here some examples of the O notation: f (n)=50n 2 +20n +3 = O(n 2) f (n)= n3 +30n 2 + 100 = O(n3) f (n)=3 n + 1003 = O(3n ) Given two functions f (n) and g(n), we can provide a formal deﬁnition of f (n)= O(g(n)) as follows: f (n)= O(g(n)) ↔∃n0 ∃c [∀n>n0 : f (n) ⩽ cg(n)], (1.5) where c is a positive constant and n0 is a positive integer. Deﬁnition (1.5) tells that what happens for low values of n (i.e., lower than n0) is not important; on the contrary, only the asymptotic behavior of f (n) is relevant. A graphical illustration of deﬁnition (1.5) is given in Figure 1.1. We are now in a position to deﬁne precisely what a reasonable complexity is. An algorithm A will be said to be efﬁcient if it runs with a complexity that is at most polynomial in the size n of the input. Actually, many problems that are relevant in practice show aPolynomial complexity much more rapid (exponential) increase in the time required to obtain a solution, when the size of the problem increases; such problems cannot be solved within acceptable time spans. In computer science the study of the computational complexity of algorithms takes a central place; since its beginnings, scientists have studied problems from the complexity point of view, categorizing their behavior into a well-known complexity class hierarchy. According to the needs of this book we show, in Figure 1.2, an oversimpliﬁed version of this hierarchy, including only three types of problem: P, NP,and NP-complete. The class P contains problems that can Introduction 7 Figure 1.1 Graphical illustration of the O notation. If f (n)= O(g(h)) then after a given threshold n0, the function f (n) must be smaller than cg(n),where c is a positive constant. What happens for n<n0 does not matter. P NP-complete NP Figure 1.2 Simpliﬁed version of the complexity class hierarchy. The class NP includes both the class P and the class of NP-complete problems. be solved in polynomial time by a Turing machine like the one described above, i.e., a deterministic Turing machine. In order to deﬁne the class NP the behav- ior of a deterministic Turing machine must be extended with a nondeterminis- tic phase, to be executed at the beginning, thus becoming a non-deterministic Turing machine. In the non-deterministic phase, a potential solution is gener- ated; this is then veriﬁed by the subsequent deterministic phase. The NP class contains those problems that can be solved in polynomial time by such a non- deterministic machine. Whereas the deterministic Turing machine captures the notion of the polynomial solvability of a problem class, the non-deterministic Turing machine captures the notion of the polynomial veriﬁability of a problem 8 Introduction class. In other words, if one is able to suggest a potential solution to a problem, the non-deterministic Turing machine can verify in polynomial time whether it is indeed a solution. It should be clear from the deﬁnition that P is a subclass of NP: polynomial solvability implies polynomial veriﬁability. Today, the question whether P = NP is still an important open problem in computer science. On the one hand it has not been possible to prove that P = NP and on the other hand no polynomial algorithm has been found for many problems in NP, notwithstanding the amount of effort devoted to the task.P = NP? Thus, the general opinion is that P ̸= NP. This opinion is strongly supported by the existence of the subclass NP-complete. This subclass contains (a large number of) problems that share the following property: each problem in NP (in- cluding P) can be reduced in polynomial time to any problem in NP-complete; as a consequence, it would be sufﬁcient to solve in polynomial time just one problem in NP-complete to prove that P = NP. Given the amount of work al- ready devoted to this task, it seems highly unlikely that this will turn out to be the case. In this book we will assume as an underlying hypothesis that P ̸= NP. A class of problems that are particularly prone to a dramatic increase in com-Combinatorial problems putational complexity with increasing problem size is the class of combinatorial problems, many among which are NP-complete. Informally, a combinatorial problem is one that requires combinations of objects belonging to a set to be explored, with the goal of deciding whether a speciﬁed property holds true or of ﬁnding some optimal combination according to a speciﬁed criterion. Combinato- rial problems are well represented in artiﬁcial intelligence, operational research, complex system analysis, and optimization and search. Among the large variety of existing combinatorial problems, two have received a great deal of attention, namely the satisﬁability (SAT) problem (Cook, 1971)and the constraint satis- faction problem (CSP) (see for instance Kumar, 1992). In Chapters 3 and 4 these two problems will be introduced and described in detail, because they are inti- mately related to machine learning and to the sources of its complexity. Reconsidering the deﬁnition of computational complexity provided earlier, it is not necessarily a good idea to take the worst-case complexity as that rep- resentative of an algorithm A. In fact, A might be able to provide a solutionTypical complexity in reasonable time for the majority of the instances in Πn, running for a very long time in only a few particular instances; this is the case, for example, for the branch-and-bound optimization algorithm (Lawler and Wood, 1966). For this reason a new paradigm has emerged, which uses the typical running behavior of an algorithm instead of its worst case. The notion of the typical complexity has a precise meaning. Namely, it requires two conditions: • The typical complexity is the most probable complexity over the class of problem instances considered. Introduction 9 • As each problem instance has its own run time, there is a difference in complexity between that for the speciﬁc instance and the most probable complexity. When the size of the considered instances grows to inﬁnity, the difference between their complexity and the most probable complexity must go to 0 with probability 1. This new perspective on the complexity of algorithms was suggested by the discovery of interesting and fruitful links (previously unsuspected) between combinatorial problems and systems obeying the laws of statistical physics. It turns out that combinatorial problems share several characteristics with physical systems composed of a large number of particles and that a precise parallel can be established between such physical entities on the one hand and combinatorial functions to be optimized on the other hand. Among the many parallels that can be drawn from the link between such Phase transitions many-body physical systems and computational systems, one aspect is particu- larly relevant for this book, namely, the emergence of a phase transition (see for instance Hogg, 1996). Some physical systems composed of a large number of particles may exist in different phases. A phase is a homogeneous (with respect to some speciﬁed physical quantity) state of the system. A well-known case in everyday life is water, which can exist in solid, liquid, and gaseous phases. The phase that water is in depends on the values of the macroscopic variables describ- ing the physical state, for instance, the temperature and pressure. In Figure 1.3 a qualitative schema of the phases in which water may exist is shown. In a phase transition we distinguish between the order and control parameters: an order parameter is a quantity that shows a marked difference in behavior across the transition line whereas a control parameter is one that determines the location of the transition. In the case of water, a possible order parameter is the density Order and control parameterswhereas a possible control parameter is the temperature. The order and control parameters characterize the phase transition. According to Ehrenfest’s classiﬁcation, there are two types of phase transi- Types of phase transitionstion, namely ﬁrst-order and second-order. A precise deﬁnition of these types will be given in Chapter 2. We just mention, here, that we are interested in ﬁrst-order phase transitions; in this type of transition, in addition to the discontinuity in the order parameters, there is usually another quantity that goes to inﬁnity when the size of the system tends to inﬁnity as well. Moreover, at the transition point the two phases coexist. In the case of water, for example, the speciﬁc heat di- verges at the transition between liquid and vapor, because heat is being supplied to the system but the temperature remains constant. In computational problems the order parameters are usually quantities that characterize aspects of the algorithm’s behavior (for instance, the probability that a solution exists) and the control parameters describe the internal structure 10 Introduction Figure 1.3 Qualitative diagrams of the phases in which water can exist. The temperature T and pressure P are the control parameters of the transition be- tween phases. Along the separation lines two of the phases coexist. At the triple point C all three phases are present. Beyond the critical point A the water is said to be in a supercritical ﬂuid state. In this state the molecules are too energetic and too close to each other for a clear transition between liquid and vapor to exist. of the problem, whereas the quantity that diverges at a “phase transition” is the computational complexity of the algorithm. There are various motivations for studying the emergence of phase transi- tions. First, their emergence seems to be an ubiquitous phenomenon in many- body systems, capturing some essential properties of their nature. They occur not only in physical and computational systems but also in human perception and so- cial sciences, as will be described later in this book. Second, systems that show a phase transition exhibit, at the transition point, interesting singularities in behav- ior called “critical phenomena”, which elucidate their real essence, in a way not evident by other means. Third, phase transitions are interesting in themselves, as they explain ensemble or macroscopic behaviors in terms of short-range micro- scopic interactions. For computational systems the discovery of a phase transition in a problem class has several important consequences. The phase transition region contains the most difﬁcult problem instances, those for which the computational com- plexity shows an exponential increase with the problem size. Also, the phase transition can be used as a source of “difﬁcult” test problems for assessing the properties and the power of algorithms and for comparing them in meaning- ful problem instances. Moreover, very small variations in the control parameter Introduction 11 value may induce very large variations in the algorithm’s behavior and/or in the types of solution. Thus, a knowledge of the critical value of a control parame- ter allows the user to roughly predict the behavior of the algorithm. Moreover, by exploiting further the analogy with physical systems, it is possible to high- light the very sources of the complexity, which is not possible within classical complexity theory. In fact, with the techniques derived from statistical physics it is possible to enter into the deep structure of the problem and of its solutions; the system’s behavior near the phase transition allows a microscopic view of the solution space of the problems to be investigated by exploiting the corre- spondence established by the link. This fact not only offers the possibility of a deeper understanding of the properties of algorithms but also opens the way to the introduction of effective new algorithms. Even though the emergence of phase transitions is a widely diffused phe- nomenon in many ﬁelds, we will limit ourselves in the main to machine learning. We will then consider different approaches to machine learning and show how the emergence of phase transitions affects their feasibility in a radical way. 2 Statistical physics and phase transitions Contents 2.1 Basic notions of statistical physics 12 2.2 Ensemble of states 19 2.3 Phase transitions 23 2.4 Ising models 26 2.5 Mean ﬁeld theory 32 2.6 Quenched disorder and self-averaging 33 2.7 Replica method 37 2.8 Cavity method 39 2.9 Comments 42 2.1 Basic notions of statistical physics In order to make this book self-contained, some basic notions of statistical physics will be introduced in this chapter. In the main we have followed the approach of Landau and Lifshitz, to which the interested reader is referred, if he or she wants to go deeper into the subject (Landau and Lifshitz, 1976, 1980). In dynamics (Landau and Lifshitz, 1976), a central role is played by the notion of a point particle, which is a body with a ﬁnite mass m whose size can be neglected when describing its motion, so that it can be geometrically assimilatedPoint particle to a point. The position of a point particle is given by a vector ⃗r in the Cartesian 12 Basic notions of statistical physics 13 coordinate space (x, y, z), and its velocity is the time derivative of ⃗r: ⃗v = d⃗r dt . Let S be a closed dynamical system composed of N particles. In order to de- Degrees of freedom termine the conﬁguration of the system in Cartesian space, N vectors must be given, one for each component point. The number of independent values that together determine the system’s position is its number of degrees of free- dom, which in this case is 3N because each vector has three components (x, y, z). As Cartesian coordinates may not always be the best choice for describing the motion of a system, a set of s generalized coordinates {q1,q2,...,qs} is used instead. Generalized coordinates are any set of variables able to characterize Generalized coordinatesprecisely the position of a system at a given time. The number s is the number of degrees of freedom. However, knowledge of the coordinates qi (1 ⩽ i ⩽ s) is not sufﬁcient to predict the future conﬁgurations of the system S; for this, the generalized velocities ˙qi (1 ⩽ i ⩽ s) as functions of time must be known.1 This allows the accelerations of the system to be obtained; then, providing the values of the generalized coordinates and velocities at a given time determines the motions in the system for all future times. EXAMPLE In order to clarify the notion of generalized coordinates, let us consider the system shown in Figure 2.1. Clearly the conﬁguration of the whole system is completely determined if we know the value of xA (the position of A on the x axis) and the angle θ of the rod with respect to the vertical axis y.The values xA range in (−∞, ∞) whereas θ ranges in the interval [0, 2π). We can deﬁne two generalized coordinates, q1 = xA and q2 = θ.The relation between the Cartesian coordinates of A and B and the generalized coordinates is as follows: xA = q1,yA =0, xB = q1 + ℓ sin q2,yB = ℓ cos q2. Analogous relationships hold between the time derivatives: ˙xA =˙q1, ˙yA =0, ˙xB =˙q1 +(ℓ cos q2)˙q2, ˙yB =(−ℓ sin q2)˙q2. 1For simplicity we use q to denote the set {q1 ,q2 ,...,qs } and ˙q to denote the set { ˙q1 , ˙q2 ,..., ˙qs }. 14 Statistical physics and phase transitions O xA y OO m1 m2 x x B yB A B F2 FA Figure 2.1 A small body A of mass m1 moves along the horizontal x-axis. A point particle B of mass m2 is attached to A by a rigid rod of length ℓ and negligible mass, hinged at A. The relationships linking the accelerations to the positions and velocities areLagrangian function called equations of motion and can be obtained using the Lagrangian function L(q, ˙q, t) of the system, which, if the system is only subject to conservative ﬁelds, can be written as L(q, ˙q, t)= 1 2 s∑ i=1 s∑ j=1 ai,j(q)˙qi ˙qj − U (q). (2.1) In (2.1) the ﬁrst summation is quadratic in the velocity components and rep-Kinetic energy resents the kinetic energy K(q, ˙q) of the system. If Cartesian coordinates are used instead of generalized coordinates, this term becomes the better-known expression K(⃗v)= 1 2 N∑ k=1 mk| ⃗vk| 2, where | ⃗vk| is the modulus of the velocity of particle pk. The second term on the right-hand side of (2.1) captures the potential energy of the system, which (for conservative ﬁelds) is a function of position only. Using the Lagrangian function, the equations of motion for the system are as follows: d dt ∂ ∂ ˙qi L− ∂ ∂qi L =0 (1 ⩽ i ⩽ s). (2.2) The Euler–Lagrange equations (2.2) are a set of second-order differential equa-Lagrange equations tions whose general integral contains 2s constants. These constants can be deter- mined by providing the values of the coordinates and velocities at a given time, Basic notions of statistical physics 15 conventionally t0 =0. In addition we can deﬁne a coordinate conjugate to ˙qi: pi = ∂ ∂ ˙qi L. The quantity pi is called a generalized momentum. In Cartesian coordinates the Generalized momentum momentum of a point particle with respect to the ith coordinate, is simply pi = mivi. Another fundamental function describing the dynamics of a system is the Hamil- Hamiltonian tonian H, which represents the total energy. The Hamiltonian can be expressed as follows: H(q, p, t)= s∑ i=1 pi ˙qi −L, (2.3) which, using (2.1), becomes H(q, ˙q, t)= K(q, ˙q)+ U (q). (2.4) Moreover, using equations (2.3) it is possible to see that ∂ ∂t H =0 if ∂L/∂t =0.Inother word, H does not depend explicitly upon time if L does not. By integrating the equations of motion (2.2) for a closed system,2 it can be seen that even though the coordinates and the velocities change with time there are certain quantities, called the ﬁrst integrals of motion, which remain constant in time. The one in which we are mostly interested in this book is the energy, Energy which is the value assumed by the Hamiltonian function for a particular set of coordinate values. EXAMPLE Let us consider again the system depicted in Figure 2.1. Now suppose that the objects A and B, with masses m1 and m2, are subject to a conservative gravitational ﬁeld, which applies forces | ⃗F1| = m1g and | ⃗F2| = m2g to A and B, respectively. Moreover, A has a translational motion along the x-axis whereas B has a composite motion, a translation along x and a rotation around A. Using the two generalized coordinates q1 = xA and q2 = θ, we can write the Lagrangian of the system as follows: L(q, ˙q, t)= [ 1 2 (m1 + m2)˙q2 1 + 1 2 m2ℓ 2 ˙q2 2 ] + m2gℓ cos q2. 2By deﬁnition, a closed system is one that does not exchange energy or matter with any body not contained in the system itself. 16 Statistical physics and phase transitions The last term is the potential energy U (q). For a gravitational ﬁeld we have U (q)= −m1gyA − m2gyB = −m2gℓ cos q2. In order to obtain the above expression for the potential energy, we set the level of zero potential energy at y =0. Then the ﬁrst term in the middle expression disappears, and only the potential energy of B remains. (Notice that the y-axis points downward and so the minus sign is required in order that U (q) decreases from top to bottom.) The generalized momenta are then p1 = ∂ ∂ ˙q1 L =(m1 + m2)˙q1,p2 = ∂ ∂ ˙q2 L = m2ℓ 2 ˙q2. We can now write down an expression for the Hamiltonian: H(q, p, t)= p1 ˙q1 + p2 ˙q2 −L(q, ˙q, t) = [ 1 2 (m1 + m2)˙q2 1 + 1 2 m2ℓ 2 ˙q2 2 ] − m2gℓ cos q2. Finally, the two equations of motion are derived from (2.2): (m1 + m2)¨qi =0 → ¨qi =0, m2ℓ 2 ¨q2 + m2gℓ sin q2 =0 → ¨q2 = − g ℓ sin q2. If the system S is composed of only a small number of particles, the equa- tions of motion (2.2) can be solved, at least numerically (an exact solution in closed form is known only for N< 3). But, when the number of particles becomes very large (of the order of the Avogadro number NA =6.022 × 1023 mol−1), it is impossible to do so. Then the microscopic behavior of the sys- tem cannot be precisely captured, not even in numerical form. One might think, then, that the behavior of such a system must be so complex that it is impossible to describe. Actually there is a way out of this situation, because the sheer number of microscopic components, which hinders a deterministic solution of the equations of motion, lets laws of a different nature emerge, namely, statistical laws. TheseStatistical laws laws, even though not reducible to purely mechanical ones, allow the value and behavior of macroscopic quantities of the system to be described and predicted. The study of these laws is the subject of statistical mechanics or, more generally, statistical physics, in which the macroscopic behaviors of systems composed of a large number of particles are explained in terms of statistical ensembles. In order to understand how this can be done, let us introduce the notion ofPhase space phase space. The phase space of a system S is a 2s-dimensional space whose Basic notions of statistical physics 17 axes correspond to the s generalized coordinates qi and the s generalized mo- menta pi (rather than the generalized velocities). Each point in the phase space is associated with a state of the system S. As time progresses, the point rep- resenting the state of the system moves around in the phase space and thus its trajectory describes the time evolution of S. The fundamental observation underlying statistical physics is that, owing to the enormous complexity of the trajectories of the component particles, during a sufﬁciently long time interval T the system will ﬁnd itself a large number of times in every possible state. More precisely, let ΔqΔp be a small volume in the phase space corresponding to values of the q’s and the p’s situated in small intervals Δq and Δp with their origin in (q, p).Let Δt be the amount of time the system spends inside the volume ΔqΔp during T . Then, as T →∞, the ratio Δt/T becomes the probability that system S can be found, at a random instant, in the volume ΔqΔp: P(S is in ΔqΔp) = lim T →∞ Δt T . (2.5) Equation (2.5) was derived by following the system S in its evolution in time. Statistical distributionMore precisely, (2.5) is a consequence of the principle of equiprobability of the states reachable by a system with energy E. However, if we look at the volume ΔqΔp in the long term and accumulate the transits of the system into and out of that volume, we may consider each transit as a stationary copy of the system and rewrite the probability (2.5)interms of the “density” of occupied states within this volume. By letting the volume become inﬁnitesimal, so that the probability becomes inﬁnitesimal as well, we can write: dP = ρ(q, p)dqdp (2.6) The function ρ(q, p) is the probability density in the phase space and is called the statistical distribution function of the system under consideration. The function ρ(q, p) is normalized over the whole phase space. An interesting property of this distribution function is that it does not depend on the initial state of the system, provided that sufﬁcient time has passed to allow the system to transit multiple times to each possible state. The equivalence between the evolution in time of the single system S in Phase space averagephase space and the stationary distribution of the state density of “copies” of the same system has important consequences. Let f (q, p) be a physical quantity depending on q and p and hence implicitly on the time t. On the one hand, the mean value ¯f of f (q, p) can be computed as follows: ¯f = ∫ Ω f (q, p)ρ(q, p)dqdp, (2.7) 18 Statistical physics and phase transitions where the integral is taken over the whole phase space Ω. Averaging in this phaseTemporal average space avoids the necessity of following the evolution in time of the function f (t)= f (q(t),p(t)). On the other hand, equation (2.5) tells that the statistical mean (2.7) is equivalent to the temporal mean and hence ¯f = lim T →∞ 1 T ∫ T 0 f (t)dt. (2.8) Systems for which this equivalence holds are called ergodic. Ergodicity is still aErgodicity debated open problem in physics; its theoretical validity has been questioned but it is widely assumed to hold in practice because such an assumption gives good predictions. Equations (2.7)and (2.8) show that in statistical mechanics it is possible to make predictions, stochastic in nature, about the behavior of macroscopic bodies composed of many particles. This is the main difference from classicalStatistical mechanics makes it possible to predict the behavior of macroscopic bodies composed of many particles. mechanics, which produces deterministic, exact, predictions only for one- and two-body systems. We note that the stochastic character of the results from sta- tistical physics is not inherent in the nature of the systems considered (as it is in quantum mechanics) but derives from the fact that such results are obtained from an amount of data much smaller than that necessary to obtain a precise and complete mechanical description. However, when the statistical approach is applied to macroscopic bodies the stochastic character of the predictions is not apparent. In fact, after a long time, all physical quantities describing an isolated macroscopic body become constant and equal to their mean value. In other words, ﬂuctuations around the mean value are then negligible because the probability distribution for any quan- tity f will be strongly peaked around the mean. If this is the case, the body is said to be in thermodynamic equilibrium (or statistical equilibrium). The time necessary for an isolated system to reach thermodynamic equilibrium is the relaxation time. To understand this, let us consider a quantity f characterizing a macroscopic body and let ¯f be its mean value. The values of f oscillate aroundFluctuations ¯f , generating an instantaneous difference Δf = f − ¯f . The mean value Δf is not a good measure of ﬂuctuation, however, because it will be zero, being average of values that are sometimes positive and sometimes negative. A better measure is the square root of the quadratic difference √ (Δf )2. If f is additive, i.e., its value for a whole system is the sum of the values for the component parts, then an important consequence follows, namely √ (Δf )2 ¯f ∼ 1 √ N , (2.9) Ensemble of states 19 where N is the number of components of the system. From (2.9) it is easy to see why ﬂuctuations are not observed in a macroscopic body: their amplitude decreases with √N and hence tends to zero rapidly. Another fundamental quantity in statistical physics is the entropy S.The Entropy entropy of a system is deﬁned in terms of the number of states in which it can be. For a system with Ω distinct microscopic states, we have S = −kB ln Ω. (2.10) Here kB =8.617 343 × 10−5 eV/◦K is the Boltzman constant.The value Boltzman constant Ω(E, V, N ), which is a mechanical quantity, is a function of the energy E,the volume V , and the number of particles N of the system. The entropy of a sys- tem, which is a thermodynamic quantity, is linked to its disorder. Low values of entropy correspond to more ordered states (the probability of ﬁnding the system in a given state is concentrated in only a few states), whereas high values of en- tropy correspond to less ordered states (the probability of ﬁnding the system in a given state is distributed among many states). If external forces are applied to a system, they can produce work. According to mechanics, the work done is the sum of the scalar products of the forces and the corresponding displacements. Doing work on a body may set it in motion or change its volume. The work performed on a body (or received from it) can be expressed as the change in a new thermodynamic quantity, the free energy,which Free energy is a function of the state of the body. As the work given or obtained depends on the thermodynamical conditions of the process, the deﬁnition of the free energy is not unique. 2.2 Ensemble of states In order to make predictions and to compute interesting properties of many-body systems, it is necessary to introduce the notion of an ensemble of states. An ensemble is speciﬁed by a set of allowed states for the system and an associated probability distribution over the states. Three types of ensemble are used: the canonical, microcanonical, and grand canonical ensembles. 2.2.1 Microcanonical ensemble In an N -body system we call a microstate a complete description of every par- Microstate ticle in the system. In other words, each point in the system’s phase space cor- responds to a conﬁguration, i.e., for systems described by classical mechanics, Conﬁgurations a complete speciﬁcation of the position and velocity of each particle. In quan- tum mechanics, however, a microstate or conﬁguration would be speciﬁed by 20 Statistical physics and phase transitions the complete many-particle wavefunction. There is thus a one-to-one correspon- dence between points in the phase space and conﬁgurations. In the following we will consider only discrete conﬁgurations. Let Γ= {γ1,γ2,...,γn} be the set of such conﬁgurations. For an isolated system, in which neither energy nor matter is exchanged with the surroundings, Γ constitutes a microcanonical ensemble. Thus a microcanonical ensemble has constant energy. It is impossible to compute the microstates of a large system exactly. There- fore, different microstates that lead to the same values of macroscopic prop- erties such as the volume, temperature or energy are associated with a unique macrostate. It is then possible to imagine many copies of the system such thatMacrostate each copy is in a different conﬁguration but is described by the same macrostate. In order to derive the macroscopic properties of the system, a probability distribution must be associated with the microcanonical ensemble, i.e., with each conﬁguration (microstate). Thus, the thermodynamic properties of the system can be computed as averages over all copies in the ensemble. The fundamental assumption of thermodynamics is that each conﬁguration (microstate) occurs with the same probability. More precisely, in the microcanonical ensemble all copies of the system have the same number N of particles, the same volume V ,andthesameenergy E.If Ω is the number of microstates in the ensemble, the probability that a copy of the system, chosen at random, would be in a given conﬁguration γi is simply P(γi)= 1 Ω . (2.11) For some types of system, for instance for an ideal gas, it is possible to compute Ω in an approximate way. In a microcanonical ensemble the entropy S is given by expression (2.10). Consideration of (2.11) suggests that, for the microcanonical ensemble, Ω assumes the role played by the partition function in a canonical ensemble. For this reason, it is sometimes called the microcanonical partition function. 2.2.2 Canonical ensemble and Gibbs distribution In a canonical ensemble the number N of particles, the system volume V ,and the temperature T are constant, whereas there are no constraints on the particle momenta. In all states of the ensemble, all N particles lie within the volume V . The shape of the volume is unspeciﬁed, and it is not important as long as the volume is sufﬁciently large for surface phenomena to be ignored. The thermody-Canonical ensemble namic properties do not depend on the shape of V . If a system is in contact with a thermal bath (i.e., a body with very large thermal inertia, so that its temperature can be considered constant), the constant temperature T of the system does not Ensemble of states 21 affect the set of its allowed states, but enters into the calculations only through the probability of the states. The canonical ensemble describes such a closed system, in which matter cannot be exchanged with the environment, but energy is exchanged between the system and the thermal bath to keep the system’s temperature constant. The most useful thermodynamic function in this case is the Helmholtz free energy F (see (2.18)). The microstates si in a canonical ensemble have probabilities given Gibbs distribution by the Gibbs distribution: P(si)= 1 Z e −H (si )/kB T = 1 Z e −βH (si ), (2.12) where H(si) is the Hamiltonian of the system in microstate si, kB is Boltzmann’s constant, and T is the absolute temperature. Gibbs’ law (2.12)as- serts that the probability of occurrence of a microstate depends only on its en- ergy. The parameter β =1/kB T is known as the inverse temperature. The nor- malization constant Z is the partition function, whose value can be computed The symbol Z for the partition function probably derives from the term Zustatensummen, used by Boltzmann from Z = n∑ i=1 e −H (si )/kB T = n∑ i=1 e −βH (si ), (2.13) where n is the number of states in the ensemble. For the distribution (2.12) there are two limiting cases: • Inﬁnite temperature, T →∞ In this case all the conﬁgurations become equiprobable and the system is totally “disordered”, i.e., it does not show any internal structure (like a gas). • Zero temperature, T → 0 The probability is concentrated around the conﬁguration with minimum energy, called the ground state. Classically, the particles assume precise positions, such that the total force on them vanishes, and the system is in a totally ordered state (like a crystal). Starting from formula (2.13), the partition function Z can be written in a different Partition function way. The Hamiltonian function of the system assumes, in the n states, a ﬁnite set of m distinct values Ek; in fact, several states may have the same energy. Then, denoting by M (Ek) the number of states with energy Ek, we can write (2.13)as follows: Z = m∑ k=1 M (Ek)e −βEk . (2.14) The partition function, beyond its role as a normalization factor, has deep links with the thermodynamic quantities introduced in the previous subsection. First, 22 Statistical physics and phase transitions we consider the energy E. The mean value of E with respect to the Gibbs distri- bution, denoted by ⟨E⟩, can be computed as follows: ⟨E⟩ = m∑ k=1 EkM (Ek)e −βEk . (2.15) Notice that the average energy ⟨E⟩ depends on the temperature T , as does Z.Let us now consider the natural logarithm of Z, namely ln Z, and take its derivative w.r.t. β: − ∂ ∂β ln Z = − 1 Z m∑ k=1 M (Ek)e −βEk (−Ek)= − 1 Z Z⟨E⟩ = ⟨E⟩. (2.16) Analogously, the variance of E with respect to the Gibbs distribution is the sec- ond derivative of ln Z with respect to β. More generally, ln Z is the generatingln Z as a generating function function of the coefﬁcient M (Ek). Let us now go back to the notions of entropy and free energy. By using the Gibbs distribution and deﬁnition (2.10) we can compute the entropy S as follows: S = ⟨E⟩ T + kB ln Z. The second term on the right-hand side is related to the Helmoltz free energy F by F = −kB T ln Z, (2.17) and hence F = ⟨E⟩− TS. (2.18) In a canonical ensemble a system tends to minimize its free energy. From a thermodynamics point of view the entropy is minimal when the free energy is minimal. As a consequence, according to (2.18) there is a competition between the entropy and the mean energy. In fact, minimizing F implies (i) minimiz- ing the mean energy, which, in turns, decreases the entropy, and (ii) maximizing the entropy (owing to the minus sign), which, in turn, increases the mean energy. This trade-off between mean energy and entropy leads to a thermodynamic equi- librium. It may be noted that the mean energy is dominant at low temperatures, whereas the entropy is dominant at high temperatures. 2.2.3 Grand canonical ensemble The grand canonical ensemble is an extension of the canonical ensemble, in the sense that a system described by a grand canonical ensemble is in equilibrium with a thermal bath with which it can exchange both particles and energy; it is Phase transitions 23 said to be an open system. A grand canonical ensemble is useful when the num- ber of particles in a system cannot be determined easily: as this number is not known, the partition function of the grand canonical ensemble is evaluated as a weighted sum of partition functions of canonical ensembles with varying num- bers of particles. The relevant thermodynamic function is the thermodynamic potential Ω, also called the Landau potential.3 By denoting as Z(N, V, T ) the partition function of a canonical ensemble Partition function for grand canonical ensemble with the same V and T as a grand canonical ensemble and with N particles, the partition function of the grand canonical ensemble is deﬁned as follows: Z(z, V, T )= ∞∑ N =0 zN Z(N, V, T )= ∞∑ N =0 n∑ i=1 zN e −H (si )/kB T . (2.19) In equation (2.19), n is the number of microstates si and the parameter z is the fugacity, which represents the ease with which a new particle may be added to the system. 2.3 Phase transitions Systems whose behavior is governed by statistical physics laws frequently show emergent phenomena, absent in classical mechanics, such as the appearance of a phase transition. According to Martin et al. (2001), “From a statistical me- chanics perspective, a phase transition is nothing but the onset of non-trivial macroscopic (collective) behavior in a system composed of a large number of el- ements that follow simple microscopic laws”. More simply, Lee and Yang (1952) deﬁned a phase transition as a singularity in the partition function of a system (Blythe and Evans, 2003). If a system has a phase transition then it can be in one of several phases, depending on the values of certain control parameters. Each phase is characterized by a different microscopic organization. In order to introduce the notion of a phase transition, we must ﬁrst deﬁne the Phase transition notion of a phase. We have already introduced phase space. In this space, a phase is simply a region including all points corresponding to a homogeneous state of the system under analysis. As an example, let us consider again Figure 1.3 for a constant mass of water. At room temperature and normal pressure, water is liquid; this state may be represented by the point X1 in the ﬁgure. If the pressure is kept constant and the temperature is increased, it is a matter of everyday experience that the water will boil, when the temperature reaches 100 ◦C (the point X2 in the ﬁgure), and become vapor. During this transformation, liquid water and vapor Phase transitions in water 3Note that here the symbol Ω does not have the same meaning as in expression (2.10). 24 Statistical physics and phase transitions coexist; as long as there is still liquid water the temperature of the mixture re- mains constant even though heat is being supplied; when all the liquid water has become vapor, the temperature of the latter begins to rise again, if heat continues to be supplied. This type of transformation is said to be ﬁrst-order phase transition, as weFirst-order phase transition will see later on. From Figure 1.3 one may wonder what happens if the temper- ature and pressure are changed so as to maintain the mixed phases on the line from C to A. Point A is a “critical” point, at T = 374 ◦Cand P = 220 atm. When A is reached the system transforms into a single ﬂuid phase (Gitterman and Halpern, 2004). Point A is the end of the coexistence between the liquid and vapor phases, and a new type of transformation, namely a second-orderSecond-order phase transition phase transition occurs at that point. This type of phase transition is a continuous one. Similar reasoning applies to the transformation from ice to liquid water and vice versa.4 The ﬁrst classiﬁcation of phase transitions in matter was proposed by Paul Ehrenfest in 1933 (see for instance Jaeger, 1998), following the discov- ery, the year before, of the λ-transition in liquid helium by W. H. Keesom and coworkers (Keesom and van den Ende, 1932). Ehrenfest classiﬁed phase transi- tions in terms of the thermodynamic quantities that present a discontinuity. The order of the transition is the same as the order of the derivative of the free en- ergy that shows a discontinuity. New ﬁndings emerged in later decades. In order to accommodate some singularities that did not ﬁt into Ehrenfest’s scheme, this last was extended, most notably by A. Brian Pippard (1957). More recently, T. Matolcsi classiﬁed phase transitions into three classesTypes of phase transition (Matolcsi, 1996): zeroth-order, ﬁrst-order, and second-order. The order corre- sponds, as in Ehrenfest’s classiﬁcation, to the lowest-order derivative of the free energy that shows a singularity across the transition. • Zeroth-order phase transitions The occurrence of this type of transi- tion was predicted theoretically, and then experimentally veriﬁed, in the theory of superﬂuidity and superconductivity, where a discontinuity in the free energy itself was discovered. • First-order phase transitions In this type of transition the free energy is continuous but one of its ﬁrst derivatives shows a jump across the tran- sition. Usually a large amount of energy is exchanged between the two phases but the temperature remains constant (as in the case of, say, boiling 4The transition between ice and water is somewhat different from that between water and vapor because the former has no critical point. Moreover, at this transition a deep restructuring of the internal organization of the matter takes place, as on the microscopic level water has a spherical symmetry, owing to its random structure, that cannot be reached smoothly from the crystalline structure of ice. Phase transitions 25 water). First-order transitions are associated with mixed-phase regimes in which the two phases coexist. In such a phase transition some other quan- tity may diverge. As already mentioned, in a liquid–vapor transition the speciﬁc heat diverges, since, even though heat is supplied, the temperature does not increase. Often the two phases across a ﬁrst-order transition show different degrees of symmetry in their internal structure. For instance, the solid phase of water (ice) is much more symmetric than the liquid phase. The transition changes the symmetry of the internal structure. A transition from a more symmetrical phase to a less symmetrical one is said to be a symmetry-breaking process. • Second-order phase transitions In this type of transition the free en- ergy and its ﬁrst derivatives are continuous, but there is a discontinuity in a second-order derivative of the free energy. Moreover, there is no coex- istence of the phases at the transition point. Second-order transitions may be symmetry-breaking. A phenomenological theory of second-order phase transitions was presented by Landau (Landau and Lifshitz, 1980). In modern statistical physics another type of phase transition is also considered, as follows. • Inﬁnite-order phase transitions These transitions involve no discon- tinuities and break no symmetries. There are examples of this kind of transition in quantum mechanics, for instance in two-dimensional electron gases. Phase transitions are far from being limited to physical systems; on the con- Importance of studying phase transitions trary, they are an ubiquitous phenomenon, occurring in many domains including the computational, social, and biological systems. Phase transitions are strongly linked to the fundamental properties of many-body systems, and this is one rea- son to investigate them. Moreover the critical phenomena that occur at the tran- sition may elucidate the very nature of the system under study. Finally, the study of phase transitions may provide answers to questions about the way in which long-range ensemble phenomena arise from local interactions. An important observation is that a phase transition is an asymptotic phe- nomenon, i.e., it emerges when the size of the system under analysis goes to inﬁnity. Strictly speaking, a ﬁnite system cannot have a phase transition. The reason is that, when the partition function Z is a sum of a ﬁnite number of terms (see expression (2.13)), Z itself, as well as the other thermodynamic functions, are analytic functions of the inverse temperature β and so do not have singulari- ties at a ﬁnite temperature. Thus, the emergence of singularities in the free energy or one of its derivatives occurs when the size of the system goes to inﬁnity, in the so-called thermodynamic limit. 26 Statistical physics and phase transitions In the study of phase transitions a relevant notion is that of the order pa-Order parameter rameter. Order parameters were deﬁned by Landau (Landau and Lifshitz, 1980) and are a measure of the “order” of the system’s state. More precisely, Landau introduced a new variable, in the expression for the free energy, which is 0 in the “disordered” phase and different from 0 in the ordered phase. The reason for the introduction of such a parameter was that in the vicinity of the phase transition (where the parameter is small) the free energy could be expanded in a Taylor se- ries. The determination of the order parameters in a phase transition is somewhat a matter of art. While the order parameter is a function that describes the changes under- going in a phase transition, a control parameter is an external variable whoseControl parameter values determine the location of the critical point. The relevance of the control parameter is that small changes in its value cause large-scale qualitative changes in the state of the system. For instance, in the liquid–vapor transition, the den- sity is an order parameter, whereas the control parameters are temperature and pressure. 2.4 Ising models In order to illustrate the notions introduced so far, in this section we will describe the well-known Ising model (Ising, 1925), which was proposed to describe mag- netization and was used in early studies on phase transitions in learning. Both Cipra (1987) and Gitterman and Halpern (2004) present a simple introduction to the mathematics of the Ising model. It may have dimension d ⩾ 1.TheHistory of the Ising model one-dimensional (1D) model was solved exactly by Ising in his doctoral the- sis (Ising, 1925); it does not show a phase transition for any temperature strictly greater than 0 (Gitterman and Halpern, 2004). Probably this negative result dis- suaded Ising from further study of the model. A decade later, in 1936, interest was raised again by the proof, offered by Rudolf Peierls (1936), that the two- dimensional (2D) Ising model was indeed guaranteed to have a phase transition for some temperature. Later on, Hendrick Kramers and Gregory Wannier (1941) located exactly the phase transition in the 2D model. But it was only later on that Lars Onsager (1944) provided a complete solution of the 2D Ising model in the absence of an external magnetic ﬁeld. The three-dimensional (3D) model is yet unsolved, as well as the 2D model with a non-zero external ﬁeld, but many partial results are available. In the Ising model it is assumed that a number N of particles (originally, magnetic dipoles) are located on the nodes of a lattice in d dimensions, with d =1, 2, 3. Each particle has a spin that can be in one of two states, σi = ±1 Ising models 27 (corresponding to spin up or spin down). The particles interact with each other Interaction between spinsin pairs, according to a speciﬁed pattern. If two particles interact, the nodes cor- responding to them are connected by an arc, called a bond. In particular there may exist short-range interactions, between pairs of nearest neighbor particles, or long-range interactions, involving particles that can be far apart. The range of If the lattice is ﬁnite, particles at the borders have fewer bonds than those in the middle the interactions determines the macroscopic behavior of the ensemble of parti- cles. In a lattice with interactions between pairs of nearest neighbors only, each particle has 2d bonds. Let Z be the partition function of the spin system. The main quantity to be calculated, from which all the interesting behaviors of the system can be derived, is the free energy per site, f = F/N , in the thermodynamic limit: f = − lim N →∞ kB T N ln Z. (2.20) The main problem in the Ising model is to ﬁnd a closed-form, analytic, expres- sion for the function f . Notice that, in principle, the limit in (2.20) may not exist. Given two spins σi and σj ,let Jij be a coefﬁcient determining the strength of their interaction. The parameter Jij is called the coupling. The potential energy of the interaction is given by Eij = −Jijσiσj . The total energy of the system is the sum of the Eij over all pairs of spins: E = − 1 2 N∑ i=1 N∑ j=1 Jijσiσj . In the energy expression, Jii =0 for 1 ⩽ i ⩽ N , and the factor 1/2 derives from the fact that each term is counted twice. 2.4.1 One-dimensional Ising model For the sake of simplicity, let us start with the 1D Ising model, in which N spins are arranged in a linear lattice. Let us assume that only adjacent spins interact and that the strength of the interaction, J, is constant for all pairs. Moreover, we assume that there is no external magnetic ﬁeld. The total energy of the system Energy of 1D Ising modelcan be computed as: E(σ1,...,σN )= − N −1∑ 1=1 Jσiσi+1. (2.21) Sometimes, in order to remove the end effects of a ﬁnite-length line of spins, an artiﬁcial bond between the last and the ﬁrst spin is introduced. In this way, the 28 Statistical physics and phase transitions spins form a ring. The energy reaches its minimum value, E0 = −J(N − 1), when all the spins point in the same direction. Using (2.13), the partition function of a system with N spins can be written as ZN = ∑ σ1 =±1 ∑ σ2 =±1 ··· ∑ σN =±1 exp [ − J kB T (σ1σ2 + ··· + σN −1σN )]. (2.22) In order to calculate Z we suppose that another spin σN +1, is added at the end of the chain and compute the new partition function, ZN +1, which can be related to ZN as follows: ZN +1 = ∑ σ1 =±1 ∑ σ2 =±1 ··· ∑ σN +1 =±1 exp [ − J kB T (σ1σ2 + ··· + σN −1σN )] × exp ( − J kB T σN σN +1 ) . By rewriting the preceding expression and setting σN +1 equalﬁrstto 1 and then to −1, we obtain ZN +1 = ∑ σ1 =±1 ∑ σ2 =±1 ... ∑ σN =±1 exp [− J kB T (σ1σ2 + ··· + σN −1σN )] × exp ( J kB T σN ) + ∑ σ1 =±1 ∑ σ2 =±1 ... ∑ σN =±1 exp [ J kB T (σ1σ2 + ··· + σN −1σN )] × exp ( − J kB T σN ) . When σN assumes the values +1 and −1, the two factors eJσN /kB T and e−JσN /kB T interchange, so their sum can be factorized: ZN +1 = ZN 2 cosh ( J kB T ) . (2.23) As the system cannot have just one spin (since then there would be no interac- tion), we will compute Z for N =2: Z2 = ∑ σ1 =±1 ∑ σ2 =±1 exp (− J kB T σ1σ2 ) = 2 exp ( J kB T ) + 2 exp (− J kB T ) = 4 cosh ( J kB T ) . Ising models 29 By induction, using Z2 as the base step and expression (2.23) as the recursive step, we ﬁnally obtain Partition function of 1D Ising modelZ = ZN =2 N ( cosh J kB T )N −1 . (2.24) Then the free energy F can be written as follows: F = −kB T ln Z = −kB T [N ln 2 + (N − 1) ln cosh ( J kB T )] . As N ≫ 1, we can approximately equate N and N − 1, obtaining ﬁnally: F = −kB T ln Z = −kB NT ln ( 2 cosh J kB T ) . (2.25) The free energy per site f is Free energy per site f = −kB T ln (2 cosh J kB T ) . (2.26) As f is an analytic function, it cannot exhibit a phase transition for any ﬁnite value of T , except T =0. 2.4.2 Two-dimensional Ising model In order to analyse the 2D Ising model, we will consider a square lattice, at each node (site) of which a spin is located, as in Figure 2.2. We assume that each spin interacts only with its four nearest neighbors (top, bottom, left, right), and that there is no external magnetic ﬁeld. Again, the strength of the interaction is Energy of the 2D Ising model constant and equal to J. Then the energy of the spin located at a point (i, j) will be E(i, j)= −Jσi,j(σi−1,j + σi+1,j + σi,j−1 + σi,j+1). (2.27) To obtain the total energy E we have to sum over all sites of the N × N grid: E = −J ∑ i̸=j E(i, j)= −J ∑ i̸=j σi,j (σi−1,j + σi+1,j + σi,j−1 + σi,j+1) = −J N∑ i=2 N∑ j=1,j̸=i σi,j σi−1,j − J N −1∑ i=1 N∑ j=1,j̸=i σi,j σi+1,j −J N∑ i=1 N∑ j=2,j̸=i σi,j σi,j−1 − J N∑ i=1 N −1∑ j=1,j̸=i σi,j σi,j+1. 30 Statistical physics and phase transitions j Figure 2.2 Square lattice of size N . A spin is located at each of the N 2 sites. Each spin can take two values (up, +1, and down, −1) and interacts only with its four nearest neighbors (except for the spins at the edges of the lattice). As in the 1D Ising model, the four sums may take into account the border effects. Using the expression for the energy, after rather long computations the partition function and the free energy F can be obtained. At all temperatures T the sta- ble state of the system corresponds to the minimum of F .When T is low, the energy predominates and F ’s minima correspond to ordered states. When T is high, the entropy dominates and the minima of F correspond to the minima of S and, hence, to disordered states. At some intermediate temperature Tcr the twoCritical value of the temperature effects balance each other; Tcr is the temperature of a critical point correspond- ingtoa phase transition. Onsager (1944) was able to compute the value of Tcr exactly: Tcr = 2J kB ln(1 + √ 2) . (2.28) Following an argument put forwad by Svrakic (1980) and further elaborated by Gitterman and Halpern (2004), the value given by (2.28) can be derived. To this end let us consider a cell with four sites, as represented in Fig- ure 2.3. As each site may have up or down spin, there are 16 possible con- ﬁgurations of the cell, whose energy can be easily computed assuming that there are only nearest neighbor interactions and that all interactions have strength J: E = −J(σ1 σ2 + σ2σ3 + σ3σ4 + σ4σ1). Ising models 31 444 4 Figure 2.3 Qualitative argument allowing the value of the critical temperature Tcr to be computed. There are four spins, connected as described, and hence 16 possible conﬁgurations. For the conﬁgurations γ1 =(σ1 =1,σ2 =1,σ3 = 1,σ4 =1) and γ2 =(σ1 = −1,σ2 = −1,σ3 = −1,σ4 = −1) the energy equals −4J, whereas for the conﬁgurations γ3 =(σ1 =1,σ2 = −1,σ3 =1,σ4 = −1) and γ4 =(σ1 = −1,σ2 =1,σ3 = −1,σ4 =1) the energy equals 4J.Inthe other 12 conﬁgurations the energy equals zero. Among these conﬁgurations, four correspond to “ordered” states, two with en- ergy 4J, and two with energy −4J, whereas 12 are “disordered”, with energy equal to 0. For “ordered” states, it is possible to build an isotropic inﬁnite 2D Ising lattice by repeatedly placing the basic patterns one adjacent to the other in both directions, whereas this is not possible with “disordered” states. Assum- ing that ordered and disordered states compete, it is possible to conjecture that the phase transition will occur when the partition function of the ordered state, namely Zord = 2 exp ( 4J kB T ) + 2 exp (− 4J kB T ) , is equal to that of the disordered state: Zdis =12. By deﬁning x = exp ( 4J kB T ), we obtain the equation x + x −1 =6, whose solutions are x =3 ± 2√2.Bytaking x =3 + 2 √ 2, it must follow that exp ( 4J kB T ) =3 + 2√ 2=⇒ 4J kB T = ln(3 + 2 √ 2). Finally, the critical temperature is Tcr = 4J kB ln(3 + 2 √ 2) . (2.29) 32 Statistical physics and phase transitions Expression (2.29) is equal to the value (2.28) computed by Onsager: equating the two expressions we obtain 2J kB ln(1 + √ 2) = 4J kB ln(3 + 2√ 2) =⇒ ln(1 + √ 2) = 1 2 ln(3 + 2 √ 2) =⇒ 1+ √ 2= √(3 + √ 8) = √ 3+ √9 − 1 2 + √ 3 − √ 9 − 1 2 =1 + √2. Unfortunately this argument does not work for the 3D Ising model. Gitterman and Halpern, however, introduced a modiﬁed criterion to ﬁnd Tcr in the 3D model using an argument involving a single cubic cell. In this way they found an estimate of the critical temperature, Tcr =4.277 J/kB , that is close to the numerical result Tcr =4.511 J/kB found by Binder and Luijten (2001)using Monte Carlo simulations. 2.5 Mean ﬁeld theory Computing the behavior of a system of many interacting particles (an N -body system) is a problem that is difﬁcult to solve except in very simple cases. The pattern of interaction makes the evaluation of the partition function a hard com- binatorial task, owing to the need to sum over all the states of the system. A possible way out of the difﬁculty is to use a mean ﬁeld approach. The basic idea is to replace the N -body system, with all its interactions, by a one-body sys- tem immersed in an appropriate external ﬁeld. In this way an approximate, but feasible, solution can be obtained. The external ﬁeld replaces the interaction of all the other particles, for an arbitrary particle. In this way some insight into the behavior of the system can be obtained at a relatively low cost. The central idea of mean ﬁeld theory (MFT) is to neglect the ﬂuctuations ofMean ﬁeld theory microscopic quantities around their average. For example, let us consider a set of N spins σi, in the absence of an external ﬁeld, and let B be the set of bondsNo external ﬁeld between the spins. Moreover, let |B| = NB . Each spin value can be written as the sum of its average m (over all the spins) and a ﬂuctuation δσi = σi − m around the average: σi = m + δσi, m = 1 N N∑ i=1 σi. Quenched disorder and self-averaging 33 In MFT it is assumed that the second-order term in the ﬂuctuation is negligible Hamiltonian in the computation of the Hamiltonian: H = −J ∑ (ij)∈B σiσj = −J ∑ (ij)∈B(m + δσi)(m + δσj ) = −J ∑ (ij)∈B[m 2 + m(δσi + δσj )+ δσiδσj ] ≃−Jm 2NB − Jm ∑ (ij)∈B(δσi + δσj ). In order to compute the last sum we notice that each bond occurs just once in The number of bonds per site is z. the sum and that each deviation occurs as many times as the number of bonds connected to each site. If z is the number of bonds per site then H = −Jm 2NB − Jmz N∑ i=1 δσi = Jm 2NB − Jmz N∑ i=1 σi. (2.30) In equation (2.30) the parameter z has been assumed to be independent of the site; then NB = zN/2. The interactions between the spins are embedded in the average m. The MFT can be considered as a zeroth-order expansion of the Hamiltonian in terms of the ﬂuctuations. Starting from it, the analysis of ﬁrst- and second-order approximations can be investigated. The approximate Hamiltonian allows other physical quantities to be com- Approximate partition functionputed more easily. For instance, the partition function can be expressed as Z = N∑ i=1 exp [ β ( Jm 2NB − Jmz N∑ i=1 σi )] = exp (−βNB Jm 2) [2 cosh(βJmz)] N . (2.31) An important point in MFT is to estimate whether a mean ﬁeld approach is a good approximation for any particular problem. From the statistical perspec- tive, a system with many interactions is a good candidate for an appropriate approximation. 2.6 Quenched disorder and self-averaging In the previous sections we considered systems whose parameters were given, as, A “quench” refers to a rapid cooling. In metallurgy, such a process is commonly used to harden steel. for instance, the coupling J of the spin interaction in equation (2.21). We will now consider the case in which the system’s parameters, even though constant in time, are random variables whose values follow a known probability distribution. In this case the system is said to exibit quenched disorder. The term “quenched”, here meaning “frozen”, refers to the invariance of the parameters with respect to time. 34 Statistical physics and phase transitions Clearly, the introduction of a further probabilistic aspect in a system makes the mathematical analysis of its behavior and properties much more complex than in the purely deterministic case. In the presence of quenched disorder theIn the presence of quenched disorder the system’s parameters are stochastic variables. structure of the system becomes random, and the weights in the partition func- tion are themselves random variables (Martin et al., 2001). Now the partition function and the other physical quantities depend on two types of randomness, a thermal randomness, whose distribution could be, for instance, the Gibbs dis- tribution, and a structural randomness, whose distribution we will denote by ρ. When computing thermal average values, we keep the quenched variables ﬁxed and then average the results with respect to ρ. In order to distinguish these two averages, we will use angle brackets to indicate a thermal average and an overbar to denote an average over the quenched random variables. EXAMPLE Following Martin et al. (2001),wewill consider,asanexample,asystem of two spins σ1 and σ2, with energy E(J)= −Jσ1σ2. The system can be in one of four states {s1,s2,s3,s4},where s1 = {σ1 =1,σ2 =1},s2 = {σ1 =1,σ2 = −1}, s3 = {σ1 = −1,σ2 =1},s4 = {σ1 = −1,σ2 = −1}. Correspondingly, the energy assumes the values E(J, s1)= −J, E(J, s2)= J, E(J, s3)= J, E(J, s4)= −J. Then, according to formula (2.13), the partition function can be computed as follows: Z(J)=2 exp ( J kB T ) +2 exp (− J kB T ) = 4 cosh ( J kB T ) . Setting β =1/kB T as usual, we deduce from (2.16)that ⟨E(J)⟩ = − ∂ ∂β ln Z = −J tanh βJ. Let us assume that the coupling J is a random variable that can take on two values {J0,J1} according to a probability distribution ρ(J) such that ρ(J0)= ρ0 and ρ(J1)=1 − ρ0. By averaging the thermal average energy with respect to J,weobtain ⟨E⟩ = −ρ0J0 tanh βJ0 − (1 − ρ0)J1 tanh βJ1. If we assume that J0 = −1, J1 =1,and ρ0 =1/2, we ﬁnally obtain ⟨E⟩ = − tanh β. Quenched disorder and self-averaging 35 In order to analyze quenched disorder it is useful to introduce the notion of Frustration frustration. Considering again a system of spins, let us suppose that the coupling may assume both positive and negative values. In this case the minimum of the energy is not reached when all spins point in the same direction, and “conﬂicts” between different conﬁgurations arise; the system is said to be “frustrated”. EXAMPLE Let us consider a set of N spins, located at the vertices of a complete graph (a graph in which every pair of vertices is connected by a unique edge), and let {Jij } be the set of couplings, which can assume both positive and negative values. The Jij are independent random variables following a known probability distribution. This model is the famous Sherrington– Kirkpatrick (SK) model (Sherrington and Kirkpatrick, 1975), which is a stochastic version of Ising’s model. The SK model has energy ESK = − 1 √N N −1∑ i=1 N∑ j =i+1 Jij σiσj . Owing to the conﬂicts in ESK arising from the presence of both positive and negative terms, to ﬁnd the ground state energy for arbitrary Jij is an NP-complete problem (Cipra, 2000). Because of the mathematical complexity of handling quenched disorder, ap- proximate methods such as the replica method (M´ezard and Parisi, 1991)and the cavity method (M´ezard and Parisi, 1985) have been developed. These methods provide results that are very often in agreement with experiment, but they have not been proved exact in general; they will be illustrated brieﬂy in the following subsections. We have seen that in the SK model the Ising model was extended in two ways: on the one hand by introducing quenched disorder and on the other by changing the geometry of the underlying interaction topology, so that, rather than being on a regular lattice, the spins are located at the vertices of a com- plete graph. It is not surprising, then, that other topologies have been investi- gated. For instance, instead of a complete graph one may think of using a graph which is random in respect of the number of edges (Hartmann and Weigt, 2005; Barr´e et al., 2009). The topology of the structure is important because it may af- fect the behavior of the system, in particular the presence and location of phase transitions. Along the same line, other topologies have been investigated. For instance, Small-world network.Jeong et al. (2003) studied the Ising model on a small-world network (Watts and 36 Statistical physics and phase transitions Strogatz, 1998). They assumed an interaction of the type Jij = Jji = { Jr−α ij if i and j are connected, 0 otherwise, where r is the Euclidean distance between two nodes. The authors found that, for an interaction ∝ r−α, there is no phase transition for any non-zero positive value of α. More recently, Brunson and Boettcher (2009) studied the Ising model on a new network, with small-world properties, that can be studied exactly using the renormalization group. The network is non-planar and has a recursive design that combines a one-dimensional backbone with a hierarchy of long-range bonds. By varying the relative strength of nearest-neighbor and long-range bonds, the authors were able to deﬁned a one-parameter family of models that exhibits a rich variety of critical phenomena quite distinct from those on lattice models. Finally, systems of spins on scale-free networks (Barab´asi and Bonabeau,Scale-free network 2003) have also been investigated. For instance, Herrero (2009) studied uncorre- lated networks using Monte Carlo simulation (Durrett, 2007). 2.6.1 Self-averaging quantities Even though physical quantities depending on quenched parameters are difﬁcult to compute, their behavior in the thermodynamic limit (N →∞)may show the important self-averaging property. In other words, as the size N of the system increases, such a quantity shows a decreasing amplitude of ﬂuctuation around its mean, so that its values become highly concentrated around the mean. More pre- cisely, in the thermodynamic limit the value of a self-averaging quantity is equalSelf-averaging quantity to its mean with probability 1. Typical examples of self-averaging quantities are the free energy, the entropy, and the magnetization; the partition function itself is generally not self-averaging. The importance of self-averaging is that in the case of large systems it is not necessary to compute the whole distribution of values for self-averaging quan- tities; the mean is sufﬁcient. In fact, self-averaging quantities do not depend on the particular type of quenched disorder exhibited by the system, but only on theFree energy density statistical properties of their distribution. In formal terms we can write, for the free energy density, f = − 1 β lim N →∞ 1 N ln Z(J). (2.32) Expression (2.32) indicates that it is possible to ﬁrst calculate the disorder aver- age for systems of ﬁnite size and then take the thermodynamic limit. The self- averaging property is restricted to intensive quantities, i.e., to quantities whose Replica method 37 value does not depend on the amount of substance for which they are computed. For instance, the density of an object is an intensive quantity whereas its mass is an extensive quantity since it is proportional to the amount of substance. 2.7 Replica method The replica approach is a heuristic procedure used to simplify the hard computa- tion involved in obtaining the value of the partition function and other thermody- namical quantities in the presence of quenched disorder. The method is reported to have been ﬁrst proposed by M. Kac in a seminar in the 1950s (Kac and Ward, Kac’s proposal 1952), but its formalization was worked out by M´ezard and Parisi (M´ezard et al., 1987; M´ezard and Parisi, 1991). For exempliﬁcation purposes, let us consider a system composed of N spins and let a set J of couplings represent its quenched disorder. Let Z(J) be the partition function. The replica method starts from the equality ln Z(J) = lim r→0 Z(J)r − 1 r , (2.33) which holds in a composite system formed by r identical and independent repli- cas of the system under consideration; in (2.33) an overbar denotes an average over the replicas. Expression (2.33) derives from the expansion Z(J)r =1 + r ln Z(J)+ O(r2), (2.34) valid for any set of couplings J and small r. Remembering that the logarithm of the partition function is linked to the free energy by F (J)= −kB T ln Z(J),we obtain ln Z(J)= −F (J)/kB T . Inserting this expression into (2.34) we obtain: Z(J)r =1 − r F (J) kB T + O(r2). By taking the average over J, ignoring the term O(r2), letting r go to 0,and using (2.33) we ﬁnally obtain F (J)= −kB T lim r→0 ( Z(J)r − 1 r ) . (2.35) The intuition behind the preceding derivation can be explained as follows. Let us suppose that we have not one, but r replicas of the same system, all with the same quenched disorder. We have now to compute Z(J)r. Then, we apply the replica trick, i.e., we can compute the partition function of the composite system Replica trick 38 Statistical physics and phase transitions as the product of the partition functions of the components: Z(J)r = Z(J)Z(J)Z(J) ··· Z(J) = ⎛ ⎝∑ {σ1 i } exp [ −βH ({σ1 i })]⎞ ⎠ ... ⎛ ⎝∑ {σr i } exp [−βH ({σr i })] ⎞ ⎠ = ∑ {σa i }a=1,...,r exp ( −β r∑ a=1 H({σa i }) ) = ∑ {σa i } exp ⎛ ⎝β ∑ i<j Jij r∑ a=1 σa i σa j ⎞ ⎠ . If we restrict ourselves to integer r,the rth moment of the partition function Z can be rewritten as Z(J)r = ( ∑ γ∈Γ e − 1 T E(γ,J ))r = ∑ γ (1 ) ,...,γ (r ) ∈Γr e − 1 T ∑r a =1 E(γ (a ) ,J ), (2.36) where Γ is the conﬁguration set. The idea is that the randomness of the couplings disappears once the averaging process has been carried out. Considering the r replicas as a composite system, this last contains N vectors ⃗σj of spins, one for each original site. Thus each vector has r components, each corresponding to a replica of the spin at that site: ⃗σj = { σ(1) j ,...,σ(r) j } (1 ⩽ j ⩽ N ). We can now compute the partition function for the composite system of N vec- torial spins using the non-random energy function E( ⃗σj )= −kB T ln exp [ − 1 T r∑ a=1 E (γ(a) j ,J) ] , (2.37) where γj is the conﬁguration that corresponds to the spin vector ⃗σj . The new partition function can be estimated analytically, in some cases, byAnalytic continuation means of the saddle-point method. The idea is to compute the right-hand side of (2.35) and take the limit for r → 0 by using analytic continuation. The prob- lem is that the analytic continuation is not unique and a heuristic hypothesis, an ansatz, on the mathematical structure is needed. To solve the problem, Parisi proposed a complete and internally consistent ansatz scheme, called replica sym-Replica symmetry ansatz metry (M´ezard and Parisi, 1985). This ansatz, although very useful in particular applications, has not yet been proven to be correct in general. Cavity method 39 Recently, W¨astlund proved the soundness of the replica symmetry ansatz for the minimum-matching and traveling-salesman problems in the pseudo- dimension-d mean ﬁeld model for d ⩾ 1 (W¨astlund, 2009). Also, Krzcakala used this ansatz in the problem of graph coloring with q colors and argued that in this case the ansatz gives exact threshold values between the colorable and uncolorable phases (Krzcakala, 2005). 2.8 Cavity method The cavity method was proposed by M´ezard, Parisi, and Virasoro in 1985 as a tool for solving mean ﬁeld models that was particularly well suited to handling disordered systems (M´ezard and Parisi, 1985). Even though it was designed with the Sherrington–Kirkpatrick model of spin glasses (Sherrington and Kirkpatrick, 1975) in mind, the method has proved to be applicable to a wide range of prob- lems. In particular, the method has been used in computer science problems, notably k-SAT (see for instance Mertens et al., 2006) and graph coloring (see for instance Krzcakala, 2005; Mulet et al., 2002). Even though the cavity ap- proach is in principle equivalent to the replica method, the former has a more intuitive interpretation and is easier to apply, so that it is often preferred. In order to explain how the method works, let us consider a particular system of Ising spins, deﬁned on a Bethe lattice (Bethe, 1935). A Bethe lattice is a Bethe lattice random graph with N vertices and ﬁxed connectivity equal to k +1, i.e., it is a graph in which there are k +1 incoming edges at each site. Spins are located at the vertices of the graph and interact with neighboring spins only. In such a spin system disorder is due to the presence of loops (see Figure 2.4) and thus occurs only on large scales. The local structure around each site is tree-like. As usual, the Hamiltonian is deﬁned as H(J)= − ∑ i<j Ji,jσiσj , where the Jij are independent identically distributed random variables with prob- ability distribution ρ(J). Our goal is to ﬁnd the value of the energy density u of the ground state in the thermodynamic limit, N →∞. More precisely, we want Ground state energy densityto compute the ground state energy, averaged both over the distribution of ran- dom graphs and the values of the couplings. This energy is denoted by E(N ) 0 .We want to compute: u = lim N →∞ E(N ) 0 N . The cavity method works iteratively on a spin model with N spins, deﬁned on a slightly different graph G(N, q), which is derived from the Bethe lattice and 40 Statistical physics and phase transitions (a) (b) 12 3 45 6 Figure 2.4 (a) Example of a part of a Bethe lattice with k =2 and N vertices. Each vertex has exactly k +1 = 3 bonds. (b) The cavity graph G(N, 6) obtained from the Bethe lattice in (a). Here q =6 and the removed bonds are such that six spins have now exactly two bonds. Notice that the sites with a bond removed are randomly selected. In the ﬁgure they have been drawn as adjacent for the sake of simplicity. called a cavity graph. A cavity graph is obtained by removing some bonds fromCavity graph the original graph, in such a way that q randomly chosen “cavity” spins have only k neighbors while the other N − q spins all have k +1 neighbors, as illustrated in Figure 2.4. Each removed bond generates a “cavity” in the original graph. The cavity spins have ﬁxed values σ1,...,σq. The global ground state energy of the corresponding spin model depends on the values of these cavity spins. The basic operations that one can perform on cavity graphs (illustrated in Figure 2.5)are the following. • Iteration This operation consists in adding a new spin σ0 of ﬁxed value to the cavity, and connecting it to k of the cavity spins, say σ1,...,σk. Thus the graph G(N, q) becomes G(N +1,q − k +1). The increments in the number of vertices and in q are as follows: δN =1,δq = −k +1. • Link addition This operation consists in adding a new link between two randomly chosen cavity spins σ1,σ2. The graph G(N, q) becomes G(N, q − 2). The increments in the number of vertices and in q are as follows: δN =0,δq = −2. Cavity method 41 (a) (c) 0 2 1 (b) Figure 2.5 (a) Iteration. A new spin σ0 is added and connected to k =2 ran- domly chosen cavity spins. (b) Link addition. A new bond is added between two randomly chosen cavity spins σ1 and σ2. (c) Site addition. A new spin σ0 is added and connected to k +1 = 3 randomly chosen cavity spins. • Site addition This operation consists in adding a new spin σ0 to the cavity and connecting it to k +1 of the cavity spins, say σ1,...,σk+1. The graph G(N, q) now becomes G(N +1,q − k − 1). The increments in the number of vertices and in q are as follows: δN =1,δq = −k − 1. Now, if in a cavity graph G(N, 2(k + 1)) a number k +1 of link additions are performed then a G(N, 0) graph is obtained; G(N, 0) is nothing other than the original spin glass problem with N spins. As an alternative, starting from the same cavity graph G(N, 2(k + 1)) and performing two site additions, a G(N + 2, 0) graph is obtained, which is the original spin glass problem with N +2 spins. We can express the difference E(N +2) 0 − E(N ) 0 in the ground state energies in going from N to N +2 in terms of the difference in energy due to a site 42 Statistical physics and phase transitions addition ΔEs and the difference in energy due to a link addition ΔEℓ: E(N +2) 0 − E(N ) 0 =2ΔEs − (k +1) ΔEℓ. (2.38) As the energy is an extensive quantity its asymptotic behavior is linear in N ,so that u = lim N →∞ E(N ) 0 N = E(N +2) 0 − E(N ) 0 2 =ΔEs − k +1 2 ΔEℓ. (2.39) If k +1 is even, the fraction (k +1)/2 is an integer. Then, formula (2.39) tells us that in order to increase N by 1 it is necessary to remove (k +1)/2 links and then add one site. Notice that the energy required to remove a link is the opposite of the energy required to add a link. 2.9 Comments Even though the content of this chapter looks quite far from the main theme of this book, the methods outlined in it have strong connections with compu- tational issues, especially with the solving of hard combinatorial problems in general and with machine learning in particular. Over a long period, connec- tions between these ﬁelds have been occasionally established and have brought innovative solutions and deep insights into the basic computational aspects of problem solving. This reason, and also the suggestion coming from statistical physics approaches of new, very effective, algorithms, has encouraged computer scientists to look more and more frequently for analogies and parallels with phys- ical systems. In subsequent chapters, several instances of such connections, not only with computer science but also with other domains such as the social and cognitive sciences, will be presented. From the practical point of view, for a computer scientist wanting to use the approaches mentioned in this chapter it is not necessary to become deeply acquainted with statistical physics; some basic notions, complemented by the mathematical tools sketched in this chapter, will be sufﬁcient to apply these ap- proaches fruitfully. Useful introductory books include Percus et al. (2006)and Hartmann and Weigt (2005). 3 The satisﬁability problem Contents 3.1 General framework 43 3.2 Random graphs 45 3.3 The SAT problem 49 3.4 The random (2 + p)-SAT 62 3.5 Solving the SAT problem 63 3.6 Comments 68 3.1 General framework Surprising as it may be, the emergence of phase transitions is not limited to phys- ical systems: it seems to be a rather ubiquitous phenomenon, existing in biology, genetics, neural networks, complex systems, and also in combinatorial problems. For the last, a precise parallel can be established with physical systems composed of very large numbers of particles. In a combinatorial problem the phase transi- tion concerns the behavior of some order parameter (usually the expectation value of a microscopic quantity) characterizing an aspect of the system (often the probability of existence of a solution). Moreover, in correspondence to the phase transition (at a critical value of the control parameter), a large increase in the computational complexity of the algorithm used to ﬁnd a solution is usually observed. The key concept that allows ideas and methods to be transferred from statisti- cal physics to combinatorial optimization and decision problems is randomness. If problem instances are taken in isolation, the application of these methods does 43 44 The satisﬁability problem not make sense. They are only meaningful if applied to a set, i.e., an ensemble, of problem instances whose probability of occurrence is governed by a well de- ﬁned law. Then the results obtained can be considered valid for any randomly extracted element from the ensemble. It is thus necessary to specify exactly how the elements of the ensemble are constructed. The study of random graphs was pioneered by Erd¨os and R´enyi (1959). Studying the clustering of vertices, they found that, by varying the parametersRandom graphs that controlled the connectivity of a random graph, in the neighborhood of a particular value there was a sudden transition from a state in which the graph had many disconnected components to a state in which it had collapsed into a single connected component involving most of its nodes. They called this behavior a zero–one law. This law can be said to describe in modern terms a phase transition in connectivity. Since then, the subject has raised consider- able interest in the artiﬁcial intelligence (AI) community, and many works have been published on phase transitions in computer science, notably in graph parti- tioning (Fu and Anderson, 1986), the characterization of hard instances in CNF (Purdom and Brown, 1987), the discovery of optimal paths in trees (Karp and Pearl, 1983), and in graph coloring (Turner, 1988). A great impulse to the inves- tigation of phase transitions in combinatorial problems was given by Cheeseman et al. (1991), who noticed that in the proximity of the phase transitions of sev- eral NP problem classes were located the most difﬁcult instances of the class. Knowing where the most difﬁcult instances of a problem are located is crucial in the testing of algorithms. For instance, Goldberg (1979) claimed that the ma- jority of satisﬁability problems could be solved by local search algorithms in at most O(n2) time, where n is the number of variables. However, Franco and Paull (1983) showed that the probability distribution used by Goldberg to sample problem instances favored easy ones to such an extent that random assignments of truth values to the variables were able to solve the problem with probability 1. As in physics, in computational problems also phase transitions only actu- ally occur in systems with inﬁnite size, and corrections to the inﬁnite model are necessary to predict the properties of ﬁnite-size systems. A domain in which the analogy with statistical physics and the emergence of phase transitions have received most attention is search, probably because of itsSearch ubiquity in AI problems. A clear introductory approach to the subject is provided by Hogg et al. (1996). The problems most studied in both computer scienceSAT and CSP and statistical physics are SAT (satisﬁability) problems and CSPs (constraintSAT problems and CSPs satisfaction problems). Such problems are NP-complete. As mentioned in Chapter 1, the notion of a computational complexity based on worst-case analysis may not be very use- ful in practice. In fact, many instances of NP-complete problems are easy to solve (Cheeseman et al., 1991) and thus provide evidence that reasoning based Random graphs 45 on the use of a “typical” complexity in harder cases is correct. The phase transi- tion framework offers a way to study problems in the “typical” complexity case which is more representative of real-world applications and also contributes to the design of efﬁcient algorithms. As mentioned earlier, the notion of a problem ensemble grounds the link be- Problem ensemble tween statistical physical systems and combinatorial problems. All the properties derived from the phase transition framework are valid for sets of random prob- lems, whose generative model is precisely speciﬁed. Thus, an important aspect to be discussed, within the framework, is what model to use and how the chosen model can cover problems encountered in the real world. Before entering into a description of the phase transition in SAT, some pre- liminary notions need to be introduced. 3.2 Random graphs Graphs are a natural way of representing the internal structure of complex sys- tems, and they will be used extensively in the rest of the book. As previously discussed, we are not interested in single graphs but in graph ensembles, whose elements have an associated known probability distribution. Deﬁnition 3.1 {Graph} A graph is a pair G =(V, E),where V = Graph {v1,...,vn} is a set of n vertices (or nodes) and E = {(vi1 ,vj1 ),..., (vir ,vjr )} is a set of r edges connecting pairs of vertices. Agraphis directed if the edges have an orientation and is undirected other- wise. A graph is weighted if there is a function w : E → R that associates a real number with every edge in the graph and is unweighted otherwise. Deﬁnition 3.2 {Path} A path in a graph is a sequence of nodes (vi1 ,...,vik , Path vik +1 ,...,vis ) such that each pair (vik ,vik +1 )(1 ⩽ k ⩽ s − 1) belongs to the set of edges E. The nodes vi1 and vis are said to be connected. If the graph is directed then vis is said to be reachable from vi1 . Deﬁnition 3.3 {Connected component} Given an undirected graph G,a con- Connected componentnected component in G is a maximal subgraph G ′ such that any two vertices in G ′ are connected. The subgraph G ′ is maximal in the sense that it is not possible to add any vertex while preserving its connectivity. Deﬁnition 3.4 {Strongly connected component} Given a directed graph G,a Strongly connected componentstrongly connected component in G is a maximal subgraph G ′ such that every vertex in G ′ is reachable from any other vertex. This condition requires that, given any two vertices vih and vik in G ′, vih is reachable from vik and vice 46 The satisﬁability problem v1 v2 v3 v 4 v5v6 v7 v8 v9 v10 Figure 3.1 Example of an undirected graph G =(V, E), where the set of vertices is V = {v1,v2,v3,v4,v5,v6,v7,v8,v9,v10} and the set of edges is E = {(v1,v2), (v2,v3), (v3,v4), (v4,v5), (v5,v6), (v6,v7), (v8,v9), (v9,v10)}. The sequence of vertices (v1,v2,v3,v4,v5,v6) is a path in G, and the subgraph G ′ =(V′, E′),where V′ = {v8,v9,v10} and E′ = {(v8,v9), (v9,v10)},isa connected component. v 1 v 2 v 3 v 4 v5v 6 v 7 v 8 v 9 v10 Figure 3.2 Example of a directed graph G =(V, E), where the set of vertices is V = {v1,v2,v3,v4,v5,v6,v7,v8,v9,v10} and the set of edges is E = {(v1,v2), (v2,v3), (v3,v4), (v5,v4), (v5,v6), (v6,v7), (v8,v9), (v9,v10), (v10,v8)}. The sequence of vertices (v1,v2,v3,v4) is a path in G,andthe subgraph G ′ =(V′, E′),where V′ = {v8,v9,v10} and E′ = {(v8,v9), (v9,v10), (v10,v8)}, is a strongly connected component. versa. Moreover, G ′ is maximal in the sense that it is not possible to add any vertex while preserving its connectivity. In Figures 3.1 and 3.2 the above deﬁnitions are illustrated for an undirected and a directed graph, respectively. Let us introduce now the notion of a random graph. Random graphs 47 Deﬁnition 3.5 {Random graph} Agraph G =(V, E) is random if some el- Random graph ement of its structure is built up stochastically, according to a known probability distribution. The ﬁrst model of random graphs was proposed independently by Solomonoff and Rapoport (1951) and by Erd¨os and R´enyi (1959), and it can be formulated in two slightly different ways. Deﬁnition 3.6 {Model ER1} Let Gn,p be an ensemble of random graphs G, Model ER1 built up as follows. Given n vertices and a probability value p ∈ (0, 1), each pair of vertices in G is connected with probability p. Deﬁnition 3.7 {Model ER2} Let Gn,r be an ensemble of random graphs G, Model ER2 built up as follows. Given n vertices and an integer number r of edges, select randomly, without replacement, r pairs of vertices and connect them. In the following, let M = n(n − 1)/2 be the total number of possible edges in an undirected graph with n vertices. In model ER1 the ensemble Gn,p has cardinality (number of elements) |Gn,p| = M∑ r=0 ( M r ), because a graph with r edges can be chosen in (M r ) different ways from the M possible graphs with r edges. A graph G with r edges occurs in Gn,p with probability P(G has r edges)= p r(1 − p)M −r. In model ER2 the ensemble Gn,r has cardinality |Gn,r| = (M r ). All graphs in it have exactly r edges, and each occurs with uniform probability P(G)= 1 (M r ) . It should be clear that Gn,r ⊂Gn,p. Deﬁnition 3.8 {Degree} In a graph G the degree of a vertex is the number of Degree nodes connected to it. The degree of the graph is the maximum degree of the nodes. In a graph G ∈Gn,p the probability that a random node has degree d is given by pd = (n − 1 d )p d(1 − p)n−d−1 ≃ zde−z d! , (3.1) where z = p(n − 1) is the average degree of the nodes. The rightmost expression is the Poisson approximation of the distribution pd when n →∞ with z constant. 48 The satisﬁability problem This approximation is valid when n →∞ while pn is kept constant. Because of the distribution (3.1) the graphs in Gn,p are called Poisson random graphs. Analogous properties hold for the ensemble Gn,r. The ensemble Gn,p shows a second-order phase transition in the connectivity,Phase transition in connectivity in correspondence with the control parameter z. More precisely, when z< 1, a random element G of the ensemble is formed by many small disconnected components, whose size is O(ln n);when z =1 the mean size of the largest component becomes O(n2/3);for z> 1 a giant component,whosesizeis O(n), appears in the graph. Thus the ensemble shows, at the phase transition, a “double jump”. An ensemble of graphs that has close connections with statistical physics was proposed by Strauss (1986) and is called the ensemble of exponential random graphs. Deﬁnition 3.9 {Exponential random graph} Given a number n of nodes, letExponential random graph ϵ1,ϵ2,...,ϵs be a set of properties measured on a single graph (such as the num- ber of edges, number of triangles, ...). Moreover, let β1,β2,...,βs be a set of parameters (the inverse temperatures). Then the ensemble of exponential ran- dom graphs is a collection Gexp of graphs G such that each graph occurs in it with probability P(G)= 1 Z exp ( − s∑ i=1 βiϵi ) , where Z is the partition function. Particularly important in the study of complex real-world networks are small- world and scale-free graphs. Small-world networks were introduced by Watts and Strogatz (1998), whereas scale-free networks were introduced by Barab´asi and Albert (1999). Intuitively, a small-world graph is one in which each node has “short” paths connecting it to all the other ones. Formally: Deﬁnition 3.10 {Small-world graph} Given a graph G with n nodes, theSmall-world graph graph is a small-world one if its diameter is O(ln n). Deﬁnition 3.11 {Scale-free graph} Given a graph G with n nodes, the graphScale-free graph is scale-free if the distribution of the degrees d of the vertices is governed by a power law, namely pd ∼ d−γ , for a given γ. Power law distribution In a scale-free network there are a few nodes with large degrees and many nodes with very small degrees. The power law distribution is explained by the hypoth- esis of preferential attachment: if the network is built up by adding one node atPreferential attachment a time, when adding node vj+1 the probability that it will be connected to an The SAT problem 49 existing node vi is proportional to vi’s current degree. The mechanism of prefer- ential attachment is quite old; it was ﬁrst proposed by Yule (1925) to explain the power-law distribution observed in the number of species per genus of ﬂowering plants. The modern approach to the mechanism was initiated by Simon (1955) in investigating the distribution of the sizes of cities. In the context of complex networks it was re-proposed by Barab´asi and Albert (1999). After providing this brief reminder of basic graph notions, we now intro- duce the ﬁrst NP-complete problem that is central to this book, namely the SAT problem. 3.3 The SAT problem The name SAT is an abbreviation of satisfaction: the SAT problem is concerned SAT problem with the satisﬁability of logical formulas in propositional calculus. The SAT problem was the ﬁrst to be proved NP-complete, in a famous theorem of Cook (1971). Boolean SAT problems play a crucial role in many important practical ap- plications (Biere et al., 2009). Moreover, such problems are strongly connected with operational research and artiﬁcial intelligence. For this reason, the ﬁeld has been deeply investigated and tremendous progress in SAT solver performance has been observed. Open source implementations are available today that scale up to extremely large problems, with the number of variables and clauses in the order of millions. Deﬁnition 3.12 {SAT problem} Let X = {x1,...,xn} beasetof n Boolean variables, which can take values in {1, 0},where 1 corresponds to true and 0 to false.Let Γ = {γ1,...,γm} be a set of clauses, i.e., disjunctions of variables or their negations. The SAT problem consists in either ﬁnding an assignment of truth values to the variables in X such that all the clauses in Γ are satisﬁed or proving that none exists. The conjunction of all clauses in Γ is a formula ϕ(x1,...,xn) that must be satisﬁed. The SAT problem is said to be satisﬁable if ϕ can be made true by some choice of the variables, otherwise it is said to be unsatisﬁable. EXAMPLE Let X = {x1,x2,x3,x4} be a set of four variables, and let Γs = {γ1,γ2,γ3} and Γu = {γ′ 1,γ′ 2} be two sets of clauses such that γ1 = x1 ∨ ¯x2,γ2 = x1 ∨ x3 ∨ ¯x4, γ3 =¯x1 ∨ x2 ∨ ¯x3, γ′ 1 = x1,γ′ 2 =¯x1, 50 The satisﬁability problem where ¯xi means the negation of xi. It is easy to see that the set Γs corre- sponds to a satisﬁable problem. In fact x1 =1,x2 =1,x3 = ∗,x4 = ∗ isThe symbol * denotes any value. a family of solutions. On the contrary, the set Γu corresponds to an unsat- isﬁable problem. We will now illustrate the relationship between the SAT problem and statis- tical physics. In order to do this, we introduce a subproblem of SAT, namely the k-SAT problem. Deﬁnition 3.13 {k-SAT problem} A k-SAT problem is a SAT problem ink-SAT problem which all clauses in Γ have exactly k terms (variables). EXAMPLE Let X = {x1,x2,x3} be a set of three variables, and let Γ = {γ1,γ2,γ3} be a set of clauses such that γ1 = x1 ∨ ¯x2,γ2 =¯x1 ∨ x3, γ3 = x2 ∨ ¯x3. This is an example of a 2-SAT problem. The problem is satisﬁable, for instance by the triple {x1 = x2 = x3 =1}. It is well known that the 1-and 2-SAT problems are polynomial, whereas the k-SAT problem for k ⩾ 3 is NP-complete. The 3-SAT problem is the most studied of the class and is the one for which the most precise results have been obtained. A generic k-SAT problem is a member of an ensemble generated as de- scribed in the following. Deﬁnition 3.14 {Generative model of k-SAT} Given two integers k and mGenerative model of k-SAT and a set X = {x1,...,xn} of variables, each clause γi ∈ Γ (1 ⩽ i ⩽ m) is generated independently by selecting randomly, with uniform probability, k variables from X; then, each selected variable xj is negated with probability p =0.5. Let Πk be the set of all k-SAT problems with m clauses over n variables. The cardinality of Πk is |Πk| = ( 2k( n k) m ) . Each element of Πk is a formula ϕ(x1,...,xn), i.e., a set of clauses as stated in Deﬁnition 3.12; these elements occur in Πk with equal probability. The SAT problem 51 P(α, k) α α 0 2 4 6 8 10 cr Figure 3.3 Qualitative behavior of the probability P(α, k) of solution of a ran- dom instance of the 3-SAT problem vs. the parameter α = m/n. The generative model for a k-SAT problem deserves further comment. Ac- cording to Deﬁnition 3.14 it may happen that in a given problem instance two clauses turn out to be equal, thus reducing the difﬁculty of satisfying the prob- lem. In order to avoid this situation the generation of the clauses should be done in another way: ﬁrst, all the possible k-term clauses are constructed and then m from these are selected without replacement. Even though this model of formula generation allows the probability of any single problem instance to be computed exactly, it is impractical in use because the number of possible clauses is (n k)2k. Thus, in practice, in order to generate k-SAT problem instances the procedure of Deﬁnition 3.14 is used. To cope with the above difﬁculty, there are two possibil- ities: either duplicated clauses are ﬁltered out (which can be done automatically) or the problem is ignored, as the probability of duplication is very low. More Duplication probabilityprecisely, the probability that at least one duplication occurs can be evaluated as follows: Pdupl =1 − [ 2k(n k)]! [ 2k(n k) − m ] ! [ 2k(n k)]m . (3.2) For example, in a small problem instance, with, say, n =50, k =3 and m =10, we have Pdupl =0.000286. The probability of duplication rapidly decreases when the problem size in- creases. Experimental investigation of the k-SAT problem has concentrated on the probability P(α, k) that a randomly chosen formula ϕ(x1,...,xn) is satisﬁable, 52 The satisﬁability problem with α = m/n. In Figure 3.3 a graph qualitatively describing this probability versus the parameter α is given. From the ﬁgure, a remarkable behavior emerges (Monasson, 2002): for all values α<αcr(k) the probability P(α, k) assumes values very close to 1, whereas when α>αcr(k) it assumes values very close to 0.The critical value αcr(k), which is a function of k, deﬁnes the bound-Critical value of the control parameter α ary between two phases, the SAT phase, where a randomly chosen formula ϕ(x1,...,xn) is almost surely satisﬁable, and the UNSAT phase, where a ran- domly chosen formula ϕ(x1,...,xn) is almost surely unsatisﬁable. The random choice of formula means that the way in which k-SAT problem instances (the formulas ϕ(x1,...,xn)) are generated produces, in the SAT (UNSAT) region, very few unsatisﬁable (satisﬁable) ones, so that a random choice would produce an unsatisﬁable (satisﬁable) formula with an extremely low probability. In or- der to ﬁnd an unsatisﬁable (satisﬁable) formula in the SAT (UNSAT) phase, such a formula must be constructed speciﬁcally. This behavior recalls a phase transition, as in physical systems. In the vocabulary of phase transitions, the probability P(α, k)isthe order parameter and α is the control parameter. The presence of a boundary between the SAT and the UNSAT phases has2-SAT been proved rigorously for the polynomial 2-SAT problem, where the critical value is αcr(2) = 1.For the NP-complete problem k-SAT with k ⩾ 3, the loca- tion of the phase transition has not been calculated precisely, but only estimated. For instance, αcr(3) ≃ 4.3 and exact lower and upper bounds are known: αlb =3.26 <αcr(3) < 4.51 = αub. Using the cavity equations introduced in Section 2.8, Mertens et al. (2006)de- rived threshold values for the parameter α of k-SAT. For k =3 they found αcr ≃ 4.267. The authors also provided some closed expressions for these3-SAT thresholds, for large k. The results of their work support the conjecture that this computation gives the exact satisﬁability threshold. The importance of the critical value is that the most difﬁcult instances are located in its neighborhood. In fact, in correspondence with the phase transition, the computational complexity involved in ﬁnding a solution (or in proving that none exists) shows a marked peak, as represented in Figure 3.4. The explanation of this easy–hard–easy pattern for the algorithms used to solve a k-SAT problem is that in the SAT phase the problem instances are undersconstrained and there are many solutions, so that it is easy to ﬁnd one; in the UNSAT phase the problem instances are overconstrained and so it is easy to show that no solution exists. In correspondence with phase transitions, there are few solutions for the solvable instances and none for the unsolvable instances; thus, it is difﬁcult to separate SAT from UNSAT instances. The SAT problem can be described in graphical form by means of a bipartite graph, called a factor graph. The SAT problem 53 C(, k) 0 2 4 6 8 10 cr α α α Figure 3.4 Qualitative behavior of the computational complexity C(α, k) for solving a k-SAT problem instance. Deﬁnition 3.15 {Factor graph} Given a SAT problem instance with n vari- Factor graph ables and m clauses, let us associate with each variable and each clause a node in a bipartite graph. Variable nodes are represented as circles, and clause nodes are represented as squares. Edges can connect variable nodes and clause nodes. An edge connecting a clause node γ and a variable node x is labeled with 1,and represented by a continuous line, when x occurs in γ as a positive literal; it is la- beled with −1 and represented by a dotted line when x occurs negated.Variable nodes have a status which can assume three possible values: 1 (true), 0 (false), and ∗ (undecided). An example of such a bipartite graph is provided in Figure 3.5. 3.3.1 SAT problems and the Ising model We have reached the stage where it is possible to establish a one-to-one corre- spondence between the SAT problem and the Ising model of spins (Monasson and Zecchina, 1997). In Table 3.1 this correspondence is summarized. The key point in creating this correspondence is to introduce an “energy” function that Energy function counts the number of unsatisﬁed clauses for a given assignment of the variables. Clearly, if the problem instance is SAT then this number goes to zero and the SAT as an Ising modelcorresponding ground state has energy equal to zero; if the problem instance is UNSAT then this number remains greater than zero and the correspond- ing ground state has strictly positive energy. A variable xj with value true 54 The satisﬁability problem x3 x1 x2 x5 x4 x6 a c b d f e Figure 3.5 Example of a bipartite graph corresponding to the SAT formula ϕ(x1,...,x6)= γa ∧ γb ∧ γc ∧ γd ∧ γe,where γa = x1 ∨ ¯x3, γb =¯x1 ∨ x2 ∨ x4, γc =¯x3 ∨ x5, γd =¯x3 ∨ ¯x4 ∨ x5, γe =¯x2 ∨ x4 ∨ x6. corresponds to a spin σj with value +1, whereas a variable xj with value false corresponds to the spin σj with value −1. As exempliﬁed in Table 3.1, given a clause γ = xj1 ∨ xj2 ··· ∨ xjr ∨ ¯xh1 ∨ ¯xh2 ··· ∨ ¯xhs , the associated energy can be written as follows: E(γ)= 1 2r+s r∏ i=1(1 − xji ) s∏ i=1(1 + xhi ). (3.3) Random clauses can be encoded in an m × n matrix C, whose rows correspond to clauses and columns to variables. An entry cij assumes values in {+1, 0, −1}. More precisely: cij =+1 if the variable xj occurs in the clause γi as a positive literal xj ; cij = −1 if the variable xj occurs in the clause γi as a negative lit- eral ¯xj ; cij =0 if the variable xj does not occur in the clause γi. The matrix C encodes the quenched disorder of the problem and is a random variable gen-Quenched disorder erated as in Deﬁnition 3.14. Table 3.2 shows the matrix C corresponding to the problem represented in Figure 3.5. Given the matrix C, the total energy of the corresponding SAT problem becomes E(C)= m∑ i=1 1 2∑n j =1 |cij | n∏ j=1(1 − cij xj ). (3.4) The SAT problem 55 Table 3.1 Correspondence between the SAT problem and the Ising model of spins SAT Ising model Boolean variable x ∈{1, −1} Ising spin σ ∈±1 Clauses Couplings Number of clauses violated Energy E of the spin conﬁguration by a logical conﬁguration Example 2-Sat x ∨ ¯yE = 1 4 (1 − σx)(1 + σy) (x ∨ ¯y) ∧ (¯x ∨ z) E = 1 4 (1 − σx)(1 + σy) + 1 4 (1 + σx)(1 − σz) 3-Sat x ∨ ¯y ∨ zE = 1 8 (1 − σx)(1 + σy)(1 − σz) Minimum number of violated clauses Ground state energy Problem is = { satisﬁable unsatisﬁable Ground state energy { =0 > 0 Table 3.2 The matrix C describing the SAT problem reported in Figure 3.5 x1 x2 x3 x4 x5 x6 γa 10 −10 0 0 γb −1101 0 0 γc 00 −10 1 0 γd 00 −1 −11 0 γe 0 −101 0 1 Knowing the probability distribution of the quenched disorder (the matrix C)the average value of the energy can be computed. For each clause (row in C), we have − n∑ j=1 cij xj = number of wrong1 literals in clause γi. (3.5) In order to explain expression (3.5), let us notice that the product cij xj is equal to 1 iff both cij and xj have the same sign (i.e., they are both equal to 1 or both equal to −1), it is equal to −1 iff cij and xj have different signs (one 1This means that cij and xj have opposite signs. 56 The satisﬁability problem equal to −1 and one equal to 1), and it is equal to zero iff cij =0.If cij =0,the variable xj does not occur in clause γi and the product cij xj does not contribute either to the number of correct literals or to the number of wrong literals. If cij xj =1, either the variable xj is positive in γi and so assumes the value 1 (it is true), or it is negative in γi and so assumes the value −1 (it is false); in both cases, the value of xj makes the whole clause γi true. On the contrary, if cij xj is equal to −1 then the variable xj assumes a value that makes the corresponding literal false. Thus, if we want to count the number of wrong literals in clause γi, we have to sum the products −cij xj over j. Given a clause with k terms, if − ∑n j=1 cij xj = k then the clause has all literals false and so it is false. For a 3-SAT problem, the condition for which a clause is false reads n∑ j=1 cij xj +3 = 0. Then, clause γi is not satisﬁed iff δ ⎛ ⎝ n∑ j=1 cij xj +3 ⎞ ⎠ =1, where δ(z) is the Kr¨onecker function, which is 1 if z =0 and 0 otherwise. Now let S denote a conﬁguration of spins (variables), i.e., an assignment of truth values to all the n variables. Moreover, let E(C, S) be the total number of unsatisﬁed clauses in S: E(C, S)= m∑ i=1 δ ⎛ ⎝ n∑ j=1 cij xj +3 ⎞ ⎠ . (3.6) The minimum E0(C) (the ground state energy) can be obtained by the optimalGround state energy logical assignment to the variables. The value E0(C) is a random variable, be- cause C is a random variable; it becomes highly concentrated around the mean value E0 = E0(C) in the thermodynamic limit (n →∞). The mean value is computed with respect to the probability distribution of the quenched disor- der (namely, the matrix C). Let us now consider the generating function of the energy: G(z, C)= ∑ S zE(C,S). The value of E0 is computed from the average logarithm of G(z, C) (Monasson, 2002), obtaining E0 = lim z→0 ln G(z, C) ln z . (3.7) The SAT problem 57 In the SAT region E0 is equal to 0, whereas it is strictly positive in the UNSAT region. The value E0 as a function of the control parameter α detemines the critical value αcr(k). EXAMPLE For the sake of illustration, we follow the treatment of a toy problem, the 1-SAT, provided by Monasson and Zecchina (1997) and Monasson (2002). Let X = {x1,...,xn } and Γ = {γ1,...,γm } be the sets of variables and clauses, respectively. In the 1-SAT case the matrix of quenched disorder C, introduced above, has only one entry per row, as all clauses are either a single variable or its negation. Concerning the columns, let us suppose that the clause γi = xj occurs in Γ. Then, in order to avoid duplication, the same clause cannot occur further in Γ. However, the clause γh =¯xj may occur in Γ but in this case the problem instance is unsatisﬁable, because the formula associated with it contains a variable and its regation, yet both must be true. Thus each column of the matrix C may have at most two entries different from zero, one equal to +1 and one equal to −1. In order to generate a 1-SAT problem instance we have to extract m ele- ments from the set of possible clauses, which is the union of the set X and the set containing all the negated variables. We have thus (2n m ) different problem instances. A unique matrix C is associated with each problem in- stance, and each matrix can be extracted with equal probability. Thus the probability distribution the quenched disorder is uniform: P(C)= 1 (2n m ) . (3.8) For 1-SAT, any matrix C is described simply by the numbers ti and fi of clauses that require a certain variable xi to be true or false, respectively (Monasson and Zecchina, 1997). Then the partition function is simply Z(C)= n∏ i=1 [exp(−βti(C)) + exp(−βfi(C))] . (3.9) By using the replica trick with r replicas, it can be derived that the average of the logarithm of Z, with respect to (3.8), assumes the value 1 r ln Z(C)=ln 2 − αβ 2 + ∞∑ h=−∞ e −α Ih (α)ln (cosh βh 2 ), (3.10) where Ih is the modiﬁed Bessel function of order h and α = m/n.If expression (3.8) is calculated for vanishing temperature (i.e., for β →∞), the ground state energy density has the value E0(α)= α 2 [ 1 − e −α I0(α) − e −α I1(α) ] , (3.11) 58 The satisﬁability problem 1 2 3 4 5 0.5 1.0 1.5 E00 α Figure 3.6 The ground state energy E0 for the 1-SAT problem. The energy is zero only for α =0. whereas the ground state entropy density is S0(α)= e −α I0(α)ln2. The graph of the ground state energy for the 1-SAT problem is shown in Figure 3.6. As can be seen, the ground state energy is zero only for α =0. Monasson and Zecchina explain this result by the fact that the entropy is ﬁnite and, hence, the number of minima in the energy is exponentially large for any α. In turn this is due to the presence of a fraction e −α I0(α) of unconstrained variables, whose value does not affect the value of the energy. 3.3.2 Structure of the solution space An interesting aspect to be investigated is the way in which solutions of k-SAT problems are organized within their respective spaces. If we consider the critical value αcr, then just above this threshold the number of solutions is equal to zero, as we are now in the UNSAT phase;2 however, just below the threshold the typical number of solutions N0(α) becomes almost surely exponential in the number of variables n (Boufkhad and Dubois, 1999). The quantity that is relatedEntropy density to the number of solutions is the entropy density s0(α) of the ground state. In 2See Chapter 14 for an alternative view. The SAT problem 59 fact, each alternative assignment of variables can be considered as a “state”, and so s0(α)= 1 n ln N0(α). For α =0 we have s0 =ln 2 because, with a number m =0 of clauses, any variable assignment is a solution of any problem and so N0(0) = 2n.Inorder to compute s0 for any α the replica symmetry method has been applied, but it turns out that this method does not provide a correct solution in the whole SAT phase. In fact replica symmetry theory implies that any two assignments (spin conﬁgurations, in the statistical physics view) have almost surely the same Hamming distance between them, i.e., they show the same fraction of variables (spins) with a different assignment (orientation). As a consequence, solutions are grouped into a cluster of diameter dn. However, it has been found that this picture Transition from one to many solution clusters is not always true for the whole SAT phase (Biroli et al., 2000; Monasson, 2002). More precisely, the SAT phase can be divided into two zones by a new critical threshold αRSB : • Below αRSB the solution space is replica symmetric (it satisﬁes the replica symmetry theory), and there is just one cluster of solutions. The Hamming distance d between pairs of solutions is a decreasing function of α. • At αRSB ≃ 4.0 the solutions become grouped into an exponential (in n) number of different clusters, each containing, in turn, an exponential number of solutions. As α increases, the number of clusters decreases. The satisﬁability transition corresponds to the vanishing of the clusters. The threshold αRSB reveals a “clustering phase transition”. In Figure 3.7 a qual- itative representation of the clustering process is shown. The region αRSB < α<αcr is called the hard-SAT region (M´ezard et al., 2005). Here the typical Hard-SAT region Hamming distance d between solutions in different clusters is about 0.3,and re- mains almost constant up to αcr. Within each cluster, solutions tend to become more and more similar, with a rapidly decreasing intra-cluster Hamming dis- tance (Monasson, 2002). Given two solutions in the same cluster, it is possible to change one into another by ﬂipping only O(1) variable values. If the solu- tions are in different clusters, to change one into the other it is required that a number O(n) of variables have their values ﬂipped. The clustered region is the most difﬁcult one for many local search algorithms (Semerjian and Monasson, 2003). The presence of clusters of solutions has suggested a new, very effective, algorithm for solving SAT problems, called the survey propagation algorithm. It will be described in Section 3.5.4. More recently, Montanari et al. (2008) reﬁned this picture of the solution space in the SAT phase. They have found, for k ⩾ 4,anew condensation phase Condensation phase 60 The satisﬁability problem α Figure 3.7 Qualitative representation of the clustering process. Below the threshold αRSB solutions are organized into a single cluster, whereas above the threshold an exponential number of clusters, each with an exponential number of solutions, appear. transition at a value αcd ∈ [αRSB ,αcr].When α ∈ [αRSB ,αcd] there are ex- ponentially many clusters whereas for α ∈ [αcd,αcr] most solutions are con- tained in a number of clusters that remains bounded when the number of vari- ables n →∞. A further reﬁnement of the solution space has been described by Zhou and co-workers (Zhou and Ma, 2009; Zhou, 2010), who have found that, for k =3 and 4, there is a giant connected component that contains dif- ferent solution groups even when α<αRSB . Solutions in the same group are more similar to each other and more densely connected than they are to other solutions. 3.3.3 Backbone In the UNSAT phase the number of solutions is almost surely zero, but another in- teresting phenomenon appears: in the ground state a backbone emerges. A back- bone is a set of variables each of which takes on its own speciﬁc value in all ground states. It is to be expected that the size of the backbone will be O(n).Fol-Backbone lowing Monasson (2002), let γ(α, k) be the number of these totally constrained variables (the size of the backbone). For α<αcr, γ(α, k)=0. When the crit- ical value is crossed, two behaviors have been observed: for k =2, γ(α, 2) is continuous at the threshold αcr(2) = 1 and then increases as the UNSAT region is entered further. For k =3 the function γ(α, 3) shows a discontinuity, jumping to a ﬁnite value γcr just above the threshold αcr(3). In other words, a ﬁnite frac- tion of variables become suddenly overconstrained when the critical value of α is crossed. Let N0 be the number of conﬁgurations in the ground state of an unsatisﬁable formula, i.e., the number of optimal assignments of truth values to the variables. The SAT problem 61 We can deﬁne μi = 1 N0 N0∑ a=1 x (a) i as the average value of the variable xi over all the ground state conﬁgurations. The average μi ranges in [−1, +1]. When μi =+1 (μi = −1), the variable xi is then equal to +1(−1) in all the conﬁgurations. If P(μ) is the distribution of the values μi, the presence of a backbone is denoted by a concentration of the probability values around the values +1 and −1. On the contrary, the central region of the distribution (P(μ)=0) denotes the presence of variables that are loosely constrained, as their values across the ground state conﬁgurations are roughly balanced between +1 and −1. The existence of the backbone has been exploited to design heuristics for solving k-SAT problems. For instance, Dubois and Dequen (2001) showed that the backbone can be exploited to design efﬁcient algorithms for solving hard unsatisﬁable 3-SAT formulas (Dequen and Dubois, 2006). Though useful for heuristics, the backbone in itself is NP-hard to ﬁnd. More than that, unless P = NP, ﬁnding a sound approximation to it is also intractable in general (Kilby et al., 2005). 3.3.4 Backdoors An interesting notion, which parallels that of a backbone and applies to solvable SAT instances, is that of a backdoor. Backdoors were introduced by Williams et al. (2003). Informally, a backdoor to a given problem is a subset of variables such that, once the variables in this subset are assigned values, the polynomial propagation mechanism of the SAT solver (the “subsolver”) solves the remaining formula.3 Backdoors correspond to clever shortcuts in the solution process. More formally, in the case of satisﬁable SAT instances a backdoor is deﬁned as follows. Deﬁnition 3.16 {Backdoor} Given a satisﬁable SAT problem represented by aformula ϕ to be satisﬁed, a backdoor to ϕ with respect to a subsolver A is a non-empty set of variables S for which there exists an assignment aS : S → {0, 1}|S| for which A returns a satisfying assignment ϕ(aS ). We may notice that a particular kind of backdoor is provided by a set of independent variables. Williams et al. (2003) also introduced the notion of strong backdoor in the case of possibly unsatisﬁable instances. Deﬁnition 3.17 {Strong backdoor} Given a SAT problem represented by a formula ϕ to be satisﬁed, a strong backdoor to ϕ with respect to a subsolver A 3The formal deﬁnition of a subsolver can be found in Williams et al. (2003). 62 The satisﬁability problem is a non-empty set of variables S such that, for all assignments aS : S → {0, 1}|S|, either A returns a satisfying assignment or the unsatisﬁability of ϕ(aS ) is established. While setting a backbone to a given value is a necessary condition, setting up a (strong) backdoor is a sufﬁcient condition for solving a problem. Knowing the backdoor of a SAT problem (i.e., the variable set S) may strongly reduce the complexity of the search. In fact, the exponential part of the search cost is O(2|S|), the rest of the computation being polynomial. The size of a backdoor cannot exceed n − 1 but the experimental investigation by Williams et al. (2003) showed that, in practice, backdoors may be quite small. This implies that, even including in the overall computational cost that for ﬁnding a backdoor, a gain in cost may still be the result, in comparison with searches without backdoors. The authors also provided a strategy to exploit backdoors formally. Finding a backdoor to a problem is intractable in general if P ̸= NP,as mentioned above. However, Kilby et al. (2005) showed that the problem be- comes tractable, in certain cases (for instance for 2-CNF polynomial subformu- las), if the size of the backdoor can be bounded. 3.4 The random (2 + p)-SAT An interesting approach to studying the differences in the behavior of 2-SAT and 3-SAT problems was proposed by Monasson et al. (1999), who investigated an intermediate problem, called (2+ p)-SAT, which is a SAT problem with clauses containing either two or three literals. More precisely, any problem instance con- tains pm clauses with three literals and (1 − p)m clauses with two literals. The problem is still NP-complete because any instance contains, for p> 0, a subfor- mula with at least three clauses. The authors aimed at computing the threshold αcr(2 + p) for ﬁxed p, knowing that αcr(2) = 1 and αcr(3) ≃ 4.267. By ob- serving that 2-SAT problem instances (or 3-SAT problem instances) are almost always unsatisﬁable for some number of clauses n (or αcrn), the following rela- tion holds: αcr(2 + p) ⩽ min ( 1 1 − p , αcr(3) p ) . Let us now consider the probability distribution P(μ) introduced in Section 3.3.3 and analyze what happens at the threshold of the 2-SAT and 3-SAT cases. Let f (k, α) be the fraction of variables that become totally constrained at and above the threshold. The function f (k, α) is identically zero below the threshold for both cases. For 2-SAT, the function becomes strictly positive above αcr(2) = 1 but is continuous at the transition point, i.e., f (2, 1+)= f (2, 1−)=0.Onthe Solving the SAT problem 63 contrary, for 3-SAT the function f (3,α) shows a discontinuity, i.e., f (3,α− cr)= 0 and f (3,α+ cr)= fcr(3) > 0. For the mixed (2 + p)-SAT model, the key point is understanding how a discontinuous 3-SAT-like transition may appear when the parameter p is in- creased from 0 to 1. By applying a previously introduced method (Monasson and Zecchina, 1997), Monasson et al. (1999) found that the model has a contin- uous SAT–UNSAT transition below the value pc =0.413 at an αcr value given by αcr(2 + p)= 1 1 − p . (3.12) Then, below the value α =1/(1 − p) the (2 + p)-SAT problem behaves as 2-SAT versus 3-SAT2-SAT. For p>pc the transition becomes discontinuous and the model behaves as 3-SAT. Achlioptas et al. (2001b) studied the (2 + p)-SAT problem in the limit n →∞ and found, by combinatorial arguments, that the critical value for p is pc =2/5. In response to this new result, Biroli et al. (2000) proved by statistical physics methods (though not rigorously) that pc indeed equals 2/5. 3.5 Solving the SAT problem In this section we will brieﬂy review the different approaches used to solve SAT problems. More speciﬁcally, we will be interested in discussing their behavior when problem instances get close to the phase transition region. The basic assumption underlying the heuristics exploited by many SAT “Regular” problem instances versus random ones, where no regularities may be assumed to exist solvers is that the problem instances occurring in practice are usually easy even when their size is large. This happens because these instances frequently exhibit some kind of regularity, which allows speciﬁc heuristics to be exploited. How- ever, problems inside the phase transition region are not of this kind and then the heuristics fail. A ﬁrst family of SAT solvers contains exact (or complete) solvers. They have been designed to always ﬁnd a solution when one exists. Nevertheless, in order to prevent their running for an undetermined time period, they are also provided with a time-out mechanism. Therefore, they classify a problem as unsatisﬁable either when they prove that a solution does not exist or when they run out of time. A second family, developed for practical applications to engineering prob- lems, is that of incomplete SAT solvers. They use heuristics that are easy to apply, such as hill climbing, but are incomplete, i.e., large regions of the search space are disregarded and remain unexplored. If the solution is in such a region, it will not be found; thus a solvable problem instance is declared unsolvable. 64 The satisﬁability problem A third family addresses a generalization of SAT called MaxSAT. Given aMaxSAT problem Boolean expression in conjunctive normal form (CNF), a MaxSAT problem con- sists in ﬁnding a variable assignment satisfying the maximum possible number of clauses, i.e., minimizing the number of violated constraints. MaxSAT reduces to SAT when the problem instance is satisﬁable. It has a strong relevance for practical applications and thus several MaxSAT solvers have been developed. It should be noted that, as we will discuss later, the SAT solvers mentioned above are not able to deal with MaxSAT. Finally, we will give special attention to a new family of algorithms that were designed for solving random SAT problems located close to the phase transition region. 3.5.1 Exact SAT solvers Most exact SAT solvers are based on the well-known Davis–Putnam–DPLL algorithm Logemann–Loveland (DPLL) algorithm (Davis and Putnam, 1960; Davis et al., 1962) and include some smart heuristics to avoid the useless exploration of re- gions of the solution space where solutions are impossible. This is a complete, backtrack, algorithm; if the heuristic is complete, the SAT solver will ﬁnd a so- lution. Usually, the solution ﬁrst found is returned. There are two key strategies, which make modern SAT solvers based on DPLL very effective: (i) fast unit propagation and (ii) clause learning (Marques-Silva and Sakallah, 1996, 1999; Moskewicz et al., 2001; E´en and S¨orensson, 2004; S¨orensson and E´en, 2005). The search strategy of DPLL is conﬂict driven. It starts with a tentative hy- pothesis about a possible assignment of the Boolean variables and then checks every single clause. When a conﬂict is detected, i.e., a clause is not satisﬁed by the current hypothesis, the algorithm backtracks, modiﬁes the hypothesis, and resumes the computation. The initial hypothesis contains only one variable; then the hypothesis is extended further to include new variables until all the variables have been assigned. Unit clauses are those that are not satisﬁed by the current hypothesis and have only one more variable to be assigned. Therefore, they set a deterministic constraint on the value of the unassigned variable. The fast prop-Fast unit-propagation heuristics agation of unit clause constraints focuses the search dramatically (Moskewicz et al., 2001). Clause learning is activated when the current hypothesis cannot be completedClause learning because it is impossible to ﬁnd a consistent assignment for the remaining vari- ables. In order to prevent the algorithm from generating another hypothesis en- tailing the same contradiction, a clause characterizing the conﬂicting variable as- signment is learned (Marques-Silva and Sakallah, 1996). Such clauses are called nogoods. Nogoods are used by a constraint propagation algorithm to restrict theNogoods space of assignments that can be generated. Solving the SAT problem 65 The most popular SAT solver of this family is MiniSat (S¨orensson and E´en, 2005), which is available in an open-source package; it can be customized de- pending on the needs of the application. An alternative to conﬂict-driven approaches is look-ahead (Heule et al., Look-ahead 2004). Both unit propagation and clause learning can be combined with look- ahead, leading to more complex implementations. Look-ahead solvers are usu- ally stronger on hard problem instances while conﬂict-driven ones are faster on large, but easy, problem instances. 3.5.2 Incomplete SAT solvers Incomplete SAT solvers use local search strategies, typically hill-climbing or gradient descent, which explore narrow regions of the hypothesis space. Unit clause propagation and other heuristics used by complete solvers can be ex- ploited by incomplete solvers as well (Schuurmans and Southey, 2001; Hirsch and Kojevnikov, 2005). However, in order to escape the local minima inher- ent in local search, incomplete algorithms include a stochastic restart.The idea Stochastic restart consists in choosing another region of the assignment space, not yet explored, and then repeating another phase of local search. From the theoretical point of view this strategy reintroduces completeness, in the limit. The many algorithms of this family differ in their heuristics and in the stochastic components used for deciding the restart point in the space of possible assignments. Solvers based on genetic algorithms, simulated annealing, and random walk have also been proposed. Among the most popular SAT solvers of this family WalkSAT (Kautz and Selman, 1996), GSAT (Selman et al., 1992) and UnitWalk (Hirsch and Ko- jevnikov, 2005) are worth mentioning. The ﬁeld is being actively investigated be- cause this approach seems the most promising for solving hard problems, which are out of the reach of exact solvers. 3.5.3 MaxSAT solvers MaxSAT solvers do not involve the assumption that the given problem instance is solvable; they are designed to ﬁnd the maximally consistent subset of the con- straints (clauses). This prevents MaxSAT solvers from using the most effective strategies exploited by SAT solvers, i.e., unit propagation and clause learning. In fact, a maximum satisﬁability solution can be one that violates a unit clause and so unit propagation would set a misleading bias on the search space. In an analogous way clause learning is activated when a conﬂict arises, in order to set a constraint that prevents parts of the search space being explored again. In this 66 The satisﬁability problem case, ignoring the conﬂict, dropping the violated constraints, and continuing the search might be the best choice. For the above reasons, progress in the area of MaxSAT has been much slower than for SAT and the available solvers are able to deal only with problem in- stances of a size much smaller than those solved by SAT. As a matter of fact, MaxSAT solvers are adaptations of the SAT solvers de- scribed in the previous subsections. One group is again based on the DPLL algo- rithm (Davis et al., 1962) but does not make use of unit propagation and clause learning. Currently, the best representatives of this approach are MaxSATZ (Li et al., 2007a)and MSUF (Marques-Silva and Manquinho, 2008), whose per- formances are orders of magnitude lower than those of SAT solvers such as MiniSAT (S¨orensson and E´en, 2005). A second group is based on local search and multiple restarts. Actually, local search seems to be more suitable for this kind of problem. Even if such a method is incomplete, it can ﬁnd better ap- proximations for large problem instances than exhaustive search does. A typical heuristic used to guide local search is the gradient of the number of satisﬁed clauses, which implicitly accepts violated clauses. State-of-the-art MaxSAT solvers based on local search are SAPS (Hutter et al., 2002) and ADAPTG2WSAT (Li et al., 2007b). Finally, recent progress has been made by Kroc and his colleagues, whose paper (Kroc et al., 2009) informed the brief review presented here. 3.5.4 Survey propagation The survey propagation algorithm (denoted SP in the following) is a SAT solver based on heuristics completely different from those discussed so far (Braunstein et al., 2008). It was designed with the purpose of trying to solve instances close to the phase transition region, where the solutions are grouped into clusters (see Section 3.3.2). The basic ideas come from statistical physics, i.e., the cavity method (see Section 2.8) and the dynamics of spin glasses. However, a strict analogy between the basic mechanisms of the algorithm and popular methods, such as belief prop- agation, in artiﬁcial intelligence was acknowledged later. In its essence, SP is still a backtrack algorithm that tries to ﬁnd a consis- tent solution. However, it uses powerful heuristics, so that it quite rarely needs to backtrack. The basic strategy consists in trying to identify the solution clus- ters, called covers. Then a speciﬁc solution is searched for inside each cluster using a local search strategy, but discovering solution clusters is per se ataskFactor graph even more complex than discovering single solutions. Survey propagation cir- cumvents the problem by computing a statistical approximation to the covers; thus the covers are just probabilistic guesses, which are much less expensive to Solving the SAT problem 67 compute than true solution clusters. The procedure uses the factor graph repre- sentation of the SAT problem introduced in Deﬁnition 3.15 (Frey et al., 1998; Kschischang et al., 2001) and exempliﬁed in Figure 3.5. The nodes in the factor graph interact iteratively, exchanging signals along the edges until a stationary status is reached. The graph nodes exchange two kinds of signals: (i) warnings and (ii) re- Nodes in the factor graph interact through warnings and requests. quests. Warnings ﬂow from variable nodes to clause nodes and report the status of the variables, whereas requests ﬂow from clauses to variables. When a clause γ needs a speciﬁc status for a variable x, because it is not satisﬁed with the status of the other variables to which it is connected, it sends a request to x asking for a status change. A variable decides its status on the basis of the requests from the clauses to which it is connected, using a majority-voting policy, and then up- dates the warning signal. In principle, one can think of simulating the behavior of the network and observing what then happens. The algorithm for doing this was supplied by Braunstein et al. (2008) as a preliminary introduction to SP and has been called warning propagation (WP). Actually, WP models the undecided sta- tus. The nodes evolve, changing their status, until the network either converges to a stable state or does not. Starting from this basic model there are methods for extracting a problem solution. However, SP goes beyond it. Instead of explicitly modeling a system’s evolution, it estimates the probability for a variable to reach a speciﬁc status. Here the undecided status is introduced to model the fact that a variable can ﬂoat between 0 and 1. To this end the factor graph is extended by labeling the edges with real values in the interval [0, 1], representing the probabilities of occurrence of the signal values (request and warning) ﬂowing through them. In an analogous way, variable nodes have associated probabilities. The algorithm for estimating probabilities is based on the cavity method and bears a strong resemblance to the belief propagation method used in Bayesian networks (Pearl, 1988). Here the Belief propagation cavity method, originally introduced for inﬁnite systems, is adapted to handle factor graphs, obtaining the cavity graph introduced in Section 2.8 and exempli- Cavity graph ﬁed in Figure 2.4(b). The probabilities of the three possible values {0, 1, ∗} of a variable node xi are computed on the basis of the probabilities of the values of the requests that xi will receive from the clause nodes to which it is connected. In turn, the latter probabilities are computed on the basis of the node status and the warning prob- abilities received by the clause nodes from the variable nodes to which they are connected. The probabilities of the values received by xi are computed using the cavity graph G. Implicitly, this is equivalent to making an independence assump- tion, that the probability values of the signals received by xi from its neighbors do not depend on xi itself. This is true only in the case where G is a tree. In the general case an approximate estimate is the result. 68 The satisﬁability problem The probability estimation algorithm is embedded in an iterative procedure, which is run until convergence to a stable distribution is obtained. Then solution clusters are identiﬁed. A solution cluster (cover) is an assignment where someValues with higher probability are tried ﬁrst in the local search phase variable nodes have the value ∗ with high probability. In fact, the cluster extrac- tion algorithm estimates the probability of the most likely cover. Then, starting from this cover, a local search procedure (called decimation) is activated; it tries to ﬁnd a solution, assigning a Boolean value 0 or 1 to the undecided variables in the cover. The probability assigned to the values 0 and 1 in the previous step is used as a heuristic for guiding the search. A clear description of the SP algorithm was provided by Braunstein et al. (2008). 3.6 Comments In this chapter we have indicated that surprising links exist between problems in statistical physics and in combinatorial search (in this chapter, the SAT problem) and that synergy between the two ﬁelds can bring beneﬁts to both. Beyond the formal translation of an Ising model to a SAT, one may wonder what (if any) are the deep reasons underlying the links. In fact, the problems handled in statistical physics typically involve a large number of interacting components (particles), whose ensemble behavior generates macroscopic properties that we can observe and measure. In SAT the microscopic and macroscopic levels are not readily distinguished, nor are their natures immediately apparent. Intuitively, the macro- scopic level consists of two “phases”, SAT and UNSAT, whereas the microscopic level is composed of the variables, which interact with each other through the clauses (the “couplings”) that constrain their possible value assignments. The pattern of interactions is represented by a factor graph, introduced in Deﬁnition 3.15. Assuming this interpretation, as only variables occurring in the same clause interact the range of the interaction is determined by the number of terms in the clauses; for instance, in a 2-SAT problem, variables interact only in pairs and we say that this is a case of a “short-range” interaction, whereas a k-SAT problem with large k may be a case where there are “long-range” in- teractions. A situation in which every pair of variables interacts corresponds to clauses involving all the variables (n-SAT). Obviously, variables occurring in different clauses are nevertheless correlated even though not directly. Augment- ing k, while keeping constant the number n of variables, makes the problem easier to satisfy; the critical value αcr scales as 2k ln 2. In this whole picture a central role is played by randomness. In fact, by constructing speciﬁc SAT prob- lems, both solvable and unsolvable problems can be obtained for any value of k and of the ratio α = m/n. For instance, to build a solvable instance it is sufﬁcient that all clauses include a given variable xj or that all clauses include its negation Comments 69 ¯xj . Conversely, any problem including the two clauses ri = xj and r2 =¯xj is unsolvable. From this observation we may conclude that the generative model of SAT problems establishes the syntax of the instances and that, for each k, m, and n, the proportion of satisﬁable (unsatisﬁable) instances with the above for- mat in the SAT (UNSAT) region is overwhelming. Thus, in order to precisely pick a satisﬁable or unsatisﬁable problem instance at will, extra knowledge is necessary. 4 Constraint satisfaction problems Contents 4.1 Algorithms for solving CSPs 73 4.2 Generative models for CSPs 79 4.3 Phase transition in a CSP 81 4.4 Comments 89 An important class of NP-complete problems is that of constraint satisfaction problems (CSPs), which have been widely investigated and where a phase transi- tion has been found to occur (Williams and Hogg, 1994; Smith and Dyer, 1996; Prosser, 1996). Constraint satisfaction problems are the analogue of SAT prob- lems in ﬁrst-order logic; actually, any ﬁnite CSP instance can be transformed into a SAT problem in an automatic way, as will be described in Section 8.4. Formally, a ﬁnite CSP is a triple (X, R, D).Here X = {xi|1 ≤ i ≤ n}CSP is a set of variables and R = {Rh, 1 ≤ h ≤ m} is a set of relations, each deﬁning a constraint on a subset of variables in X; D = {Di|1 ≤ i ≤ n} is a set of variable domains Di such that every variable xi takes values only in the Di, whose cardinality |Di| equals di. The constraint satisfaction problem consists in ﬁnding an assignment in Di for each variable xi ∈ X that satisﬁes all relations in R. In principle a relation Rh may involve any proper or improper subset of X. Nevertheless, most authors restrict investigation to binary constraints, deﬁned as relations over two variables only. This restriction does not affect the generality of the results that can be obtained because any relation of arity higher than two can always be transformed into an equivalent conjunction of binary relations. A relation Rh involving the variables xi1 ,...,xij can be represented asTabular representation a table in which every row contains an admissible assignment (ai1 ,...,aij ) 70 Constraint satisfaction problems 71 X = {x1,x2,x3}, R = {R1(x1,x2),R2(x1,x3),R3(x2,x3)}, D1 = D2 = D3 = {a, b, c, d}. R1 (x1, x2) R2(x1, x3) R (x2, x3)3 1x 2x 1x 2x3x 3x a b a d c b cc cd a b b d cb d c a a a d b b c a c b c d d a bd Figure 4.1 Example of a binary CSP where the constraints are represented in tabular form. to (xi1 ,...,xij ) of constants from Di1 × ··· × Dij . Some examples of rela- tions are provided in Figure 4.1. Checking a constraint Rh on a variable as- signment (ai1 ,...,aij ) to (xi1 ,...,xij ) reduces to checking whether the tuple (ai1 ,...,aij ) is present in the corresponding table. If all relations are binary, an alternative representation for the constraints becomes possible. In fact, a binary relation Rh(xi,xj ) can be represented as a Boolean matrix Mi,j of size di × dj , where an entry contains T (true)ifthe corresponding tuple is admissible and F (false) otherwise. Entries containing T are usually called goods whereas entries containing F are called nogoods.The advantage of this representation is that a constraint can be checked in constant time by means of a single inspection of the matrix. The disadvantage is that the matrices can become very large when the size of the domains grows. Examples of matrix representations are given in Figure 4.2. Constraint satisfaction problems can be described in some logic language which, most frequently, is chosen to be a subset of ﬁrst-order logic. Finite CSPs can be described in a function-free ﬁrst-order logic called DATALOG, typically DATALOG used in relational learning. We will come back to this point in Chapters 6 and 9; here we will merely introduce the simple transformations necessary to express a ﬁnite CSP in DATALOG. Relations and variable domains can be immediately associated with predi- cates in DATALOG. More speciﬁcally, a relation Rh(xi1 ,...,xij ) of arity j can be associated with a predicate ph(xi1 ,...,xij ), of arity j having the same vari- ables as arguments; a domain Di corresponding to variable xi will be associated 72 Constraint satisfaction problems X = {x1,x2,x3},,R = {R1(x1,x2),R2(x1,x3),R3(x2,x3)} .D1 = D2 = D3 = {a, b, c, d} R3(x2, x3)R2(x1, x3)R1(x1, x2) F T F T F F F T F T T T T F F F x2 1x a bcd a b c d F T F F F F F T F T F F F F T F x3 1x ab c d a b c d T F F T F T F F T T F T F F F F x3 2x ab c d a b c d Figure 4.2 Examples of the same binary relations as those in Figure 4.1.Here the constraints are represented as Boolean matrices. with a unary predicate ui(xi). Relations and domains deﬁne the semantic inter- pretation of the corresponding predicates. Moreover, we notice that, in a CSP, the set of constraints deﬁned by the relations in R must be satisﬁed simultane- ously. This corresponds to a logical AND. Therefore any CSP (X, R, D) can be translated into a DATALOG formula having the format CSP (x1,...,xn)= n⋀ i=1 ui(xi) m⋀ h=1 ph(xi1 ,...,xijh ). (4.1) For the example in Figure 4.1, expression (4.1) becomes CSP (x1,x2,x3) = u1(x1) ∧ u2(x2) ∧ u3(x3) ∧ p1(x1,x2) ∧ p2(x1,x3) ∧ p3(x2,x3). Therefore, solving the CSP deﬁned by this expression means ﬁnding a set of values (substitutions) for the variables x1, x2, x3 that veriﬁes CSP (x1,x2,x3) in the universe deﬁned by D and R. Artiﬁcial intelligence, operational research, and logic programming offer a number of algorithms potentially eligible for this task. However, depending on the speciﬁc case, not all algorithms are equivalent from the performance point of view. Globally, the task remains non-polynomial (unless P = NP). Nevertheless, subclasses of CSPs have been identiﬁed that can be described in restricted fragments of DATALOG and can be solved in polynomial time using proper algorithms. For binary CSPs, a graphical representation can also be used; it consists of an undirected graph G =(V, E), with |V| = n and |E| = m′, called the Algorithms for solving CSPs 73 1x 3x2x R1 R2 R3 Figure 4.3 Graphical representation of the binary CSP described in Figures 4.1 and 4.2. In this case the graph is completely connected, but this is not typical. constraint graph. A simple example is provided in Figure 4.3. In the graph G, Constraint graphthe vertices correspond to variables and the edges correspond to binary relations (constraints). More precisely, an edge connects node xi with node xj iff there exists a relation Rh(xi,xj ) in R whose arguments are the variables xi and xj . If several relations are allowed to share their arguments then the number m′ of edges in G will be smaller than the number m of relations. If this is not allowed then m = m′. Notice that the possible presence of unary relations is ignored when considering the structure of the graph. They may possibly be associated with its nodes. The aspect of CSPs that primarily interests us, however, is the emergence of a phase transition in sets of randomly generated problem instances. The Experimental investigation of phase transition appearance of a phase transition has been experimentally investigated by sev- eral authors, mostly in binary CSPs (Prosser, 1996; Smith and Dyer, 1996; Giordana and Saitta, 2000; Smith, 2001; Xu and Li, 2000). In the following sec- tions we will brieﬂy recall the main results, and in later chapters the relationship between CSPs and learning tasks will be illustrated. 4.1 Algorithms for solving CSPs Constraint satisfaction problems encompass a broad class that includes several subclasses, each characterized by peculiar features. This has led to different ap- proaches to ﬁnd a solution. A ﬁrst important subdivision is between “continuous” CSPs and “discrete” Continuous and discrete CSPsCSPs. Continuous CSPs, where constraints usually take the form of inequalities, are typically investigated in operational research and are solved with optimiza- tion techniques such as, for instance, linear programming. Symbolic CSPs are usually solved using search algorithms developed for artiﬁcial intelligence and logic programming. In the following we will brieﬂy review algorithms for solving symbolic CSPs, speciﬁcally those that can be described in DATALOG. Not surprisingly, we will see that most methods we described for solving SAT problems have a 74 Constraint satisfaction problems correspondence in the more general framework of CSPs. However, the values of variables in CSPs are not simply true or false, as in SAT, but are selected from their corresponding domains of discrete values. 4.1.1 Generate and test with backtracking Backtrack search is a general algorithm for solving any kind of search problem, and it represents the baseline for solving a CSP. However, the well-deﬁned for- mal structure of a CSP allows task-speciﬁc heuristics to be exploited that apply to the whole class and make the search much more efﬁcient. Good introductions to CSPs and CSP solvers are provided by Kumar (1992) and Russell and Norvig (2003). For illustrating these algorithms we will use a classical graph coloring prob-The minimum number of colors required for solving this CSP is three. lem as a guide line. Thus, suppose that the problem is to paint the faces of a cube in such a way that adjacent faces always have different colors. Suppose, moreover, that three colors are available: red (R), white (W), and green (G). EXAMPLE Problem: Assign colors to the six faces of a cube as above. Available colors:R,W,G. CSP formulation: Satisfy the logical expression ϕ(x1,x2,x3,x4,x5,x6)= Color(1,x1) ∧ Color(2,x2) ∧ Color(3,x3) ∧ Color(4,x4) ∧ Color(5,x5) ∧ Color(6,x6) under the constraints x1 ̸= x2 ∧ x1 ̸= x3 ∧ x1 ̸= x4 ∧ x1 ̸= x5, x2 ̸= x3 ∧ x2 ̸= x5 ∧ x2 ̸= x6, x3 ̸= x4 ∧ x3 ̸= x6, x4 ̸= x5 ∧ x4 ̸= x6, x5 ̸= x6. In the above formulas the predicate Color(k, xk ) has the meaning “Face k has color xk ”. The constraint graph is shown in Figure 4.4(a) and the search tree generated by the basic backtracking algorithm is given in Figure 4.4(b). Integers denote the cube faces, whereas the lower-case let- ters refer to the nodes of the search tree. The basic search algorithm is very simple. The problem variables {x1,...,x6} and the set of values characterizing the domain of each variable, i.e., D = (R, W, G), are put into a chosen order apriori. Following this assigned order, the algorithm tries to ﬁnd a value, compatible with the problem constraints, for each Algorithms for solving CSPs 75 1 3 5 42 6 3 42 3 1 2 1 4 1 5 4 6 5 6 2 5 4 5 1 3 3 6 2 6 {} {R} {RR} {RW} {RWR} x {RWW} x x {RWG} {RWGR} x {RWGW} {RWGWR} {RWGWW} {RWGWG} x x {RWG WGR} a bc de f gh il m n r (a) (b) Figure 4.4 Constraint satisfaction problem consisting in coloring the faces of a cube using three different colors, R, W, G, in such a way that adjacent faces cannot have the same color. (a) The constraint graph. (b) A search tree of pure backtracking. Edges tagged with “x” correspond to backtrack actions. variable. Every time a new assignment is made, the current partial solution is checked against the constraints. If one (or more) is violated, the algorithm back- tracks to the previous node and tries again with the next assignment. If a solution exists, the algorithm is guaranteed to ﬁnd it. Otherwise it will test all the possi- ble assignments before reporting failure. This basic algorithm can be made much more efﬁcient by exploiting heuristics that are applicable to any CSP (Haralick Heuristics and Elliott, 1980). The following are popular heuristics. • Variable and value reordering In general, selecting variables and values Variable and value reorderingaccording to an apriori order is not the most effective strategy. In fact, the risk of backtracking in subsequent steps can be signiﬁcantly reduced by selecting the next action on the basis of results obtained in the previous steps. A frequently used and easy to implement strategy consists in giv- ing the preference to the most constrained variables. In our graph-coloring 76 Constraint satisfaction problems example this strategy reduces to selecting the cube face whose set of al- ready colored neighborhoods is the largest. • Look-ahead The basic algorithm ﬁrst expands the tree and then checks for consistency. Many wrong choices and the consequent backtracks can be avoided by selecting values that are compatible with those already as- signed. This can be done by introducing a look-ahead step, which checksLook-ahead the constraints before expanding the tree (Frost and Dechter, 1995). Con- sidering the tree in Figure 4.4(b), according to this strategy the nodes d, e, g, i, l, n will not be generated. • Intelligent backtracking The backtracking strategy used by the basic algorithm, previously described, is called chronological backtrack, i.e., the algorithm goes back to the last choice made. It goes back further only when all the choices in the current subtree have failed. An alternative strat-Intelligent backtracking egy, developed for CSPs, consists in backtracking not to the last choice point but to an upper-level node, where the search looks more promising, thus avoiding a sequence of choices with consequent backtracks that can be predicted to be unsuccessful. This strategy is called intelligent back- tracking or back-jumping (Gupta, 2000; Prosser, 1995). 4.1.2 Constraint propagation The most powerful task-speciﬁc technique for increasing the efﬁciency of CSP solvers is constraint propagation (Tsang, 1993; Caramia and Dell’Olmo, 2002).Constraint propagation When a value is assigned to a variable it is propagated through the constraint graph, removing from the domains of the other variables values that are incom- patible with the assigned value. In this way, in subsequent steps choices cannot be made that are incompatible with the values already assigned. Of course, it may happen that the domain of a variable becomes empty, requiring the sequence of assignments already made to be reconsidered. In the example of Figure 4.4, propagating the ﬁrst value (R) assigned to variable x1 (face 1) through the constraint graph has the effect of eliminating R from the domains of the cube faces adjacent to face 1. Thus the domains of x2, x3, x4,and x5 will contain only the values W and G. After the color of x2 has been selected as W, the domains of x3 and x5 will contain only G, that of x4 still contains W and G, and that of x6 contains R and G. So, in this simple case, after a few steps the procedure reduces to a deterministic choice. In general, constraint propagation is combined with a backtracking algorithm and has the effect of reducing the need for backtracking to the case where one or more variables have an empty domain. Notice that, by limiting constraint prop- agation to the relations directly affecting a variable in the constraint graph, this Algorithms for solving CSPs 77 strategy corresponds to a look-ahead step. However, propagation through the full graph allows long-range interactions between variables to be captured, and this leads to the detection of constraint violations. A good strategy, usually adopted The most constrained variables should be selected ﬁrst. in CSP solvers based on constraint propagation, is to select ﬁrst the most con- strained variables. Finally, the constraint propagation technique can be combined with the back- tracking heuristics previously mentioned, leading to a family of hybrid search algorithms where techniques such as back-jumping can be made smarter by ex- ploiting the constraint graph (see, for instance, Prosser, 1993). 4.1.3 Local search As we have already seen for SAT, local search algorithms are quite popular and effective for general CSPs also. Usually, local search starts with a tentative assignment, which may be chosen randomly or according to some problem-speciﬁc heuristic. Then the assignment is progressively reﬁned by the elimination of constraint violations as far as pos- sible. The search process often follows a hill-climbing strategy, selecting trans- formations that minimize the number of violated constraints. When the search becomes entrapped in a local minimum, from where a consistent solution can- not be reached, a restart is made by selecting another initial hypothesis. There- fore, local search is frequently used in conjunction with stochastic algorithms Stochastic algorithms and restart for selecting the restart points. Moreover, local search for CSPs has been widely exploited in connection with evolutionary algorithms (Michalewicz, 1996)and simulated annealing (Kirkpatrick et al., 1983). One popular algorithm, which we have already mentioned for SAT at the end of Section 3.5.2 and which works very well for CSPs, is WalkSAT (Erenrich and Selman, 2003). Another algorithm, which is simple to implement and has performed extremely well on a large number of CSPs, is ChainSAT (Russell and Norvig, 2003; Alava et al., 2008). 4.1.4 MaxCSP In the previous chapter we saw a generalization of SAT called MaxSAT, which ﬁnds a partial solution minimizing the number of violated clauses. In an anal- ogous way, MaxCSP ﬁnds a solution satisfying the largest possible subset of constraints. However, in view of the wider framework set by CSPs, MaxCSP in- As many clauses as possible are satisﬁed. cludes a variety of subcases, which differ both in the problem setting and in the speciﬁc techniques developed for addressing the task. A ﬁrst remark is that most MaxCSP research has been done in the area of continuous-valued CSPs and involves linear programming. Here, constraints 78 Constraint satisfaction problems come in the form of inequalities such as xi ≤ xj . As we have already men- tioned, investigating CSPs in continuous domains is beyond the scope of this book. Nevertheless, it is worth noticing that this kind of CSP is very important for approaches to machine learning based on regularization theory and linear algebra, such as kernel machines (Shawe-Taylor and Cristianini, 2004). Never- theless, in many cases a continuous CSP can be approximated by a discrete one (Deineko et al., 2008). In MaxCSP a fundamental distinction is made between hard constraints and soft constraints. Hard constraints cannot be violated whereas soft constraintsHard and soft constraints provide options to be optimized. In other words, a solution to a MaxCSP must satisfy all hard constraints and, in agreement with them, as large a number of soft constraints as possible. The number of satisﬁed soft constraints is usually a parameter for ranking alternative partial solutions. As for SAT, many algorithms designed for CSPs can be adapted to MaxCSP. The best candidates are those based on local search and multiple restart, such as WalkSAT. Nevertheless, the literature shows that a remarkable number of spe- ciﬁc algorithms have been produced for MaxCSP. In particular, most stochastic algorithms based on genetic algorithms and simulated annealing are aimed at solving problems that ﬁt into the MaxCSP framework. 4.1.5 Constraint logic programming Constraint logic programming is a form of constraint programming in which logic programming is extended to include techniques from constraint satisfac- tion (Van Hentenryck, 1989; Jaffar and Maher, 1994). In practice, constraint logic programming is a good framework for CSPs: logic programming provides a satisfactory environment for specifying CSPs while constraint programming algorithms provide the tools for implementing efﬁcient CSP solvers (Apt, 2003; Dechter, 2003). The logic programming environment is based on Horn clauses and contains DATALOG as a special case. The classical logic programming environment is represented by Prolog. In Prolog, a logic program consists of a set of Horn clauses that, in principle, can be seen as a statement of the constraints char- acterizing a CSP. The Prolog interpreter executes a logic program that tries to solve the CSP it encodes, i.e., it tries to ﬁnd a value for each variable occurring in the clauses that satisﬁes all logical constraints. The classical interpreter is based on a pure backtracking algorithm, which operates exactly as described in Section 4.1.1. In constraint logic programming the interpreter is extended with constraint propagation techniques. However, inBacktrack algorithms this environment constraints on the variable domains are not explicitly given but Generative models for CSPs 79 may occur in the body of a clause together with other literals. The job of dis- covering and handling them is left to the interpreter. Before assigning a tentative value to a variable occurring in a clause, the interpreter scans the other clauses looking for constraints on the variable’s domain. Constraints encountered during this scan are kept in a set called a constraint store. If this set is found to be unsat- isﬁable, because some variable has an empty domain, the interpreter backtracks and tries to use other clauses to attain the goal. In practice the constraint set may be checked using any algorithm used for CSPs. Constraint logic programming is still an active research area, and the envi- ronments for constraint logic programming are becoming more and more pow- erful and sophisticated (Apt and Wallace, 2007). 4.2 Generative models for CSPs In order to investigate the emergence of a phase transition in CSPs, it is necessary to analyze a large number of problems, as in the case of k-SAT. However, now the problem of generating random CSPs is more complex. The problem space is characterized by a greater number of dimensions, and it becomes more difﬁcult to explore it systematically. For this reason many authors have proposed gen- erative models that sample restricted subspaces of the problem space in which phase transitions are detected but which are still representative of the CSPs en- countered in the real world. In the following we will consider only binary CSPs and will mostly follow Prosser’s approach (Prosser, 1996). In order to generate a random ensemble of CSPs, the stochastic construction of the problem instances must follow a precise probability model. Randomly generated (binary) CSPs are characterized by the Generating models4-tuple (n, d, p1,p2),where n is the number of variables, d is the size of the domains, which is assumed to be the same for all variables, p1 is the fraction of existing edges among the n(n − 1)/2 possible edges in the constraint graph, and p2 is the fraction of value pairs excluded by each relation Rh;again,itis assumed that each relation prohibits the same number of pairs. The parameter p1, the constraint density, may be thought of as the density of the constraint graph, Constraint density and tightness whereas p2 is the constraint tightness (Smith and Dyer, 1996; Prosser, 1996). We may notice that this generative model makes the simplifying assumption that all the domains in which the variables take values have the same cardinality d and that each relation Rh rules out the same number of value pairs. The 4-tuple (n, d, p1,p2) can be interpreted in different ways according to whether p1 and p2 are treated as probabilities or as parameters specifying exactly the number of edges in the constraint graph and the cardinality of the relations, respectively. More precisely, four models were introduced initially in the study 80 Constraint satisfaction problems of phase transitions in CSPs (Smith and Grant, 1997; MacIntyre et al., 1998; Prosser, 1996; Gent et al., 2001), as follows. Model A In this model, both p1 and p2 are treated as probabilities. MoreModel A speciﬁcally, given a number n of variables and a probability p1, let the con- straint graph G be an element of the Erd¨os and R´enyi graph ensemble Gn,p1 , as introduced in Deﬁnition 3.6. As described in Section 3.2, the number m of edges in G is a stochastic variable that follows a binomial distribution with mean m ≡ E[m]= p1n(n − 1)/2 and variance V[m]= p1(1 − p1)n(n − 1)/2.The relation between m and p1 is then p1 = 2 E[m] n(n − 1) or E[m]= p1 n(n − 1) 2 . For the second control parameter, p2, we proceed as follows: consider in turn each edge in G.Let (xi,xj ) be an edge. From the Cartesian product D × D,of cardinality d2, extract without replacement and with probability 1− p2, a number of variable assignment pairs (ai,aj ) and use them to create a table Rh(xi,xj ). This table represents the allowed assignments (ai,aj ) to (xi,xj ). Then the car- dinality N of each relation (edge) is a stochastic variable with mean (1 − p2)d2 and variance p2(1 − p2)d2. More precisely, p2 =1 − E[N ] d2 or E[N ]=(1 − p2)d2. In model A, two instances of CSPs having the same control parameters p1 and p2 will differ in the number of edges in the constraint graphs, in the identity of these edges, in the number of goods, and in their identity. Model B In this model both p1 and p2 are treated as proportions (Palmer,Model B 1985). More speciﬁcally, given a number n of variables and a number m of edges, let the constraint graph G be an element of the Erd¨os and R´enyi graph en- semble Gn,m, as introduced in Deﬁnition 3.7. In this case edges are added to G by extracting without replacement m elements from the possible set of n(n − 1)/2 edges. The relation between m and p1 will then be p1 = 2m n(n − 1) . For p2, consider in turn each edge in G.Let (xi,xj ) be an edge. From the Carte- sian product D × D, of cardinality d2, extract without replacement N variable assignment pairs (ai,aj ) and create a table Rh(xi,xj ). These pairs represent the allowed assignments (ai,aj ) to (xi,xj ). Then the cardinality N of each relation is linked to p2 via p2 =1 − N d2 . Phase transition in a CSP 81 In model B, two instances of CSPs having the same values of m and N will differ in the identity of the edges in the constraint graph and in the identity of the goods (see Section 4.1). Model C In this model, p1 is considered as a probability and p2 as a proportion; Model C p1 and N are given. The constraint graph G is built up as in model A and belongs to Gn,p1 . The relation between m and p1 is p1 = 2 E[m] n(n − 1) or E[m]= p1 n(n − 1) 2 . The relations corresponding to the constraints, however, are built up as in model B. Thus p2 =1 − N d2 . In model C, two CSP instances having the same values of p1 and N will differ in the number of edges in the constraint graphs, in the identity of these edges, and in the identity of the goods. Model D In this model, p1 is considered as a proportion and p2 as a probability; Model D m and p2 are given. The constraint graph G is built up as in model B and belongs to Gn,m. Then the relation between m and p1 is p1 = 2m n(n − 1) or m = p1 n(n − 1) 2 . The constraints are built up as in model A, and so p2 =1 − E[N ] d2 or E[N ]=(1 − p2)d2. In model D, two CSP instances having the same values of m and p2 will differ in the identity of edges in the constraint graphs and in the number and identity of the goods. 4.3 Phase transition in a CSP Using various control parameters, several studies have been performed on the emergence of a phase transition in CSPs. In particular, Prosser (1996) system- atically explored the spaces of the control parameters p1 and p2 experimentally, using model B. As mentioned in Chapter 3, the resulting CSP corresponds to a constraint graph belonging to Gn,m and p1 is a parameter controlling the emer- gence of a phase transition in the connectivity. Thus, for low values of p1 the resulting graph G may be disconnected. Particular cases occur when p1 and p2 82 Constraint satisfaction problems assume extreme values. For example, if p1 =1 then G is complete. If p2 =1 then N =0, i.e., no pairs of values are allowed and the problem instance is certainly unsolvable; on the contrary, p2 =0 denotes a surely solvable problem instance with no disallowed pairs. In the experiments Prosser used FC-CBJ-DKC-FP, a complete forward- checking algorithm with conﬂict-directed backjumping, extended with directedProsser’s experiments k-consistency and the fail-ﬁrst heuristic (Prosser, 1996). He generated sets of problems (20, 10,p1,p2) with n =20 variables and uniform domain size d =10. The values of p1 ranged from 0.1 to 1 in steps of 0.1, whereas the values of p2 ranged from 0.01 to 0.99 in steps of 0.01. For each pair of p1 and p2 values, 100 problems were generated. Globally the experiments involved 99 000 problems, with a ratio 1.27 of solvable and unsolvable problems. The experiments were performed by varying the p2 values for each p1 value. Prosser measured the complexity of the search by the number of consistency checks; when p1 =0.5 he found that the search complexity showed a marked increase around p2 ≈ 0.30, reached a maximum at p2 ≈ 0.38, and then de- creased again (see Figure 4.5). In the region 0.35 <p2 < 0.41 there is a mixture of solvable and unsolv-Mushy region able problems; Smith (1994) referred to this as the mushy region.Itisinthis region that the average search effort is maximal. Unsolvable instances require, on average, a greater computational complexity at the phase transition because the whole search tree may need to be explored. As p2 is varied across the mushy region, the probability of ﬁnding a solution Psol drops from almost 1 to almost 0 (Williams and Hogg, 1994; Smith and Dyer, 1996; Prosser, 1996). The complexity involved in ﬁnding one solution (or of proving unsolvability) shows a marked peak at Psol =0.5, which is called the crossover point (Crawford and Auton, 1996; Smith, 1994). Prosser (1996) also performed experiments in which he let both p1 and p2 vary at the same time, obtaining the graphs in Figure 4.6. The p2 value corresponding to the crossover point, ˆp2,cr, is called the critical value; it is conjectured to correspond to an expected number of solutions roughly equal to 1 (Williams and Hogg, 1994; Smith and Dyer, 1996; Prosser, 1996; Gent and Walsh, 1996). Its location also depends upon the structure of the constraint graph. Williams and Hogg (1994), Prosser (1996), and Smith and Dyer (1996) all derived the same estimate for the critical value of p2: ˆp2,cr =1 − d−2/p1 (n−1) =1 − d−n/m. (4.2) The estimate ˆp2,cr can be used to predict the location of the phase transition.Location of the phase transition Formula (4.2) was derived by assuming that the average number of solutions (over the set of problems) at the phase transition is 1. However, the value ˆp2,cr given by (4.2) is a good predictor only for high values of p1 or for large values Phase transition in a CSP 83 50000 (a) (b) 40000 30000ChecksChecks 20000 160000 120000 80000 40000 0 10000 0 0 0.2 0.3 0.4 0.5 0.6 0.7 0.1 0.2 0.3 0.4 p2 p2 0.5 0.6 0.7 0.8 max mean median stdev min 0.9 1.0 Figure 4.5 Computational search complexity vs. p2 for the (20, 10, 0.5, p2)en- semble of CSP problems. (a) The mushy region. (b) The complexity is evaluated as the number of consistency checks made by the FC–CBJ–DKC–FP algorithm. For p2 < 0.35 all the considered problems were solvable whereas for p2 > 0.41 all were unsolvable. Reprinted from Prosser (1996) with permission. of n.If p1 is low, typically p1 < 0.3, the constraint graph is sparse and many alternative conﬁgurations may exist, loosening the correspondence between ˆp2,cr and the actual location of the phase transition. In this case the mushy region is determined by a mixture of alternative constraint graphs, each corresponding to a different crossover point. An average number of solutions equal to 1 may then correspond to a large number of unsolvable problems coupled with a small number of solvable problems with many solutions. The effect is to shift the value given by (4.2) to the right of the actual phase transition location. Other authors have used different control parameters to specify the location of the phase transition. For instance, Williams and Hogg (1994) considered an Model of Williams and Hogg 84 Constraint satisfaction problems 200000 checks (a) (b) 150000 100000 50000 1.0 p2 p2 p1 p1 0.5 0 Figure 4.6 A map of (a) search effort and (b) solubility for the (20, 10, p1,p2) problems investigated by Prosser. Reprinted from Prosser (1996) with permission. ensemble of problems characterized by the 4-tuple (n, d, m, N ′),where n, d, and m have the same meaning as previously whereas N ′ is the number of no- goods per constraint, i.e., N ′ = d2 − N . These authors suggested that the phase transition occurs when the ratio β between the total number of local nogoods (conﬂicts between a pair of variables) and the number of variables assumes a critical value. The parameter β can be expressed in terms of p1 and p2 as β = (d2 − N )m n = 1 2 p1(n − 1)p2d2. (4.3) The critical value βcr was given by Williams and Hogg (1994): βcr = − ln d ln(1 − d−2) . (4.4) Phase transition in a CSP 85 The value βcr can be rewritten in terms of p2 as follows: βcr = −p2d2 ln d ln(1 − p2) , (4.5) When β = βcr,thevalue ˆp2,cr can be inserted into both (4.3)and (4.5), giving 1 2 p1(n − 1)ˆp2,crd2 = −ˆp2,crd2 ln d ln(1 − ˆp2,cr) . (4.6) By simplifying (4.6) and solving with respect to ˆp2,cr, we obtain ln(1 − ˆp2,cr)= 2 p1(n − 1) ln ( 1 d ) . (4.7) and ﬁnally ˆp2,cr = d−2/p1 (n−1) =1 − d−n/m. (4.8) Expression (4.8) is the same as (4.2). Gent and Walsh (1996) proposed yet another parameter, κ, to quantify the Parameter κ constrainedness of the search. This parameter is deﬁned in terms of the number S of search states and the average number of solutions, Nsol: κ =1 − log2 E[Nsol] log2 S , (4.9) where E[Nsol] is the expected number of solutions existing in a search space with S states. Assuming that the phase transition occurs for E[Nsol]=1,the critical value of κ is κcr =1. For a CSP of the type considered by Gent and Walsh, formula (4.9)gives κ = − m log2(1 − p2) n log2 d . (4.10) Setting κcr =1, expression (4.2) is obtained for the corresponding ˆp2,cr. 4.3.1 Asymptotic behavior In the studies reported above the number of variables was usually kept constant, whereas the structural parameters were varied. An interesting question is what happens when the CSP’s size grows, in particular when the number of variables n →∞. In some insightful work, Achlioptas et al. (1997, 2001a) investigated the CSP ensembles generated with model B by assuming that the number of variables, n, increases. The main result is that when n →∞ the probability that a random 86 Constraint satisfaction problems instance generated by Model B is unsolvable tends to 1, provided that p2 ⩾ 1/d.Asymptotic behavior for n →∞ Thus, the authors question the claim that a “true” phase transition exists for such ensembles (except for a small region in the parameter space where p2 < 1/d). The condition p2 < 1/d is equivalent to 1 − N d2 < 1 d ⇐⇒ N> d(d − 1). More speciﬁcally, Achlioptas et al. (1997)set p1 = c/n,where c is a sufﬁciently large constant. Using the expression p1 =2m/n(n − 1) for model B one obtains p1 = c n = 2m n(n − 1) and thus np1 = 2m n − 1 = c = constant. As a consequence the number of constraints, m, must scale linearly with n. The asymptotic behavior of CSPs for increasing n was investigated also by Smith (2001), who proposed a modiﬁcation of model D in order to obtain a guaranteed phase transition in CSPs, for a speciﬁed range of p2 values. This was achieved by letting some parameters deﬁning the instances vary with n,as described in the next subsection. 4.3.2 New models In order to overcome the problem discussed in the previous subsection, new mod- els for generating CSP ensembles, which are guaranteed to exhibit a phase tran- sition even asymptotically, have been proposed. One was deﬁned by Achlioptas et al. (1997); the authors called it model E. Model E This model is speciﬁed by four parameters n, m, d, k,where n isModel E the number of variables, m the number of constraints, d the cardinality of the variables’ domains, and k the arity of the constraints (we will consider the case k =2). The CSP instances are generated by selecting uniformly, at random, and with repetition a total number of nogoods. The generation of nogoods in model E is similar to that proposed by Williams and Hogg (1994) except that repetition is allowed in model E. According to Achlioptas et al. (1997), model E is interesting when the number of constraints is m =Θ(n). However, a disadvantage of this model is that a complete constraint graph is easily generated, in which constraints have only a few forbidden pairs of values. This makes it unrepresentative of the CSPs that arise in real-world problems. Phase transition in a CSP 87 Denoting by r the ratio m/n of the number of constraints over the number of variables, and by Pk(n, r) the probability that a random instance generated by model E be solvable, the following properties can be proved. Theorem 4.1 {Achlioptas et al., 1997} For any k there exists a function rk(n) Exact phase transitionsuch that, for any ϵ> 0, lim n→∞ Pk(n, rk(n) − ϵ)=1 and lim n→∞ Pk(n, rk(n)+ ϵ)=0. Then, for all r ⩾ 0 and ϵ> 0, if lim inf n→∞ Pk(n, r) ⩾ ϵ then lim n→∞ Pk(n, r)=1. The above theorem can be used to prove that ensembles of CSP instances gen- erated according to model E indeed exhibit a phase transition. However, Gent et al. (2001) showed that things are actually more complex than that, as there are regions where model B does not suffer from the ﬂaws pointed out by Achlioptas et al. (1997) whereas model E does. In the same paper, the authors noticed also that in real-world problems it is not unusual to observe structures in a constraint graph that are very rare in random graphs. These structures may strongly affect the performances of solving algorithms. As mentioned in the previous subsection, Smith (2001) proposed a modiﬁca- Modiﬁed model Dtion of model D in which both the number of constraints m and the domain size d slowly increase with n. More speciﬁcally, let us suppose that we have generated an ensemble of instances having parameter sets (n0,m0,p (0) 1 ,p (0) 2 ).If n →∞, on the one hand the behavior of d(n) is determined by the expression d = a log n + c, where a is a constant greater than 1, the log is to the base 2,and c is a constant depending on n0, m0,and a. On the other hand, m(n) is determined by the following equation: {1 − [1 − (1 − p (0) 2 )d]m}n−1 = 1 2 . (4.11) From (4.11) the function m(n) can be derived: m(n)= log ( 1 − 2−1/(n−1)) log [ 1 − ( 1 − p (0) 2 )d(n)] . With this choice of d(n) and m(n), all instances for which p2 ⩽ p (0) 2 are satisﬁ- able with probability at least 0.5. Hence, p (0) 2 is a lower bound for the transition 88 Constraint satisfaction problems point. In order to guarantee that a phase transition occurs for all values of n,the upper bound of p2,cr must converge to a value less than 1. This last condition was veriﬁed experimentally by Smith (2001),whoalsoprovedthat p2,cr < 1 − (1 − p (0) 2 )2 . The above results, obtained by modifying model D, cannot be transferred directly to the other standard models, A, B, and C. Starting from the analysis of Achlioptas et al. (1997), Xu and Li (2000, 2006) proposed a new generative model, model RB, which is guaranteed to show a phase transition even in the asymptotic case of large n. The model has two control parameters, r and p; they have critical values rcr and pcr, respectively. For any ﬁxed value r< rcr or p<pcr, a random CSP instance, generated by model RB, is satisﬁable with probability almost 1,when n →∞.Conversely, a random CSP instance is unsatisﬁable with probability almost 1 when r> rcr or p>pcr. The critical values rcr and pcr can be computed exactly. Model RB assumes that all constraints have arity k ⩾ 2. The main departure from previous models is that the cardinality of the variables’ domains is no longer constant but depends on n: d = nα. The generation of the CSP instances is achieved in two steps, as described in the following. Model RB (Xu and Li, 2000) Step 1: Select with replacement m = rn ln nModel RB random constraints, each involving a set of k variables extracted without replace- ment from the set X. Step 2: For each constraint, select uniformly, without re- placement, a number N =(1 − p)dk of compatible tuples (goods) of values. An instance of model RB is denoted by RB(k, n, α, r, p). The parameter r> 0 determines the number of constraints m = rn ln n, the parameter p (0 ⩽ p ⩽ 1) determines the number N =(1−p)dk of allowed tuples for each relation, k ⩾ 2 is the arity of each relation, n ⩾ 2 is the number of variables, and α> 0 determines the domain size d = nα of each variable. Regarding model RB, the main results of the papers of Xu and Li (Xu and Li, 2000, 2006) is contained in the theorems that follow. Theorem 4.2 {Xu and Li, 2000} Let rcr = −α/ ln(1 − p).If α> 1/k andExact location of the phase transition 0 <p< 1 are two constants, and k and p satisfy the inequality k ⩾ 1/(1 − p), then lim n→∞ P(SAT )=1,r < rcr, (4.12) lim n→∞ P(SAT )=0,r > rcr. (4.13) Comments 89 Theorem 4.3 {Xu and Li, 2000} Let pcr =1 − e−α/r.If α> 1/k and r> 0 are two constants, and k, α, and r satisfy the inequality ke−α/r ⩾ 1,then lim n→∞ P(SAT )=1,p < pcr, (4.14) lim n→∞ P(SAT )=0,p > pcr. (4.15) For the problem instances generated by model RB it is possible to compute an average number of solutions: E[sol]= dn(1 − p)rn ln n = nαn(1 − p)rn ln n. With model RB it is possible to generate provably hard instances in the proximity of the phase transition location for all values of n (Xu and Li, 2006). 4.4 Comments Solving CSP is central to the theme of the book; relational learning heavily relies on it, as will be described in Chapters 9 and 10. Even though any ﬁnite CSP can be translated into an equivalent SAT problem, as will be shown in Section 8.4, handling CSP instances directly appears more complex than handling SAT in- stances; in the ﬁrst place CSPs have more degrees of freedom (two relevant con- trol parameters, p1 and p2, instead of just one, α, as in SAT). Moreover, several generative models with different characteristics are available. An interesting point, not yet fully analyzed,1 is the structure of the con- straint graph. Basically, in the vast majority of work this structure corresponds, with small variations, to the Erd¨os and R´enyi ensembles of random graphs (see Section 3.2), but in principle the differing underlying structures can deeply af- fect solvability. As in the case of SAT, if we consider CSP instances that are not random then the consequences may be quite different from the theoretical pre- dictions, both in terms of solvability and in terms of computational complexity. Moreover, we have to notice that statistical physics methods have been ap- plied directly to CSPs much more rarely than to SAT problems, and mainly with the aim of counting existing models. A paper that makes use of these methods is Gent et al. (1995). The authors established a (weak) link with a physical system by associating variables with multi-valued “spins” interacting through the CSP’s relations and associating the parameter κ (see (4.10)) with a kind of “tempera- ture”. They used a heuristic method called ﬁnite-size scaling to model the phase transition in CSPs. This method predicts that, at the phase transition, problems 1With some exceptions; see, for instance (Walsh, 1999). 90 Constraint satisfaction problems Figure 4.7 Example of a graph associated with a CSP problem having m =12 literals and L =15 constants. of different sizes cannot be distinguished, except for a change of scale. In other words, we have Psol = f ((τ − τcr) N (1/ν)) , (4.16) where f is some function, τ is the order parameter under consideration, and N represents the size of the system. A closer connection between a CSP and a statistical physics system might be established by associating goods with the particles in a many-body system. Comments 91 Each good corresponds to a node in a graph; the different goods (ai,aj ), sat- isfying a predicate ϕ(xi,xj ) are independent and, hence, not connected; two goods (ai,aj ) and (bh,bk) satisfying predicates ϕ1(xi,xj ) and ϕ2(xh,xk),re- spectively, are connected in the graph if the conjunction ϕ1(ai,aj ) ∧ ϕ2(bh,bk) is true. An example of such a graph is shown in Figure 4.7. Finding a solution to the CSP corresponds to ﬁnding a subgraph in this graph (see Chapter 14 for more details). The graph obtained may be quite complex and can be analyzed using statistical physics methods, as described in Chapter 12. 5 Machine learning Contents 5.1 Concept learning 93 5.2 Representation languages 106 5.3 Comments 122 In this chapter we introduce the main topic of this book, namely machine learn- ing. In order to make the book self-contained, a brief introduction to the subject is presented. The word learning is generally associated with a category of performance,Learning as in learning to play chess or learning to program computers, or with a corpus of knowledge, as in learning geometry. It also often comes in association with some mechanism, as in learning by doing, learning by explanation, learning by analogy, learning by trial and error, and so on. Learning appears under seemingly very different guises: from habituation (the reduction in sensibility or attention with the repetition of a situation or in problem solving), imitation, rote learning, discrimination (the ability to dis- tinguish one type of input from others), categorization (constructing categories from observations of the environment), to learning whole bodies of knowledge or even discovering theories about the world. Since learning (throughout evolution or through cultural and individual ac- quisition) is at the source of all behavioural and cognitive capabilities in naturalUbiquity of learning systems, as well as in many artiﬁcial ones, it is no surprise that it displays such a wide variety of appearances and mechanisms. There are, however, some com- mon aspects and ingredients that underlie many of these diverse manifestations 92 Concept learning 93 of learning. One can list at least three: • percepts • decision and actions • measure of performance An agent learns when it interacts with the world, using percepts to make decisions and take actions, and then measures its performance with the aim of improving its future decision-making process. Rote learning is the limiting case, when learning solely involves the storage of past experience in order to determine future decisions or actions. Actually, Generalization even rote learning is not possible per se since it implies by necessity some form of selection in the storage of the “raw percepts”. This in turn means that several percepts might be stored as the same “experience” even though they are actually different. Generalization, albeit in an arguably limited form in rote learning, is thus an intrinsic part of learning. This is even more so when one is considering learning to discriminate from examples, categorizing, or constructing theories about the world. One of the simplest and purest form of learning is concept learning.The word “concept” may have several meanings and deﬁnitions. In the ﬁrst place Concepts there are two approaches to deﬁning a concept, the extensional approach and the intentional approach. In the extensional approach a concept is simply a set of objects (instances) that share some properties. In the intensional ap- proach there are at least three different views. In the classical view, which goes back to Aristotle, a concept is a name corresponding to a set of nec- essary and sufﬁcient conditions. The instances are not given explicitly but they are all those objects that satisfy the conditions. This deﬁnition, well suited for mathematical concepts, is inadequate for everyday-life concepts, as Wittgenstein pointed out with the simple example of the concept of a “lemon”, for which deﬁning criteria cannot be formulated (Wittgenstein, 1954). Thus weaker deﬁnitions have been introduced. The “heuristic” view of a concept keeps only sufﬁcient conditions, whereas the “exemplar” view (Rosch, 1973; Murphy, 2002) considers a concept as a prototype, i.e., a real or virtual example characterized by the “typical” features occurring in the instances. In machine learning the heuristic view dominates the ﬁeld. 5.1 Concept learning In many learning situations a central task consists in acquiring the ability to dis- Interesting experiments on human and animal classiﬁcation in regard to toxic substances were reported by Fabre-Thorpe et al. (2001). tinguish between one class of patterns (a “concept”) and the rest of the world. Evolution has thus endowed animals with the ability to quickly distinguish 94 Machine learning predators from other living beings and to distinguish edible substances from potentially toxic substances. In most cases this discrimination capability is ac- quired through exposure to experiences felt either as positive (e.g., good food) or as negative (e.g., bringing sickness). This type of learning situation, whereSupervised learning each supposedly isolated input is associated with a response, is called super- vised learning because it corresponds to teacher-assisted environments, in which a teacher helps the learner by tagging each output. The couple (input, tagged output) is accordingly called a training instance.Training examples When the responses, or tagged outputs, can only take one of two values (pos- itive or negative), the learning task is described as concept learning. Training instances associated with a positive response are called positive examples,or ex- amples for short, while instances associated with a negative response are called negative examples or counter-examples. More formally, concept learning involves the task of inducing a Boolean function deﬁned over an input space, also called an example space and denoted by X , onto a set Y = {−1, 1} from a limited training set, denoted by SL,com- prising m learning examples (⃗xi,yi) (1 ≤ i ≤ m). Although the term “set” is conventional, these training examples may be either different examples or re- peated examples. Furthermore, they can be accessed and considered sequentially by the learner – in an online setting – or dealt with in a single sweep, as in a batch setting. One crucial difference lies in the fact that, in the former setting, at any one time the learner maintains a model of the environment and has to use this model, instead of a memory of past events, to make decisions and learn further. 5.1.1 A formal view of concept learning Most studies in inductive learning assume that the patterns that are encountered, either by the learner or the classiﬁer, are generated according to a random pro- cess, as follows. Each pattern or object belongs to class −1 or class 1 and is summarized by a ﬁnite number, say n, of measurements (generally real-valued), called features. Thus the description of a pattern is given by a feature vector ⃗x ∈X (where, most often, X = Rn). The uncertainty about the class to which an object belongs is modeled using apriori probabilities P−1 and P1 for the two classes (such that P−1 + P1 =1). To express the relationship between the class of an object and the feature vector (including the uncertainty and noise in the measurement process), it is assumed that an object in the class y ∈{−1, 1} engenders a random feature vector according to a class-conditional distribution function PX|Y (see Figure 5.1). In this setting the learning agent comes across random feature vectors ⃗x (called “observables”), which are generated according to the following two-stage Concept learning 95 P P y <x, y> Y X|Y Figure 5.1 The two-stage generation of learning examples. process. First, a random class y ∈{−1, 1} is selected using the apriori prob- abilities PY ; then the observed feature vector ⃗x is generated according to the class-conditional distribution PX|Y . The distribution over labeled patterns is thus given by PXY (⃗x,y)= PY (y) PX|Y (⃗x,y)= PX (⃗x) PY|X (⃗x,y). When acting as a classiﬁer, the agent is facing the following problem: given a realization of the measured feature vector ⃗x, to decide whether the unknown object engendering ⃗x belongs to class −1 or class 1. In this setting, a classiﬁer or decision rule is simply a mapping h : X→ Y that determines the class h(⃗x) to which an observed feature vector ⃗x should be assigned. In the context of machine In statistics a hypothesis is known as a model.learning this map is called a hypothesis, hence the notation h. We will denote by H the space of possible hypotheses. The performance of a classiﬁer can be deﬁned as the probability of error, given by ϵ(h)= PXY {h(⃗x) ̸= y}. (5.1) In general different costs can be assigned to different types of errors by In medicine it is much more costly to miss a tumor diagnosis than to make a more expensive analysis only to ﬁnd out that it was a false alarm. specifying a loss function ℓ, deﬁned as ℓ(h(⃗x),y): X× Y → R+. (5.2) The performance of a classiﬁer is deﬁned as a risk, which is an expectation over Risk. the possible events: R(h)= E[ℓ(h(⃗x),y)] = ∫ ⃗x∈X ,y∈Y ℓ(h(⃗x),y)PXY d(⃗x,y). (5.3) If the apriori probability PY and conditional probability PY|X are known Bayes’ decision rule then the optimal decision rule, in the sense that it gives the minimum probability of error (or minimum risk), is Bayes’ decision rule,1 denoted h∗ and deﬁned by h ∗(⃗x)=ArgMin y∈{−1,1} (ℓ(y, 1 − y) PYX (⃗x,y) ) . (5.4) In many situations, however, the distribution PXY is unknown or only par- tially known. It is then generally assumed that, in addition to the observed 1The Bayes error is zero when there are no two examples, belonging to different classes, that have identical descriptions. When such two examples do exist, it is clearly impossible to discrim- inate between them. 96 Machine learning vector ⃗x, one is given a training set SL = {(⃗x1,y1),..., (⃗xm,ym)}∈ (X×Y)m that is chosen according to the unknown probability distribution PXY . The basic assumption underlying learning is that all the data (both observed and unseen) are generated by the same process, which is formalized by saying that the data is sampled independently from the same (ﬁxed but unknown) probability distribu- tion (i.i.d. sampling). The i.i.d. assumption expresses the relationship needed for the induction task of inferring rules for future unseen data from the data at hand. The learning problem can be then formulated as follows. Given a training set consisting of labeled objects, assumed to be drawn i.i.d. from the unknown distribution PXY , ﬁnd a function h that assigns labels to objects such that if new objects are given then this function will label them correctly. 5.1.2 Concept learning in three questions Short of attaining a perfect identiﬁcation of the target dependency between the feature vectors ⃗x and their labels, the performance of a classiﬁer or hypothesis is measured by the risk R(h) (see (5.3)). A large part of the theory in machine learning focuses on ﬁnding conditions for constructing good classiﬁers h whose risk is as close to R∗ = R(h∗) as possible. Thus the questions that have to be answered for learning to take place are the following. 1. How should one choose an appropriate hypothesis space? 2. How should one evaluate functions in the hypothesis space? 3. How should one explore the space in order to ﬁnd a (sub)optimal hypoth- esis? The ﬁrst two questions are intimately related. Let us ﬁrst tackle the sec- ond question: on the basis of the information available after the performance of a training set has been observed, which hypothesis (or hypotheses) should be preferred? A natural and simple approach is to consider the class H of hypotheses h : X→ Y and to estimate the performance of each hypothesis on the basis of itsEmpirical risk empirical performance measured on the learning set. The most obvious choice to estimate the risk associated with a hypothesis is to measure its empirical risk on the learning set SL: Rm(h)= 1 m m∑ i=1 ℓ(h(⃗xi),yi), (5.5) Concept learning 97 which, in the case of binary classiﬁcation with a {0, 1} loss function, gives Rm(h)= 1 m m∑ i=1 I(h(⃗xi )̸=yi ), (5.6) where one counts the number of prediction errors on the training set. In (5.6), Iα denotes the indicator function of the condition α: Iα = { 1 if α is true, 0 if α is false. In this framework it is natural to select the hypothesis with the minimal empirical risk as the most promising one to classify unseen events. This choice criterion is called the empirical risk minimization principle and stipulates the choice of a best candidate hypothesis as ˆh ∗ = ArgMin h∈H Rm(h). (5.7) This would seem to answer the question about the so-called inductive crite- rion, i.e., how to evaluate the candidate hypotheses with respect to the learning set at hand. However, the statistical theory of learning, developed over three decades by Vapnik and co-workers (Vapnik, 1999) and ﬂourishing nowadays, has shown that it is crucial that the hypothesis space from which candidate hy- potheses are drawn should be limited in terms of its expressive power. Other- wise, in the limit one can perform rote learning, and not incur any empirical risk, but obviously without real learning as such. To adapt the classiﬁer to the training data too closely generates the phenomenon of overﬁtting, i.e., the clas- siﬁer shows good performances on the training set but behaves poorly on future, unseen, data. The studies of Vapnik and co-workers thus answer both the ﬁrst and second questions, about the choice of an appropriate class of hypotheses and about the right way to evaluate the hypotheses for inductive purposes, which must take the hypothesis space into account. Namely, one should concentrate not only on ﬁnding hypotheses that minimize the empirical risk irrespective of the hypothesis space but also take into account its capacity or expressive power. In fact, the less Capacity of the hypothesis spacediverse is H, the tighter the link between the measured empirical risk Rm(h) and the expected risk R(h) for a given sample size m. Modern inductive techniques automatically search for the best trade-off, given the training data, following either one of two approaches: 98 Machine learning + + + + + + + + + + − − − − − − − − − − − − −− − ? Figure 5.2 From a training set with examples (labeled +) and counter-examples (labeled −), the learner tries to ﬁnd a partition of X that discriminates between the patterns ⃗x (shaded region) that belong to the target concept and those that do not belong to it. • Model selection,2 whereby induction is considered as an alternating two- step process, in which a hypothesis space Hi is chosen and then a best hypothesis ˆh∗ i ∈Hi is found, this procedure being repeated until a hy- pothesis space with lowest total error (estimation plus approximation) is found. • Regularization, where one looks for a hypothesis directly minimizing a combination of the empirical error and a term depending on the capacity of H (or sometimes depending on the complexity of h). We now turn to the third question: how to search effectively for a good hy- pothesis in the hypothesis space. 5.1.3 Searching the hypothesis space Recall that concept learning consists of ﬁnding, within an example space X ,a region containing all and only the instances of the concept to be learned, using in- formation provided by the learning set SL = {(⃗x1,y1), (⃗x2,y2),..., (⃗xm,ym)}. The concept to be learned is called the target concept. In the ideal case the ex- amples are not corrupted by noise and the description language is rich enough that no example and its counter-example share the same description. In this case the desired region must include all examples (those with label y =1) and must not include any counter-examples (those with label y = −1). One says that the region must cover the examples and must exclude the counter-examples (see Figure 5.2). 2In the recent proposal called ensemble learning, hypotheses are not selected but combined. However, such a method is not considered in this book. Concept learning 99 + + + + + + + + + + − − − − − − − − − − − − −− − hx H ? Figure 5.3 Using a hypothesis space H. Each element h, or hypothesis, of H is associated with a partition of X . Of course, except in special cases, one is not interested in learning a concept deﬁned in extension, that is by enumerating (if indeed this is possible) all its el- ements. One rather looks for some description of the concept in a representation language LH that deﬁnes a hypothesis space H. In this case, concept learning becomes the search for an expression in LH, i.e., for a hypothesis h ∈H that describes a partition in the example space X (see Figure 5.3) that best ﬁts the training set. In the case of a {0, 1} loss function, concept learning corresponds to searching in H for a hypothesis (and hence a partition of X ) that, as far as possible, “covers” all positive training examples and excludes all negative training examples, therefore incurring minimal empirical risk. A hypothesis associated with a subset of X that includes every positive example is said to be complete, while it is said to be correct if it excludes every negative example. When a hypothesis space is available, the search for a partition in X is per- formed through an exploration of H. Indeed, by modifying the expression of a candidate hypothesis, one obtains new hypotheses associated with new partitions of X . In this way, learning becomes the art of searching the hypothesis space in order to identify a hypothesis that has a minimal, or near minimal, empirical risk. Using a hypothesis space has several advantages. 1. First, concepts are handled intensionally rather than extensionally (see the start of Section 6.1), which is more practical, and more helpful, in inter- preting the hypothesis if the language is well chosen. 2. Second, since it is usually the case that not every partition of X is express- ible in the representation language LH, induction comes naturally. Indeed, one can no longer be satisﬁed with rote learning of the positive instances; one must look for the hypothesis associated with the partition closest to the available data. In a sense the more constrained the hypothesis language, 100 Machine learning the larger the necessary inductive leap. Of course, if the hypothesis space is not well attuned to the target regularities then induction cannot come up with satisfactory hypotheses. 3. Finally, the hypothesis space can offer structures that may (or may not) be of help in conducting a systematic and efﬁcient exploration of H. To look into the third point in more detail, let us suppose that, at time t,the learner is not satisﬁed with its current candidate hypothesis ht; how, then, should it choose another hypothesis? It is at this point that the existing structures on H can play a determining role with regard to the efﬁciency of the learning process. The richer and the more attuned to induction are these structures, the easier be- comes an efﬁcient exploration of H. Let us examine three possible cases, each corresponding to an increasing degree of structure in H. • The hypothesis space is not endowed with any apriori topology or metric. In this case only a random exploration is possible. There is nothing to guide the search. This is the worst-case scenario. • The hypothesis space is endowed with a neighborhood relationship.Itis then possible to explore H using gradient-like optimization techniques. The learner explores the neighborhood of the current hypothesis (either by something akin to differentiation, if H allows for this, or by the enumera- tion of neighbor hypotheses) and selects the direction of greatest gradient of a given criterion. This technique is very popular since it can make use of general optimization procedures. Most hypothesis spaces lend themselves to the deﬁnition of a distance and therefore of a neighborhood. However, one fundamental problem is to identify a relevant neighborhood relation- ship. A badly informed choice can mean that the learner goes away from the best area in the hypothesis space. Furthermore, this is still a weak struc- ture, which, except in special circumstances (the differentiability, convex- ity, and other helpful properties of H) does not yield to a fast and thorough exploration of the hypothesis space. • In some cases, it is possible to endow the hypothesis space with a stronger structure, making it possible to organize its exploration efﬁciently. This is, in particular, the case where there are partial orderings of the elements of H induced by a generality relationship between hypotheses. In this case it becomes possible, for example, to modify an erroneous hypothesis either by specializing it just enough that it no longer covers the offending neg- ative examples or, conversely, by generalizing it just enough that it cov- ers the positive examples so far excluded. This type of partial ordering, Concept learning 101 + + ++ + cover( t) cover( +1) X h t t t h h h +1 H Figure 5.4 The inclusion relation in X induces a generality relation in H.Here ht+1 ≼ ht. The circles denote negative examples and the crosses denote positive examples. induced by generality relationships, does not come naturally with every hypothesis space. For instance, if one uses a hypothesis space induced by the possible weight values of a neural network then there is no known way to decide easily whether one hypothesis is more general than another. However, some hypothesis languages, noticeably those based on logi- cal representations, lend themselves to such partial ordering. In this case the exploration of the hypothesis space for inductive purpose is greatly expedited. 5.1.4 Hypothesis space with generality relationships Hypothesis h1 is said to be more general than hypothesis h2 (notated h1 ≽ h2) if and only if the associated subset of h1 in X (called its coverage) includes the subset associated with h2. More formally, we have the following deﬁnitions. Deﬁnition 5.1 {Coverage of a hypothesis} The coverage of a hypothesis h ∈ H, with respect to an example space X , is denoted by cover(h), and is deﬁned as the subset of X described by h. Hypothesis h is said to cover the elements of cover(h). Deﬁnition 5.2 {Generality relation in H} A hypothesis h1 is more general (or less speciﬁc) than a hypothesis h2, notated as h1 ≽ h2, if and only if cover(h2) ⊆ cover(h1). The relations ≼ and ≽ on H are illustrated in Figures 5.4 and 5.5. 102 Machine learning + + ++ + cover( +1) cover( t t ) X h +1 h h h t t H + + Figure 5.5 The inclusion relation in X induces a generality relation in H.Here ht+1 ≽ ht. The circles denote negative examples and the crosses denote positive examples. The inclusion relation deﬁned over X induces a generality relation over H, which is a partial order relation. The partial order relation induces a lattice struc- ture over H. This means that, for any pair of hypotheses hi and hj , there exists at least one hypothesis which (a) is more general than both hi and hj and (b) can- not be made more speciﬁc without losing this property. The set of such hypothe- ses is called the set of maximally speciﬁc generalizations of hi and hj , denoted msg(hi,hj ),orthesetof least general generalizations, denoted lgg(hi,hj ). Likewise, there exists a non-empty set of hypotheses that are more speciﬁc than hi and hj and that cannot be generalized without losing this property. This set is called the set of maximally general specializations of hi and hj and is denoted mgs(hi,hj ). It is easy to extend these deﬁnitions to the case of sets of hypotheses that are larger than pairs, and we then obtain the sets lgg(hi,hj ,hk,...) and mgs(hi,hj ,hk,...). Finally, we assume3 that there exists in H a hypothesis that is more general than all others (called the maximal element), denoted ⊤, and a hypothesis that is more speciﬁc than all others (called the minimal element), denoted ⊥ (see Figure 5.6). However, one should be aware that the regularities existing in X do not, in general, translate completely to the hypothesis space H deﬁned by the language LH. For instance, the least general generalization (lgg) and the most general specialization (mgs), are not, in general, uniquely deﬁned. 3This assumption is valid in general. Concept learning 103 hi hj msg (hi, hj) mgs (hi, hj) ⊥ H Figure 5.6 A schematic and partial view of the generalization lattice induced on H by the inclusion relation in X . Each arrow corresponds to a generality relation ≼ between a pair of hypotheses (crosses). EXAMPLE Consider the following two clauses:4 c1: p(X,Y) ← q(a,f(X)),s(t(c),Y). c2: p(b,Z) ← t(Z),q(Z,f(b)),s(t(c),Z). Lower-case letters stand for constants and capital letters stand for vari- ables. The lgg of c1 and c2 is the following clause: c: p(X,W) ← q(Z,f(X)),s(t(c),W) The inclusion relation in X and hence the generality relation in H are clearly of fundamental importance for induction. Indeed, it is natural to want to ex- tend a subset of X that does not cover a positive instance and, conversely, to shrink a subset if it erroneously covers a negative instance. In terms of the hy- pothesis space, one needs either to generalize or to specialize an unsatisfactory hypothesis. 4The “typewriter” font is often used in the machine learning context for logical formulas and predicates. 104 Machine learning The inclusion relationship in X induces a generality relation in H, but this correspondence is actually used in the opposite direction: we work from the gen- erality relation in H and derive inclusion in X . Indeed, the whole point of using a hypothesis space is to be able to manipulate expressions in LH directly, to pro- duce new hypotheses and therefore to explore H. The question then becomes: what (easily carried out) syntactic manipulations in LH correspond to an inclu- sion relation in X ? In other words, what kind of syntactic operator on LH is guaranteed to be associated with an inclusion relation in X when used on an ex- pression in H? It turns out that this question can become quite tricky, depending on the hypothesis language that one is using. In the following example we will illustrate this point in the framework of a hypothesis language based on proposi- tional logic. EXAMPLE Let us suppose that the description language of the hypothesis space is constructed from conjunctions of attribute values in a Boolean represen- tation. For instance, red ∧ noisy ∧ fast could be a description of a car (where the symbol ∧ is to be understood as a logical conjunction). The expression red ∧ fast, obtained through the operation of drop- ping a conjunct (here noisy), corresponds to a more general hypothesis, since its associated coverage in X encompasses the coverage of red ∧ noisy ∧ fast. In the language of propositional logic it is easy to check that the operator “drop a conjunct” is a generalization operator. Many other such syntactic op- erators, that are similarly associated with generalization (or conversely special- ization) relations, are known in propositional logic. It is important to note that usually these operators do not allow all existing inclusion relations in X to be generated. In an analogous way, the language LH does not usually allow one to describe every subset of X . The hypothesis language and its associated syntactic operators thus imply a bias on what is expressible within H. As noted before, this is a necessary limitation if induction is to be possible at all; it may carry the price of having an ill-tuned language for the universe at hand. 5.1.5 Learning in a hypothesis space with a generality relationship Once a generality lattice is available on H, induction can be tightly controlled and therefore made efﬁcient. As was suggested earlier, one approach would be to start with some hypothesis in H, possibly generated at random, and then to use operators to produce new, more general (more speciﬁc), hypotheses as long as positive instances (negative instances) are not covered (are covered) by the Concept learning 105 current candidate hypothesis. Indeed, this is what Tom Mitchell considered as a possibility when he started his Ph.D. in 1976, working on ways to learn in the framework of expert systems (Mitchell and Schwenzer, 1978). However, he soon realized that a more systematic method was possible and to be preferred. Let us start with a hypothesis that is just a maximally speciﬁc generalization of a given example. This can be made very easy if the description language of the examples is part of the hypothesis language, LX ⊂LH. In this case (known as the single representation trick), the maximally speciﬁc generaliza- Representation trick tion of any example is unique and is just this very example. In any other case, the principle is to consider the other positive instances of the training set and, each time any example is not covered by a candidate hypothesis, a generaliza- tion operator is applied so as to produce the maximally speciﬁc generalization msg(ht, ⃗xt+1) of the current hypothesis, ht, and the positive instance currently considered, ⃗xt+1. In fact, at least in principle one could envision the possibil- ity of generating in a breadth-ﬁrst strategy every element of H that is part of msg(P),where P is the subset of all the positive instances in the training set SL. Indeed, if the training data is not noisy (i.e., corrupted by description er- rors), if the language LX is sufﬁciently complete for the learning task, and if the hypothesis language LH is adequately biased then one can be certain that the tar- get concept is at least as general as an element in msg(P) (also called the S-set; see below). Indeed, the target concept must at least cover every positive training instance. Of course, it could be more general than the elements in msg(P) but it should not, if possible, cover negative instances of the training set. All generalizations of P must therefore not be so general as to cover any element of the subset N of all negative training instances. Let us call mgg(P) (also called the G-set)theset of hypotheses that both cover all positive training instances and are maximally general without covering any negative training instances. Then all hypotheses that are both more general than at least one element of msg(P) and more spe- Version space ciﬁc than at least one element of mgg(P) are potential candidate hypotheses to approximate the unknown target concept. This set is called the version space VSH(SL) associated with the training set. Besides being one of the ﬁrst to point out this view of supervised induc- tive learning, Tom Mitchell made a further contribution by discovering that the version space could be bounded by two sets when a generality relationship is available that guarantees the convexity of H. These are, on one hand, the so- called S-set, the set of all hypotheses that are maximally speciﬁc generalizations of the positive instances P and do not cover any negative instance and, on the other hand, the so-called G-set, the set of all maximally general generalizations of P that do not cover any negative instance. Every hypothesis of the version space must lie between these two bounds, i.e., it must be more general than at 106 Machine learning least one element of the S-set and be more speciﬁc than at least one element of the G-set. Tom Mitchell provided an algorithm, the candidate elimination algorithm, that was able to maintain the S-set and the G-set while the elements of the train- ing set were given in an incremental manner to the learner (Mitchell, 1982). However, even given this ingenious idea, of deﬁning the whole space of solu-Candidate elimina- tion algorithm tions simply by maintaining the S-set and the G-set, this is not always practical because of the sheer size these bounding sets sometimes have. One is then con- demned to explore only a subpart of the hypothesis space at any one time. Still, it is of interest to organize this search by either moving from the most speciﬁc hypotheses to more general ones, until one must stop in order to avoid covering negative training instances (the so-called speciﬁc-to-general or bottom-up strat- egy), or by moving from the most general hypotheses and specializing them in order to exclude negative instances while still covering the positive ones (the so-called general-to-speciﬁc or top-down strategy). Most learning algorithms that exploit generality relations in the hypothesis space H are implementations of either of the above strategy or even of a com- bination of both, such as the candidate elimination algorithm (Mitchell, 1977). 5.2 Representation languages There are not many representation languages for which generalization and spe- cialization operators are known. The languages most used in machine learningLanguages for machine learning are propositional logic, ﬁrst-order logic,and grammars. These representation languages are important in machine learning and, more widely, in artiﬁcial intelligence since they have three desirable properties. 1. A generality relation exists that guides the search in the hypothesis space for supervised learning. 2. They offer a natural interface with prior knowledge. More speciﬁcally: • they produce expressions (hypotheses) that are readable and gener- ally easy to interpret, in contrast with, for instance, neural networks or support vector machines (SVMs), • they allow one to (easily) incorporate domain knowledge to help learning, for instance under the form of rules. 3. They have an expressive power that allows them (in particular, ﬁrst-order logic and grammars) to express complex relationships in the world. Representation languages 107 b c d e f g h Attributes of the learning events {a, b, c, d, e, f, g, h, . . .} Shape : {square, rectangle, triangle, circle, ellipse} Hatched : {YES, NO} Length : real Height : real P N Classes {P, N } a Figure 5.7 Examples (a–h) of propositional learning events. Class P is deﬁned to contain a–d and class N is deﬁned to contain e–h. There exists a very large literature about these representation languages. This section just aims at providing the basic notions that are necessary to understand the rest of the book. 5.2.1 Propositional representation A language representation offers support for the representation of facts and rules about the world, as well as for reasoning facilities enabling one to infer new facts and rules from the current state of knowledge and, possibly, from new infor- mation gathered from the world. One of the simplest representation languages, Propositional logic where representation and reasoning can be well deﬁned and be speciﬁed with a truth theory, is propositional logic. The simplest case considered in concept learning occurs when every learn- ing event (also known as a learning example or training example), i.e., the arrival of some perceptual data from the external world, is a single item that is indepen- dent of other such items. Every event is characterized by a set of properties or attributes, which can be qualitative, such as shape and color, or quantitative, such as weight, density, and so on. Some examples of learning events of this type are provided in Figure 5.7 where a two-class classiﬁcation problem is reported. 108 Machine learning Learning event Shape Hatched Length Height Class a rectangle 1.5 2.3 P b circle 1.5 1.5 P c triangle 3.0 1.5 P d circle 2.2 2.2 P e square 3.0 3.0 N f ellipse 1.5 3.0 N g rectangle 3.5 1.0 N h triangle NO NO NO YES NO YES YES NO 1.3 2.5 N Figure 5.8 Tabular representation of the attributes of the learning events illus- trated in Figure 5.7. The upper row contains instances of the positive class (P) whereas the lower row contains negative instances (N ). The induction problem consists in ﬁnding a function discriminating the positive from the negative class, i.e., a function that can predict the class value when this is unknown. Representation with ⟨attribute, value⟩ vectors The most immediate representation for learning events of the type in Figure 5.7 is the so-called ⟨attribute, value⟩ representation, i.e., a list of pairs whose ﬁrst item is the attribute name and second item is the attribute value. If, as frequently happens, all objects are characterized by means of the same attribute set then this representation form leads to a tabular encoding of the learning events, as is shown in Figure 5.8, which tabulates the learning events in Figure 5.7 according to their attributes. This form of tabular representation is found naturally in many data-mining applications, where data comes from relational databases. Concept descriptions as and/or Boolean expressions Let us now consider the problem of selecting a class of functions (hypotheses) able to discriminate the positive from the negative instances. We can individuate three major classes of functions: 1. Boolean functionsClasses of functions 2. continuous functions 3. probability distributions Boolean functions are typically used together with algorithms for learning rules, or decision trees, whereas continuous functions are typically encoded using Representation languages 109 neural networks or other mathematical approximators. Probability distributions are continuous functions that are explicitly trained in order to approximate prob- abilities. As continuous functions and probability distributions are outside the scope of this book, we will restrict the discussion to Boolean functions. Independently of the way in which they are encoded (by rules or by decision trees), Boolean functions can always be reduced to a disjunctive normal form (a disjunction of conjunctions) of conditions on the attribute values. Referring to Figures 5.7 and 5.8, a possible deﬁnition of the class P is P :: (Hatched = NO) ∧ (Height ≤ 2.3) ∨ (Shape = circle), (5.8) which perfectly discriminates the positive instances from the negative instances. In general, a Boolean function is a mapping A1 × A2 × ... × An →Y (5.9) from the space deﬁned by the attribute set to the space of possible concepts. It is easy to verify that, in the case of real-valued attributes, the space of Boolean formulas is inﬁnite, since the set of possible conditions that can be set on any real attribute is inﬁnite. Nevertheless, even in the case of discrete values or categoric attributes, the size of the hypothesis space deﬁned by the class of Boolean functions can be very large. However, effective algorithms exist that are able to ﬁnd good approximate hypotheses. Finally, we observe that the language in expression (5.8) uses notation typical of propositional logic. In fact, propositional logic provides a formal framework for handling Boolean functions that has been used by many authors. Covering test in propositional logic In Section 5.1.4 the notion of the coverage of a hypothesis h, namely cover(h), was introduced. Figures 5.4 and 5.5 illustrated its links with the “more general than” relation (Deﬁnition 5.2) between hypotheses. Clearly, this notion is bound to play a fundamental role in learning; therefore, providing a procedure to com- pute the coverage of a hypothesis is central to the search for good hypotheses. The computation of cover(h) can be reduced to the repetition over all avail- able examples of the following task: given a hypothesis h and an example e, does e verify h or, con- Matching problem or covering testversely, is h true on e? The above task is called the matching problem or covering test. As it turns out, the matching problem has an efﬁcient solution in propo- sitional logic. In order to go into more detail let us consider a rather general 110 Machine learning form for representing a concept in propositional logic, namely, disjunctive nor- mal form (DNF). A propositional formula h in DNF is a disjunction of conjunc-DNF representation tions γi of assertions cj specifying attribute values of the concept instances: h = γ1 ∨ γ2 ∨ ··· ∨ γk, γi = c1 ∧ c2, ∧··· ∧ cri (1 ⩽ i ⩽ k). Any other representation in the propositional framework can be translated into DNF with a time complexity linear in the number of assertions. Given the con- cept description h and an object o to be classiﬁed, we say that o is recognized (classiﬁed) as a positive instance of the concept if its own description veriﬁes h. To this end, it is sufﬁcient that the description of the object satisﬁes at least one of the conjunctions γi. The process of comparing the assertions in h with those describing o is called the matching problem. EXAMPLE We will consider the instances in Figure 5.7 and their representation as ⟨attribute, value⟩ vectors tabulated in Figure 5.8.Let h be the formula h = γ1 ∨ γ2 with γ1 =(Dashed = NO) ∧ (Height ⩽ 2.3), γ2 =(Shape = circle). If we consider example a in Figure 5.8, it can be written as a = (Shape = rectangle) ∧ (Hatched = NO) ∧ (Length = 1.5) ∧ (Height = 2.3). By comparing the formula h with the example description, we can see that γ2 is false for a but γ1 is true. Thus h covers a. Considering example g = (Shape = rectangle) ∧ (Hatched = NO) ∧ (Length = 1.3) ∧ (Height = 2.5), we see that neither γ1 nor γ2 are true. Thus, h does not cover g. Now that the example above has given us an intuition of how the covering test can be effectively computed, we can describe how the matching problem can be approached, in general, within propositional logic. Examples in ⟨attribute, value⟩ form can be translated into a set of ground assertions, each corresponding to an atomic test, that possibly occur in a hy- pothesis h. Thus an atomic test consists of checking the value of an attribute. The hypothesis h, plus the assertions obtained from an example e,represent a propositional theory. Resolution (see Section 5.2.3) can be used to check the consistency of the theory. If it derives false then h does not cover e;otherwise, h covers e. Representation languages 111 We note that atomic tests are nothing other than Boolean variables, which assume the value true or false depending on the value of the corresponding at- tribute in e. The covering test for a hypothesis has a complexity that is linear in the number of attributes and in the number of instances to be classiﬁed. However, if the framework is extended to include full propositional logic, the covering test complexity may become exponential. For instance, this happens when concepts are deﬁned not by a single rule but by means of a theory, which is constructed incrementally. In this case, logical deduction may need to construct a refutation tree having a size that is exponential in the number of clauses. For the sake of simplicity, in this book we will always consider the simpler procedure described earlier (and applied in the example above) when performing a covering test. 5.2.2 Relational representation In the previous sections concept learning was deﬁned in the framework provided by propositional logic, where a concept corresponds to a propositional assertion on a single object, which may be true or false depending on the values of its attributes. Here we will discuss how concept learning can be extended to the First-order logic more general framework of ﬁrst-order logic (FOL). More speciﬁcally, a concept will be made to correspond to a relation involving several objects, for which speciﬁc requirements must be satisﬁed. An example of a concept is the relation x is the boss of y, which, in order to be veriﬁed, requires a set of other relations involving x, y, and possibly other entities to be veriﬁed as well. These could be, for instance, x and y work in department z, x is the director of z,and yisa programmer. As we will see in the following, the extension to ﬁrst-order logic is not trivial: its impact on the complexity of the learning task can be dramatic. INDUCE, developed by Michalski (1983), represents the ﬁrst attempt at de- veloping a learner in ﬁrst-order logic. Later, other programs adopting the same The origin of FOL learningframework as INDUCE appeared; these include ML-SMART (Bergadano et al., 1988)and FOIL (Quinlan, 1990). Finally, a radical boosting of the ﬁeld occurred owing to the birth of the so-called inductive logic programming (ILP) approach (Muggleton and Feng, 1990; Muggleton, 1991), which was followed by a large output of publications. 5.2.3 The problem setting In Section 5.2.1 we saw how, in the propositional setting, learning events can be represented as ⟨attribute, value⟩ vectors, collected into tables. Starting from the propositional framework we will now introduce the relational framework. More 112 Machine learning b d a c (a) Ee x y a b c d on(x,y) x y a c a d left(x,y) b c b d (b) x a c b c left(x,y)∧ on(y,z) d d y z (c) Figure 5.9 (a) A block-world instance e, composed of four objects, a, b, c, and d. (b) Tables describing e when the description language contains only two predicates, namely on(x, y) and left(x, y). (c) Substitutions for x, y, z satisfying the hypothesis h(x, y, z) = left(x, y) ∧ on(y, z). More precisely, h(a, c, d)= left(a, c) ∧ on(c, d) is true in e. speciﬁcally, a learning event becomes a complex scenario where many objects may exist on which relations may be deﬁned. In this framework concept learn- ing becomes equivalent to learning the deﬁnition of a new relation between the objects in the scenario and the hypothesis space becomes the space of possible well-formed ﬁrst-order formulas. Data representation as multiple ⟨attribute, value⟩ vectors A structured object is a set of elementary objects for which interdepen- dency relations may exist. Consider, for instance, the block-world scenario inStructured objects Figure 5.9(a), in which there are four elementary objects. Each object is charac- terized by a vector of attributes describing its speciﬁc features. Moreover, two re- lations (or predicates) between object pairs are deﬁned: left(x, y),and on(x, y). Extending the framework of Section 5.2.1, this scenario may be represented as a set of tables, one table for describing the objects and another for every relation (see Figure 5.9(b)). Notice that in the given example all objects are of the same type and are described by means of the same attribute vector. In general, however, the objects may have different types and so be described by different attribute vectors. Then a table needs to be given for each type. In this new framework, to extend the notion of a concept (class) introduced in the propositional framework is immediate. Deﬁnition 5.3 {Concept} A concept is an n-ary relation c(x1,x2,...,xn),Concepts where x1,x2,...,xn denote generic objects. Let e be a composite object (a scenario), containing a set of elementary objects O = {o1,o2,...,om}. Every n-tuple ⟨o1,o2,...,on⟩ built on O for which c(o1,o2,...,on) is true is a positive instance of the concept c. Representation languages 113 The relations on(x, y) and left(x, y) in Figure 5.9 can be considered as ele- mentary binary concepts. Moreover, new concepts can be deﬁned starting from them. For instance, h(x, y, z) ≡ on(x, y) ∧ left(y, z) is a new ternary concept deﬁned in terms of the two basic concepts (see Figure 5.9(c)). In the same way, other concepts of different arities can be deﬁned. For in- stance h1(x, y) ≡∃z[on(x, y) ∧ left(x, z) ∧ left(y, z)] is a binary concept, whereas h2(x) ≡∃y, z[on(x, y) ∧ left(x, z)] is a unary concept. It is immediate to verify that the table describing the concept h(x, y, z) de- ﬁned above can be obtained by means of the natural join between the tables describing on(x, y) and left(x, y). Moreover, the tables h1(x, y) and h2(x) can be obtained from the natural join of on(x, y) and left(x, y) followedbyprojec- tions onto x, y,and x, respectively. Every row in the new tables corresponds to a concept instance. The Horn clause representation language In order to deal with relations between objects, an adequate language is nec- essary. As already introduced above, relations may be described in an abstract way through predicate calculus. As an example, let us consider the expression Restricted predicate calculuson(x, y). The symbol on(x, y) denotes a predicate with an associated table; x and y are variables ranging over all the objects existing in the scenario provided by the learning event. When the values of x and y correspond to two items oc- curring in the same row in the table associated with predicate, the predicate is true; otherwise it is false. Thus predicate calculus provides a powerful tool for describing relational concepts. However, unrestricted predicate calculus is at the same time too pow- erful and too complex for this purpose. In practice, Horn clause languages (Kowalski, 1979) (a restricted predicate calculus) are used (Muggleton, 1992). Before introducing Horn clauses we need to introduce logical clauses. Alog- Clauses ical clause is a disjunction of atomic assertions, where an atomic assertion,for which the term literal is used in the following, is a possibly negated predicate of arity n (n ⩾ 0), i.e., it is applied to n arguments. In the more general case an argument may be a constant (the name of an item), a variable,ora function.An example of a clause is provided by the logical expression p(x) ∨ q(x, y) ∨ ¯r(y, z) ∨ ¯s(z, y). (5.10) Clauses are implicitly considered as universally quantiﬁed, i.e., expression (5.10) can be rewritten equivalently as ∀x,y,z [p(x) ∨ q(x, y) ∨ ¯r(y, z) ∨ ¯s(z, y)]. (5.11) In other words, a clause is true if it is true for any value that can be assumed by the variables occurring in it. 114 Machine learning Clausal representation plays a fundamental role in automated deduction. On the one hand, any set of logical equations in ﬁrst-order predicate calculusHorn clauses can be translated into clausal form (see, for instance (Kowalski, 1979)). On the other hand, there exists a simple and complete deduction rule, namely resolution (Kowalski, 1979), which is suitable for implementation in automated reasoning systems. However, the logical languages used in automated reasoning are usu- ally based on Horn clauses; as mentioned above these are a restricted form of clausal representation. A Horn clause is a clause in which at most one literal is not negated. An example of Horn clause is the logical expression:An equivalent notation for Horn clauses, easier to compile for an automated program, consists in replacing the symbol ∧ with a comma, and the symbol ← with :-. p(x) ∨ ¯q(x, y) ∨ ¯r(y, z) ∨ ¯s(z, y). (5.12) By remembering that a logical expression of the type ¯p ∨ q is equivalent to p → q, where the symbol → denotes a material implication, expression (5.12) can be rewritten as: p(x) ← q(x, y) ∧ r(y, z) ∧ s(z, y), (5.13) which is the most popular format for Horn clauses. For such clauses, the resolu- tion inference rule can be simpliﬁed with respect to its general form, leading to more tractable implementations. Moreover, the resolution rule can be “inverted” (inverse resolution,see Muggleton, 1992; Muggleton and Buntine, 1988), pro- viding an automated induction schema. For the above reasons, Horn clause lan- guages are those most frequently used in relational learning and inductive logic programming. An attractive property of Horn clause languages is that they offer a homogeneous framework for describing learning instances, background knowl- edge, and concept deﬁnitions. Multiple vector representations are mapped to sets of ground assertions We have seen how structured objects can be described by means of a set of relational tables (see Figure 5.9). It is immediate to represent tables as sets ofMultiple vector representation ground Horn clauses, i.e., clauses whose terms are only constants: every row in a table is mapped into a ground clause. As an example, the tables headed on(x, y) and left(x, y) in Figure 5.9 can be described by a set of ground clauses as follows: on(a, b) ← true, on(c, d) ← true, left(a, c) ← true, left(a, c) ← true, left(b, c) ← true, left(b, d) ← true, where every table row deﬁnes a ground assertion stating that the speciﬁc relation is true for the tuple of objects in the row. Representation languages 115 a b c d a b c d a b c d e d e c a ba b c d e a b d e f f (a) (b) (c) (d) (e) (f) Figure 5.10 Six relational learning events, each based on a combination of ob- jects labeled a, b, ... Concept deﬁnitions are mapped to sets of clauses In Section 5.2.1 we discussed how concepts can be deﬁned in terms of and/or Boolean expressions. It is now immediate to verify that any form of Boolean expression can be rewritten in terms of Horn clauses in propositional logic. For instance, expression (5.8) can be equivalently written as P← (Hatched = NO) ∧ (Height ≤ 2.3), P← (Shape = circle). The same formal structure can be used in ﬁrst-order logic to provide deﬁni- tions of relations. A conjunctive deﬁnition can be stated through a single clause. For instance, considering the example in Figure 5.9, a new relation left-on(x) can be deﬁned by means of the clause left-on(x) ← on(x, y) ∧ left(y, z). (5.14) The meaning of (5.14) is that any object x for which there exists another object y such that x is on y and for which there exists a third object z such that y lies to the left of z satisﬁes the relation left-on. The more powerful framework offered by ﬁrst-order logic allows different forms of concepts to be represented, corresponding to learning tasks of different complexity. We will discuss this point using a more complex example, shown in Figure 5.10, where six different scenarios are provided. Each scenario is a speciﬁc learning event containing instances of both elementary and composite concepts. 116 Machine learning The simplest form of a relational concept is one where the concept is a 0-arity relation, which may be true or false in a given scenario depending on the rela- tionships between the elementary objects it contains. Referring to Figure 5.10, an example of 0-arity concept may be the assertion “an arch is present”. To de- cide whether this assertion is true or false in a speciﬁc scenario, we must verify whether it contains a set of objects realizing an arch. A possible deﬁnition for this concept could be: “an arch is present” ← grounded(x) ∧ grounded(y) ∧ on(z, x) ∧ on(z, y). (5.15) We recall that variables occurring in the head (left-hand side) of a Horn clause are universally quantiﬁed, whereas those occurring only in the body are existentially quantiﬁed. Thus deﬁnition (5.15) will be true of a given scenario if it contains at least three objects such that, when substituted to for the variables x, y,and z, verify the conditions stated in the body. Referring to Figure 5.10, we can see that in scenarios (a), (b), (c), (f) there is a unique triple of objects satisfying deﬁnition (5.15). In scenario (d), the deﬁnition is veriﬁed (satisﬁed) by two different triples (a, b, d) and (b, c, e), whereas in scenario (e) deﬁnition (5.15) is not veriﬁed because no single object is simultaneously on both a and b. In the following we will return to this point and discuss how to exploit the ﬁrst-order framework to deal with the more general arch instance in (e). In the case of relations with arity greater than 0, concept deﬁnitions are more informative. More speciﬁcally, the components that realize the concept instance can be explicitly identiﬁed. For instance, the concept deﬁnition arch(x, y, z) ← grounded(x) ∧ grounded(y) ∧ on(z, x) ∧ on(z, y) (5.16) explicitly identiﬁes the three components of the arch. The advantage is that, when a scenario contains more than one instance, all can be identiﬁed. As an exam- ple, in scenario (d) of Figure 5.10, deﬁnition (5.16) will ﬁt the two instances arch(a, b, c) and arch(b, c, e). The consequence is that the implicit assumption made by many learning algorithms that a scenario either provides a positive or a negative example of the target concept no longer holds. In principle, a scenarioPositive and negative examples may provide many positive examples of the target concept. Moreover, the notion of a negative example is deﬁned in a different way: any substitution of the vari- ables in the target relation by object names that do not satisfy the body of any clause of the concept deﬁnition is implicitly a negative example. For instance, in scenario (a) of Figure 5.10 the triples (a, c, d), (b, c, d), (a, b, d), etc., are nega- tive instances of the concept arch(x, y, z), according to deﬁnition (5.16). Since negative concept instances grow combinatorially with the number of elementary objects in a scenario, they are implicitly deﬁned making the so-called Representation languages 117 closed-world assumption (Kowalski, 1979): any instance not explicitly declared positive is to be considered as negative. Therefore, dealing with n-arity relations requires learners more powerful than those suitable for 0-arity concepts. In fact, such learners must be able to deal with the presence of multiple instances in a single scenario and with the closed-world assumption. Let us consider again the problem of learning concept deﬁnitions involving a variable number of objects. It can be solved by means of recursive deﬁnitions. Referring to the learning events given in Figure 5.10 and setting a 0-arity target concept, a suitable deﬁnition could be: “an arch is present” ← grounded(x) ∧ grounded(y) ∧ on(z, x) ∧ on(w, y) ∧ connected(z, w), connected(x, x) ← T, connected(x, y) ← adjacent(x, y), connected(x, y) ← connected(x, w) ∧ adjacent(w, y). Here the girder of the arch is deﬁned as a sequence of connected objects: two objects x and y are connected if they are adjacent or if there is a chain of con- nected objects adjacent to both of them. Moreover, an object is connected to it- self. It is immediate to verify that this deﬁnition will be satisﬁed in scenario (e) of Figure 5.10 also. However, learning recursive deﬁnitions such as that described above dramatically increases the size of the hypothesis space and requires smarter algorithms. A further requirement is to extend the framework to handle n-ary rela- tions when the objects involved in a concept are complex and contain a vari- able number of elementary components. For instance, referring to the concept arch(x, y, z), we are looking for a deﬁnition covering scenario (e) of Figure 5.10 also. Up to now we have considered only clauses in which the terms occurring in the predicates are variables or constants. In other words, we have used a function- free description language, i.e., a DATALOG language. In order to deal with composite objects we will need to use functions, thus increasing the power of the language. Referring to our simple case study, we will deﬁne a complex object by means of the composition function link(x, y),which constructs a new object connecting two simpler objects x and y. Therefore a revisited deﬁnition of arch(x, y, z) could be arch(x, y, z) ← grounded(x) ∧ grounded(y) ∧ on(z, x) ∧ on(z, y) ∧ girder(z), girder(x) ← object(x), girder(link(x, y)) ← adjacent(x, y) ∧ object(x) ∧ girder(y). 118 Machine learning Applying this deﬁnition to scenario (e) in Figure 5.10 will return the instance arch(a, b, link(d, link(e, f ))). However, the leap to non-DATALOG languages further increases the com- plexity of the learning task and, consequently, of the learner. In particular, as we will discuss below, the most frequently used rule for searching a hypothesis space, i.e., θ-subsumption, becomes incomplete for non-DATALOG languages. Covering test in ﬁrst-order logic In Section 5.2.1 we saw that the covering test in propositional logic can be de- ﬁned either as a deduction task in a propositional theory including both the hy- pothesis and the example description or as a task directly matching the assertions in the hypothesis and the description of the example. The deductive view can be immediately extended to the relational (ﬁrst-order logic) framework. This was in fact the initial attempt in relational learning (Quin- lan, 1990). The idea of learning that uses relational theories is very appealing and the deductive paradigm for implementing the covering test is sound within this framework. Nevertheless, in general it is too complex and becomes rapidly in- tractable as the complexity of the theory increases. Therefore, a restricted form of deduction, called θ-subsumption (Plotkin, 1970), is used in practice (Muggleton and De Raedt, 1994). In the following we will provide both a formal deﬁnition of θ-subsumption and an intuitive ex- planation of how it works; it was introduced for the ﬁrst time by Plotkin (1970). In order to provide a deﬁnition of θ-subsumption, we need to recall that a FOL formula may contain as arguments constants, variables, and/or functions; these are collectively known as terms. Then, a generic formula can be written as ϕ(t1,t2,...,tn),where the ti (1 ⩽ i ⩽ n) are terms. Formally: Deﬁnition 5.4 {θ-subsumption} Let ϕ(t1,t2,...,tn) and ψ(s1,s2,...,sm) be two ﬁrst-order logic formulas. We will say that ϕ(t1,t2,...,tn) subsumes ψ(s1,s2,...,sm) if there exists a renaming θ of the terms in ϕ and ψ that trans- forms ϕ into a sub-formula of ψ. As already mentioned, in this book only the DATALOG subset of ﬁrst-order logics will be considered. In DATALOG, which is a function-free language, terms are only allowed to be either variables or constants. In particular, a hy- pothesis h is a conjunction of predicates containing variables, whereas an ex- ample e is a conjunction of ground literals, which are either constants denoting the names of the components of e or values of the attributes characterizing these components. Then, the deﬁnition of θ-subsumption can be simpliﬁed. Deﬁnition 5.5 {θ-subsumption in DATALOG} Let h(x1,x2,...,xn) be a ﬁrst-order logic hypothesis, with variables xi (1 ⩽ i ⩽ n) and let e be an Representation languages 119 example. We will say that h subsumes e if there exists a substitution θ for the variables in h that makes h a subset of e. Notice that if ϕ(t1,t2,...,tn) and ψ(s1,s2,...,sm) are two DATALOG Subsumption and generalityformulas, saying that ϕ subsumes ψ implies that ϕ ≽ ψ, i.e., that ϕ is more general than ψ. Moreover, if h subsumes e then h can be obtained from e by dropping some predicates and turning some constants into variables in e. In general, given two formulas ϕ and ψ,the θ-subsumption between them is not univocally deﬁned because more than one uniﬁcation θ such that ϕ subsumes ψ may exist. Actually, in some cases it may be interesting to count the number of alternative ways in which θ-subsumption can be instantiated. The θ-subsumption relation offers a means to perform the covering test be- tween a hypothesis h and a learning event e or even to test the more-general-than relation. However, it is per se a combinatorial problem, as we will discuss later on. EXAMPLE Let us consider again the problem illustrated in Figure 5.9. Let h1(x, y, z)= left(x, y) ∧ on(y, z) and h2(u, v)= on(u, v) be two hy- potheses. It is immediate to see that the substitution θ = {u/y, v/z} makes h2 a subset of h1. By looking at the table in Figure 5.9(c) one can see that h1 is veriﬁed by the two tuples (a, c, d) and (b, c, d). If we project the table corresponding to h1 onto the last two columns then we obtain a single pair (c, d), whereas the hypothesis h2 is veriﬁedbythetwopairs (a, b) and (c, d). This is a conﬁrmation that h2 ≽ h1. Let us now consider again hypothesis h2 and the learning event e deﬁned in Figure 5.9(a). We would like to test whether h2 covers e. The learning event e can be written as e = on(a, b) ∧ on(c, d) ∧ left(a, c) ∧ left(a, d) ∧ left(b, c) ∧ lef t(b, d). By applying to h2 the substitution θ = {u/a, v/b} we see that h2 be- comes a subset of e. However, the substitution θ = {u/c, v/d} has the same effect. Thus in this case there are two substitutions that prove that h2 covers e. An informal but intuitive way for testing whether a hypothesis h covers a learning event e is to consider each predicate in h as a test to be performed on e. This can be done by binding the variables in h to components of e and then ascertaining whether the selected bindings verify in e the predicates ap- pearing in h. The binding procedure should be made for all possible choices of the objects in e. The procedure will stop as soon as a binding satisfying h is 120 Machine learning found, thus reporting true, or it will stop and report false after all possible bind- ings have been explored. The procedure is called, as in the propositional case, “matching h to e”. Matching h to e has the advantage that it avoids the need to translating the learning event e into a ground logical formula, as, usually, examples come in tabular form. In practice, several learners use this matchingA procedure for the matching problem approach for testing coverage (Bergadano and Giordana, 1988; Quinlan, 1990; Botta and Giordana, 1993). Moreover, matching is much more practical when used in machine learning and data mining algorithms working on databases. However, matching and θ-subsumption testing are equally computationally de- manding. Matching h and e will be the subject of Chapter 9. 5.2.4 Sequence or string representation A very important kind of datum, which is being actively investigated in the areas of machine learning and data mining, is represented by sequences. A sequence is probably the most frequent form in which data are obtained from the environment. Sequences can be seen as the output of a sequential pro- cess producing item after item according to the logic that controls its behavior. Thus sequences can also be thought of as structured objects, where a total or- der is deﬁned between the elementary objects that are output by the generative process. Therefore, in sequences it is usually assumed that an item depends di- rectly or indirectly on the previous items and, in turn, can inﬂuence the following items but not vice versa. In this sense a sequence can be seen as a special case of a structured object. However, sequences can be unlimited whereas the structured objects considered in relational learning are usually ﬁnite. In many cases the objects in the sequence are each characterized by a sin- gle attribute, which may be a real value or a symbol. In the ﬁrst case they are referred to as temporal series and in the second case as strings.Examples of temporal series are the stock market index and the continuous signals pro- duced by an analogic equipment, whereas examples of strings are written texts and DNA. In the following we will brieﬂy review the most frequently investigated su- pervised learning tasks occurring in sequences. More speciﬁcally, we will con- sider three tasks: 1. predicting a property or the value of an item on the basis of the past history; 2. identifying the process generating a sequence; 3. sequence tagging. Representation languages 121 Then we will discuss the classes of functions useful for approaching these kinds of learning task. Learning to predict a property of the next item A typical example of task 1 could be that of learning to forecast the weather to- morrow on the basis of the weather sequence observed in the recent past. Assum- ing a limit on the length of the past sequence, deﬁned as the part of the sequence that could signiﬁcantly inﬂuence the prevision for the future day, this learning problem can be reduced simply to a problem of relational learning, where the days in the considered window in the past history are the elementary objects in an environment, like those considered in relational learning. Moreover, if the window in the history has a ﬁxed size, it is not difﬁcult to imagine how the prob- lem could be further reduced to a problem of propositional learning: the window could be encoded as an attribute-value vector. Learning to identify the generative process for a sequence Many important problems related to sequence analysis can be formalized as a the multi-class classiﬁcation problem: that of identifying the process that generates the observed sequence from a set of known processes. However, it is also worth mentioning a two-class variant of this task, consisting in deciding whether a sequence belongs to a known process. In this case the negative examples can be generated by any process different from the known process. Examples of the multi-class problem are the recognition of isolated words and the identiﬁcation of a user navigating on the web. An example of the two- class problem is the authentication of a user proﬁle in fraud detection. Depending on the structure of the sequences generated by different pro- cesses, the problem of discriminating between processes can present quite differ- ent levels of difﬁculty. In the simplest cases, discrimination can be made on the basis of single items or short subsequences speciﬁc to the various generative pro- cesses. In the general case, an abstract characterization of the global generative process may be necessary. Learning to accomplish sequence tagging Given a set Y of labels, the task of sequence tagging consists in assigning a label y ∈Y to every item in the sequence. In general the label corresponds to an abstract category whose meaning depends on the speciﬁc application. In isolated-word recognition it could be a phonetic category, whereas in a DNA strand it could be the name of a protein. When the label of an item xi can be assigned on the basis of the items immediately preceding xi, the task can be reduced to simple prediction. Nevertheless, in the most general case a label may 122 Machine learning correspond to some speciﬁc phase of the generative process to be recognized. Then, sequence tagging may entail a task of process identiﬁcation. The hypothesis space Many different approaches to encoding hypotheses related to sequences have been proposed; they depend upon the speciﬁc task, the sequence format, and the errors that are possibly present. When the items are characterized as attribute vectors, prediction or tagging tasks can be undertaken using the approaches de- scribed for the relational–propositional framework. However, very different approaches are used when sequences are simply strings of symbols. Depending on the degree of noise present in the strings, three main approaches can be distinguished: 1. string matching; 2. formal language; 3. Markov chain. The string-matching approach has many variants, ranging from dynamic pro- gramming (Gussﬁeld, 1997) to string kernels (Shawe-Taylor and Cristianini, 2004), which all share the same assumption, that a string s can be attributed to a speciﬁc generative process on the basis of a set of substrings of s. In the formal language approach (Hopcroft and Ullman, 1969) it is assumed that a string is a sentence generated by an agent (automaton) speaking a spe- ciﬁc language. Then, any question related to a string can be answered by parsing the string according to the grammar governing the language of the agent. The learning task to solve is that of reconstructing this speciﬁc grammar, which rep- resents the concept to be learned. Thus the hypothesis space is that of formal languages (grammars), whose instances are the observed strings. In the literature two kinds of space have been actively investigated, those of regular languages and context-free languages. Finally, the Markov chain approach can be seen as an extension of the for- mal language approach in a Bayesian probabilistic framework (Rabiner, 1989; Durbin et al., 1998) that accounts for the noise present in the data. In Chapter 11 we will consider the formal language approach, where inter- esting discontinuous phenomena have been found. 5.3 Comments In this chapter we aimed to provide the reader with the basic notions of ma- chine learning, sufﬁcient to understand the rest of the book. Machine learning Comments 123 is a ﬁeld that includes a vast range of approaches, both numerical (neural net- works, support vector machine, statistical learning methods, etc.) and symbolic (learning rules, decision trees, logical formulas, grammars, graphs, etc.). Here, we have concentrated on symbolic learning, in particular on learning rules (both in propositional and ﬁrst-order logics) and grammars. Nevertheless, other types of learning approach will be outlined in Chapter 7, when they have connections with statistical physics. Even though most approaches to machine learning, including the learning of optimal decision trees,involve NP-complete problems, heuristic versions thereof have been quite successful in solving relevant practical problems. This is especially true for propositional approaches, where examples are not structured and can be described via a set of attributes. On the one hand relational learning, as discussed in Section 5.2.2, is much more complex and advances in this area have been slower. On the other hand, owing to its very complexity relational learning (and grammar induction) offers the best opportunities for establishing links with statistical physics, even though on the surface the two ﬁelds may ap- pear to be very far apart. These links will be illustrated in Chapters 9–11. 6 Searching the hypothesis space Contents 6.1 Guiding the search in the hypothesis space 125 6.2 FOIL: information gain 131 6.3 SMART+: beam search 132 6.4 G-Net: genetic evolution 133 6.5 PROGOL: exhaustive search 134 6.6 Plateaus 135 6.7 Comments 139 In Chapter 5 we introduced the main notions of machine learning, with particular regard to hypothesis and data representation, and we saw that concept learning can be formulated in terms of a search problem in the hypothesis space H.As H is in general very large, or even inﬁnite, well-designed strategies are required in order to perform efﬁciently the search for good hypotheses. In this chapter we will discuss in more depth these general ideas about search. When concepts are represented using a symbolic or logical language, algo- rithms for searching the hypothesis space rely on two basic features: 1. a criterion for checking the quality (performance) of a hypothesis; 2. an algorithm for comparing two hypotheses with respect to the generality relation. In this chapter we will discuss the above features in both the propositional and the relational settings, with speciﬁc attention to the covering test. 124 Guiding the search in the hypothesis space 125 6.1 Guiding the search in the hypothesis space If the hypothesis space is endowed with the more-general-than relation (as is always the case in symbolic learning), hypotheses can be organized into a lattice, as represented in Figure 5.6. This lattice can be explored by moving from more general to more speciﬁc hypotheses (top-down strategies) or from more speciﬁc to more general ones (bottom-up strategies) or by a combination of the two. Both directions of search rely on the deﬁnition of suitable operators, namely, generalization operators for moving up in the lattice and specialization operators for moving down. These operators are very important because they allow the generality relation between two hypotheses to be checked intensionally (i.e., by looking at their syntactic structures) rather than extensionally (i.e., by looking at their coverage). Once we have selected a particular kind of strategy for the exploration, we need some criterion to assess the worthiness of the hypotheses encountered. To this end we may use the loss function (5.2) or some other heuristic criterion. In general, searching for the optimum of this criterion (be it the loss function or any other) on the hypothesis lattice is exponential, since the number of nodes is exponential. Thus most learners use a greedy search, in which moves on the lattice are guided by some local optimality criterion. A search is then a path on the lattice connecting nodes that locally look the the most promising. Of course, greedy search does not guarantee that optimality is reached; usually the search ends up in some local extremum. However, greediness makes the search tractable. We are now in a position to illustrate the main approaches proposed in the literature for searching a hypothesis space, both in the propositional and in the relational settings. 6.1.1 Greedy search guided by information gain A popular method for navigating through the hypothesis space is to go top- down, starting from the most general hypothesis ⊤ of the lattice (induced by the more-general-than relation) and constructing more-and-more-speciﬁc hy- potheses via specialization operators. In the propositional framework, this is the approach used for learning decision trees or logical decision rules in DNF form. A widely used heuristic for selecting the hypotheses in the lattice is based on the information gain, which exploits the notion of entropy. The entropy of an inductive hypothesis h is deﬁned as the uncertainty about the class to be assigned to an instance ⃗x that satisﬁes h.Let Y be the set of labels denoting the possible 126 Searching the hypothesis space classes to which the examples in a set X could belong, and let yi be one of these labels. The entropy S(h) of hypothesis h is deﬁned by S(h)= |Y|∑ i=1 −pi log2(pi), (6.1) pi being the probability that an example verifying h belongs to class yi.The pi are usually unknown, but they can be estimated via the empirical frequen- cies measured on the learning set. Notice that S(h)=0 when h is true only for the examples of a single class yk. In this case, pk =1 and pj =0 for any j ̸= k. Let us consider now two hypotheses h1, h2 such that h1 is more general than h2 in the hypothesis lattice. The information gain IG(h1,h2) is deﬁned as the difference in entropy between h1 and h2: IG(h1,h2)= S(h1) − S(h2) > 0. (6.2) Intuitively, (6.2) provides a measure of the decrease in uncertainty between classes when one moves from a more general to a more speciﬁc hypothesis. Usu- ally the new hypothesis h2 is built up from the current hypothesis h1 by adding to h1 a single constraint, the one having the maximum information gain with re- spect to h1. The search stops when a hypothesis with entropy 0 is reached. Then all examples have been correctly classiﬁed. Under the assumption that the learning set SL is consistent (i.e., there is no example with multiple classiﬁcation) and that it does not contain noise (such as, for instance, some example misclassiﬁed by the teacher), the above strategy aims at ﬁnding a consistent hypothesis, i.e., one that covers all positive examples and does not cover any negative example. EXAMPLE Let us consider the construction of a decision tree from the exam- ples (learning events) given in Figure 5.7. We have the following descriptions: d =(Hatched = YES) ∧ (Shape = circle), a =(Hatched = NO) ∧ (Shape = rectangle), b =(Hatched = NO) ∧ (Shape = circle), c =(Hatched = NO) ∧ (Shape = triangle) ∧ (Height < 0.7), f =(Hatched = YES) ∧ (Shape = ellipse), g =(Hatched = YES) ∧ (Shape = rectangle), e =(Hatched = NO) ∧ (Shape = square), c =(Hatched = NO) ∧ (Shape = triangle) ∧ (Height > 0.7). Guiding the search in the hypothesis space 127 Hatched Shape Shape YES NO P circle N N ellipse rectangle PP N rectangle square circle Height triangle PN <0.7 0.7 Figure 6.1 Decision tree classifying the examples (learning events) of Figure 5.7. The bold path corresponds to the hypothesis h =(Hatched = NO) ∧ (Shape = triangle) ∧ (Height < 0.7). The entropy at the root S(⊤) is 1, because there are four positive and four negative examples in the learning set. The entropy of the right son of the root S(Hatched = NO) is 0.971, because the hypothesis (Hatched = NO) covers three positive and two negative exam- ples. Classiﬁcation occurs by letting an example go down the tree until it reaches a leaf, where it receives the label associated with it. For instance, example c follows the bold path in the tree and is classiﬁed as positive. A decision tree is a tree whose nodes correspond to attributes; the edges outgoing from a node ν are labeled with the values assumed by the at- tribute associated with ν. A hypothesis h(ν) is associated with each node ν; h(ν) is built up by concatenating the conditions found along the edges from the root to the node ν. “Within” each node ν are the examples cov- ered by h(ν). A node is a leaf when all the examples within it belong to thesameclass. In Figure 6.1 a decision tree perfectly classifying the examples (learning events)ofFigure 5.7 is shown. 128 Searching the hypothesis space From a decision tree it is easy to compile a set of decision rules: it is suf- ﬁcient to collect all the paths from the root to the leaves, and form rules that have the hypothesis on the leaf as body and the label associate to the leaf as head (classiﬁcation). From the tree in Figure 6.1 the following rules can be obtained:Decision trees can be immediately converted into propositional rules, and vice versa. (Hatched = YES) ∧ (Shape = circle) →P, (Hatched = NO) ∧ (Shape = rectangle) →P, (Hatched = NO) ∧ (Shape = circle) →P, (Hatched = NO) ∧ (Shape = triangle) ∧ (Height < 0.7) →P, (Hatched = YES) ∧ (Shape = ellipse) →N , (Hatched = YES) ∧ (Shape = rectangle) →N , (Hatched = NO) ∧ (Shape = square) →N , (Hatched = NO) ∧ (Shape = triangle) ∧ (Height > 0.7) →N . Rules can be learned directly, as well, by using algorithms explicitly designed to do so (see for instance Dietterich and Michalski, 1983; Cohen, 1995). Rules areRule learning usually learned one at a time and, each time a rule is accepted by the learner, the set of examples covered by it is removed from the learning set. The acquisition of new rules stops when all positive examples are covered. Unfortunately, this simple strategy alone does not work well in most practical cases. First, it is not optimal because the greedy search strategy is incomplete; it does not take into consideration interactions between the constraints. In fact, it is possible that the conjunction of two or more constraints, which in isolation do not show the maximum information gain, constitutes a better hypothesis than that constructed by the above strategy. Second, it is quite rare that a consistentLimits of the greedy IG heuristic learning set is available. Inconsistencies may arise from errors at the time of data collection or may be due to an apriori misclassiﬁcation on the part of the teacher who labels the examples or may be the effect of a poor choice of attributes, and so on. As a consequence, the learning set can contain examples that have the same description but different classiﬁcations. Even worse, the effect of noise on the attribute values can hide this problem, allowing two or more examples having in reality the same description to appear different only because of the noise. In these cases, the IG heuristic is likely to generate a disjunction of a number of very detailed hypotheses, each covering few examples (possibly only one). This phenomenon, well known in machine learning under the name of overﬁtting, produces hypotheses that are very good (if not perfect) on the training set but which show a poor classiﬁcation ability on previously unseen instances (poor generalization power). In order to combat this problem, the IG heuristic is usually combined withPre-pruning pre-pruning or post-pruning techniques based on other heuristics suggested by statistics or information theory. The idea of pre-pruning simply consists in re- quiring that a new, more speciﬁc, hypothesis h2 not only exhibits the maximum Guiding the search in the hypothesis space 129 IG with respect to the current hypothesis h1 but also exhibits a reduction in the classiﬁcation error for instances not belonging to the training set SL. To this end a set of examples, called the pruning set, is kept apart and used for the sole pur- pose of pre-pruning (Breiman et al., 1984). If this requirement is not satisﬁed then the specialization process stops and h1 is added to the global solution. In the case of post-pruning the greedy search algorithm constructs a detailed Post-pruning (possibly overﬁtted) solution guided by the IG heuristic only. Then the solution undergoes a simpliﬁcation procedure in which conditions not providing a signif- icant reduction in the classiﬁcation error of new learning instances are dropped. A powerful pruning heuristic is based on the minimum description length Minimum description length (MDL) principle (Rissanen, 1978). The MDL is a measure of complexity which counts the minimum number of bits necessary for describing a global hypothesis h that represents regularities in the data, plus the bits necessary to describe the data not explained by the hypothesis (the exceptions). According to this princi- ple, a more speciﬁc hypothesis h2 replaces the current hypothesis h1 only if the MDL decreases from h1 to h2. Therefore, a detailed hypothesis covering only a few examples is likely to be rejected. The MDL principle has the advantage of not requiring a pruning set, and it is very easy to implement in pre-pruning techniques (Quinlan, 1986). However, it has two drawbacks. The ﬁrst is that it is not computable, in the sense of computability theory; however, several good approximations of it are available. The second drawback is that the assumption that minimizing the MDL of a hypothesis also reduces the classiﬁcation error on an independent test set ST remains a conjecture to be proved. However, the method works well with decision trees, providing performances comparable to those ones obtained using a pruning set. 6.1.2 Lifting information gain to ﬁrst order We will now discuss the heuristics frequently used to guide learning algorithms in the relational framework. In this case also, many heuristics are based on the concept of information gain. However, in the relational framework, things are more complex than in the propositional framework, and the IG measure (6.2) cannot be applied directly as in the previous subsection. As discussed in Section 5.2.3, a ﬁrst-order formula can be satisﬁed in many different ways in a learning instance. Let us consider again the example of Figure 5.10 and the 0-arity concept:1 “arch” ← grounded(x) ∧ grounded(y) ∧ on(z, x) ∧ on(w, y) ∧ connected(z, w). 1Here we will make speciﬁc reference to 0-arity concepts because the analysis of phase tran- sitions in relational learning is done using this type of concept. 130 Searching the hypothesis space Table 6.1 Numbers of alternative tuples satisfying h1 and h2 in the different scenarios of Figure 5.10; P is the class of positive instances (a) (b) (c) (d) (e) (f) total P h1 62666 638 32 h2 22242 313 11 We saw that in scenarios (a), (b), (c), (f) there is a unique triple of objects satisfying this concept deﬁnition whereas in scenario (d) the deﬁnition is ver- iﬁed (satisﬁed) by two different triples of objects, namely (a, b, d) and (b, e, c). Finally, scenario (e) is a negative example of this simple deﬁnition, because no single object is simultaneously on both x and y. Suppose that we want to learn the concept “arch” using a general-to-speciﬁc greedy strategy guided by the IG heuristic. Suppose, moreover, that the hypothesis h1 ≡ “simple arch” ← grounded(x) ∧ grounded(y) has already been constructed and that the algorithm is evaluating the IG with respect to the new formula h2 ≡ “simple arch” ← grounded(x) ∧ grounded(y) ∧ on(z, x) obtained by adding the new literal (relation) on(z, x) to h1. Expression (6.2) will return IG(h1,h2)=0, because both h1 and h2 cover all the learning scenar- ios. Nevertheless, this literal is the only possible choice for learning the correct deﬁnition. From this simple example it is clear that the heuristic widely used in propositional calculus does not work, without modiﬁcation, in the relational framework. Let us consider now the number of possible ways in which h1 and h2 are satisﬁed in the different scenarios in Figure 5.10.InTable 6.1 the numbers of alternative tuples of constants satisfying hypothesis h1 and h2, respectively, is reported. We observe that the proportion of tuples in the positive scenarios is slightly higher for h2 (11/13 = 0.846), than for h1 (32/38 = 0.842). In fact, the lit- eral on(z, x) captures a pattern that is more frequent in the positive instances and is a necessary precondition for acquiring the correct deﬁnition. There- fore, new heuristic deﬁnitions of the information gain are proposed in rela- tional learning; for each of h1 and h2 they depend on the ratio of the number of satisfying tuples in the positive examples and the total number of satisfying tuples. FOIL: information gain 131 In the remaining of this chapter we will illustrate the basic functioning and heuristics used by the machine learning algorithms in the experimental study reported in later chapters. 6.2 FOIL: information gain The ﬁrst relational learner proposed in the literature that was guided by a heuristic based on the information gain was FOIL (Quinlan, 1990; Quinlan and Cameron-Jones, 1993). This learner exploits a greedy hill-climbing search strat- egy, which is guided by the IG heuristic (6.2). FOIL was an extension to the relational case of the corresponding algorithm used in the learning of decision trees (Quinlan, 1986). FOIL uses a top-down search strategy for building clauses that describe dif- ferent modalities of the target concept or relation c(x1,...,xn). The basic ver- sion of the algorithm relies, for learning, on a database of tuples of constants, some labeled positive (i.e., they are in P) and some negative (i.e., they are in N ). The algorithm consists of two nested loops. In the outer loop it iteratively constructs one Horn clause at a time; after a new clause is acquired, the cov- ered positive learning tuples are removed from the learning set and the search restarts by looking for new clauses covering the remaining positive learning tu- ples. In the inner loop FOIL seeks a Prolog clause (see Section 4.15) of the form c(x1,...,xn) ← L1,...,Lk, which characterizes some subset of the relation c. The clause is “grown” by starting with just the left-hand side and adding literals Li (1 ⩽ j ⩽ k) one by one to the right-hand side. This inner loop makes use of a local training set consisting of labeled k-tuples of constants extracted from the global training set. The information gain heuristic plays its role in the construction of single clauses. Let h1 denote the current hypothesis corresponding to a Horn clause h1 ← L1,...,Li. Moreover, let h2 be a more speciﬁc Horn clause obtained by adding a literal Li+1 to L1,...,Li. FOIL’s information gain IG(h1,h2) is given by the following expression: IG(h1,h2)= t log2 ( P2 P2 + N2 ) − log2 ( P1 P1 + N1 ) , (6.3) where P1, P2, N1, N2 are the numbers of tuples satisfying h1 and h2 in positive and in negative instances; t is the number of positive tuples covered by both h1 and h2.If h2 is obtained by adding to h1 a literal containing a new variable, a tuple covered by h1 is considered to be covered also by h2 if it is contained in a tuple covered by h2. 132 Searching the hypothesis space FOIL also includes special heuristics in order to handle the case where no new hypothesis exists having a positive information gain with respect to the cur- rent one. In this case, FOIL adds a literal that extends the number of variables in the body of the clause. 6.3 SMART+: beam search SMART+ is a multi-strategy learning system which incorporates a set of several alternative strategies that the user can select and/or combine, depending on the speciﬁc learning problem. Again, we will limit here the description of the system to its essence. The interested reader is referred to the work by Botta et al. (1993) for a complete description of the system. Basically, SMART+ proceeds top-down as FOIL does. A distinctive feature is the use of beam search instead of pure hill-climbing. The maximum width w of the beam can be set by the user; for instance, if w =1, beam search reduces to hill-climbing. A second feature is that SMART+ can learn multiple concepts at the same time. However, it is not able to learn relations of arity greater than 0. Finally, SMART+’s heuristic for guiding the search is more sophisticated than FOIL’s and combines the information gain criterion with other criteria account- ing for the completeness and consistency of the hypotheses and, possibly, for the available domain knowledge. For the sake of simplicity we will restrict the description of the search heuris- tic to the case of the learning of only one positive concept (as with FOIL) without any domain knowledge. Given a current conjunctive hypothesis h1 (a Horn clause), any new hypoth- esis h2 obtained by adding a literal to h1’s body (right-hand side) is evaluated by a function μ(h1,h2) that is the weighted sum of two terms: μ(h1,h2)= αμ1(h1,h2)+(1 − α)μ2(h2)(0 ≤ α ≤ 1). (6.4) The ﬁrst term is the information gain of h2 with respect to h1 and is computed as follows: μ1(h1,h2)= P2 log2 ( P2 P2 + N2 ) − log2 ( P1 P1 + N1 ) . (6.5) Expression (6.5) is analogous to (6.3), but with the difference that here the infor- mation gain is multiplied by the number of positive tuples satisfying h2 instead of the number of tuples satisfying both h1 and h2. The second term has the fol- lowing expression: μ2(h2)= |cover(h2) ∩P| |P| |cover(h2) ∩P| |cover(h2) ∩P| + |cover(h2) ∩N | . (6.6) G-Net: genetic evolution 133 and is the heuristic rule used by a precursor of SMART+ (Bergadano et al., 1988). More speciﬁcally, (6.6) is the product of two factors: the ﬁrst is the ratio of the number of positive learning instances covered by h2 and the total number of positive instances in the learning set, and is a measure of the completeness of h2. The second factor is the number of positive instances covered by h2 divided by the total number of instances (both positive and negative) covered by h2,and is a measure of the consistency of h2. If α is set to 1,SMART+ uses only the information gain term in (6.4) while if α is set to 0 it uses the second term only. The default value is α =0.5. Let B denote the size of the current hypothesis beam. At each step SMART+ evaluates, with rule (6.4), all the hypotheses that can be derived from those in the beam by adding one literal and retains the best B chosen from the union of the old and the new hypotheses. The search stops when all learning instances are covered or when any new hypothesis has a score lower than the worst in the beam. 6.4 G-Net: genetic evolution Genetic algorithms are general purpose biologically inspired tools for perform- ing a search in optimization problems (Goldberg, 1989). The basic idea consists in encoding tentative solutions to a problem as DNA chromosomes. Evolving the DNA according to the Darwinian paradigm of genetic evolution, the solu- tions tend to approach a global, or local, optimum. The literature of the ﬁeld is very rich, and even an introduction to it is outside the scope of this book. The interested reader can ﬁnd a good one in the book by Goldberg (1989). As the task of concept learning can be cast as a search problem, ge- netic algorithms were proposed for this task very early on (Holland, 1986; De Jong et al., 1993). Since then, many authors have proposed different evo- lutionary paradigms speciﬁcally tailored to concept learning. Here we will focus on G-Net (Giordana and Saitta, 1994; Anglano et al., 1998), a task-oriented ge- netic algorithm that will be used in the following for investigating the emergence of phase transitions in relational learning. In fact, G-Net differs from other re- lational learners principally in its search strategy, which is based on a stochas- tic genetic search guided by the minimum description length (MDL) principle (Rissanen, 1978). As shown by Giordana and Saitta (1994), the portion of hy- pothesis space visited by G-Net is different from that visited by other learners; thus it can ﬁnd solutions that others cannot ﬁnd, and vice versa. Like FOIL and SMART+, G-Net describes a concept as a set {h1,h2,...., hn} of Horn clauses. Each clause is a partial deﬁnition covering a different modality of the concept. G-Net’s inductive engine exploits a stochastic search 134 Searching the hypothesis space algorithm organized on two levels. The lower level, named the genetic layer (G-layer), searches for single Horn clauses hi. The architecture of the G-layer derives from the diffusion model (Manderik and Spiessens, 1989) and integrates different ideas originating within the community of evolutionary computation and tabu search (Rayward-Smith et al., 1989). The upper level, namely the su- pervisor, builds up a global concept deﬁnition ϕ out of the partially deﬁned hi’s generated inside the G-layer, using a greedy set-covering algorithm. From a computational point of view, the G-layer consists of a set of (virtual) elementary processors called G-nodes. Each G-node is associated with a single concept instance e+ and executes a local evolutionary search aimed at cover- ing e+ as well as possible according to a ﬁtness function based on the MDL principle. In more detail, the search starts with a maximally speciﬁc clause cov- ering e+, constructed by a seeding operator (Giordana and Saitta, 1994). Then this initial clause is evolved by applying a set of stochastic operators, which per- form generalization, specialization, and random mutation. Hence, G-Net exploits a bidirectional data-driven search strategy. According to the MDL principle, a new clause obtained in this way receives a good evaluation when it is simple and consistent. Nevertheless, simple hypotheses also tend to be general and to cover many other examples; then the set of clauses ϕ′ evolved by the G-layer tends to be highly redundant. As a consequence the basic task of the supervisor consists in extracting a minimal (according to MDL) set ϕ of clauses from ϕ′. Moreover, the supervisor interacts with the G-layer, focusing the search towards partial hy- potheses covering positive examples not yet covered by the current set of clauses ϕ. This is done by increasing the number of G-nodes, searching the concept in- stances that are not covered or are poorly covered by the current clauses in ϕ. 6.5 PROGOL: exhaustive search PROGOL is probably the best-known learning program developed in the ILP community and is available in two basic implementations, one in C language (C-PROGOL) and the other in Prolog (P-PROGOL). The PROGOL algorithm was described in detail by Steve Muggleton (1995); a good introduction to the theory, implementation, and applications of ILP is provided by Muggleton and De Raedt (1994). P-PROGOL was intended to be a prototype for exploring ideas. It started in 1993 as part of a project under- taken by Ashwin Srinivasan and Rui Camacho at Oxford University. The main purpose was to understand the idea of inverse entailment, which eventually ap- peared in (Muggleton, 1995). C-PROGOL is an implementation written in C that contains its own Prolog interpreter and is aimed at increasing the computational efﬁciency. The main differences in implementation (other than language) are in Plateaus 135 the search technique used and in the degree of allowed user interaction. During routine use PROGOL follows a very simple procedure, which consists of four steps. 1. Select example Select an example to be generalized. If none exists, stop; otherwise proceed to the next step. 2. Build most speciﬁc clause Construct the most speciﬁc clause that entails the example selected and complies with the language restrictions. This clause is usually a deﬁnite clause with many literals and is called the “bot- tom clause”. This is sometimes called the saturation step. 3. Search Find a clause more general than the bottom clause. This is done by searching for some subset of the literals in the bottom clause that has the “best” score. Two points should be noted here. First, conﬁning the search to subsets of the bottom clause does not actually produce all the clauses more general than the bottom clause, but this description is sufﬁcient for a thumbnail sketch. Second, the exact nature of a clause’s score is not really important here. This step is sometimes called the reduction step. 4. Remove redundant examples The clause with the best score is added to the current theory and all examples made redundant are removed. This step is sometimes called the “cover removal” step. Note here that the best clause may make clauses other than the examples redundant. Again, this will be ignored here. Return to step 1. In other words the search starts bottom-up, as in G-Net, and the second step is similar to the seeding operator, where a maximally speciﬁc clause is constructed. Afterwards, more general clauses are built up using the inverse entailment oper- ator. The basic search strategy used in this case is a best-ﬁrst exhaustive search. Nevertheless, it can be modiﬁed by the user by supplying preference criteria and pruning techniques to limit the set of clauses generated, which otherwise could quickly become intractable. As in the cases of FOIL and SMART+ the positive examples covered by a clause selected at the end of the third step are removed from the learning set before a new induction step is started. 6.6 Plateaus When solving optimization problems, local search algorithms may be faster than complete search algorithms, but they tend to become trapped in local minima. An interesting phenomenon may occur during searching, i.e., starting from the 136 Searching the hypothesis space PLATEAU MINIMUM BENCH LOCAL MINIMUM GLOBAL MINIMUM CONTOUR No exit Exit No lower value Lower value All states exist Figure 6.2 Classiﬁcation of plateaus according to Frank et al. (1997). current search state the algorithm cannot reach, in one step, any state that shows an improvement of the objective function. In other words, the algorithm has no guidance about where it should go next. A region in which the objective function does not change is called a plateau. In a plateau the search goes blind and turns into a random search until either an exit from the plateau is found or the search stops for some reason. Frank et al. (1997) studied this phenomenon and deﬁned different types of plateaus, as indicated in Figure 6.2. They used, for the experiments, the GSAT algorithm (Selman et al., 1992) for solving a variety of 3-SAT problems. In the following description of their work we will assume that the objective function H is to be minimized. Plateaus are deﬁned as any maximally connected region of the local search space over which the objective function is constant. They are divided, by the authors, into two classes: local minima and benches. We will now explain the difference. Given a plateau, its border is the set of points in the search space that are neighbors to some state in the plateau but differ in the value of the objective func- tion H.Ifthevalueof H in the plateau is lower than the value of H at any of its border points, then the plateau is a (global or local) minimum. If, on the contrary, the value of H at some point s in the border is lower than the value in the plateau then the points inside the plateau adjacent to s are called exits; plateaus with exits are called benches. Intuitively, minima are plateaus surrounded by regions of the search space where the objective function is greater than in the plateau. A greedy local searcher cannot escape from a minimum once it enters it. Benches are plateaus with exits towards regions where the objective function has lower values than in the plateau. Thus a searcher can escape from them. However, the experiments of Frank et al. showed that benches are often much larger than local minima; most have a high number of exits but some have very few. A bench may Plateaus 137 1.0 0.8 0.6 0.4 0.2 0 380 400 420 Number of clausesProportion of plateaus which are minima 440 Level 1 plateaus Level 2 plateaus Level 3 plateaus Level 4 plateaus Level 5 plateaus 460 Figure 6.3 Proportion of minima among the plateaus found in 3-SAT by Frank et al. (1997). The levels correspond to the values of E. Reprinted from Frank et al. (1997) with permission. consist entirely of exits; in this case it is called a contour, and a local searcher will visit only one point of such a bench before moving away from it. Using the above deﬁnitions and applying the GSAT search algorithm (Selman et al., 1992), Frank et al. (1997) investigated the behavior of plateaus in ensembles of 3-SAT problems with variable number n = 100, near the phase transition (see Chapter 3), for values of α in the interval [3.8, 4.6]. The objective function to be minimized was the number E of unsatisﬁed clauses. First, satisﬁ- able problem instances were analyzed. In order to ﬁnd a plateau, GSAT was run until it found a state with a prespeciﬁed level of E (from 0 to 5). Then, using a breadth-ﬁrst strategy, all the states with the same value of E were searched for and recorded. At the same time the nature of the plateau (minimum or bench) was determined. The proportion of minima and benches in sets of 1000 problems for each value of E was computed. Figure 6.3 gives the results of this investiga- tion. Another aspect investigated by the authors was the size distribution of the local minima and benches. For the same set of problems as before (100 variables 138 Searching the hypothesis space 15 10 5 0 0 0.1 0.2 0.3 0.4 0.5 Proportion of exits to bench sizeNumber of occurrences 0.6 0.7 0.8 0.9 1.0 Figure 6.4 Number of benches with a given proportion of exits, for E =1,in problems with 100 variables and 430 clauses. Reprinted from Frank et al. (1997) with permission. and 430 clauses) and for E =1 they found that the majority of local minima have size less than 300 states (the median was 48 states), but the distribution has a long tail, reaching to 10 000 states. In addition, by setting E =0, global minima are obtained (note that the study was done for satisﬁable instances); the set of global minima consists of several separate minima of widely varying size. Analogous results were found for the bench size distributions; these again show long tails, but the benches are much larger (by a factor 10–30) than the minima and the size distribution tends to be ﬂatter. As the difﬁculty of escaping from a bench depends on the number of exits, a relevant parameter to investigate is the ratio of the number of exits and the size of the bench. Figure 6.4 gives the experimental results. Finally, Frank et al. (1997) searched for features that could distinguish a satisﬁable from an unsatisﬁable problem instance, so that a local searcher could exploit this information early on. Unfortunately, nothing substantial was found. Interesting results have also been found for the MaxSAT problem (Sutton et al., 2009), where, in order to manage very large instances, it is fundamental to be able to navigate and escape plateaus effectively and to ﬁnd exits where they exist. The authors modeled the presence of plateaus as a percolation process on Comments 139 a hypercube graph and described how lower and upper bounds on a plateau’s expected size can be estimated (together with their accuracy), given the E value of the plateau. As we will see in later chapters, the presence of plateaus plays a fundamental role in relational learning as well. 6.7 Comments The difference in complexity existing between representations of hypotheses in propositional and relational learning, described in Section 5.2, is matched by an analogous difference in the complexity of the algorithms devoted to acquir- ing the two kinds of knowledge. Globally, in order to solve a learning problem the learning algorithm, whatever its search strategy may be, must exploit some type of evaluation function to guide the search, as the exploration of the whole hypothesis space is out of question except in trivial cases. There are basically three types of guidance that a learning algorithm can receive: a hypothesis evaluation function (e.g., the information gain or the min- imum description length), training data, and domain knowledge. All three have advantages and drawbacks. Evaluation functions may be ineffective in some re- gions of the hypothesis space, owing to the presence of plateaus, but in other regions they may help the learner to ﬁnd good hypotheses. Adhering too closely to training data, however useful, may mislead the search and generate overﬁtting, particularly in very noisy domains; on the other hand, training data may allow large parts of the hypothesis space to be disregarded. Finally, domain knowl- edge may help considerably in ﬁnding human-meaningful hypotheses, but it is difﬁcult to handle. Even though learning is a search problem, the machine learning community has developed speciﬁc algorithms rather than trying to use those available in the search community. One reason for this could be the feeling that learning is a special type of search, to which ad hoc algorithms will prove to be better suited than generic searchers. Some experimental studies support this opinion. Recently, as a consequence of the establishment of links with statistical physics, new efforts have been devoted to explore the possibility of using and developing new algorithms. 7 Statistical physics and machine learning Contents 7.1 Artiﬁcial neural networks 140 7.2 Propositional learning approaches 152 7.3 Relational learning 163 7.4 Comments 167 The study of the emergence of phase transitions, or, more generally, the applica- tion of statistical physics methods to automated learning, is not new. For at least a couple of decades ensemble phenomena have been noticed in artiﬁcial neural networks. In the ﬁrst part of this chapter we will illustrate these early results and then move to currently investigated issues. According to Watkin et al. (1993), statistical physics tools are not only well suited to analyze existing learning algorithms but also they may suggest new ap- proaches. In the paradigm of learning from examples (the paradigm considered in this book), examples are drawn from some unknown but ﬁxed probability dis- tribution and, once chosen, constitute a static quenched disorder (Watkin et al., 1993). 7.1 Artiﬁcial neural networks Artiﬁcial neural networks (NNs) are graphs consisting of a set of nodes that correspond to elementary computational units, called “neurons”, connected via 140 Artiﬁcial neural networks 141 i i o o o Figure 7.1 A generic structure of a neural network. Nodes labeled “i” are input nodes, nodes labeled “o” are output nodes, and blank nodes are internal nodes. links recalling “axons” and “synapses”. Even though the terminology is bor- rowed from neurology, the analogy between an NN and the brain can well be ignored. The idea behind the computation in an NN is that inputs from the ex- ternal world activate a subset of the neurons (the input neurons), which, in turn, elaborate the input and transmit the results of this local computation to other neu- rons until some subset of neurons (the output neurons) provide the ﬁnal results to the external world. All neurons that are neither input nor output are internal. In Figure 7.1 an example of a generic NN is given. Clearly the above deﬁnition covers an unlimited number of structures. More- over, the types of function computed by the elementary units increase the variety of NNs along another dimension. If no limits are set on the network’s struc- ture and local computation, it is almost impossible to analyze its behavior. Thus precisely deﬁned network types have been introduced and studied. For this, a model of the neuron is needed. A very basic model of a neuron νj , represented in Figure 7.2, includes the following elements. Formal model of a neuron • A set of input links (synapses), which transmit to a neuron νj the signals (x1,...,xr) arriving from r other neurons or from the external world. Each link xi,j (1 ⩽ i ⩽ r) has an associated weight wi,j , which multi- plies the input signal xi.If wi,j > 0 the link is excitatory, whereas it is inhibitory if wi,j < 0.If wi,j =0, the link is not present in the network. An output link yj carries the activation value of the neuron. 142 Statistical physics and machine learning x1 yj x1 x2. . . xr w1,j wr,j w2,j j u Σ j 1 0 f(u)f (a) (b) Figure 7.2 A basic model of a neuron in an artiﬁcial neuron network. Within the neuron, (a) an adder computes uj as a weighted sum ∑r i=1 wi,j xi of the input signals and (b) the output is then calculated by a limiting activation function f (u) (in the ﬁgure it is logistic). • An adder, which sums up the input signals weighted by the respective wi,j values. Thus, the adder computes the sum uj = r∑ i=1 wi,j xi. The quantity uj is known as the post-synaptic potential. • An activation function yj = f (·), which limits the amplitude of the out- put signal. Typically, the output range of a neuron is the interval [0, 1] or [−1, +1]. The output yj is then computed from yj = f (uj − τj ), where τj is the threshold typical of neuron νj . The activation function may take a wide variety of formats; two common ones are the threshold function, f (u)= { 1 if v ⩾ 0, 0 if v< 0, (7.1) and the logistic function, f (u)= 1 1+ e−au . (7.2) The numerical value a in (7.2)isa slope parameter. Artiﬁcial neural networks 143 . . . x1 J 1 x2 xi xn J 2 Ji Jn y Figure 7.3 The perceptron. All the neurons in the input layer are connected to the output neuron, with links labeled Ji (1 ⩽ i ⩽ n).The Ji represent the quenched disorder. The ﬁrst studies on NNs date back to the 1950s, when Rosenblatt (1958) proposed a very simple network model, which nevertheless aroused considerable interest: the perceptron. Its structure is simply organized into two layers, one of The perceptron input neurons (the input layer) and the other constituted by a single output neu- ron (the output layer), as represented in Figure 7.3.1 The input layer receives the signals (x1,...,xn) from a “retina”; the output neuron elaborates these signals and provides the result y. Since there is a unique output node, the weights can simply be deﬁned as Ji (1 ⩽ i ⩽ n). They represent the quenched disorder introduced in Chapter 2. Central to the operation of Rosenblatt’s perceptron is the McCulloch–Pitts model of the neuron, depicted in Figure 7.2. Given an external threshold τ ,the adder produces the value u = n∑ i=1 wixi − τ. (7.3) The activation function yj is a hard limiter, which outputs 1 if u ⩾ 0 and 0 otherwise. The purpose of the perceptron is to distinguish between two classes of objects, c1 and c2. The decision boundary is the hyperplane u = n∑ i=1 wixi − τ =0. (7.4) 1Nevertheless, this basic construct is regarded as a single-layer perceptron; the output layer is disregarded in this terminology. 144 Statistical physics and machine learning x1 x2 xnxi zjz1 zh y1 . . . . . . . . . . . .. . . ysyk Figure 7.4 Multi-layer perceptron with a single layer of hidden units. If u ⩾ 0 then the input is assigned to class c1, otherwise to class c2. The interest in the perceptron was mainly due to the possibility of training it to recognize inputs and classify them. To this end, a set of labeled training examples is shown to the perceptron, and the weights are updated each time a new example (or a set of examples) is seen. Rosenblatt proved that the updating algorithm converges and correctly separates the two classes by a hyperplane, if the classes are indeed linearly separable. Notwithstanding Rosenblatt’s optimism about the potential of the perceptron, the use of a step function for f (u) did not allow effective training. A critical analysis of the perceptron, published by Minsky and Papert (1969), pointed out a number of essential weaknesses, as a consequence of which research on neural networks almost died out. Interest in neural networks returned following the proposal, by Rumelhart, Hinton, and Williams (Rumelhart et al., 1986; Rumelhart and McClelland, 1986), of a new network model, the multi-layer perceptron (MLP), with non-Multi-layer perceptron linear but differentiable functions f (u). The new model overcame the problem of the original perceptron’s step function, and was also provided with an effec- tive training method, the error back-propagation algorithm. The MLP, whose scheme is illustrated in Figure 7.4, is a layered, directed, network, in which neu- rons are organized into an input layer,an output layer, and one or more hidden layers. The neurons in the internal layers are called hidden units. Only neurons in adjacent layers can be connected. The MLP is a feed-forward network, where Artiﬁcial neural networks 145 the information ﬂows from input to output. It can potentially realize any kind of nonlinear separation between classes. In contrast, even though the simplicity of the perceptron makes it unrealistic for practical application (it discriminates only between linearly separable classes of objects), the same simplicity allows for detailed studies of its behaviors. In particular, early research on the emergence, in learning, of phenomena typical of statistical physics concentrated on neural networks and, in particular, on the perceptron (Kinzel, 1998; Engel and Van den Broeck, 2001; Biehl et al., 2000; Nishimori, 2001). 7.1.1 The perceptron In order to describe the results obtained by the statistical mechanics approach to learning in a perceptron, we need to introduce some notions ﬁrst. Let n be the number of input units in the network. Given n and the activation function f (·), a given perceptron P differs from any other only with respect to the synaptic weights on the links between the input and the output neurons. The net has n de- grees of freedom. Let ⃗x =(x1,...,xn) be the input vector with n components, ⃗W =(w1,...,wn) the corresponding vector of weights, and y the output. The vector ⃗x belongs to the input space X . Let us denote by W the set of all possible weight assignments. Then, any network can be identiﬁed by its corresponding weight vector ⃗W. The network ⃗W, called the “student”, must learn a decision boundary be- The student network tween two classes c1 (corresponding to an output y =+1)and c2 (correspond- ing to an output y = −1) by looking at a subset of X , namely the learning set SL = {⃗x(i)|1 ⩽ i ⩽ r}, containing r examples. Let ⃗T be the “teacher”, namely a The teacher network network with weights that allow perfect discrimination between the two classes, and let the output be yT . The goal of learning is to exploit SL to let the network ⃗W become as close as possible to ⃗T. In order to measure the progress of ⃗W,a performance measure is needed; a suitable one is the following: d( ⃗W, ⃗T, ⃗x)= 1(−y(⃗x) · yT ), (7.5) where ⃗x is a given input vector, and 1(u) is the step function, which assumes the value 1 if u ⩾ 0 and 0 otherwise. Clearly, d =1 iff ⃗W and ⃗T classify the input vector ⃗x differently (an error has occurred). Using (7.5) the training error, i.e., the error that results when ⃗W performs on the learning set SL, can be computed as follows: εt = 1 r r∑ i=1 d ( ⃗W, ⃗T, ⃗x(i)) . (7.6) As discussed in Chapter 5, choosing a student with a training error as low as possible might not be a good idea, as there is a danger of overﬁtting. We need to 146 Statistical physics and machine learning introduce the generalization error ε( ⃗W, ⃗T), which is deﬁned as the average of d over all possible inputs ⃗x:Generalization error ε = ε( ⃗W, ⃗T)= ∑ ⃗x∈X P(⃗x) d( ⃗W, ⃗T, ⃗x). (7.7) The average (7.7) is performed over the quenched disorders (the training exam- ples). The probability distribution P(⃗x) is usually ﬁxed but unknown. The error ε can also be interpreted as the probability that ⃗W is in error on an input vector ⃗x randomly drawn from P(⃗x). What we want to obtain is an error ε as low as possible. The behavior of an NN in the limit of large n can be rewritten in terms of sta- tistical physics quantities. More precisely, the weights ⃗W are the couplings ⃗J of the net (hence, wi = Ji), and they can also be considered as describing quenched disorder. Actually, the generalization error ε given in (7.7) is still a function of ⃗J. In order to analyze the behavior of the perceptron quantitatively, we have to make some assumptions about the range of values assumed by the quantities involved. If the output y can only assume values ±1 then the perceptron is called binary, and f (u) is a threshold function. If, on the contrary, f (u)= u, the perceptron becomes linear. In an analogous way, the vector ⃗W = ⃗J may have continuous or binary components; in the latter case, the perceptron is called an Ising percep- tron. For example, an Ising binary perceptron has both the Ji (1 ⩽ i ⩽ n) and y equal to ±1.If ⃗J has continuous components, a special case is that in which all possible ⃗J vectors have the same length, √ n; this type of perceptron is said to be spherical. In the following we will consider the case where ⃗W2 = ⃗J2 = n∑ i=1 J 2 i = n. (7.8) Moreover, let ⃗x2 = n∑ i=1 x 2 i = n. (7.9) By using the deﬁnition of energy introduced in Chapter 1, the Hamiltonian ofHamiltonian of the perceptron the perceptron can be written as H(⃗x)= − n∑ i=1 Jixiy. (7.10) If the perceptron’s behavior is governed by a threshold function f (u), it can be shown that on the one hand the Hamiltonian is upper-bounded. In fact, from Artiﬁcial neural networks 147 (7.3)wehavethat H(⃗x)= −uf (u), with τ =0.If u ⩾ 0 then f (u)=1 and H = −u< 0;if u< 0 then f (u)=0 and H =0. On the other hand, the Hamiltonian is also lower-bounded, because |u| ⩽ n. As a consequence the perceptron will reach an attractor state, where it will stay (Engel and Van den Broeck, 2001). Since in the thermodynamic limit the number of degrees of free- dom, n, of the perceptron diverges, we may expect that for learning to take place the number of examples shown to the perceptron must diverge too. As it turns out, r = |SL| diverges but the ratio α = r/n must remain constant. Requiring that ⃗J, ⃗T,and ⃗x have length √n does not affect the performance of the perceptron, because only the angle between ⃗J and ⃗x is important, as we now explain. The boundary between the two classes provided by equation (7.4) can be written as n∑ i=1 Jixi = ⃗J · ⃗x = |⃗J||⃗x| cos θ =0, (7.11) where “·” denotes the scalar product of two vectors. As neither |⃗J| nor |⃗x| can become zero, the only relevant quantity is cos θ, i.e., the cosine of the angle between the two vectors. As already mentioned, the goal of learning is to reduce the distance between the student ⃗J and the teacher ⃗T. In order to evaluate their distance, the overlap R is introduced: Overlap between networks R = ⃗W · ⃗T n = ⃗J · ⃗T n = 1 n n∑ i=1 wiTi. (7.12) The overlap R is 0 when ⃗J and ⃗T are orthogonal vectors, whereas it is a maxi- mum when they coincide. In fact, the generalization error ε of the network can be written as: ε = 1 π arccos R. (7.13) In Figure 7.5, a circle of unit radius illustrates the relation between ⃗J and ⃗T. As R = cos θ, the error is equal to the ratio of the total length of the two arcs deﬁning the hatched regions (2 arccos R) and the whole circumference (2π). In order to set the weights ⃗J, a simple learning scheme, the Gibbs rule, can be exploited. Let us consider exactly the set of all couplings ⃗J that classify the training examples seen so far as the teacher. These couplings are said to be compatible and they constitute the version space. We want to compute the gen- Version space eralization error of a vector ⃗J drawn randomly from the version space. When a new example is shown to the network, the version space can only shrink and the generalization error decrease; the reason is that some more incompatible cou- plings are rejected, and the generalization error is given by (7.7), in which the 148 Statistical physics and machine learning T J uJ =0 uT =0 Figure 7.5 Relationship between the student ⃗J and the teacher ⃗T. The hyper- planes orthogonal to the vectors represent the decision boundaries between the classes. Above the hyperplane uT =0 all the objects belongs to class c1, whereas below the hyperplane all the objects belong to class c2;as ⃗T is the teacher this is the correct classiﬁcation. However, the student puts in class c1 objects that are above the hyperplane uJ =0 andinclass c2 those that are below it. Thus all objects located in the hatched regions are misclassiﬁed by the student. 2 4 6 8 10 12 α 0.1 0.2 0.3 0.4 0.5 Error Figure 7.6 Computation of the generalization error ε∞(α) as a function of α, from (7.14). proportion of compatible couplings now increases. The obtained generalization error characterizes the typical performance of a compatible student. It is possible to show (Engel and Van den Broeck, 2001) that, in the thermodynamic limit, the generalization error is the following function of α:The parameter α = r/n is the ratio of the number of training examples and the degree of freedom of the perceptron. ε∞(α) = argmax [ 1 2 ln sin 2(πε)+ α ln(1 − ε) ] . (7.14) For α =0 we have ε =0.5, i.e., the student is orthogonal to the teacher and the learned classiﬁer performs random guesses. For α →∞ we expect ε → 0. Artiﬁcial neural networks 149 0.7 0.6 0.5 0.4 0.3 0.2 0.1 0 01 2α ε Figure 7.7 Phase transition of the generalization error ε as a function of α.The critical value of the control parameter is αcr ∼= 1.245. The solid curve starting at 0.5 represents the generalization error and the solid curve starting at 0.7 rep- resents the entropy. The broken lines correspond to metastable states. Reprinted from Engel and Van den Broeck (2001). The computation of ε∞(α) is described in Figure 7.6.Forlarge α, equation (7.7) gives: ε ∼ 1 α . (7.15) The above simple analysis yields qualitatively correct results. In order to ob- tain quantitatively correct results, methods from statistical physics must be used, in particular the annealed approximation and Gardner’s analysis (Engel and Van den Broeck, 2001). The most difﬁcult part of the computation is handling the quenched disorder, namely, the training example distribution. The obvious quantity to use to compute the generalization error would seem to be the volume of version space but unfortunately this is not a self-averaging quantity (see Sec- tion 2.6.1). In fact the correct quantity for use in generalization problems is the entropy, which is the logarithm of the version space volume; its average value can be computed in the thermodynamic limit, n →∞, using the replica trick with the symmetry ansatz (see Section 2.7). The results are given in Figure 7.7. In Figure 7.6 the generalization error shows a smooth decrease from ε =0.5 to the asymptotic limit ε =0. If some network parameters are constrained to be Boolean, new phenomena emerge. For example, if an Ising perceptron with Boolean ⃗J and ⃗x that is learning from another Ising perceptron ⃗T is considered, then statistical physics methods reveal the presence of a ﬁrst-order phase transi- tion in the generalization error ε (the order parameter) with respect to the control parameter α. More precisely, the generalization error drops to 0 at the value Transition to perfect generalizationαcr ∼= 1.245, showing an abrupt transition to perfect learning. The meaning of 150 Statistical physics and machine learning the phase transition is that if an Ising perceptron classiﬁes 1.245 n random inputs in the same way as the teacher, it will classify correctly all 2n possible inputs. This results was obtained by applying the replica symmetry method (Engel and Van den Broeck, 2001). These results conﬁrmed that obtained by Seung et al. (1992), who studied perceptron learning with equilibrium statistical mechanics methods. The exact quenched disorder analysis was approximated in two cases, the high-temperature limit and the annealed approximation. The authors assumed realizable target rules, i.e., perfect decision boundaries between two classes, provided by a teacher perceptron with the same structure as the learner’s. They studied four types of perceptron determined by the continuous or discrete nature of the weights and of the output. If the weights are continuous, the generalization er-Continuous weights do not generate discontinuities. ror varies with continuity and shows the typical inverse-power-law behavior for increasing number of training examples. When the weights are discrete, a ﬁrst- order phase transition appears: if the output is linear, the transition is from a state of poor generalization to one of good generalization followed by an inverse power law decay toward zero. If the output is discrete as well then the transi- tion is to perfect generalization. Monte Carlo simulations demonstrate that the results are quantitatively correct at high temperatures and qualitatively correct at low temperatures. A comprehensive account of phase transition appearances in neural networks was provided by Watkin et al. (1993), who proposed a general setting for inves- tigation of the issue and reported results for several types of networks, including multi-layered ones. 7.1.2 Multi-layer perceptrons Multi-layer perceptrons were studied by Biehl et al. (2000). The authors consid- ered the two-layer perceptron shown in Figure 7.8, which has also been called the soft-committee machine (see also Kinzel, 1998). Each hidden unit zj (1 ⩽ j ⩽ K) is connected to all input units xi (1 ⩽ i ⩽ n), with weights Jij (1 ⩽ i ⩽ n, 1 ⩽ j ⩽ K).Bydeﬁningas ⃗J(j) (1 ⩽ j ⩽ K) a vector whose components are the weights Jij,the activation value of the hidden units can be given as zj = 1 √n ⃗J(j) · ⃗x (1 ⩽ j ⩽ K), and the output as y(⃗x)= 1 √ K K∑ j=1 erf ( zj √2 ) . Artiﬁcial neural networks 151 . . .x1 x2 xn xi . . .zjz1 zK y . . . Jij 1/ K Figure 7.8 Two-layer perceptron studied by Biehl et al. (2000). The input layer has n neurons, and there are K hidden units and one output unit. The weights of the connection between the hidden and output neurons are all equal to 1/ √ K. Learning occurs, as usual, through the provision of a training set SL = {⃗x(k)|1 ⩽ k ⩽ m} containing m labeled examples. The exact rule that the student net- work is supposed to learn corresponds to an identical two-layer perceptron, with weights ⃗B(j) between the input and the hidden units and output v(⃗x).Both y(⃗x) and v(⃗x) being continuous, the empirical error is evaluated as the squared dif- ference between the true and the learned outputs for the examples belonging to SL: εt = 1 m m∑ k=1 [y(⃗x(k)) − v(⃗x(k))]2 . (7.16) As already mentioned the examples in SL, extracted from an unknown but ﬁxed probability distribution D, act as a quenched disorder. Thus, the generalization error ε can be expressed as follows: ε = [y(⃗x) − v(⃗x)] 2, (7.17) where the overbar denotes the average with respect to the distribution D of the quenched disorder. The inputs xi are independent identically distributed Gaus- sian variables with zero mean and unit variance. From a statistical physics per- spective the product mεt can be considered as the extensive energy of the sys- tem, which can be used, as in expression (2.12), to assign the probabilities exp[−(βmεt)] to an ensemble of networks (Kinzel, 1998) each satisfying the condition (⃗J(j))2 = n. 152 Statistical physics and machine learning 0.03 0.02 K = 2 K = 5 0.01 0.00 0.0 20.0 40.0 60.0 α ε Figure 7.9 Learning curves for small K (reprinted from Biehl et al., 2000). For K =2 a second-order phase transition occurs at the critical value αcr(2) ≃ 23.7, whereas for K =5 a ﬁrst-order transition occurs at αcr(5) ≃ 46.6. To develop the analysis further, Biehl et al. (2000) considered the case of high temperatures, i.e., β → 0. Under the above conditions the generalization error shows, as in the case of the perceptron described in Section 7.1.1, a phase transition for a critical value of the number of training examples. More precisely, the control parameter is α = βm/(nK). The nature of the transition and the crit- ical values depend on K. In particular, for K =2 the transition is second-order and occurs at αcr(2) ≃ 23.7, whereas the transition is ﬁrst-order for K ⩾ 3. The main results are given in Figure 7.9. 7.2 Propositional learning approaches Statistical physics methods have been applied, in the past, not only to analyze the behavior of neural networks but also in more general settings, including the learning of Boolean functions, learning with support vector machines, and sym- bolic learning. 7.2.1 Learning Boolean functions Haussler et al. (1994) provided rigorous learning curve bounds using methods derived from statistical physics. More precisely, they showed that the bounds Propositional learning approaches 153 are often tighter and more realistic than those provided by the classical Vapnik– Chervonenkis theory. The learning curves may show discontinuous behaviors, such as the emergence of phase transitions, as well as power law asymptotic behaviors that are not explained within that theory. The Vapnik–Chervonenkis theory of learning a function in a class F,via minimization of the empirical error on a random sample of m examples, leads to bounds on the generalization error which decrease at a rate O(d/m),where Generalization error boundd is the Vapnik–Chervonenkis dimension of the class, if the target function is in F. If the target function is not in F, the generalization error decreases at the much lower rate of O(d/√m). These bounds are general, in the sense that they are valid for any class F, any input distribution, and any target function. The only problem-speciﬁc quantity is d, which is typical of F. In addition, these bounds are the best possible distribution-independent bounds. Nonetheless, vari- ous workers have pointed out discrepancies between the predictions of the theory and the experimental results. Statistical physics methods have helped to show where the Vapnik–Chervonenkis bounds fail to model the true behavior of learn- ing curves, by revealing unexpected behaviors such as the emergence of phase transitions or asymptotic power laws whose exponent is neither 1 nor 1/2. In Haussler et al. (1994), the authors exploited the annealed approximation and the thermodynamic limit to derive a precise and rigorous theory of learn- ing curves. The thermodynamic-limit setting allows the notion of a correct scale to be introduced for describing the learning curves. These last derive from a competition between an entropy function and an energy function. The entropy is measured by the logarithm of the number of hypotheses as a function of the generalization error ε. The energy is measured by the probability of minimiz- ing the empirical error on a random sample as a function of the generalization error ε. Haussler and co-workers started their analysis from a very simple case, in which a Boolean function over an input space X is learned using a training set SL of m labeled examples. The target function f (⃗x) is known to belong to a class F containing a ﬁnite number of {0, 1}-valued functions. Moreover, there is a probability distribution D(⃗x) deﬁned over X .If h(⃗x) is a Boolean function output of some learning algorithm, the generalization error can be written as ε(h)= P⃗x∼D[h(⃗x) ̸= f (⃗x)]. (7.18) In order to perform their analysis of the generalization error, the version space Version space (see Section 7.1.1) is used. Formally, the version space is deﬁned by VS(SL)= {h ∈F | ∀ [⃗x,f (⃗x)] ∈SL,h(⃗x)= f (⃗x)}. (7.19) 154 Statistical physics and machine learning In other words, it contains all the hypotheses (functions) that are consistent with the training set. Then, an η-ball B(η) is deﬁned around the target function: B(η)= {h ∈F | ε(h) ⩽ η}. (7.20) Using a method close to the annealed approximation, the following union bound can be established: PSL [ VS(SL) ⊆ B(η) ⩾ 1 − δ] , (7.21) where δ = ∑ h∈B(η) [1 − ε(h)] m . The main results can be restated as follows. Theorem 7.1 {Haussler et al., 1994} Let F be any ﬁnite class of Boolean func- tions. For any 0 <δ ⩽ 1, with probability at least 1 − δ, any function h ∈F that is consistent with m random examples of the target function satisﬁes the relation ε(h) ⩽ η,where η is the smallest value satisfying the condition ∑ h∈B(η) [1 − ε(h)] m ⩽ δ. Haussler et al. derived also a standard bound, which they call the cardinality bound, ε(h) ⩽ 1 m ln ( |F| δ ) . (7.22) As acknowledged by the authors themselves, the results they provide have more theoretical value than practical value. The greater tightness of the bounds com- pared with those provided by the Vapnik–Chervonenkis theory comes, in fact, at the expense of a greater amount of information required, namely, knowledge of the example distribution, as against knowledge of the class F only in the Vapnik– Chervonenkis theory. In addition, in the method of Haussler et al. the analysis is limited to function classes of ﬁnite cardinality. 7.2.2 Support vector machines Support vector machines (SVMs) can be considered as a generalization of single- layer perceptrons (see Section 7.1); they project the initial examples, belonging to a set of non-linearly separable classes, onto a high-dimensional feature space, where linear classiﬁers can be found. Support vector machines were introduced by Cortes and Vapnik (1995), and have proved to be effective learners for a variety of tasks. Propositional learning approaches 155 Analogously to single and multi-layer perceptrons, SVMs too lend them- selves to a statistical mechanics analysis, which provides insights into the typical behavior of the generalization error (Dietrich et al., 1999; Malzahn and Opper, 2005). Let n be the dimension of the input vectors (the examples) to be clas- siﬁed, N the number of features in the transformed space, and m the number of training examples. Let us deﬁne, as for the perceptron, α = m/n. Dietrich et al. (1999) took the thermodynamic limit n →∞ for various scales of in- crease in m. As the number of learned parameters is N , one may expect that the decrease to zero in the generalization error ε should occur for m = O(N ). On the contrary, however, ε becomes small even for m = O(n). Thus a reason- able ansatz is m = αnℓ. If both the student and the teacher are expressed via quadratic kernels, these authors found that for ℓ =1, i.e., m = αn, the student is able to learn only the linear part of the teacher’s rule; then, for increasing α, the generalization error reaches a plateau where ε(α) − ε(∞) ∼ α−1. If the number of examples increases on the larger scale m = αn2, the well- known asymptotic behavior ε ∼ α−1 is found. If the kernels are polynomials of degree p, a sequence of plateaus appears. A further result obtained by Dietrich et al. (1999) was that SVMs show a resistance to overﬁtting. In fact, by letting a quadratic SVM learn a linear rule, successful learning occurs on the scale m = αn even though the generalization error decay is ε ∼ α−2/3, somewhat slower than the classical α−1. Support vector machines have also been investigated by Malzahn and Opper (2005), whose main goal was to prove that methods from statistical physics can be easily extended to become applicable to real learning algorithms working on real data. To achieve their goal, the authors used a combination of the replica approach and the variational method. More recently, an extension of SVMs, namely multiple instance support vec- tor machines (MI-SVMs) were investigated by Gaudel et al. (2008). The MI- SVMs combine multiple instance learning (Dietterich et al., 1997) with SVMs and represent an intermediate step between propositional and fully relational learning. In the MI setting, each example ⃗z(i) is a “bag” of ni propositional in- stances x (i) 1 ...,x (i) ni ,where ⃗z(i) is positive iff some of its instances satisfy the (propositional) target concept. For MI problems the kernel K of two bags of instances is deﬁned as the average of the kernels k of pairs of instances: K(⃗z(i),⃗z(j))= 1 fn(⃗z(i))fn(⃗z(j)) ni∑ k=1 nj∑ h=1 k(x (i) k ,x (j) h ). (7.23) 156 Statistical physics and machine learning In (7.23) fn(⃗z) is a normalization function. The approach is efﬁcient under the so-called linearity assumption, i.e., an example is positive iff it contains (at least) one instance satisfying the target concept. In order to investigate the quality of the propositionalization induced by re- lational kernels, the authors generated a set of artiﬁcial problems, each consist- ing of a learning set SL = {(⃗z(1),y1),..., (⃗z(m),ym)} and a test set ST = {(⃗z′(1),y′ 1),..., (⃗z′(m′),y′ m′)}. The training set SL induces a propositionaliza- tion of the domain space, mapping every MI example ⃗z to the m-dimensional real vector ΦL(⃗z)=(K(⃗z(1),⃗z),...,K(⃗z(m),⃗z)).Let RL describe this new repre- sentation. The novelty of the proposed methodology is that it rewrites an MI- SVM learning problem (SL, ST ) as a constraint satisfaction problem Q(SL, ST ) in RL.If ε denotes the generalization error of the optimal linear classiﬁer h∗ L deﬁned on RL then the authors lower-bounded ε’s expectation as follows: Em[ε] ⩾ 1 − (ˆτm,m′ + η) 1/m′, (7.24) where the average is computed over a set of learning problems {(S (r) L , S (r) T )| 1 ⩽ r ⩽ R},where η> 0 is any number and ˆτm,m′ is the fraction of CSPs Q(S (r) L , S (r) T ) that are satisﬁable. For the experiments, 40 learning problems were generated for each assign- ment of values to a set of 12 control parameters, by choosing independently the target concept c, the training set SL, and the test set ST .The kernelswere Gaussian and the normalization function f (⃗z) was set to the number of instances (Pic,Nic) in the example ⃗z. Looking at the inﬂuence of the various parameters involved, it was noticed that there is a region where all the CSPs Q(S (r) L , S (r) T ) are unsatisﬁable; for instance, in the plane (Pic,Nic) this region appears along the diagonal Pic = Nic, as expected. The size of this region decreases as the number of training examples increases (left-hand column in Figure 10.1) but increases as the number of test examples increases (right-hand column in Figure 10.1). Even though not directly related to the appearance of a phase tran- sition, the reported results reveal the emergence of discontinuous phenomena in this type of propositionalization. 7.2.3 Decision tree induction Work similar in spirit to that described in the previous section was carried out by Baskiotis and Sebag (2004). Taking inspiration from the phase transition paradigm, their goal was to attach a principled competence map to a learningCompetence map algorithm, characterizing the regions (if any) of the problem space where the algorithm typically succeeds or fails. Such competence maps could then be ex- ploited as look-up tables for the choice of a learning algorithm. The proposed approach was applied, as a particular case, to the decision tree learner C4.5 (Quinlan, 1993). The target concept space was set to formulas in disjunctive Propositional learning approaches 157 (a) (b) (c) (d) (e) (f) 100 80 60 40 20 0 30 40 50 60 70 80 90 100 PicNic 100 80 60 40 20 0 30 40 50 60 70 80 90 100 PicNic 100 80 60 40 20 0 30 40 50 60 70 80 90 100 PicNic 100 80 60 40 20 0 30 40 50 60 70 80 90 100 PicNic 100 80 60 40 20 0 30 40 50 60 70 80 90 100 PicNic 100 80 60 40 20 0 30 40 50 60 70 80 90 100 PicNic Figure 7.10 Fraction of satisﬁable CSPs Q(SL, ST ) in the plane (Pic,Nic) out of 40 runs. Reprinted from Gaudel et al. (2008) with permission. normal form and, hence, the Rule learning mode of C4.5 was used. In this mode a set of decision trees is constructed, pruned, and compiled into rules; the rules are then ﬁltered and ordered on the training set; ﬁnally, the rule set is used as a decision list on the test examples. For the experiments, four control parameters were considered: the num- ber n of Boolean variables representing the problem domain; the number k of (distinct) terms γi in the target concept, each term being the conjunction of a set of (distinct) literals yi, each either a variable (xi) or its negation (¯xi); the number The assumption of uniform ℓ was later on relaxed in the paper. ℓ of literals in a term; the imbalance ratio r, which is the fraction of positive learning instances. Assuming that all terms have the same length, the target con- cept space is actually a restriction of the DNF language, termed (k, ℓ)-term DNF. 158 Statistical physics and machine learning 40 30 20C4.5 error 10 0 20 10 0 25 20 15 10 5 0 m ℓ Figure 7.11 Competence map for the C4.5 percentage error for (k, ℓ)-term DNF, represented in the plane (m, ℓ) with k =15 and r =1/2. Reprinted from Gaudel et al. (2008) with permission. For each setting (n, k, ℓ, r), 100 learning problems Li(n, k, ℓ, r) were generated. Each learning problem consisted of a target concept, a training set, and a test set of examples (globally, 400 examples with different r values). In Figure 7.11 the C4.5’s competence map is reported. From Figure 7.11 it appears that the error is, in most regions, very low, con- ﬁrming the known robustness of C4.5. However, a failure region (error equal or greater than 20%) is observed as the term length ℓ takes on medium values (ℓ ∈ [5, 10]), whenever the number n of variables is non-negligible (n> 15). It is no surprise that the learning difﬁculty increases with the total number n of variables, since the representativity of the training set (ﬁxed at 200 positive and 200 negative examples, in the case of Figure 7.11) decreases. The relationship between the error and the term length ℓ is less obvious: for ﬁxed m, r,and k the error ﬁrst increases, and then decreases, as ℓ increases. However, it is almost insensitive to the imbalance ratio r. The initial increase in the error with ℓ can be attributed to the myopic search of C4.5, greedily optimizing the information gain ratio criterion. Indeed, as the term length increases, each literal becomes less discriminant; furthermore, it is often the case that both a variable and its negation appear in some terms of the target concept, causing the information gain ratio criterion to miss the variables that contribute to the target concept. Therefore, a signiﬁcant amount of look- ahead would be necessary to prevent the greedy search from becoming trapped Propositional learning approaches 159 in local optima owing to erroneous early choices. In other words, the (univariate) gain ratio becomes a noisy selection criterion as the target concept involves more speciﬁc terms; hence the probability of making no errors along ℓ selections, based on this criterion, decreases with ℓ. When the term length ℓ increases again (ℓ> 10), the error decreases. This empirical ﬁnding was unexpected since the learning difﬁculty is usually seen as proportional to the target concept complexity, and ℓ is considered a factor in the complexity. The fact that the failure region does not depend much on the imbalance ratio r is unexpected too, since imbalanced example distributions are widely acknowledged as a factor in complexity. The tentative interpretation offered by the authors for this ﬁnding is based on the observation that rules produced by C4.5 are not arbitrarily long, because they must cover a signiﬁcant number of positive training examples; on average, their size is limited by a maximum value ℓc. Therefore, the probability p(n, ℓ) for a leaf in a C4.5 tree to be irrelevant (to differ by at least one irrelevant literal from a generalization of a true conjunct) when learning a (k, ℓ)-term DNF concept is bounded by the probability that at least one irrelevant literal will be selected out of ℓc choices. However, the probability that an irrelevant feature will be selected decreases as ℓ increases. The rise in the error as ℓ increases up to ℓc is thus explained as due to the increasing number of choices (hence the probability of error); the error falls for ℓ>ℓc because it is the product of ℓc factors that all decrease as ℓ increases. 7.2.4 k-term DNF learning The learning of k-term DNF concepts is an important task in machine learning. We have already seen, in the previous section, that such learning is mediated by the learning of decision trees. A direct approach was taken by R¨uckert et al. (2002), who showed that phase transitions exist even in this propositional setting. Moreover, they were able to locate and characterize these phase transitions using as parameters the number of terms k, the numbers mp = |P| and mn = |N | of positive and negative training examples, and the number n of Boolean variables. In the experiments, positive and negative examples of the target concept were generated by choosing either xi =1 or xi =0 with the same probability for each variable xi (1 ⩽ i ⩽ n). The search costs were measured by counting the number of partitionings generated by a complete algorithm. The probability Psol that a problem instance is soluble and the search costs were computed for a broad range of problem settings. Some results are given in Figure 7.12. In this ﬁgure the number of positive examples and k were kept constant, whereas the number of negative examples and of variables were varied. 160 Statistical physics and machine learning 1.0 0.8 0.6 0.4 0.2Psol 0 160 N 160120 1 0 160 160120 12080 80 40 40 0 0 2 12080 n n 80 40Search costs × 10 4 40 0 0 N Figure 7.12 The probability that a problem instance is soluble, Psol (upper panel), and the search costs (lower panel), plotted respectively as a three- dimensional graph and a contour plot for problem settings with k =3,mp = 15, 1 ⩽ mn ⩽ 128,and 1 ⩽ n ⩽ 128. Each data point represents the av- erage over 100 problem instances. Reprinted from R¨uckert et al. (2002) with permission. As expected, the search costs are especially high in the region of Psol ≃ 0.5.In order to locate the phase transition, the authors took n as the control parameter, whose critical value ncr is deﬁned from the following condition: Psol(ncr)=0.5. Propositional learning approaches 161 The authors also investigated from an algorithmic point of view the use of stochastic local search (SLS) for k-term DNF learning. They compared several variants that ﬁrst reduce k-term DNF to SAT and then apply well-known stochas- tic local search algorithms such as GSAT and WalkSAT. The experimental results indicate that WalkSAT is able to solve the largest fraction of hard problem in- stances (R¨uckert et al., 2002; R¨uckert and Kramer, 2003). 7.2.5 Vector quantization Vector quantization is an effective and frequently applied method for unsuper- vised learning. It allows a large amount of data to be compressed into just a few prototypes, thus uncovering the structure underlying the data. Witoelar et al. (2008) applied methods from statistical mechanics, similar to those used in the analysis of neural networks, to off-line vector quantization with a rank- based cost function. The main ﬁnding was that phase transitions emerge in the training process; in fact, a critical number of examples is required to uncover the underlying structure. More precisely, the authors considered a set of m vectors S = {⃗x(i) ∈ Rn| 1 ⩽ i ⩽ m}, drawn independently from a given probability distribution, and a set of k prototypes Z = {⃗z(j) ∈ Rn| 1 ⩽ j ⩽ k}. Using a squared Euclidean distance d(⃗x, ⃗y)=(⃗x − ⃗y)2,a rank function g(rj ) can be deﬁned such that, for every prototype ⃗z(j) and input vector ⃗x, rj is the rank of ⃗z(j) with respect to its distance from ⃗x: rj = k − k∑ h=1,h̸=j Θh,j , (7.25) Θh,j = 1[d(⃗x,⃗z(h)) − d(⃗x,⃗z(j))]; (7.26) here 1(u) is the step function, which is equal to 1 if u ⩾ 0 and to 0 otherwise. The rank function is deﬁned as follows: g(rj )= e−rj /λ ∑k j=1 e−rj /λ , (7.27) where λ controls a “soft” assignment of the vectors to the prototypes (soft in that each vector may belong to more than one cluster). If λ → 0, only the clos- est prototype is taken into account and so each vector is assigned to a unique prototype. In the thermodynamic limit (n →∞) the number of examples is also as- sumed to increase linearly, namely, m ∼ n. In the statistical physics approach, training is considered as a minimization process on the data S of the functional 162 Statistical physics and machine learning H(⃗z(j),...,⃗z(k)) ,where: H(⃗z(1),...,⃗z(k))= m∑ i=1 ε(⃗z(1),...,⃗z(k), ⃗x(i)), (7.28) ε(⃗z(1),...,⃗z(k), ⃗x)= 1 2 k∑ j=1 d(⃗z(j), ⃗x)g(rj ) − 1 2⃗x2. (7.29) As thermodynamic equilibrium is reached, each conﬁguration (⃗z(1),...,⃗z(k)) is observed to have a probability given by the Gibbs distribution (see Chapter 2): P(⃗z(1),...,⃗z(k))= 1 Z e −βH (⃗z(1 ) ,...,⃗z(k ) ); (7.30) Z is the partition function and β = kB T . As described in Chapter 2, thermal averages ⟨·⟩ are evaluated with respect to P(⃗z(1),...,⃗z(k)) and can be obtained from derivatives of the free energy. The quantities introduced so far have been computed on a speciﬁc data set S. In order to obtain generic properties, a new average, with respect to the data distribution (the quenched disorder), has to be performed; thus the quenched free energy may be obtained. The complete cal- culation requires the use of the replica trick. The authors resort to a simpliﬁed situation, one in which β → 0 (the high-temperature limit). In this case, the noise introduced by the high temperature has to be compensated by the use of a large number of training examples, namely ˜α = βm/n. It may be shown (Witoelar et al., 2008) that the generalization error ⟨ε⟩ can be expressed as a function of two order parameters, Rji = ⃗z(j) · ⃗b(i) and Qji = ⃗z(j) · ⃗z(i), where the ⃗b(i) (1 ⩽ i ⩽ k) are the centers of the “true” clusters. The behavior of the order parameter Rj1 is shown in Figure 7.13.If λ =0 (partitioning clustering) and k =2, the structure in the data cannot be discov- ered if ˜α is smaller than a critical value ˜αcr. Above ˜αcr the structure emerges, and each prototype overlaps with exactly one cluster (see Figure 7.13(a)). The corresponding graph for ⟨ε⟩ is given in Figure 7.13(b). At the critical point, the graph is not differentiable but it is continuous in value. The ﬁnding for k ⩾ 3 are different; then, both Rj1 and the ⟨ε⟩ graphs show a discontinuity in correspon- dence with the critical value αcr (see Figures 7.14(a), (b)). The main conclusion of the work is that, for any k, no optimization strategy, however good, can un- cover the structure in the data unless a sufﬁciently large number of examples is supplied. Relational learning 163 1.2 0.8 0.6 0.4 0.2 –0.6 –0.7 –0.8 –0.9 –1.0 –1.1 –1.2 –1.3 23 4 5 23 α ∼ 4 (a) α ∼ (b) ⟨ε⟩ 5 1.0 1RRj Figure 7.13 (a) Order parameter Rj1 (1 ⩽ j ⩽ 2) of the stable conﬁguration for k =2 vs. ˜α. There is a continuous phase transition at the critical value ˜αcr(2) ≃ 3.70. (b) Graph of the mean error ⟨ε⟩ vs. ˜α for k =2.Thereisa discontinuity in the derivative at ˜αcr. Reprinted from Witoelar et al. (2008) with permission. 7.3 Relational learning The ﬁrst results on the emergence of a phase transition in symbolic learning were reported by Giordana and Saitta and co-workers (Botta et al., 1999; Giordana and Saitta, 2000; Giordana et al., 2000a,b; Botta et al., 2000, 2003; Serra et al., 2001). They found that, in relational learning, the probability that an example is 164 Statistical physics and machine learning 0.9 (a) (b) 4.3 –1.41 –1.42 4.3 4.35 4.4 4.45 4.35 4.4 4.45 0.8 0.7 α ∼ α ∼ ⟨ε⟩ 1RRj Figure 7.14 (a) Order parameter Rj1 (1 ⩽ j ⩽ 3) vs. ˜α. Two of the three Rj1 coincide on the upper curve. The transition is ﬁrst order and ˜αcr(3) ≃ 4.37. (b) Graph of the mean error ⟨ε⟩,vs. ˜α for k =3. There is a discontinuity at ˜αcr. Reprinted from Witoelar et al. (2008) with permission. covered by a hypothesis (the order parameter), expressed in a DATALOG lan- guage, shows a steep transition from almost 1 (in the YES region) to almost 0 (in the NO region) with respect to certain control parameters that characterize both the hypothesis and the example. The analysis performed and the results obtained will be described in detail in Chapter 9. Later on, the same authors investigated the impact of the presence of a phase transition in matching on the very feasibility of relational learning. They found that, around the phase transition, a wide region exists where learning proves to be impossible. A detailed description of this work will be reported in Chapter 10. Relational learning 165 Following the ﬁrst results, several other research groups have pursued the issue, extending and/or reﬁning the original results of Giordana and Saitta. For instance, Wieczorek et al. (2006) replicated the experiments described by Giordana and Saitta (2000), introducing a partial subsumption test π instead of θ-subsumption and a subsumption index Iπ . More precisely, given a hypothesis h and an example e containing distinct variables, one says that h “π-subsumes” e iff there exists a subexpression h′ in h (h′ ⊆ h) and a substitution θ of the variables in h such that h′θ ⊆ e. Moreover, given a hypothesis h andanexample e such that hθ-subsumes e, the subsumption index Iπ is a function from (h, e) to the interval [0, 1]that quantiﬁes the “degree of subsumption” from h to e, i.e., the covering degree of h relative to h, with h′ ⊆ h.If h′ = h then hθ-subsumes e and Iπ =1.When no subexpression h′ θ-subsumes e,wehave Iπ =0. By using the above notion of partial subsumption, Wieczorek et al. (2006) found that the probability that a match exists (in a random set of pairs (h, e)) is still almost 1 on one side of the phase transition and smoothly descends towards 0 on the other side instead of jumping down to 0 abruptly. This ﬁnding may be relevant in designing more effective heuristics to learn long concepts. An extensive study of phase transition emergence in relational learning has been made by Alphonse and Osmani (2007, 2008a,b, 2009). These au- thors started from Giordana and Saitta (2000) and Botta et al. (2003) and no- ticed that these results were obtained mostly by FOIL, which uses a top-down (TD) generate-and-test (GT) search strategy where reﬁnements are based on the structure of the hypothesis space and the learning data is ignored. There- fore, Alphonse and Osmani (2007) suggested that data-driven (DD) strategies based on a generalization of a seed example may allow the pruning of irrele- vant branches by the use of training data without relying on the evaluation func- tion, thus possibly overcoming the problem of plateaus. Notably, near-miss ex- Near misses are deﬁned, in this context, as negative examples that differ by only one literal from the seed example. amples are particularly effective: a top-down data-driven learner (TD–DD) can cross plateaus and reach the target concept whenever near misses are supplied in the training set, whereas these same near misses do not change the plateau pro- ﬁle and hence do not guide a TD–GT learner (Alphonse and Osmani, 2008b). Actually, substantially similar results to those with FOIL were obtained by Giordana and Saitta (2000) via G-Net, which is a data driven bidirectional searcher. Clearly, near misses would greatly ease learning but their availability may be problematic. In order to perform a systematic analysis of the impact of plateaus on heuristic search in relational learning, Alphonse and Osmani designed a consis- tency problem generator, RLPG (relational learning problem generator) based on the model RB that was proposed for CSPs (see Chapter 4). In the model RLPG(k, n, α, N, |P|, |N |), the parameters k, n, α are the same as in model RB 166 Statistical physics and machine learning (Xu and Li, 2000), whereas the deﬁnition of N is that of Giordana and Saitta (2000) (see Chapter 9); |P| and |N | are the numbers of positive and negative examples in the learning set, respectively. Using RLPG’s properties, Alphonse and Osmani proved that the current hypothesis size, evaluated during learning, is a control parameter of the phase transition of the subsumption test. This re- sult asymptotically guaranties the existence of a plateau for the heuristic search. Moreover, the size of the plateau is proven to grow sub-quadratically with the problem size. It was shown that problems of very small size can be generated in which the existence of plateaus is still guaranteed thus providing a well-suited benchmark for relational learning. Empirical conﬁrmation was obtained by run- ning several complete-search learners on problems generated by RLPG that ex- hibit the pathological case where informed-search learners degenerate into non- informed-search learners. Alphonse and Osmani also performed an extensive study of the learning cost of several learners on inherently easy and hard instances of the corresponding consistency problem, looking for the typical easy–hard–easy pattern across the phase transition line. According to Gottlob et al. (1997), the simple bounded inductive logic programming (ILP) consistency problem is Σ2-complete, i.e., it belongs to a class higher in the polynomial hierarchy than NP-complete prob- lems. Since a conjecture has been put forward that a phase transition could be exhibited further up the polynomial hierarchy, the phase transition framework could be useful for investigating other PSPACE (see Garey and Johnson, 1979) problems as well. Actually, Alphonse and Osmani proved that this conjecture is true for the bounded ILP consistency problem, which is representative of rela- tional learning. Using the generator previously mentioned, Alphonse and Osmani (2009) generated and handled a set of benchmark datasets with controlled complex- ity, with the number of examples as control parameter. A ﬁrst outcome of the work is that all well-known top-down relational algorithms, rooted in either the generate-and-test or the data-driven paradigm, fail to exhibit the standard “easy– hard–easy” pattern. Their complexity tends to increase with the number of ex- amples, and therefore they exhibit an “easy–hard–hard” pattern. An exception is the depth-ﬁrst bottom-up data driven (DF-BDD) algorithm, an lgg-based learner, which does not perform as well as the others on the “solvable” side of the phase transition but does perform well elsewhere. 7.3.1 Sequence learning Sequences constitute a type of data that is very relevant in practical applications; they can be considered as an intermediate case between propositional and re- lational representation. It is then interesting to ascertain whether discontinuous Comments 167 phenomena such as phase transitions also occur when one is inferring sequence models from data. Cornu´ejols and co-workers (Pernot et al., 2005) investigated learning of a speciﬁc type of model, namely grammars, inferred from strings of symbols. The approach followed by these researchers and the results obtained will be discussed in detail in Chapter 11. 7.4 Comments The emergence of a phase transition, a typical phenomenon in many-body sys- tems, appears in a large variety of learning approaches. Among these, neural networks are primary candidates for being handled as complex physical systems. In fact, it is quite natural to let neurons correspond to the elementary objects in a complex network and synaptic connections to interactions. By exploiting the notion of distance in a graph we can say that both in the single-layer perceptron and in the multi-layer perceptron, interactions are short-range, as they connect only neurons in adjacent layers. A fundamental control parameter in different learning approaches appears to be the number of training examples. If the learner sees a critical number of them, it is as if it has seen them all. The training examples are drawn from a ﬁxed (but usually unknown) distribution, and they act as a quenched disorder. Surprising as it might be, analogous phenomena occur in learners that appear to be quite far from physical systems, such as symbolic learners. In Chapters 9– 11 tentative explanations of why this happens will be suggested. 8 Learning, SAT, and CSP Contents 8.1 Reducing propositional learning to SAT 168 8.2 Phase transitions and local search in propositional learning 175 8.3 The FOL covering test as a CSP 178 8.4 Relation between CSP and SAT 179 8.5 Comments 183 An interesting issue, relevant to the main theme of this book, is whether, and if so how, learning, either propositional or relational, can be linked to the satisﬁabil- ity (SAT) problem or to the constraint satisfaction problem (CSP). Establishing such a link can have important consequences in practice, because the theoretical aspects of SAT and CSP could be transferred to learning problems, and so the very effective algorithms developed for those combinatorial problems could be applied to learning tasks. Intuitively, one may expect that propositional learning should be related to SAT and relational learning to CSPs. This intuition will be substantiated in the following sections. Moreover, ﬁnite CSPs must be reducible to SAT problems. 8.1 Reducing propositional learning to SAT The formal transformation of a propositional learning problem into a SAT prob- lem was investigated, for the ﬁrst time, by Kamath et al. (1992)inrelationtothe induction of k-DNF (disjunctive normal form) rules. The same transformation was then applied by R¨uckert et al. (2002) to analyze the emergence of a phase transition in the corresponding SAT problem. Here, we will brieﬂy review the 168 Reducing propositional learning to SAT 169 transformation proposed by Kamath, then we will discuss the implications and the extension to propositional learning in general. A k-DNF concept deﬁnition consists of a set of k propositional rules with the format In an equivalent way, rule (8.1) can be written as a set of k Horn clauses: γ1 → h, ..., γk → h. γ1 ∨ γ2 ∨ ··· ∨ γk → h, (8.1) γ1,γ2,...,γk being conjunctions of conditions on the attribute values describing theinstancetobeclassiﬁed. The problem of learning a k-DNF concept deﬁnition from a learning set of concept instances, classiﬁed by a teacher, was formally introduced by Valiant (1984) as a fundamental problem in computational learning theory. Since then it has been investigated by many authors. In fact, this form of concept deﬁnition is relevant to many applications but involves a learning problem that is computa- tionally hard (Kearns and Vazirani, 1994). Kamath et al. (1992) approached the problem of deriving a k-DNF rule, complete and consistent with respect to a learning set, by starting from a rule template deﬁned apriori. The assumption was that the learning instances are described by Boolean attributes only (i.e., attributes may only have the values 1 or 0). However, this assumption is not limitative because any multiple-valued attribute can always be transformed into an equivalent set of Boolean attributes. Let ⃗x denote the n-dimensional vector of Boolean attributes describing a learning instance. Moreover, let xj (1 ⩽ j ⩽ n) denote the ith component of ⃗x. A k-DNF rule can be represented as an expression in Boolean algebra, where the n binary attributes are the input variables. Rules of this form have an immediate representation in terms of logical circuits, which provide an intuitive graphical representation (see Figure 8.1). The rule template has the structure of a k-DNF rule over the whole set of variables extended with a set of control variables, which are used to make the template consistent with the positive and negative learning instances by the se- lection or exclusion of single components of the input variables in ⃗x. Then, the problem of learning a k-DNF concept deﬁnition is reduced to the problem of ﬁnding a consistent assignment to the control variables, and this, in turn, can be reduced to a SAT problem. The rule template (see Figure 8.1) is the OR of k conjunctions, where each conjunction γi (1 ⩽ i ⩽ k) is the AND of n variables yij (1 ⩽ i ⩽ k, 1 ⩽ j ⩽ n), each obtained by combining a Boolean attribute xj with a pair of two control variables ⟨sij,s′ ij ⟩. Depending on the values of sij and s′ ij, either the variable yij reproduces the value of xj or of xj or it becomes independent of xj .More speciﬁcally, the logical expression deﬁning yij is the following: yij =(xj ∨ sij) ∧ (xj ∨ s ′ ij ). (8.2) The truth values of yij are given in Table 8.1. 170 Learning, SAT, and CSP Table 8.1 Truth table corresponding to the variable yij deﬁned by (8.2) sij s′ ij y Comment 01 yij = xj yij ≡ xj 10 yij = xj yij ≡ xj 11 1 yij ≡ true, i.e., xj is irrelevant 00 0 yij ≡ false, i.e., a contradiction occurs x h x1 x1 xn n s………… 11 s11 s1n s1n y 11 y 1n x1 x1 xn xn sk1 sk 1 skn skn y k1 y kn 1 k ′ ′ ′ ′ Figure 8.1 Logical circuit corresponding to the rule template. The circuit is then generalized in order that it can learn a k-DNF classiﬁcation rule. From this table we note that when sij =0 and s′ ij =1 the value of yijSetting sij =1 and s′ ij =1 is equivalent to applying the “dropping condition” rule widely used in machine learning algorithms. corresponds to the value of xj , while it corresponds to xj when sij =1 and s′ ij =0. Moreover, if sij =1 and s′ ij =1 then yij does not depend on xj as it is always true (i.e., yij =1). Therefore the control variables sij, s′ ij provide a tool for selecting a condition on the corresponding attribute xj or dropping the dependency upon xj . Finally we notice that by setting sij =0 and s′ ij =0 we obtain yij = xj ∧ xj ,which is always false, causing γi to be false as well. Thus, this setting must be forbidden for any pair ⟨sij ,s′ ij⟩. This can be stated by requiring that the clauses in the Reducing propositional learning to SAT 171 following set, Γ1, must all be satisﬁed: Γ1 = {(si,j ∨ s ′ ij ) | 1 ⩽ i ⩽ k, 1 ⩽ j ⩽ n}. (8.3) Expression (8.3) deﬁnes the initial set of nk clauses of the corresponding SAT problem. We will now consider the constraints due to the learning set SL. Every pos- itive or negative learning instance e ∈SL will impose some constraints on the output value h of the k-DNF rule to be learned. By propagating these constraints toward the inputs, new clauses on the control variables are obtained. First let us consider the negative examples. For any example e− r ∈N the value of h must be false (i.e., h =0). This means that all the conjunctions γ(r) i must have the value 0 for that example. This condition can be satisﬁed if, for every γ(r) i ,at least one variable y(r) ij has the value 0, i.e., ∃t|y(r) it =1. All these conditions can be grouped together in the following set Γ′ 2 of clauses: Γ′ 2 = ⎧ ⎨ ⎩ n⋁ j=1 y(r) ij ∣ ∣ ∣ ∣ ∣ 1 ⩽ r ⩽ |N |, 1 ⩽ i ⩽ k ⎫ ⎬ ⎭ , (8.4) which must be veriﬁed on each example e− r ∈N . According to deﬁnition (8.2) of yij , and assuming a speciﬁc value of xj for a learning instance e− r ∈N , the clauses in (8.4) can be modiﬁed in order to obtain constraints on the con- trol variables sij and s′ ij . More speciﬁcally, if attribute x (r) j =0 in e− r then we obtain from (8.2)that y(r) ij = sij . Thus, in order to have y(r) ij =1 we must have sij =0. As a consequence we may substitute the literal y(r) ij by the lit- eral sij in (8.4). Applying analogous reasoning to the case x (r) j =1 in e− r ,we can conclude that in this case the literal y(r) ij in (8.4) can be replaced by the literal s′ ij . Thus we obtain the following set of clauses: Γ2 = ⎧ ⎨ ⎩ n⋁ j=1 σij (x (r) j ) ∣ ∣ ∣ ∣ ∣ 1 ⩽ r ⩽ |N |, 1 ⩽ i ⩽ k ⎫ ⎬ ⎭ , (8.5) where σij (x (r) j )= ⎧ ⎨ ⎩ sij if x (r) j =0, s′ ij if x (r) j =1. (8.6) We may notice that in (8.4)the y(r) ij depend on the example e− r , whereas sij and sij do not. However, the dependence of the clauses in Γ2 on a speciﬁc example is reﬂected in the different number of sij and sij occurring in each clause and in their position. In conclusion, for every e− r ∈N aset of k clauses can be derived 172 Learning, SAT, and CSP from expression (8.4) by applying the above reasoning. Then |Γ2| = k|N |,and the set Γ2 is added to the SAT problem. Let us now consider the constraints due to the positive examples e+ ∈P. Every e+ r ∈P must satisfy the k-DNF rule, requiring that h =1. This condition is achieved if, for any positive example, at least one conjunction γi (1 ⩽ i ⩽ k) is veriﬁed. This condition can be stated by deﬁning, for every example e+ r ∈P, aset Zr = {z(r) i | 1 ⩽ i ⩽ k} of k variables. The variable z(r) i assumes the value 1 iff the conjunction γi is true in e+ r . Then the requirement that at least one conjunction is true in each e+ r can be translated into the following set Γ′ 3 of clauses: Γ′ 3 = { k⋁ i=1 z(r) i ∣ ∣ ∣ ∣ ∣ 1 ⩽ r ⩽ |P|, 1 ⩽ i ⩽ k } . (8.7) Again, in order to be operational we must link the variables in Zr to the control variables, as we did for the negative examples. To this end we observe that re- quiring z(r) i to be 1 entails y(r) ij =1 (1 ⩽ j ⩽ n). Formally this can be stated as follows: z(r) i → (y(r) i1 ∧ y(r) i2 ∧ ··· ∧ y(r) in ) . (8.8) We remember that z(r) i → (y(r) i1 ∧ y(r) i2 ∧ ··· ∧ y(r) in ) is equivalent to z(r) i ∨(y(r) i1 ∧ y(r) i2 ∧ ··· ∧ y(r) in ). Then, by applying the distributive property of the AND operator, expression (8.8) can be rewritten in the equivalent form n⋀ j=1(z(r) i ∨ y(r) ij ). (8.9) Applying reasoning analogous to that for the negative learning instances, the variables y(r) ij can be tied to the control variables sij and s′ ij according to the value of x (r) i in any single positive example. In this case, we want y(r) ij to be true; then the variable y(r) ij in (8.9) is replaced by sij or by s′ ij according to whether the value of x (r) j is 0 or 1. Therefore, the set Γ′ 3 becomes the following: Γ3 = {(z(r) i ∨ σij (x (r) j )|1 ⩽ r ⩽ |P|, 1 ⩽ i ⩽ k , 1 ⩽ j ⩽ n}, (8.10) where σij (x (r) j ) is the function deﬁned by (8.6). The cardinality of Γ3 is kn|P|. Then, by collecting the clauses in the three sets Γ1, Γ2,and Γ3, we obtain c clauses, where c = nk + k|N | + kn|P|. (8.11) The number v of variables is v =2nk + k|P| = k(2n + |P|). (8.12) Reducing propositional learning to SAT 173 Then the parameter α = c/v assumes the value α(|N |, |P|, n)= c v = nk + k|N | + kn|P| k(2 n + |P|) = |N | + n(|P| +1) 2 n + |P| . (8.13) Notice that the resulting SAT has clauses of varying length: Γ1 and Γ3 contain clauses of length 2 whereas Γ2 contains clauses of length n. Thus it is not pos- sible directly to transfer to k-DNF learning the results about the location of the phase transition. Nonetheless, from equation (8.13) it can be seen that lim |N |→∞ α(|N |, |P|, n)= ∞, lim |P|→∞ α(|N |, |P|, n)= n. From the above expressions one can see that increasing only the number of nega- tive examples makes the SAT problem unsatisﬁable. Increasing only the number of positive examples allows α to converge to the value n; in this case, α scales linearly with n. EXAMPLE Suppose that we want to learn a 2-DNF rule classifying objects described by three Boolean variables x1,x2,and x3. The learning set SL contains the six examples, three positive and three negative, shown below in Figure 8.2. There are eight examples in all, so generalization is still possible because there are two unclassiﬁed examples. In order to ﬁnd the ﬁrst set of clauses x1 x2 x3 h 000 1 010 1 Positive example set P 001 1 100 0 110 0 Negative example set N 011 0 Figure 8.2 Learning set used to acquire a 2-DNF formula. in the corresponding SAT problem, we must deﬁne the following set of 12 variables: {s11,s ′ 11,s12,s ′ 12,s13,s ′ 13,s21,s ′ 21,s22,s ′ 22,s23,s ′ 23}. Theruletemplateforthe 2-DNF rule is then h = γ1 ∨ γ2, with γ1 =(x1 ∨s11)∧(x1 ∨s ′ 11)∧(x2 ∨s12)∧(x2 ∨s ′ 12)∧(x3 ∨s13)∧(x3 ∨s ′ 13), γ2 =(x1 ∨s21)∧(x1 ∨s ′ 21)∧(x2 ∨s22)∧(x2 ∨s ′ 22)∧(x3 ∨s23)∧(x3 ∨s ′ 23). 174 Learning, SAT, and CSP The ﬁrst set of clauses, deﬁned by (8.3), is the following: Γ1 = {(s11∨s ′ 11), (s12∨s ′ 12), (s13∨s ′ 13), (s21∨s ′ 21), (s22∨s ′ 22), (s23∨s ′ 23)}. Accordingto (8.5) a second set of clauses is obtained by instantiating the function (8.6) on the negative examples: Γ2 = {(s11 ∨ s ′ 12 ∨ s ′ 13), (s21 ∨ s ′ 22 ∨ s ′ 23), =(s11 ∨ s12 ∨ s ′ 13), (s21 ∨ s22 ∨ s ′ 23), =(s ′ 11 ∨ s12 ∨ s13), (s ′ 21 ∨ s22 ∨ s23)}. The clauses in Γ2 are to be added to the SAT problem. Finally, considering the positive examples, we must introduce the new variables: z(1) 1 ,z(1) 2 ,z(2) 1 ,z(2) 2 ,z(3) 1 ,z(3) 2 . The last set of clauses is thus Γ ′ 3 = { (z(1) 1 ∨ z(1) 2 ), (z(2) 1 ∨ z(2) 2 ), (z(3) 1 ∨ z(3) 2 ) } , which can be transformed into: Γ ′ 3 = { (z(1) 1 ∨ y(1) 11 ), (z(1) 1 ∨ y(1) 12 ), (z(1) 1 ∨ y(1) 13 ), =(z(1) 2 ∨ y(1) 21 ), (z(1) 2 ∨ y(1) 22 ), (z(1) 2 ∨ y(1) 23 ), =(z(2) 1 ∨ y(2) 11 ), (z(2) 1 ∨ y(2) 12 ), (z(2) 1 ∨ y(2) 13 ), =(z(2) 2 ∨ y(2) 21 ), (z(2) 2 ∨ y(2) 22 ), (z(2) 2 ∨ y(2) 23 , =(z(3) 1 ∨ y(3) 11 ), (z(3) 1 ∨ y(3) 12 ), (z(3) 1 ∨ y(3) 13 ), =(z(3) 2 ∨ y(3) 21 ), (z(3) 2 ∨ y(3) 22 ), (z(3) 2 ∨ y(3) 23 ) } . Substituting the y(r ) ij by the sij and s ′ ij , we ﬁnally obtain Γ3 = { (z(1) 1 ∨ s ′ 11), (z(1) 1 ∨ s ′ 12), (z(1) 1 ∨ s ′ 13), =(z(1) 2 ∨ s ′ 21), (z(1) 2 ∨ s ′ 22), (z(1) 2 ∨ s ′ 23), =(z(2) 1 ∨ s ′ 11), (z(2) 1 ∨ s12), (z(2) 1 ∨ s ′ 13), =(z(2) 2 ∨ s ′ 21), (z(2) 2 ∨ s22), (z(2) 2 ∨ s ′ 23), =(z(3) 1 ∨ s ′ 11), (z(3) 1 ∨ s ′ 12), (z(3) 1 ∨ s13), =(z(3) 2 ∨ s ′ 21), (z(3) 2 ∨ s ′ 22), (z(3) 2 ∨ s23) } . The conjunction of all the clauses in Γ1 ∪ Γ2 ∪ Γ3 deﬁnes the CNF for- mula characterizing the SAT problem. A possible solution to the problem is illustrated in Figure 8.3, which shows the template, the value for the Phase transitions and local search in propositional learning 175 h x1 x 1 x3 x3 s11 s ′ 11 s13 s ′ 13 y 11 y 13 x1 x1 x x 3 x 3 s21 s ′ 21 s23 s′ 23 y 21 y 23 x2 2 s22 s′ 22 y 22 x2 x2 s12 s′ 12 y 12 0 0 0 0 1 1 1 1 1 1 1 1 1 2 Figure 8.3 A possible solution of the learning problem described in the Exam- ple. In the template corresponding to the problem the ﬁnal values of the control variables sij , s′ ij are stated on the corresponding input; the shaded components indicate attributes that have been eliminated from the ﬁnal rule. The learned 2- DNF formula is h =(x1 ∧ x3) ∨ (x1 ∧ x2). control variable sij , s ′ ij , and the rule obtained after the template has been simpliﬁed by the removal of redundant literals. In conclusion, we have transformed the learning problem into a (2+ p)-SAT with c =30 clauses, v =18 variables and ratio α =1.667. Of the clauses, 12 are of length 2 and 18 are of length 3; hence p =0.6 (see Section 3.4). 8.2 Phase transitions and local search in propositional learning As already mentioned, k-DNF concept descriptions are highly representative of propositional learning. In fact, they correspond to the standard output for- mat of many learners that work in propositional logics, such as, for instance, RIPPER (Cohen, 1995), PFOIL (Mooney, 1995), and C4.5rules (Quinlan, 1993). 176 Learning, SAT, and CSP A commonly employed heuristic consists in trying to ﬁnd the simplest possi- ble solution, i.e., the solution with the smallest k. The fundamental difference between the approach used by classical learners and the problem reformula- tion described in the previous section is that in the former case k is obtained as an a posteriori result provided by the learner while in the latter case k is given apriori. However, from a practical point of view this is not restrictive, since many values of k can be tried as the learner searches for the smallest value for which a solution does exist. It is worth noticing (R¨uckert et al., 2002; R¨uckert and Kramer, 2003) the following. • If k = |P| then the problem always has a trivial solution, because everyk = |P| means no generalization of the examples. positive example can be encoded into a speciﬁc disjunct. • If a solution exists for a given value ks, a solution will exist for any k> ks. Adding new disjuncts to an already true disjunctive formula does not affect its truth. Thus it is interesting to ﬁnd the minimum value km for which a solution exists. • Finding a solution for any k> km will be easier than ﬁnding a solution for km, because the problem is less restrictive. We will now consider two questions. 1. Given that a k-DNF learning problem can be mapped to a SAT problem, and that SAT problems typically exhibit a phase transition, does k-DNF learning exhibit a phase transition as well? 2. Apart from the theoretical interest, has the transformation from k-DNF learning to SAT any practical advantage? For instance, can the very ef- fective search algorithms developed for SAT be successfully used for learning? As mentioned in Chapter 7, the phase transition emergence in k-DNF learning problems has been throughly investigated by R¨uckert et al. (2002); they showed that a phase transition does exist for a critical value of the number n of variables (Boolean features). Moreover, the critical point ncr of the phase transition was characterized as a function of k and of the numbers |P| and |N | of positive and negative training examples, respectively: ncr ≈ [a(k)log2|N |] (b|P|+c). (8.14) Formula (8.14) is a reasonable conjecture, which was experimentally validated by these authors. It is worth noticing that the phase transition analysis was done Phase transitions and local search in propositional learning 177 using an ad hoc learning algorithm based on set covering, without exploiting the transformation into SAT. In the same paper, and in a companion paper (R¨uckert and Kramer, 2003), an extensive comparison of different stochastic local search (SLS) algorithms was made. As none of these algorithms was designed to work directly on the k-DNF learning problem, this last was reduced to SAT (for which several such searchers exist) using the transformation of Kamath et al. (1992). The algorithms selected were GSAT (Selman et al., 1992), GSAT + Random Walk, GSAT + Tabu, and WalkSAT (Kautz and Selman, 1996). Moreover, these authors designed an efﬁ- cient native SLS algorithm (R¨uckert and Kramer, 2003), which is able to solve hard k-DNF learning problems without transforming them into SAT. The experiments were performed on three sets each containing 100 hard solvable problems taken from the phase transition region. Each learning problem needed to be solved by ﬁnding a k-DNF formula. The reported results clearly show that the native SLS, explicitly designed to solve this speciﬁc task, dom- inates the algorithms designed for SAT; in fact, only WalkSAT reaches perfor- mances that, though inferior, are comparable with those of the native SLS. From the machine learning side, three learners have been selected for com- parison: C5.0 (an improved version of C4.5 (Quinlan, 1993)), RIPPER (Cohen, 1995), and PART (Witten and Frank, 2005). However, these learners are primar- ily aimed not to minimize the number of disjuncts but to reliably cover the class instances. Therefore, the solutions they provide typically contain more disjuncts than the minimum required and exhibit misclassiﬁcation errors on the learning set itself because of the covering criterion used to guide the algorithms. Never- theless they always do provide a solution, but one that has not been tested on an independent test set to evaluate its real accuracy. The computational complexity of the search algorithm is much lower for the machine learning algorithms than for the SAT algorithms. The above results touch a crucial point. Searching for a concept description Concept learning and constraint satisfaction have different goals. is not quite a problem of constraint satisfaction. In the former case, as discussed in Chapter 6, the primary goal is to ﬁnd a formula that exhibits a low general- ization error. Therefore, in general, completeness of the learning set is sacriﬁced in favor of other criteria related to predictiveness. On the contrary, SAT algo- rithms aim at ﬁnding, when possible, a solution that satisﬁes all constraints and is then complete and consistent with regard to the learning set. For this reason it is impossible to use pure SAT algorithms if there is noise (it is always present in real-world domains), because noise makes the learning set inconsistent; then, a pure SAT algorithm cannot ﬁnd a solution. However, in practice algorithms for MaxSAT can be used for this task, as was done by R¨uckert et al. (2002). Nevertheless, like the other algorithms, MaxSAT has the goal of maximizing the number of satisﬁed constraints, without regard for the effect this may have 178 Learning, SAT, and CSP on the predictiveness of the formula being constructed. This can lead to solutions that overﬁt the data and are poorly predictive when applied to data not belonging to the learning set. It is not obvious how to modify SAT or MaxSAT solvers’ heuristics in order to ﬁx this problem. Finally, we note that the same problem remains even when the learning set is consistent: according to the learning heuristic it may be preferable to leave uncovered some examples in order to avoid data overﬁtting, whereas SAT or MaxSAT solvers would provide a complete and consistent solution. From the above discussion it follows that, on the one hand, mapping a k-DNF learning problem to a SAT learning problem is not likely to systemat- ically yield better practical results. On the other hand, the transformation has theoretical relevance as it helps one’s understanding of the mechanisms underly- ing learning. A more successful transformation from a decision-tree learning problem to SAT was described by Bessi`ere et al. (2009), who formulated the problem asInduction of decision trees as a SAT problem one of optimization, namely, to ﬁnd the tree with the minimum number of nodes that correctly classiﬁes all the examples in the learning set. They investigated a formulation based on satisﬁability and constraint programming and compared their approach against standard induction algorithms. More precisely, let T = (X, U, r) be a binary tree, where X is the set of nodes, U is the set of edges, r ∈ X is the root, and L ⊆ X is the set of leaves. A decision tree based on T is a labeled tree in which each internal node x is labeled with a feature, taken from a set F and denoted f (x). Each edge (x, y) ∈ U is labeled with a Boolean function g(x, y),where g(x, y)=0 if y is the left child of x and g(x, y)=1 if y is the right child of x. The size of the decision tree is the number of nodes of T . Given a learning set SL = {e1,...,em}, the authors exhibited a SAT formula that is satisﬁable iff there exists a decision tree, based on T , that classiﬁes SL correctly. The trees obtained through this reformulation were compared by Bessi`ere et al. with those induced by standard state-of-the-art learners, both pruned and unpruned, on several publicly available datasets. The results clearly show that the constraint programming (CP) approach produces very accurate trees, which are smaller than those found using standard greedy unpruned methods. Even when compared with pruned trees, the accuracy of the CP approach is often competitive with, or exceeds, that of pruned trees built using standard methods. 8.3 The FOL covering test as a CSP As introduced in Section 5.2.3, in most relational (ILP) learners the basic covering test consists in proving the satisﬁability of existentially quantiﬁed Relation between CSP and SAT 179 conjunctive formulas such as ∃⃗x [ϕ(⃗x)], with n variables (belonging to a given set X = {x1,...,xn})and m literals (predicates or their negation from a set P) over a universe U . The universe consists of the set of relations (tables) con- taining the extensions of the atomic predicates that are true for an example e; a tabular instance representation was given in Figure 5.9. The formula ϕ(⃗x) is satisﬁable if there exists at least one model (instance) of it in e. We will call the pair (ϕ(⃗x),e)a matching problem. Recalling the deﬁnition of a CSP introduced in Chapter 4, it is clear that a matching problem can be mapped directly to a CSP: the n variables and their associated domains play the same role whereas the m relations expressed by the literals occurring in ϕ(⃗x) correspond to the set R of relations in a CSP. In learning relational concepts, each hypothesis (formula) ϕ(⃗x) generated by the learner must be matched to all the training examples, each corresponding to a different universe. Given that a learner may generate thousands of hypotheses during its work, the complexity of the matching problem may deeply affect the very feasibility of learning. The equivalence between a matching problem and a CSP will be formalized and discussed in detail in Chapter 9. 8.4 Relation between CSP and SAT In previous chapters we have seen that the classes of SAT problems and CSPs are characterized by the presence of a phase transition. In this section we will explore the relations between the two classes. Clearly such relations are guaranteed to exist, because both SAT and CSP are NP-complete and thus in principle can be translated one into the other in polynomial time. Before entering into details, we note that any ﬁnite DATALOG theory can always be translated into an equivalent set of sentences in propositional logic. Let us now introduce an algorithm for translating a ﬁnite CSP into an equiv- Translating CSP into SATalent SAT problem. The fundamental difference between CSP and SAT is that variables in a CSP may have values in a large domain, whereas variables in SAT are Boolean, i.e., they may only assume the two mutually exclusive values {1, 0}. Thus we need a transformation for converting multi-valued variables in a CSP into a set of binary variables. We will consider here only binary CSPs, as the extension to non-binary CSPs is immediate. Let xi ∈ X be a variable in a CSP with domain Di, with cardinality |Di| = di.Wedeﬁneaset Bi of Boolean variables associated with the domain Di.Avariable xi:air, belonging to Bi, assumes the value true when xi is bound to the value air ∈ Di and assumes the value false otherwise. Notice that one and only one variable in the set Bi must be true. These constraints can be encoded in 180 Learning, SAT, and CSP two sets of clauses, S1 and S2.The set S1 contains the clauses stating that each S1 contains clauses stating that each variable must assume one of its values. variable must assume at least one value in its domain: S1 = {αi|1 ⩽ i ⩽ n}, (8.15) αi = di⋁ r=1 xi:air. (8.16) The set S2 contains clauses stating that each variable may assume only oneS2 contains clauses stating that each variable must assume only one of its values. value from its domain: S2 = {β(i) rs |1 ⩽ i ⩽ n, 1 ⩽ r, s ⩽ di,r ̸= s}, (8.17) β(i) rs = xi:air ∨ xi:ais. (8.18) We have now to translate the constraints in the set R (with cardinality m)of the CSP into clauses in SAT. With this aim, let us consider the matrices M (h) ij introduced at the beginning of Chapter 4, which correspond to the constraints Rh(xi,xj ) (1 ⩽ h ⩽ m). Each false entry in M (h) ij corresponds to nogoods and must be excluded. In other words, if the entry m (h) rs is false in M (h) ij then the pair of assignments (xi = air) and (xj = ajs) is forbidden. By translating this condition into the notation introduced before, we obtain a third set, S3,ofClauses excluding the nogoods clauses: S3 = {γ(h) rs |1 ⩽ h ⩽ m, m (h) rs = F }, (8.19) γ(h) rs = xi:air ∨ xj:ajs. (8.20) Solving the CSP is then equivalent to solving the SAT problem that has the set of variables B = ⋁n i=1 Bi and the set of clauses S = S1 ∪ S2 ∪ S3. Globally, the formula to be made true, corresponding to the obtained SAT, is the following: ϕ = ( n⋀ i=1 αi ) ∧ ⎛ ⎝ n⋀ i=1 di⋀ r,s=1,r̸=s β(i) rs ⎞ ⎠ ∧ ⎛ ⎜ ⎝ m⋀ h=1 ⋀ r,s|m(h ) rs =F γ(h) rs ⎞ ⎟ ⎠ . (8.21) Relation between CSP and SAT 181 In order to clarify the translation described above, we will use the small CSP shown in Figure 5.9. EXAMPLE Let X = {x1,x2,x3} be a set of variables, all of which take values in the same domain D = D1 = D2 = D3 = {a, b, c, d}, with cardinality d =4. Moreover, let R = {R1,R2,R3} be the set of three constraints (relations) represented in tabular form in Figure 5.9. The set S1 contains three clauses: S1 = {α1,α2,α3}, where α1 = x1:a ∨ x1:b ∨ x1:c ∨ x1:d, α2 = x2:a ∨ x2:b ∨ x2:c ∨ x2:d, α3 = x3:a ∨ x3:b ∨ x3:c ∨ x3:d. The set S2 contains 18 clauses, six for each variable: S2 = {β(i) rs |1 ⩽ i ⩽ 3, 1 ⩽ r, s ⩽ 4,r ̸= s}, where β(1) 1,2 = x1:a ∨ x1:b, β(1) 1,3 = x1:a ∨ x1:c, β(1) 1,4 = x1:a ∨ x1:d, β(1) 2,3 = x1:b ∨ x1:c, β(1) 2,4 = x1:b ∨ x1:d, β(1) 3,4 = x1:c ∨ x1:d, β(2) 1,2 = x2:a ∨ x2:b,..., β(2) 3,4 = x2:c ∨ x1:d, β(3) 1,2 = x3:a ∨ x3:b,..., β(3) 3,4 = x3:c ∨ x3:d. The set S3 contains the clauses representing the nogoods for the three relations R1, R2,and R3: S3 = {γ(h) rs |1 ⩽ h ⩽ 3, (air ,ajs) /∈ Rh }. For relation R1(x1,x2) the set of nogoods is the following: nogoods1 = {(a, a), (a, c), (b, a), (b, b), (b, c), (c, a), (d, b), (d, c), (d, d)}. Then γ(1) 1,1 = x1:a ∨ x2:a, ... γ(1) 4,4 = x1:d ∨ x2:d. 182 Learning, SAT, and CSP In an analogous way we obtain γ(2) 1,1 = x1:a ∨ x3:a, ... γ(2) 4,4 = x1:d ∨ x3:d, γ(3) 1,2 = x2:a ∨ x3:b, ... γ(3) 4,4 = x2:d ∨ x3:d. The propositional formula to be made true is thus ϕ(x1:a, x1:b,...,x3:d)=(x1:a ∨ x1:b ∨ x1:c ∨ x1:d) ∧ (x2:a ∨ x2:b ∨ x2:c ∨ x2:d) ∧ (x3:a ∨ x3:b ∨ x3:c ∨ x3:d) ∧ (x1:a ∨ x1:b) ∧ (x1:a ∨ x1:c) ∧ ··· ∧ (x3:c ∨ x3:d) ∧ (x1:a ∨ x2:a) ∧ ··· ∧ (x2:d ∨ x3:d). Let us now count how many clauses we have obtained with the preceding transformation. The set S1 contains as many clauses as there are variables; thus,Number of clauses in S1 |S1| = n. Each clause αi (1 ⩽ i ⩽ n) has as many terms as there are values in the domain Di; hence |αi| = di. For any variable xi taking values in Di,thereare ( di 2 ) pairs of conﬂictingNumber of clauses in S2 assignments. Thus |S2| = n∑ i=1 (di 2 ) . (8.22) Given a relation Rh(xi,xj ), the number of entries in the corresponding ma- trix M (h) ij that take the value false is the difference between |Di × Dj | and |Rh(xi,xj )|. Then, for each relation there are (didj −|Rh(xi,xj )|) nogoods.Number of clauses in S3 The set S3 has thus cardinality |S3| = m∑ h=1(didj −|Rh(xi,xj )|). (8.23) The total number of clauses is thus T (n, m, d1,...,dn)= n + n∑ i=1 (di 2 ) + m∑ h=1(didj −|Rh(xi,xj )|). (8.24) We may notice that the clauses in both S2 and S3 have two terms whereas the clause in S1, corresponding to the variable xi,has di terms. Comments 183 If the original CSP was generated by model B, then |Di| = d ∀i ∈ [1,n], |Rh| = N ∀h ∈ [1,m]. Hence, the total number of clauses reduces to: T (n, m, d)= O [n + n( d 2 ) + m(d2 − N ) ] . The ratio of clauses and variables in the corresponding SAT will be, in this case, Value of α in the corresponding SAT for a CSP generated with model B.α = 1 n [n + n(d 2 ) + m(d2 − N )] =1 + d(d − 1) 2 + m n (d2 − N ). Using the expressions p1 =2m/[n(n − 1)] and p2 =1 − N/d2, the control parameter α can be rewritten as α =1 + d(d − 1) 2 + p1p2 d2(n − 1) 2 . (8.25) We now have a formal method for converting a CSP into a SAT problem. The immediate beneﬁt is that we can use an algorithm for solving a SAT problem to solve a CSP. 8.5 Comments Even if the transformations between propositional learning and SAT problems and between CSP and SAT are interesting per se, a question arises about their practical utility. One would like, on the one hand, to exploit the results found for SAT in order to predict when the converted problem is in the phase transition region and, on the other hand, to apply the very effective search algorithms de- signed for SAT. Unfortunately, both hopes remain to be realized. The classical models used for predicting the phase-transition location in SAT assume a ﬁxed size k for all clauses, while the SAT instances obtained by transformation have clauses with a variable number of terms, leaving aside the fact that most results have been obtained only for k ⩽ 3. In addition, the utility of SAT solvers for learning and solving CSPs has not received a deﬁnite assessment; performances appear to depend on the speciﬁc problem approached. 9 Phase transition in FOL covering test Contents 9.1 Model RL 185 9.2 The search algorithm 195 9.3 Experimental analysis 198 9.4 Comparing model RL with other models for CSP generation 202 9.5 Smart algorithms for the covering test 214 9.6 Comments 217 In this chapter we will discuss in depth the results that have emerged in re- cent work on the covering test in ﬁrst-order logic (Giordana and Saitta, 2000; Maloberti and Sebag, 2004); this was introduced in Section 5.2.3, with particu- lar emphasis on the DATALOG language. With this language, the covering test for a hypothesis ϕ(x1,...,xn) reduces to the problem of ﬁnding a substitution θ, for the variables x1,...,xn, by a set of constants a1,...,an that satisﬁes the formula ϕ. Moreover, in Section 8.3 we showed how a covering test, i.e., the matching problem (ϕ, e), can be transformed into a CSP. As a consequence, a phase tran- sition may be expected in the covering test, according to results obtained by sev- eral authors (Smith and Dyer, 1996; Prosser, 1996). As discussed in Chapter 4, studies on CSPs have exploited a variety of generative models designed to ran- domly sample areas of interest in the CSP space. As the CSPs occurring in 184 Model RL 185 practice may have hundreds or thousands of variables and constraints, the in- vestigations were oriented toward large problems; also, there was much interest in the asymptotic behavior of CSPs for large n. In machine learning, even though the equivalence of the matching problem Machine learning deals with small CSP problems. with a CSP suggests the emergence of a phase transition, the range of problem sizes involved is much smaller, as the typical number of variables and constraints in relational learning is rarely greater than 10. Thus, the ﬁrst question we want to answer is whether a phase transition is present in the region of the CSP space visited by a relational learner.AsuncoveredbyBotta et al. (1999) and by Gior- dana and Saitta (2000), a phase transition is indeed detected for problem sizes relevant to machine learning, even if it is less sharp than in the area explored by Prosser (1996). In this chapter we will discuss this in detail. A second relevant question concerns the impact that the presence of a phase transition may have upon the quality, or even the very feasibility, of relational learning. Chapter 10 answers this question. Investigating the covering test in ﬁrst-order logic, Giordana and Saitta (2000) implicitly proposed a generative model of matching problems of the type en- countered in machine learning. Thus our starting point will be to revisit this model, which we will name model RL,1 making explicit its properties and rela- tionship to the classical models. Then we will review and discuss the experiments of Giordana and Saitta (2000) and of Maloberti and Sebag (2004). Finally, we will compare the ﬁndings obtained using model RL with those obtained by other authors. 9.1 Model RL Generative models used for investigating CSPs are characterized by: • a set of control parameters describing the CSP space; • a set of basic assumptions restricting the control parameters; • an algorithm for the stochastic generation of CSP instances. An aspect that differentiates model RL from other models is the choice Model RL was designed to investigate the occurrence of a phase transition in the matching problem in relational learning. of control parameters. Instead of using the classical p1 and p2 directly (see Section 4.2), four different parameters, two characterizing the example complex- ity and two characterizing the hypothesis complexity, are chosen, as described in the following. The generative algorithm is also different, so that problem in- stances preserve some plausibility with respect to real learning problems. 1The notation RL indicates that the model was designed to investigate CSPs in relational learning. 186 Phase transition in FOL covering test 9.1.1 The control parameters Before entering into the discussion of control parameter selection, we recall that a matching problem is a pair (ϕ, e),where ϕ is a hypothesis (a DATALOG for- mula) and e is an example (a set of tables). The example e constitutes the universe U ,where ϕ must be proved true or false by performing the covering test. Control parameters characterizing learning examples In relational learning an example e is deﬁned by a set of atomic objects described by a set of attributes and a set of relations stating their mutual interactions. The atomic objects occurring in the universe U corresponding to e are given and, in a logical framework, they are identiﬁed by means of a set Λ of L constants (symbols) ai: Λ= {a1,a2,...,aL}. (9.1) The ﬁrst parameter, which naturally appears as a good candidate for characteriz- ing the complexity of an example, is the number L of its atonic components, i.e., the cardinality of the set Λ. As discussed in Section 5.2.2, relations between objects are represented by means of tables, as is common in relational databases. Every instance of a rela- tion Rh involving a group of objects is encoded by a row in the corresponding table. Let Nh denote the cardinality of the relation Rh (i.e., the number of rows in the corresponding table) and rh denote its arity (i.e., the number of columns in the associated table). It is immediate to see that Rh is a subset of the maximal table Λrh obtained as the Cartesian product of set Λ with itself rh times. If the tuples that populate the table are sampled from Λrh uniformly and with replacement, the probability that a tuple ⟨a1,a2,...,arh ⟩ is included at least once in Rh is given by Ph = P(⟨a1,a2,...,arh ⟩∈ Rh)=1 − (1 − 1 Lrh )Nh , (9.2) where Nh is the cardinality of Rh. Alternatively, if sampling is performed without replacement the probability is given by Ph(⟨a1,a2,...,arh ⟩∈ Rh)= Nh Lrh . (9.3) We note that (9.2)and (9.3) tend to coincide when L →∞. In fact, for x → 0 we have (1 − x)t ⋍ 1 − tx. It is of interest to observe how L and Nh interact. From equations (9.2)and (9.3) we see that, in both cases, increasing Nh means that Ph increases whereas increasing Lh means that Ph decreases. Thus if Rh is a binary constraint in a CSP (rh =2), the probability of obtaining a solution is directly correlated with Model RL 187 Nh and inversely correlated with L2. Therefore we will use the Nh and L as parameters to characterize the complexity of e. Control parameters depending on the hypothesis description Let ϕ(x1,x2,...,xn) be the hypothesis to be veriﬁed in e. Both the complexity of the covering test and the probability of success depend on two features of ϕ: the number n of variables and the number m of literals (i.e., predicates or their negation) occurring in ϕ. We recall that in DATALOG the covering test corresponds to the problem of ﬁnding a substitution θ =(x1/a1,x2/a2,...,xn/an), (9.4) for variables x1,x2,...,xn with constants ai from the domain Λ, such that ϕθ is satisﬁed. The parameter n deﬁnes the tuple length and characterizes the size of the space Θ from which θ must be selected. More speciﬁcally, the size of Θ is |Θ| = Ln. The parameter m deﬁnes the number of constraints occurring in ϕ.Were- member that each predicate ph occurring in ϕ is associated with a speciﬁc rela- tion Rh deﬁned in e. Thus ph denotes a constraint deﬁned by Rh,whichrules out a subset of the possible substitutions Θ. Note that keeping constant the number of variables n and increasing the number of literals m in a hypothesis ϕ reduces the number of substitutions θ ∈ Θ that satisfy ϕ,making ϕ more difﬁcult to satisfy. Conversely, increasing n while m remains constant increases the number of substitutions θ satisfying ϕ,making ϕ easier to satisfy. In our context, we select the number of predicates m as a second control parameter. 9.1.2 Model assumptions In order to obtain a manageable form of the matching problem (ϕ, e), while preserving the essence of the problem itself, we need to make some assumptions about the control parameters to be used and the structure of the hypothesis and of the example. The parameters n (the number of variables) and m (the number of literals) have an immediate interpretation in ϕ and can be used as control parameters. However, the cases of L and Nh need some discussion. Every relation Rh occur- ring in e may have, in principle, a different size Nh. Moreover, in the real world every relation Rh can be selected from the space Λrh using a different criterion, i.e., a different distribution, depending on the speciﬁc application. In addition, not all the L constants may appear in all relations. Thus it is not possible to obtain Nh and L from an example without making further assumptions. 188 Phase transition in FOL covering test Assumption 1 All relations have the same size N , the same arity r and the same distribution over the space Λr. The choice in Assumption 1 focuses the attention on speciﬁc classes of problems that are relevant to practical learning applications while potentially containing very hard instances (Giordana and Saitta, 2000). This class is characterized byAll relations have the same size. examples containing large numbers of atomic objects of only a few different types, linked by the same type of relations. Problems of this class are frequently found, for instance, in chemistry and molecular biology. Assumption 1 allows the matching problem (ϕ, e) generated by the model RL to be characterized by a 4-tuple ⟨n, m, L, N ⟩. Assumption 2 Target relations have 0-arity and conjunctive descriptions. As discussed in Chapter 5, the simplest case of relational learning consists in learning 0-arity relations (constants) corresponding to concept descriptions of the form: ϕ(x1,x2,...,xn) → c, (9.5) where c is a constant (a concept name), which is true or false in a given ex- ample e depending on whether ϕ is true or false in e. We also remember that variables in a clause not occurring in the head (in this case the right-hand side of the implication) are implicitly existentially quantiﬁed. Moreover, the formula ϕ describing the concept is assumed to be a conjunction of literals. Thus in this case the covering test reduces to the veriﬁcation of an existen-Target concepts are 0-arity relations with conjunctive descriptions. tially quantiﬁed formula of the type ∃⃗x [ϕ(⃗x)],where ϕ(⃗x) is a conjunction of literals. As a matter of fact assumption 2 is not strongly limitative, because in su- pervised learning the complexity of the covering test depends only on the com- plexity of verifying the existentially quantiﬁed part of the formula. In fact, the possible bindings for the variables occurring in the head of a hypothesis (the target relation) are ﬁxed by the apriori knowledge given by the teacher. Apart from its simpliﬁcation of the matching problem, this assumption also allows us to compare, in the next chapter, various relational learners independently of their ability to learn relations having arity greater than 0. Assumption 3 Only binary relations are considered in the examples and, consequently, only binary predicates will occur in the hypotheses. This third assumption (r =2) greatly simpliﬁes the model while preserving its plausibility. In addition, it allows our results to be compared directly with the Model RL 189 many available in the literature for binary CSPs. In principle, relations of any arity may occur in a universe e, including unary relations and relations of arity greater than 2. Nevertheless, a restriction to binary relations is not limitative for Concept descriptions are built on binary relations. two reasons. The ﬁrst is that most existing relational learners work with unary and binary relations only. The second is that it is always possible to transform a universe containing relations of different arity into a universe containing only binary relations. Assumption 4 Only connected formulas are considered. This fourth assumption concerns the structure of the hypothesis. We say that aformula ϕ is unconnected when there exist two (or more) subsets of vari- ables ⃗x1 = {x1,x2,...,xk} and ⃗x2 = {x′ 1,x′ 2,...,x′ r} such that no literal in ϕ(⃗x1, ⃗x2) has variables in both ⃗x1 and ⃗x2. In fact, if two such subsets exist then a hypothesis, under assumption 1, can always be reduced to the conjunction of two independent existentially quantiﬁed subformulas: ∃ ⃗x1, ⃗x2 [ϕ(⃗x1, ⃗x2)] ≡∃⃗x1[ψ(⃗x1)] ∧∃⃗x2[ρ(⃗x2)]. (9.6) In this case, the original problem is reduced to two simpler problems, consisting in matching ∃⃗x1[ψ(⃗x1)] and ∃⃗x2[ρ(⃗x2)] separately on e. In order to avoid this case, model RL is prevented from generating uncon- nected hypotheses. This restriction is not limitative. On the one hand, most ex- Only connected formulas are considered. isting relational learners will make assumption 4 and so will not generate un- connected hypotheses. In fact, allowing a relational learner to construct such hypotheses entails a tremendous increase in the size of the region of hypothe- sis space visited by the learner. On the other hand, the complexity of the cov- ering test for unconnected formulas can be simply obtained as the sum of the complexity of the unconnected components. Thus investigating the covering test complexity for connected formulas is sufﬁcient. Assumption 5 Learning examples contain only relations corresponding to the literals occurring in ϕ. This last assumption concerns the structure of the examples. More speciﬁcally, in model RL it is assumed that a positive example only contains relations that occur in the target concept, namely in examples where there are no irrelevant predicates. This assumption is a simpliﬁcation that does not affect the complexity of the covering test; irrelevant relations, i.e., relations that do not correspond to any literal in the formula to be veriﬁed, are simply disregarded by any theorem prover. On the contrary, it makes signiﬁcantly easier the inductive search of the All relations in an example are relevant to the concept description. 190 Phase transition in FOL covering test learner, as we will discuss in the following chapter. In fact, a large number of irrelevant hypotheses are implicitly ruled out. Therefore, under the above ﬁve assumptions, every pair (ϕ, e) generated by model RL will correspond to a speciﬁc point in the space ⟨n, m, N, L⟩. 9.1.3 Matching problem generation We are now ready to describe the algorithm used to construct CSPs belong- ing to the space characterized by model RL. The input of the algorithm is a 4-tuple ⟨n, m, N, L⟩ chosen apriori. The CSP construction occurs in two steps. The ﬁrst generates the universe e (the example), while the second con-n variables m literals L constants N rows in relational tables structs the hypothesis ϕ to be veriﬁed in e. More speciﬁcally, the second step ﬁrst constructs a “skeleton” of the formula, thus guaranteeing that it is con- nected; then, other literals are added until the required number m of literals is reached. Let X = {x1,x2,...,xn} denote the set of n variables, and P = {p1,...,pm} the set of m literals. Given L and N , e is fully deﬁned by a set R of m relational tables, each one associated with a predicate in the set P. According to the assumptions made, allAn example is a universe containing tables corresponding to the predicates deﬁned in the hypothesis description language. tables are binary and have the same size N . Every table is populated by sam- pling at random, without replacement, N pairs from the set Λ × Λ. The table construction proceeds as in step 1 below. Step 1 Relational table construction Let R denote the table, initially empty, to be populated. Let s be the current number of tuples added to R. 1. Construct the universal binary relation Λ × Λ,and set s =0. 2. While s<N , extract uniformly, without replacement, one pair t from Λ × Λ and add t to R. Increment s by 1. 3. Add R to example e. Notice that, as pairs are sampled without replacement, no relation will contain duplicate tuples. Step 2 Construction of hypothesis ϕ Starting from X and P, and assuming that m ≥ n − 1, a formula ϕ(⃗x) is constructed as follows: 1. Set ϕ(⃗x)= ⊤, the most general hypothesis. 2. Form the sequence of variables x1,x2,...,xn. Model RL 191 3. For each pair of consecutive variables (xi,xi+1)(1 ⩽ i ⩽ n − 1) do • Extract uniformly, without replacement, a predicate from P and ap- ply it to the variable pair (xi,xi+1). • Call αi(xi,xi+1) the literal so obtained and add it to the current for- mula as a conjunct. 4. For each of the remaining m − n +1 predicates in P, do • Extract a pair of variables (yj ,zj ) from X×X such that yi ̸= zi, call βj (yj ,zj ) the literal so obtained, and add it to the current formula as a conjunct. In step 2, the third point constructs the “skeleton” of the connected formula and guarantees that all n variables are chained, so that the matching problem cannot be reduced to smaller problems (with smaller n values). The fourth point brings the number of predicates in ϕ(⃗x) to the desired value m. Note that no predicate is negated. The formula generated contains exactly n variables and m predicates, and the same pair of variables may appear in more than one predicate. The ﬁnal formula assumes the following format: ϕ(⃗x)= n−1⋀ i=1 αi(xi,xi+1) ∧ m−n+1⋀ j=1 βj (yj ,zj ). (9.7) The above generation procedure is close to model B, introduced by Smith and The procedure for generating the example is similar, but not identical, to that used in model B. Dyer (1996) for CSPs. Similarities and differences will be discussed later in this chapter. The hypothesis space H to be explored contains a number |HRL| of syntactically different formulas: |HRL| = ( m n − 1 )(n − 1)!(n2 − n) m−n+1. (9.8) Expression (9.8) is computed as follows: when constructing the ﬁrst part of for- mula (9.7), n − 1 predicates are selected without replacement from a set of m; this selection gives ( m n−1) alternatives. Each of the n − 1 selected predicates can be applied to any pair (xi,xi+1) of variables; each permutation of the as- signments generates a different formula, because the predicates are all differ- ent, as well as the variable pairs. Thus there are ( m n−1) (n − 1)! alternatives for the ﬁrst part of formula (9.7). Regarding the second part of the formula, the predicates are the m − n +1 not yet used; each can be applied to any combi- nation of different variable pairs. The total number of variable pairs is n2,but we have to subtract pairs where the same variable occurs in both places, i.e., 192 Phase transition in FOL covering test x 1 x 2 x 3 x4 x 5 p2 p 4 p 8 p1 p5 p7 p3 Figure 9.1 Example of a constraint graph corresponding to a formula gener- ated by model RL, starting from a set X = {x1,x2,x3,x4,x5} of ﬁve vari- ables and a set P = {p1(x, y),p2(x, y),p3(x, y),p4(x, y),p5(x, y),p6(x, y), p7(x, y),p8(x, y)} of eight predicates. The formula is ϕ(x1,...,x5)=[ p2(x1,x2) ∧ p4(x2,x3) ∧ p8(x3,x4) ∧ p1(x4,x5)] ∧ [ p3(x2,x3) ∧ p5(x2,x5) ∧ p7(x3,x5)] . n pairs. Thus the number of different alternatives for the third factor in (9.7) is (n2 − n)m−n+1. In Figure 9.1 an example of a constraint graph corresponding to a formula generated by model RL is given. We can also count the number of different examples that can be constructed by model RL: |ERL| = (L2 N )m (9.9) Globally, model RL can generate a number of matching problems equal to |HRL||ERL| = m!(n2 − n)m−n+1 (m − n + 1)! (L2 N )m. Notice that, according to assumption 3, any ϕ generated in this way contains binary predicates only. Moreover, according to assumption 5, e contains all and only the relations corresponding to the literals occurring in ϕ. The natural loga- rithm of |HRL| is plotted in Figure 9.2 as a function of n and m. EXAMPLE Let us consider the variable set X = {x1,x2,x3} and the predicate set P = {on(x, y), left(x, y), adjacent(x, y)}. In this case n =3 and m =3. The predicate on(x, y) states that object x touches object y from above and the predicate left(x, y) states that object x is to the left of object y whereas the predicate adjacent(x, y) states that objects x and y touch each Model RL 193 2 4 6 8 10 n 5 10 15 20 m 0 20 40 60 ln H Figure 9.2 Natural logarithm of the function ln |HRL| vs. n and m. c a b c a b (a) (b) Figure 9.3 (a) An instance satisfying the formula ∃⃗x[ϕ1(⃗x)]. (b) An instance satisfying the formula ∃⃗x[ϕ2(⃗x)]. other laterally. The predicate adjacent(x, y) is symmetrical. Two possible formulas are ∃⃗x[ϕ1(⃗x)] = left(x1,x2) ∧ on(x2,x3) ∧ adjacent(x3,x1), ∃⃗x[ϕ2(⃗x)] = on(x1,x2) ∧ adjacent(x2,x3) ∧ left(x1,x3). In Figure 9.3 one instance of each formula is provided. An interesting point to be discussed is the structure of the constraint graph G. In fact, owing to the fact that predicates may share the same pair of variables, the number s of edges in G is a stochastic variable whose value depends upon m 194 Phase transition in FOL covering test 0 10 20 30 40 50 0.1 0.2 0.3 0.4 0.5 0.6 m 50 m 45 m 40 m 30 m 24 m 20 m 13 s qm-n ( ) +1 s Figure 9.4 Probability distribution qm−n+1(s) as a function of the number of edges s in the constraint graph. The curves are shown for n =10 and various values of m. The curves start at s = n − 1=9. (Note that the deﬁning symbols merge along the s axis.) 10 20 30 40 50 10 15 20 25 30 m s Figure 9.5 Average value ¯s of the number of edges in the constraint graph gen- erated by model RL, as a function of the number m of predicates. The search algorithm 195 and n. All the graphs that can possibly be generated belong to an ensemble GRL, which can be partitioned according to the number of edges: GRL = m⋃ s = n−1 Gs. All graphs belonging to a particular Gs have the same probability of occurrence, but the probability that a constraint graph belongs to Gs is not uniform over the number of edges s. In order to compute this probability, let us consider what happens in point 4 of step 2 of the above generation algorithm. In the following, let us deﬁne M = n(n − 1)/2. A number m − n +1 of extractions of pairs of (different) variables is performed in sequence and with replacement. Then, let us deﬁne by qk(s)(n − 1 ⩽ s ⩽ min[n + k − 1,M ]) the probability distribution of s after the kth extraction. At each extraction the number s may either remain the same (if the extracted pair already appears in the formula) or may increase by 1 (if the extracted pair does not already appear in the formula). As extraction is uniform, the probability that an already existing pair is extracted is proportional to the current number of existing pairs. We can provide a recursive deﬁnition of the probability qk(s): q0(s)= δ(s, n − 1), qk(s)= ⎧ ⎪⎪⎪⎪⎪⎪⎨ ⎪⎪⎪⎪⎪⎪⎩ 0 if s ⩽ n − 2, [(n − 1)/M ] k if s = n − 1, qk−1(s − 1) [1 − (s − 1)/M ] + qk−1(s)s/M if n ⩽ s ⩽ min[M, n + k − 1], 0 if s ⩾ min[M, n + k − 1] + 1. It is easy to prove, using induction over k,that qk(s) is indeed a probability distribution, as it is normalized for each k ∈ [0,m − n +1] over the values s ∈ [n − 1, min[M, n + k − 1]]. Notice that, from the point of view of the graph structure, the pair (xi,xj ) is equivalent to the pair (xj ,xi). The ﬁnal probability distribution is that obtained for k = m−n+1. In Figure 9.4 the probability distributions obtained for n =10 and m =13, 20, 24, 30, 40, 45, 50 are given. In Figure 9.5 the average value of s is shown for 10 ⩽ m ⩽ 50. 9.2 The search algorithm Before addressing the experimental analysis of the covering test complexity for formulas generated by model RL, we need to select the search algorithm. Given 196 Phase transition in FOL covering test left(x1, x2) ν0 adjacent(x1, x2) on(x1, x2) x1/c, x2/b, x3/a x1/c, x2/b x1/c x1/a Figure 9.6 The search tree explored by the covering test for the formula ∃⃗x [ϕ(⃗x)] = on(x1,x3) ∧ left(x1,x2). aformula ϕ, with n variables and the syntactic structure (9.7), and a universe e, the search for a substitution θ satisfying ϕ in e entails visiting a tree τ ,as indicated in Figure 9.6. A node ν at a level k in τ corresponds to an allowed substitution θ for the variables x1,...,xk, considered in a given sequence.2 The leaves of τ at the level k = n represent models of ϕ and are solutions to the matching problem. Depending upon the strategy used for visiting τ , different algorithms show different search complexities. However, the primary goal of the inves- tigation reported in the following was not to reduce the search complex- ity but to design a generic (unbiased) algorithm to be used as a standard tool to measure and compare complexity. Smart, sophisticated, search algo- rithms tend to exhibit performances that are dependent on the speciﬁc problem conﬁguration. The stochastic search algorithm that we propose guarantees performances more homogeneous than those of deterministic backtracking algorithms. A natural reference baseline is represented by backtrack search algorithms, which have been the starting point for most problem-solving methods in artiﬁ- cial intelligence and are still now at the heart of the inference mechanism in logic programming environments such as Prolog. However, backtrack algorithms visit 2Different orderings of the variables, both static and dynamic, have been tried with no notice- able change in the emergence of the phase transition. The search algorithm 197 the search tree in a preassigned order and exhibit very different performances depending on the position of the solutions in the tree. An alternative is repre- sented by stochastic search algorithms, which show more homogeneous perfor- mances. A comparison between a backtrack deterministic search algorithm and a stochastic search algorithm, in the context of the present study, was presented by Botta et al. (1999). Based on that comparison, the analysis reported here was done using a stochastic algorithm because it offers the advantage of both a lower average complexity and a lower complexity variance than a deterministic algorithm. The search algorithm consists of the iteration of a one-step stochastic search function until either a model is found or the whole tree has been explored unsuc- cessfully. Let MC(τ, n) be a Monte Carlo stochastic algorithm, i.e., an algorithm that, according to the classiﬁcation of Brassard and Bratley (1988),alwayspro- vides an answer; however, the answer may be incorrect. The parameters τ and n of the function denote the search tree and the number of variables (the maxi- mum depth of the tree), respectively. The algorithm MC(τ, n) explores one path on the search tree (see the example in Figure 9.6), starting from the root ν0 and ending in a leaf ν, which may or may not be a solution. During the algorithm’s execution, ν is associated with a sequence of nodes in the tree at increasing depth, and corresponds to increasingly complete, allowable, partial assignments of values to the variables x1,...,xn. By iterating MC on τ as follows, more and more paths are explored: MC(τ, n) ν = ν0, leaf = false while(¬leaf ) do3 if ν is a leaf at level k then leaf = true else Identify the Selectable children of ν, and put them into a set C(ν) Extract a node ν′ from C(ν) with uniform probability Set ν = ν′ endif end Label ν is closed if the level of ν is k = n then answer YES else answer N O. Depending on the semantics of the criterion Selectable, different sets of child nodes of ν are included in C(ν). In the simplest case, all nodes are always 3The notation ¬leaf means the negation of leaf . 198 Phase transition in FOL covering test Selectable, and the stochastic search is made with replacement: any leaf can be reached repeatedly. In this case the complete exploration of τ may asymp- totically require an inﬁnite number of repetitions of MC. If a search without replacement is chosen, the Selectable predicate will not include in C(ν) any node that either is closed (already explored) or has only closed children. In this case every iteration of MC ends in a different leaf of τ , and the whole tree is guaranteed to be completely explored with at most the same complexity as that of an exhaustive backtrack search algorithm. The experiments reported in this chapter were done using search without replacement. 9.3 Experimental analysis In order to locate the phase transition, points in the (m, L) plane were systemati- cally explored for ﬁxed values of the parameters n and N . More speciﬁcally, for n =4, 6, 10, 12, 14 and for N =50, 80, 100, 130 the complete mesh, covering the region (10 ≤ L ≤ 50, n − 1 ≤ m ≤ 50) in the plane (m, L), was consid- ered. For each pair (m, L) belonging to the mesh, 100 problems were generated, giving a total of about 900 000 problems. The range of n was chosen to be con- sistent with that employed in relational learning, where only a few variables have been considered so far. 9.3.1 Probability of solution A three-dimensional plot representing the empirical probability of solution Psol as a function of m and L is shown in Figure 9.7 for n =10 and N = 100.For each point in the mesh, Psol has been computed as the fraction of problems with a solution among all the generated ones at that point. The graph in Figure 9.7 is very steep. To the left of the descent it shows a plateau, where the probability of ﬁnding a solution is almost equal to 1 (all the generated matching problems were solvable); we call this the YES region.TotheA sharp transition from a YES region toaNOregion appears. right the graph again shows a plateau, where the probability of ﬁnding a solution is almost equal to 0 (no generated matching problem was solvable); we call this the NO region. In between, where the graph values rapidly drop from almost 1 to almost 0, is the phase transition region, also called the mushy region (Smith, 1994). The ideal phase transition location coincides with the set of points on the graph where Psol =0.5. An interesting feature of the graph is the regularity of the projection onto the (m, L) plane of the contour level plot at Psol =0.5; this projection is a very smooth curve with a hyperbolic-like behavior. Figure 9.8(a) shows these Experimental analysis 199 100 Psol 50 m L 0 20 30 40 50 20 30 40 50 Figure 9.7 Three-dimensional plot of the probability of solution Psol for n = 10 and N = 100. Some contour level plots, corresponding to Psol values in the range [0.85 ÷ 0.15],4 have been projected onto the (m, L)plane. L L )b()a( n = 6 m m N = 50 n = 10N = 100 Figure 9.8 Plots of the 0.5-level contour of the probability of solution Psol. (a) Graphs corresponding to the numbers of variables n =6, 10,and 14, with relation cardinality N = 100.Aswemusthave m ⩾ n − 1 for each m value, the highest acceptable graph is that for n = m +1. (b) Graphs corresponding to relation cardinalities N =50, 80, 100,and 130, with n =10.Aswemusthave N ⩽ L2 for each value of L, the rightmost acceptable graph is that for N = L2. 4This can also be written as [0.85, 0.15]. 200 Phase transition in FOL covering test projections for numbers of variables n =6, 10,and 14, with relation cardinalities N = 100. Figure 9.8(b) shows an analogous set of contour plots for a constant number of variables n =10 and for relation cardinalities N =50, 80, 100,and 130. 9.3.2 Search complexity For a quantitative analysis of the complexity, a random search without replace- ment was performed by repetition of the Monte Carlo algorithm described in Section 9.2.Thecost C of the search was deﬁned as the total number of nodes explored in the search tree until either a ﬁrst solution is found or unsatisﬁabil- ity is proved. For unsatisﬁable problems it is necessary to explore the whole tree. In Figure 9.9(a) the graph of the search complexity C, averaged over 100 repetitions for each point, is shown, for n =10 and N = 100.The shape and location of the highest-complexity region roughly matches the transition in probability seen in Figure 9.7 but it is more irregular and also broader, like a mountain chain. Within the “mountain” there is a large variability between dif- ferent problems, witnessed by the variance plot shown in Figure 9.9(b). As oneA complexity peak appears in correspondence with the phase transition. might expect, the highest-variance values correspond to the highest peaks. The maximum-complexity contour coincides with the contour plot at Psol =0.5, as found previously by, for instance, Hogg (1996), Hogg et al. (1996),and Cheeseman et al. (1991). It is worth noticing that the complexity distributions for solvable and unsolv- able problems may be very different, as unsolvable problems usually require much more search. Approximations to the complexity probability distributions at the phase transition for solvable and unsolvable CSPs were provided by Frost et al. (1997). They showed that a lognormal distribution is a good approxima- tion for unsolvable problems. For solvable problems several known distributions (in particular, the Weibull distribution) were tried with less success. However, from all the reported experiments it clearly emerges that the complexity distribu- tions of both solvable and unsolvable problems have a long tail in the region of extremely hard problem instances. Finally, Figure 9.9(c) shows the dependency of the CPU time upon the number of nodes explored, for two different imple- mentations of the stochastic matching algorithm, S1 and S2. Implementation S1 stores the entire search tree, so that the time complexity is linear in the number of nodes but the memory requirement is very heavy. Conversely, implementa- tion S2 makes use of implicit indexing to avoid storing the pointers from a node to its children. Then the memory request is more modest but there is an extra cost in CPU time, which is quadratic in C. Implementation S2 is a reasonable (a) (b) 0 20 40 60 80 100 0 5000 10000 15 000 20000CPUS1 S2 (c) 10 000 20 30 40 50 20 30 40 50 5000 0 20 30 40 50 C 20 30 m m L L 40 50 SDC 10 000 5000 0 C Figure 9.9 (a) Plot of the complexity C of the Monte Carlo stochastic search algorithm MC without replacement, for n =10 and N = 100. Each point is the average over 100 problem instances. (b) Plot of the standard deviation of the complexity. (c) CPU time in centiseconds vs. the complexity of the search for two different implementations, S1 and S2, of the stochastic matching algorithm. 202 Phase transition in FOL covering test trade-off and was used for most experiments reported here.5 The measures were obtained using a Pentium II-366. 9.4 Comparing model RL with other models for CSP generation We will now provide an interpretation of the experimental ﬁndings given in the previous section for model RL and compare them with other models discussed in the literature (see Section 4.2). Figure 9.8 shows the hyperbolic-like shape of the phase transition edge in the plane (m, L), which moves far from the origin as parameters n and N increase. 9.4.1 Explaining the ﬁndings with model RL An intuitive explanation of the observed hyperbolic behavior is obtained by con- sidering how the probability value Pα that a substitution {xi/ai,xj /aj } satisﬁes a generic relation α(xi,xj ) depends upon L (see (9.1)). According to (9.3)the probability Pα that the pair (ai,aj ) occurs in the table Rα is N/L2, as sampling is done without replacement in model RL. Thus the effect of increasing L whileIncreasing L for constant n and N increases the constraint tightness. N remains constant corresponds to a decrease in the value Pα, i.e., an increase in hardness of the constraint set for each literal occurring in a formula. This ex- plains why the phase transition edge moves closer and closer to the L axis as L increases. In fact, if we observe that the larger is m the harder it is to satisfy the formula (for N constant) then increasing L means that even very small formulas (with only a few predicates) become unsatisﬁable. The opposite is also true: if L decreases, it is necessary to construct very long formulas (large m values) for such formulas to be unsatisﬁable. However, in this case L cannot decrease down to 0. In fact, when L = √ N , the probability Pα that the pair (ai,aj ) occurs in Rα is 1 because, for this value of L, all pairs in Λ2 occur in the table and the formula ϕ is satisﬁed for any value of m. Thus the horizontal line L = √N is a limiting curve in the plane (m, L). Another limiting line is the vertical at m = n − 1. Let us now consider Figure 9.8(b) and the effect that an increase in the cardi- nality N of the relations has on the location of the phase transition. For constant 5During the generation of the graph in Figure 9.9(a) (involving 160.000 matching problems), S2 never exceeded the memory size of 2 Mbytes whereas S1 grew to 12 Mbytes. The time elapsed was about 215 min for S1 and 280 min for S2 . When formulas with 14 variables were being processed, several times S1 was unable to ﬁnish whereas S2 exhibited a typical size of 2 Mbytes in the phase transition region and reached a maximum of 56 Mbytes. The time elapsed was 1650 min for S2 whereas S1 ran for several days due to its intensive use of the virtual memory. Comparing model RL with other models for CSP generation 203 L, increasing N means increasing Pα. Let us consider in Figure 9.8(b) a particu- lar curve corresponding to a value N1,and let N2 >N1. For each horizontal line corresponding to a speciﬁc value of L, the intersection of the phase transition line for N2 with this horizontal line will be located to the right of the intersec- tion point with the phase-transition line corresponding to N1. In fact, increasing N will extend the YES region, which is located to the left of the phase transition boundary. As a consequence the whole phase transition line will be displaced to- wards the right as N increases. However, for any ﬁnite N , Pα → 0 for L →∞. In order to understand how the phase transition boundary depends on the number n of variables (see Figures 9.8(a) and 9.10), we need to consider how the probability Psol = Pϕ that a formula ϕ is satisﬁed depends upon the struc- ture of ϕ. In fact, increasing or decreasing n affects the distribution of the literals over the variables, weakening or hardening the constraints on the edges of the constraint graph associated with ϕ. Providing an analytic form for Pϕ is a difﬁ- cult task, not yet solved in its generality. Nevertheless, a rough estimate can be obtained for particular cases. Thus we will consider simple formulas as building blocks of more complex formulas, for example, ψ(x1,x2)= k⋀ i=1 αi(x1,x2). (9.10) Under the assumption that all the relations αi contain exactly N tuples indepen- dently sampled from Λ2, the probability that a constant pair (a1,a2) satisﬁes ψ is Pψ = P k α . Thus the set of pairs of constants satisfying ψ in a universe e is the intersection of the k relational tables αi, whose expected size (with respect to the different constraint graphs having the same parameters) is Nψ = L 2P k α = L 2 ( N L2 )k = N k L2(k−1) . (9.11) As a particular case, when k =2 we have Nψ = N 2 L2 . (9.12) Considering model RL, we note that formulas of the type (9.10) emerge as funda- mental building blocks. In fact, according to the generative algorithm described in Section 9.1.3, several literals may share the same variable pair; hence, the global constraint on an edge of the constraint graph associated with ϕ will be a subformula of the type (9.10). Another construct worth considering for our purpose is a chain of two pred- icates through a single shared variable xs: ϕ(xi,xs,xj )= α1(xi,xs) ∧ α2(xs,xj ). 204 Phase transition in FOL covering test (a) (b) (c) C C C 200 600 400 200 120000 80000 40000 0 0 10 10 20 30 40 50 10 20 30 40 50 20 30 40 50 10 20 30 40 50 150 100 50 0 0 10 m m m L L L 20 30 40 10 20 30 40 50 Figure 9.10 Dependency of the complexity C on the number n of variables: (a) n =4 and N = 100;(b) n =6 and N = 100;(c) n =14 and N = 100. Note the different scales on the C axis. Comparing model RL with other models for CSP generation 205 If all the relational tables are randomly sampled according to the same dis- tribution from the set Λ2, the distributions of the values of xs occurring in Rα1 and Rα2 are each multinomial, with equal probabilities of success 1/L for all ai ∈ Λ: Pα1 (k1,...,kL)= ( N k1,...,kL ) 1 LN , (9.13) Pα2 (h1,...,hL)= ( N h1,...,hL ) 1 LN , (9.14) where the ﬁrst factor on each right-hand side is a multinomial coefﬁcient. The tuples that satisfy ϕ(xi,xs,xj ) are those that occur in the natural join between the tables Rα1 and Rα2 . The average number of these tuples is given by Nϕ = E [ L∑ i=1 ki hi ] . The sum is a stochastic variable, where the ki and hi follow the distribution (9.13) and (9.14), respectively. Then Nϕ = L∑ i=1 N L N L = N 2 L . (9.15) We are now able to explain why increasing the number n of variables allows the phase transition edge to move far from the origin of the (m, L) plane. First, considering the generic formula (9.7) generated by model RL, we notice that subformulas of type (9.10), with k =2, may include either two β’s or one α and one β. However, chaining certainly occurs, by construction, between the n − 1 α’s and may additionally occur between the β’s and between the α’s and β’s. For a given m, increasing n has the effect of reducing the average number of literals built from the same variable pair and, hence, the exponent k in (9.11) de- creases. In support of this observation we report, in Figure 9.11, the probability distributions of s for n =20.6 As can be seen, the number of edges in the con- straint graph is much closer to m, meaning that fewer variable-pair duplications occur. As chaining is less restrictive than intersection, a hypothesis in which chain- ing dominates will be easier to verify, other things being equal, than one where intersection dominates. If the probability of intersection decreases with n then the probability of chaining increases because all the predicates β generate chain- ing if they are not intersections (i.e., because all the variables occur anyway in 6Recall that s is the number of edges in the constraint graph. 206 Phase transition in FOL covering test s 0 10 20 30 40 50 0.1 0.2 0.3 0.4 0.5 0.6 m 50 m 45 m 40 m 30 m 20 Figure 9.11 Probability distributions of the s values for n =20.All distribu- tions are shifted toward the right compared with Figure 9.4; thus variable-pair duplication is less likely. The leftmost acceptable value is s = n − 1=19. the α’s). As a consequence, the YES region is widened and the phase transition boundary moves toward the right in the (m, L) plane. Recall that, for any n, only the region to the right of the vertical line m = n − 1 is sampled by model RL. 9.4.2 Comparison with model B In the literature, CSPs generated by model B are typically characterized by two parameters, namely p1 and p2 (see Section 4.2). For the reader’s convenience, we repeat here their deﬁnitions: p (B) 1 = 2m n(n − 1) , (9.16) p (B) 2 =1 − N L2 . (9.17) In model RL the value of m does not correspond to the number of edges in the constraint graph, because several constraints may share the same pair of variables. Thus p1 is a stochastic variable, because the number of edges in a CSP instance is s, whose probability distribution was computed in Section 9.1.3. Comparing model RL with other models for CSP generation 207 So we may expect that all quantities depending on p1 will be, in CSPs derived from model RL, averaged over s according to the probability distribution qk(s) introduced in Section 9.1.3. In particular, the value of p1 itself would be p (RL) 1 = 2¯s n(n − 1) . (9.18) For a given value of m, p1 assumes smaller values in model RL than in model B. In machine learning, the parameters p1 and p2 do not have a direct meaning. On the contrary, in machine learning the complexity of an inductive hypothesis is frequently measured by m and the complexity of a concept instance can be related to L, i.e., the number of atomic objects it contains. In previous work, experiments have usually been done by changing p2 and keeping p1 constant. In (9.17) the ratio N/L2 represents the fraction of pairs al- lowed to occur in the corresponding predicates. The fact that model RL allows multiple arcs on G introduces a further difference between model B and model RL: as discussed in the previous subsections, edges may be labeled by conjunc- tions of constraints rather than elementary constraints. Thus, even though the elementary constraints are generated with the same cardinality N , subformulas labeling the edges may have different cardinalities (smaller than or equal to the original ones). Therefore p2 should also take into account this variation: p (RL) 2 =1 − N L2 , (9.19) where N is the average cardinality. To compute the probability distribution of the values of N in the composite tables is quite a hard task. Estimates can be obtained using arguments similar to those in Section 9.4.1. In practice, the em- pirical mean of the values obtained in the CSP instance under analysis can be used as an estimate. To summarize, using the same values for m and N in models B and RL we obtain p (RL) 1 ⩽ p (B) 1 and p (RL) 2 ⩾ p (B) 1 . (9.20) The number of “hypotheses” (constraint graphs) generated by model B is |HB | = ( n(n−1) 2 m ) , and the number of “examples” (sets of tables) is |EB | = (L2 N )m. 208 Phase transition in FOL covering test 10 20 30 40 50 5 10 15 20 0 50 100 150 n m Figure 9.12 Contour plot of the logarithm to the base 10 of the number of hy- potheses |HB | generated by model B as a function of n and m.The valueof m is upper-bounded by n(n − 1)/2. Comparing |HB | and |EB | with the corresponding values, |HRL| in (9.8)and |ERL| in (9.9), for model RL we note that the number of examples is the same. In Figures 9.12 and 9.13 the contour graphs of the base-10 logarithms of |HB | and |HRL| are reported, respectively. As is apparent from the ﬁgures, the spaces of hypotheses generated by the two models are rather different, not only in car- dinality but also in the sampled regions of (n, m) space. Starting from a theoretical analysis presented by Williams and Hogg (1994), Prosser (1996) derived an estimate for the critical value of p2: ˆp (B) 2,cr =1 − L −2/[p1 (n−1)] =1 − L −n/m. (9.21) From (9.21) the following value of ˆmcr may be derived: ˆm (B) cr = n ln L ln(L2/N ) . (9.22) Comparing model RL with other models for CSP generation 209 100 150 200 250 300 350 5 10 15 20 0 20 40 60 80 100 120 140 n m Figure 9.13 Contour plot of the logarithm to the base 10 of the number of hy- potheses |HRL| generated by model RL as a function of n and m.The valueof m is lower-bounded by n − 1. The same estimate as (9.21) was obtained by Smith and Dyer (1996)usinga slightly different approach. Moreover, the same expression is also obtained by using the parameter κ (see (4.10)) introduced by Gent and Walsh (1996),and setting it to 1. For model RL, ˆmcr must be replaced by the critical value of the average of s, namely ˆ¯scr: ˆ¯scr = n ln L ln(L2/N ) . (9.23) Using (9.21) we can also compute the corresponding estimate for the critical value of ˆLcr, keeping all other parameters constant. We have 1 − N ˆL2 cr =1 − ˆL −n/ˆ¯scr . The predicted critical value of Lcr is thus ˆLcr = N x, (9.24) 210 Phase transition in FOL covering test L (b)(a) 10 20 30 40 50 10 20 30 40 50 m L n = 10 N = 50 10 20 30 40 50 0 10 20 30 40 50 m N = 100 n = 4 6 10 14 Figure 9.14 The values predicted for ˆscr by (9.23) and the experimental ﬁnd- ings shown in Figure 9.8:(a) N =50, 80, 100,and 130 and n =10; (b) n =4, 6, 10,and 14 and N = 100. The upper line in each pair cor- responds to the theoretical prediction of the phase transition edge. The lower line in each pair corresponds to the experimental ﬁndings already reported in Figure 9.8. where x =(2 − n/ˆ¯scr)−1. It is of interest to compare the plot of functionTheoretical predictions obtained from model B closely resemble the experimental ﬁndings obtained with model RL. (9.22), for different values of N and n, with the experimental results shown in Figure 9.8. This is done in Figure 9.14, where substantial agreement with the critical value predicted by model B, as computed by (9.23), can be seen. However, there are small systematic differences whose explanation is intrigu- ing. We notice that the YES region found in the empirical analysis is a little smaller than that predicted by model B. However, the curves overlap when L is small, in the region close to the m axis. This also occurs for larger m values. To ﬁnd an interpretation of this phenomenon, two aspects have to be con- sidered. First, owing to the difference between m and ¯s, each experimental curve must be to the left of the theoretical one because it corresponds to the actual value of ¯s; this value is not known in advance (we only know m), but certainly ¯s ⩽ m. Moreover, we need to consider how the structure of a for- mula may affect the probability of success of the covering test. Model B does not take into account the structure of the constraint graph, because the tight- ness of the constraints is the same for all edges. In model RL the latter is not true because many literals can share the same variable pair. In order to see the Comparing model RL with other models for CSP generation 211 Table 9.1 Expected number of tuples for subformulas in ϕ1 and ϕ2 Formula Relation Expected number ϕ1 α1(x1,x2) ∧ β2(x1,x2) Nα1 ,β2 = N 2/L2 ϕ1 α3(x2,x3) ∧ β4(x2,x3) Nα3 ,β4 = N 2/L2 ϕ2 α1(x1,x2) ∧ β2(x1,x2) ∧ β3(x1,x2) Nα1 ,β2 ,β3 = N 3/L4 ϕ2 α4(x2,x3) N effect of this difference on the phase-transition edge, let us ﬁrst consider an example. EXAMPLE Let ϕ1 and ϕ2 be the formulas ϕ1 = α1(x1,x2) ∧ β2(x1,x2) ∧ α3(x2,x3) ∧ β4(x2,x3) (9.25) and ϕ2 = α1(x1,x2) ∧ β2(x1,x2) ∧ β3(x1,x2) ∧ α4(x2,x3). (9.26) Both formulas have the same number of literals. However, the literals in ϕ1 are equally distributed over the variable pairs (x1,x2) and (x2,x3) while in ϕ2 three literals share (x1,x2) and only one is applied to (x2,x3). Let us estimate the expected number of solutions in the domain Λ3 for the formulas ϕ1 and ϕ2 in the above example. The expected numbers of tuples sat- isfying the subformulas of ϕ1 and ϕ2 are given in Table 9.1. Using expressions (9.11) and (9.15), we obtain for Nϕ1 and Nϕ2 , the exptected number of tuples respectively satisfying ϕ1 and ϕ2, Nϕ1 = 1 L N 2 L2 N 2 L2 = N 4 L5 , (9.27) Nϕ2 = 1 L N 3 L4 N = N 4 L5 . (9.28) Thus the expected numbers of solutions for ϕ1 and for ϕ2 are the same. This Constraints in model RL are tighter than in model B for large values of L. means that, on averaging the number of solutions obtained from a large number of constraint graphs (all having the same parameters), we will obtain approxima- tively the same value. However, we do not know what happens for every single graph; the number of solutions could always be close to the average or there 212 Phase transition in FOL covering test 10 1005020 0.01 0.1 1 10 100 1000 L Number of solutions Figure 9.15 Average number of solutions for ϕ1 and ϕ2 and two of their sub- formulas, for N = 100. could be no solution for many graphs and a large number of solutions for a few graphs. For this reason it is important to consider the variance of the number of solutions in addition to the average. In fact, this difference in behavior actually occurs for ϕ1 and ϕ2. Figure 9.15 shows plots of the expected numbers of solutions Nϕ1 , Nϕ2 , Nα1 ,β2 , Nα1 ,β2 ,β3 (see Table 9.1) as functions of L.For L =50, Nϕ1 = Nϕ2 = 10. However, in the case of ϕ1 this number was obtained from the natural join of two tables each containing the expected number of 10 tuples while in the case of ϕ2 the number was obtained by the natural join of a table that contains an average number of 0.1 tuples and a table with 100 tuples. This means that in the latter case we can expect that in 90% of cases we will have no solution while in 10% of cases we will have almost 100 solutions. Thus ϕ2 is on the border of the NO region while ϕ1 is on the border of the YES region. In other words, formulas where literals are irregularly distributed over the variables (i.e., the number of literals deﬁned on the same variable pair is highly unpredictable across pairs) are globally more difﬁcult to satisfy. As model RL may generate formulas with literals irregularly distributed on the variables, we can expect a number of cases where the probability of success is smaller than for model B (given the same m), even if the expected number of solutions is the same. In support of this explanation we observe that when n is small the differences between the theoretical prediction of model B and the experimental ﬁndings of our model are less conspicuous. In fact, when the variables are few the literals Comparing model RL with other models for CSP generation 213 have less chance of being distributed irregularly on them. Moreover, when L is small the constraints due to the predicates are more soft, and so the effect of the difference in structure in the formulas becomes less evident. 9.4.3 Asymptotic behavior and model RB As discussed in Section 4.3.1, Achlioptas et al. (1997) demonstrated that, when the number n of variables grows to inﬁnity, the probability that a random instance of CSP generated by model B is unsatisﬁable tends to 1, provided that p2 > 1/L and that the number of constraints is m = O(n). In model RL there is a substantial difference from model B, because in model Bwemusthave m ⩽ n(n − 1)/2 whereas in model RL we must have m ⩾ n−1, and, for the number of edges in the constraint graph, s ⩽ n(n − 1)/2. Then, given constant m, N, and L, model B can generate a CSP for n →∞, whereas model RL cannot. It is thus necessary that m →∞ when n →∞ merely for the generation procedure of model RL to be applicable. In order to maintain the basic feature of model RL, namely that the generated formula is connected, we must have m =Ω(n);if m grows linearly with n, i.e., m =Θ(n), since the connected part always includes n − 1 literals the graph consists substantially of this connected part plus some other edges.7 As the expected number of satisfying When both n and m grow to inﬁnity, formulas become always unsatisﬁable. tuples for a chain of k predicates is given by formula (9.15), the probability of solution for a chain of n − 1 literals is in turn given, on average, by the number of satisfying tuples divided by the number of possible tuples, namely Psol = ( N L2 )n−1 . (9.29) When n →∞, probability (9.29) tends to 0. Clearly adding more constraints makes the problem even harder. In order to obtain regions of asymptotic satisﬁ- ability, the number of constants in the domain must increase with n,asinmodel RB (see Section 4.3.2). In this last model it is of interest to note that the critical value rcr, given by Theorem 4.2, formally coincides with expression (9.22)even though the parameters have different deﬁnitions: rcr = − α ln(1 − p) = ln L ln n ln(L2/N ) = ˆmcr n ln n . (9.30) Formula (9.22) can be immediately derived from (9.30). 7For Ω and Θ, see the discussion after equation (1.4). 214 Phase transition in FOL covering test 9.5 Smart algorithms for the covering test In previous sections we have observed the emergence of phase transitions in the covering test even for a small number of variables. Consequently, we have measured the complexity for searching in the phase transition region using a backtrack stochastic search algorithm. This approach gave us the baseline for the problem complexity. However, in Chapter 4, we described how modern CSP solvers exploit efﬁcient heuristics that allow them to solve very large prob- lems in a relatively short time. We may then wonder whether the complex- ity shown in Figure 9.9 could possibly be altered using one of these advanced algorithms. As an answer we will provide results obtained using two algorithms based on CSP methods similar to those described in Chapter 4. One is multilevel coor- dinate search (MCS), from Scheffer et al. (1996) and the other is Django, from Maloberti and Sebag (2004). The MCS algorithm exploits a constraint graph to prune the search space us- ing the techniques of constraint propagation. The constraint graph contains both clauses with variables and also ground literals. Thus θ-subsumption (the cover-Using smart heuristics from the CSP domain, order-of-magnitude decreases in the complexity peak are observed. ing test) is transformed into the problem of ﬁnding a maximal clique (a complete graph) in the constraint graph. As this problem is of exponential complexity, the MCS algorithm searches for cliques of size n for pruning the search space. Af- terwards, the maximal clique is searched for by starting from the cliques of size n that have been found already. The Django algorithm also exploits graph constraint propagation, such as arc consistency, in order to prune the search space. The major difference from MCS and other matching algorithms is that Django works on a constraint graph obtained by transforming the original CSP into a dual binary CSP. In the following we will brieﬂy review the technique used for this trans- formation. The binary CSP is deﬁned at a metalevel with respect to the origi- nal problem. Let ϕ denote the formula to be tested and U the universe whereDjango maps the original CSP into a binary CSP. the test is to be performed. For every literal pi(xi,...,xj ) occurring in ϕ,a metavariable Yi is deﬁned whose domain is the relation Ri deﬁning the seman- tics of pi in U , i.e., tuples in Ri are the values that Yi can assume. Metavariables corresponding to literals built on the same predicate symbol pi share the do- main Ri. Metavariables are constrained by metarelations. For each literal pair pi(...,xr,...),pk(...,xr,...) sharing at least one variable xr, a binary con- straint rj (Yi,Yk) is deﬁned: this states that values for Yi and Yk must correspond to legal substitutions for the subformula pi(...,xr,...) ∧ pk(...,xr,...), i.e., variables shared between the two literals must be bound to the same constant. An example of the metavariables, metaconstraints and constraint graph obtained Smart algorithms for the covering test 215 a a c d a a c b a b b d b b a d c c b d b a a c R1(x1, x2) R2(x1, x2) R3(x1, x2) P1(x1, x2) P2(x2, x3) P3(x3, x4) P2(x1, x4) Y1 Y2 Y3 Y4 r1 r3 r5 r4 r2 Figure 9.16 Example of the binary CSP constructed by the algorithm Django before executing the covering test of a formula. from a formula using four literals is provided in Figure 9.16. In this example, for the sake of simplicity the original CSP was also binary; however, the same method can be applied to formulas containing literals of any arity. On the con- straint graph obtained in this way it is simple to test for arc consistency and for deterministic matching, i.e., literals for which there exists only one admissible match. The performances of MCS and Django are illustrated for comparison in Figures 9.17 and 9.18, which show the match complexity for the same region of the space (n, m, N, L) as in Figure 9.9(a). It is surprising how MCS already exhibits an advantage of several orders of magnitude in the phase-transition re- gion over the basic backtracking algorithm (it is about 200 times faster). In turn, Django has an advantage of about one order of magnitude over MCS (it is 2000 times faster than stochastic backtracking). Interestingly, both MCS and Django yield the same pattern for the probability of solution and for the complexity as that shown in Figure 9.7. The only difference is that for these algorithms the The phase transition exists independently of the search algorithm. height of the complexity peak is much lower. One may see, therefore, that the phase transition exists independently of the search algorithm, as expected. 216 Phase transition in FOL covering test 50 40 30 20 10 0 10 15 20 25303540 45 50 1015 20 25 30 L m 35 40 45 50 Figure 9.17 Three-dimensional plot of the complexity reported by MCS as a function of the time elapsed in seconds (vertical axis), for n =10 and N = 100, vs. m and L. 5 4 3 2 1 0 10 15 20 25 30 35 40 45 505045403025201510mL Figure 9.18 Three-dimensional plot of the complexity reported by the algo- rithm Django as a function of the time elapsed in seconds (vertical axis), for n =10 and N = 100,vs. m and L. Comments 217 9.6 Comments As relational learning relies heavily on matching candidate hypotheses to train- ing examples, investigation of the matching problem’s characteristics is of funda- mental relevance for the success of this type of learning. Owing to the straight- forward equivalence between a matching problem and a CSP, one may expect that the former shows the presence of a phase transition in the same way as the latter. What is relevant, in the context of learning, is the identiﬁcation of suitable control parameters and the location of the phase transition within the parameter space. As we have seen, a simple adoption of the classical parameters p1 and p2 is not well suited to learning because they cannot be associated with recognizable features, either of the hypothesis (the formula) or the examples. The parameters selected (the number of variables n and the number of predicates m for the for- mula, the number of goods N , and the number of constants L for the examples), beyond being meaningful in learning allow comparisons to be made with other models, as they can be expressed as functions of p1 and p2. As the investigation of all four parameters at the same time is computation- ally prohibitive, we have chosen to focus on two, namely m for the formula and L for the examples, keeping n and N ﬁxed. However, a limited exploration has highlighted the fact that analogous results are obtained by choosing any of the pairs (n, L), (n, N ), (m, L),and (m, N ) as control parameters. Concerning the location of the phase transition, it turns out that the set of critical pairs (mcr,Lcr) is situated in a region of the parameter space well populated by the learning prob- lems encountered in practice. This aspect will be discussed in more detail in the next chapter. Regarding problem generation, model B, used for CSPs, and model RL, used for matching problems, produce different ensembles of instances, i.e., the hy- pothesis spaces HB and HRL are not the same whereas the two models generate the same sets of relational tables. The reason why we have not used model B directly is that formulas in HB are not realistic in learning problems, where learned formulas with several predicates on the same variable are quite com- mon. Moreover, the number m of predicates occurring in a formula of model RL is not upper-bounded by M = n(n − 1)/2, so that long concepts may also be considered without the need to increase the number n of variables. As a con- sequence, there is a region where formulas can be generated only by model B and another where formulas can be generated only by model RL. These regions can be clearly seen in Figures 9.12 and 9.13.Evenforapair (n, m) located in the region where both models can generate instances, the sets of formulas gener- ated by the two models are different. Both use m predicates, but while model B cannot produce formulas with predicates deﬁned on the same pair of variables (whereas model RL can), model RL cannot produce formulas in which not all 218 Phase transition in FOL covering test variables pairs (x1,x2),..., (xn−1,xn) occur (whereas model B can). Using the probability distribution qk(s), we can see that the probability that model RL will generate a formula with all pairs of variables different is qm−n+1(m)= m−n+1∏ i=1 (1 − n + i − 2 M ) (n ⩽ m ⩽ M ), which, for a given n, decreases with increasing m. We may notice that model RL generates constraint graphs that are the super- position of a path between node x1 and node xn including n nodes and n − 1 edges and a random graph with the same nodes and s − n +1 edges. However, this random graph does not belong to Gn,s−n+1 because the edges are extracted with replacement in m − n +1 trials. A comparison of model RL with model RB is more tricky, because one has to choose what is kept constant and what may vary. Let us suppose that n and N are constant, as in model RL, and let k =2.Thenlet (mcr,Lcr) be a point on the phase transition for model RL. The corresponding value of r will be r = mcr n ln n , and the corresponding value of α will be ln Lcr/ln n. Finally, we obtain p = 1 − N/L2 cr. We have to compare the obtained r value with the critical value rcr = − α ln(1 − p) . In order for rcr to be the location of the phase transition, we must have α> 1/2 and p ⩽ 1/2, namely: √n<Lcr ⩽ √2N. If the above condition holds then rcr is indeed the location of the phase transition and the computed value of r has to be compared with it, in order to check the probability of solution. EXAMPLE In order to see how the problems generated by models RB and RL, respec- tively, are mapped, let us take n =10 and N = 100. One point on the phase transition for model RL is given by mcr =30, Lcr =14.From these values we obtain r =1.303,α =1.146,p =0.490. The conditions to be veriﬁed are α> 1/2, which is true, and p ⩽ 1/2, which is also true. The critical value for r is rcr =1.45. The actual value Comments 219 of r is lower than this. Thus in this case a problem generated by model RB, with the parameters of a problem generated by model RL at the phase transition, is located in the solvable part of the plane even though it is close to the phase transition. This result is not generalizable, and its only purpose is to show a way of obtaining the mapping. By changing the point selected on the phase-transition line of model RL or by varying n and N , different situations may arise. Finally, considering the computational cost, we note that, even though the absolute cost varies according to the search algorithm used, the same behavior emerges: all tested algorithms show the pattern easy–hard–easy across the phase transition region. 10 Phase transitions and relational learning Contents 10.1 The experimental setting 221 10.2 Experimental results 229 10.3 Result interpretation 235 10.4 Beyond general-to-speciﬁc learning strategies 247 10.5 Comments 255 In the previous chapter we showed how the covering test in relational learning exhibits a phase transition associated with a complexity peak, for control param- eter values typical of the problems investigated by current relational learners. We also showed that the complexity associated with the phase transition in match- ing can be partially tamed using smart search algorithms. However, as soon as the number of variables increases a little (say, from four to ﬁve) the complex- ity is again a strongly limiting factor for learning, because a learner must face hundreds of thousands of matching problems during its search for hypotheses (formulas). Leaving aside the problems caused by the computational complexity of matching, one may wonder whether the presence of a phase transition has ad- ditional effects on learning, for instance whether it affects the quality of the learned knowledge. Another question is whether it is possible to escape from 220 The experimental setting 221 the region of the phase transition by suitably manipulating the control parame- ters. In this chapter we try to provide an answer to these questions, by means of an experimental analysis and its interpretation. 10.1 The experimental setting In order to test the independence of the results from the learning algorithm, we used the learners FOIL (Quinlan and Cameron-Jones, 1993), SMART+ (Botta and Giordana, 1993), G-Net (Anglano et al., 1997; Anglano and Botta, 2002), and PROGOL (Muggleton, 1995) described in Chapter 6. To be more precise, the impact on the quality of learning of the phase transi- The impact of the phase transition on relational learning is analyzed with respect to the difﬁculty in solving the task, the effectiveness of the heuristic used to guide the inductive search, and the accuracy of the learned concept descriptions. tion in the covering test will be analyzed under three aspects: • Can “easy” and “difﬁcult” learning regions be distinguished, with respect to the control parameters of the matching problem? How are these regions located in relation to the phase transition? Do other phase transitions exist that are not related to the covering test? • Where and when are common search criteria, involving for example the information gain principle (Quinlan, 1990) or the minimum descrip- tion length principle (Muggleton, 1995), reliable? What is the impact of plateaus? • For a learning problem, the generalization error is certainly an important aspect but it is not the only one. Another is the meaningfulness of the acquired concept description; this is particularly relevant for automated knowledge discovery, where the learned knowledge should provide the domain experts with new, relevant, insights. Thus another question to be answered is to what extent the acquired concept coincides with the target concept, beyond its prediction ability. The above questions have been answered experimentally. The artiﬁcial prob- lem generator described in Section 9.1.3 has been extended to generate fully relational learning problems with known target concept. A suite of about 500 problems was constructed, sampling the YES, NO, and phase transition regions. Results were obtained using the three relational learners FOIL 6.4, SMART+, and G-Net. PROGOL was not able to cope with the computational complexity of the task. As we will discuss in the following, these systematic experiments shed some light on the behavior, potentialities, and limitations of existing relational learners. 222 Phase transitions and relational learning 10.1.1 Generating artiﬁcial learning problems We will now review the procedure used to construct a set of artiﬁcial learning problems (Giordana et al., 2000a; Botta et al., 2003). A relational learning prob- lem Π is atriple(c, SL, ST ), where c is the target concept and SL and ST are the learning and test sets, respectively. For the sake of simplicity, concepts were restricted to be binary, described by conjunctive formulas, as generated by model RL (see Section 9.1). This means that a target concept (relation) description has the form p1(xi1 ,xj1 ) ∧ p2(xi2 ,xj2 ) ∧ ··· ∧ pm(xim ,xjm ) → c, (10.1) where the target concept c is a constant name and the variables (xik ,xjk )(1 ⩽ k ⩽ m) are taken from a set X = {xj | 1 ⩽ j ⩽ n} and are implicitly existen- tially quantiﬁed. In the target concept there are no repeated predicate names and no variable pairs made up by two instances of the same variable, i.e., xik ̸= xjk . The procedure for generating a learning problem consists of three steps. InLearning problems are generated in three steps. the ﬁrst step a concept description is generated, using the algorithm described in Section 9.1 for sampling the hypothesis space generating covering test problems. Then each concept description c is stochastically built up, by model RL, using the variable set X and m literals. All literals are built on distinct predicate symbols. Complementary experiments (not reported here) show that this restriction does not affect the results to any signiﬁcant extent. In order to keep the computational cost within reasonable limits, the number n of variables is set to 4 (n =4)inall target concepts.1 If n =4, from (9.8) we obtain that the number of formulas that Model RL can generate is: |HRL| = (m 3 ) 12m 288 = O(m 312M ). Next the learning set SL and the test set ST are created, using a variant ofLearning set and test set the procedure we described for generating the examples for the covering test. Thus each example e is deﬁned by a set R of relational tables, sampled without replacement from a set Λ × Λ of pairs of constants. Each relation Ri deﬁnes the semantic (extension) of a corresponding predicate pi occurring in the concept description. An example e is labeled as positive if it veriﬁes the deﬁnition of c, and as negative otherwise. Again for computational reasons, the size N of each 1Note that most relational learners have similar restrictions. For instance, in the mutagenesis domain (King et al., 1995), the maximum number of chemical atoms considered in a hypothesis, corresponding here to the number of distinct variables, varied from 3 to 5. The experimental setting 223 Ri is set to 100 for all relations, and the size L of Λ is taken to be the same for all examples in the same problem Π. As the number of examples generated by model RL does not depend on n, this last is the same as in (9.9). A clariﬁcation is needed with respect to the generation of the examples. In each example we have to choose the number of tables to be associated with it. When we were studying the matching (ϕ, e) between a hypothesis and an ex- ample, the natural number of tables to be associated with e was the number of predicates in ϕ. In fact, additional predicates would be ignored by the matching procedure, and some missing predicate tables would make the hypothesis auto- matically false (according to the “closed world assumption”, no tuple veriﬁes the predicate). When generating a learning problem the target concept c is known, and hence the number m of its predicates as well. However, during learning the examples are likely to be matched against hypotheses of different lengths; then the determi- nation of the number of tables in the example is not obvious. We have chosen to describe each example by m tables, corresponding to the number of predicates in c. The reason is that in relational learning the predicates available to con- struct hypotheses are given, and they constitute the “background knowledge”. These predicates have for relational learning the same role that attributes have for propositional learning. Thus, the learner only constructs hypotheses with lit- erals built upon the given predicates.2 Furthermore, it is worth noticing that sampling the set Λ×Λ does not guaran- tee that every relational table contains all the constants in Λ. As a consequence, the L value for each relation Rh, which is the number of constants appearing in Rh, may be different from relation to relation; the only observed effect is a slight increase in the apparent width of the phase transition, as discussed later in the chapter. In order to visit the YES, NO, and phase transition regions as uniformly A set of 451 artiﬁcial relational learning problems was generated to analyze the impact of the phase transition on relational learning. as possible, while avoiding an exhaustive exploration, 451 (m, L) pairs were uniformly selected without replacement, where m ranged in the [5, 30] interval and L ranged in the [12, 40] interval. For each selected pair (m, L) a learning problem Πm,L was constructed, as explained above. As anticipated, the procedure for constructing the training and test examples is a variant of that described in Section 9.1. The modiﬁcation was made necessary by the following difﬁculty: if (m, L) lies in the YES region (on the left of the phase transition) then by construction c will almost surely cover any stochastically constructed example. In other words, the training and test sets would contain a huge majority of positive examples (the ratio of positive and 2We do not consider here the case of constructive learning, in which new predicates are intro- duced during learning. 224 Phase transitions and relational learning ———————————————————– Procedure ProblemGeneration (m, L) Construct c with m literals using model RL SL = DataGeneration(m, L, c). ST = DataGeneration(m, L, c). Return Π=(c, SL, ST ). Procedure DataGeneration(m, L, c) np = 0, ne = 0 Let S = ∅ while ne < 100 or np < 100 do Generate a random example e with model RL if e is covered by c then if np = 100 then ChangeToNegative( c, e) Set label of e = NEG else Set label of e =POS endif else if ne = 100 then ChangeToPositive( c, e) Set label of e = POS else Set label of e = NEG endif endif S = S∪{(e, label)} if label = POS then np = np + 1 else ne = ne + 1 endwhile Return S ———————————————————– Figure 10.1 Generation of the training and test sets of examples. negative examples could be as high as 106). Symmetrically, if (m, L) lies in the NO region (on the right of the phase transition), the training and test sets would contain a huge majority of negative examples. The generation of the examplesRandomly generated examples are modiﬁed in order to obtain balanced learning and testing sets. thus needs to be made according to the procedure given in Figure 10.1. The procedure ProblemGeneration ﬁrst constructs the target concept c;then the training and test sets are built by the procedure DataGeneration. The latter The experimental setting 225 Procedure ChangeToPositive( c, e) Uniformly select four constants in the domain Λ of the variables, and denote them (without loss of generality) a1,a2,a3,a4 Let θ denote the substitution θ = {x1/a1,x2/a2,x3/a3,x4/a4} for each literal pk(xi,xj) in c, do if pair (ai,aj) does not already belong to table Rk then replace a uniformly selected pair in Rk with (ai,aj) endif end Return e Figure 10.2 Procedure to turn a negative example of the concept c, generated stochastically by model RL, into a positive example. It is sufﬁcient to select a consistent substitution for the four variables and add the corresponding pairs to the appropriate tables, at the same time removing a randomly selected pair. accumulates examples constructed with model RL; the examples are labeled pos- itive or negative, respectively, depending on whether they verify c. When the maximum number of positive (respectively, negative) examples is reached, fur- ther examples are prepared using the ChangeToNegative (respectively, Change- ToPositive) procedure, to ensure that the training and test sets are equally dis- tributed. The procedure ChangeToPositive turns a negative example e into a positive one and is given in Figure 10.2. Conversely, the procedure Change- ToNegative turns a positive example e into a negative one and is given in Figure 10.3. 10.1.2 The learners The learners for the experiments were selected from the relational learners that The experimentation was performed using three learners, FOIL, SMART+, and G-Net. we brieﬂy reviewed in Chapter 6. Three learning strategies were considered: a top-down depth-ﬁrst search, a top-down beam search, and a genetic algorithm- based search. The majority of the learning experiments were done using the top-down learner FOIL (Quinlan and Cameron-Jones, 1993). FOIL starts with the most general hypothesis and iteratively specializes the current hypothesis ht by adding as a conjunct the “best” literal pk(xi,xj ) according to some statistical criterion, involving for example the information gain (Quinlan, 1986, 1990) or the mini- mum description length (MDL) (Rissanen, 1978). When further specializations 226 Phase transitions and relational learning Procedure ChangeToNegative( c, e) Build up the set Θ of all substitutions θ = {x1/a1,x2/a2,x3/a3,x4/a4} such that e verifies c Randomly select a literal pk(xi,xj) in c Remove from relation Rk in e all pairs (θ(xi),θ(xj)) of constants belonging to a substitution θ in Θ Replace them by uniformly selected pairs of constants not belonging to any substitution θ in Θ Return e Figure 10.3 Procedure to turn a positive example of the concept c, generated stochastically by model RL, into a negative one. It is necessary to disrupt the concatenation of pairs that satisﬁes the concept. Taking any literal, all pairs that belong to a substitution in Θ are removed and replaced by pairs that do not be- long to any substitution in Θ. This process may occasionally introduce a new matching tuple; then the new pairs must be checked out. In principle, the trans- formation of a positive into a negative example may turn out to be impossible; in this case the example has to be discarded. However, in the experiments that were performed this case never occurred. of the current hypothesis do not lead to further improvements ht is selected, all positive examples covered by ht are removed from the training set, and the search is restarted unless the training set is empty. The ﬁnal hypothesis ˆc returned by FOIL is the disjunction of all selected, conjunctive, partial hypotheses ht. We must note that the space of hypotheses explored by FOIL does not exactly coincide with that generated by model RL. Both FOIL and model RL use only the m predicates provided as background knowledge, but FOIL allows formu- las with multiple occurrences of the same predicate having different arguments. Moreover, FOIL allows literals having the same variable as both ﬁrst and second argument. However, FOIL’s formulas are connected, as are those generated by model RL, because a new literal pk(xi,xj ) must share at least one variable with the part of the formula already built up. Thus, for a given m,theset HRL of for- mulas generated by model RL is a subset of those of the same length generated by FOIL. More precisely, model RL can generate formulas with a length t such that n − 1 ⩽ t ⩽ m (in the speciﬁc case considered, 3 ⩽ t ⩽ m), whereas FOIL builds up, in principle, formulas with a length t such that 1 ⩽ t ⩽ mn2 (in the speciﬁc case considered, 1 ⩽ t ⩽ 16m). Therefore, even for n =4, FOIL allows hypotheses with a lesser number n′ of variables (1 ⩽ n′ ⩽ n). The experimental setting 227 =2 L m L 1 L 2 L 3 m 1 m 2 m 3 Inductive search path Inductive search path for large L ( 1, 1, 1 )SSc n =3n =4n LT ( 2, 2, 2)SSc LT ( 3 , 3 , 3)SSc LT Figure 10.4 Location of learning problems in the (m, L) plane. Top-down learners visit candidate hypotheses from left to right. In order to make the results of Chapter 9 applicable to the discussion of learn- ing, we need to consider, in the (m, L) plane, multiple phase-transition curves, i.e., those corresponding to n′ =2, 3, 4, and use the curve associated with the number of variables in FOIL’s current hypothesis (see Figure 10.4). An excep- tion occurs when m =1. In this case model RL cannot generate any hypothesis, because at least two variables are needed to construct the ﬁrst literal α(x1,x2), as described in Section 9.1.3; in fact, m =1 would imply n =2, as the same variable cannot occur, in formulas generated via model RL, in both arguments of a literal. Nevertheless, when FOIL generates its ﬁrst hypothesis with one literal, h1(x1,x2)= pk(x1,x2), this hypothesis is certainly veriﬁed in all examples, both positive and negative, as long as the corresponding table in every example is not empty. Another top-down learner, SMART+ (Botta and Giordana, 1993), has also SMART+ been used. The main difference between FOIL and SMART+ resides in their search strategies; FOIL basically performs hill climbing and uses a limited amount of backtrack, whereas SMART+ uses a beam search with a user- supplied beam width. The search space visited by FOIL or SMART+ can be FOIL and SMART+ are based on a top-down learning strategy. G-Net is based on a genetic algorithm. visualized as a path in the (m, L) plane (see Figure 10.4). Both learners navigate in the plane by moving from left to right, as the number t of literals in the current hypothesis is incremented at each step. When there are only a small number of constants in a variable’s domain Λ, the relational tables for the examples in the learning set SL are likely to involve all possible constants. Top-down learners therefore navigate the horizontal line L = |Λ| in the (m, L) plane. For a large number of constants, it might happen that not all constants appear in all relational tables. Thus the number of effective 228 Phase transitions and relational learning constants considered in early learning stages might be less than |Λ|; it increases as the hypothesis size increases. The path visited by the learner goes to the right (as the current hypothesis is specialized) and upwards (as the effective number of constants in the examples increases). A third learner, G-Net (Anglano et al., 1998), based on genetic search, wasG-Net also considered. G-Net starts with an initial population of candidate hypotheses; these can be viewed as randomly distributed points on a segment of the hori- zontal line, L = |Λ| in the (m, L) plane. The learner navigates on this straight line, moving to the right or to the left, since genetic operators allow candidate hypotheses to be either specialized or generalized. As usual with evolution- ary computation-based search, the computational cost of G-Net is signiﬁcantly higher than that of the other two learners. A smaller number of experiments have therefore been performed with G-Net. Further experiments have also been done with the relational learners PROGOL (Muggleton, 1995)and STILL (Sebag and Rouveirol, 2000).PROGOL PROGOL uses background knowledge to tailor the search space and optimize the learning search. However, its clever heuristics make it ill-suited to dealBottom-up learners like PROGOL and STILL ran out of memory. with large artiﬁcial problems in the absence of background knowledge and it failed to learn any hypothesis in an acceptable time. As reported by Srini- vasan and Muggleton (1995), in the mutagenesis domain some 100 000 sec- onds are needed to learn on a medium-size problem (N =30, L =30) when there is no background knowledge. STILL uses a bottom-up approachSTILL based on the stochastic (uniform or biased) sampling of the matchings be- tween hypotheses and examples. It failed to provide any relevant classiﬁer, owing to the uniform construction of the examples and the lack of any domain bias. Summarizing the experimental setting, we list the assumptions that have been made; some facilitate the search (these are marked with a +) while oth- ers make relational learning more difﬁcult (these are marked with a −): + The training and test sets are equally distributed (100 positive and 100 negative examples), without any noise. + All target concepts are conjunctive: a single hypothesis c covers all posi- tive examples and rejects all negative examples. + All predicates in the examples are relevant: they all appear in the target concept. − All examples have the same size Nm, i.e., the cardinality of a table times the number of predicate symbols in the target concept. Experimental results 229 − All predicates have the same number N of tuples (pairs) built on them in every example. − All variables (predicate arguments) have the same domain Λ of values. The last three assumptions make learning more difﬁcult because they tend to make the positive and negative examples more similar. Note that, even if the structure of the target concept (m literals involving n =4 variables) were known by the learners, which is obviously not the case, the size of the search space would prevent the solution from being discovered by chance. 10.2 Experimental results To investigate the global impact on relational learning of the phase transition Performances were evaluated with respect to predictive accuracy, concept identiﬁcation, and computational cost. in matching, the three learners mentioned in the previous section were run on the set of selected learning problems. The results were analyzed in the light of the position of the learning problem with respect to the phase transition. Every learner was examined using three speciﬁc criteria: • Predictive accuracy The predictive accuracy is commonly measured by the percentage of test examples correctly classiﬁed by the hypothesis ˆc produced by the learner.3 It is considered satisfactory iff it is greater than 80% (this threshold value will be discussed later). • Concept identiﬁcation It must be emphasized that a high predictive ac- curacy does not imply that the learner has discovered the true target con- cept. The two issues must therefore be distinguished. Identiﬁcation is con- sidered satisfactory iff the structure of ˆc is close to that of the true target concept c, i.e., if ˆc is conjunctive, with the same size as c. • Computational cost The computational cost reﬂects both the total num- ber of candidate hypotheses considered by the learner and the cost of matching each hypothesis on the training set. Typically, the more candi- date hypotheses in the phase-transition region, the higher the computa- tional cost. 3The predictive accuracy was not evaluated on a test set drawn from the same distribution as the learning set; if the experiments had been doubled, this would have been equivalent to a twofold cross-validation (Dietterich, 1998). We did not double the experiments, because of the huge total computational cost. For the same reason, it was impossible to perform a cross-validation evaluation. Moreover, even though the learning result obtained for any (m, L) is based on a single trial, it can be considered signiﬁcant to the extent that other trials performed in the same area give similar results. 230 Phase transitions and relational learning m L Figure 10.5 FOIL competence map: the success and failure regions, for n =4 and N = 100; L is the number of constants in the model. Plus signs, success (predictive accuracy ≥ 80%); dots, failure (predictive accuracy < 80%). The phase-transition region is indicated by the broken curves, corresponding, bottom to top, to the contour plots for Psol = 90%, Psol = 50%,and Psol = 10%,as determined by Giordana and Saitta (2000). In the following we will review the results obtained by FOIL, SMART+,and G-Net on the artiﬁcial relational learning problems constructed as described in the previous section. 10.2.1 Predictive accuracy Figure 10.5 summarizes the results obtained by FOIL with regard to predictive accuracy. As mentioned earlier, 451 (m, L) pairs were chosen in such a way as to explore signiﬁcant parts of the YES, NO, and phase transition regions. On each problem, FOIL either succeeds (shown by a plus sign, indicating that the predictive accuracy on the test set is greater than 80%) or fails (shown by a dot.). Let us ﬁrst comment on the signiﬁcance of these results, with respect to A large region emerged, located across the phase transition, where no learner succeeded. the success threshold and the learning strategy. First, the shape of the failure Experimental results 231 region (the blind spot) is almost independent of the threshold used to deﬁne a failure case (a predictive accuracy on the test set of 80%). In the vast majority of cases the hypotheses ˆc learned by FOIL are either very accurate (a predic- tive accuracy close to 100%) or comparable with a random guess (a predictive accuracy close to 50%). The threshold could thus be any value between 95% and 60% without making any signiﬁcant difference in the shape of the blind spot. Second, quite similar results are obtained with FOIL and SMART+, except when SMART+’s beam width is close to the size of the target concept c (mean- ing that SMART+ performs an almost exhaustive, and much more computation- ally heavy, search). Complementary experiments with G-Net conﬁrm that the failures should not be blamed on the top-down strategy embedded in FOIL or SMART+. Even though G-Net explored a much larger part of the hypothesis space than FOIL or SMART+ (and was therefore tried for only a few learning problems, situated mostly in the failure region for FOIL), G-Net failed on these problems, too. Regarding just the learning performances, it appears that relational learning Learning succeeds either when the target concept is simple or when it is very complex. Failures occur for concepts of intermediate complexity. succeeds in two main cases, either when the target concept is simple (for low values of m), or when the learning problem is far to the right of the phase- transition region. The ﬁrst case is hardly surprising; the simpler the target concept, the easier learning should be. Much more unexpected is the fact that learning problems far from the phase transition appear to be easier to solve. In particular, the fact that increasing the number of constants in the application domain facilitates re- lational learning (other things being equal, i.e., for the same target concept size), is counterintuitive. Along the same lines, it is counterintuitive that increasing the size m of the target concept might facilitate relational learning (other things be- ing equal again, i.e., for the same number of constants L). These remarks will be enlarged upon in Section 10.3. 10.2.2 Concept identiﬁcation What really happens when FOIL succeeds or fails? Table 10.1 reports the char- acteristics of the ﬁnal hypothesis ˆc produced by FOIL for a few representative learning problems. The ﬁrst column indicates the region to which the learning problem belongs. The second column gives the identiﬁer of the problem, which will be referred to in the discussion. Columns 3 and 4 show the “coordinates” of the learning problem i.e., the size m of the target concept c, and the number L of constants in the examples. Columns 5 and 6 refer to the hypothesis ˆc learned by FOIL; ˆc Simple concepts tend to be correctly identiﬁed. Complex concepts are approximated by descriptions corres- ponding to generalizations of the correct one.involves one or several conjunctive hypotheses ht, iteratively produced by FOIL. 232 Phase transitions and relational learning Table 10.1 Hypotheses produced by FOIL for some representative learning problems Accuracy (%) Region Problem mL |ˆc| m(ht ) EL ET CPU time (s) Π0 5 15 1 3 100 100 10.3 Y Π1 6 20 1 5 100 99.5 21.4 E Π2 7 19 1 7 100 100 52.3 S Π3 8 16 1 8 100 100 106.2 Π4 9 15 1 9 100 100 69.1 r Π5 10 13 1 14 100 99 144.2 e Π6 10 16 8 <10−13> 11.75 88 48.5 783.5 g Π7 11 13 1 11 100 100 92.2 i Π8 11 15 6 <11−16> 13.5 85 53.5 986.2 o Π9 12 13 3 <13−15> 14 98.5 83 516.4 n Π10 13 13 1 13 100 100 455.9 Π11 14 12 1 13 100 98.5 297.0 Π12 13 31 13 <1−8> 4.77 90.5 49.5 1317.3 Π13 15 29 1 6 100 100 185.3 Π14 15 35 2 <5−7> 6 97.5 84.5 894.6 N Π15 15 38 1 6 100 99.5 101.5 O Π16 16 38 3 <5−8> 6.33 97.5 90 1170.6 Π17 18 24 1 10 100 100 196.4 r Π18 18 35 1 6 100 100 201.0 e Π19 19 26 2 <1−8> 4.5 100 98.5 298.4 g Π20 21 18 8 <1−10> 4.13 81.5 58 1394.9 i Π21 24 20 1 10 100 99.5 252.3 o Π22 25 24 1 6 100 99 135.9 n Π23 27 18 10 <1−13> 5.6 94 72.5 1639.6 Π24 29 17 1 12 100 99.5 144.9 Π25 29 23 1 10 100 99.5 720.5 Π26 29 24 1 9 100 99 618.8 Π27 6 26 1 6 100 100 82.5 Π28 628 12 <5−11> 8.083 33 91.5 50.5 815.4 Π29 727 11 <5−11> 8.272 73 92 53 1237.0 Π30 728 11 <1−10> 7.636 36 91.5 60.5 1034.2 P Π31 8 27 1 7 100 100 58.8 T Π32 11 22 5 <1−12> 3.2 71.5 70.5 851.0 Π33 11 27 1 8 99 98.5 250.4 r Π34 13 21 10 <1−11> 4.1 85.5 63 1648.2 e Π35 13 26 1 9 100 99 476.8 g Π36 14 20 5 <1−11> 4.8 94 88 722.7 i Π37 14 24 3 <7−9> 7.666 67 99 92.5 774.0 o Π38 17 14 8 <13−17> 15 93 46 294.6 n Π39 17 15 9 <1−13> 5 78.5 66 916.8 Π40 18 16 8 <1−15> 8.875 91 58.5 404.0 Π41 19 16 7 <1−12> 8.142 86 83.5 60.5 1268.5 Π42 26 12 3 <24−25> 24.3333 80 58 361.4 Experimental results 233 The number of such ht, denoted |ˆc|, is given in column 5 (let us recall that the true target concept c is conjunctive, i.e., a correct identiﬁcation of c implies that |ˆc| =1). Maximum, minimum, and average sizes of the conjunctive hypotheses ht learned by FOIL are displayed in column 6 under the heading m(ht).These may be compared with the true size m of the target concept (column 3). The last three columns list the predictive accuracy of ˆc on the training and test set and the total CPU time required by FOIL to complete the learning task, as measured in seconds by Botta et al. (2003), on a Sparc Enterprise 450. The learning problems in Table 10.1 can be grouped into three categories. • Easy problems, which are correctly solved. FOIL ﬁnds a conjunctive hy- pothesis ˆc that accurately classiﬁes (almost) all training and test examples. Furthermore, ˆc is identical to the true concept c or differs by at most one literal. Problems of this type are Π0–Π5, Π7, Π10, Π11, Π27,and Π31. Most easy problems lie in the YES region; others lie in the phase transi- tion for low values of m (m ≈ 6). • Feasible problems, which are efﬁciently solved even though the correct target concept is not found. More precisely, FOIL learns a concept ˆc which (i) is accurate in prediction (nearly all training and test examples are correctly classiﬁed), (ii) consists of a single conjunctive hypothesis, as does the original target concept c, and (iii) shares many literals with c. However, ˆc is signiﬁcantly shorter than c (e.g., ˆc involves nine literals ver- sus 29 in c for problem Π26); in many cases, ˆc largely overgeneralizes c. Most feasible problems lie in the NO region, rather far from the phase tran- sition. Problems of this kind are Π13, Π15, Π17, Π18, Π21, Π22, Π24– Π26, Π33,and Π35. • Hard problems, which are not solved by FOIL. The learned concept ˆc is the disjunction of many conjunctive hypotheses ht (between six and 15) of various sizes, and each ht only covers a few training examples. From a learning perspective, FOIL produces overﬁtting (each ht behaves well on the training set but its accuracy on the test set is comparable with that of random guessing) related to an apparent small disjunct problem (Holte et al., 1989) even though the true concept is conjunctive. Hard problems lie in the NO region; as opposed to feasible problems, hard problems are close to the phase transition. These results conﬁrm the fact that predictive accuracy may be only loosely correlated with the discovery of the true concept. Indeed, FOIL succeeds when- ever it correctly discovers a single conjunctive concept. It is clear that in real- world problems there is no way of making any difference between feasible and 234 Phase transitions and relational learning Table 10.2 Summary of the experiments. Easy and feasible learning problems (Solved pbs.) are distinguished from hard problems (Unsolved pbs.) Average no. of hyps Avg of solved pbs.No. of Percentage of solved unsolved Region pbs. solved pbs. pbs. pbs. Test acc. CPU time YES 46 88.1% (37) 1 6.33 99.61 74.05 NO 195 72.8% (142) 1.27 8.28 99.61 385.43 PT 210 28.1% (59) 1.10 8.18 99.12 238.25 Total 451 52.8% (238) 1.12 7.60 99.45 232.58 30 20 10 0 5 10 15 20 25 30 35 15 20 25 30 35 L m 40 45 Figure 10.6 Distribution of the number of conjunctive hypotheses ht (vertical axis) learned by FOIL; they are centered on the phase transition region. easy problems, since the true concept is unknown. We shall return to this point later. A ﬁrst remark concerns the localization of the learning failures. A summary of the average results obtained in the YES, NO, and phase transition regions is reported in Table 10.2. This shows that most hard problems are located near the phase transition; conversely, most problems in the phase transition region are hard. A second remark concerns the localization of the hypotheses ht learned by FOIL. It is observed that for all learning problems, except the easy problems The hypotheses learned by FOIL tend to be in the phase transition region. located in the YES region, all hypotheses ht lie in the phase transition region (Figure 10.6). This is the case no matter whether FOIL discovers one or several Result interpretation 235 conjunctive hypotheses ht or whether the location of the learning problem lies in the phase transition or in the NO region. More precisely: • When the target concept lies in the phase transition region and the problem is easy, FOIL correctly discovers the true concept. • For feasible learning problems FOIL discovers a generalization of the true concept that lies in the phase transition region. • For hard problems FOIL retains seemingly random ht, most of which be- long to the phase transition region. 10.2.3 Computational complexity The computational complexity of the search depends mainly on two factors: the number of hypotheses ht retained and the average number of their models in an example e, i.e., the number of substitutions θ such that htθ is satisﬁed in e.For easy problems, a single hypothesis ht (ˆc ≈ c) is constructed; the computational cost remains low though it increases, as expected, when the average number of models of ht goes to 1. For feasible problems also, a single hypothesis ht (ˆc most often overgeneralizes c) is constructed. In most cases the computational cost is very low and the average number of models is very high.4 Finally, in the case of hard problems many hypotheses ht are constructed and the computational cost is always very high. This might be explained by the fact that most ht’s lie The learning cost is higher for problems in the NO region. in the phase transition region, and some admit roughly a single model in the examples. Other things being equal, the learning cost is higher for problems in the NO region. A general cause for this higher complexity is the size of the hypothe- sis space, which increases exponentially with the number m of literals in c;this causes many more hypotheses to be considered and tested in each learning step. Another cause is that the NO region includes many hard problems (Figure 10.5); for such problems the phase transition is visited again and again as more hy- potheses are learned. 10.3 Result interpretation We will now provide some interpretation of the results reported in the previous section. The discussion focuses on three main questions: why is the learning 4A single exception can be seen in Table 10.1: for the learning problem Π25 , the average number of models is 1 and the computational cost is high. 236 Phase transitions and relational learning search captured by the phase transition region?; when and why does relational learning miss the true target concept?; when and why does relational learning fail to ﬁnd any accurate approximation of the target concept? 10.3.1 Phase transition as an attractor In Section 10.2.2 we saw that a large part of the search ends up in the phase transition region, independently of both the location of the true concept and of the used learner. In other words, the phase transition behaves as an attractor for the search. Similar results were presented by Botta et al. (1999), who showed speciﬁcally, using a large set of artiﬁcial problems, that FOIL systematically tends to generate concept descriptions located in the phase transition region. In order to understand why, we will take a closer look at what happens during an inductive search by the different learners we have considered. Being a top-down learner using a hypothesize-and-test strategy, FOIL con- structs a series of candidate hypotheses {h1,...,hi,...,ht} with increasingLearning strategies guided by information gain and minimum description length always end up with a search in the phase transition region. speciﬁcity. The ﬁrst hypothesis in the series (just one literal) belongs to the YES region by construction.5 Then FOIL adds new literals one at a time, moving on the line L = |Λ| toward the right and remaining for a while inside the YES re- gion. If the most speciﬁc hypothesis hi that can be built up in the YES region is not satisfactory according to its stop criterion (see below), FOIL possibly comes to visit the phase transition region and so hi+1 belongs to it. It might possibly happen that the most speciﬁc hypothesis hj ( j> i) in the phase transition region is not satisfactory either; FOIL then comes to visit the NO region. Let us consider the stop criterion used in FOIL. On the one hand the search is stopped when the current hypothesis is sufﬁciently correct, covering no or few negative examples; on the other hand, at each step the current hypothesis is re- quired to be sufﬁciently complete, covering sufﬁciently many positive examples. In the following, the implications of these criteria are discussed for various loca- tions of the target concept c in relation to the phase transition. Case 1 The target concept c belongs to the phase transition region By construction, the target concept c covers with probability 0.5 any exampleConcept c belongs to the phase transition region. randomly constructed by model RL; therefore, the repair mechanism ensuring equidistribution of the dataset is not employed (Section 10.1.1). We may draw the following conclusions. 5Strictly speaking, one should refer to the location of the learning problem with respect to the phase transition. A hypothesis with size m does not belong to the phase transition per se;this depends upon the number L of constants in the examples. However, for the sake of readability and since L is ﬁxed from the datasets, we shall speak of the location of a hypothesis or of the target concept. Result interpretation 237 • Since any hypothesis in the YES region almost surely covers any randomly constructed example, it almost surely covers all positive and negative train- ing examples. Therefore the search cannot stop in the YES region but must come to visit the phase transition. • Symmetrically, any hypothesis in the NO region almost surely rejects (does not cover) any random example and will almost surely cover no training example at all. Though these hypotheses are correct they are not admissible since they are insufﬁciently complete. Therefore the search must stop before reaching the NO region. From these remarks, it can be seen that FOIL is bound to produce hypotheses ht lying in the phase transition region. Case 2 The target concept c belongs to the NO region In this case, the examples generated by model RL are almost surely negative examples (Section 10.1.1), and half must be turned into positive examples using the ChangeToPositive algorithm. It follows that any hypothesis h in the YES Concept c belongs to the NO region.region will almost surely cover the negative examples. In addition, it is likely that it also covers the positive ones, because the latter have been constructed in such a way that they are easier to verify; moreover, as any hypothesis generated by the learner uses only the predicates occurring in c, a hypothesis is most likely to be a generalization of c. In any case, any h in the YES region covers at least all negative examples and thus it must be specialized. As a consequence the search cannot stop in the YES region. However, any hypothesis in the NO region will almost surely be correct (i.e., it will cover no negative examples); therefore there is no need for FOIL to engage deeply in the NO region. Hence FOIL is bound to produce hypotheses ht lying in the phase transition or on the verge of the NO region. Case 3 The target concept c belongs to the YES region The situation is different here, since there exist correct hypotheses in the YES re- gion, namely the target concept itself and possibly many specializations thereof. Should these hypotheses be discovered (the chances of such a discovery are dis- cussed in the next subsection), the search can stop immediately. In all cases, however, the search must stop before reaching the NO region for the following reason. As c belongs to the YES region, randomly constructed examples are al- most surely positive examples (Section 10.1.1). This implies that any hypothesis in the NO region will almost surely reject the positive examples and will there- fore be considered insufﬁciently complete. Again in this case, FOIL is bound to produce hypotheses ht in the YES or phase transition regions. In conclusion, FOIL is unlikely to produce hypotheses in the NO region, whatever the location of the target concept c, at least when the negative examples 238 Phase transitions and relational learning are uniformly constructed. Most often FOIL will produce hypotheses belonging to the phase transition region, though it might produce a hypothesis in the YES region if c itself belongs to the YES region. It is worth noting that such a behavior has also been detected in several real- world learning problems (Giordana and Saitta, 2000). Analogous considerations hold for SMART+, and, more generally, for all top-down learners using a hypothesize-and-test strategy: as maximally general hypotheses are preferred, provided that they are sufﬁciently discriminant, there is no beneﬁt in searching the NO region. The above argument explains why the phase transition constitutes an attractor for top-down hypothesize-and-test relational learners. Experiments done with G-Net indicate that the same conclusion also holds for a data-driven genetic-based learning search, even though it differs signif- icantly from a top-down search. This ﬁnding can be explained as follows. The starting point in a genetic search (the initial population of solutions) con- sists of random hypotheses distributed on the horizontal line L = |Λ| (see Figure 10.4). Then the evolutionary search proceeds by focusing on the ﬁtter hypotheses, where the ﬁtness function favors the most discriminant and simple hypotheses. On the one hand, discriminant hypotheses are mostly found close to the phase transition; on the other hand, since simple hypotheses score higher than complex ones, other things being equal, a genetic search will favor hy- potheses in the phase transition or on the verge of the YES region. Like FOIL and SMART+, G-Net will most often produce hypotheses in the phase transition region (Giordana and Saitta, 2000). In order to support the claim that most discriminant hypotheses are located inDiscriminant hypotheses of low complexity lie in the phase transition region. the phase transition region, we conducted another set of experiments. Let us now consider two examples of a given concept c, namely e+ and e−, one positive and one negative. Let L0 be the average number of constants occurring in the two examples. Suppose that the goal is to learn a concept deﬁnition ϕ that covers e+ and does not cover e−.Given L0, model RL generates a set of hypotheses that, paired with e+ and e−, constitute matching problems (ϕ, e+)and(ϕ, e−) corresponding to points on the horizontal line L = L0 in the (m, L) plane. This line intersects the mushy region. We know that, in the NO region, the matching problems (ϕ, e+)and (ϕ, e−) have very little chance of being satisﬁed. It would be easy to exclude e−, but ﬁnding a deﬁnition for c that covers e+ may turn out to be a very hard search problem indeed. On the contrary, hypotheses generated in the YES region produce matching problems that are most likely to be veriﬁed. Then it is easy to cover e+ but very difﬁcult to exclude e−. However, a hypothesis deﬁning a matching problem on the phase transition has probability about 0.5 of verifying any example, so that it should be easier to discriminate between e+ and e−. Result interpretation 239 1.0 Pd Psol 0.8 0.6 0.4 0.2 0 010 20 mProbability 30 40 50 Figure 10.7 Proportion of hypotheses discriminating between two concept in- stances. For each m value, 1000 formulas were generated corresponding to 2000 matching problems. The largest fraction of discriminant hypotheses corresponds to 50% chance that a solution exists. In order to test the above conjecture we built up two instances, e1 and e2, On the phase transition edge every formula has about a 50% chance of verifying an example. each with L =16 constants. Moreover, 45 binary predicates were deﬁned, cor- responding to relations containing N = 100 tuples. Finally, hypotheses with n =4 variables were created according to the procedure used in Section 9.1.3. More precisely, for each value of m ∈ [3, 45], 1000 formulas were generated, and 86 000 matching problems were deﬁned by pairing each formula with both e1 and e2. For each m value the proportion of formulas, Pd, covering exactly one of e1 and e2 (i.e., discriminant formulas) was computed and is shown in Figure 10.7. For reference, the graph of the probability of solution Psol is also shown. From the graph for Pd it is clear that the proportion of discriminant for- mulas reaches its maximum when Psol =0.5, at the phase transition. Therefore, independently of the speciﬁc distribution of the concept instances, the part of the hypothesis space that deﬁnes matching problems inside the mushy region has a much higher density of acceptable concept deﬁnitions than other parts. In conclusion, we formulate the conjecture that any coverage-based induction algo- rithm will most likely search in this region. The behavior described is reinforced by a search heuristic biased toward simplicity; in fact, a learner guided by such a heuristic will tend to focus the search where the hypotheses are discriminant and, at the same time, are as simple as possible, i.e., in the mushy region. Finally, we analyzed the time evolution of the hypothesis population manip- ulated by the evolutionary learner G-Net, which was used for the case studies 240 Phase transitions and relational learning p2 − ˆp2 ,cr p2 − ˆp 2 , cr )b()a( 2000 200 160 120 80 40 0 −0.4 −0.2 0 0.2 0.4 1600Number of matching problemsComplexity1200 800 400 0 −0.4 −0.2 0 0.2 0.4 Figure 10.8 Evolution of the population of inductive hypotheses manipulated by G-Net. (a) Distributions of the p2 − ˆp2,cr values for the hypotheses belonging to an initial population (solid line) and to the hypothesis population after 10 000 hypothesis-generation steps (broken line). The concentration of individual hy- potheses towards the phase transition clearly emerges. (b) Distributions of the matching complexity for the same populations as in (a). A remarkable increase in the matching complexity appears in the later distribution. reported in Appendix A. Given a set of examples, Figure 10.8(a) shows the dis- tribution of the variable p2 − ˆp2,cr for matching problems obtained by pairing each example with all the hypotheses belonging to an initial (almost random) population6 and all the hypotheses belonging to the population reached after 10 000 generation steps. Clearly, as time goes on the hypotheses evolved by G- Net tend to accumulate around the phase transition point, where p2 =ˆp2,cr. Figure 10.8(b) shows the corresponding matching complexity, averaged over all problems corresponding to the same p2 − ˆp2,cr value. In conclusion, we expectExperiments run with FOIL and G-Net conﬁrm that the phase transition region is an attractor for inductive search. that a relational learner will tend to explore the phase transition region, being the place where it is more likely to ﬁnd simple and discriminant hypotheses. 10.3.2 Correct identiﬁcation of the target concept Given that the selected hypotheses are most often close to the phase transition, let us examine why and when these hypotheses might differ from the true target concept c even though c itself belongs to the phase transition. 6G-Net uses a special seeding operator to generate the initial population of hypotheses. Details of the procedure can be found in Anglano et al. (1998). Result interpretation 241 When c belongs to the phase transition, two possibilities have been observed (see Table 10.1). If c involves few literals (m ≤ 6) then it is correctly identiﬁed. Otherwise, a number of hypotheses ht are retained, in which each ht covers a few positive training examples, and their disjunction ˆc performs very poorly on the test set. The reasons why a top-down learner fails to identify a long target concept (m> 6) are illustrated with an example. Let us consider the target concept c for problem Π8,20 (m =8,and L =20), which belongs to the phase transition: c = r0(x1,x2) ∧ r1(x2,x3) ∧ r2(x2,x3), r3(x3,x4) ∧ r4(x1,x4) ∧ r5(x1,x4) ∧ r6(x3,x4) ∧ r7(x3,x4). The top-down search proceeds by greedy optimization of the information gain. The choice of ﬁrst literal is indeterminate, since any literal covers all positive and negative examples, as explained in Section 10.1.2. This does not penalize the search; in fact, any choice is relevant since all predicates appear in c by construction. All eight specialization paths, corresponding to all possible choices for the ﬁrst literal, are thus considered in parallel (see Figure 10.9). Given the ﬁrst selected literal (say h1 = r0(x1,x2)), the information gain for each literals connected to h1 is computed, and the literal with the maximum information gain is retained. Unfortunately, it turns out that the best literal ac- cording to this criterion (i.e., r6(x3,x2), with gain 270.37) is incorrect, i.e., the hypothesis h2 = r0(x1,x2)∧r6(x3,x2) does not generalize c; the search cannot recover from this error and it will randomly wander thereafter unless backtrack is allowed (see below). For this problem, maximization of the information gain appears to be seri- ously misleading. In all eight specialization paths but one, the ﬁrst effective spe- cialization step (involving the second literal) fails since FOIL selects incorrect literals (displayed with a broken oblique arrow, together with the corresponding information gain, in Figure 10.9). When a specialization choice is incorrect, FOIL must either backtrack or end up with an erroneous hypothesis ht. In order to see the total amount of backtrack- ing needed to ﬁnd the true target concept c, we correct hypothesis h2 manually and replace the erroneous literal by the best correct literal (the literal with the maximum information gain such that h2 generalizes the true target concept). The best correct literal is indicated by a solid vertical arrow in Figure 10.9, together with the corresponding information gain; clearly, the best correct literal often does poorly in terms of information gain. Figure 10.9 depicts all specialization paths. Unfortunately, it appears that forcing the choice of a correct second literal is not enough; even though h2 is correct, the selection of the third literal is again misled by the information gain criterion in all branches but one. To pursue the investigation, we iteratively force the choice of the best correct ith literal in allr0(X1,X2)r1(X1,X2)r2(X1,X2)r3(X1,X2)r4(X1,X2)r5(X1,X2)r6(X1,X2)r7(X1,X2)r6(X3,X2)r4(X1,X3)r4(X4,X3)g=270.37r1(X3,X2)g=663.91g=246.80r5(X1,X3)g=237.78r2(X1,X4)g=1943.96r0(X1,X4)r781.96r4(X1,X3)g=3928.51r7(X3,X1)g=1196.79r7(X2,X3)g=979.65r3(X2,X3)g=1010.14r6(X2,X3)g=1013.87r4(X4,X2)g=320.77r2(X4,X1)g=225.23r5(X2,X1)g=532.38r6(X1,X2)g=1355.43r7(X1,X2)g=1651.52R4(X4,X3)g=1735.84r0(X4,X3)g=963.29r1(X4,X1)g=3366.04r1(X3,X1)g=205.21r3(X3,X2)g=452.89r4(X3,X2)g=445.87r1(X2,X3)g=274.88r2(X1,X3)g=237.78r2(X1,X4)g=1943.96r0(X1,X4)g=781.96r4(X1,X2)g=3928.51r7(X2,X1)g=1196.79r7(X3,X2)g=979.75r3(X3,X2)g=1010.14r6(X3,X2)g=1013.87r4(X4,X2)g=320.77r2(X4,X1)g=225.23r6(X1,X2)g=1071.68r5(X2,X1)g=532.38r7(X1,X2)g=1471.76r0(X2,X1)g=1543.87r3(X1,X2)g=1425.26r5(X3,X2)g=4563.94r3(X1,X2)g=1294.97R4(X4,X3)g=1573.73r0(X3,X4)g=1419.35r0(X4,X3)g=1011.54r4(X4,X2)g=3305.10r1(X4,X1)g=4328.31r4(X3,X2)g=121.57r0(X3,X1)g=243.30r1(X3,X1)g=158.13r4(X2,X3)g=296.44r2(X3,X1)g=982.56r0(X1,X3)g=246.80r6(X4,X2)g=1028.28r5(X1,X2)g=4329.64r7(X4,X2)g=1071.89r3(X4,X2)g=1179.06r2(X1,X4)g=982.56R7(X2,X1)g=1708.79r0(X3,X1)g=213.73r1(X4,X2)g=3431.41r4(X3,X4)g=985.66r5(X3,X4)g=3485.03r7(X4,X3)g=1220.88r6(X2,X4)g=402.46r7(X4,X3)g=490.57r7(X2,X4)g=312.22r3(X2,X4)g=352.79g=2179.51r6(X4,X3)g=1028.28r5(X1,X3)g=4239.64r7(X4,X3)g=1071.89r3(X4,X3)g=1179.06r2(X1,X4)g=982.56r1(X2,X4)g=129.24r2(X3,X2)g=272.70 1|96)r1(X4,X2)g=129.24r5(X4,X2)g=378.25r1(X3,X4)g=129.24r1(X4,X3)g=129.24r5(X4,X2)g=378.25r1(X4,X1)g=129.24R7(X3,X1)g=1708.79Figure10.9VisitingthespecializationtreefortheproblemΠ8,20.Allspecializationsteps“misled”(incor-rectlysuggested)byinformationgainmaximizationareindicatedwithobliquebrokenarrows;theincorrectbestliteralisgivenwiththeassociatedinformationgaing.Insuchcases,abacktrackisforcedtothebestcorrectliteral(indicatedwithaverticalsolidarrow,togetherwiththeassociatedinformationgain). Result interpretation 243 cases where the optimal literal with respect to information gain is not correct. All repairs needed are indicated in Figure 10.9. The above procedure shows that a greedy top-down hypothesize-and-test search is bound to miss the true target concept, as it will not ﬁnd any error-free specialization path for this learning problem. 10.3.3 Backtrack and domain knowledge AccordingtoFigure 10.9, a huge amount of backtracking would be needed to discover the true target concept from scratch. More precisely, the informa- tion gain appears to be reliable only in the late stages of induction and pro- vided that the current hypothesis is correct (the search is “seeded” with four correct literals). In other words, the information gain criterion can be used to transform an educated guess (of the ﬁrst four literals) into an accurate hy- pothesis, if the educated guess has reached some critical size (in the partic- ular case of problem Π8,20 the critical size corresponds to half the size of the true concept). The educated guess to be provided to the learner can be thought of as domain knowledge. The above remarks thus echo the need for strong domain knowledge for learning to proceed, as is generally acknowledged in the inductive logic programming (ILP) literature (Srinivasan et al., 1995; Muggleton, 1992). In the YES region, the IG measure is not reliable for choosing the literals to be added to the current hypothesis. The amount of background knowledge needed in order for learning to occur can be evaluated from the critical size mk of the educated guess, deﬁned as follows. The critical size mk is the minimal number of literals such that, with probability 0.5, FOIL ﬁnds the target concept or a correct generalization thereof (see Section 10.3.4) by reﬁning a mk-literal guess that generalizes c. Figure 10.10 shows the critical size mk(m, L) according to an educated guess for all problems Πm,L within or close to the phase transition, obtained as for problem Π8,20 by systematic backtracking. Figure 10.10 could be thus in- terpreted as a reliability map of the information gain: high values of mk(m, L) indicate poor reliability. These empirical limitations of the information gain criterion can be ex- plained within the phase transition paradigm. Let us consider the sequence of hypotheses explored by FOIL (or SMART+). While the current hypothesis hi belongs to the YES region, it covers any example; the number of substitutions or models that satisfy hi increases exponentially with the number of variables in hi, regardless of the example label. This hinders the distinction between correct and incorrect literals, as the signal-to-noise ratio is very low. When the search enters the phase transition region, the information gain criterion becomes effec- tive and guides the learner towards one among the many existing discriminant 244 Phase transitions and relational learning 40 30 20 10 30252015105 L m Figure 10.10 Minimum number mk of correct literals, for all problems Πm,L within or close to the phase transition, to be provided before the information gain becomes reliable. hypotheses. However, the selected discriminant hypothesis may differ signiﬁ- cantly from the true target concept, owing to earlier erroneous choices. To back up these considerations, the average number of substitutions θ (mod- els) such that hθ is veriﬁed in e (where h and e are generated by model RL) and its variance have been measured experimentally. Figure 10.11(a) gives the aver- age number μ of models, for random h and e, as a function of the number m of literals in h, in the cases when h respectively involves 2, 3, and 4 variables; it appears that the number of models decreases very quickly as the phase transition is approached. Figure 10.11(b) shows the standard deviation σ of the number of models, which is very high for all hypotheses in the YES region. 10.3.4 Correct approximation of the target concept According to the above discussion, the target concept c has hardly any chance of being correctly identiﬁed through top-down learning when either its size m or the number L of constants in the application domain are large, which is the case for all problems in the NO region. Result interpretation 245 μσ n = 4 n = 4 n = 3 n = 2 n = 3 n = 2 m m (a) (b) Figure 10.11 (a) The average number μ of models (candidate substitutions θ) such that htθ is veriﬁed in e vs. the number m of literals in ht. (b) The standard deviation σ. On the contrary, it is observed that FOIL does succeed in ﬁnding highly ac- curate hypotheses (Figure 10.5) for many problems in the NO region, when both the target concept is large and the examples involve many constants (upper-right region, where m and L are large). A closer inspection shows that this is the case when m is more than twice the critical value mcr (where the horizontal line L = |Λ|, L being the number of constants in the model, meets the phase transi- tion). A tentative explanation for this goes as follows. Let us consider a learning problem in the NO region. As the size m of the target concept increases, so does the amount of modiﬁcation needed to transform a random example into a positive one (Section 10.1.1). The underlying distributions for the positive and negative examples become more and more different as m increases, which intuitively ex- plains why it becomes easier to separate them. More formally, let us consider a generalization ϕ of the target concept; by A top-down search, looking for discriminant concept descriptions, will stop as soon as it ﬁnds one in the phase transition region. construction ϕ is complete, i.e., it covers all positive examples. However, if ϕ belongs to the NO region then it almost surely rejects all random examples, and negative examples in particular (the argument closely follows that in Section 10.3.1). All generalizations of c in the NO region are thus almost surely com- plete and correct. Hence, if the learner discovers a generalization ϕ of the target concept close to the NO region, the learning search stops because ϕ behaves per- fectly on the training set; as ϕ behaves perfectly on the test set as well, relational learning is deemed to have succeeded. From the standpoint of predictive accu- racy, the success of relational learning thus depends on the probability of ﬁnding a generalization ϕ of c on the edge of the phase transition. Let m and g denote the number of literals of c and ϕ, respectively. As ex- pected, the number G(g, m) of generalizations of c reaches its maximum for 246 Phase transitions and relational learning 8 × 105 G(g, 22) 6 × 105 4 × 105 2 × 105 0 0 5 10 15 20 g Figure 10.12 The number G(g, 22) of g-literal generalizations of a 22-literal target concept c vs. g. 12 × 106 10 × 106 8 × 106 6 × 106 4 × 10 6 2 × 10 6 0 10 12 14 16 18 20 22 24 m G G(mcr , m) Figure 10.13 The number G(mcr,m) of mcr-literal generalizations of an m- literal target concept c. The number of all g-literal generalizations of c for g ≤ mcr is S. g = m/2; Figure 10.12 shows G(g, m) versus g for m =22. Figure 10.13 shows G(g, m) versus m when g = mcr; we see that the number of generaliza- tions starts growing very fast as m increases and that half belong to the phase transition region when m is more than twice the critical value mcr. Beyond general-to-speciﬁc learning strategies 247 Both considerations explain why relational learning problems appear to be easier to solve as the size m of the target concept increases and is greater than twice the critical value mcr. 10.4 Beyond general-to-speciﬁc learning strategies We have seen that the traditional general-to-speciﬁc hypothesize-and-test learn- ing strategies are “misled” by the presence of the phase transition in the cover- ing test. In this section we will investigate other possible strategies, in particular those that are stochastic, knowledge directed, or top-down data-driven. Then we will show that, even if in essence the limits set by the presence of the phase transition cannot be eliminated and no general strategy exists for approaching induction problems of arbitrary complexity, there exist search strategies much more powerful than those used in FOIL, SMART+, and PROGOL. In previous sections we saw that heuristics relying on the number of models that hypotheses have in the examples (Quinlan, 1990; Botta and Giordana, 1993; Rissanen, 1978) are not reliable in the YES region. The reason is that both in- correct and correct generalizations of the target concept have similar numbers of models in the positive and in the negative examples. In support of this claim, let us consider again Figure 10.11, which shows the average number μ and the standard deviation σ of the model number versus the number of literals in a hy- pothesis. It is clear that an increase by 1 in the number n of variables induces a large increase in μ and an even larger increase in the standard deviation σ;when FOIL fails when the concept description cannot be approxi- mated by a formula with three variables only. n =4 the standard deviation is larger than the number of positive examples in the learning set. Thus, even if we assume that generalizations of the target con- cept c have at least one more model in the positive examples than in the negative examples, these generalizations cannot be distinguished from a purely random hypothesis. On the contrary, for hypotheses with two or three variables only, μ is much smaller and we may expect that, provided that a correct generalization ˆc of c with only two or three variables exists, it should be easier to ﬁnd it than any generalization having four variables. This conjecture agrees with the fact that many solutions actually gener- ated by FOIL have only three variables even though the target concept is de- scribed by a formula with four variables. A more detailed analysis is shown in Figure 10.14, where the line corresponds to the phase transition edge for n =4. In Figure 10.14(a) the plusses indicate the locations of a set of target concepts c with four variables, whose description learned by FOIL also contains four variables. Figure 10.15(a) shows the location of the solutions found by FOIL. Most of these solutions are generalizations of c with four variables, because 248 Phase transitions and relational learning (b)(a) m m LL Figure 10.14 Solutions generated by FOIL for problems in the NO region. (a) Problems solved with hypotheses containing four variables; (b) problems solved with hypotheses containing only three variables. (b)(a) L m m L n = 4 n = 3 Figure 10.15 Solutions generated by FOIL for problems in the NO region. (a), (b) Locations in the (m, L) plane of the solutions generated by FOIL correspond- ing to the problems in Figure 10.14(a), (b), respectively. no acceptable generalizations with three or fewer variables could be found. Figure 10.14(b) shows the locations of a set of target concepts with four vari- ables, whose description as learned by FOIL contains only three variables (see Figure 10.15(b)). Beyond general-to-speciﬁc learning strategies 249 The problems in Figure 10.14(b) are easier to solve than problems in Figure 10.14(a): this result corresponds to the fact that problems in the latter are closer to the phase transition than problems in the former. We observe that the prob- ability that a problem is correctly approximated by a formula with only three variables increases with the number of literals in the target concept c.When c contains more literals, the number of its subformulas that are correct general- izations of c increases as well; then we may expect that at least some contain a number of variables smaller than c’s. Moreover, the difﬁculty of a learning prob- lem increases when L decreases, whereas the critical value mcr increases. When L< 20, the only solutions found have three variables. In conclusion, most learning problems in the NO region have only been solved because approximations with only three variables were sufﬁcient. When more than three variables are required, mcr becomes larger and the available heuristics for top-down search are unable to grow valid inductive hypotheses starting from the YES region. However, we could not ﬁnd any bottom-up learn- ing algorithm capable of coping with the complexity of working directly inside the NO region. 10.4.1 A stochastic approach In the absence of a reliable heuristic, stochastic search may be a valid alternative especially if combined with deterministic search. An example of an effective combination of a Las Vegas search algorithm with deterministic search in the n-queens problem was given by Brassard and Bratley (1988). A hybrid approach, combining stochastic search and hill-climbing general-to-speciﬁc search, is proposed. As described in Section 10.3.3, the information gain heuristic is able to guide the inductive search towards a good generalization ˆc of a target concept c when an educated hypothesis hk, containing an appropriate number k of good literals, is available. The algorithm proposed here, which is stated in Figure 10.16,isbased ona two-step strategy. The ﬁrst step creates a hypothesis hk with a complexity (num- ber of literals) k large enough that hk lies on the border between the YES region and the mushy region; hk is the result of random sampling of the hypothesis space. The second step consists in a general-to-speciﬁc search, starting from hk and performing a hill-climbing strategy guided by the information gain heuristic. If the target concept has a conjunctive description in the hypothesis space H, the Monte Carlo algorithm SFind isverylikelyinthelong runtoﬁnda c,orat SFind least a good generalization ˆc of this c; that is correct on the learning set SL. We would like to compute the complexity of the algorithm SFind (see Fig- ure 10.16), assuming that the complexity m and the number of variables n in the concept c are known. By the complexity of the algorithm we mean the min- imum number Tϵ of trials necessary to reach a probability 1 − ϵ of ﬁnding ˆc 250 Phase transitions and relational learning Algorithm SFind Let ˆccur = ∅ while halt condition does not hold do 1. Randomly generate a hypothesis hk close to the mushy region. 2. Make hk more speciﬁc by following a hill-climbing strategy guided by the information gain. Let ˆct be the locally best hypothesis found in trial t. 3. if ˆct is better than ˆccur then replace ˆccur with ˆct. end Return ˆct Figure 10.16 Stochastic algorithm for searching the space of hypotheses. (or c, as a specially lucky case). If we choose k ≃ mcr − 2, there is strong ex- perimental evidence that a hill-climbing search, guided by the information gain, will ﬁnd ˆc almost surely. The reason is that the search explores the region where the information gain becomes reliable. Let pk be the probability that hk is a subformula of c; then the probability p (t) ˆc of ﬁnding ˆc in no more than t steps is given by the expression p (t) ˆc =1 − (1 − pk)t. (10.2) The dependency of the relation (10.2) upon t and pk is plotted in Figure 10.17. By setting p (t) ˆc =1 − ϵ in (10.2) and solving with respect to t we obtain Tϵ = log ϵ log (1 − pk) . (10.3) Given m and n, the probability pk can be estimated, for a generic number k of literals: pk = G(m, n, k) S(m, n, k) (10.4) where G(m, n, k) is the number of subformulas of c with k literals and any num- ber of variables and S(m, n, k) is the total number of formulas in the hypothesis space with k literals.7 Both G(m, n, k) and S(m, n, k) have been estimated ex- perimentally with an ad hoc algorithm. 7The values m and n are those referring to the target concept c. Beyond general-to-speciﬁc learning strategies 251 0.3 0.4 0.5 0.6 0.7 0.8 0.9 102 103 104 105 106 107 10−7 10−6 10−5 10−4 10−3 10−2 1.0 t p (t ) c Figure 10.17 Probability that a random searcher will ﬁnd any subformula hk of the target concept c vs. the number of trials t, for various values (10−2–10−7) of pk. The curve for pk =0.99 practically concides with the line p (t) c =1. We note that the value Lcr is known when the learning examples are given, The algorithm SFind succeeded in solving many learning problems beyond the reach of FOIL. because Lcr is the average number of constants occurring in them. Table 10.3 reports the results of a set of experiments using Algorithm SFind, starting with different values of k until a correct approximation ˆc was obtained. Going left to right the columns give: 1, 2. the coordinates (m, L) of the target concept c; 3. the number of literals mcr for a target concept supposedly on the edge of the phase transition; 4. the number k of literals in the stochastically sampled hypothesis; 5. the estimated number of S(m, 4,k) formulas with k literals in units of 103 steps; 6. the estimated number G(m, 4,k) of existing generalizations of the target concept, computed by an ad hoc algorithm; Table 10.3 Results obtained by adding a stochastic search step to the basic hill-climbing strategy. Spaces separate the results obtained for different problems S(m, 4,k) G(m, 4,k) mL mcr k (103 )(103 ) pk T0 . 001 Err % 739 6 4 22.82 0.03 0.001 194 7 5778 100% 738 6 4 22.82 0.03 0.001 194 7 5778 100% 736 6 4 22.82 0.03 0.001 194 7 5778 100% 735 6 4 22.82 0.03 0.001 194 7 5778 100% 734 6 4 22.82 0.03 0.001 194 7 5778 100% 733 6 4 22.82 0.03 0.001 194 7 5778 100% 732 6 4 22.82 0.03 0.001 194 7 5778 47% 5 190.68 0.02 0.000 099 6 69 379 100% 831 6 4 45.64 0.05 0.001 175 8 5871 53% 5 508.48 0.05 0.000 098 0 70 497 100% 830 7 4 45.64 0.05 0.001 175 8 5871 49% 5 508.48 0.05 0.000 098 0 70 497 100% 829 7 4 45.64 0.05 0.001 175 8 5871 51% 5 508.48 0.05 0.000 098 0 70 497 100% 828 7 4 45.64 0.05 0.001 175 8 5871 50% 5 508.48 0.05 0.000 098 0 70 497 100% 827 7 4 45.64 0.05 0.001 175 8 5871 48% 5 508.48 0.05 0.000 098 0 70 497 100% 926 7 4 82.15 0.10 0.001 166 5 5918 49% 5 1144.08 0.11 0.000 097 2 71 056 100% 924 8 4 82.15 0.10 0.001 166 5 5918 50% 5 1144.08 0.11 0.000 097 2 71 056 100% 10 23 8 4 136.92 0.16 0.001 161 9 5941 51% 5 2288.16 0.22 0.000 096 8 71 336 48% 6 24 497.76 0.20 0.000 008 1 856 074 100% 10 22 8 4 136.92 0.16 0.001 161 9 5941 49% 5 2288.16 0.252 0.000 096 8 71 336 52% 6 24 497.76 0.20 0.000 008 1 856 074 100% 11 21 9 4 215.16 0.25 0.001 159 7 5953 48% 5 4194.96 0.41 0.000 096 6 71 476 50% 6 53 895.07 0.43 0.000 008 1 857 753 100% 12 20 9 4 322.74 0.37 0.001 158 5 5959 51% 5 7191.36 0.69 0.000 096 5 71 581 50% 6 107 790.14 0.87 0.000 008 0 858 592 100% 13 19 10 4 466.18 0.715 0.001 158 0 5961 50% 5 11 685.96 1.13 0.000 096 5 71 581 49% 6 200 181.70 1.61 0.000 008 0 859 012 49% 7 2 481 967.49 1.66 0.000 000 7 10 308 184 100% Beyond general-to-speciﬁc learning strategies 253 7. the probability pk that hk is a generalization of c; 8. the number of trials T0.001 required for a conﬁdence level of 0.999 that a correct approximation will be found by starting from hk, if it exists; 9. the error rate Err of the best approximation ˆc of c on the test set. 10.4.2 Improving the stochastic search algorithm Expression (10.2) allows one to estimate the number Tϵ of trials required to reach a conﬁdence level 1 − ϵ that the algorithm SFind has found an approximation ˆc, provided that such an approximation exists. The search can be planned as follows. 1. Assume an initial value n for the number of variables in c. 2. Estimate the number Tϵ of trials necessary to reach the conﬁdence level 1 − ϵ.If Tϵ is too high then stop; otherwise go to the next step. 3. Run SFind for Tϵ trials. 4. If the result returned by SFind is acceptable then stop; otherwise increase n by 1 andgotoStep 2. We note that the cost for generating and evaluating a hypothesis in the initial random sampling phase is much lower than the cost for the subsequent hill- climbing search. More speciﬁcally, the number of hypotheses to be generated and evaluated for the hill-climbing step can be estimated by: O( (1 + ν)mn(n − 1) ) , (10.5) ν being an integer that has been observed experimentally to range from 0 to 3. In expression (10.5)the term 1+ ν is an estimate of the number of literals to be added to a hypothesis hk in order to cross the phase transition, whereas the term mn(n − 1) estimates the number of alternative specializations to be considered at each hill-climbing step. Thus the number of hypotheses to be evaluated in the hill-climbing phase is one or two orders of magnitude larger than the number of stochastic trials. A second point worth noting is that, assuming that the information gain heuristic is reliable for any hypothesis hk ∧ ψ, it is also likely that hk itself is scored higher than the average when it is a subformula of c. On the basis of the previous considerations we introduce a new algorithm, which can be more effective than the algorithm SFind.Let Tϵ be the number of trials estimated by 254 Phase transitions and relational learning Algorithm T4 1. Create a set Φ, of cardinality Tϵ, of hypotheses with k literals. 2. Rank the hypotheses in Φ according to their information gain with respect to the trivial hypothesis h0 ≡ true (veriﬁed on all positive and negative examples). 3. Starting from the top-ranked hypothesis, apply the hill-climbing specialization step to the K 4. Return the best description ˆc. best-ranked hypotheses. Figure 10.18 Improved stochastic algorithm. (10.2) in order to reach a conﬁdence level 1−ϵ in the output of SFind. Moreover, let K (1 ≤ K ≤ Tϵ) be a user-deﬁned parameter. The algorithm T4 tries to limit the number of hill-climbing steps to the moreT4 limits the number of hill-climbing steps. promising hypotheses, thus reducing the computational complexity. Of course, the parameter K is an arbitrary choice and the conﬁdence level 1−ϵ is guaranteed to be reached only when K = Tϵ. In practice we have observed that, using values of K that are relatively small (K = 100 as against Tϵ = O(105)), T4 tends to produce the same results as for K = Tε. This algorithm was tested on the set of learning problems shown in Figure 10.5, with the aim of solving those lying in the NO region by following the strategy described above. We started with the minimal hypothesis, with n =3. The parameter k was set to 4, which approximately corresponds to the edge of the phase transition for n =3 and L ≥ 30. Even though for smaller values of L our strategy predicts larger values of k, it was found that T4 was also able to ﬁnd a solution, with the above setting, for many problems where 20 ≤ L ≤ 30. Afterwards, more expensive hypotheses were progressively considered, ﬁrst byThe computational cost of T4 is comparable with that of FOIL. increasing k until the value foreseen by the phase transition was reached (or an excessive cost was foreseen) and then by setting n =4.The value K = 100 was used everywhere. The results are given in Figure 10.19. A comparison with Figure 10.5 shows that many problems lying in the blind spot have been solved. In practice, almost all the problems above the phase transition and the line L =18 have been solved with a complexity that is larger than FOIL’s but still affordable. A cluster of 20 Pentium III (800 Mhz) machines was used for the experi- ments; every problem required a time ranging from few minutes to several hours (an elapsed time comparable to FOIL on a sequential machine). When a problem Comments 255 40 35 30 25 20 15 10 510 15 20 25 30 m L Figure 10.19 Results obtained by the algorithm T4. The numbers denote the minimum value that had to be assumed for K in order for the learning problem to be solved. When a number is preﬁxed by a plus it means that n =4 has been assumed; otherwise n =3. A dot means that the problem was not solved. was not solved, we progressively increased the complexity of the hypothesis by increasing k. 10.5 Comments Moving from the analysis of the covering test (which is equivalent to a single CSP) to a whole learning problem widens considerably the range and complex- ity of the phenomena that have been observed, some of which were expected and some not. First, the YES region constitutes a plateau for any top-down searcher exploiting heuristics based on a distinction between the coverage of positive and of negative examples (typically, the information gain). In fact, random hypothe- ses generated in the YES region almost surely cover any random instance, so that they are unable to distinguish between positive and negative examples, thus making the information gain uninformative. Even when one considers the num- ber of models instead of the number of examples the situation does not improve, because the high variance (see Figure 10.11) masks the difference between the number of models in the positive and negative examples. 256 Phase transitions and relational learning However, the YES region is not a local minimum but a bench (see Section 6.6), because there are exits towards the phase transition region, where the information gain has higher values than on the plateau. The leftmost points marked with numbers in Figure 10.10 represent, in some way, the border of the plateau. In the NO region the situation would be analogous for a bottom- up learner, but on the negative side: any randomly chosen hypothesis will not cover any randomly chosen example, either positive or negative. However, we have not found any purely bottom-up learning algorithm that is able to attack such computationally demanding learning problems and, hence, the only plateau of interest is that in the YES region. In an interesting paper, Alphonse and Osmani (2007) showed that the plateau in the YES region may actually be successfully crossed by a top-down searcher that exploits a data-driven strategy, when near-miss negative examples (Winston, 1975) are provided in the learning set. Their experimental results were obtained using a generative model (Alphonse and Osmani, 2008b) derived from model RB (see Section 4.2); this generative model has a guaranteed phase transition for all problem sizes. However, the observed beneﬁcial effects are due rather to the special role of the near misses than to the data-driven strategy; even though the genetic learner G-Net exploits a bidirectional data-driven strategy to learn, it was unable to solve more problems than FOIL or SMART+. These results conﬁrm the intuitive feeling that supplying information to the learner, either in the form of special examples or in the form of the minimum size that the concept should have (see Figure 10.10) may reduce the negative impact of the presence of the phase transition. The partial solvability of complex problems in the NO region comes as a surprise, as the simplicity of the target concept has always been considered a factor both facilitating learnability and favoring robustness. However, we have to be careful in declaring a success in learning such problems in that the “true” concept was never acquired in these experiments. Not knowing in real learning settings the true concept, good approximations thereof are all we need as long as we do not require perfect classiﬁcation. Actually, a long concept provides a much larger number of alternative approximations than a short one. All the investigations presented in this chapter were made with the num- ber of variables n equal to 4. This is roughly the limit one encounters in performing experiments such as those reported here. Most learning prob- lems with ﬁve variables could not be handled, owing to the exceedingly high computational resources required. Even though smart algorithms may suc- ceed in reducing the complexity of the single covering test, as was shown in Chapter 9 the sheer number of required in a learning run hinders learning prob- lems from scaling up in size satisfactorily. As mentioned in Chapter 9, this is one reason why the asymptotic behavior with respect to the number of variables is Comments 257 not of much interest in symbolic machine learning of the type described in this book. In learning statistical relational models, for instance in learning the struc- ture of a Markov logical network, the same issue emerges, because only short clauses (with few variables) can be learned. Only recently some efforts have been devoted to trying to overcome this limitation (Kok and Domingos, 2010; Mihalkova and Mooney, 2007). A last point worth mentioning is that we have limited ourselves to investi- gating the emergence of a phase transition in the covering test and its effects on relational learning in general. In all our experiments we kept constant the num- bers of positive and negative examples (100 positive and 100 negative examples in both the training and the test set). However, in principle the learning problem per se may have some control parameter that, reaching a critical value, deter- mines another phase transition. Actually, this seems to be the case, as Alphonse and Osmani (2009) have shown in relational learning and R¨uckert et al. (2002) have shown in propositional learning. In both cases, the number of negative ex- amples was involved as a control parameter. 11 Phase transitions in grammatical inference Contents 11.1 Learning grammars 258 11.2 Grammatical inference by generalization 269 11.3 A phase transition in learning automata? 274 11.4 The covering test: random sampling in H 275 11.5 Learning, hypothesis sampling, and phase transitions 278 11.6 Consequences of the behavior of the learning algorithms: how bad is it? 293 11.7 Comments 298 11.1 Learning grammars Grammatical inference has been studied since the inception of the theory of for- mal grammars in the 1960s, in particular to provide a formal framework for lan- guage acquisition. Since the pioneering paper of Gold (1967), which introduced the concept of identiﬁcation in the limit, numerous works have been carried out in several scientiﬁc communities, including those studying machine learning, pattern recognition, natural language processing, formal language theory, and electronic circuit design. Their goal was to set a theoretical framework for gram- matical inference and to design practical learning methods. Recently, these tech- niques have been used in several application domains such as genomics, natural language processing, and the testing of computer programs. 258 Learning grammars 259 This chapter provides the necessary fundamental concepts to understand the ﬂavor of this ﬁeld and reports on a study of generic learning algorithms with regard to the covering test and generalization. Experimental evidence points again to a phase transition phenomenon, albeit different from those already encountered in this book. 11.1.1 The task of inferring grammars While so far we have discussed a learning scenario where the task is to extract regularities from sets or collections of (labeled) descriptions, this scenario is far from covering all learning situations. Indeed, much data comes in sequences, and often what one wants to learn is the trend, tendency, or even the rule gov- Sequential data erning the sequences. Thus, the important relationship is the sequential or tem- poral organization of the data. This is the case when a child learns the gram- mar of its native tongue, when a biologist tries to decipher how DNA strands command the fabric of some proteins, or when one wants to guess the oil price next month. Mathematicians have come up with the concepts of discrete time functions and differential equations to account for time changes. Computer scientists and specialists in signal processing have added other tools, most notably Markov models and grammars, the latter being closely related to abstract machines called automata. Markov models are versatile and allow one to represent a large variety of (time) dependencies; however, learning a Markov model from data involves learning ﬁrst its structure and then the values of its numerous parameters. Gram- matical inference is mostly concerned with learning the structure of sequences and is often used as a ﬁrst step to decide the type of dependencies that are at play. This is why it is relevant to start with the study of grammatical inference. Formal grammars were originally developed to model natural languages. One key contribution, due to Noam Chomsky (1957), was the deﬁnition of a hierarchy of grammars in terms of their generative power and the claim that the syntax of well-formed sentences in natural languages, like sentences in English, could be characterized with respect to one of these grammars (in partic- ular, context-free grammars). Whereas this claim is still controversial, grammars have been used extensively in the analysis and design of computer languages and compilers. Grammars are natural tools for modeling strings of “letters”, and as such they have been applied to the study of biological sequences and to many problems in computational molecular biology. More precisely, Noam Chomsky introduced four types of formal language, which form the Chomsky hierarchy of formal languages. These types are dis- tinguished by the types of productions that are permitted in their corresponding grammars. 260 Phase transitions in grammatical inference Regular Regular grammars1 are deﬁned by rules of the form A → b orTypes of grammar of the form A → bC.2 Context-free Context-free grammars are deﬁned by rules of the form A → α and are therefore unrestricted in the form that the right-hand side of a rule may take.3 Context-sensitive Context-sensitive grammars are deﬁned by rules of the form αAβ → αγβ,where γ is not the empty string. Unrestricted: Unrestricted grammars are identical to context-sensitive grammars except that γ may be the empty string. Grammatical inference refers to the search for hidden regularities in gram- mars expressed in strings. For instance, according to Chomsky, language acqui- sition is mostly the process of discovering the grammar that underlies it. Take for instance the problem of, given the sequence “aaabbb”, making a guess at the next element. It is most useful to ﬁnd the actual generating function (e.g., a⋆b⋆, meaning a sequence of “a”s followed by a sequence of “b”s). The questions that concern machine learning specialists are: by which mechanism, i.e., algorithm, can we process the data to ﬁnd a candidate generating function? Can we obtain such a function from any presentation (any string, in any order)? How fast can we learn? How do we know that we have succeeded? These ques- tions involve three different metaparameters: 1. the hypothesis space (or class of functions) considered by the learner; 2. the protocol of presentation of the data; 3. the performance criterion used to measure success or distance from suc- cess. In grammatical inference the hypothesis space corresponds to grammars that are able to generate or recognize strings, trees, graphs, and other types of structured object. However, inﬂuenced by its earlier roots in cognitive sci- ence and linguistics, grammatical inference has long been concerned only with learning non-probabilistic grammars. It was indeed thought that probabilities were not fundamentally at play in the learning of languages. Only relatively recently has the learning of probabilistic grammars become an important sub- ject of research. This subject is closely related to that of (hidden) Markov chain models. 1Regular grammars produce languages that can be recognized using ﬁnite automata. 2Upper-case and lower-case roman letters stand respectively for non-terminal and terminal symbols (see Deﬁnition 11.5). 3Greek letters stand for strings of terminal and/or non-terminal symbols. Learning grammars 261 From the start, grammatical inference and the ﬁeld of text learning in general have been much more theoretically oriented than machine learning in its early days. While the latter was at ﬁrst mainly the theater of many experimental and heuristically oriented studies, there were intense debates and reﬂections about plausible and controllable protocols in language learning. Again, under the in- ﬂuence of computational linguistics it was thought that negative examples did not play any signiﬁcant role in the learning of languages. Therefore, most proto- cols did not include negative learning examples, even if some type of interaction Only positive exampleswith the teacher could be envisioned. In addition, the identiﬁcation of a language was thought to be the legitimate goal because the role of probabilities in language acquisition was not seen as plausible. More precisely, whereas most of machine learning has yielded to a statistical theory of learning (Vapnik, 1995), in which Identiﬁcation vs. approximationlearning is seen as ﬁnding a satisfying hypothesis most of the time (the “prob- ably approximately correct learning” (PAC) setting), grammatical inference has long retained the goal of exactly identifying the target language. As a consequence, one requires that candidate hypotheses satisfy the con- straints associated with positive instances on the one hand and negative instances on the other hand, i.e., that they “cover”, exactly and not in probability, the pos- itive instances and reject the negative instances. This makes the covering test a central component of the learning process, which, at an abstract level, acts as a generate-and-test mechanism. Of course, there is no reason to believe that a tar- get grammar actually exists. It might simply be convenient to hypothesize that the best model of the data, for which one is looking, can be expressed as a gram- mar. In this case it is possible that no grammar can perfectly label the training data and that one should settle instead for searching for the best, or a good, ap- proximation to the target regularities, whatever they are. One should speak then of grammar induction rather than grammar inference. In any case the covering test still plays a major role in the inductive process. In addition, as will be shown below, a generality relationship can be imposed Generality relationship in H upon grammars. This relationship induces a partial ordering in the space of the hypotheses and thus opens the door for algorithms that exploit this structure to search for candidate hypotheses satisfying the constraints imposed by the train- ing examples. 11.1.2 An introductory example Suppose that some phenomenon in nature or in a man-made device provides us with strings of observations that can be labeled by “+”or“−”. For example, instances of nucleotide sequences could correspond either to introns or to exons. For the sake of simplicity, let us assume that we have received the following sets of instances: P = {aa, a, bb} and N = {ab,b,ba}. 262 Phase transitions in grammatical inference a a b b b 1 0 2 3 4 5 a 1 2 a a bb Figure 11.1 Two possible solutions (left) and (right) to the learning problem P = {aa, a, bb} and N = {ab,b,ba}. The double rings indicate states that are possibly terminal (i.e., if a sequence ends in this state then it is recognized as belonging to the language). One could learn a model that would explain the positive instances and reject the negative ones. This model can take the form of a regular grammar in a natural way and, as we will see shortly, this type of grammar can be represented by ﬁnite state automata. There exists an inﬁnity of automata that can explain the above dataset. A learning algorithm could for instance return either the left automaton or the right automaton in Figure 11.1. Both produce the correct label for each training in- stance. So, which automaton is the best? In Chapter 5, on machine learning, we showed that a reasonable criterion is that a model should both behave well on the training data and also be “simple”. The latter requirement aims at preventing overlearning. Furthermore, a simpler model generally allows for better understanding of the detected underlying reg- ularities. According to this inductive criterion, the automaton at the right is to be preferred. 11.1.3 Automata and grammars Before studying learning algorithms in grammatical inference and their proper- ties, it is necessary to introduce some notions and terminology that pertain to this ﬁeld. Basic notions Deﬁnition 11.1 {Alphabet} An alphabet Σ is a ﬁnite non-empty set of sym- bols called letters. Learning grammars 263 Alphabets can have as few as two letters, as in the Boolean case, or four letters as in the DNA genetic code or thousands of symbols, as in the Chinese alphabet. Deﬁnition 11.2 {Strings} A string w over Σ is a ﬁnite sequence w = a1 ··· an of letters. Let |w| denote the length of w. In this case, we have |w| = |a1 ··· an| = n. The empty string is denoted by λ. The set of all ﬁnite strings over the alphabet Σ will be denoted Σ⋆. Strings can be ordered. Suppose that we have a total order relation over the letters of the alphabet Σ; this is generally called the alphabetical order. Then different orders can be deﬁned over Σ⋆. Without entering into the formal details of their deﬁnition, we can single out the hierarchical order. With Σ= {a, b},theﬁrst few strings according to that order are λ,a,b,aa,ab,bb,aaa,... Given two (possibly empty) strings u and v, we will denote by u · v the concatenation of strings u and v. When the context allows, we will use the notation uv. Given a string w, x is a substring of w if there are two strings l and r such that w = lxr.4 Deﬁnition 11.3 {Preﬁx} A string u is a preﬁx of another string w if there exists v such that uv = w. EXAMPLE Given w = abbaabbaabab,then abbaa is preﬁx of w. By contrast, aabbaa is a subsequence but not a preﬁx of w. Deﬁnition 11.4 {Language} A language is any set of strings that is a subset of Σ⋆. The complement of a language L is deﬁned with respect to Σ⋆: ¯L = {w ∈ Σ⋆ : w/∈ L}. The representation of a language by enumeration of the subset of the words of Σ⋆ that belong to it would be at best cumbersome, especially if the language is not ﬁnite. This is why languages are generally represented by grammars of the types deﬁned by Chomsky. A grammar is a mathematical object associated with an algorithmic process that can generate a language. 4With this deﬁnition, x is always a substring of itself. 264 Phase transitions in grammatical inference Deﬁnition 11.5 {Grammar} A grammar is a quadruplet G =(N, Σ,P,S), where: • N is an alphabet of all the non-terminal symbols of G;5 • Σ is the terminal alphabet of G and is distinct from N .Weset V = N ∪Σ; • P ⊆ (V ⋆N +V ⋆ × V ⋆) is a ﬁnite set of production rules; • S ∈ N is an axiom of G. A production rule P is written as α −→ β, with β ∈ V ⋆ and α ∈ V ⋆N +V ⋆, which means that α contains at least one non-terminal symbol. Deﬁnition 11.6 {Word generated by a grammar} Aword v ∈ Σ⋆ is said to be generated by a grammar G when it can be generated from the axiom S of G. The language generated by the grammar G is the set of all the words in Σ⋆ that can be generated by G.Wedenoteitby L(G). Here are two examples. When there is no ambiguity, one can simplify the description of the grammar by providing its rules only and by writing in a line all the rules with the same left-hand side. EXAMPLE The grammar deﬁned by N = {S}, Σ= {a, b, c} and P = {(S −→ aSb), (S −→ ϵ)} can be written as S −→ aSb | ϵ This grammar generates the language {a n b n | n ≥ 0}. Indeed, one can see, taking an example, that its axiom S allows the derivation of the word aaabbb in four steps: three applications of the rule S −→ aSb and one of the rule S −→ ϵ, giving successive steps S aSb aaSbb aaaSbbb aaabbb. Chomsky noticed that the representation of languages using grammars allows the deﬁnition of language types in terms of the production rules that generate the languages. This classiﬁcation introduces a strict hierarchy among the classes of languages. The regular grammars are the simplest. They are also called rational languages because they form the smallest family of languages 5Non-terminal symbols are not observed in the strings of a language (see Deﬁnition 11.4) but are used as place-holders or auxiliary symbols in the derivation of sentences. Learning grammars 265 1 2 a 3 b a 4 b b a b a Figure 11.2 A ﬁnite state automaton accepting strings composed of an even number of a’s andanevennumberof b’s. on Σ⋆ that is closed by the rational functions that are the union, the product of concatenations, and Kleene’s iteration operation ⋆. Regular grammars A regular grammar is deﬁned by A −→ wB or A −→ w, with w ∈ Σ∗, A ∈ N , and B ∈ N . A language that can be generated by a regular grammar is said to be a regular language. A classical result of the theory of languages is the following. Theorem 11.1 Any regular language can be generated by a ﬁnite automaton. Conversely, any ﬁnite automaton generates a regular language. Automata can be seen as a kind of graphical representation of regular gram- Graphical representa- tion of ﬁnite state machines mars, where the non-terminal states correspond to non-terminal symbols and the transitions or edges to the derivation rules. By convention, a terminal state is represented with a double circle and the initial state is indicated by an entering arrow. EXAMPLE The grammar deﬁned by N = {1, 2, 3, 4}, Σ= {a, b} and P = {(1 −→ a2), (1 −→ b3), (1 −→ ϵ), (2 −→ a1), (2 −→ b4), (3 −→ a4), (3 −→ b1), (4 −→ a3), (4 −→ b2)} is strictly equivalent to the ﬁnite state au- tomaton of Figure 11.2.6 Strings that are accepted are composed of an even number of a’s and an even number of b’s. This grammar can be rewritten more simply as: 1 −→ a2 | b3 | ϵ, 2 −→ a1 | b4, 3 −→ a4 | b1, 4 −→ a3 | b2 6Here, the axiom is not denoted S,but 1. 266 Phase transitions in grammatical inference The words accepted by the automaton are those for which there exists a pathWords accepted by an automaton from the initial state to a terminal state through the transitions dictated by the symbols of the words of the language. Finite automata Automata are ﬁnite state machines that can recognize strings. They correspond to a simpliﬁed and limited version of Turing machines. A string is provided on the input tape; it is then read from left to right and, at each step, the next state of the system is chosen depending on the previous state and the letter or symbol that is read. The automata is deterministic if only one action is possible at each step. Deterministic ﬁnite automata are usually preferred because they are simpler to manipulate and lead to more efﬁcient parsing and also because a number of theoretical results apply only to them. However, nondeterminism may be better suited for modeling certain phenomena and could also be a partial solution to the difﬁculties one has when facing noisy data. As claimed by Theorem 11.1, ﬁnite automata are equivalent to regular gram- mars. We are now going to deﬁne them more precisely. Deﬁnition 11.7 {Finite automata} A ﬁnite automaton is a quintuplet (Q, Σ,δ,q0,F ),where Q is a ﬁnite set of states, Σ is a ﬁnite alphabet, δ is a transition function, i.e., a function from Q × Σ to 2Q, Q0 ∈ Q is the subset of initial states and F ∈ Q is the subset of ﬁnal states, also known as accepting states. First, we consider deterministic ﬁnite state automata, then the nondetermin- istic case. Deterministic ﬁnite state automata Deﬁnition 11.8 {Deterministic ﬁnite state automata (DFA)} If, for every state q ∈ Q and for every letter a ∈ Σ, the transition function δ(q, a) contains at most (respectively exactly) one element and if Q0 contains only one element q0, the automaton A is said to be deterministic (respectively complete). In what follows we will use the abbreviations DFA for deterministic ﬁnite state automata and NFA for non-deterministic ﬁnite state automata. EXAMPLE The automaton of Figure 11.2 is a DFA. Another example of a ﬁnite state automaton is given in Figure 11.3. It contains ﬁve states, Q = {0, 1, 2, 3, 4}. It is deﬁned over the two-letter alphabet Σ= {a, b}.The initial states are 0 and 5, Q0 = {0, 5}, and the states 3 and 4 are ﬁnal, F = {3, 4}. Learning grammars 267 0 5 1a 2 a a a 3 b 4b b Figure 11.3 A non deterministic ﬁnite state automaton. This is an NFA since there are two edges labeled with the letter a from state 0 and since there are two initial states. Here, δ(0,a)= {1, 2}. Furthermore, this automaton is not complete since the transition function δ is not everywhere deﬁned. For instance, δ(5,b) is not deﬁned. Language accepted by a ﬁnite automaton A language L(A) accepted by an automaton A is the set of all strings that are accepted by A, i.e., for which there exists a sequence of states that are “excited” from an initial state to a ﬁnal state when one uses the transition func- tion on the successive letters of the string. For instance, the sequence of states (0, 1, 3) is associated with an acceptation of the sequence aab in the automaton of Figure 11.3. It is sometime possible to remove some states from an automaton without changing its accepted language. This leads to the deﬁnition of a minimal accept- ing automaton. Deﬁnition 11.9 {Minimal deterministic ﬁnite automata} For any regular lan- guage L there exists a DFA A(L) that generates L and has a minimal num- ber of states; A(L) is called the minimal deterministic automaton or canonical automaton associated with L. It can be proved that this automaton is unique. EXAMPLE The automaton of Figure 11.4 accepts a language composed of the strings that start with an odd number of a’s followed by an odd number of b’s (which corresponds to the regular expression L = a(aa) ⋆ b(bb) ⋆ ). This is the same language as that accepted by the automaton of Figure 11.3. There exists no automaton that contains fewer states than this and that accepts the language L. This is therefore the canonical automaton corre- sponding to language L. 268 Phase transitions in grammatical inference 0 1a a 2b 3b b Figure 11.4 Canonical automaton of the language deﬁned by the regular ex- pression L = a(aa)∗b(bb)∗. Nondeterministic ﬁnite state Automata While most published works deal with the implications of deterministic ﬁnite state automata, it is the case that nondeterministic ﬁnite state automata (NFA) have interesting properties also. For instance, they may offer compact represen- tations of some regular languages. It may thus happen that an NFA needs an exponentially smaller number of states than its corresponding deterministic ﬁ- nite state automaton. In addition, the use of NFA offers different ways of expressing the same language, thus allowing one to choose the representation most adapted to one’s needs. This is why, in many domains, for example in genomics, NFA are used to represent biological regularities of interest even though there are fewer learning algorithms for NFA. In the following, we will be looking at both DFA and NFA. 11.1.4 Learning automata There exists a complete one-to-one mapping between the four types of grammars in the hierarchy of Chomsky and the four types of automata. Grammar Regular Context-free Context-sensitive Unrestricted7 Automata Finite state automata Pushdown automata Bounded-tape Turing machines Turing machines Theoretical works on grammatical inference show that the class of regular languages is the most general class of languages that is identiﬁable in the limit in polynomial time. In practice this means that regular languages are sufﬁciently expressive for a wide range of applications while remaining effectively learnable. 7Also known as recursively enumerable. Grammatical inference by generalization 269 This is the reason why the learning of regular languages has been the subject of numerous studies. 11.2 Grammatical inference by generalization We now turn to a hypothesis space consisting of grammars or ﬁnite automata. We will show that there exists a partial ordering that can be deﬁned over such a space that will allow us to use learning methods that exploit this ordering. 11.2.1 The space of ﬁnite automata In the hypothesis spaces that we have considered so far, the crucial structure that permits a well-guided search for good hypotheses was induced by the relation of inclusion in the space of examples. Thus, in Chapter 5, it was said that one hypothesis, hi, is more general than another, hj , if the set of instances that hy- pothesis hi labels as positive (i.e., covers) includes the set of instances covered by hj . While this induced ordering was immediate in the case of propositional representations, it was more involved in the case of relational concepts and en- tailed some special care. In the ﬁeld of grammatical inference, likewise, one wants to ﬁnd a descrip- tion of the target language (or of some language close to it) that is not in ex- tension, by which we mean not in the form of the set of all accepted sentences. As we have seen, a favored description takes the form of automata. The ques- tion is therefore how to induce a partial ordering on the space of ﬁnite automata from the ordering associated with the inclusion relation deﬁned over the space of sentences. Derived automata A central operation over automata is the partitioning of its states. Recall that a partition π of a set S is a set of subsets of S such that these subsets are not null, are disjoint by pairs, and their union is equal to S. When deﬁned over the set of states of an automaton A, a partition determines a quotient automaton A/π where all states belonging to one subset in the partition are merged together (see an example of the Figure 11.5). One fundamental property of the state-merging operation is that if an au- tomaton A/πj derives from an automaton A/πi through state-merging opera- tions then the language accepted by A/πi is included in the language accepted State merging induces a generaliz- ation in the space of automata. by A/πj .Inother words, the operation of merging states of a ﬁnite state au- tomaton induces a generalization of the languages accepted. Thanks to this property it is possible to build all the automata that can be de- rived from a starting automaton A by enumerating all the partitions of its states. 270 Phase transitions in grammatical inference 0 5 1a 2 a a a 3 b 4b b 0,1 a 3,4b 2 a b b Figure 11.5 Left, a nondeterministic ﬁnite state automaton A. Right, the quo- tient automaton A/π1,where π1 = {{0, 1, 5}, {2}, {3, 4}}. 0,1,2 a 3,4 b b Figure 11.6 The quotient automaton A/π2 derived from A/π1 with π2 = {{0, 1, 2, 5}, {3, 4}}. 0 b a Figure 11.7 The universal automaton over the alphabet Σ= {a, b}. Furthermore, as we have seen, there exists a partial ordering on the space thus deﬁned that is consistent with the inclusion relationship between languages. The automaton where all states are merged into a single state is called the universal automaton (UA). It accepts all strings deﬁned over a given alphabet. For instance, the universal automaton deﬁned over the alphabet {a, b} is rep- resented in Figure 11.7. A lattice over the space of automata From the above property it can be inferred that the hypothesis space can be en- dowed with a lattice structure. Indeed, it can be proved that the set of the au- tomata derived from a given automaton A, partially ordered by the derivation Grammatical inference by generalization 271 a, b a, b a, ba, bb a b bbb b a b bb a b a, bb b b a b b a a b a b b b a a, b a, b a abb gλ gb gb qb qab gb gb qaqa,b qλ, a,b qλ, a qλ, a,b qλ, a,ab qλ, ab,b qλ, bqλ, b qλ qa,b qa,b qb,ab qa,b qa qa qλ qλ qλ qλ qa,bqa qa qa,b qλ,ab qa,ab qa,bqa,ab qa,b,ab qb,ab Figure 11.8 The lattice for the derived automata built on MCA({a, ab}) (cour- tesy of Colin de la Higuera). operation, is a lattice; the automaton A and the universal automaton (UA) are respectively its minimal and maximal elements. This lattice is denoted Lat(A). Figure 11.8 shows Lat (A) when the automaton A is the maximum canonical au- tomaton (MCA) of a set of strings, which is a star-shaped NFA with one branch per string. 272 Phase transitions in grammatical inference 11.2.2 A structure for the space of ﬁnite automata Up to now we have seen how it is possible to endow the space of ﬁnite au- tomata with a partial order associated with the generality relationship between automata. An automaton derived from another accepts at least all the strings ac- cepted by the latter. It therefore recognizes a more general language. However, we have not yet introduced the notion of a training sample or train- ing set from which we want an automaton to learn. Given a sample SL = P∪N ,where P contains the positive examples and N contains the negative examples, the empirical risk-minimization principle dic- tates that an optimal hypothesis is one that minimizes the error on the sample. Actually, as shown in Chapter 5, we should take into account the complexity of the hypothesis space in order to obey a regularized inductive principle. In grammatical inference we usually seek a consistent hypothesis, one that doesThe inductive criterion not make any error on the training set. Of course, this assumes that the data is not suspected of being noisy. We will see how regularization is taken care of by generic learning methods. Structural completeness The number of automata consistent with a given (not conﬂicting8) training sam- ple is inﬁnite. Additional knowledge or bias must therefore be provided to make learning possible. For instance, suppose that the alphabet contains the letters a, b,and c but that only the letters a and b are seen in the positive examples. Then, unless we are told otherwise, there should be no reason to introduce the letter c in the candidate automata. In other words, we will assume that the training sample is sufﬁciently representative of the language to be learned. In concrete terms this means that every component of the target automaton is exercised in the recognition of at least one learning example. Most standard grammatical in- ference systems that have been devised follow this assumption since it confers desirable properties on the search space. Deﬁnition 11.10 {Structural completeness} Aset P is said to be structurally complete with respect to a DFA A if P covers each transition of A and uses every element of the set of ﬁnal states of A as an accepting state. Structural completeness can be extended, with care, to the nondeterministic setting. We do not detail this here. The interested reader can consult de la Higuera (2010) with proﬁt. We will therefore search only for ﬁnite automata for which the training sam- ple is structurally complete. 8That is, where P∩ N = ∅. Grammatical inference by generalization 273 0 2 b 1a 4a 5b 3b Figure 11.9 PTA({a, ab, bab}). As we have seen above, the space of automata can be endowed with a generality-based partial ordering. Furthermore, given a positive training sam- ple P, the search space, under the structural completeness hypothesis, has the following properties. Theorem 11.2 Every DFA in the lattice partition Lat(MCA(P)) is structurally complete for P. Likewise, every NFA in the lattice partition Lat(MCA(P)) is structurally complete for P. Conversely, we have the following. Theorem 11.3 Every DFA that is structurally complete for P is in the lattice partition Lat(MCA(P)). Likewise, every NFA that is structurally complete for P is in the lattice partition Lat(MCA(P)). If, furthermore, we are interested in ﬁnding the smallest deterministic ﬁnite state automaton accepting P, then we can reduce the search space. First, let us deﬁne the preﬁx tree acceptor (PTA) associated with a positive training sample. Deﬁnition 11.11 {Preﬁx tree acceptor (PTA)} A preﬁx tree acceptor (PTA) is a tree-like DFA built from the learning sample by taking all the preﬁxes in the sample as states and constructing the smallest DFA which is a tree such that ∀q ∈ Q, |{q′ : δ(q′,a)= q}| ≤ 1, i.e., that each state has at most one ancestor. EXAMPLE The automaton of Figure 11.9 is the preﬁx tree acceptor for the positive sample P = {a, ab, bab}. Thus, we have the following property. Theorem 11.4 The smallest DFA consistent with a sample S = P∪N is in Lat(PTA(P)). 274 Phase transitions in grammatical inference In addition, since it can be shown that PTA(P) derives from MCA(P),we have Lat(PTA(P)) ⊆ Lat(MCA(P)) and therefore searching a solution in Lat(PTA(P)) is generally more efﬁcient. This property immediately suggests a learning approach for a DFA. The prin-The generic approach ciple is to start the exploration of the search space Lat(PTA(P)) from PTA(P) and then to explore it using the state-merging operator. Overgeneralization is preventedbyusing N . No candidate automaton should accept a string from N . This strategy is at the core of many learning algorithms, such as RPNI,that are widely used. It must be noted that the crucial “more speciﬁc than” relationship is unde- cidable for context-free grammars. This of course precludes the use of learningA difﬁculty for context-free grammars algorithms guided by this well-informed relationship and explains, in part, why so little work has been devoted to learning algorithms for context-free grammars (see, however, Lehn and Ball (1987)). 11.3 A phase transition in learning automata? We saw in Chapters 9 and 10 that an important step in the study of learning was the realization that learning could be cast as a constraint satisfaction problem. In the case of concept learning, one is often interested in discovering a hypoth- esis that is consistent with the training data. It should make no errors, which means that it should predict as positive the positive examples and as negative the negative examples. At an abstract level the problem amounts to checking that there exists at least one hypothesis that can satisfy the constraints imposed both by the positive and by the negative training instances. While in the SAT domain the question raised was the importance of the value of k in the k-SAT problem, in machine learning and in artiﬁcial intelligence in general, the focus is rather on the expressiveness of the hypothesis language. It has been known since the fundamental work of Brachman and Levesque (2004) that the tractability of deduction and the expressiveness of the supporting lan- guage are tied by a trade-off: the more expressive is the language, and therefore its ability to leave things unspeciﬁed, the more intractable is deduction using this language. In machine learning the pioneering work on the covering test in ﬁrst-order logic (see Chapter 9) and the corresponding display of a phase transition phe-Expressiveness and phase transitions nomenon suggested that languages as expressive as ﬁrst-order logic were likely to be conducive to similar abrupt transitions in the covering test. This, in turn, is indicative of potential severe difﬁculties for learning concepts expressed using these languages. The covering test: random sampling in H 275 In the same way that in SAT we raised the question whether there is a bound- ary between the uneventful 2-SAT problem and the phase-transition-prone 3- SAT problem, the question whether there is some kind of threshold in the lan- guage expressiveness between zeroth-order logic (propositional logic) and ﬁrst- order logic was, and still is, open in machine learning. From in this perspective the study of automata learning seemed appropriate. Indeed, while grammars, and especially regular grammars, are less expressive than ﬁrst-order logic they are more expressive than propositional logic. Although language expressiveness is not just a one-dimensional property, it was felt that it might be illuminating to study the covering test in the case of automata learning. Should we then expect a phase transition in learning automata? No theoreti- cal argument then existed. Cornu´ejols, Pernot, and Sebag (Cornu´ejols and Sebag, 2008), examined the experimental evidence relating to regular grammars, that is, to ﬁnite automata. 11.4 The covering test: random sampling in H In order to check the evidence for a phase transition, the standard procedure is as follows. One deﬁnes control parameters that correspond to key characteristics of the learning problem and then studies, in the space deﬁned by these param- eters, the probability that hypotheses of the type controlled by the parameter values can satisfy the constraints of training sets controlled in the same way. The same overall procedure was used in the study of ﬁrst-order logic reported in Chapter 9. The goal here is to test whether there exists a sharp transition in the coverage of training samples controlled by certain parameters (e.g., the length ℓ of the strings) when the characteristics of the hypotheses (e.g., the number of states, average branching factors, and so on) are varied. The existence of such a sharp transition would be a strong indication that there exists some sort of discontinuity, in the “size” of the hypotheses (their cov- erage in the space of strings Σℓ), that is intrinsic to the representation language associated with ﬁnite automata. 11.4.1 The experimental protocol One key question is how to deﬁne a proper model for the random generation of automata and examples, in order to test the variations in the coverage of the automata (see the discussion on model RL in Chapter 9 for the case of relational learning). 276 Phase transitions in grammatical inference Following the methodology introduced by Giordana and Saitta (2000), the phase transition phenomenon was investigated by means of control parame-Control parameters ters chosen in accordance with the parameters used in the Abbadingo challenge (Lang et al., 1998):9 • the number Q of states in the deterministic ﬁnite state automaton; • the number B of output edges on each state; • the number L of letters on each edge; • the fraction a of accepting states, taken in (0, 1); • the size |Σ| of alphabet considered; • the length ℓ of the test examples and also the maximal length of the learn- ing examples in P (as explained below). The study ﬁrst focused on the intrinsic properties of the search space without regard to the learning algorithms, that is, without regard to the lattice structure induced by state-merging operations. Using the set of control parameters, the average coverage of automata was studied analytically and empirically. The sampling mechanism over the whole deterministic ﬁnite state au-The experimental protocol tomata (FSA) space was deﬁned as follows. Given the control parameter values (Q, B, L, a, |Σ|): • for every state q,(i) B output edges (q, q′) were created, where q′ was uni- formly selected with no replacement among the Q states; (ii) LB distinct letters were uniformly selected in Σ; and (iii) these letters were evenly distributed among the B edges above; • every state q was turned with probability a into an accepting state. The sampling mechanism for nondeterministic ﬁnite state automata differed from the above in a single respect: two edges with the same origin state were not required to carry distinct letters. For each setting of the control parameters, 100 independent problem in- stances were constructed. For each FSA considered (the sampling mechanisms are detailed below), the coverage rate was measured as the percentage of covered examples in 1000 examples (strings of length ℓ) uniformly sampled. 9The Abbadingo challenge was proposed in 1997 in order to stimulate and evaluate research on the induction of target DFA from sets of training strings labeled by that target concept and a set of unlabeled testing strings. Each problem was to be considered solved by the ﬁrst person to demonstrate a test-set error rate of 1% or less. The challenge comprised 16 benchmark problems of difﬁculty varying according to the size of the target concept (with 64, 128, 256, or 512 states) and the sparsity of the training data. The induction of target concepts with 128, 256, or 512 states remained unsolved for the case when the training data was lowest. The covering test: random sampling in H 277 1.0 0.4 0.2 0 1 1 0.8 0.6 0.4 0.2 0 1 2 Coverage NFADFA Coverage a a B B Figure 11.10 Coverage landscapes for deterministic and nondeterministic FSA, for |Σ| =2,L =1 and ℓ =10. The density of accepting states a varies in [0, 1]. The branching factor B varies in {1, 2} for the DFA and in {1, 4} for the NFA. 11.4.2 The ﬁndings Figure 11.10 shows the average coverage in the (a, B) plane, for |Σ| =2, L =1 and ℓ =10, where the accepting rate a varies in [0, 1] and the branching factor B varies in {1, 2}. Each point indicates the average coverage of a sample string s by an FSA (averaged over 100 FSA drawn with accepting rate a and branching factor B,testedon 1000 strings s of length ℓ). These empirical results are stated analytically in the simple equations below, which give the probability that a string of length ℓ is accepted by an FSA deﬁned on an alphabet of size |Σ|, with branching factor B and L letters on each edge, in the DFA and NFA cases (the number of states Q is irrelevant here). P (accept)= { a(BL/|Σ|)ℓ for a DFA, a[1 − (1 − L/|Σ|)B ]ℓ for a NFA. (11.1) The coverage of the FSA decreases as a and B decrease. The slope is more abrupt in the DFA case than in the NFA case; still, there is clearly no phase transition here. No phase transition according to this protocol While the reported results may seem too limited in their scope to warrant a deﬁnitive conclusion about the absence of a phase transition, in fact many more experiments with a wider range of parameter values all converge to- wards the same overall pattern of a gradually varying coverage probability. But the strongest argument comes from the analytical analysis and its near-perfect agreement with experimental measures. Clearly, there is no phase transition, with 278 Phase transitions in grammatical inference respect to the covering test, when one looks at uniform sampling in the whole space of ﬁnite automata. 11.5 Learning, hypothesis sampling, and phase transitions The coverage landscape displayed in Figure 11.10 might suggest that grammati- cal inference takes place in a well-behaved search space. However, grammatical inference algorithms do not explore the whole FSA space. Rather, as stated in Section 11.2, the search is restricted to the generalization cone,thesetofgen- eralizations of the preﬁx tree acceptor (PTA) formed from the set P of positive examples. The next step is thus to consider the search space actually explored by generic grammatical inference algorithms. 11.5.1 Evidence for abrupt changes when generalizing A new sampling mechanism was deﬁned to explore the DFA generalization cone.A new experimental protocol 1. A number |S +| (200 in the experiments) of examples of length ℓ were uniformly and independently sampled within the space of all strings of length ℓ (with varying ℓ), and the corresponding PTA was constructed. 2. A number N (50 in the experiments) of PTAs were constructed in this way. 3. A number K (20 in the experiments) of generalization paths, leading from each PTA to the most general FSA or the universal acceptor (UA), were constructed. In each generalization path (A0 = PTA(P); A1,...,At = UA), the ith FSA Ai was constructed from Ai−1 by merging two uni- formly selected states in Ai−1 and subsequently applying the determiniza- tion operator if needed. 4. The generalization-cone sample for each training set P was taken from all the FSAs in all the generated generalization paths (about 270 000 FSAs in the experiments). Regarding the NFA generalization problem, the sampling mechanism on the nondeterministic generalization cone differed from the above in a single respect: the determinization operator was never applied. Figure 11.11 (left) shows the behaviour of the coverage in the DFA gener- alization cone for |Σ| =4 and ℓ =8. Each DFA A is depicted as a point with coordinates (Q, c), where Q is the number of states of A and c is its coverage. Learning, hypothesis sampling, and phase transitions 279 100 80 60 40 20 0 100 80 60 40 20 0 0 0 100 200 300 400 500 600 700 200 400 600 800 1000 1200 Number of statesNumber of states GeneralizationCoverage rateCoverage rate Figure 11.11 (Left) Coverage landscape in the DFA generalization cone (|Σ| = 4, ℓ =8, |S +| = 200). At the far right lie the 50 PTA sampled, with about 1150 states each. The generalization cone of each PTA includes 1000 generalization paths leading from the PTA to the universal acceptor. Each point indicates the coverage of a DFA, evaluated over a sample of 1000 strings. The graph shows the existence of a large gap regarding both the number of states and the coverage of the DFAs that can be reached by generalization. (Right) Coverage landscape in the NFA generalization cone, with same control parameters as in the left-hand panel. The coverage rate for each FSA in the sample is evaluated from the coverage rate on 1000 test strings of length ℓ. Typical of all experimental results in the range of observation (|Σ| =2, 4, 8, 16,and ℓ =2, 4, 6, 8, 16, 17), the ﬁgure shows a clear-cut phase transition. Speciﬁcally, here, the coverage abruptly jumps from circa 13%to 54%, and this jump coincides with a gap in the number of states A phase-transition- like phenomenonof the DFAs in the generalization cone: no DFA with a number of states in the range [180, 420] was found. The gap becomes even more dramatic as the length of the training and test sequences ℓ is increased. Figure 11.11 (right) shows the behaviour of the coverage in the NFA gener- alisation cone, with |Σ| =4 and ℓ =16. Interestingly, a much smoother picture appears. Although the coverage rapidly increases when the number of states de- creases from 300 to 200, no gap can be seen either in the number of states or in the coverage rate itself. Further experiments with different values for the control parameters conﬁrm this general pattern (see Figure 11.12). All the curves obtained in this new setting, where the effective search space is sampled, show a markedly different behavior from that in Section 11.4.In 280 Phase transitions in grammatical inference Figure 11.12 Here, coverage landscapes were obtained from 1000 experiments using an alphabet size |Σ| =4, learning strings of length ℓ =16, and a training- set size |S+| = 100. (Left) DFA; (right) NFA. The test strings are increasingly long from top to bottom with values 4, 16,and 32. both the DFA and NFA cases, the covering rate varies rapidly at one point of the generalization process. This is all the more striking as the length of the strings in the training and test sets increases (see Figures 11.12 and 11.14). Furthermore, even without more precise experiments, a large qualitative difference between the DFA and NFA cases manifests itself. It is easy to suspect its cause. Learning, hypothesis sampling, and phase transitions 281 Merging Merging Determinization Figure 11.13 (Left) The lattice partition Lat(PTA(S+)) is searched using merging operations. (Right) In the DFA case, further merging operations to re- store determinization can cause jumps in the search space. At the top of each panel the universal algorithm (UA) is indicated. Indeed, the generalization trajectories differ in the two cases in one respect, and this difference might be the key for the large observed differences. While, in both cases, learning uses state-merging operations starting from the PTA, in the DFA case further merging operations can occur at each step in order to restore the determinism of the candidate automaton (see Figure 11.13, which shows the difference between the two search spaces). We will examine later on whether this dissimilarity can explain the different learning landscapes. First, we will look more closely at the induction of NFA. 11.5.2 The generalization landscape in the NFA case To get a more precise view of the evolution of the covering probability during the learning of a nondeterministic automaton (NFA), an extensive set of experiments were realized by Raymond Ros.10 In these experiments he varied the following parameters: Control parameters 10Raymond Ros was a Ph.D. student at L.R.I., University of Paris-Orsay, in 2005–6. 282 Phase transitions in grammatical inference • the size of the alphabet |Σ|∈{2, 4, 8}; • the length of the training and test strings ℓ ∈{[1,..., 8], [1,..., 16], 8, 16, 32}; • the size of the training set |P| ∈ {200, 500}; • the size of the test set T∈ {200, 500, 1000}. Again, the same pattern of an abrupt transition between hypotheses (au- tomata) with low coverage and hypotheses with high coverage was observed (see Figure 11.14). These curves exhibit increasingly steeper transitions as the length of the learning and test strings increases. One analysis that predicts this is given in Appendix B. It is not known whether it is a correct explanation but it is an intriguing one. However, this tendency is a minor concern compared with the general pattern. Indeed, when one thinks about it, all these data are quite extraordinary and go exactly contrary to what might have been expected.Seemingly a complete mystery In fact, grammatical inference sets itself apart in the ﬁeld of machine learn- ing. As stated in Chapter 5, a major lesson of the theoretical study of learning over the last 30 years is that a learning bias is required if one wants to perform in- duction. Without a bias that limits the expressiveness of the hypothesis space, or more formally its capacity, one loosens the link between the empirical risk mea- sured on the training set and the expected risk. Therefore, learning can no longer be guided and the hypotheses obtained are likely to perform almost randomly on the unseen examples. Because of this phenomenon, known as overﬁtting, there is a focus in machine learning on carefully controlling the so-called capacity or ex- pressiveness of the hypothesis space, a problem also known as model selection. Margin-based learning methods, much in fashion nowadays, are a prominent ex- ample of new methods that seek to control capacity automatically. Yet there exists no such representation bias in the case of the induction of reg- ular languages. Regular languages are learned through exploration of the space of ﬁnite automata, and every regular language can be represented by at least one automaton. Furthermore, the exploration operator, by state-merging, is complete in the sense that, starting from the preﬁx tree acceptor PTA(P), every general- ization of the set of positive examples can be attained by a (well-chosen) succes- sion of state merges. In formal terms, the capacity of the hypothesis language is inﬁnite and the exploration operator apriori does not limit the effective search space. Therefore, if learning can succeed at all, its success must be explained on other grounds. If one now turns to the characterization of the hypothesis space by the cov- erage rate of its elements, a further mystery is lurking around the corner.. . . and even more so! 100 80 60 40 20 0 100 80 60 40 20 0 100 80 60 40 20 0 0 0 500 0 1000 2000 3000 4000 5000 6000 1000 1500 #States #States #States 2000 2500 200 400 600 800 Figure 11.14 The coverage landscapes were obtained with the following con- trol parameter values: |P| = 200, alphabet size |Σ| =4,and ℓ uniformly ∈ [1,..., 8], [1,..., 16], [1,..., 32], respectively, from top to bottom. The size of the preﬁx tree acceptor PTA(P) correspondingly grows from approximately 800 states to approximately 2400 states and ﬁnally to approximately 5600 states. Each ﬁgure represents 10 learning trajectories, obtained starting with the same PTA(P). 284 Phase transitions in grammatical inference Number of hypotheses 1 0 Coverage rate Figure 11.15 The coverage rate of the regular languages with respect to the strings of a given length ℓ. Since the hypothesis space has no bias, every partition of the space of strings (i.e., |Σℓ| for a given maximal length ℓ) can be represented. The number of par- titions that cover n examples (strings) is equal to ( |Σ ℓ| n ). Therefore, the over- whelming majority of these partitions (languages) cover approximately |Σℓ|/2 examples. In consequence, a graph of the coverage rate of the elements of the language space should look like Figure 11.15, if one measures the coverage with respect to strings of length ℓ. If one looks at the space of all generalizations of an automaton representing a preﬁx tree acceptor PTA(P) (a generalization cone), the pattern is the same; almost all possible hypotheses cover approximately half the unseen examples. Now, since the state-merging operator allows a full exploration of the gener- alization cone, one would expect that randomly sampled possible generalization trajectories would predominantly explore languages with a coverage rate close to 1/2. The experiments tell a completely different story. The learning trajectories ﬁrst stay for a long time in the region of languages that cover a small fraction of all possible strings and then suddenly jump upward, rapidly crossing the re- gion of intermediate coverage, before leveling off in the region of languages that accept almost all strings. This surprising behavior points to special properties of the merging oper- ations. At one point in the exploration, a few state merges sufﬁce to change radically the coverage rate of the generated automata. One must realize that, even though this closely resembles the behavior de- scribed in Chapters 9 and 10, the reason behind it is quite different. In the case of inductive logic programming (ILP) the phase transition be- havior is intrinsic to the representation language. When sampled uniformly withTowards solving the mystery respect to the four control parameters, there is a very narrow, vanishingly small, region with hypotheses of intermediate coverage. This has nothing to do with the learning algorithms. By contrast, in grammatical inference, because there is no apriori representation bias, most potential hypotheses cover approximately half all possible strings. However, it is the generalization operator which induces an Learning, hypothesis sampling, and phase transitions 285 abrupt change in the coverage rate of the hypotheses generated during learning and a fast crossing of the region where most potential hypotheses lie. In grammatical inference, the phase transition is a property of the learning approach, not of the space of hypotheses. This fact is even more striking in the case of DFA learning. 11.5.3 The generalization landscape in the DFA case In the NFA case we have seen that, the generalization cone starting from a learn- ing sample is explored by successive generalization steps, i.e., state merging. The coverage rate always undergoes a sharp transition between a regime where the induced automata cover a very small fraction of random test strings and a regime where they cover a large fraction of them. The ﬁrst experiments reported in Section 11.5.1 clearly indicate that even though an abrupt transition occurs also in the case of the inference of DFA, it is of a different nature. Speciﬁcally, a gap appears between the automata with low coverage rate that are produced ﬁrst and automata of high coverage rate that are encountered later in the generalization process. It is of interest to look again at the Abbadingo challenge presented in Section 11.4.1. One challenge regarding the induction of DFA involved a target automata of 128 states with a “sparse” learning set of |P| = 4382 strings deﬁned over an alphabet of size |Σ| =2. The strings had an average length ℓ =17. This prob- lem remained unsolved during the competition. A look at the variations in the coverage rate in the generalization cone may explain part of the reason for this (see Figure 11.16). As is strikingly apparent, no DFA of coverage rate between almost 0% and 95% is ever considered. And this curve is one among hundreds that exhibit the same pattern. If, indeed, this curve represents the behavior of the learning algorithms, then it is no wonder that induction fails in this case. A set of experiments was therefore aimed at a better characterization of this phenomenon in the DFA case. It is noticeable that the same shape was found for the variation in the cover- age rate in a large variety of situations (see Figures 11.12, 11.16, 11.17–11.19). It is therefore of a generic nature, i.e., independent of the size |Σ| of the alphabet, the length of the learning and test strings, or the size of the training set. Since this shape exhibits a large gap in the coverage of the automata that are considered in the generalization cone, serious consequences can be expected for the learning algorithms. It is therefore important to understand the reasons for this typical behavior. We start by examining some parameters associated with the dynamics of the Why is there a gap? generalization process. An important characteristic associated with graphs and 286 Phase transitions in grammatical inference 0 20 40 60 80 100 0 5000 10 000 15 000 20 000 25 000 30 000Covering rate (%) Number of states Figure 11.16 Induction of a DFA in the conditions of the Abbadingo challenge. The alphabet size |Σ| =2, the average length of the strings ℓ =17,andthe target automaton has 128 states and is used to label the 4382 learning strings. The preﬁx tree acceptor in this case comprised approximately 27 000 states. with ﬁnite state automata in particular is the ratio of the number of exit edges and the number of (non-terminal) states. We would expect it to increase as states are merged since at each time the resulting merged state inherits at least as many edges as the more connected parent state. Indeed, this is what is observed ex- perimentally. For instance, Figure 11.18, obtained for an alphabet size |Σ| =4, a training set size |P| = 500, and strings of length ℓ ∈ (1,..., 8),shows a gradual increase in the ratio #edges/#states. In the PTA the ratio is close to 1 since the automaton essentially consists of sequences of states associ- ated with each training string. This is especially true when the training set is sparse in the space of all possible training strings. Then, for instance, the space of strings of length ℓ ∈ (1,..., 8) deﬁned over an alphabet of size 4 is of size 8∑ i=1 4i = 4(48 − 1) 4 − 1 = 87 380. A learning set of size 500 is therefore sparse. The surprising fact is that there is no great jump in the ratio when the gap in the learning trajectories is crossed. In Figure 11.18, it goes from a value ≈ 1.6 to a value ≈ 2. Only then does it sharply increase, during the last generalization operations. Learning, hypothesis sampling, and phase transitions 287 100 100 80 60 40 20 0 0 2000 4000 6000 8000 10000 12000 14000 80 60 40Covering rate (%)Covering rate (%) 20 0 0 400 800 Number of states Number of states 1200 1600 Figure 11.17 Variation in the coverage rate when random samples of automata are taken within the generalization cone from the DFA. Here the alphabet size |Σ| =4 and the learning set size |P| = 500. In both ﬁgures the proﬁle is made up of eight generalization processes, in the top panel with strings of length ℓ ∈ (1,..., 8) and in the bottom panel with strings of length ℓ ∈ (1,..., 32). Another key parameter is the ratio of the number of accepting states and the total number of states. Since each time an accepting state is merged with another state the resulting state is accepting as well, one would expect this ratio to in- crease during the generalization process. However, experiments tell a completely different story (see Figure 11.19). Whereas the ratio does indeed gradually in- crease during the ﬁrst part of the generalization, before the gap, it jumps back to almost 0 after the gap. How should we to understand this? 288 Phase transitions in grammatical inference 4 3 2 1 0 400 800 1200 Number of states 1600 Figure 11.18 Evolution of the ratio of the number of exit edges and the number of (non-terminal) states. Here, the alphabet size is |Σ| =4, the training set size is |P| = 500 and the strings have length ℓ ∈ (1,..., 8). The curve results from the aggregation of eight generalization trajectories. One explanation would be that a small number of accepting states is involved in all the state-merging operations. In order to test this hypothesis, a lengthy visual study of the evolution of the automata was undertaken. An example of an automaton after the gap is given in Figure 11.20. The states have an array proportional to their connectivity. One can see that one terminal and accepting state has attracted most links. Therefore, the ratio of accepting states and the total number of states remains low and can even decrease dramatically. One fact that differentiates DFA induction from NFA induction is that, in the former, after each state-merging operation other such operations may be neces- sary to restore the deterministic character of the automaton. This is illustrated in Figure 11.21. It is then natural to examine how many of these determinization operations are carried at each step in a generalization trajectory. In Figure 11.22,the y-axis reports the number of states merging for deter- minization after each generalization step starting, as usual, from the PTA. Again, this ﬁgure is a compound proﬁle with eight individual learning trajectories. The pattern is always the same. Up to the threshold of the gap, the number of deter- minization operations is very low, limited to less than 10 except in two cases, one where an “eruption” of approximately 100 operations occurs on one trajec- tory and another where approximately 160 operations occur on another trajec- tory. However, at the verge of the gap, for all trajectories there occurs a sudden Learning, hypothesis sampling, and phase transitions 289 1.0 0.8 0.6 0.4 0.2 0 1.0 0.8 0.6 0.4 0.2 0 0 500 1000 Number of states Number of states 1500 2000 2500 0 200 400 600 800 Figure 11.19 Evolution of the ratio of the number of accepting states and the total number of states. Here, the alphabet size |Σ| =4 and the training set size |P| = 200. The curves result from the agglomeration of eight curves. In the upper panel the strings are of length ℓ ∈ (1,..., 8). In the lower panel the strings are of length ℓ ∈ (1,..., 16). very large cascade of determinization operations of sizes, in these cases, between 1200 and 1500 operations. This is what explains the gap in the exploration of DFA by generalization from the PTA. After the gap, again each generalization operation entails very few determinization operations. Given the apparently universal character of this singular pattern, it is im- portant to look at models that could predict it. At the elementary level, a Attempt at a theoretical model 290 Phase transitions in grammatical inference Figure 11.20 An example of an automaton just after the gap in the general- ization trajectory has been crossed. One terminal state has attracted most of the links. determinization merging takes place whenever two states are merged that have at least one output link with the same letter (see Figure 11.21, where the merged states share “a” as an output letter). Indeed, in this case the output of the state is no longer determined if a letter is given. This, in turn, entails other state-merging operations further down on the states reached by the same letter. The expected number of state-merging operations E[merges] can be computed from a chain- reaction-like model: E[merges]=1 + E[merges] ⎛ ⎝ |Σ|∑ i=1 P(k = i) · i ⎞ ⎠ (11.2) where P(k = l) is the probability that a state-merging operation provokes an intersection of size i of the output letters for the two merged states. The expected number E[merges] diverges when ∑|Σ| i=1 P(k = i) · i> 1. Learning, hypothesis sampling, and phase transitions 291 a b b b a a b b a a b b b a a b b a a b b b a a b b a a b b b a b b a Figure 11.21 Starting from the learning sample S = {⟨a, b, c⟩, ⟨a, b, a, a⟩, ⟨a, b, a, b⟩, ⟨b, b, a⟩}, the preﬁx tree acceptor (top automaton) is built. Then, a pair of states is chosen for merging (shaded oval). This leads to the third automa- ton from the top. This automaton being non-deterministic, another state-merging operation is carried out to restore the deterministic character of the automaton (bottom). This model is crude in the sense that it assumes that the state-merging op- erations are independent. As it is, it does not take into account the distribution of the letters and of the different states with respect to their output connectivity. However, it is easy to turn this simple model into a simulation tool where one starts by providing the relative proportion of states with 0, 1, 2,... output links and then running the simulation. That was done, for instance, for the case of the Abbadingo challenge already encountered in Figure 11.16. There, the alphabet size is |Σ| =2, the average length of the strings is ℓ =17, the target automaton has 128 states and is used to label the 4382 learning strings. The preﬁx tree acceptor in this case com- prised approximately 27 000 states. The onset of the gap occurs when the con- sidered automaton has approximately 16 200 states, that is, after approximately 8800 state-merging operations. This is to be compared with the prediction of the model, which is that a divergence in the expected number of state-merging operations should arise after 11 716 state-merging operations. 292 Phase transitions in grammatical inference 1600 1200 800 400 0 0 500 1000 1500 2000 2500 Figure 11.22 The number of states of the DFA that are produced during an exploration by generalization from the PTA (going from right to left) is plotted along the x-axis. The number of state-merging operations required to restore the deterministic character of the new candidate automaton after each generalization step is plotted along the y-axis. One large cascade of state-merging operations occurs at the verge of the gap. The prediction is in error by only 33%. Given the simplifying assumptionsA quite remarkably precise prediction that underly the model, the agreement with the actual value is quite remarkable. The existence of a gap in the coverage rate of the candidate DFA generated by a generalization process from the PTA can thus be explained in terms of a chain-reaction-like phenomenon. At one point, one more state-merging opera- tion leads to a state of the system, i.e., the current candidate automaton, that cannot be made deterministic without a very large number of determinization operations. This effectively renders the generalization process blind to a whole region of the generalization space, since it cannot stop generalizing in this region. In other words, there is a long sequence of generalization steps, each producing an NFA, before a DFA is obtained. This, in effect, means that learning meth- ods based on state-merging operations are unable to produce a DFA in a whole region of the generalization space. In the next section we study the consequences of the performances of these learning algorithms. Are these generalization performances really as bad as might be expected from the proﬁle of the coverage rate during generalization? In the following, we focus on the induction of DFAs. Consequences of the behavior of the learning algorithms: how bad is it? 293 State-merging operation No more necessary merging At least one more merging operation At least two more merging operations At least a more merging operations k = 0 k = 1 k = 2 k = a a Figure 11.23 When two states are merged they can have 0, 1, 2 or more out- put letters in common (k = i). Depending on the size k of this intersection, 0, 1, 2 or more further determinization mergings must take place. This can lead to a diverging chain reaction of state-merging operations, each new operation potentially leading to more. 11.6 Consequences of the behavior of the learning algorithms: how bad is it? The coverage landscape, for the DFAs, shows a hole in the generalization cone: for a large coverage range, the density of hypotheses falls abruptly. Therefore, a random exploration of the generalization cone would face severe difﬁculties in ﬁnding a hypothesis in this region and would be likely to return hypotheses of poor performance if the target grammar had a coverage rate in this “no man’s land” interval. However, the existing learning algorithms do not merge states at Does the phase-transition-like phenomenon actually hamper learning? random when generalizing. Do their control strategies protect them against the avalanche phenomenon and allow them somehow to explore the “gap”? Another concern is related to what has been observed in inductive logic pro- gramming, namely a discrepancy between the target concept and the learned hypotheses. In the case of the induction of ﬁnite state automata, a ﬁrst and easy measure of such discrepancies is the difference in the coverage rate of the target automaton and the learned one. For instance, given a target automaton with cov- erage lying in the gap (e.g., 50%), are the learning algorithms able to probe the associated region of hypotheses having same range of coverage rate and to re- turn a hypothesis in this region? In other words, are they able to guide the search toward hypotheses of appropriate coverage rate, especially if this coverage falls in the gap? 294 Phase transitions in grammatical inference The performances of two standard algorithms in grammatical inference, namely the RPNI and the RED–BLUE (on EDSM) algorithms (Oncina and Garc´ıa, 1992; Lang et al., 1998) have thus been studied. We ﬁrst report the ex- periments and their outcome. We then look at the control strategies used by these algorithms. 11.6.1 Experimental setting The experiments reported in Section 11.5 were for training sets made of positive- only string sequences. Since the focus was on the generalization cone based on the PTA, there was no need to consider negative instances. However, in order to assess the performance of a learning algorithm, the learned hypothesis must be compared with the target automaton. Therefore, an- other experimental setting is used in this section: the sampling of target automata and the construction of training and test sets. These data sets include positive and negative examples, as most grammatical inference algorithms (and speciﬁcally RPNI and RED–BLUE) use negative examples as a means of stopping the gener- alization process. The ﬁrst experiments tested whether heuristically guided inference algo- rithms can ﬁnd good approximations of target automata when these automata have a coverage rate falling in the gap and when they have the low coverage rate typical of many applications. Thus, target automata with (i) an approximately 50% coverage rate (as in the inﬂuential Abbadingo challenge and in the middle of the “gap”) and (ii) with a 3% coverage rate were considered. For each target coverage rate, the same experimental setting as that described in Lang et al. (1998) was used in order to retain a certain number of target au- tomata with a mean size of Q states (Q =50, in these experiments). Then, for each automaton, N =20 training sets of size |SL| = 100, labeled according to the target automaton, were generated, with an equal number of positive and negative instances (|P| = |N | =50) of length ℓ =14. The coverage rate was computed as before on 1000 uniformly chosen strings having no intersection with the training set. 11.6.2 The coverage rates of the target and learned automata Let us ﬁrst compare the coverage rate of the learned automata with the coverage rate of the target automata. In the ﬁrst set of experiments, target automata were generated having a cover- age rate close to 56%. Only the graph obtained for the RPNI algorithm is shown here (see Figure 11.24), with three typical learning trajectories. Similar results were obtained with the RED–BLUE algorithm. Consequences of the behavior of the learning algorithms: how bad is it? 295 0 20 40 60 80 100 0 100 200 300 400Coverage rate Number of states 0 20 40 60 80 100 0 100 200 300 400Coverage rate Number of states Figure 11.24 (Left) Three RPNI learning trajectories for a target automaton of coverage 56%. Their extremity is outlined in the light gray oval on the left. The broken horizontal line corresponds to the target automaton coverage. The cloud of points corresponds to random trajectories. (Right) Same as the left-hand panel except for the coverage of the target automaton, here 3%. One immediate ﬁnding is that both the RPNI and the EDSM heuristics man- age to probe the “gap”. The three learning trajectories obtained using the RPNI algorithm show that candidate automata of all coverage rates are generated up to approximately 40% coverage rate. This contrasts with the learning trajectories produced from the same preﬁx tree acceptors when the state-merging operations are random; here again, a wide gap appears. This may explain why the gap phenomenon was not discovered before, and why the RED–BLUE algorithm, for instance, could solve some cases of the Ab- badingo challenge where the target automata have a coverage rate of approx- imately 50%. The RPNI algorithm, however, tends to overspecialize the target automaton by returning learned automata with coverage in the range (35%, 45%) when the target automata have 56% coverage rate. Conversely, experiments show that RED–BLUE tends to overgeneralize by 5% to 10%. A second set of experiments was carried out in which the target automata had a coverage rate of approximately 3%. The results (Figure 11.24) show that, in this case, RPNI ends up with automata of coverage 4–6 times greater than the target coverage. The effect is even more pronounced with RED–BLUE,which returns automata having an average coverage rate around 30%! These results are unexpected, since low-coverage automata seem to be much more densely probed than medium-coverage ones. An explanation is needed. But before looking for it, we will examine further the generalization performances of learned automata in this low-coverage regime. 296 Phase transitions in grammatical inference 11.6.3 Generalization error A set of experiments analyzed the learning performances of the algorithms with respect to test errors, differentiating the false positives and the false negatives. In these experiments, the type of target automaton was chosen by setting the number of states Q and some predetermined structural properties, as follows. Deterministic target automata were generated along four parameters: • the size |Σ| of the alphabet; • the number of states |Q|; • the density of the connections; • the level Trec of recursivity of the connections. More precisely, for each generated target automaton a tree of |Q| states was ﬁrst built randomly. At this stage, the density of connection is minimal, with value 1.Then density ×|Q|(|Σ|− 1) transitions are added, of which a number Trec create cycles. The leaves of the tree are taken as accepting states, and the remaining states are labeled as accepting with a probability of 20%. A whole set of experiments was carried out by varying the four control pa- rameters. We report here one typical ﬁnding where the number of states of the target automaton is the key parameter. In these experiments, |Σ| =4, Trec = 50%, density = 50%. Moreover, the learning set consisted of 1000 strings of length ℓ ∈ (1, (2 × depth)),where depth is the depth of the target automaton (the maximal depth of the initial tree). It is useful to measure the degree of structural completeness achieved by the learning set, that is, the proportion of all transitions of the target automa- ton that are excited by the learning strings. The following results were obtained for training sets of structural completeness Prct ≥ 40%.The uniform cover- age rates ucovt and ucovf were estimated using 1000 test strings of length ℓ ∈ (1, (2 × depth)) that were not used in the training set. The positive cov- erage rate pcovf (the negative coverage rate ncovf ) is estimated using a sample of 1000 test strings labeled as positive (as negative). The numbers in Table 11.1 were obtained by repeating each experiment 100 times for each setting of the control parameters. Table 11.1, obtained for different sizes of the target automaton and for train- ing sets of structural completeness above 40%, conﬁrms that both RPNI and RED–BLUE return overgeneralized automata. Indeed, what is remarkable is that this overgeneralization does not imply that the learned automata are complete: on the contrary, the coverage of the positive examples remains below 65% in all but one setting. On the one hand their aver- age coverage is vastly greater than the coverage of the target automaton; on the Consequences of the behavior of the learning algorithms: how bad is it? 297 Table 11.1 Performances of the algorithms RED–BLUE (RB) and RPNI for target DFA of sizes Q =15, 25, 50,and 100 states and of (low) coverage rate ucovt. The learned automata are characterized by Qf , ucovf , pcovf ,and ncovf , which respectively denote their average size, their average coverage, the true positive rate, and the false positive rate. Algorithm Qucovt Qf ucovf pcovf ncovf RB 15 5.97 10.38 33.81 60.93 34.69 RB 25 4.88 12.77 40.35 62.68 37.87 RB 50 4.20 14.23 45.38 66.14 42.23 RB 100 3.39 13.13 30.35 42.81 28.69 RPNI 15 5.95 5.14 22.90 57.51 26.99 RPNI 25 4.70 7.56 23.07 56.38 25.98 RPNI 50 3.87 14.08 23.45 51.89 24.42 RPNI 100 3.12 26.41 23.15 50.12 24.40 other hand they tend to cover only part of the positive test instances while they cover a signiﬁcant proportion of the negative test instances. Both precision and recall are therefore poor. This shows that the heuristics used in both RPNI and A poor performance in the case of targets with low coverage RED–BLUE may be inadequate for target automata of low coverage. It is time to examine these heuristics and why they can lead to such results. 11.6.4 The control strategies and their impact The RPNI (regular positive and negative grammatical inference) algorithm, (Oncina and Garc´ıa, 1992), starts by building the preﬁx tree acceptor (PTA) from the positive instances of the training set. The algorithm then iteratively selects pairs of states that could be merged, checks whether a candidate-merge would yield an automaton that covers at least one negative instance, and makes the merge if it is admissible. The choice of a pair of states to merge is made sys- tematically and does not depend on the current situation of the search. When the PTA is built, its states are given labels {q1,q2,..., } starting from the root and increasing in a breath-ﬁrst manner. The RPNI algorithm considers pairs of can- didate states according to their lexicographic order, that is, it favors merges that are close to the root of the current automaton. If one looks at the size of the generalization steps that this heuristic entails, one can see that merges of pairs of states close to the root lead to larger gen- eralization steps than merges of pairs of far-away states. Furthermore, RPNI is subject to an “avalanche” of determinization operations. 298 Phase transitions in grammatical inference The heuristic developed for the Red–Blue algorithm, called EDSM (evidence driven state merging), by contrast chooses at each step the pair of states that will entail the largest number of determinization operations. The mean generalization step is therefore generally higher than for RPNI. However, it is less prone to the avalanche phenomenon. This last quality may also explain its tendency to overgeneralization. Indeed, in the case of the RPNI algorithm, during the last steps of the gener- alization process most attempted merges are pruned because they would lead to an avalanche of further merging operations and therefore to the covering of neg- ative instances. Consequently, the generalization process stops short of too much overgeneralization. This is conﬁrmed by the experimental results. The Red–Blue algorithm, however, can apply generalization steps further away before the gen- eralization process stops. At least in the case of target automata having small coverage rates, this unfortunately steers the learning towards hypotheses of much larger coverage, that is, to high rates of false positive predictions. 11.7 Comments We now compare and contrast the cases of learning in ﬁrst-order logic and in grammatical inference. In the former the phase-transition-like phenomenon is in- herent in the language representation: when hypotheses and examples are drawn randomly according to a uniform distribution within the space of the control parameters, an abrupt transition is observed between a region where the hy- potheses cover almost all examples and a region where almost no examples are covered. When the same kind of experiment is carried out in grammatical inference, looking at the probability that random automata recognize random strings, no such sudden transition is observed. The average branching factor of the states, i.e., the average number of output links, plays a larger role in the probability of coverage but, overall, the coverage rate exhibits a well-behaved gradient that should perfectly inform the learning algorithms. However, when the modus operandi of the most prevalent learning systems are taken into account, the ﬁndings are quite different. When the exploration of the hypothesis space starts from the preﬁx tree acceptor and proceeds by the merging of states in the candidate automaton then, again, a very steep transition appears between the beginning of the search where candidate automata cover almost no test strings and the region reached later where almost every test string is covered. Actually, the phenomenon is even more dramatic with the induction of DFAs since then an actual gap usually appears between the two regions. Comments 299 In grammatical inference, therefore, the phase transition phenomenon is not inherent in the language representation: rather, it is due to the generalization A phase transition due to the learning algorithm, not the representation language. process used in learning. Somehow the state-merging operations used for gen- eralization radically increase the gradient in the coverage of the automata that are considered. In addition, as was seen in the case of DFA induction, a further phenomenon occurs: an avalanche of state-merging operations needed to ensure that candidate automata are deterministic. The nature of the phase transition in grammatical inference is therefore dif- ferent from that encountered in ﬁrst-order-logic learning. It is a property of the learning algorithm rather than a property of the representation language. Moreover, whereas the covering test is NP–complete in ﬁrst order logic, it is of linear complexity in the case of grammatical inference. Consequently, one does not observe an increase in the search cost around the phase transition. Grammatical inference does not truly belong to the same class of problems as SAT or relational-concept learning and thus does not have the same kind of phase transition. But, in a strange way, the phase transition exhibited in DFA is a nice example of a physical-like process with a chain reaction mechanism. In some respects, then, it is a proper example of a phase transition. 12 Phase transitions in complex systems Contents 12.1 Complex systems 301 12.2 Statistical physics and the social sciences 304 12.3 Communication and computation networks 309 12.4 Biological networks 310 12.5 Comments 311 Even though this book is focused on learning, we thought it might be useful to widen its scope to include a brief overview of the emergence of ensemble phe- nomena (typically phase transitions) in complex networks. Beside their intrinsic interest as systems amenable to be studied via statistical physics methods, com- plex networks may well impact relational learning because both examples and formulas can be represented as networks of tuples, as we have seen in previous chapters. The same can be said for the constraint graph in CSP and the factor graph in SAT. In ensemble phenomena, emerging from a network of “micro- scopic” interactions, it is likely that the underlying graph structure has an impact on the observed macroscopic properties; thus cross-fertilization might be of mu- tual beneﬁt. Complex networks are complex systems, meaning systems composed of a large number of mutually interacting components. Even though in such systems it is impossible to describe the behavior of the individual components, the pat- terns of interactions among them allows macroscopic properties to emerge which would be missed by a reductionist approach. Thus, the science of complexity 300 Complex systems 301 aims to discover the nature of these emerging behaviors and to link them to the system’s microscopic level description. 12.1 Complex systems From its very deﬁnition, it is clear that the science of complexity naturally de- rives from statistical physics. Thus, the emergence of phase transitions and the behavior of complex systems have strong links. In fact, both derive their proper- ties from the effects of the interaction patterns among many small components, and both have at their core the notion of graphs or networks. The nodes of such a network constitute an ensemble of elements, whose interactions let the network’s macroscopic behavior emerge. In Chapter 3 we introduced the notion of graphs and mentioned the best known classes investigated in mathematics and the most common structures oc- curring in the real world. As mentioned in that chapter, a ﬁrst hint as to the ex- istence of phase transitions in graphs was provided by Erd¨os and Renyi (1959), who discovered what amounted to a phase transition in the connectivity during the process of generating a random graph from the Gn,p ensemble. Later, the emergence of phase transitions in complex networks was investi- gated systematically. An overview of early results was given by Newman (2003). Several authors have studied spin models, such as the Ising model, on networks of various kinds, for example random graphs (Dorogovtsev et al., 2002; Leone et al., 2002), small-world networks (Barrat and Weigt, 2000; Pelalski, 2000; Herrero, 2002), and Barab`asi–Albert networks (Aleksiejuk et al., 2002). The question behind this body of work is whether (and how) graph structures that are not random affect the emergence and location of the phase transition. For instance, Walsh (1999) looked at colorability in Watts–Strogatz small-world graphs; he found that these graphs are easily colorable for both small and large values of the shortcut density parameter p but that they are harder to color in in- termediate regimes. V`azquez and Weigt (2003) examined the vertex cover prob- lem, and found that on generalized random graphs solutions are harder to ﬁnd for networks with stronger degree correlations. Given the links between complex networks and statistical physics, there is no wonder that methods borrowed from the latter are used to investigate prop- erties of the former. For instance, the continuum theories proposed to predict the degree distribution can be mapped, often exactly, onto some well-known problems investigated in statistical physics. Two such cases are the mapping between evolving networks and Simon’s model (Simon, 1955), on the one hand, and the equilibrium Bose–Einstein gas (Park and Newman, 2004), on the other. 302 Phase transitions in complex systems Park and Newman (2004) proposed a method for generating networks that match the expected properties of a graph ensemble, given a set of measurements made on a real-world network. As for the Boltzmann distribution in statistical mechanics, these models offer the best prediction of properties subject to the constraints imposed by a given set of observations. Using exponential random graphs, Park and Newman provided for models in this class exact solutions that show arbitrary degree distributions and arbitrary but independent edge proba- bilities. They also discussed more complex examples with correlated edges; for these cases approximate or exact solutions can be found by adapting various methods from statistical physics. An interesting approach was proposed by Biely and Thurner (2006). They used a microscopic Hamiltonian derived from the socio-economically motivated assumption that individual nodes increase or decrease their utility by linking to nodes with respectively a higher or lower degree than their own. Utility is an equivalent of energy in physical systems. Nodes tend to maximize utility as physical particles minimize energy. From the study of the temperature depen- dence of the emerging networks, the existence of a critical temperature Tcr was observed, at which total energy (utility) and network architecture undergo rad- ical changes. At this topological transition a scale-free network, with complex hierarchical topology, is obtained. Another approach explicitly based on statistical physics was proposed by Vicsek (2007). He investigated topological transitions in the restructuring of net- works. In his approach energy is associated with the different network topologies and temperature is used as a measure of the noise level during rewiring of the edges. A variety of topological phase transitions emerges when the temperature is varied. These transitions denote changes in the essential features of the global structure. Then Vicsek addressed the question of network structure modularity. The global organization can be viewed as the coexistence of structural commu- nities, associated with highly interconnected parts. The approach he proposed allows one to analyze the main statistical features of the interwoven sets of over- lapping communities, so making a step towards the uncovering of the modular structure of complex systems. The approach is based on deﬁning communities as clusters of percolating complete subgraphs called k-cliques. A set of new char- acteristic quantities is deﬁned for the statistics of the communities, and an efﬁ- cient technique is applied to explore overlapping communities on a large scale. Signiﬁcant overlappings among communities were detected, and some universal features of networks uncovered. A key concept in complex systems, as well as in statistical physics, is that of order. Several types of phase transition, occurring in a variety of ﬁelds, concernOrder and disorder a transition between ordered and disordered states. Different statistical mechan- ics tools have been devised to describe the different levels of organization of Complex systems 303 networks and to measure their degree of order. Among the different measures used with this aim, entropy (as a measure of disorder) holds a prominent place. In a recent paper, Bianconi (2009) deﬁned and characterized the notion of struc- tural entropy, i.e., the entropy of ensembles of undirected, uncorrelated, sim- ple networks with given degree sequence. She pointed out the apparent paradox that scale-free degree distributions are characterized by having a small struc- tural entropy even though they are frequently encountered in the real world. She explains this ﬁnding by noticing that scale-free networks correspond to the most likely degree distribution given the corresponding value of the structural entropy. Random Boolean networks have been recently investigated by Andrecut and Random Boolean networksKauffman (2010). These networks are non-linear and show a well-understood transition between ordered and disordered phases. The authors studied their com- plex dynamics as a function of the connectivity k between the elements of the network. They have uncovered an order-chaos phase transition for a critical con- nectivity kcr =2; moreover, pairwise correlation and complexity measures are maximized in dynamically critical networks. Their results are in good agreement with the previously reported studies on random Boolean networks and random threshold networks. A phase transition corresponding to explosive percolation has been found by Percolation Friedman and Nishimura (2010) in several models of random networks, widely applicable to physical, biological, and social networks. In such networks giant clusters appear (essentially) without warning, phenomenon that may have im- portant implications in several ﬁelds. Finally, Komin and Toral (2010) have used ideas from statistical physics to reduce large systems of coupled differential equations with diverse parameters to three equations, one for the global mean ﬁeld variable and two describing the ﬂuctuations around this mean value. With this tool they analyzed phase tran- sitions induced by microscopic disorder in three prototypical models of phase transitions, which have been studied previously in the presence of thermal noise. Macroscopic order is induced or destroyed by time-independent local disorder. A ﬁnite-size analysis of the numerical results allows the calculation of the corre- sponding critical exponents. Transitions in networks from a small-world structure to a fractal structure Small-world networkshave been investigated by Rozenfeld et al. (2010). By using the renormalization group they showed that network topologies can be classiﬁed into universality classes in the conﬁguration space. Moreover, they found a trivial stable ﬁxed point of a complete graph, a non-trivial point of a pure fractal topology (stable or unstable according to the amount of long-range links in the network), and another stable point of a fractal with shortcuts that exist exactly at the small- world to fractal transition. In addition, they were able to explain the coexistence 304 Phase transitions in complex systems of fractal and small-world phases and to extract information on the distribution of shortcuts in real-world networks. 12.2 Statistical physics and the social sciences Complex networks have found an increasing number of applications in the so- cial sciences, where both classical and statistical mechanical methods have been applied to investigate their properties. A comprehensive overview of statistical mechanics methods used to model and study social systems was provided by Castellano et al. (2009). These authors worked on opinion formation, cultural dy- namics, collective behaviors, and the coevolution of topology. Social networks, notwithstanding the limited number of interactions that people may have, show remarkable ensemble behaviors, such as transitions from disorder to order. An example of this is the spontaneous formation of a common language/culture. There are also cases of scaling and universality. The idea of modeling social phenomena using physics tools is not new, as it was already present in the thought of philosophers such as Laplace and Comte. However, only in the past few years has the idea moved from a philosophical possibility to concrete research involving many physicists. This was motivated, on the one hand, by the availability of large networks for study and, on the other, by new social phenomena (mostly related to the Internet) observable on a large scale. As Castellano et al. (2009) noticed, a conceptual difﬁculty immediately arises when one is approaching social dynamics from the point of view of statis-Social dynamics tical physics. In fact, in physics, elementary constituents of complex systems are simple objects whose behavior is well known. Thus, the observed macroscopic phenomena derive substantially from the complexity of the interaction and not from the complexity of the constituents. With humans, modeling involves strong simpliﬁcations that are not always well grounded; any investigation of models of social dynamics involves an additional difﬁculty, namely the very deﬁnition of realistic microscopic models of the entities involved (humans, in particular). However, many macroscopic properties do not depend on the details of the com- ponent processes, and qualitative results at least can be obtained that match the observed reality. Hence, in many cases it is sufﬁcient to include in the model only the basic properties necessary to describe an individual behavior. As a general ﬁnding, in social models the drive toward order is provided by the tendency of the agents to become more alike. This effect is termed so- cial inﬂuence and can be seen as an analogue of the ferromagnetic interaction in magnets. Even though analogies can be drawn between social systems and statis- tical physics systems, there are concepts that present more difﬁculty in physical Statistical physics and the social sciences 305 interpretation. For instance, in many social dynamic models there is the idea that only quite similar agents are willing to interact. This concept is not immediately translatable into statistical physics but can be loosely associated with the con- cept of the distance between particles. A fundamental aspect of social modeling is diversiﬁcation in the topology of interactions whereas, in statistical physics, patterns of interaction are often regular lattices. On the contrary, more plausible interaction patterns are those determined by more complex topologies, such as small-world or scale-free ones. 12.2.1 Opinion dynamics In opinion dynamics the dynamics of agreement or disagreement between in- dividuals is complex. In statistical physics approaches, the opinion states of a population are deﬁned as well as the elementary processes that determine transi- tions between such states. One of the ﬁrst pieces of work using statistical physics methods in opinion dynamics was by Galam et al. (1982), who applied the Ising model with spin-spin coupling representing the pairwise interaction between agents and the magnetic ﬁeld representing the cultural majority. Personal prefer- ences toward either orientation were modeled as individual ﬁelds. Depending on the strength of the individual ﬁelds, the system may reach either total consensus toward one of two possible opinions or a state where both opinions coexist. Voter model One of the main approaches to opinion formation is the voter model. Voter dy- namics was ﬁrst discussed by Clifford and Sudbury (1972) as a model for the competition of species. It reached popularity because it is one of the very few non-equilibrium stochastic processes that can be solved exactly in any dimen- sion. In the model, each agent is modeled by a binary variable s = ±1. At each time step an agent i is selected along with one of its neighbors j and si is set equal to sj , i.e., the agent takes on the opinion of the neighbor. This updating rule implies that agents tend to imitate their neighbors. Starting from a disor- dered initial condition, voter dynamics tends to increase the order of the system. Recently, more complex models have been proposed. For instance, Castell´o et al. (2006) introduced the AB model with three states. At each time step an agent i is randomly chosen and its state is updated according to the following transition probabilities: PA→AB = 1 2 σB , PB→AB = 1 2 σA, PAB→B = 1 2 (1 − σA), PAB→A = 1 2 (1 − σB ). where σk (k = A, B) is the local density of each state in the neighborhood of i. The idea here is that in order to go from A to B one has to pass through the 306 Phase transitions in complex systems intermediate state AB. The rate for going from state A to AB is proportional to the density of neighbors in state B. This implies that consensus on the AB state, or a frozen mixture of A and B, is not possible, the only two possible absorbing states being those of consensus of either the A or the B type. Non-regular topologies have important effects on the dynamics of the voter model. On a complete graph the one-dimensional diffusion equation, with a position-dependent diffusion constant, can be solved analytically. The average time needed to reach consensus in a system of ﬁnite size can be computed exactly for any value of the initial “magnetization” and increases with the size of the system. When considering disordered topologies different ways of deﬁning the voter dynamics, which are equivalent on regular lattices, are nonequivalent generalizations of the voter model. When the degree distribu- tion is heterogeneous, the order in which a site and the neighbor to be copied are selected is relevant because high-degree nodes are more easily chosen as neighbors than low-degree ones. An interesting effect of the topology occurs on small-world networks. After an initial regime the system remains trapped in a metastable state with coexisting domains of opposite opinions (Vilone and Castellano, 2004). The lifetime of the metastable state is linear with the system size, so that for ﬁnite systems consensus is eventually reached on a temporal scale shorter than that for a regular one- dimensional lattice. For inﬁnite systems the state with coexisting opinions is actually stable, leading to the conclusion that long-range connections prevent a complete ordering of the voter model. Majority rule model An alternative approach to opinion dynamics is the majority rule (MR) model. A population includes N agents, such that a fraction p+ of agents has opinion +1, while a fraction p− =1 − p+ has opinion −1. For simplicity, it can be assumed that the interconnection network is a complete graph. At each iteration a group of r agents is selected at random (a discussion group): they interact and ﬁnally all agents assume the majority opinion inside the group (Galam, 2002). The group size r is not ﬁxed but is selected at each step from a given distribution. If r is odd, there is always a majority in favor of either opinion. If r is even and it happens that either opinion is supported by exactly r/2 agents, bias is introduced in favor of one of the opinions, say +1, and then that opinion prevails in the group. Social impact theory Lewenstein et al. (1992) proposed a model of social impact that can be solved in the mean-ﬁeld approximation. A population contains N individuals i, each char- acterized by an opinion σi = ±1 and by two random parameters, the persuasive- ness pi and the supportiveness si, which describe the capability to convince an Statistical physics and the social sciences 307 individual to change or to keep its opinion, respectively. These two parameters represent the quenched disorder of the system. Let Ii be the total impact that an individual i experiences from its social environment; then the opinion dynamics is expressed by the rule: σi(t +1) = −sgn[σi(t)Ii(t)+ hi], where hi is a random ﬁeld representing all sources other than social impact that may affect the opinion. According to the above rule, an opinion ﬂips if the pres- sure in favor of the opinion change overcomes the pressure to keep the current opinion. In general, in the absence of individual ﬁelds, the dynamics leads to the dominance of one opinion on the other but not to complete consensus. If the initial “magnetization” is about zero, the system converges to conﬁgurations characterized by a large majority of “spins” in the same opinion state, and by stable domains of “spins” in the minority opinion state. In the presence of indi- vidual spin ﬁelds these minority domains become metastable: they remain sta- tionary for a very long time and then suddenly shrink to smaller clusters, which again persist for a very long time before shrinking again, and so on (“staircase dynamics”). 12.2.2 Social and cultural dynamics Cultural dynamics is the multivaried version of opinion dynamics. The basic question is related to the uncovering of the microscopic mechanisms that drive the formation of a cultural domain and of its eventual persistence. The work of Axelrod (1997) has been very inﬂuential; he included in the model two mecha- nisms that are believed to be fundamental in the understanding of the dynamics of cultural assimilation (and diversity): social inﬂuence and homophily.Theﬁrst is the tendency of individuals to become more similar when they interact. The second is the tendency of likes to attract each other, so that they interact more frequently. These two ingredients were generally expected by social scientists to generate a self-reinforcing dynamics leading to a global convergence to a single culture. It turns out instead that the model predicts in some cases the persistence of diversity. From the point of view of statistical physics, the Axelrod model is a simple vectorial generalization of models of opinion dynamics that generates some truly novel behavior. In the model, individuals are located on the nodes of a network and are associated with F integer variables (σ1,...,σF ) that can assume q values σf =0, 1,...,q − 1. The variables are called cultural features and q is the number of the possible traits allowed per feature. They are supposed to model the different “beliefs, attitudes and behavior” of individuals. In an elementary dynamic step an individual i and one of its neighbors j are selected, and the 308 Phase transitions in complex systems overlap between them, namely ωi,j = 1 F F∑ f =1 δσf (i),σf (j), is computed. With probability ωi,j a feature for which traits are different (σf (i) ̸= σf (j)) is set equal to σf (i). Otherwise there is no change. Clearly the dynamics tends to make interacting individuals more similar, but interac- tion is more likely for neighbors already sharing many traits (homophily) and becomes impossible when no trait is the same. There are two stable conﬁgura- tions for a pair of neighbors: when they are exactly equal, so that they belong to the same cultural region, or when they are completely different, i.e., they are on either side of the border between cultural regions. Starting from a disordered initial condition, the evolution of any ﬁnite system leads unavoidably to one of the many absorbing states, either a state in which all individuals have the same set of variables or a frozen state with the coexistence of different cultural re- gions. The state reached depends on the number of possible traits q in the initial condition. For small q, individuals share many traits with their neighbors and full consensus is quickly achieved. For large q, very few individuals share traits and there is the emergence of small cultural domains that are not able to grow, a disordered frozen state. On regular lattices the two regimes are separated by a phase transition at a critical value qcr, which depends on F . Recently, Contucci et al. (2008) applied statistical mechanics models to de- scribe the cultural interchange between two homogeneous groups of individuals. The interaction inside a group is imitative whereas across groups it may be ei- ther imitative or counter-imitative. When two populations come into contact, as in the case of immigration but also in a more general context through the me- dia, sometimes cultural traits are evenly mixed and sometimes one population’s traits dominate. An interesting ﬁnding is that, in some cases, the changes vary smoothly with the relative proportions of the two groups whereas in other cases the crossing of a critical value triggers a jump in the observed quantity (Michard and Bouchaud, 2005). Contucci et al. (2008) built a mean ﬁeld theory of the two-population prob- lem, i.e., they assumed that every individual interacted with every other with the same strength. To build their model, the authors mapped the resident–immigrant cultural interaction problem onto that of two interacting groups of spins. A bi- nary spin σi ∈{+1, −1} is associated with each cultural trait. The interaction between two individuals i and j is modeled by a potential, which reﬂects the will to agree or disagree between the two. The system has two control parameters: α, the ratio of the number N1 of immigrants and the total cardinality N of the pop- ulation, and J12, which represents the strength of imitation or counter-imitation across the two groups. The output is the average magnetization ⟨m⟩,which,in Communication and computation networks 309 this context, represents the average opinion of the interacting system. The ob- tained results show that ⟨m⟩ varies smoothly when the interchange coefﬁcient is small but abruptly when the coefﬁcient is large. More intriguing is the observed dependence of the critical percentage on the internal cohesion of each group. Owing to a ﬁne balance between internal energy and entropy they found that a strong cohesion penalizes the cohesion of group. Another study that revealed the presence of a phase transition in a social system was performed by Woloszyn et al. (2007). Their goal was to investigate the social ability to become organized, as a function of the topology of a social- ties network organized into cliques. Again, a spin σi is assigned to each node and an interaction energy J to each link. The authors’ aim was to discover the presence of a phase transition; if it exists, it is indeed a sign of the ability of the network to become organized. The results indicate that if the connections between the small groups are too sparse then the system as a whole does not show any collective behavior. 12.3 Communication and computation networks Another type of complex system for which the methods of statistical physics are particularly well suited are large networks of communicating devices, such as telephone networks, computational grids, the Internet, and the World Wide Web. In recent years, in fact, these networks have reached sizes that justify ensemble approaches to their analysis. It is to be expected, then, that emerging phenomena such as phase transitions are found in their behavior. Ohira and Sawatary (1998) created a simulation model of trafﬁc in a com- puter network and found the presence of a phase transition. They were particu- larly interested in the shifting of the phase transition points from a state of low congestion to one of high congestion when the strategy for selecting paths for the packets is changed. The order parameter of the transition was the average travel time of packets and the control parameter was the generation rate of packets in the network. The interest of the work is that the authors proposed a stochastic routing strategy that shifts the location of the phase transition. If a parameter, used to control randomness in the path selection, assumes an appropriate value, then the onset of the congestion phase (at the phase transition) is delayed, i.e., the network can accomodate a higher rate of packet generation before becoming congested. The authors also changed the number of routers that apply this strat- egy and found that the model shows a non-linear response as a function of the proportion of these routers. This observation suggests that the phase transition is mostly due to their interaction. Lawniczak and Tang (2005) investigated a similar problem, namely the packet trafﬁc dynamics in a data network model near the phase transition point 310 Phase transitions in complex systems from free ﬂow to congestion. They built a model to investigate the spatiotemporal dynamics of packets trafﬁc near the phase transition point for different network connection topologies and for static or adaptive routing algorithms. The results showed, for adaptive routings and periodic square-lattice connection topologies, the emergence of synchronization, i.e., of a structure with peaks and valleys in the distributions of outgoing queue sizes when the network models are in their congested states. The emergence of this type of synchronization is accelerated by adding an extra link but destroyed by adding many more links. With adaptive routings and periodic triangular-lattice connection topologies, the packet trafﬁc was much more evenly distributed. In a more recent paper Marbukh (2007) discussed the possible presence of a phase transition in various types of complex communication networks, as well as the consequences of these phenomena for network performance evaluation and control. The microscopic description of the network was given by a Markov pro- cess with a large number of locally interacting components. The relation between microscopic and macroscopic descriptions was studied using statistical physics tools. A more comprehensive approach to the analysis of synchronization in complex networks, including both numerical and analytical approaches, was provided by Arenas et al. (2008). The authors offered explanations of the syn- chronization occurring in a network with complex topology when oscillating elements interact. Moreover, they highlighted the new features emerging from the interplay between the structure and the underlying pattern of connections. The investigation was extended to the analysis of opinion formation, where nu- merical simulations show that there is a phase transition from incoherence to synchrony at a well-deﬁned critical coupling. A directed small-world network consisting of attractively coupled identical phase oscillators has been analyzed recently (T¨onjes et al., 2010). The authors found that complete synchronization is always stable but is not always reach- able from random initial conditions. Depending on the shortcut density and on the asymmetry of the phase coupling function, there exists a regime of persistent chaotic dynamics. On increasing the density of shortcuts or decreasing the asym- metry of the phase coupling function, they observed a discontinuous transition in the ability of the system to synchronize. 12.4 Biological networks Large biological networks, such as, for instance, gene regulatory networks, are typical of the complex systems that can be found in many branches of biol- ogy and physiology. Problems in these areas have been often approached via Comments 311 machine learning techniques, both supervised and unsupervised; cluster analy- sis, in particular, has been widely applied, for example to ﬁnd groups of related genes (Naczar et al., 2007). Clearly, such large networks have also been inves- tigated with complex systems tools with aim of linking biological properties to network measures, such as betweenness, centrality, degree distribution,andso on. Very recently, methods from statistical mechanics have been used also with very promising results. One approach was proposed by Braunstein et al. (2008), who analyzed and compared two different algorithmic approaches to identify gene-regulatory interactions from high-throughput gene expression data. The ﬁrst approach uses pairwise correlations between regulated and regulating genes and the second uses message-passing techniques for inferring activating and in- hibiting regulatory interactions. The message-passing (belief propagation) tech- niques can be understood as an algorithmic reinterpretation of the cavity method in spin glass physics. It is the same idea as that underlying the survey propa- gation algorithm described in Section 3.5.4. The performances of the two al- gorithms have been analyzed theoretically on well-deﬁned test sets, using tools from the statistical physics of disordered systems such as the replica method. The message-passing algorithm was found to outperform the classical algorithms, since it takes into account the collective effects of multiple regulators. An interesting work linking evolutionary learning to gene network genera- tion appeared recently (Nicolau and Schoenauer, 2009). The authors proposed a novel approach to generating scale-free network topologies that is based on an existing artiﬁcial gene-regulatory-network model. From this model different interaction networks can be extracted, on the basis of the value of an activation threshold. Using an evolutionary computation approach, the model is allowed to evolve in order to reach network-speciﬁc statistical measures. The results obtained show that, when the model uses a duplication and divergence initial- ization, such as that seen in nature, the resulting regulation networks are closer in topology to scale-free networks. Indeed, these initialized genomes are far bet- ter suited for evolution than are purely random networks, owing to the larger range of degrees in the networks they encode as well as to the wider choice of resulting networks obtained by varying the threshold parameter that decides the existence of an edge between nodes. 12.5 Comments The networks mentioned in this chapter have different natures regarding their composition at the microscopic level. In fact, the component elements differ greatly in their complexity, autonomy, and richness of interactions, ranging from 312 Phase transitions in complex systems proteins and computers to human beings. It is then quite striking that analogous patterns of behaviors appear. As a matter of fact, once the components have been brought to a suitable level of abstraction (keeping only the essentials of their individual behavior and discarding irrelevant details) only the pattern and strength of their interactions matters. It is thus possible to ﬁnd commonalities in systems that differ largely in their composition but not in their behavior, allowing the transfer of results from one domain into another. For this reason, this chapter does not aim at providing full details of the approaches and results but suggests where one should start to look for similarities in other domains. 13 Phase transitions in natural systems Contents 13.1 Comments 317 Ensemble phenomena such as the emergence of a phase transition are by no means limited to artiﬁcial and inanimate entities. On the contrary, in living be- ings one may not infrequently observe similar phenomena, whose origin can be tracked down to the effect of the interaction among many components. In- deed, in living organisms the number of cells cooperating in biological and physiological processes is so large that ensemble behaviors are only to be ex- pected. The rapid transition between two neural states was observed as early as the late 1980s (Freeman, 1988). The experimental setting used by Freeman and co-workers included animal and human subjects, engaged in goal-directed be- havior, on which high-density electrode arrays were ﬁxed. Action potentials and brain waves (electroencephalograms (EEG) and local ﬁeld potentials) were then recorded and used to develop a data-driven brain theory. Freeman and co-workers designed data processing algorithms that enhance the spatial and temporal resolution of the textures of brain activity patterns found in three-layer paleocortex and six-layer neocortex. A major discovery of their work was evidence that cortical self-organized criticality creates a pseudo- equilibrium in brain dynamics that allows cortical mesoscopic state transitions to be modeled analogously to phase transitions in near-equilibrium physical systems. In more detail, the uncovered transition has four stages: a ﬁrst-order phase transition, which resets the phase of beta–gamma EEG oscillations in a 313 314 Phase transitions in natural systems discontinuity of the cortical dynamics; a pattern selection in the attractor land- scape by phase resynchronization; a second-order phase transition, which leads to pattern stabilization by a dramatic decrease in the rate of change of the order parameter; and then high-energy pattern broadcast over divergent–convergent axonal cortical output pathways, during which the rate of free energy dissipa- tion is maximized. The ratio of the rate of free energy dissipation and the rate of change in the order parameter deﬁnes the pragmatic information, which is max- imized during cortical transmission. On the basis of these ﬁndings the authors noticed that the power law and fractal distributions of EEG parameters enabled the scale-free dynamics of the cortex to be displayed as a macroscopic cortical state transition that sometimes covers an entire cerebral hemisphere almost in- stantaneously, even in humans; thus, they hypothesize that this transition is the neural mechanism that forms Gestalts (uniﬁed multisensory percepts). Freeman also investigated the emergence of a phase transition in the ani- malvisualsystem (Freeman, 1990). By analogy with the olfactory system, he suggested that in the visual cortex also a state transition causes a jump in the cortical dynamic state, constituting a type of bifurcation. The model proposed by Freeman requires that the cortex be intrinsically unstable and liable to sudden transitions under the appropriate stimuli. The conditions that facilitate controlled instability include a high level of cortical activity and of excitability, which is achieved under the neurochemical states of behavioral arousal and motivation. In a suitably aroused animal that expects a certain stimulus, the arrival of the sought stimulus can induce neural activity that serves as a bifurcation parameter. After two decades of work on the subject, the presence of phase transitions in perception is still at the core of Freeman’s interest. In a recent paper (Freeman, 2009) he investigated the process of storing information, extracted from micro- scopic sensory inputs, in the mesoscopic memory for retrieval in recognition. The process requires the creation of spatio-temporal patterns of neural activ- ity. Such a construction occurs through phase transitions in cortical populations that condense the background activity through spontaneous symmetry breaking. Large-scale interactions create ﬁelds of synaptically driven activity, which is ob- served by measuring brain waves (with an electrocorticogram) and evaluated by constructing a mesoscopic vectorial order parameter. Recently, Cowan also investigated in depth the question of phase transi- tions in the brain (Koppes, 2008). According to his view the same rules that are valid in the transition from vapor to liquid or from liquid to solid can be applied to the activation schemes followed by the neurons in the human brain. In particular, he observed the emergence of phase transitions as a consequence of neural interactions: he showed that, using the mathematical tools provided by statistical physics, it is possible to explain how the rhythms observed with an electroencephalogram, including δ-waves (occurring during sleep), α-waves (linked to visual processing), and γ-waves (linked to information processing), are Phase transitions in natural systems 315 generated. Cowan was a proposer of the Wilson–Cowan equations, which are aimed at describing the dynamic activity of (biological) neural nets. Even though these equations are too simple to be realistic, they are nevertheless a ﬁrst step to- wards relating neural phase transitions and neurological conditions or cognitive states. Neurological functioning in humans is not the only such area where phase transitions have been found. For instance, Szabo et al. (2006) recorded the swarming-like collective migration of a large number of keratocytes (tissue cells obtained from the scales of goldﬁsh) using long-term videomicroscopy. The au- thors showed that on increasing the density of the migrating cells, a kinetic phase transition from a disordered to an ordered state occurs. Near the critical density, interacting clusters of cells, moving in groups, appear. On the basis of these experimental results they proposed a ﬂocking model that exhibits a continuous transition to the ordered phase, assuming only short-range interactions and no explicit information about the directions of motion of neighbors. Placing cells in microfabricated arenas, they found a spectacular whirling behavior, which they could also reproduce in simulations. The formation of groups of moving cells near the phase transition is surprisingly similar to the formation of clusters of solutions in the analogous SAT problem, as described in Section 3.3.2. Another piece of work related to the emergence of a phase transition was reportedbyKshivets (2008). He found that in lung cancer the diameter of the tumor cell shows a critical value (2 cm) that separates a state in which the ﬁve- year survival chance after surgery is 100% from a state where the survival chance falls sharply. It was earlier proved that this happens because there is a phase transition in so-called “early-invasive lung cancer” at a critical level of the lung- cancer cell population. Carmesin and Arndt (1995) described a neural network, constituted by sen- sors (the input layer) and inner neurons (the hidden layer), that models multi- stable visual perception (Kruse et al., 1996). The authors proposed a dynamic model that includes a stochastic neuronal dynamics, a formal Hebb-type cou- pling dynamics, and a resource mechanism that corresponds to saturation ef- fects in perception. The model comprises a set of differential equations. Single stimuli are bound to exactly one percept, even in ambiguous situations where multistability occurs. The network exhibits both discontinuous and continuous phase transitions and can model various empirical ﬁndings, including the per- cepts of succession, alternative motion, and simultaneity; the percept of oscilla- tion is explained by the oscillation of percepts at a continuous phase transition. In particular, Carmesin and Arndt studied the phenomenon of stroboscopic alter- native motion. Increasing the frequency of presentation, there are ﬁve different percepts: (a) succession, (b) ﬂuttering motion, (c) reversible clockwise and an- ticlockwise turning motion, (d) oppositional motion, and (e) simultaneity. The frequency of presentation serves as the control parameter, whereas the percepts 316 Phase transitions in natural systems are the order parameters, of the phase transition. Both theoretical prediction and experiments agree on the existence of the three phases (a), (c), and (e), with the two continuous phase transitions (b) and (d) in between. Work in a related ﬁeld was done by Kelso et al. (1990) and Fuchs et al. (2000). These authors studied the transition in coordination behavior from synco- pation to synchronization in human subjects. The subjects’ task was to perform a ﬂexion movement of the preferred index ﬁnger in between two consecutive tones of an auditory metronome, i.e., to syncopate with the stimulus. It is well known that, by increasing the presentation rate of the stimuli as a control parameter, a point is reached where subjects can no longer perform a stable syncopated co- ordination pattern and, under the instruction to keep pace with the metronome, switch spontaneously to a movement that is instead synchronized with the stim- ulus. Three major changes in brain activity take place when the switch in the movement behavior occurs. • The topography of the dominant spatial pattern of brain activity changes. • The frequency of the time-dependent amplitude of neuromagnetic activity corresponding to the pattern described above switches from the coordina- tion frequency (prior to the transition) to twice the coordination frequency (after the transition). • In certain sensors the time series undergoes a phase shift of π at the same time as the transition in the coordination behavior. Subsequent theoretical work established the nature of the phase transition at both brain and behavioral levels through phenomenological modeling. More recently, a theory connecting the brain and behavioral levels of description has been de- veloped, based on the known cellular, and neural, ensemble properties of the cerebral cortex. Another phenomenon in which a phase transition has been uncovered is in the trace conditioning paradigm, speciﬁcally in the air-puff eye-blink paradigm (Howe and Levy, 2007). The paradigm consists of presenting to rabbits two tem- porally separated non-overlapping stimuli (air puffs) with a speciﬁed amount of stimulus-free time in between. A rabbit should learn to anticipate the second air puff, the unconditioned stimulus (US), by a timely blinking just prior to its on- set. The US follows at a speciﬁed time after the offset of a conditioned stimulus (CS). The stimulus-free time between the CS offset and the US onset is called the trace interval. As the paradigm requires the rabbit to predict the US onset based on the CS, the paradigm belongs to the class of problems handled by the authors’ computational theory of the hippocampus as a multisensory sequence encoding and predicting system. The ability to predict the US onset shows an Comments 317 abrupt change. No US neurons predict the US for 95 trials. Then, within ﬁve ad- ditional trials, more than 30% of US neurons produce a timely prediction. After a training period, characterized by a failure in prediction, rabbits suddenly and accurately begin to predict the US onset. Moreover, a prior investigation of CS and US longevity noted a phase-transition-like behavior in the predictive mode that was dependent on the trace-interval length (Wu and Levy, 2005). An overview of phase-transition-like phenomena in brain functioning was reported by Werner (2007), who considered both experimental observations and theoretical models. The brain clearly appears to be a non-linear system operating at the edge of criticality, which is achieved and maintained by self-organization. The concepts of scaling and universality, derived from statistical physics, prove to be useful notions for explaining the nature of the underlying neural processes occurring in neural circuits of cerebral cortex and subcortical structures. A sim- ilar view was proposed by Haken (2002), who considered the brain as a pattern- forming system that operates close to instability in order to achieve ﬂexible and rapid switching between coherent states. Basar contributed to this view of the brain as a dynamic system as early as the 1980s (Basar, 1983). Since 1975, Free- man has produced a steady ﬂow of studies of the dynamic principles of wave patterns in brains, which have yielded numerous relevant ﬁndings including char- acterizations of attractors, bifurcations, and critical phase transitions (Freeman, 1975; Freeman and Vitiello, 2006). Recently, Cocco et al. (2009) have applied methods from inverse statistical physics to infer coupling between retinal ganglion cells in salamanders. As the complexity of neural systems often makes it impractical to measure the interac- tions between neural cells, the authors propose to use inverse statistical physics approaches to infer effective couplings between neurons from their spiking ac- tivity. In particular, they described two computationally efﬁcient inverse algo- rithms, based on the Ising and “leaky integrate-and-ﬁre” models, and applied them to re-analyze multielectrode recordings in the salamander retina in dark- ness and under random visual stimuli. The authors found strong positive cou- plings between nearby ganglion cells common to both types of stimulus, whereas long-range couplings appear under random stimulus only. They claimed that the proposed methods would also allow the real-time evaluation of couplings for large assemblies of neurons. 13.1 Comments Given the internal complexity of biological entities, it should be expected that ensemble phenomena will occur. In fact, most activities of life consist of the interaction of large numbers of small components, be they proteins in regulation 318 Phase transitions in natural systems networks, cells in organs, or neurons in the brain. However, only recently have these patterns of interactions become the object of investigation with methods derived from complex systems theory and statistical physics. Even though natura non facit saltus, according to Carl von Linn´ee1 (and Leibniz and Darwin), we do experience discontinuities, especially in our cogni- tive functioning. For instance, this happens with ambiguous illusions, which are pictures or objects that may have two valid interpretations that are not both visi- ble at the same time: the viewer can only switch from one to another, as if there is a barrier to cross. In reasoning also we may suddenly reach a long-sought goal, such as grasping or learning a concept, after a critical amount of information has been collected. In the future this situation might be related to what happens in artiﬁcial neural networks, reported in Section 7.1. In consequence the investiga- tion of cognitive processes with methods from statistical physics may prove to be both viable and successful. 1Philosophia Botanica, Stockholm, 1751. 14 Discussion and open issues Contents 14.1 Phase transitions or threshold phenomena? 320 14.2 Do phase transitions occur in practice? 327 14.3 Blind spot 329 14.4 Number of examples 331 14.5 Machine learning and SAT or CSP solvers 331 14.6 Relational learning and complex networks 333 14.7 Relational machine learning perspective 334 In the long journey undertaken in this book, we have visited statistical mechan- ics, constraint satisfaction problems and satisﬁability, complex networks and nat- ural systems, and, in particular, many facets of machine learning ranging from propositional to relational learning, grammatical inference, and neural networks. The thread that connects all these ﬁelds is the emergence of phenomena ex- hibiting sharp discontinuities. These phenomena are reminiscent of the phase transitions found in physics and, indeed, the methods of statistical physics have been employed with success to analyze them. In this chapter we try to summa- rize what we have learned from these connections and in particular from the role played by machine learning. Our aim is to point out gaps in the understanding of basic phenomena and to identify open questions that may suggest future research directions. 319 320 Discussion and open issues 0 0.2 0.4 0.6 0.8 1.0 0 0.2 0.4 0.6 0.8 1 n = 20 n = 40 n = 60 n = 80 n = 100 n = 120 n = 140 n = 160 n = 180 Phead β Figure 14.1 Probability Phead vs. β for various values of the number n of trials in a single session. 14.1 Phase transitions or threshold phenomena? In a recent and very interesting paper, which recalls similar arguments put for- wards in Percus et al. (2006), Zweig et al. (2010) have challenged the current view of phase transitions in computational problems, wondering whether the abrupt change observed in the probability of solution (the order parameter) in SAT problems is in fact nothing other than a “self-fulﬁlling” discontinuity, i.e., an existential discontinuity generated by the very deﬁnitions of the problem and of the order parameter. The ﬁrst argument in support of their claim is that it is easy to produce rather simple models that exhibit phase transition phenomena while, as most of us would agree, the essential ingredients that underly a “true” phase transition are lacking. Indeed, Zweig et al. managed to produce a model that tightly ﬁts the measures available in the 3-SAT problem. Regarding the models exhibited by these authors, the ﬁrst consists in tossingCoin tossing acoin n times with a probability 1 − β of outputting head. The probability β is the control parameter. The order parameter is the probability Phead that among the n tosses there is a majority of heads. Clearly, when n →∞, Phead → 1 below β =0.5 and Phead → 0 above. The system also shows a ﬁnite size- scaling effect, with exponent 0.5. In Figure 14.1 Phead is shown as a function of Phase transitions or threshold phenomena? 321 β for various values of the number of trials n. The increasing sharpness with n of the curves in Figure 14.1 seems to be ascribable to the law of large numbers rather than a transition between two “phases”. The other problem is the coupon collector problem: there are n distinguish- Coupon collector problemable items (the “coupons”), named “1”,..., “n”, and multiple copies of each are contained in a large multiset S. A collector extracts an item from S one at a time, uniformly at random, and puts it in his or her collection C, if it is not yet present there. Let Ck be the collection when it contains k different items. The collection is complete when k = n.As S is very large, extraction with and extraction with- out replacement are almost equivalent and the probability of extracting a new item, not already belonging to Ck, can be written as (n − k)/n. The expected number of ways yk of obtaining Ck+1 from Ck is given by the equation yk n − k n =1, i.e., yk = n/(n − k). The total number of ways y of obtaining Cn is then y = n−1∑ k=0 n n − k = nHn, where Hn is the nth harmonic number. Let us now generalize the problem from just one to x collections, and let Pfull(t) be the proportion of full collections after t draws. By taking into account the size n of the problem, and by introducing the Euler–Mascheroni constant γ =0.577,avariable τ is deﬁned: τ = t nHn ≃ t n ln n + γn +0.5 . Plotting Pfull(τ ) versus τ gives a graph similar to that in Figure 14.1, with an apparent phase transition at the value τcr =1. Also, the system shows a non- trivial ﬁnite-size scaling effect with exponent 0.17. On the basis of the two simple examples reported above, Zweig et al. (2010) observe that, notwithstanding their mathematical behavior, our intuition hardly accepts that these systems undergo a “true” phase transition. And this observa- True phase transition?tion leads them to raise the issue of a precise deﬁnition of what a phase transition really is. Informally, in their opinion, a “true” phase transition should correspond to some structural and deep change in the system under study that is independent of the deﬁnition of the order parameter. In other words, the “phases” must be deﬁned ﬁrst and then the nature of the transition between them has to be investi- gated as opposed to deﬁning the phases from the behavior of the order parameter itself (i.e., the phases are deﬁned as regions of the control parameter space where the order parameter assumes different values). This is what happens in physical 322 Discussion and open issues systems when, for instance, water freezes or boils. Even though contributing to this deﬁnitional discussion is beyond the scope of the book, we will make some comments on the implications that such discussion may have on our problem of interest, namely relational machine learning. Before proceeding any further it is important to realize that whatever the true nature of the phase-transition-like phenomena at play in machine learning, their impact on the practicality of machine learning is undiminished. However, we agree with intuition of Zweig et al. that in a phase transition phenomenon something more fundamental should be happening than the typical mathemati- cal behavior of the order parameter. In particular, we believe that two essential aspects should be present: 1. the existence of a micro level where a large number of entities are present; 2. some interaction of these entities that produces ensemble phenomena (such as a phase transition) at the macro level. The above is also the context in which statistical physics methods are applicable. Whereas in neural networks, in complex social and information networks, and in the brain the micro and macro levels are quite easy to identify (as we saw in Chapters 7, 12,and 13, respectively), in computational problems such as SAT and symbolic machine learning it may be more difﬁcult to do this. Considering the coin-tossing problem, clearly neither condition 1 nor condi- tion 2 above is veriﬁed; in fact, there is no underlying structure, and each toss is independent of the others, so that no interaction exists. Extrapolating from this example and from the coupon collector example, one may wonder whether a similar threshold phenomenon on a stochastic variable might actually be the mechanism underlying several other apparent phase transitions. However, as suggested above, the answer to this question may actually be irrelevant as the important thing is the effect that this type of behavior has in practice. To be more precise, the ﬁndings that emerged in Chapter 10 set limits on the feasibility of relational machine learning, independently of the actual nature of the transition investigated in Chapter 9. Likewise, for k-SAT and other NP-hard problems it is relevant in practice to know where the most difﬁcult instances are located in the space of the control parameters. Nevertheless, to distinguish between a true phase transition and an apparent one has a signiﬁcant impact on a deep under- standing of the problem under study. Therefore, the need for a precise deﬁnition of a phase transition depends on the perspective one takes. Before moving to machine learning we would like to illustrate a further point with an intuitive example, namely, the idea of feedback in complex sets of inter-Feedback acting entities. Let us consider the toy system in Figure 14.2, which shows a box whose bottom is covered by a regular grid of cylindric holes. Suppose that a some pellets randomly slide over the bottom of the box, colliding with each other and Phase transitions or threshold phenomena? 323 )b()a( Figure 14.2 Toy model for a complex system exhibiting a phase transition. (a) When the pellet speed is above a given threshold the pellets ﬂy over the holes. (b) When the average speed decays below a given threshold, the pellets are quickly entrapped in the holes. The arrows in (a) indicate the pellets’ vector velocities. with the box walls, according to a pseudo-Brownian motion. More speciﬁcally, let us assume that the velocity vi of pellet πi follows a normal distribution with average value vavg and standard deviation σ (the motion is isotropic). Finally, around the rim of each hole is a small incline, which imparts a vertical veloc- ity to the pellets.1 As long as the pellets have a speed whose modulus is above a given threshold vcr, they ﬂy over the holes and the motion continues.2 Only those pellets whose velocity lies below vcr fall into the holes. Their number depends on σ. When the average speed decays below the threshold, more and more pellets fall into the holes. If we deﬁne as an order parameter the proportion of pellets that have fallen into holes and as a control parameter the average speed vavg,the order parameter decreases with increasing vavg.When vavg = vcr the proportion of fallen pellets is 0.5. The form of the function is typical of a phase transition and its steepness increases with decreasing σ. In fact, the function becomes a step function when σ =0. This case is analogous to the coin tossing problem, as each pellet is effec- tively independent of the others as long as their number allows a macroscopic description of their motion. On the contrary, the number n of pellets, if sufﬁ- ciently large, does not inﬂuence the results unless we consider the normal distri- bution as a description of the ﬂuctuations around the mean velocity. In this case, the intensity of the ﬂuctuations decreases as 1/ √n, approaching 0 for increasing system size. Even though the ensemble of pellets may constitute a microscopic level for the system, the elementary constituents do not interact so that it is still 1This is necessary otherwise the pellets would always fall into the holes whatever their hori- zontal speed. 2The threshold vcr is a constant depending on the system geometry (the hole size), the vertical velocity, and the elasticity, texture, etc. of the material used to construct the box and balls. 324 Discussion and open issues difﬁcult to consider the introduced order parameter as revealing a phase transi- tion. In fact, as in the case of the coin tossing, the transition seems dictated by the law of large numbers. Now, let us complicate the system a little more, by assuming that a pellet that has fallen into a hole modiﬁes the geometry of the system by widening the hole. Thus, the size of the holes grows, according to a given law, with the num- ber of pellets already entrapped. The ﬁrst pellets that fall into holes (those with velocities close to 0, located in the extreme left tail of the distribution) cause the hole size to increase, with the consequence that the critical velocity increases and more pellets are captured because more pellets have a lower speed than vcr.In this way an “avalanche” process is started by the positive feedback resulting from the entrapped pellets, which very quickly brings the proportion of entrapped pel- lets from 0 to 1 for any speed distribution, provided that there is at least one pellet with a speed lower than the original critical value. The difference between this setting and the preceding one is that now there are indirect interactions between the pellets, and the order parameter behavior depends on the global conﬁgura- tion of the system. Moreover, as the feedback strength depends on the number of entrapped pellets the global number n of pellets present in the box matters since the speed of the process increases with n. The existence of a loop determined by the feedback is reﬂected in the possibility of plotting the order parameter (the proportion of fallen pellets) as a function of the total number of pellets fallen so far. The same kind of retroaction and avalanche phenomenon has been seen in the case of grammar induction, as was described in Section 11.5.3. Moving on to relational learning, we showed in Chapter 10 how the change in the probability of ﬁnding a matching between a hypothesis and an example in- ﬂuences the quality of the learned knowledge as well as its learnability. Assum- ing that experiments have uncovered a true phase transition, one has to wonder what the micro and macro levels might be and what kind of interaction could be hypothesized as the basis of the macroscopic behavior. Let us start from the cov- ering test described in Chapter 9. In the covering test, or matching problem (ϕ, e) between a hypothesis ϕ andanexample e, the macroscopic level corresponds to either an existential or a quantitative problem: the former can be formulated as “Does ϕ cover e?”, whereas the latter can be formulated as “How many models has ϕ in e?”. This is the same distinction as that pointed out by Zweig et al. (2010). For our purpose we may consider either formulation, as our attention is fo- cused on the less obvious microscopic level. This level must involve the exam-Microscopic level in machine learning? ples. Actually there is more than one way to encode examples as a set of inter- acting entities, and the one we proposed is just a suggestion. We described in Chapter 9 how an example e comprises a set of m tables, each with N goods; each good is a pair of constants, both taken from the same set Λ of cardinality Phase transitions or threshold phenomena? 325 L. Let us associate with each good in each table a node in an m-partite colored multigraph Ge with mN nodes. Given a node (ai,aj ) from table Rh and a ver- tex (ai′,aj′) from table Rk, the two nodes are connected iff one of the following conditions holds. • ai = ai′ In this case we connect the nodes with a red edge. • ai = aj′ In this case we connect the nodes with a green edge. • aj = ai′ In this case we connect the nodes with a blue edge. • aj = aj′ In this case we connect the nodes with an orange edge. Two nodes may then have up to four edges connecting them. Edges can only be established between nodes corresponding to different relations, as each predicate in the domain appears only once in any formula. For this reason the graph is m- partite. The graph captures the internal structure of the example e and deﬁnes interactions between the variable pairs. The pattern of interaction determines whether a formula ϕ covers the example. However, the graph Ge is insufﬁcient for this, because all examples are generated with the same procedure and there is nothing intrinsic in example e that makes it positive or negative with respect to a hypothesis ϕ. Now comes the second level of interaction: when the formula ϕ is generated the predicates in it have speciﬁed pairs of variables, whose chain- ing must be matched by the example. Thus there is an interaction between the structure of the formula and the structure of the neutral example that determines whether ϕ covers e. More precisely, let α1(x, y) and α2(u, v) be two predicates in ϕ, with variables taken from the set X = {x1,...,xn}. Let us build a new graph Gϕ, with pairs of variables as nodes. The node (x, y) is connected to node (u, v) with a colored edge using the same criteria as for Ge. The graph Gϕ is m-partite as well, and the node (x, y) associated with the variable pair in α1 corresponds to the N nodes associated with the pairs oc- curring in the table α1 in Ge. Knowledge of the formula ϕ induces a transforma- tion in Ge; in fact, given a node (ai,aj ) in Ge corresponding to the extension of predicate α1 and another node (ai′,aj′) corresponding to the extension of predi- cate α2, all edges with a different color from those occurring in Gϕ between the variable pairs of α1 and α2 can be removed, because they will never be part of a model of ϕ in e. As a consequence, ϕ will have a model in example e iff Ge contains at least one subgraph isomorphic to Gϕ. The solution of the matching problem is then determined by the global interaction pattern among the goods and by that between the formula and the goods. It is an open question whether these two kinds of interaction generate matching problems whose structure is essentially different for pairs (ϕ, e) with and without a solution. 326 Discussion and open issues Moving to the global level of learning rather than just matching, similar con- siderations apply. We recall that a learning problem Π consists of a target concept c andexamplesintwosets, P (positive) and N (negative). Possible structural differences between positive and negative examples cannot exist, per se, because both sets of examples are generated by an identical procedure. What makes them positive or negative is their interaction with the target concept. In fact, given a set of constants Λ, most examples are located on the horizontal line L = |Λ| in the plane (m, L); thus each example is labeled positive or negative either by the lo- cation of the target concept itself or when needed by the modiﬁcation procedures (see Section 10.1.1), which depend upon ϕ as well. In the case of learning, we can build two ensembles of graphs, Gp and Gn, whose elements are associated with the positive and negative examples, respec- tively. In this case we do not know the target concepts but instead the labels, positive and negative, of the examples are known. Learning consists in extract- ing commonalities from Gp and Gn, those from the former to be included in the learned concept, those from the latter to be avoided. This process is again a global one, which exploits the structure of the examples and their links to gener- alize them. Also, in this case it is an open question whether the internal structures of the ensembles Gp and Gn, once that they have been labeled by the target con- cept, are essentially different. As a matter of fact the two ensembles cannot be different, per se: they were generated using the same procedure. It is only af- ter the target concept has been deﬁned that the examples are labeled. Thus, it is the interaction with the target concept that may distinguish them. However, examples in Gp and Gn can be labelled as positive and negative arbitrarily. In this case it might happen that a concept distinguishing them cannot be found, if the example sets do not have differentiating structures. Another novel aspect in the paper by Zweig et al. (2010) refers to experimen- tal results on the 3-SAT problem. These comprise three issues. The ﬁrst is that their experimental measurements provide for αcr a value closer to that found by Kirkpatrick and Selman (1994), i.e., 4.15 ± 0.05, than the value found theoreti- cally by M´ezard and Zecchina (2002), i.e., 4.267, which is believed to be exact. The second issue consists of a challenge to the phase transition nature of 3-SAT, as they were able to build a simple model that has all the characteristics of the actual k-SAT without invoking any deep restructuring of the solution space. The third issue is the most interesting, from our perspective, as it concerns the num- ber of models. Contrary to what is widely acknowledged, the average number of solutions at the phase transition of a 3-SAT is not 1 and does not drop abruptly to 0 to the right of the critical value αcr; instead, solutions may be found deeper into the UNSAT phase, their average number reaching 1 at the value α =5.19. It is true, however, that this average number is dominated by a few instances with many solutions and a large number of instances with no solution. The Do phase transitions occur in practice? 327 average number of solutions does not show, however, any anomalous behavior at αcr.3 This last ﬁnding is interesting, not only because it may deeply change the current view of 3-SAT but also because it recalls a phenomenon that occurs in physical phase transitions: a system existing in one phase may go into another by passing the critical point and remaining as it is in an unstable state, which suddenly may change if some perturbation occurs. As a concrete example, let us take water. Very pure water may remain liquid at a temperature well below the freezing point (for instance, at −20 ◦C at normal pressure) if the temperature is lowered very slowly. The water enters thus an unstable state; it is sufﬁcient to introduce an impurity particle or let the water come into contact with a warmer surface to see it change into ice in almost no time. Owing to the structure of the solution space, it is not unreasonable to think that some instances with α<αcr can be transformed, with small steps, into instances with α>αcr and still be solvable. Clearly, such type of instance must be a minority and the transforma- tion cannot take the original solvable instance too far inside the UNSAT region (actually, α =5.19 is quite close to αcr). This explanation would leave the essence of the 3-SAT phase transition unchanged but it would further complicate the structure of the solution space. Actually, we guess that something similar might happen in learning when positive (negative) examples are slowly trans- formed into negative (positive) ones. For matching problems (ϕ, e) that have moved from the YES region into the NO region, near misses (which are negative examples that are almost identical to corresponding positive examples except for a crucial aspect; Winston, 1975; Alphonse and Osmani, 2008a) could be the extremal points that they can reach. 14.2 Do phase transitions occur in practice? As we have seen in Chapters 3, 4, 9,and 10, generative models for SAT prob- lems, CSPs, and matching and learning problems all have an essentially stochas- tic nature. It is then a reasonable question to ask whether phenomena such as those investigated in the above-mentioned chapters actually do occur in real life. In order to interpret the emergence of an ensemble phenomenon such as a phase transition, one has to hypothesize that the problems to be solved are extracted from a population of random problems having the same values of the order pa- rameters as those actually considered. 3In Chapter 10 we found similar results, as the average number of models that a formula ϕ has in an example e in the YES region decreases exponentially towards the phase transition but does not show a discontinuity at the boundary. 328 Discussion and open issues However, the real world does not seem to us, in general, as random (rather the opposite); evolution has shaped it toward the creation of an environment suitable for life. Thus, given a class of problems and its space of control parameters, the studies that have been performed tell us that the solvable and unsolvable prob- lems are not uniformly distributed and that there are regions where one type of problem dominates the other. Random sampling serves to identify these regions. The fact that in a given region the overwhelming majority of problems is unsolv- able does not mean that solvable problems are not present (and vice versa); it means, however, that the latter must be searched for speciﬁcally and that we do not have much hope of ﬁnding them by just moving around randomly. Learning is an anomalous task, in this respect. In fact, the ensemble of prob-There is experi- mental evidence that a phase transition also occurs in real-world relational problems. lems to consider for the emergence of phase transitions is generated internally by the learner itself. Indeed, if the set of training examples is given, the learner is responsible for the generation of the candidate hypotheses during search. Each example is paired with each hypothesis, generating thus a possibly large number of matching problems. Given a speciﬁc learning task, including a set of train- ing examples, learners differ from each other in the way in which they generate hypotheses, i.e., in the heuristics they use. Different heuristics might correspond to phase transitions of a different location and steepness, and the ensemble of matching problems to which they give birth may be more or less similar to the randomly generated set. As we showed in Chapter 10, the space of matching problems has large benches (plateaus), where all heuristics based on coverage are ineffective and the search becomes almost random without additional knowl- edge. It is no surprise, then, that even in real learning problems a phase transi- tion emerges and that it attracts the search, as in the case of random problem sets (Giordana and Saitta, 2000). In Appendix A two real learning applications, solved by a learner based on an evolutionary search strategy and guided by the minimum description length principle (Anglano et al., 1997, 1998) are analyzed in detail. However, learning is not an exception. In fact, other authors have previously shown that phase transitions do emerge in real-world problems that are not ran- domly generated. For instance, Gent and Walsh (1996) analyzed the travelling salesperson problem on a city graph containing the capitals of 48 contiguous states of the USA. A phase transition did occur, although at a smaller control parameter value than for random graphs whereas the cost of search was higher than predicted. The same authors also noticed a phase transition in graph color- ing problems derived from university exam timetables (Gent et al., 1995); Gomes and Selman (1997) found a phase transition in quasi-group completion.4 4This term comes from group theory. Blind spot 329 Finally, considering again the case of machine learning, it is worth noticing that in the learning problems used in Chapter 10 the examples were not purely random. In fact, negative examples in the YES region and positive examples in the NO region were constructed on purpose. Even so, both the phase transition in the covering test and the consequent blind spot have been detected. 14.3 Blind spot One of the most surprising effect linked to the occurrence of the phase transition in matching is the presence of a region in the plane (m, L) where learners fail to learn. We called this region, in Chapter 10,a blind spot. It includes learning problems that lie in the phase transition region or in the part of the NO region immediately adjacent to it. Considering the ﬁndings reported in Chapters 9 and 10, the blind spot can be explained by considering the distribution of models of relational formulas in the (m, L) plane. As can be seen in Figure 10.11(a) the number of models has a peak in the YES region and then decays expo- nentially toward the phase transition edge. There are three consequences of this distribution. 1. Counting the models in the YES region has an exponential cost for any search algorithm. 2. Finding at least one model for a formula is very easy in the YES region but becomes exponentially hard in the phase transition region. In fact, it requires a very large search tree to be visited, where few or no leaves correspond to a model. 3. The information gain heuristic becomes unreliable, because any system- atic difference between the model counts in the positive and negative ex- amples is masked by the large stochastic variance of the model number (see Figure 10.11(b)). For the same reason, any other heuristic based on the model count is expected to fail as well. The blind spot has quite sharp contours, as might correspond to a threshold phe- nomenon in the information gain effectiveness; this has an analogue in the coin- tossing problem. In fact, in the case of a binary concept, FOIL’s information gain reduces to the computation of the expression IG(h1,h2)= t [ lg2 ( P2 P2 + N2 )] − lg2 ( P1 P1 + N1 ) , where P1, P2, N1,and N2 are the number of instances that two hypotheses have on a set of learning events sampled from the world. Thus P1, P2, N1,and N2 are 330 Discussion and open issues inherently stochastic variables and so the information gain itself is a stochastic variable. Therefore, the decision to add a literal to a hypothesis is always done by selecting the maximum value among a set of stochastic variables, as in the case of the coin-tossing problem. When the difference between the number of models (ways of verifying a formula) that a correct concept approximation has in posi- tive and negative instances is small, the probability of distinguishing the correct concept from incorrect approximations will tend to 0.5 and thus the heuristic reduces to a random choice. Even if this point has not yet been experimentally addressed, by referring to Figure 14.1 we can guess that the transition between solvable and unsolvable problems will be quite sharp. Another important aspect, related to the information gain, is that top-down strategies, used for instance by FOIL (Quinlan and Cameron-Jones, 1993)and SMART+ (Botta and Giordana, 1993), require the number of models that the formula has in every example to be counted. Algorithms like Django only check whether there exists at least one model and stop as soon as this has been found. The process of counting the models, whose number can be very large in the YES region even close to the border with the phase transition region, has a complexity which is lower-bounded by the number of models itself. Thus, the complexityThe information gain heuristic requires the models that a formula has in an example to be counted. peak is still to be considered as a serious obstacle in scaling up to relational learning problems more complex than those currently addressed. Going into a little more detail, in the YES region every formula has typically plenty of models whereas in the NO region any formula has typically no models. This means that the search trees that must be visited to ﬁnd a model in the YES region are huge until the phase transition edge is crossed. A formula ϕ,onthe border of the phase transition region, that has been obtained by adding one more literal to a formula ψ may have a search tree of about the same size as that of ψ. The difference is that the leaves of ϕ’s tree are almost all failure nodes while those in the ψ’s tree correspond to models. Deciding whether ψ contains at least one model has a low complexity because only a small portion of the tree needs to be visited. At the same time, counting the models of ψ does not help the information gain heuristic because their number is comparably large on all examples. On the contrary, the covering test for ϕ requires a large part (possibly all) of the tree to be visited; thus regions of the search space where models are few and highly informative for the inductive heuristic are entered by this covering test. As a ﬁnal observation, in relational learning we notice that, considering the outcomes of the coin-tossing model, we may expect that by increasing the number of positive and negative examples in the learning set it should become easier to detect small differences in the information gain of correct and incorrect concept approximations. Then, the blind spot should shrink. Unfortunately, the tremendous complexity of the learning process in this region has prevented a systematic investigation of this conjecture. Machine learning and SAT or CSP solvers 331 Also in propositional learning, as Baskiotis and Sebag (2004)haveshown, there may be regions of the control parameter space where learning tends to fail; speciﬁcally, they found such a region for C4.5, guided by the information gain. The considerations for relational learning still hold in this case. In addition, it is plausible to believe that the variance of the information gain estimate increases when a large number of attributes are taken into account in its evaluation. More- over, we may expect that upon increasing the number of examples, the difference between the information gain of two formulas could be estimated more reliably, so that the blind spot of C4.5 shrinks. Experimental evidence to support this guess would be welcome. 14.4 Number of examples In the research described in this book, we have not considered the dependence of the results obtained upon the number of training examples. This issue appears to be a relevant one. For instance, as described by Watkin et al. (1993), in Ising neural networks a phase transition occurs to perfect learnability in correspon- dence with a critical value of the number of examples in the learning set (see Chapter 7). Phase transitions with the number of examples as a control parame- ter have also been detected by R¨uckert et al. (2002) and Alphonse and Osmani (2009). These ﬁndings suggest that relational learning may show a double phase transition, one at the level of matching and one at the level of learning itself. So far, no work reports results on the possible interactions or separation between the two. It would be interesting to investigate their separate contributions to the overall computational complexity. Moreover, an increasing number of examples could constitute a suitable thermodynamic limit for the study of asymptotic be- haviors. As we have seen, scaling with the number of variables n does not make much sense in learning, as this value is always limited and actually quite small. 14.5 Machine learning and SAT or CSP solvers In this book, on the one hand we have presented machine learning as a set of hard search problems, both in the propositional and in the relational framework. On the other hand we have seen how the CSP and SAT ﬁelds have progressed, de- veloping powerful search algorithms able to solve problems of a very large size. Particularly impressive are the algorithms for SAT, such as WalkSAT and survey propagation, which are now able to solve problems with millions of clauses and variables. 332 Discussion and open issues A natural question is whether, and if so how, such algorithms could be exploited to make progress in machine learning as well, solving problems of a size and complexity that are still intractable today. In fact, we showed in Chapter 10 how a rather naive local search algorithm actually solves many re- lational problems located in the blind spot, where classical learners fail. Even though an increase in the variable number would render the blind spot uncon- querable, we could at least expect to increase the size of the solvable problems by one or two orders of magnitude. Considering propositional learning, we showed in Section 8.1 how a two- class learning problem can be mapped onto a SAT problem that can be solved by SAT solvers. In turn, a relational learning problem described in a DATALOG lan- guage can always be transformed into a propositional learning problem (Kramer et al., 2000). Thus, at least in principle, a relational learning problem can be mapped onto a SAT problem using a two-step transformation. This is surely an interesting approach, worth exploring, which, at least in principle, could solve learning problems that are much more complex than those currently solved by state-of-the-art relational learners. An alternative way, not yet explored, could be to state a relational learning problem as a CSP (which, as a matter of fact, it ac- tually is). Then, either CSP solvers could be used to solve the learning problem or, in turn, the CSP problem could be converted into a SAT problem, as we saw in Chapter 8. In practice, things are not so simple. The ﬁrst obstacle is that SAT and CSP exact solvers cannot be used because of the noise which affects all data sets ex- tracted from the real world. So, we must look at MaxSAT and MaxCSP solvers. Nevertheless, in this case also there is an issue to investigate before going further in this direction. MaxSAT and MaxCSP solvers aim at minimizing the number of violated constraints, without considering the nature of these constraints. This strategy may produce solutions that overﬁt the data without providing useful con- cept deﬁnitions. Actually, this is what happens in the blind spot, where the search heuristics of FOIL and of the other learners fail. As discussed in Chapter 10,in this case the solution is just a description of the learning set which minimizes the number of errors (violated constraints) but does not correctly classify new concept instances because it lacks generalization. The question is thus how to formulate the problem, or how to provide MaxSAT and MaxCSP solvers with proper heuristics, in order to select good generalizations of the target concept. It is worth noting that a major stream in machine learning, that based on the kernel approach (Shawe-Taylor and Cris- tianini, 2004), formulates a learning problem as a task of minimizing the num- ber of violated constraints. The difference from the approach we are proposing here is that kernels are actually continuous functions and the task is solved with methods developed in linear algebra. Relational learning and complex networks 333 14.6 Relational learning and complex networks We have seen that every single example used by relational learning can be rep- resented as a colored graph (network) of items. A subset of these examples, i.e., the positive examples in the YES region and the negative examples in the NO region, are actually constructed as random graphs and thus they must exhibit the properties discussed in Section 4.2. More speciﬁcally, we should expect a phase transition in the connectivity in correspondence with the critical value zcr =1 of the degree z of the graph. However, the average degree z of the examples randomly generated to investigate relational learning is approximately z =2(m − 1) ( N L2 ) , which is usually much larger than the critical value zcr =1.Thismeansthat most of the time all considered examples are strongly connected. Neverthe- less, for N very small (N< L2/2(m − 1)), the examples will reduce to a set of small independent substructures and the learning problem will be located very far from the phase transition, easy to solve, and not interesting for our purpose. Let us consider the strongly connected examples that we actually generated. In this case, the models of a formula ϕ in an example e correspond to subgraphs in the graph Ge of the example. Finding a solution to the problem of the covering test reduces to ﬁnding a subgraph in Ge that is isomorphic to Gϕ.Thisisthe viewpoint taken in the development of algorithms like MCS (Scheffer et al., 1996). In any case, looking at structured learning examples as graphs is suggestive and opens other perspectives for future research. In the ﬁrst place it establishes an explicit link between relational learning and investigations of complex net- works. Discovering a “community”, like, for instance, Internet users, in a graph is equivalent to describing a subgraph satisfying a set of preassigned conditions. Thus it can be modeled as a relational learning problem. However, a method for discovering communities in social networks should be easy to adapt to the problem of verifying a logical formula. Another intriguing point to investigate is the impact of the graph structure on the performances of relational learning algorithms. The blind spot for FOIL was found by considering examples whose background structure is an almost ho- mogeneous random graph. Singularities constructed by the procedure Change- ToPositive described in Section 10.1.1, correspond to a single (non-random) sub- graph forcibly inserted into a random graph. Then, solving a learning problem in the blind spot reduces to ﬁnding and characterizing a non-random subgraph in a large set of random subgraphs. 334 Discussion and open issues Thus, in learning, two types of graphs are involved: the ﬁrst is the con- straint graph and the second is the graph associated with each example. Both have the underlying structure of a random graph, such as those introduced in Deﬁnitions 3.6 and 3.7. It would be interesting to investigate what would happen if the generation procedures considered here were replaced by a small-world or scale-free graph generator. With very few exceptions (see for instance Walsh, 1999), this issue has not been approached so far. 14.7 Relational machine learning perspective The most appealing properties of learning in ﬁrst-order logic is the comprehen- sibility of the acquired knowledge and the ability to learn in complex domains where objects cannot be simply represented by ⟨attribute, value⟩ pairs. How- ever, according to the ﬁndings reported in this book, relational learning also has strong limitations, especially relating to the number of variables; in fact, we can- not expect to scale up to clauses with more than four or ﬁve variables without incurring a prohibitive computational complexity. Therefore relational learning, as we now know it, is probably restricted to dealing with data and concepts of limited size, however interesting. Moreover, as the phase transition region acts as an attractor, the quality of the learned knowledge is also affected because only hypotheses in that region may actually be learned. These facts are likely also to affect statistical relational learning, or at least those approaches that learn ﬁrst the network structure and then the parameters. Coming back to the statistical physics perspective and assuming that the ex- perimentally uncovered phase transition is a “true” one, several questions arise that need to be answered. We saw in Chapter 2 that, according to a modern view, a phase transition occurs when the partition function of the system under analysis has a singularity. If we want to transfer results from statistical physics to rela- tional learning, we need to identify what the corresponding “partition function” might be. This function is likely to be linked to the structure of the examples and to their interactions, both within themselves (the connections between tuples of constants in one example) and among them (commonalities to be discovered). In this way, we could be in the same situation as that for Ising neural networks and for SAT problems, where a precise deﬁnition of the partition function can be obtained and methods from statistical physics can be applied. Moreover, given the strict relation between matching and CSP, the solution space of matching also might show an analogous clustering structure. Investi- gating this aspect has the potential of suggesting more effective learning strate- gies, in the same way as it suggested the survey propagation algorithm for SAT. Concerning the search algorithms we have seen that, by exploiting the powerful Relational machine learning perspective 335 heuristics developed in the CSP ﬁeld, the complexity of the covering test can be at least partly reduced. This opens up the possibility of handling hypothe- ses that are much more complex that those currently generated by relational learners. We may wonder whether an analogous step ahead in the area of the heuristics for guiding the inductive search is likely. The stochastic algorithm presented in Chapter 10 proved to be capable of solving many problems not solved by FOIL, while its complexity was comparable. More speciﬁcally, we showed that by combining stochastic search with local deterministic search it is possible to learn approximated concept descriptions where no known classical algorithm is successful. Even if the algorithm is used under the stringent assump- tion that a conjunctive concept description exists, it is not difﬁcult to extend it to cope with more general concept descriptions. For instance, disjunctive descrip- tions can be learned by integrating the algorithm T4 (Section 10.4.2) with the type of set-covering algorithm found in most relational learners (Quinlan and Cameron-Jones, 1993; Botta and Giordana, 1993). As a matter of fact, the ap- proach described, even if still in a very elementary version, goes along the lines of CSP heuristics such as local search and tabu search.5 Thus we expect that more powerful relational learners can be designed and implemented. Finally, in machine learning in general it is well known that the selection of the learning set SL can deeply affect the robustness of the learned knowledge, especially for unstable learners such as decision tree learners. As we have seen in previous chapters, SL acts as the quenched disorder of the learning system. An interesting question is whether the generalization error is a self-averaging quantity, such that, for increasing cardinality of SL, it becomes independent of the learning set, so that only its mean value need be computed, not its whole distribution. This question has received a positive answer in the case of neural networks, as we saw in Chapter 7. A point that seems a real obstacle to the scaling up of relational learning is the number of variables. Even under the simplistic assumption that all predicates are relevant to the concept description, the task looks hard for many concepts requir- ing at least four variables. On increasing the number of variables, the complexity rises exponentially. Given the presence of irrelevant predicates, the analysis we performed still holds but the density of subformulas of the target concept close to the phase transition becomes even smaller, and so the difﬁculty increases further. This limit on the number of variables means, for instance, that we cannot learn descriptions of scenarios with more than four objects in them. After pointing out the difﬁculties of the task, we will mention possible ways to mitigating the negative aspects of the relational learning task. Beyond the po- tential improvements in the search algorithms mentioned above, there appear to 5A tabu search has a memory of past failures, kept to avoid repeating them. 336 Discussion and open issues be three ways to scale up relational learning, from the point of view of reducing its computational needs and improving the quality of the results, which we now discuss. Propositionalization In relational machine learning much effort has been devoted to propositionaliza- tion, i.e., the process of transforming a relational learning problem into a propo- sitional one, with the aim of exploiting the efﬁcient propositional learning algo- rithms that are available (Lavraˇcand Dˇzeroski, 1994; Alphonse and Rouveirol, 2000; Bournaud et al., 2003; Mauro et al., 2010). Reviews have been presented by Kramer et al. (2000), Krogel et al. (2003), and Karunaratne and Bostr¨om (2009). The idea is to transform a multirelational data set containing structured ex- amples into a propositional one with grounded ⟨attribute, value⟩ features de- scribing the structural properties of the examples. The propositional data set con- tains a single table, with one row per example. Propositionalization has proved to be an effective method in relational learning, and several algorithms imple- menting the process are available in the literature. The process has, however, two potentially negative aspects. The ﬁrst is that the size of the target table may grow exponentially in the size of the original problem, so that the advantage of using a fast propositional algorithm is reduced by the very size of the data. The second is that the learned knowledge may only be an approximation to what could have been learned in the ﬁrst-order logic set- ting. In fact, by aggregating and summarizing the original data some information may be lost. Nevertheless, propositionalization may be a viable way of approaching theProblems solved by current relational learners are easy to transform into the propositional framework. problem. In this case it would be interesting to investigate where the phase tran- sition in the matching of the original problem lies. Furthermore, an accurate investigation of the issue may suggest more effective ways of transforming the original data. It could be more rewarding to invest in techniques for translating a relational problem into a propositional one than in new algorithms for learning directly in the relational framework. Apriori knowledge Another way of scaling up to more complex problems could be to exploit domain knowledge to guide the search. As an example, Alphonse and Osmani (2009) showed that by providing the right knowledge, in the form of “near-miss” neg- ative examples, it is possible to solve all the problems in the dataset we used for the experiments described in previous chapters. This agrees with the princi- ple on which the stochastic approach we proposed is based. If we know a good Relational machine learning perspective 337 Figure 14.3 Abstraction process for problem solving. In learning, the ground problem consists of the representation spaces of examples and hypotheses. These spaces are then abstracted, obtaining some “simpler” spaces where learning may take place. After learning, the acquired knowledge may be re-transformed into the original space even though in some cases this step may not be necessary. educated guess to start from, we would not need stochastic sampling on the hy- pothesis space. In a random domain like the one we explored, no domain knowledge is pos- sible. Nevertheless, in many real-world applications this knowledge is available and can be exploited to prune the search in the hypothesis space. Of course, cod- ing the necessary knowledge and developing algorithms for using it is costly but may be a winning strategy in the long run. Considering the many complex problems successfully solved in ﬁelds such as signal interpretation and molecular biology, we can see that there has been substantial progress in discovering the underlying structure of a problem when learning techniques, typically in a propositional framework, have been exploited. In principle one could think of approaching the same kind of problem in a re- Knowledge-based approaches may be a valid option. lational framework that exploits the expressive power of ﬁrst-order-logic lan- guages. An interactive approach, where human experts and machines cooperate to learn in complex domains might be the solution. Abstraction Another way to try to reduce the negative effects of a phase transition in learn- ing problems is to use abstraction. Abstraction is a pervasive activity in human 338 Discussion and open issues perception, conceptualization, and reasoning. It is generally associated with a transformation of a problem representation that allows a solution to be found more easily, i.e., with reduced computational effort. The process is represented in Figure 14.3. Abstraction seems a very promising way out of the limitations of relational learning. Indeed, previous works have already shown that, when a “good” abstraction can be found, relational learning may be achieved with the same quality of acquired knowledge and with a strong reduction in computa- tional cost (Saitta and Zucker, 2000). However, the type of abstraction has to be chosen carefully, because it always entails an information reduction. This loss of information may be critical, and the learning problem might not be solvable in the abstract space. Leaving aside all considerations regarding the choice of a good abstraction (which are outside our current scope), we just provide a hint of how it may work. Among various abstraction operators (Saitta and Zucker, 2000, 2001, 2009) let us consider the term construction operator, which inputs a description of the parts of an object, and of how they are related, and outputs a single composite description. For instance, the whole object “bicycle” can be obtained from two “wheels”, one “handlebar”, two “pedals”, and so on. As long as we do not need to distinguish its parts, the whole object may be used for learning. The big advan- tage of an abstract space where only whole bicycles exist is that each bicycle can be associated with a single variable whereas in the concrete space many variables were needed to describe it. As we have seen that the number of variables is the strongest limiting factor in relational learning, this type of abstraction moves the learning problem into a space where a phase transition still exists but is located in a region of the control parameters where the complexity is lower. Another approach exploiting abstraction to move away from the phase tran- sition in CSP is described by Schrag and Miranker (1996). They used domain ab- straction to allow some subset of constants appearing in the relations to collapse to single constants. They showed that the transformation loosens the constraints so that this type of abstraction is effective when both the original and the abstract CSP are unsolvable. Through this type of abstraction, when effective, a sensible reduction in computational cost is obtained. The explicit use of abstraction techniques for the same problem class was proposed by Caseau (1991) and Ellman (1993). Beyond the ideas suggested in this section, other approaches may be con- sidered, in order to improve relational learning with respect to both quality and computational cost. Up to the present time only simple learning applications have been described, so that the negative effects of the phase transition in match- ing have been limited. For the future, either we will not need more complex learning cases or we will need to devise means to cope with them. Appendix A Phase transitions detected in two real cases In Chapter 9 we claimed that there is experimental evidence that in real-world applications also, where examples are not randomly generated, discriminant hy- potheses found by relational learners lie on the phase transition edge. In order to support this claim, we discuss here the ﬁndings presented by Giordana and Saitta (2000) concerning two-real world applications. The ﬁrst is a popular benchmark known as the mutagenesis dataset (Srinivasan et al., 1995), while the second is an application to mechanical troubleshooting in a chemical plant (Giordana et al., 1993). In both cases the learning problems were solved using G-Net, the relational learner based on evolutionary search described in Chapter 6 (Anglano et al., 1997, 1998). It is worth noticing that datasets suitable for relational learning and avail- able in public repositories are few and, in general, rather simple. In fact, the concept descriptions that have been learned from them contain few literals only and, mostly, two or three chained variables. The datasets that we present in this appendix are among the most complex approached with machine learning: for both, descriptions containing up to four variables and up to six binary relations have been discovered. For the sake of reference, Figure A.1 gives the same graph as Figure 9.9(a) but for n =4. A phase transition is evident, but the expected complexity in the mushy region is much lower than that in Figure 9.9(a). Comparing Figure A.1 (n =4) with Figure 9.9(a) (n =10), we notice that the mushy region is much wider for n =4 than for n =10, as predicted by the theory (Williams and Hogg, 1994). Moreover, a 50-fold increase in the complexity is observed in correspondence with a 2.5-fold increase in the number of variables. A.1 Mutagenesis dataset The mutagenesis dataset has been widely used in the machine learning commu- nity as a benchmark for testing induction algorithms in ﬁrst-order logic. The task 339 340 Phase transitions detected in two real cases C 200 150 100 50 0 0 10 20 30 40 10 20 30 40 50 m L Figure A.1 Complexity in the (m, L) plane for randomly generated matching problems with n =4 and N = 100. is to learn to predict the mutagenicity in nitroaromatic chemical compounds on the basis of their structure (Srinivasan et al., 1995). The goal of our analysis was to investigate where the classiﬁcation rules learned by an inductive program lie in the plane (m, L), with respect to the mushy region. The mutagenesis dataset1 consists of the chemical description of 188 molecules classiﬁed as “mutagenic” (125 positive examples) or “non-mutagenic” (63 negative examples). The goal of the learning task is to discover classiﬁca- tion rules that separate the two classes. Every compound is described as a set of atoms, each characterized by an attribute vector reporting the atom type, the atomic number, and the electrical charge, plus a set of relations describing atomic links and substructures of the molecule such as aromatic rings. Moreover, every compound is characterized by two global numeric attributes: lumo and logp,cor- responding to the energy of the compound’s lowest unoccupied molecular orbital and the logarithm of the compound’s octanol–water partition coefﬁcient, respec- tively. Extensive experimentation with different sets of attributes was reported by Srinivasan et al. (1995). The deﬁnition of this learning problem is usually based upon predicates (con- straints) with arity greater than 2, and it is not immediately suitable for analysis with the method used in Chapter 9, which was limited to binary constraints.2 However, the problem can be reformulated using only unary and binary predi- cates, as was done by Anglano et al. (1998). Every molecule is considered as 1The dataset used here is a “regression friendly” one: it includes those examples that can be modeled with a good approximation by linear regression. 2A discussion on the relations between binary and non-binary CSPs was provided by Bacchus and van Beek (1998). Mutagenesis dataset 341 Figure A.2 Example of a nitroaromatic molecule structure in the mutagenesis dataset. Each atom is denoted by a constant, and each link deﬁnes a binary rela- tion between two atoms. a different universe that must be classiﬁed as either mutagenic or not. The hy- pothesis description language contains literals of the form P (x, K) or Q(x, y), where variable x and y range over atoms and K denotes a set of constants that are to be learned by an induction algorithm (Giordana et al., 1997). In Figure A.2 an example is shown. A set of experiments was performed for each of two different hypothe- sis description languages, L1 and L2. The language L1 was analogous to that used by other authors in the past (Sebag and Rouveirol, 1997, 2000) and con- tains three unary predicates, namely, chrg(x, K), reporting the electrical charge, anm(x, K), reporting the atomic number, and type(x, K), reporting the atomic type, plus one binary predicate, bound(x, y), stating the existence or otherwise of a link between two atoms. Moreover, the constraint x<y was imposed for ev- ery variable pair in order to avoid inefﬁciency due to the test of symmetric or re- ﬂexive relations entailed by the relation bound(x, y). The language L2 contains all the predicates deﬁned in L1 with the addition of lumo(x, K) and logp(x, K) to the description of each atom. The algorithm G-Net was programmed to gen- erate formulas with exactly four variables, which is the maximum number used in previous studies. In both experiments G-Net was run several times on the entire dataset of 188 examples, producing sets of classiﬁcation rules correctly 342 Phase transitions detected in two real cases ϕ1 : anm(x3, [195, 22, 3, 27, 38, 40, 92]) ∧¬chrg(x3, [−0.2, 0.2])∧ anm(x4, [195, 22, 3, 38, 40, 29, 92]) ∧¬type(x4, [O]) ∧¬chrg(x4, [−0.2])∧ (x1 <x2) ∧ (x1 <x3) ∧ (x1 <x4) ∧ (x2 <x3) ∧ (x2 <x4) ∧ (x3 <x4)∧ bound(x3,x4) → mutagenic, ϕ2 : ¬chrg(x1, [−0.2]) ∧¬type(x2, [N ]) ∧¬anm(x3, [22])∧ ¬chrg(x3, [−0.6, −0.4]) ∧¬type(x4, [H, N, O]) ∧ (x1 <x2) ∧ (x1 <x3)∧ (x1 <x4) ∧ (x2 <x3) ∧ bound(x2,x3) ∧ (x2 <x4) ∧ (x3 <x4)∧ bound(x3,x4) → mutagenic, ϕ3 : anm(x1, [195, 38, 29, 92]) ∧ chrg(x1, [−0.8, 0.6]) ∧¬type(x3, [C])∧ ¬chrg(x3, [0.0]) ∧ anm(x4, [195, 22, 3, 27, 38, 29, 92]) ∧¬type(x4, [N ])∧ (x1 <x2) ∧ (x1 <x3) ∧ (x1 <x4) ∧ (x2 <x3) ∧ (x2 <x4) ∧ (x3 <x4) → mutagenic, ϕ4 : anm(x1, [195, 3, 27, 38, 40, 29, 92]) ∧¬type(x1, [H]) ∧¬chrg(x1, [−0.2]) ¬anm(x3, [40]) ∧ anm(x4, [195, 22, 27, 38, 40, 29, 92]) ∧¬type(x4, [H, N ]) (x1 <x2) ∧¬bound(x1,x2) ∧ (x1 <x3) ∧ (x1 <x4) ∧ (x2 <x3)∧ (x2 <x4) ∧ bound(x3,x4) ∧ (x3 <x4) → mutagenic. Figure A.3 The solution Φ learned by G-Net using the language L1; Φ correctly classiﬁes 94.1% of the dataset.4 covering from 90%to 95% of the examples depending on the control parameter setting.3 In the following we will analyze in detail two solutions, namely Φ= {ϕ1,ϕ2,ϕ3,ϕ4} consisting of the four clauses shown in Figure A.3, which are expressed in the language L1,and Ψ= {ψ1,ψ2,ψ3} consisting of the three clauses shown in Figure A.4, which are expressed in the language L2. The same analysis was performed on several other solutions generated by G-Net, and qual- itatively equivalent results were obtained. All rules in the solutions Φ and Ψ were analyzed according to the following procedure. For each rule ϕi ∈ Φ or ψi ∈ Ψ, the two parameters p2 and ˆp2,cr were computed for every example in the dataset. The reasons for using p2 were that m and n are constant for each formula whereas L and N change from one example to another; this variability is captured by p2, which depends upon both N and L. Thus, theoretical results from the literature (Prosser, 1996) can be used directly. 3In these experiments the whole dataset was used, because here we were interested not in eval- uating the predictive power of the learned knowledge, but in the impact of the matching complexity on the learning process. 4In the ϕi the symbol ¬ denotes, as before, the negation of a variable. Mutagenesis dataset 343 ψ1 : first − atom(x1) ∧ logp(x1, [0.0 ÷ 7.0]) ∧¬lumo(x1, [−1.0])∧ ¬logp(x2, [1.5, 7.0]) ∧¬lumo(x2, [−1.25]) ∧¬logp(x3, [0.5, 1.0, 6.5])∧ ¬lumo(x3, [−4.0 ÷−1.0]) ∧¬logp(x4, [2.5, 3.0]) ∧ (x1 <x2) ∧ (x1 <x3)∧ (x1 <x4) ∧ (x2 <x3) ∧ (x2 <x4) ∧ (x3 <x4) → mutagenic, ψ2 : first − atom(x1) ∧ logp(x1, [0.0 ÷ 7.0]) ∧¬lumo(x1, [−1.0])∧ ¬logp(x2, [1.5]) ∧¬lumo(x2, [−1.25]) ∧¬logp(x3, [0.5])∧ lumo(x3, [−1.5, −0.75]) ∧¬logp(x4, [2.5]) ∧¬lumo(x4, [−1.75]) ∧ (x1 <x2) ∧ (x1 <x3) ∧ (x1 <x4) ∧ (x2 <x3) ∧ (x2 <x4) ∧ (x3 <x4) → mutagenic, ψ3 : first − atom(x1) ∧¬lumo(x1, [−1.0]) ∧¬logp(x2, 2.0])∧ anm(x3, [195, 22, 3, 27, 38, 40, 29, 92]) ∧¬chrg(x3, [−0.20)])∧ ¬anm(x4, [22]) ∧ type(x4, [C, O, F ]) ∧¬chrg(x4, [−0.4, 0.0])∧ (x1 <x2) ∧ (x1 <x3) ∧ (x1 <x4) ∧ (x2 <x3)∧ (x2 <x4) ∧ (x3 <x4) → mutagenic. Figure A.4 The solution Ψ learned by G-Net using the language L2; Ψ correctly classiﬁes 90.7% of the dataset. For our analysis, every formula was decomposed into subformulas with the following structure: γ(x1,x2)= α1(x1) ∧ α2(x2) ∧ β(x1,x2). (A.1) Each subformula γ was considered as a single constraint. The unary predicates occur in each subformula containing the same variable as an argument; they have the role of reducing the number of bindings that may occur in the binary relations (namely, the N value). As all variables in a clause are correlated at least through the predicate <, six binary formulas were always obtained. Thus, p1 =1 for every clause, whereas the parameter ˆp2,cr depends upon the number L of constants; L corresponds, in this case, to the number of atoms in a molecule and varies from one example to another. More precisely, the minimum value for L in the dataset was Lmin =18, the maximum was LMax =40, and the average was Lavg =26.7. Using the expression (9.21) we obtain, considering all formulas: ˆp2,cr =1 − L −4/6.7 (A.2) The parameter p2 also depends upon the formula ϕ and upon the universe U represented by an example e; in order to stress this dependency, we use the no- tation p2(ϕ, e). More speciﬁcally, p2 was computed according to the expression p2(ϕ, e)= 1 6 6∑ j=1 p2(γj ,e)=1 − 1 6L2 6∑ j=1 Nj . (A.3) 344 Phase transitions detected in two real cases (b)(a) (d)(c) 60 All Pos Match All Pos Match All Pos Match All Pos Match 50 40 30 20 10 0 −0.2 −0.1 0.1 0.20 −0.2 −0.1 0.1 0.20 −0.2 −0.1 0.1 0.20 −0.2 −0.1 0.1 0.20 60 50 40 30 20 10 0 60 50 40 30 20 10 0 60 50 40 30 20 10 0 Figure A.5 Distribution of the variable p2 − ˆp2,cr for the mutagenesis dataset, for (a) ϕ1,(b) ϕ2,(c) ϕ3,(d) ϕ4 vs. the number of examples (all, positive, and those matched by the formula). In (A.3), γj is a binary subformula obtained from ϕ; its associated re- lation has Nj elements. Let us consider now the classiﬁcation rules Φ= {ϕ1,ϕ2,ϕ3,ϕ4}. For each rule ϕi we computed the distribution of the variable p2 − ˆp2,cr over all the examples in the dataset, over the positive examples, and over the examples (both positive and negative) “covered” by the rule. The graphs of these distributions are shown in Figure A.5. If the matching problem corre- sponding to a (ϕ, e) pair is exactly on the phase transition then the value p2−ˆp2,cr is zero. Notice that the mushy region is quite large for n =4, as we can see from Figure A.1; moreover, as neither L nor N are constant across relations and exam- ples, the broadening of the mushy region is enhanced. Figure A.5 clearly shows that, for the formulas ϕ2, ϕ3,and ϕ4,the p2 values are distributed substantially in the mushy region for both positive and negative examples whereas the matching problems involving ϕ1 seem to lie mostly in the YES region. The same analysis was performed for the solution Ψ, and the results are shown in Figure A.6. The Solution Ψ shows a different behavior from Φ.In fact, the rules ψ1 and ψ2 exhibit three separate peaks: one to the left, one inside, and one to the right of the mushy region, respectively. Moreover, in each case the peaks corresponding to the examples satisfying the rule practically coincide with the left-hand peak. A different behavior is exhibited by rule ψ3,whichshows only two peaks, the ﬁrst near the critical point ˆp2,cr, and the second clearly to the Mutagenesis dataset 345 )b()a( (c) 80 All Pos Match All Pos Match All Pos Match 70 60 50 40 30 20 10 0 80 70 60 50 40 30 20 10 0 80 70 60 50 40 30 20 10 0−0.2 −0.1 0 0.1 0.2 −0.2 −0.1 0 0.1 0.2 −0.2 −0.1 0 0.1 0.2 Figure A.6 Distribution of the variable p2 − ˆp2,cr for the mutagenesis dataset, for (a) ψ1,(b) ψ2,and (c) ψ3, vs. the number of examples (all, positive, and those matched by the formula). right of the mushy region. This situation is conﬁrmed by the presence of both positive and negative instances in the peaks. From Figures A.5(a)–(d) we predict that formula ϕ1 should be easy to match for all the examples, whereas matching ϕ2 is likely to involve a high computa- tional cost because most examples lie in the critical region. For formulas ϕ3 and ϕ4, many examples are close to the mushy region but not exactly at the transition point, so that an intermediate complexity should be expected. In Table A.1 the measured complexities for matching the formulas on the whole dataset are re- ported. As can be seen the theory prediction for all the formulas is substantially veriﬁed, except for ϕ1, for which both the location of the peak in Figure A.5(a) and the complexity in Table A.1 appear to be in error. Looking more closely at formula ϕ1 in Figure A.3, we suggest the following explanation. On the one hand, the formula ϕ1 actually contains only two “meaningful” variables, namely x3 and x4, in the predicate bound(x3,x4); thus, both n and m are overestimated and so the value ˆp2,cr is actually a little larger than that in the ﬁgure. On the other hand, N is computed as the average of all the relations involved in the formula, 346 Phase transitions detected in two real cases Table A.1 Average complexities for matching the clauses in Φ and Ψ to the examples of the dataset ΦΨ ϕ1 ϕ2 ϕ3 ϕ4 ψ1 ψ2 ψ3 Avg 26 215.10 5168.06 1249.04 1496.85 1.33 1.43 7.06 Avgpos 22.46 207.74 23.89 1249.86 2.00 2.00 2.35 Avgneg 30 418.86 8609.00 1463.44 1789.79 1.00 1.00 8.33 Table A.2 Classiﬁcation rates obtained by setting a threshold between the peaks corresponding to low and high p2 values, respectively, for the three formulas ψ1, ψ2,and ψ3. The values within parentheses correspond to the classiﬁcation obtained by actually matching the formula on the dataset. Setting a threshold on p2 reduces the omission error but increases the commission error Formula Threshold on p2 Positive Negative ψ1 0.85 80 (80) 3 (1) ψ2 0.85 60 (60) 4 (2) ψ3 0.95 54 (40) 23 (0) so that the extension of (x1 <x2), which is much larger than the other, means that p2 appears much smaller than it must be. The consequence is an apparent shift toward the left with respect to the phase transition. The second aspect to be explained, namely the abnormally high complexity of ϕ1 seen in Table A.1, is also related to spurious joins of the intermediate tables corresponding to x1 and x2, which are pruned only later. This effect would not have appeared if a dynamic variable ordering had been exploited during matching. A set of focused experiments in which ϕ1 was reduced to the subformula containing only x3 and x4, conﬁrmed both explanations. Of the seven formulas in Φ and Ψ, ϕ1 is the only formula in which only two variables are effective. It is sufﬁcient that three among the four variables are chained by the predicate bound, which is much more constraining than the predicate <, for the anomaly to disappear. An interesting observation can be made for Figure A.6(a)–(c): the positive and negative examples could be discriminated almost without performing the matching but simply by setting a threshold on p2: by considering as “positive” the examples on the left and as “negative” those on the right of the threshold, the classiﬁcation reported in Table A.2 is obtained. The values of p2 and hence the Mechanical troubleshooting datasets 347 threshold can be computed from N and L only. Problems that exhibit this kind of behavior are essentially “propositional” even though formally expressed in a FOL language. The very low matching complexities in Table A.1 conﬁrm this assertion. The above property can be exploited to reduce the amount of matching to be done during learning and knowledge use. By estimating the distributions of p2 values for the positive and negative training examples, a “best” threshold (or, preferably, a “best margin”) can be learned. Moreover, by looking at the syntactic structure of the clauses in Ψ,(seeFig- ure A.4), we notice that most literals occurring in them involve the attributes lumo and logp, which have the same value for all atoms, according to the way they have been deﬁned. Therefore, in spite of their structural aspect, ψ1 and ψ2 are easily translated into propositional assertions. The rule ψ3 shows a differ- ent structure, since it also contains literals related to the atomic charge and the atomic number. This is sufﬁcient to require an actual matching. This last situa- tion occurs in all clauses of the solution Φ. A.2 Mechanical troubleshooting datasets The second real-world case study that we discuss here is a problem approached by two of the authors some time ago in an industrial environment. The goal of the application was the automatic acquisition of a diagnostic knowledge base for mechanical troubleshooting at the chemical company ENICHEM in Ravenna. The knowledge base learned by the system ENIGMA (Giordana et al., 1993) has been used for many years by the company. The basis for the troubleshooting was mechanalysis, a methodology that ex- ploits mechanical vibrations and requires considerable expertise for its applica- tion. The diagnosed apparatus, ranging from small motor pumps to large turbo alternators, shared the common feature of possessing a rotating shaft. When some fault occurs in the machine, anomalous vibrations appear. Mechanalysis basically performs a Fourier analysis of the vibratory motions measured on the supports of the machine components. Each mechanalysis constitutes an exam- ple. The data, arranged into groups, correspond to the machine’s supports: each group contains the frequency and velocity of the harmonic components of the vibration for three spatial directions, as shown in Figure A.7. The troubleshooting task consists of discriminating between six classes (one “normal” and ﬁve for the types of fault). G-Net found 13 conjunctive formulas, distributed over the six classes,5 each having at most four variables. One of these 5In the real-world application the system ENIGMA was used (Giordana et al., 1993), but here we have re-analyzed the dataset using the new system G-Net. In fact, the knowledge base used in the ﬁeld was obtained by an integration of similarity- and explanation-based learning, and 348 Phase transitions detected in two real cases A B C D Motor (a) (b) Pump BasementJoint Support Direction Total vibration Fourier analysis Amplitude (µm) Speed (mm/s) w (CPM) v (mm/s) w (CPM) v (mm/s) Hor (7–11) (2.4–2.6) 3000 (0.7–0.9) . . . . . . 18 000 0.7 Vert (4–8) (1.2–1.4) 3000 (0.2–0.7) . . . 18 000 0.4 A Ax. 20 12 3000 (3–3.2) . . . 18 000 (0.8–1) Figure A.7 Structure of a mechanalysis table corresponding to a single exam- ple. (a) Scheme of a motor pump. The vibrations of the four supports A, B, C, and D are measured. (b) For each support (A, B, C and D) and for each triple of “total vibration” measurements, several groups of three rows, such as those given under the heading “Fourier Analysis”, may be present, as vibrations with different frequencies are measured. Globally, a mechanalysis table may contain 20 through 60 items, an item being an entry in the mechanalysis table, i.e., a 4-tuple <support, direction, frequency, velocity> for each vibration harmonic. formulas is the following: ϕ = vout(x1) ∧ sup(x1, [2, 3, 4]) ∧ ismax(x2) ∧¬mis(x2, [0.0 − 3.0]) ∧ vin(x3) ∧ rpm(x2, [2, 3, 4, 6, 7, 8]) ∧¬cpm(x3, [9.0]) ∧¬mis(x3, [1.0, 2.0]) ∧¬fea(x3, [ia, iv]) ∧¬rpm(x3, [5]) ∧¬sup(x4, [1, 3]) ∧ near(x1,x2, [1]) ∧ near(x1,x3, [1]) ∧¬near(x1,x4, [1]) ∧ near(x2,x3, [0, 1]). The meaning of the predicates in ϕ is not important here and can be found in Giordana et al. (1993). The relevant aspect is the syntactic structure of ϕ. In Figures A.8 and A.9 the results of the same analysis as that performed on was structured with chains of disjunctive rules instead of ﬂat ones. In the cited paper a complete description of the application may be found. Mechanical troubleshooting datasets 349 120 100 80 60 40 20 0 –0.2 –0.1 0 0.1 0.2 Figure A.8 Distribution of the variable p2 − ˆp2,cr for the matching problems obtained by pairing each of the 13 formulas (disjuncts) in the solution with all the examples in the dataset. Each graph corresponds to one of the 13 formulas. 120 100 80 60 40 20 0 –0.2 –0.1 0 0.1 0.2 Figure A.9 Distribution of the variable p2 − ˆp2,cr obtained by matching each disjunct corresponding to a given class with the positive examples of the same class that are covered by it. Hence, all the considered problems are solvable. the mutagenesis dataset are shown. More speciﬁcally, Figure A.8 reports the distribution of the variable p2 − ˆp2,cr for the matching problems obtained by pairing each of the 13 formulas with all the examples in the dataset (164 exam- ples), giving a total of 2132 matching problems. In Figure A.9, however, only matching problems obtained by pairing each formula with the positive examples of its class are considered. 350 Phase transitions detected in two real cases 510 15 20 25 70 60 50 L 40 30 20 m Figure A.10 Location of the line Psol =0.5 for N =50, 80, 100, 130 and n =4 variables. The symbols + and * (this lies about halfway up the vertical axis) locate the positions in the plane (m, L) of the “average” matching problems found in the mutagenesis and mechanical troubleshooting datasets, respectively. As we can see from Figure A.8, most problems lie inside the mushy region, except for one formula. A closer analysis of this formula showed that, in contrast with the case of Figure A.1(a), the peak to the left of the phase transition actually corresponds to an “easy” problem, with a low matching complexity and a high coverage of both positive and negative examples. In the two real-world problems that we have considered, the cardinality N of the relations corresponding to the basic predicates was not constant, as is assumed in model RL. Thus, we considered the model prediction for a range of N values corresponding to the actual cardinalities occurring in the two datasets. The plot in Figure A.10 is analogous to that in Figure 9.8(b) but for n =4 variables. Again, N was set to 50, 80, 100,and 130, respectively. In Figure A.10 we have indicated the “average” solutions found by G-Net (the average was over all pairs (ϕ, e), in the plane (m, L)). As can be seen from the ﬁgure, these solutions are located on the respective phase transition curves. Appendix B An intriguing idea It is easy to produce a probability function that exhibits a very steep transition between the values 0 and 1. Take for instance a binary tree corresponding to the exploration graph of a two-player game with a constant branching factor b. Each node in the tree represents a position, and each edge a possible move for a player from one position to a next position. Some games do indeed offer only exactly b possibilities at each time to the current player. Suppose further, as it is usually the case, that the computer whose turn it is to play does not have sufﬁcient time or memory space to explore the whole tree of possibilities. Then, the standard approach is for the computer to develop the tree to a given depth, say 10, and then to evaluate the merit of each position and to carry up these estimations through the celebrated min–max procedure. If a node represents the computer’s turn to play, the maximum value of the nodes below is returned and passed above, otherwise the minimal value is passed above. One question is then how to compute the probability of a “win” at the root of the tree given the probability that a leaf node is a win. By computing the proba- bility that a node is a win, given the probability of a win of its direct successors and its own nature (either a Max node or a Min node), it is straightforward to compute the probability at a Max node at depth d − n from the probability of a Min node at depth d − (n − 1), one move ahead: thus Pn =1 − (1 − P b n−1)b, (B.1) where b is the branching factor and Pn is the probability of a win when n is the number of moves to be played by Max until a leaf node (where n =0) is reached. This is a recursive function (called in this case the logistic function), from which the probability of a win at the root can be calculated given the probability of a win at a leaf node, Pd = f (P0). The function f (x)=1 − (1 − xb)b intersects the line y = x at three points. Two of them, at x =0 and x =1, are stable points and the third, x = ξb, is unstable. If Pn−1 is equal to any of these three values then we have Pn = Pn−1. If, however, Pn−1 <ξb then Pn <Pn−1 and therefore Pn+1 <Pn <Pn−1, and so on, whereas if Pn−1 >ξb then Pn >Pn−1 and therefore Pn+1 >Pn >Pn−1, and so on (see Pearl, 1984). 351 352 An intriguing idea 1 0 0 0 1 0 11 1 0 1 1 0 0 11 1 111 111 1 0000 0 0 0 Max node Min nodes Min nodes Max node Max node 0.2 0.4 0.6 0.8 1.0 0.2 0.4 0.6 0.8 1.0 Figure B.1 (Lower panel) The probability (see (B.1)) of a win at the root node of a max–min game with branching factor b =2 (upper panel) when the depth of the game increases from n =1 to n =5 and n =10. As a consequence, the greater the value of the depth d, the steeper the func- tion f (see Figure B.1). In the limit, we have lim d→∞ Pd(P0)= { 1 if P0 >ξb 0 if P0 <ξb (B.2) The same analysis can be carried out to compute the probability of accep- tance of a string when an automaton has a self-similar structure. Suppose that we have a “circuit” of the form shown of Figure B.2 (upper panel). We will call such a circuit a series circuit by analogy with the electrical case. Each edge in the circuit acts as a ﬁlter. Either the current letter in the incom- ing string matches the letter speciﬁed by the edge and the remaining string goes An intriguing idea 353 OU ET G G need show go the a fly PRP VBP want you what I UNK WP flight flight DT NN VBZ IN Baltimore breakfast breakfast breakfast from from from with Atlanta Dallas NNP to Baltimore Philadelphia TO goes G G G G GP PP P P PP P P Figure B.2 (Upper panel) A self-similar series–parallel circuit. The top left el- lipse encloses a series circuit. The probability that a string passes through the circuit is Pn−1 = Q2 n if the probability that the string passes each test is Qn.The larger ellipse encloses an elementary series–parallel circuit with two branches. The probability that a string passes it is Pn =1 − (1 − P 2 n−1)2. (Lower panel) Example of an automaton obtained during learning from a preﬁx tree acceptor (PTA). It exhibits a series–parallel pattern, if not a self-similar one. on, possibly towards an accepting state, or it does not match and the string is not accepted. When the edges appear on the same branch, the string must satisfy all conditions. This acts as an AND logical door, or as a Min node in a two-player game (see Figure B.1, upper panel). If we assume that the probability that the string successfully passes an elementary test is Pn−1 then the probability that the string successfully passes the series of b tests is Qn = P b n−1. However, if several branches, say b, are available in parallel (see Figure B.2) and if the probability that the string passes one branch is Qn then the probability that the string does not pass the parallel circuit is 1 − Pn =(1 − Qn)b. Thus, we obtain again Pn =1 − (1 − P b n−1)b. Overall, the probability that a string passes a self-similar circuit such as that of Figure B.2 has the same form as 354 An intriguing idea Figure B.1. As the depth of the circuit increases, the transition from probability 0 to probability 1 sharpens and tends towards a step function. Therefore, if an automaton exhibited a topology akin to such self-similar series-parallel circuits, should one expect a phase-transition-like proﬁle for the coverage of random strings? Is this realistic, or is it only a game of the mathe- matical mind? This remains to be studied more carefully.References ACHLIOPTAS,D., KIROUSIS,L., KRANAKIS,E., KRINZAC,D., MOLLOY,M., and STAMATIOU, Y. (1997) Random constraint satisfaction: a more accurate picture. In Lecture Notes in Computer Science,vol. 1330, pp. 107–120. ACHLIOPTAS,D., KIROUSIS,L., KRANAKIS,E., KRIZANC,D., MOLLOY,M., and STAMATIOU, Y. (2001a) Random constraint satisfaction: a more accurate picture. Constraints 6: 329–344. ACHLIOPTAS,D., KIROUSIS,L., KRANAKIS,E., and KRIZANC, D. (2001b) Rigorous results for random (2 + p)-SAT. Theor. Computer Sci. 265: 109–129. ALAVA,M., ARDELIUS,J., AURELL,E., KASKI,P., KRISHNAMURTHY,S., and ORPONEN, P. (2008) Circumspect descent prevails in solving random constraint satisfaction problems. PNAS 105: 15 253–15 257. ALEKSIEJUK,A., HOLYST,A., and STAUFFER, D. (2002) Ferromagnetic phase transition in Barab´asi–Albert networks. Physica A 310: 260–266. ALPHONSE, E. (2009) Empirical study of the phase transition in relational learning. In Proc. CAP 09, pp. 173–184, Hammamet. ALPHONSE,E., and OSMANI, A. (2007) Phase transition and heuristic search in relational learning. In Proc. 6th Int. Conf. on Machine Learning and Appli- cations, pp. 112–117, Cincinnati, Ohio. ALPHONSE,E., and OSMANI, A. (2008a) A model to study phase transition and plateaus in relational learning. In Lecture Notes in Computer Science,vol. 5194, pp. 6–23. ALPHONSE,E., and OSMANI, A. (2008b) On the connection between the phase transition of the covering test and the learning success rate in ILP. Machine Learning 70: 135–150. ALPHONSE,E., and OSMANI, A. (2009) Empirical study of relational learning algorithms in the phase transition framework. In Lecture Notes in Computer Science,vol. 5781, pp. 51–66. 355 356 References ALPHONSE,E., and ROUVEIROL, C. (2000) Lazy propositionalisation for re- lational learning. In Proc. 14th European Conf. on Artiﬁcial Intelligence, pp. 256–260, Berlin. ANDRECUT,M., and KAUFFMAN, S. (2010) Phase transition in non-linear ran- dom networks. arXiv:1003.0871v2. ANGLANO,C., and BOTTA, M. (2002) Now G-net: Learning classiﬁcation programs on networks of workstations. IEEE Trans. Evolutionary Comput. 6: 463–480. ANGLANO,C., GIORDANA,A., LOBELLO,G., and SAITTA, L. (1997) A network genetic algorithm for concept learning. In Proc. 7th Int. Conf. on Genetic Algorithms, pp. 434–441, East Lansing, MI. ANGLANO,C., GIORDANA,A., LOBELLO,G., and SAITTA, L. (1998) An experimental evaluation of coevolutive concept learning. In Proc. 15th Int. Conf. on Machine Learning, pp. 19–23, Madison, WI. APT, K. (2003) Principles of Constraint Programming. Cambridge University Press. APT,K., and WALLACE, M. (2007) Constraint Logic Programming using Eclipse. Cambridge University Press. ARENAS,A., D´IAZ,A., KRTHS,J., MORENO,Y., and ZHOU, C. (2008) Syn- chronization in complex networks. Phys. Rep. 469: 93–153. AXELROD, R. (1997) The dissemination of culture – a model with local con- vergence and global polarization. J. Conﬂict Resolution 41: 203–226. BACCHUS,F., and VAN BEEK, P. (1998) On the conversion between non- binary and binary constraint satisfaction problems. In Proc. 15th Nat. Conf. on Artiﬁcial Intelligence, pp. 311–318, Madison, WI. BARAB´ASI,A., and ALBERT, R. (1999) Emergence of scaling in random net- works. Science 159: 509–512. BARAB´ASI,A., and BONABEAU, E. (2003) Scale-free networks. Scientiﬁc American 288: 50–59. BARR´E,J., CIANI,A., FANELLI,D., BAGNOLI,F., and RUFFO, S. (2009) Fi- nite size effects for the Ising model on random graphs with varying dilution. Physica A 388: 3413–3425. BARRAT,A., and WEIGT, M. (2000) On the properties of small-world networks. Eur. Phys. J. B 13: 547–560. BASAR, E. (1983) Toward a physical approach to integrative physiology: brain dynamics and physical causality. Amer. J. Physiol. 245: 510–533. BASKIOTIS,N., and SEBAG, M. (2004) C4.5 competence map: a phase transition-inspired approach. In Proc. Int. Conf. on Machine Learning, pp. 73– 80, Banff. References 357 BERGADANO,F., and GIORDANA, A. (1988) A knowledge intensive approach to concept induction. In Proc. 5th Int. Conf. on Machine Learning, pp. 305– 317, Ann Arbor, MI. BERGADANO,F., GIORDANA,A., and SAITTA, L. (1988) Learning concepts in noisy environment. IEEE Tran. Pattern Analysis and Machine Intelligence PAMI-10: 555–578. BESSI `ERE,C., HEBRARD, E., and O’SULLIVAN, B. (2009) Minimising deci- sion tree as combinatorial optimisation. In Proc. 15th Int. Conf. on Principles and Practice of Constraint Programming, pp. 173–187, Lisbon. BETHE, H. (1935) Statistical theory of superlattices. Proc. Roy. Soc. London Ser. A 150: 552–575. BIANCONI, G. (2009) The entropy of network ensembles. Phys. Rev. E 79: 036 114. BIEHL,M., AHR,M., and SCHL ¨ASSER, E. (2000) Statistical physics of learn- ing: phase transitions in multilayered neural networks. Adv. Solid State Phys. 40: 819–826. BIELY,C., and THURNER, S. (2006) Statistical mechanics of scale-free net- works at a critical point: complexity without irreversibility? Phys. Rev. E 74: 066 116. BIERE,A., HEULE,M., VAN MAAREN,H., and WALSH, T. (2009) Hand- book of Satisﬁability: Frontiers in Artiﬁcial Intelligence, Vol. 185. IOS Press, Amsterdam. BINDER,K., and LUIJTEN, E. (2001) Monte Carlo tests of renormalization- group predictions for critical phenomena in Ising models. Phys. Rep. 344: 179–253. BIROLI,G., MONASSON,R., and WEIGT, M. (2000) A variational description of the ground state structure in random satisﬁability problems. Eur. Phys. J. B. 14: 551–574. BLYTHE,R., and EVANS, M. (2003) The Lee–Yang theory of equilibrium and nonequilibrium phase transitions. Brazilian J. Phys. 33: 464–475. BOTTA,M., and GIORDANA, A. (1993) SMART+: a multi-strategy learning tool. In Proc. 13th Int. Joint Conf. on Artiﬁcial Intelligence, pp. 937–943, Chamb´ery. BOTTA,M., GIORDANA,A., and SAITTA, L. (1999) An experimental study of phase transitions in matching. In Proc. 16th Int. Joint Conf. on Artiﬁcial Intelligence, pp. 1198–1203, Stockholm. BOTTA,M., GIORDANA,A., SAITTA,L., and SEBAG, M. (2000) Relational learning: hard problems and phase transitions. In Lecture Notes in Computer Science,vol. 1792, pp. 178–189. 358 References BOTTA,M., GIORDANA,A., SAITTA,L., and SEBAG, M. (2003) Relational learning as search in a critical region. J. Machine Learning Res. 4: 431–463. BOUFKHAD,Y., and DUBOIS, O. (1999) Length of prime implicants and num- ber of solutions of random CNF formulas. Theor. Computer Sci. 215: 1–30. BOURNAUD,I., COURTINE,M., and ZUCKER, J.-D. (2003) Propositionaliza- tion for clustering symbolic relational descriptions. In Proc. 12th Int. Conf. on Inductive Logic Programming, pp. 1–16, Szeged. BRACHMAN,R., and LEVESQUE, H. (2004) Knowledge Representation and Reasoning. Morgan Kaufmann. BRASSARD,G., and BRATLEY, P. (1988) Algorithmics: Theory and Practice. Prentice Hall. BRAUNSTEIN,A., PAGNANI,A., WEIGT,M., and ZECCHINA, R. (2008) In- ference algorithms for gene networks: a statistical mechanics analysis. J. Stat. Mech., 12 001. BREIMAN,L., FRIEDMAN,J., OHLSEN,R., and STONE, C. (1984) Classiﬁca- tion And Regression Trees. Wadsworth & Brooks. BRUNSON,T., and BOETTCHER, S. (2009) The peculiar phase transitions of the Ising model on a small-world network. In Proc. 76th Annual Meeting of the Southeastern Section of APS, p. BAPS.2009.SES.NA.9, Atlanta, Georgia. CARAMIA,M., and DELL’OLMO, P. (2002) Constraint propagation in graph coloring. J. Heuristics 8: 83–107. CARMESIN,H., and ARNDT, S. (1995) Organization of motion percepts. Uni- versity of Bremen, ZKW Bericht no. 6/95. CASEAU, Y. (1991) Abstraction interpretation of constraints on order-sorted domains. In Proc. Int. Symp. on Logic Programming, pp. 435–452, San Diego, CA. CASTELLANO,C., FORTUNATO,S., and LORETO, V. (2009) Statistical physics of social dynamics. Rev. Mod. Phys. 81: 591–646. CASTELL´O,X., EGU´ILUZ,V., and MIGUEL, M. S. (2006) Ordering dynamics with two non-excluding options: bilingualism in language competition. New J. Physics 8: 308–322. CHEESEMAN,P., KANEFSKY,B., and TAYLOR, W. (1991) Where the really hard problems are. In Proc. 12th Int. Joint Conf. on Artiﬁcial Intelligence, pp. 163–169, Sydney. CHOMSKY, N. (1957) Syntactic Structures. Mouton. CHURCH, A. (1936) An unsolvable problem of elementary number theory. Ameri. J. Math. 58: 345–363. References 359 CIPRA, B. (1987) An introduction to the Ising model. Ameri. Math. Monthly 94: 937–959. CIPRA, B. (2000) The Ising model is NP-complete. SIAM News 33 (6). CLIFFORD,P., and SUDBURY, A. (1972) A model for spatial conﬂict. Biometrika 60: 581–588. COCCO,S., LEIBLER,S., and MONASSON, R. (2009) Neuronal couplings between retinal ganglion cells inferred by efﬁcient inverse statistical physics methods. PNAS 106: 14 058–14 062. COHEN, W. W. (1995) Fast effective rule induction. In Proc. Int. Conf. on Ma- chine Learning, pp. 115–123, Tahoe City, CA. CONTUCCI,P., GALLO,I., and MENCONI, G. (2008) Phase transitions in social sciences: two-population mean ﬁeld theory. Int. J. Mod. Phys. B 22: 2199– 2212. COOK, S. (1971) The complexity of theorem-proving procedures. In Proc. 3rd Annual ACM Symp. on Theory of Computing, pp. 151–158, New York. CORNU ´EJOLS,A., and SEBAG, M. (2008) A note on phase transitions and com- putational pitfalls of learning from sequences. Int. J. Intelligent Information Syst. 31: 177–189. CORTES,C., and VAPNIK, V. (1995) Support vector machines. Machine Learn- ing 20: 273–297. CRAWFORD,J., and AUTON, L. (1996) Experimental results on the crossover point in random 3-SAT. Artiﬁcial Intelligence 81: 31–58. DAVIS,M., and PUTNAM, H. (1960) A computing procedure for quantiﬁcation theory. J. ACM 7: 201–215. DAVIS,M., LOGEMANN,G., and LOVELAND, D. (1962) A machine program for theorem-proving. Commun. ACM 5: 394–397. DE JONG,K.A., SPEARS,W.M., and GORDON, F. D. (1993) Using genetic algorithms for concept learning. Machine Learning 13: 161–188. DE LA HIGUERA, C. (2010) Grammatical Inference: Learning Automata and Grammars. Cambridge University Press. DECHTER, R. (2003) Constraint Processing. Morgan Kaufmann. DEINEKO,V. G., JONSSON,P., KLASSON,M., and KROKHIN, A. A. (2008) The approximability of MaxCSP with ﬁxed-value constraints. J. ACM 55. DEQUEN,G., and DUBOIS, O. (2006) An efﬁcient approach to solving random k-SAT problems. J. Automated Reasoning 37: 261–276. DIETRICH,R., OPPER,M., and SOMPOLINSKY, H. (1999) Statistical mechan- ics of support vector networks. Phys. Rev. Lett. 82: 2975–2978. 360 References DIETTERICH, T. (1998) Approximate statistical tests for comparing supervised classiﬁcation learning algorithms. Neural Computation 10: 1895–1923. DIETTERICH,T., and MICHALSKI, R. (1983) A comparative review of selected methods for learning from examples. In Machine Learning, an Artiﬁcial Intel- ligence Approach, eds. J. Carbonell, R. Michalski, and T. Mitchell, pp. 41–81, Tioga. DIETTERICH,T., LATHROP,R., and LOZANO-PEREZ, T. (1997) Solving the multiple-instance problem with axis-parallel rectangles. Artiﬁcial Intelligence 89: 31–71. DOROGOVTSEV,S., GOLTSEV,A., and MENDES, J. (2002) Ising model on net- works with an arbitrary distribution of connections. Phys.Rev.E 66: 016 104. DUBOIS,O., and DEQUEN, G. (2001) A backbone-search heuristic for efﬁcient solving of hard 3-SAT formulae. In Proc. 17th Int. Joint Conf. on Artiﬁcial Intelligence, pp. 248–253, Seattle, WA. DURBIN,R., EDDY,S., KROGH,A., and MITCHISON, G. (1998) Biological Sequence Analysis. Cambridge University Press. DURRETT, R. (2007) Random Graph Dynamics. Cambridge University Press. E ´EN,N., and S ¨ORENSSON, N. (2004) An extensible SAT solver. In Lecture Notes in Computer Science,vol. 2919, pp. 333–336. ELLMAN, T. (1993) Abstraction via approximate symmetry. In Proc. Int. Joint Conf. on Artiﬁcial Intelligence, pp. 916–921. ENGEL,A., and VAN DEN BROECK, C. (2001) Statistical Mechanics of Learn- ing. Cambridge University Press. ERD ¨OS,P., and R ´ENYI, P. (1959) On random graphs. Publ. Math. Debrecen 6: 290–297. ERENRICH,J., and SELMAN, B. (2003) Sampling combinatorial spaces us- ing biased random walks. In Proc. Int. Joint Conf. on Artiﬁcial Intelligence, pp. 1376–1380, Acapulco. FABRE-THORPE,M., DELORME,A., MARLOT,C., and THORPE, S. (2001) A limit to the speed of processing in ultra-rapid visual categorization of novel natural scenes. J. Cognitive Neurosci. 13: 171–180. FRANCO,J., and PAULL, M. (1983) Probabilistic analysis of the Davis–Putnam procedure for solving the satisﬁability problem. Discrete Applied Math. 5: 77– 87. FRANK,J., CHEESEMAN,P., and STUTZ, J. (1997) When gravity fails: local search topology. J. Artiﬁcial Intelligence Res. 17: 249–281. FREEMAN, W. (1975) Mass Action in the Nervous System. Academic Press. References 361 FREEMAN, W. (1988) Why neural networks don’t ﬂy: inquiry into the neuro- dynamics of biological intelligence. In Proc. 2nd Annual Int. Conf. on Neural Networks, pp. 1–8, San Diego, CA. FREEMAN, W. (1990) On the problem of anomalous dispersion in chao-to- chaotic phase transitions of neural masses, and its signiﬁcance for the man- agement of perceptual information in brains. In Synergetics or Cognition,eds. H. Haken and M. Stadler, pp. 126–143, Springer-Verlag. FREEMAN, W. (2009) Vortices in brain activity: their mechanism and signiﬁ- cance for perception. Neural Networks 22: 491–501. FREEMAN,W., and VITIELLO, G. (2006) Nonlinear brain dynamics as macro- scopic manifestation of underlying many-body ﬁeld dynamics. Phys. Life Rev. 3: 93–118. FREY,B.J., KSCHISCHANG,F. R., LOELIGER,H., and WIBERG, N. (1998) Factor graphs and algorithms. In Proc. 35th Allerton Conf. on Communica- tions, Control, and Computing, pp. 666–680, Allerton, Iowa. FRIEDMAN,E., and NISHIMURA, J. (2010) Explosive percolation in social and physical networks. arXiv:1001.4772. FROST,D., and DECHTER, R. (1995) Look-ahead value ordering for constraint satisfaction problems. In Proc. 14th Int. Joint Conf. on Artiﬁcial Intelligence, pp. 572–578, Montreal. FROST,D., RISH,I., and VILA, L. (1997) Summarizing CSP hardness with continuous probability distributions. In Proc. 14th National Conference on Artiﬁcial Intelligence, pp. 327–333, Providence, RI. FU,Y., and ANDERSON, P. (1986) Application of statistical mechanics to NP- complete problems in combinatorial optimization. J. Phys. A 19: 1605–1620. FUCHS,A., DEECKE,L., and KELSO, J. (2000) Phase transition in the hu- man brain revealed by large squid arrays: response to Daffertshofer, Peper and Beek. Phys. Lett. A 266: 303–308. GALAM, S. (2002) Minority opinion spreading in random geometry. Eur. Phys. J. B 25: 403–406. GALAM,S., GEFEN,Y., and SHAPIR, Y. (1982) Sociophysics: a mean behavior model for the process of strike. J. Math. Sociol. 9: 1–13. GAREY,M.R., and JOHNSON, D. S. (1979) Computers and Intractability: A Guide to the Theory of NP-completeness. W. H. Freeman and Co. GAUDEL,R., SEBAG,M., and CORNU ´EJOLS, A. (2008) A phase transition- based perspective on multiple instance kernels. Lecture Notes in Computer Science,vol. 4894, pp. 112–121. GENT,I., and WALSH, T. (1996) The TSP phase transition. Artiﬁcial Intelli- gence 88: 349–358. 362 References GENT,I.P., MACINTYRE,E., PROSSER,P., SMITH,B., and WALSH, T. (1995) Scaling effects in the CSP phase transition. In Lecture Notes in Computer Science vol. 976, pp. 70–87. GENT,I.P., MACINTYRE,E., PROSSER,P., SMITH,B., and WALSH, T. (2001) Random constraint satisfaction: ﬂaws and structure. Constraints 6: 345–372. GIORDANA,A., and SAITTA, L. (1994) Learning disjunctive concepts by means of genetic algorithms. In Proc. 11th Int. Conf. on Machine Learning, pp. 96– 104, New Brunswick, NJ. GIORDANA,A., and SAITTA, L. (2000) Phase transitions in relational learning. Machine Learning 41 (2): 17–251. GIORDANA,A., SAITTA,L., and BERGADANO, F. (1993) Enigma: a system that learns diagnostic knowledge. IEEE Trans. Knowledge and Data Eng. KDE-5: 15–28. GIORDANA,A., NERI,F., SAITTA,L., and BOTTA, M. (1997) Integrating multiple learning strategies in first order logics. Machine Learning 27: 209– 240. GIORDANA,A., SAITTA,L., SEBAG,M., and BOTTA, M. (2000a) Analyzing relational learning in the phase transition framework. In Proc. 17th Int. Conf. on Machine Learning, pp. 311–318, Stanford, CA. GIORDANA,A., SAITTA,L., SEBAG,M., and BOTTA, M. (2000b) Can rela- tional learning scale up? In Lecture Notes in Computer Science,vol. 1932, pp. 85–104. GITTERMAN,M., and HALPERN, V. (2004) Phase Transitions: A Brief Account with Modern Applications. World Scientiﬁc. G ¨ODEL, K. (1931) ¨Uber formal unentscheidbare S¨atze der Principia Mathemat- ica und verwandter Systeme. Monatshefte Math. Phys. 38: 173–198. GOLD, E. M. (1967) Language identiﬁcation in the limit. Information and Control 10: 447–474. GOLDBERG, A. (1979) On the complexity of satisﬁability problem. Courant Computer Science Report no. 16, New York University. GOLDBERG, D. (1989) Genetic Algorithms. Addison-Wesley. GOMES,C., and SELMAN, B. (1997) Problem structure in the presence of perturbations. In Proc. 14th Nat. Conf. on Artiﬁcial Intelligence, pp. 431–437, Providence, RI. GOTTLOB,G., LEONE,N., and SCARSELLO, F. (1997) On the complexity of some inductive logic programming problems. In Lecture Notes in Computer Science,vol. 1297, pp. 17–32. GUPTA, D. K. (2000) Dynamic variable ordering in graph based backjumping algorithms for CSPs. Int. J. Computer Math. 75: 167–186. References 363 GUSSFIELD, D. (1997) Algorithms on Strings, Trees, and Sequences. Cambridge University Press. HAKEN, H. (2002) Brain Dynamics. Springer. HARALICK,R. M., and ELLIOTT, G. L. (1980) Increasing tree search efﬁciency for constraint satisfaction problems. Artiﬁcial Intelligence 14: 263–313. HARTMANN,A., and WEIGT, M. (2005) Phase Transitions in Combinatorial Optimization Problems. Wiley-VCH. HAUSSLER,D., KEARNS,M., SEUNG,H., and TISHBY, N. (1994) Rigorous learning curve bounds from statistical mechanics. Machine Learning 25: 195– 236. HERRERO, C. (2002) Ising model in small-world networks. Phys.Rev.E 65: 066110. HERRERO, C. (2009) Antiferromagnetic Ising model in scale-free networks. Eur. Phys. J. B 70: 435–441. HEULE,M., DUFOUR,M., VAN MAAREN,H., and VAN ZWIETEN, J. (2004) March eq: implementing efﬁciency and additional reasoning into a lookahead SAT solver. J. Satisﬁability, Boolean Modeling and Computation 1: 25–30. HIRSCH,E.A., and KOJEVNIKOV, A. (2005) Unitwalk: a new SAT solver that uses local search guided by unit clause elimination. Ann. Math. Artiﬁcial Intelligence 43: 91–111. HOGG, T. (1996) Reﬁning the phase transition in combinatorial search. Artiﬁcial Intelligence 81: 127–154. HOGG,T., HUBERMAN,B.A., and WILLIAMS, C., eds. (1996) Frontiers in Problem Solving: Phase Transitions and Complexity. Artiﬁcial Intelligence 81 (1–2). HOLLAND, J. (1986) Escaping brittleness: the possibilities of general purpose learning algorithms applied to parallel rule based systems. In Machine Learn- ing: An Artiﬁcial Intelligence Approach, eds. R. Michalski, J. Carbonell, and T. Mitchell, volume 2, Morgan Kauffman. HOLTE,R., ACKER,L., and PORTER, B. (1989) Concept learning and the prob- lem of small disjuncts. In Proc. 11th Int. Joint Conf. on Artiﬁcial Intelligence, pp. 813–818, Detroit, MI. HOPCROFT,J., and ULLMAN, J. (1969) Formal Languages and Their Relation to Automata. Addison-Wesley. HOWE,A., and LEVY, W. (2007) A hippocampal model predicts a ﬂuctu- ating phase transition when learning certain trace conditioning paradigms. Cognitive Neurodynamics 1: 143–155. 364 References HUTTER,F., TOMPKINS,D., and HOOS, H. (2002) Scaling and probabilistic smoothing: efﬁcient dynamic local search for SAT. In Proc. 8th Int. Conf. on Principles and Practice of Constraint Programming, pp. 233–248, London. ISING, E. (1925) Beitrag zur Theorie des Ferromagnetismus. Z. Physik 31: 253 258. JAEGER, G. (1998) The Ehrenfest classiﬁcation of phase transitions : introduc- tion and evolution. Arch. Hist. Exact Sci. 53: 51–81. JAFFAR,J., and MAHER, M. (1994) Constraint logic programming: a survey. J. Logic Programming 19/20: 503–581. JEONG,D., HONG,H., KIM,B., and CHOL, M. (2003) Phase transition in the Ising model on a small-world network with distance-dependent interactions. Phys.Rev.E 68: 027 101. KAC,M., and WARD, J. (1952) A combinatorial solution of the two- dimensional Ising model. Phys. Rev. 88: 1332–1337. KAMATH,A., KARMARKAR,N., RAMAKRISHNAN,K., and RESENDE,M. (1992) A continuous approach to inductive inference. Math. Programming 57: 215–238. KARP,R., and PEARL, J. (1983) Searching for an optimal path in a tree with random costs. Artiﬁcial Intelligence 21: 99–117. KARUNARATNE,T., and BOSTR ¨OM, H. (2009) Graph propositionalization for random forests. In Proc. Int. Conf. on Machine Learning and Applications, pp. 196–201, Miami Beach, FL. KAUTZ,H., and SELMAN, B. (1996) Pushing the envelope: planning, propo- sitional logic, and stochastic search. In Proc. 13th Nat. Conf. on Artiﬁcial Intelligence, pp. 1194–1201, Portland, Oregon. KEARNS,M., and VAZIRANI, U. (1994) An Introduction to Computational Learning Theory. MIT Press. KEESOM,W.H., and VAN DEN ENDE, J. (1932) Proc. Kon. Akad. Amsterdam 35: 743. KELSO,J., DEL COLLE,J., and SCH ¨ONER, G. (1990) Action-perception as a pattern formation process. In Proc. 13th Conf. on Attention and Performance, pp. 139–169, Hillsdale, NJ. KILBY,P., SLANEY,J., THI ´EBAUX,S., and WALSH, T. (2005) Backbones and backdoors in satisﬁability. In Proc. 20th Nat. Conf. on Artiﬁcial Intelligence, pp. 1368–1373, Pittsburgh, PA. KING,R., SRINIVASAN,A., and STENBERG, M. (1995) Relating chemical ac- tivity to structure: an examination of ILP successes. New Generation Comput- ing 13: 411–433. References 365 KINZEL, W. (1998) Phase transitions of neural networks. In Proc. Minerva Workshop on Mesoscopics, Fractals and Neural Networks, pp. 1455–1477, Eilat. KIRKPATRICK,S., and SELMAN, B. (1994) Critical behavior in the satisﬁability of random boolean expressions. Science 264: 1297–1301. KIRKPATRICK,S., GELATT,C. D., and VECCHI, M. P. (1983) Optimization by simulated annealing. Science 220: 671–680. KOK,S., and DOMINGOS, P. (2010) Learning Markov logic networks using structural motifs. In Proc. 27th Int. Conf. on Machine Learning, pp. 502–509, Haifa. KOMIN,N., and TORAL, R. (2010) Phase transitions induced by microscopic disorder: a study based on the order parameter expansion. arXiv:1003.1061. KOPPES, S. (2008) Cowan discovers analogy between behavior of chemical reaction networks, neural networks of brain. Univ. Chicago Chron. 17 (12). KOWALSKI, R. (1979) Logic for Problem Solving. North-Holland. KRAMER,S., LAVRA ˇC,N., and FLACH, P. (2000) Propositionalization ap- proaches to relational data mining. In Relational Data Mining,eds.N.Lavraˇc and P. Flach, pp. 262–286, Springer-Verlag. KRAMERS,H., and WANNIER, G. (1941) Statistics of the two-dimensional ferromagnet, I. Phys. Rev. 60: 252–262. KROC,L., SABHARWAL,A., GOMES,C., and SELMAN, B. (2009) Integrating systematic and local search paradigms: a new strategy for maxsat. In Proc. IJCAI 2009, pp. 544–551. KROGEL,M., RAWLES,S., ˇZELEZN´Y,F., FLACH,P., LAVRAC,N., and WROBEL, S. (2003) Comparative evaluation of approaches to propositional- ization. In Lecture Notes in Computer Sciences,vol. 2835, pp. 197–214. KRUSE,P., CARMESIN,H., PAHLKE,L., STR ¨UBER,D., and STADLER,M. (1996) Continuous phase transitions in the perception of multistable visual patterns. University of Bremen, Germany: ZKW Bericht no. 3/95. KRZCAKALA, F. (2005) How many colors to color a random graph? Cavity, complexity, stability and all that. Prog. Theoret. Phys. 157: 357–360. KSCHISCHANG,F., MEMBER,S., FREY,B.J., and ANDREA LOELIGER,H. (2001) Factor graphs and the sum–product algorithm. IEEE Trans. Informa- tion Theory 47: 498–519. KSHIVETS, O. (2008) Synergetics, artiﬁcial intelligence, and complex system analysis in recognition of phase transition early-invasive lung cancer. J. Clin. Oncol. 26: 22183. KUMAR, V. (1992) Algorithms for constraint satisfaction problems: a survey. AI Magazine 13: 32–44. 366 References LANDAU,L., and LIFSHITZ, E. (1976) Mechanics, Third Edition. Pergamon Press. LANDAU,L., and LIFSHITZ, E. (1980) Statistical Physics, Third Edition. Perg- amon Press. LANG,K.J., PEARLMUTTER,B. A., and PRICE, R. A. (1998) Results of the Abbadingo One DFA learning competition and a new evidence-driven state merging algorithm. In Lecture Notes in Computer Science,vol. 1433, pp. 1–12. LANGLEY, P. (1986) Editorial: On machine learning. Machine Learning 1:5– 10. LAVRA ˇC,N., and D ˇZEROSKI, S. (1994) Inductive Logic Programming: Tech- niques and Applications. Ellis Horwood. LAWLER,E.L., and WOOD, D. E. (1966) Branch-and-bound methods: a sur- vey. Op. Res. 13: 699–719. LAWNICZAK,A., and TANG, X. (2005) Network trafﬁc behaviour near phase transition point. Eur. Phys. J. B 50: 231–236. LEE,T., and YANG, C. (1952) Statistical theory of equations of state and phase transitions. II. Lattice gas and Ising model. Phys. Rev. Lett. 87: 410–419. LEHN,K.V., and BALL, W. (1987) A version space approach to learning context-free grammars. Machine Learning J. 2: 39–74. LEONE,M., V´AZQUEZ,A., R., and ZECCHINA, A. V. (2002) Ferromagnetic ordering in graphs with arbitrary degree distribution. Eur. Phys. J. B 28: 191– 197. LEWENSTEIN,M., NOWAK,A., and LATAN´E, B. (1992) Statistical mechanics of social impact. Phys. Rev. A 45: 763–776. LI,C., MANY `A,F., and PLANES, J. (2007a) New inference rules for Max-SAT. J. Artiﬁcial Intelligence Res. 30: 321–359. LI,C., WEY,W., and ZHANG, H. (2007b) Combining adaptive noise and look- ahead in local search for SAT. In Lecture Notes in Computer Science,vol. 4501, pp. 121–133. MACINTYRE,E., PROSSER,P., SMITH,B., and WALSH, T. (1998) Random constraint satisfaction: theory meets practice. In Lecture Notes in Computer Science,vol. 1520, pp. 325–339. MALOBERTI,J., and SEBAG, M. (2004) Fast θ-subsumption with constraint satisfaction algorithms. Machine Learning 55: 137–174. MALZAHN,D., and OPPER, M. (2005) A statistical physics approach for the analysis of machine learning algorithms on real data. J. Statist. Mech.: Theory and Experiment 11: 11 001–11 033. References 367 MANDERIK,B., and SPIESSENS, P. (1989) Fine-grained parallel genetic algo- rithms. In Proc. 4th Int. Conf. on Genetic Algorithms, pp. 264–270, Fairfax, VA. MARBUKH, V. (2007) Towards understanding of complex communication net- works: performance, phase transitions and control. In Proc. Workshop on Math. Performance Modeling and Analysis, San Diego, CA. MARQUES-SILVA,J., and MANQUINHO, V. (2008) Towards more effective unsatisﬁability-based maximum satisﬁability algorithms. In Lecture Notes in Computer Science, vol. 4996, pp. 225–230. MARQUES-SILVA,J., and SAKALLAH, K. (1996) Grasp – a new search al- gorithm for satisﬁability. In Proc. IEEE/ACM Int. Conf. on Computer-Aided Design, pp. 220–227, Washington, DC. MARQUES-SILVA,J., and SAKALLAH, K. (1999) Grasp: a search algorithm for propositional satisﬁability. IEEE Trans. Computers 48: 506–521. MARTIN,O., MONASSON,R., and ZECCHINA, R. (2001) Statistical mechanics methods and phase transitions in optimization problems. Theoret. Computer Sci. 265: 3–67. MATOLCSI, T. (1996) On the classiﬁcation of phase transitions. Zeit. Ange- wandte Math. Phys. 47: 837–857. MAURO,N.D., BASILE,T., FERILLI,S., and ESPOSITO, F. (2010) Approxi- mate relational reasoning by stochastic propositionalization. Stud. Computa- tional Intelligence 265: 81–109. MERTENS,S., M ´EZARD,M., and ZECCHINA, R. (2006) Threshold values of random k-SAT from the cavity method. Random Structures and Algorithms 28: 340–373. M´EZARD,M., and PARISI, G. (1985) Replicas and optimization. J. de Phys. Lett. 46: 771–778. M´EZARD,M., and PARISI, G. (1991) Replica ﬁeld theory for random mani- folds. J. de Physique I 1: 809–836. M ´EZARD,M., and ZECCHINA, R. (2002) The random k-satisﬁability problem: from an analytic solution to an efﬁcient algorithm. Phys. Rev. E 66: 56–126. M´EZARD,M., PARISI,G., and VIRASORO, M. (1987) Spin Glass Theory and Beyond. World Scientiﬁc. M ´EZARD,M., MORA,T., and ZECCHINA, R. (2005) Clustering of solutions in the random satisﬁability problem. Phys. Revi. Lett. 94: 197 205. MICHALEWICZ, Z. (1996) Genetic Algorithms + Data Structures = Evolution Programs, Third Edition. Springer. 368 References MICHALSKI, R. (1983) A theory and methodology of inductive learning. In Ma- chine Learning: An Artiﬁcial Intelligence Approach, eds. R. Michalski, J. Car- bonell, and T. Mitchell, pp. 83–134. Morgan Kaufmann. MICHARD,Q., and BOUCHAUD, J. (2005) Theory of collective opinion shifts: from smooth trends to abrupt swings. Eur. Phys. J. B 47: 151–159. MIHALKOVA,L., and MOONEY, R. (2007) Bottom-up learning of Markov logic network structure. In Proc. 24th Int. Conf. on Machine Learning, pp. 625–632, Corvallis, OR. MINSKY,M., and PAPERT, S. (1969) Perceptrons. MIT Press. MITCHELL, T. (1977) Version spaces: a candidate elimination approach to rule learning. In Proc. 5th Int. Joint Conf. on Artiﬁcial Intelligence, pp. 305–310, Cambridge, MA. MITCHELL, T. (1982) Generalization as search. Artiﬁcial Intelligence 18: 203– 226. MITCHELL,T., and SCHWENZER, G. (1978) Applications of artiﬁcial intel- ligence for chemical inference: a computer program for automated empirical 13C-NMR rule formation. Organic Magnetic Resonance 11: 378–384. MONASSON, R. (2002) Threshold phenomena and complexity: a statistical physics analysis of the random satisﬁability problem. In Lectures on Random Combinatorial Problems, MDSU, Lansing, USA. MONASSON,R., and ZECCHINA, R. (1997) Statistical mechanics of the random k-SAT problem. Phys.Rev.E 56: 1357–1361. MONASSON,R., ZECCHINA,R., KIRKPATRICK,S., SELMAN,B., and TROYANSKY, L. (1999) 2+ p-sat: relation of typical-case complexity to the nature of the phase transition. Random Structures and Algorithms 15: 414– 435. MONTANARI,A., RICCI-TERSENGHI,F., and SEMERJIAN, G. (2008) Clusters of solutions and replica symmetry breaking in random k-satisﬁability. J. Stat. Mech.: Theory and Experiment p. P04004. MOONEY, R. (1995) Encouraging experimental results on learning CNF. Ma- chine Learning 19: 79–92. MOSKEWICZ,M., MADIGAN,C., ZHAO,Y., ZHANG,L., and MALIK,S. (2001) Chaff: engineering an efﬁcient SAT solver. In Proc. 38th Design Au- tomation Conf., pp. 530–535, Las Vegas, NV. MUGGLETON, S. (1991) Inductive logic programming. New Generation Com- puting 8: 295–318. MUGGLETON, S., ed. (1992) Inductive Logic Programming. Academic Press. MUGGLETON, S. (1995) Inverse entailment and Progol. New Generation Com- puting 13: 245–286. References 369 MUGGLETON,S., and BUNTINE, W. (1988) Machine invention of ﬁrst-order predicates by inverting resolution. In Proc. 5th Int. Conf. on Machine Learn- ing, pp. 339–352, Ann Arbor, Michigan. MUGGLETON,S., and DE RAEDT, L. (1994) Inductive logic programming: theory and methods. J. Logic Program. 19: 629–679. MUGGLETON,S., and FENG, C. (1990) Efﬁcient induction of logic programs. In Proc. 1st Conf. on Algorithmic Learning Theory, pp. 368–381, Tokyo. MULET,R., PAGNANI,A., WEIGT,M., and ZECCHINA, R. (2002) Coloring random graphs. Phys. Rev. Lett. 89: 268 701. MURPHY, G. (2002) The Big Book of Concepts. MIT Press. NACZAR,B., ZUCKER,J., HENEGAR,C., and SAITTA, L. (2007) Feature construction from synergic pairs to improve microarray-based classiﬁcation. Bioinformatics 23: 2866–2872. NEWMAN, M. E. J. (2003) The structure and function of complex networks. SIAM Review 45: 167 256. NICOLAU,M., and SCHOENAUER, M. (2009) On the evolution of free-scale topologies with a gene regulatory network model. Biosystems 98: 137–148. NISHIMORI, H. (2001) Statistical Physics of Spin Glasses and Information Processing. Oxford University Press. OHIRA,T., and SAWATARI, R. (1998) Phase transition in computer network trafﬁc model. Phys. Rev. E 58: 193–195. ONCINA,J., and GARC´IA, P. (1992) Inferring regular languages in polynomial updated time. In Pattern Recognition and Image Analysis : Selected Papers from the 4th Spanish Symposium, pp. 49–61, World Scientiﬁc. ONSAGER, L. (1944) Crystal statistics I. A two-dimensional model with an order–disorder transition. Phys. Rev. 65: 117–149. PALMER, E. (1985) Graphical Evolution. Wiley. PARK,J., and NEWMAN, M. (2004) The statistical mechanics of networks. Phys. Rev. E 70: 066 117. PEARL, J. (1984) Heuristics. Intelligent Search Strategies for Computer Prob- lem Solving. Addison-Wesley. PEARL, J. (1988) Probabilistic Reasoning in Intelligent Systems, second edition. Morgan Kauffmann. PEIERLS, R. (1936) Ising’s model of ferromagnetism. Proc. Camb. Phil. Soc. 32: 477–481. PELALSKI, A. (2000) Ising model on a small world network. Phys. Rev. E 64: 057 104. 370 References PERCUS,A., OSTRATE,G., and MOORE, C., eds. (2006) Computational Com- plexity and Statistical Physics. Oxford University Press. PERNOT,N., CORNU ´EJOLS,A., and SEBAG, M. (2005) Phase transitions within grammatical inference. In Proc. 19th Int. Joint Conf. on Artiﬁcial Intelligence, pp. 811–816, Edinburgh. PIPPARD, A. (1957) Elements of Classical Thermodynamics. Cambridge Uni- versity Press. PLOTKIN, G. (1970) A note in inductive generalization. In Machine Intelligence, eds. B. Meltzer and D. Michie, vol. 5, pp. 153–163. PROSSER, P. (1993) Hybrid algorithms for the constraint satisfaction problem. Computational Intelligence 9: 268 – 269. PROSSER, P. (1995) MAC-CBJ: Maintaining arc consistency with conﬂict- directed back-jumping. Research Report 95/177, University of Strathclyde. PROSSER, P. (1996) An empirical study of phase transitions in constraint satis- faction problems. Artiﬁcial Intelligence 81: 81–109. PURDOM,P.J., and BROWN, C. (1987) Polynomial average-time satisﬁability problems. Information Science 41: 23–42. QUINLAN, J. (1993) C4.5: Programs for Machine Learning.Morgan Kauf- mann. QUINLAN,J., and CAMERON-JONES, R. (1993) FOIL: a midterm report. In Lecture Notes in Artiﬁcial Intelligence,vol. 667, pp. 3–20. QUINLAN, R. (1986) Induction of decision trees. Machine Learning 1: 81–106. QUINLAN, R. (1990) Learning logical deﬁnitions from relations. Machine Learning 5: 239–266. RABINER, L. (1989) A tutorial on hidden Markov models and selected applica- tions in speech recognition. Proc. IEEE 77: 257–286. RAYWARD-SMITH,V., OSMAN,I., REEVES,C., and SMITH, G. (1989) Mod- ern Heuristic Search Methods. Wiley. RISSANEN, J. (1978) Modeling by shortest data description. Automatica 14: 465–471. ROSCH, E. (1973) Natural categories. Cognitive Psychology 4: 328–350. ROSENBLATT, F. (1958) The perceptron: a probabilistic model for information storage and organization in the brain. Psychol. Rev. 65: 386–407. ROZENFELD,H., SONG,C., and MAKSE, H. (2010) Small-world to fractal transition in complex networks: a renormalization group approach. Phys. Rev. Lett. 104: 025 701. References 371 R ¨UCKERT,U., and KRAMER, S. (2003) Stochastic local search in k-term DNF- learning. In Proc. Int. Conf. on Machine Learning, pp. 648–655, Washington, DC. R ¨UCKERT,U., KRAMER,S., and DERAEDT, L. (2002) Phase transitions and stochastic local search in k-term DNF learning. In Lecture Notes in Computer Science,vol. 2430, pp. 43–63. RUMELHART,D. E., and MCCLELLAND, J. L. (1986) Parallel Distributed Pro- cessing: Explorations in the Microstructure of Cognition, Parts I & II.MIT Press. RUMELHART,D. E., HINTON,G.E., and WILLIAMS, R. J. (1986) Learning representations by back-propagating errors. Nature 323: 533–536. RUSSELL,S., and NORVIG, P. (2003) Artiﬁcial Intelligence: A Modern Ap- proach. Prentice Hall. SAITTA,L., and ZUCKER, J. (2000) Abstraction and phase transitions in rela- tional learning. In Lecture Notes in Artiﬁcial Intelligence,vol. 1864, pp. 291– 301. SAITTA,L., and ZUCKER, J. (2001) A model of abstraction in visual perception. Int. J. Applied Intelligence 80: 134–155. SAITTA,L., and ZUCKER, J. (2009) Perception-based granularity levels in concept representation. In Lecture Notes in Computer Science,vol. 1932, pp. 201–214. SCHEFFER,T., HERBRICH,R., and WYSOTZKI., F. (1996) Efﬁcient θ- subsumption based on graph algorithms. In Lecture Notes in Artiﬁcial In- telligence,vol. 1314, pp. 212–228. SCHRAG,R., and MIRANKER, D. (1996) Abstraction and the CSP phase transi- tion boundary. In Proc. Int. Conf. on Artiﬁcial Intelligence and Mathematics, pp. 138–141, Fort Lauderdale, FL. SCHUURMANS,D., and SOUTHEY, F. (2001) Local search characteristics of incomplete sat procedures. Artiﬁcial Intelligence 132(2): 121–150. SEBAG,M., and ROUVEIROL, C. (1997) Tractable induction and classiﬁcation in first order logic via stochastic matching. In Proc. 15th Int. Joint Conf. on Artiﬁcial Intelligence, pp. 888–893, Nagoya. SEBAG,M., and ROUVEIROL, C. (2000) Resource-bounded relational reason- ing: induction and deduction through stochastic matching. Machine Learning 38: 41–62. SELMAN,B., LEVESQUE,H., and MITCHELL, D. (1992) A new method for solving hard satisﬁability problems. In Proc. 11th Nat. Conf. on Artiﬁcial Intelligence, pp. 440–446, Washington, DC. 372 References SEMERJIAN,G., and MONASSON, R. (2003) Relaxation and metastability in a local search procedure for the random satisﬁability problem. Phys. Rev. E 67: 066 103. SERRA,A., GIORDANA,A., and SAITTA, L. (2001) Learning on the phase tran- sition edge. In Proc. 17th Int. Joint Conf. on Artiﬁcial Intelligence, pp. 921– 926, Seattle, WA. SEUNG,H., SOMPOLINSKY,H., and TISHBY, N. (1992) Statistical mechanics of learning from examples. Phys. Rev. A 45: 6056–6091. SHAWE-TAYLOR,J., and CRISTIANINI, N. (2004) Kernel Methods for Pattern Analysis. Cambridge University Press. SHERRINGTON,D., and KIRKPATRICK, S. (1975) Solvable models of spin glass. Phys. Rev. Lett. 35: 1792–1796. SIMON, H. (1955) On a class of skew distribution functions. Biometrika 42: 425–440. SMITH, B. (1994) Locating the phase transition in binary constraint satisfaction problems. Artiﬁcial Intelligence 81: 155–181. SMITH, B. (2001) Constructing an asymptotic phase transition in random binary constraint satisfaction problems. Theor. Computer Sci. 265: 265–283. SMITH,B., and DYER, M. (1996) Locating the phase transition in binary constraint satisfaction problems. Artiﬁcial Intelligence 81: 155–181. SMITH,B., and GRANT, S. (1997) Modelling exceptionally hard constraint satisfaction problems. In Lecture Notes in Computer Science,vol. 1330, pp. 182–195. SOLOMONOFF,R., and RAPOPORT, A. (1951) Connectivity of random nets. Bull. Math. Biophys. 13: 107–116. S ¨ORENSSON,N., and E ´EN, N. (2005) MiniSAT v1.13: a SAT solver with con- ﬂict clause minimization. In Proc. 8th Int. Conf. on Theory and Applications of Satisﬁability Testing, St. Andrews. SRINIVASAN,A., and MUGGLETON, S. (1995) Comparing the use of back- ground knowledge by two ILP systems. In Proc. Conf. on Inductive Logic Programming 1995, Katholieke Universiteit Leuven. SRINIVASAN,A., MUGGLETON,S., and KING, R. (1995) Comparing the use of background knowledge by two ILP systems. In Proc. 5th Int. Workshop on ILP, pp. 199–229, Leuven. STRAUSS, D. (1986) On a general class of models for interaction. SIAM Review 28: 513–527. SUTTON,A., HOWE,A., and DARRELL, L. (2009) Estimating bounds on ex- pected plateau size in MAX-SAT problems. In Proc. 2nd Int. Workshop on References 373 Engineering Stochastic Local Search Algorithms. Designing, Implementing and Analyzing Effective Heuristics, pp. 31–45. SVRAKIC, N. (1980) Critical temperatures of Ising models. Phys. Lett. A 80: 43– 44. SZABO,B., SZOLLOSI,G., GONCI,B., JURANYI,Z., SELMECZI,D., and VICSEK, T. (2006) Phase transition in the collective migration of tissue cells: experiment and model. Phys.rev.E 74: 061 908. T ¨ONJES,R., MASUDA,N., and KORI, H. (2010) Synchronization tran- sition of identical phase oscillators in a directed small-world network. arXiv/1003.2020. TSANG, E. (1993) Foundations of Constraint Satisfaction. Academic Press. TURING, A. (1936) On computable numbers, with an application to the entschei- dungsproblem. Proc. London Math. Soc. 2 42: 230–265. TURNER, J. (1988) Almost all k-colorable graphs are easy to color. J. Algo- rithms 9: 63–82. VALIANT, L. (1984) A theory of the learnable. Commun. ACM 27: 1134–1142. VAN HENTENRYCK, P. (1989) Constraint Satisfaction in Logic Programming. MIT Press. VAPNIK, V. N. (1995) The Nature of Statistical Learning Theory. Springer- Verlag. VAPNIK, V. N. (1999) An overview of statistical learning theory. IEEE Trans. Neural Networks 10: 988–999. V´AZQUEZ,A., and WEIGT, M. (2003) Computational complexity arising from degree correlations in networks. Phys.Rev.E 67: 027101. VICSEK, T. (2007) Phase transitions and overlapping modules in complex net- works. Physica A 378: 20–32. VILONE,D., and CASTELLANO, C. (2004) Solution of voter model dynamics on annealed small-world networks. Phys.Rev.E 69: 016 109. WALSH, T. (1999) Search in a small world. In Proc. 16th Int. Joint Conf. on Artiﬁcial Intelligence, pp. 1172–1177, Stockholm. W ¨ASTLUND, J. (2009) Replica symmetry and combinatorial optimization. In Proc. Conf. on Physics of Algorithms, Santa Fe, New Mexico. WATKIN,T., RAU,A., and BIEHL, M. (1993) The statistical mechanics of learn- ing a rule. Rev. Mod. Phys. 65: 499–556. WATTS,D., and STROGATZ, S. (1998) Collective dynamics of small-world net- works. Nature 393: 440–442. WERNER, G. (2007) Metastability, criticality and phase transitions in brain and its models. Biosystems 90: 496–508. 374 References WIECZOREK,S., BISSON,G., and GORDON, M. (2006) Guiding the search in the NO region of the phase transition problem with a partial subsumption test. In Lecture Notes in Computer Science,vol. 4212, pp. 817–824. WILLIAMS,C., and HOGG, T. (1994) Exploiting the deep structure of constraint problems. Artiﬁcial Intelligence 70: 73–117. WILLIAMS,R., GOMES,C., and SELMAN, B. (2003) Backdoors to typical case complexity. In Proc. 18th Int. Joint Conf. on Artiﬁcial Intelligence, pp. 1173– 1178, Acapulco. WINSTON, P. (1975) Learning structural descriptions from example. In The Psychology of Computer Vision, ed. P. Winston, pp. 157–209, McGraw-Hill. WITOELAR,A., BIEHL,M., GHOSH,A., and HAMMER, B. (2008) Learning dynamics and robustness of vector quantization and neural gas. Neurocom- puting 71: 1210–1219. WITTEN,I., and FRANK, E. (2005) Data Mining: Practical Machine Learning Tools and Techniques. Morgan Kaufmann. WITTGENSTEIN, L. (1954) Philosophical investigations. Phil. Rev. LXIII: 530– 559. WOLOSZYN,M., STAUFFER,D., and KULAKOWSKI, K. (2007) Order–disorder phase transition in a cliquey social network. Eur. Phys. J. B 57: 331 335. WU,X., and LEVY, W. (2005) Increasing CS and US longevity increases the learnable trace interval. Neurocomputing 65–66: 283–289. XU,K., and LI, W. (2000) Exact phase transitions in random constraint satis- faction problems. J. Artiﬁcial Intelligence Res. 12: 93–103. XU,K., and LI, W. (2006) Many hard examples in exact phase transitions. Theor. Computer Sci. 355: 291–302. YULE, G. (1925) A mathematical theory of evolution, based on the conclusions of Dr. J. C. Willis, F.R.S. Phil. Trans. Roy. Soc. London B 213: 221–87. ZHOU, H. (2010) Solution space heterogeneity of the random k-satisﬁability problem: theory and simulations. In Proc. Int. Workshop on Statistical Me- chanical Informatics, Tokyo. ZHOU,H., and MA, H. (2009) Communities of solutions in single solution clus- ters of a random k-satisﬁability formula. Phys. Rev. E 80: 066 108. ZWEIG,K., PALLA,G., and VICSEK, T. (2010) What makes a phase transition? Analysis of the random satisﬁability problem. Physica A: Statistical Mechan- ics and its Applications 389: 1501–1511. Index abstraction, 338 animal visual system, 314 aromatic rings, 340 asymptotic behavior, 85–86, 213 attractor, 147, 236, 314, 317 avalanche process, 324 Avogadro number, 16 Axelrod model, 307 backbone, 60–61 backdoor, 61–64 batch setting, 94 Bayes’ decision rule, 95 Bayes error, 95 Bethe lattice, 39 bifurcations, 317 blind spot, 231, 329, 333 Boltzman constant, 19 boolean algebra, 169 attribute, 169 expression, 108 function, 94 matrix, 71 Bose–Einstein gas, 301 canonical ensemble, 21 categorization, 92 cavity graph, 40, 67 cavity method, 35, 39–42, 68, 311 cavity method approach, 39 ChangeToNegative, 225 ChangeToPositive, 225 Church−Turing thesis, 4 classiﬁcation classiﬁer, 95 problem, 107 rule, 340 clique, 214, 309 k-clique, 302 closed world assumption, 117, 223 cluster of solutions, 59, 315 coexisting opinions, 306 coin tossing, 322, 323 collective behavior, 304, 309 complex systems, 300, 301, 302, 309, 310, 311, 333 complexity computational, 3 covering test, 111, 189, 195 polynomial, 6 space, 5 time, 5 typical, 8 worst case, 5 computational cost, 219, 229 computational grids, 309 concept, 93, 112 approximation, 244, 253 n-arity, 117 0-arity, 116, 129 binary, 113 description of, 339 approximated, 335 k-DNF, 169 375 376 Index concept (cont.) identiﬁcation of, 229, 231 learning of, 93–106, 124 unary, 113 conditioned stimulus, 316 connected component, 45 connected formula, 189, 191 constraint, 71 binary, 340 density, 79 propagation, 78, 214 satisfaction problem, 8, 70, 156 store, 79 tightness, 79, 210 constraint graph, 73, 79, 81, 82, 87, 89, 192, 193, 194, 205, 210, 214, 334 constraint logic programming, 78–79 constraint satisfaction problem (CSP), 8, 44, 70–73, 168, 190, 206, 327, 334 binary, 73, 79 ChainSAT, 77 constraint propagation, 78 continuous, 73 discrete, 73 FC-CBJ-DKC-FP, 82 generative model for, 79–81 MaxCSP, 77, 332 solver, 74, 214 exact, 332 symbolic, 73 WalkSAT, 77 control parameter, 26, 52, 187, 308, 309, 315, 331 coordination frequency, 316 counter-imitative interaction, 308 coupling, 35 covering test, 109, 119, 178, 185, 220, 333 critical density, 315 point, 30 temperature, 31, 32 value, 43, 52, 57, 208, 209, 210, 213, 327 cultural dynamics, 304, 307 DATALOG, 71, 117, 164, 186, 332 decidability, 3 decision tree, 125, 127, 178 degree of freedom, 13 disordered state, 315 disordered systems, 311 distance, 100 Hamming, 59 Django, 214 domain knowledge, 337 easy problems, 233 electroencephalograms, 313 emerging phenomena, 309 empirical risk, 96 energy, 36, 56, 151, 340 function, 53 ensemble behavior, 16, 313 entropy, 19, 36, 126 density, 58 ergodic system, 18 Euclidean distance, 161 Euler–Lagrange equations, 14 examples counter-example, 98 generation of, 223 negative, 94, 171 positive, 94 training, 94 set of, 96, 98 explosive percolation, 303 exponential random graphs, 302 eye-blink paradigm, 316 Index 377 feasible problems, 233 ﬁnite state automaton (FSA), 4, 266–269 deterministic (DFA), 266 minimal, 267 nondeterministic (NFA), 266, 268 ﬁrst-order logic, 70, 111, 185, 339 clause representation, 113 Horn clause, 78, 113–115, 119 language, 114 language for, 337 predicate calculus for, 113 ﬁrst-order phase transition, 9, 24, 313 ﬂocking model, 315 formal languages (grammars), 122 Fourier analysis, 347 fractal, 303 fractal distribution, 314 fractal topology, 303 free energy, 19, 25, 27, 29, 30 density, 36 frustration, 35 gene expression, 311 generalization, 93 generalization error, 147 lattice structure, least general, 102 lgg, 102 maximally general specialization, 102 more-general-than relation, 101, 125 msg, 102 relation of generality, 101 θ-subsumption, 118–119 generalization cone, generalized coordinates, 13 generating function, 56 generative model, 50, 86–89, 185 Gestalt, 314 Gibbs distribution, 21, 34, 162 Gibbs rule, 147 G-NET, goal-directed behavior, 313 goods, 71, 81, 90 grammar, 167, 264 alphabet, 262 context-free, 260 language, 122 context-sensitive, 260 hierarchy of, 259, 268 language, 122, 263 regular, 260, 264 unrestricted, 260 grand canonical ensemble, 22 graph, 45 betweenness, 311 centrality, 311 colored, 74, 333 complete, 306 degree of, 47 degree distribution of, 311 exponential random, 48 factor, 53, 67 ensemble of, 45, 302 random, 45–49 scale-free, 48 small-world, 48, 301 structure, 195 greedy search, 125 ground assertion, 110, 114 ground state energy, 56 Hamiltonian, 15, 33, 146 Hamming distance, 59 hard problem, 233, 331 instance of, 200 378 Index Helmholtz free energy, 22 heuristics back-jumping, 76, 77 clause learning, 64 constraint propagation, 76 information gain, 125, 131, 221, 329, 331 intelligent backtracking, 76 look-ahead, 65, 76, 77 minimum description length (MDL), 129, 134, 226 most constrained variables, 77 variable reordering, 75 high-energy pattern, 314 homophily, 307 hypothesis, 94–96 complete, 99 correct, 99 coverage of, 101 discriminant, 238 generation, 240 language, 99, 341 lattice, 125 space, 96, 98, 124 i.i.d. sampling, 96 imitative interaction, 308 incompleteness theorem, 2 inductive logic programming (ILP), 111, 114, 243 inverse entailment, 135 inﬁnite systems, 306 interaction, 29 interaction energy, 309 Internet, 309 Ising model, 26–32, 53, 54 1D model, 27–29 2D model, 29–32 Ising perceptron, 149 keratocytes, 315 Lagrangian function, 14 Las Vegas search algorithm, 249 learning, 92–98 artiﬁcial problem, 222–225 bottom-up strategy, 228 by analogy, 92 by candidate elimination, 106 by doing, 92 by explanation, 92 by trials and errors, 92 dropping condition rule in, 170 evolutionary, 311 explanation-based, 347 from examples, 140 inductive, 94 inductive criterion in, 97 knowledge discovery in, 221 multi-strategy, 132 negative instance, 108 positive example, 172 positive instance, 108 rote, 93 rule, 128 similarity-based, 347 structured example, 336 supervised, 94 k-term DNF concept, 159 theory discovery in, 92 learning event, 108 learning example, 94, 189 learning problem, 96, 339, 340 learning set, 94, 126, 224 local interaction, 25 local search, 77 logic programming, 73, 78 logical circuit, 171 logical model, 196 long-range interactions, 27, 77 long-range phenomenon, 25 Index 379 loss function, 95, 125 low congestion, 309 lung cancer, 315 machine learning, 1, 78, 92, 96, 124, 177, 185, 311, 319, 336 macroscopic order, 303 macrostate, 20 majority rule, 306 Markov chains, 122 logical network, 257 process, 310 matching, 120 complexity of, 342 algorithm for, 214 problem of, 109, 188, 192, 220, 340, 349 string, 122 mean ﬁeld, 32 mean ﬁeld approximation, 306 mean ﬁeld theory, 32–33 mechanical troubleshooting, 347 mesoscopic state transitions, 313 metastable state, 306 microcanonical ensemble, 20 microscopic disorder, 303 microscopic Hamiltonian, 302 microstate, 19 minimum description length (MDL), 129, 134, 226 model, A, 80 B, 80, 81, 86, 183, 191, 206 C, 81 D, 81, 87 E, 86 ER1, 47 ER2, 47 RB, 88, 219 RL, 185, 189, 202, 209, 223, 225, 227 model selection, 98 Monte Carlo process, 197 simulation, 32 multi-stability, 315 mushy region, 339, 344 mutagenesis, 339 mutagenicity, 340 nearest-neighbor interaction, 30 negative literal, 54 network adaptive routing algorithm, 310 biological, 310 complex, 301, 310 computer, 309 degree of, 301 gene regulatory, 310 neural, 106, 315 artiﬁcial, 140 random, 303 boolean, 303 scale-free, 302, 311 small-world, 36, 301, 303, 306, 310 social, 304 static routing algorithm for, 310 stochastic routing, 309 topologies for, 302 World Wide Web, 309 neural activity, 314 ensemble properties, 316 network, 141 states, 313 neuron, McCulloch–Pitts model, 143 neuron model, 141 NO region, 198, 212, 223, 233, 254, 329, 330 380 Index nogoods, 64, 71, 84, 86 NP-complete, 44, 49, 70 opinion dynamics, 305 order parameter, 26, 43, 52, 309, 314, 316 ordered state, 315 overﬁtting, 97, 128 packet trafﬁc dynamics, 309 paleocortex, 313 partition coefﬁcient, 340 partition function, 21, 25, 27, 28, 30, 31, 33, 34, 36, 37, 48 pattern selection, 314 percept of oscillation, 315 perceptron, 143 decision boundary, 145 error back-propagation, 144 feed-forward network, 144 hidden layer, 144 hidden unit, 144 input layer, 143 multi-layer (MLP), 144 output layer of, 144 soft-committee machine, 150 spherical, 146 percepts, 93, 315 performance, 93 measure of, 145 phase space, 16 phase transition, 9, 23–26, 29, 30, 31, 45, 48, 52, 81, 83, 89, 149, 160, 173, 198, 217, 220, 254, 301, 309, 313, 315, 317, 321, 322, 331, 334, 337, 339 clustering, 59 continuous, 315 control parameter for, 88 critical value for, 82, 84, 85, 88 discontinuous, 316 edge, 239, 339 in perception, 314 mushy region, 82, 83 phase transition region, 219, 235 physical particles, 302 systems, 313 plateau, 198, 255 point particle, 12 Poisson approximation, 47 random graphs, 48 positive examples, positive literal, 54 post-pruning, 128 potential energy, 14, 27 power law, 314 pre-pruning, 128 predictive accuracy, 229 preferential attachment, 48 preﬁx tree acceptor (PTA), 273 problem ensemble, 45 ProblemGeneration, 225 prolog, 78 propositional calculus, 49 framework, 336 learner, 175 C4.5, 156, 331 C4.5rules, 176 C5.0, 177 RIPPER, 176, 177 learning, 152, 169, 183, 332 logic, 49, 104 matching, 336 propositionalization, 336 rule, 127 theory, 110 Index 381 quantum mechanics, 19 quenched disorder, 33–36, 54, 146, 151 random graph, 44, 47, 87, 301, 334 real learning applications, 328, 339 problems, 328 recursive deﬁnition, 117 regular grammar, 260, 264, 265 regularization, 98 relation 0-arity, 116 binary, 71, 188, 339 binary predicate, 192, 340 n-ary, 112 target, 188 universal binary relational concept, 113 framework, 129 generality relation, 102 inclusion relation, 102 learner, 131, 189, 336, 339 C-PROGOL, 134 ENIGMA , 347 FOIL, 111, 131, 221, 225, 230, 247, 330 G-Net, 133, 221, 228, 341 P-PROGOL, 134 PFOIL, 176 PROGOL, 134, 221, 228 SMART+, 132, 221, 227, 330 STILL, 228 top-down, 227, 241 learning, 114, 139, 163, 166, 185, 220, 231, 319, 336, 338, 339 learning problem, 221 representation, 111 renormalization group, 303 replica approach, 37 method, 37–39, 311 symmetry, 38, 150 theory, 35 representation ⟨attribute, value⟩, 108 clause, 49, 54, 111 CNF, 44, 174 decision rules, 125 DNF, 110, 125 multiple vector, 114 propositional logic, 107 relational, 111 tabular, 70, 108, 112 representation language, 106–122 resolution, 110 risk empirical, 96 minimization of, 97 expected, 95 rule template, 169 salamander retina, 317 SAT, 44, 49–53, 168, 275, 300, 327, 334 k-SAT, 50, 68, 274, 322 k-SAT problem, 50 2-SAT, 50, 275 (2+ p)-SAT, 63, 175 3-SAT, 50, 56, 63, 136, 275, 320, 327 clause satisfaction, 49 complete SAT solver, 63, 332 conjunctive normal form, 64 GSAT algorithm, 137 incomplete SAT solver, 63 MaxSAT, 64, 65, 77, 138, 332 phase, 52, 59 problem, 8, 49–63, 315 solver, 183 382 Index SAT (cont.) UNSAT phase, 52, 60, 326 WalkSAT, 161 satisﬁability, 49 scale-free dynamics, 314 network, 36, 48 search with replacement, 198 without replacement, 198 searching backtrack, 74, 196, 243 algorithm for, 215 beam, 132, 227 bench, 136, 256 bottom-up, 135 data-driven strategy for, 247 Davis–Putnam–Logemann– Loveland (DPLL) algorithm, 64 exits from plateau, 136 general-to-speciﬁc, 247 generalization strategy for, 125 genetic algorithms for, 65, 133, 228 hill-climbing, 131, 227 hypothesize-and-test, 247 local, 175 local minima in, 136 multi-strategy, 132 plateau, 136, 155 random walk, 65 restart in, 77 simulated annealing, 65 specialization strategy for, 125 top-down, 131 strategies for, 125 second-order phase transition, 9, 25, 314 self-averaging, 36–37 sequence, 120 generative process for, 121 sequence tagging, 120, 122 SFind, 249, 251 Sherrington–Kirkpatrick model, 35, 39 short-range interaction, 27 smart algorithms, 214–215 social dynamics, 304 inﬂuence, 307 networks, 304 system, 309 solvable problem, 200 spatio-temporal dynamics, 310 patterns, 314 specialization tree, 242 spiking activity, 317 spin glass, 39 spin coupling in, 27, 33, 34 spin glass physics, 311 staircase dynamics, 307 statistical mechanics, 16, 140, 302, 304 statistical physics, 11, 12, 16, 44, 89, 140, 301, 303, 309, 314, 317, 322, 334 stochastic algorithms, 77 neuronal dynamics, 315 search, 197, 249 string, 120–122, 263 string preﬁx, 263 structural communities, 302 entropy, 303 substitution, allowed, 196 subsumption 165 index, 165 partial subsumption test, 165 θ-subsumption, 118–119, survey propagation, 66, 311 algorithm, 59 Index 383 belief propagation, 311 decimation, 68 support vector machines (SVM), 106, 154 kernel, 155 Gaussian, 156 MI-SVM, 155 symmetry-breaking process, 25 target concept, 98, 222, 223, 231, 237, 247 temperature, 302 test set, 224 thermodynamic equilibrium, 18 thermodynamic limit, 25, 27, 36, 147 threshold phenomenon, 320 topological transition, 302 total energy, 27, 29, 54 trace conditioning paradigm, 316 transformation, 169 Turing machine, 4 typicality, 45 undecidability, 2, 3 unit clause, 64 propagation, 65 universal automation (UA), universe, 186, 341 unsatisﬁable SAT problem, 49 unsolvable problem, 200 Vapnik–Chervonenkis bounds, 153 version space, 105, 153 visual cortex, 314 voter dynamics, 306 water boiling, 321 freezing, 321 wave patterns in brains, 317 whirling behavior of keratocytes, 315 Wilson–Cowan equations, 315 YES region, 198, 212, 223, 234, 244, 329, 330","libVersion":"0.3.2","langs":""}