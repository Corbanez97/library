{"path":"Notes/Probability - The Science of Uncertainty and Data/books/Introduction to Probability - Short Version.pdf","text":"Introduction to Probability SECOND EDITION Dimitri P. Bertsekas and John N. Tsitsiklis Massachusetts Institute of Technology Selected Summary Material – All Rights Reserved 1 Sample Space and Probability Excerpts from Introduction to Probability: Second Edition by Dimitri P. Bertsekas and John N. Tsitsiklis c⃝ Massachusetts Institute of Technology Contents 1.1. Sets . . . . . . . . . . . . . . . . . . . . . . . . . . . p. 3 1.2. Probabilistic Models . . . . . . . . . . . . . . . . . . . . p. 6 1.3. Conditional Probability . . . . . . . . . . . . . . . . . p. 18 1.4. Total Probability Theorem and Bayes’ Rule . . . . . . . . p. 28 1.5. Independence . . . . . . . . . . . . . . . . . . . . . . p. 34 1.6. Counting . . . . . . . . . . . . . . . . . . . . . . . p. 44 1.7. Summary and Discussion . . . . . . . . . . . . . . . . p. 51 Problems . . . . . . . . . . . . . . . . . . . . . . . . p. 53 1 2 From Introduction to Probability, by Bertsekas and Tsitsiklis Chap. 1 1.1 SETS 1.2 PROBABILISTIC MODELS Elements of a Probabilistic Model • The sample space Ω, which is the set of all possible outcomes of an experiment. • The probability law, which assigns to a set A of possible outcomes (also called an event) a nonnegative number P(A) (called the proba- bility of A) that encodes our knowledge or belief about the collective “likelihood” of the elements of A. The probability law must satisfy certain properties to be introduced shortly. Probability Axioms 1. (Nonnegativity) P(A) ≥ 0, for every event A. 2. (Additivity) If A and B are two disjoint events, then the probability of their union satisﬁes P(A ∪ B) = P(A) + P(B). More generally, if the sample space has an inﬁnite number of elements and A1, A2, . . . is a sequence of disjoint events, then the probability of their union satisﬁes P(A1 ∪ A2 ∪ · · ·) = P(A1) + P(A2) + · · · . 3. (Normalization) The probability of the entire sample space Ω is equal to 1, that is, P(Ω) = 1. Sec. 1.2 Probabilistic Models 3 Discrete Probability Law If the sample space consists of a ﬁnite number of possible outcomes, then the probability law is speciﬁed by the probabilities of the events that consist of a single element. In particular, the probability of any event {s1, s2, . . . , sn} is the sum of the probabilities of its elements: P ( {s1, s2, . . . , sn}) = P(s1) + P(s2) + · · · + P(sn). Discrete Uniform Probability Law If the sample space consists of n possible outcomes which are equally likely (i.e., all single-element events have the same probability), then the proba- bility of any event A is given by P(A) = number of elements of A 4 From Introduction to Probability, by Bertsekas and Tsitsiklis Chap. 1 1.3 CONDITIONAL PROBABILITY Properties of Conditional Probability • The conditional probability of an event A, given an event B with P(B) > 0, is deﬁned by P(A | B) = P(A ∩ B) Sec. 1.5 Independence 5 1.5 INDEPENDENCE Independence • Two events A and B are said to be independent if P(A ∩ B) = P(A)P(B). If in addition, P(B) > 0, independence is equivalent to the condition P(A | B) = P(A). • If A and B are independent, so are A and Bc. • Two events A and B are said to be conditionally independent, given another event C with P(C) > 0, if P(A ∩ B | C) = P(A | C)P(B | C). If in addition, P(B ∩ C) > 0, conditional independence is equivalent to the condition P(A | B ∩ C) = P(A | C). • Independence does not imply conditional independence, and vice versa. Deﬁnition of Independence of Several Events We say that the events A1, A2, . . . , An are independent if P ( ⋂ i∈S Ai ) = ∏ i∈S P(Ai), for every subset S of {1, 2, . . . , n}. 6 From Introduction to Probability, by Bertsekas and Tsitsiklis Chap. 1 1.6 COUNTING The Counting Principle Consider a process that consists of r stages. Suppose that: (a) There are n1 possible results at the ﬁrst stage. (b) For every possible result at the ﬁrst stage, there are n2 possible results at the second stage. (c) More generally, for any sequence of possible results at the ﬁrst i − 1 stages, there are ni possible results at the ith stage. Then, the total number of possible results of the r-stage process is n1n2 · · · nr. Summary of Counting Results • Permutations of n objects: n!. • k-permutations of n objects: n!/(n − k)!. • Combinations of k out of n objects: ( n k ) = n! 2 Discrete Random Variables Excerpts from Introduction to Probability: Second Edition by Dimitri P. Bertsekas and John N. Tsitsiklis c⃝ Massachusetts Institute of Technology Contents 2.1. Basic Concepts . . . . . . . . . . . . . . . . . . . . . p. 72 2.2. Probability Mass Functions . . . . . . . . . . . . . . . p. 74 2.3. Functions of Random Variables . . . . . . . . . . . . . . p. 80 2.4. Expectation, Mean, and Variance . . . . . . . . . . . . . p. 81 2.5. Joint PMFs of Multiple Random Variables . . . . . . . . . p. 92 2.6. Conditioning . . . . . . . . . . . . . . . . . . . . . . p. 97 2.7. Independence . . . . . . . . . . . . . . . . . . . . . . p. 109 2.8. Summary and Discussion . . . . . . . . . . . . . . . . p. 115 Problems . . . . . . . . . . . . . . . . . . . . . . . . p. 119 7 8 From Introduction to Probability, by Bertsekas and Tsitsiklis Chap. 2 2.1 BASIC CONCEPTS Main Concepts Related to Random Variables Starting with a probabilistic model of an experiment: • A random variable is a real-valued function of the outcome of the experiment. • A function of a random variable deﬁnes another random variable. • We can associate with each random variable certain “averages” of in- terest, such as the mean and the variance. • A random variable can be conditioned on an event or on another random variable. • There is a notion of independence of a random variable from an event or from another random variable. Concepts Related to Discrete Random Variables Starting with a probabilistic model of an experiment: • A discrete random variable is a real-valued function of the outcome of the experiment that can take a ﬁnite or countably inﬁnite number of values. • A discrete random variable has an associated probability mass func- tion (PMF), which gives the probability of each numerical value that the random variable can take. • A function of a discrete random variable deﬁnes another discrete random variable, whose PMF can be obtained from the PMF of the original random variable. Sec. 2.4 Expectation, Mean, and Variance 9 2.2 PROBABILITY MASS FUNCTIONS Calculation of the PMF of a Random Variable X For each possible value x of X: 1. Collect all the possible outcomes that give rise to the event {X = x}. 2. Add their probabilities to obtain pX (x). 2.3 FUNCTIONS OF RANDOM VARIABLES 2.4 EXPECTATION, MEAN, AND VARIANCE Expectation We deﬁne the expected value (also called the expectation or the mean) of a random variable X, with PMF pX , by E[X] = ∑ x xpX (x). Expected Value Rule for Functions of Random Variables Let X be a random variable with PMF pX , and let g(X) be a function of X. Then, the expected value of the random variable g(X) is given by E[ g(X) ] = ∑ x g(x)pX (x). 10 From Introduction to Probability, by Bertsekas and Tsitsiklis Chap. 2 Variance The variance var(X) of a random variable X is deﬁned by var(X) = E [( X − E[X] )2] , and can be calculated as var(X) = ∑ x ( x − E[X])2pX (x). It is always nonnegative. Its square root is denoted by σX and is called the standard deviation. Mean and Variance of a Linear Function of a Random Variable Let X be a random variable and let Y = aX + b, where a and b are given scalars. Then, E[Y ] = aE[X] + b, var(Y ) = a2 var(X). Variance in Terms of Moments Expression var(X) = E[X 2] − ( E[X])2. Sec. 2.5 Joint PMFs of Multiple Random Variables 11 2.5 JOINT PMFS OF MULTIPLE RANDOM VARIABLES Summary of Facts About Joint PMFs Let X and Y be random variables associated with the same experiment. • The joint PMF pX,Y of X and Y is deﬁned by pX,Y (x, y) = P(X = x, Y = y). • The marginal PMFs of X and Y can be obtained from the joint PMF, using the formulas pX (x) = ∑ y pX,Y (x, y), pY (y) = ∑ x pX,Y (x, y). • A function g(X, Y ) of X and Y deﬁnes another random variable, and E[ g(X, Y ) ] = ∑ x ∑ y g(x, y)pX,Y (x, y). If g is linear, of the form aX + bY + c, we have E[aX + bY + c] = aE[X] + bE[Y ] + c. • The above have natural extensions to the case where more than two random variables are involved. 12 From Introduction to Probability, by Bertsekas and Tsitsiklis Chap. 2 2.6 CONDITIONING Summary of Facts About Conditional PMFs Let X and Y be random variables associated with the same experiment. • Conditional PMFs are similar to ordinary PMFs, but pertain to a universe where the conditioning event is known to have occurred. • The conditional PMF of X given an event A with P(A) > 0, is deﬁned by pX|A(x) = P(X = x | A) and satisﬁes ∑ x pX|A(x) = 1. • If A1, . . . , An are disjoint events that form a partition of the sample space, with P(Ai) > 0 for all i, then pX (x) = n∑ i=1 P(Ai)pX|Ai(x). (This is a special case of the total probability theorem.) Furthermore, for any event B, with P(Ai ∩ B) > 0 for all i, we have pX|B(x) = n∑ i=1 P(Ai | B)pX|Ai∩B(x). • The conditional PMF of X given Y = y is related to the joint PMF by pX,Y (x, y) = pY (y)pX|Y (x | y). • The conditional PMF of X given Y can be used to calculate the marginal PMF of X through the formula pX (x) = ∑ y pY (y)pX|Y (x | y). • There are natural extensions of the above involving more than two random variables. Sec. 2.6 Conditioning 13 Summary of Facts About Conditional Expectations Let X and Y be random variables associated with the same experiment. • The conditional expectation of X given an event A with P(A) > 0, is deﬁned by E[X | A] = ∑ x xpX|A(x). For a function g(X), we have E[g(X) | A ] = ∑ x g(x)pX|A(x). • The conditional expectation of X given a value y of Y is deﬁned by E[X | Y = y] = ∑ x xpX|Y (x | y). • If A1, . . . , An be disjoint events that form a partition of the sample space, with P(Ai) > 0 for all i, then E[X] = n∑ i=1 P(Ai)E[X | Ai]. Furthermore, for any event B with P(Ai ∩ B) > 0 for all i, we have E[X | B] = n∑ i=1 P(Ai | B)E[X | Ai ∩ B]. • We have E[X] = ∑ y pY (y)E[X | Y = y]. 14 From Introduction to Probability, by Bertsekas and Tsitsiklis Chap. 2 2.7 INDEPENDENCE Summary of Facts About Independent Random Variables Let A be an event, with P(A) > 0, and let X and Y be random variables associated with the same experiment. • X is independent of the event A if pX|A(x) = pX(x), for all x, that is, if for all x, the events {X = x} and A are independent. • X and Y are independent if for all pairs (x, y), the events {X = x} and {Y = y} are independent, or equivalently pX,Y (x, y) = pX (x)pY (y), for all x, y. • If X and Y are independent random variables, then E[XY ] = E[X] E[Y ]. Furthermore, for any functions g and h, the random variables g(X) and h(Y ) are independent, and we have E[ g(X)h(Y ) ] = E[g(X) ] E[h(Y ) ] . • If X and Y are independent, then var(X + Y ) = var(X) + var(Y ). Sec. 2.8 Summary and Discussion 15 2.8 SUMMARY AND DISCUSSION Summary of Results for Special Random Variables Discrete Uniform over [a, b]: pX (k) = { 1 3 General Random Variables Excerpts from Introduction to Probability: Second Edition by Dimitri P. Bertsekas and John N. Tsitsiklis c⃝ Massachusetts Institute of Technology Contents 3.1. Continuous Random Variables and PDFs . . . . . . . . . p. 140 3.2. Cumulative Distribution Functions . . . . . . . . . . . . p. 148 3.3. Normal Random Variables . . . . . . . . . . . . . . . . p. 153 3.4. Joint PDFs of Multiple Random Variables . . . . . . . . . p. 158 3.5. Conditioning . . . . . . . . . . . . . . . . . . . . . p. 164 3.6. The Continuous Bayes’ Rule . . . . . . . . . . . . . . . p. 178 3.7. Summary and Discussion . . . . . . . . . . . . . . . . p. 182 Problems . . . . . . . . . . . . . . . . . . . . . . . . p. 184 17 18 From Introduction to Probability, by Bertsekas and Tsitsiklis Chap. 3 3.1 CONTINUOUS RANDOM VARIABLES AND PDFS Summary of PDF Properties Let X be a continuous random variable with PDF fX. • fX (x) ≥ 0 for all x. • ∫ ∞ −∞ fX(x) dx = 1. • If δ is very small, then P ([x, x + δ]) ≈ fX (x) · δ. • For any subset B of the real line, P(X ∈ B) = ∫ B fX (x) dx. Expectation of a Continuous Random Variable and its Properties Let X be a continuous random variable with PDF fX. • The expectation of X is deﬁned by E[X] = ∫ ∞ −∞ xfX (x) dx. • The expected value rule for a function g(X) has the form E[ g(X) ] = ∫ ∞ −∞ g(x)fX (x) dx. • The variance of X is deﬁned by var(X) = E[( X − E[X])2] = ∫ ∞ −∞ ( x − E[X])2fX (x) dx. • We have 0 ≤ var(X) = E[X 2] − (E[X])2. • If Y = aX + b, where a and b are given scalars, then E[Y ] = aE[X] + b, var(Y ) = a2var(X). Sec. 3.2 Cumulative Distribution Functions 19 3.2 CUMULATIVE DISTRIBUTION FUNCTIONS Properties of a CDF The CDF FX of a random variable X is deﬁned by FX (x) = P(X ≤ x), for all x, and has the following properties. • FX is monotonically nondecreasing: if x ≤ y, then FX (x) ≤ FX (y). • FX (x) tends to 0 as x → −∞, and to 1 as x → ∞. • If X is discrete, then FX (x) is a piecewise constant function of x. • If X is continuous, then FX (x) is a continuous function of x. • If X is discrete and takes integer values, the PMF and the CDF can be obtained from each other by summing or diﬀerencing: FX (k) = k∑ i=−∞ pX (i), pX (k) = P(X ≤ k) − P(X ≤ k − 1) = FX (k) − FX (k − 1), for all integers k. • If X is continuous, the PDF and the CDF can be obtained from each other by integration or diﬀerentiation: FX (x) = ∫ x −∞ fX (t) dt, fX(x) = dFX 20 From Introduction to Probability, by Bertsekas and Tsitsiklis Chap. 3 3.3 NORMAL RANDOM VARIABLES Normality is Preserved by Linear Transformations If X is a normal random variable with mean µ and variance σ2, and if a ̸= 0, b are scalars, then the random variable Y = aX + b is also normal, with mean and variance E[Y ] = aµ + b, var(Y ) = a2σ2. CDF Calculation for a Normal Random Variable For a normal random variable X with mean µ and variance σ2, we use a two-step procedure. (a) “Standardize” X, i.e., subtract µ and divide by σ to obtain a standard normal random variable Y . (b) Read the CDF value from the standard normal table: P(X ≤ x) = P ( X − µ Sec. 3.4 Normal Random Variables 2122 From Introduction to Probability, by Bertsekas and Tsitsiklis Chap. 3 3.4 JOINT PDFS OF MULTIPLE RANDOM VARIABLES Summary of Facts about Joint PDFs Let X and Y be jointly continuous random variables with joint PDF fX,Y . • The joint PDF is used to calculate probabilities: P ((X, Y ) ∈ B) = ∫ ∫ (x,y)∈B fX,Y (x, y) dx dy. • The marginal PDFs of X and Y can be obtained from the joint PDF, using the formulas fX (x) = ∫ ∞ −∞ fX,Y (x, y) dy, fY (y) = ∫ ∞ −∞ fX,Y (x, y) dx. • The joint CDF is deﬁned by FX,Y (x, y) = P(X ≤ x, Y ≤ y), and determines the joint PDF through the formula fX,Y (x, y) = ∂2FX,Y Sec. 3.5 Conditioning 23 3.5 CONDITIONING Conditional PDF Given an Event • The conditional PDF fX|A of a continuous random variable X, given an event A with P(A) > 0, satisﬁes P(X ∈ B | A) = ∫ B fX|A(x) dx. • If A is a subset of the real line with P(X ∈ A) > 0, then fX|{X∈A}(x) =    fX(x) 24 From Introduction to Probability, by Bertsekas and Tsitsiklis Chap. 3 Summary of Facts About Conditional Expectations Let X snd Y be jointly continuous random variables, and let A be an event with P(A) > 0. • Deﬁnitions: The conditional expectation of X given the event A is deﬁned by E[X | A] = ∫ ∞ −∞ xfX|A(x) dx. The conditional expectation of X given that Y = y is deﬁned by E[X | Y = y] = ∫ ∞ −∞ xfX|Y (x | y) dx. • The expected value rule: For a function g(X), we have E[g(X) | A ] = ∫ ∞ −∞ g(x)fX|A(x) dx, and E[ g(X) | Y = y] = ∫ ∞ −∞ g(x)fX|Y (x | y) dx. • Total expectation theorem: Let A1, A2, . . . , An be disjoint events that form a partition of the sample space, and assume that P(Ai) > 0 for all i. Then, E[X] = n∑ i=1 P(Ai)E[X | Ai]. Similarly, E[X] = ∫ ∞ −∞ E[X | Y = y]fY (y) dy. • There are natural analogs for the case of functions of several random variables. For example, E[ g(X, Y ) | Y = y] = ∫ g(x, y)fX|Y (x | y) dx, and E[ g(X, Y ) ] = ∫ E[ g(X, Y ) | Y = y]fY (y) dy. Sec. 3.5 Conditioning 25 Independence of Continuous Random Variables Let X and Y be jointly continuous random variables. • X and Y are independent if fX,Y (x, y) = fX (x)fY (y), for all x, y. • If X and Y are independent, then E[XY ] = E[X] E[Y ]. Furthermore, for any functions g and h, the random variables g(X) and h(Y ) are independent, and we have E[ g(X)h(Y ) ] = E[g(X) ] E[h(Y ) ] . • If X and Y are independent, then var(X + Y ) = var(X) + var(Y ). 26 From Introduction to Probability, by Bertsekas and Tsitsiklis Chap. 3 3.6 BAYES’ RULE AND APPLICATIONS IN INFERENCE Bayes’ Rule Relations for Random Variables Let X and Y be two random variables. • If X and Y are discrete, we have for all x, y with pX (x) ̸= 0, pY (y) ̸= 0, pX (x)pY |X (y | x) = pY (y)pX|Y (x | y), and the terms on the two sides in this relation are both equal to pX,Y (x, y). • If X is discrete and Y is continuous, we have for all x, y with pX (x) ̸= 0, fY (y) ̸= 0, pX (x)fY |X (y | x) = fY (y)pX|Y (x | y), and the terms on the two sides in this relation are both equal to lim δ→0 P(X = x, y ≤ Y ≤ y + δ) Sec. 3.7 Summary and Discussion 27 3.7 SUMMARY AND DISCUSSION Summary of Results for Special Random Variables Continuous Uniform Over [a, b]: fX (x) =    1 4 Further Topics on Random Variables Excerpts from Introduction to Probability: Second Edition by Dimitri P. Bertsekas and John N. Tsitsiklis c⃝ Massachusetts Institute of Technology Contents 4.1. Derived Distributions . . . . . . . . . . . . . . . . . . p. 202 4.2. Covariance and Correlation . . . . . . . . . . . . . . . p. 217 4.3. Conditional Expectation and Variance Revisited . . . . . . p. 222 4.4. Transforms . . . . . . . . . . . . . . . . . . . . . . p. 229 4.5. Sum of a Random Number of Independent Random Variables p. 240 4.6. Summary and Discussion . . . . . . . . . . . . . . . . p. 244 Problems . . . . . . . . . . . . . . . . . . . . . . . . p. 246 29 30 From Introduction to Probability, by Bertsekas and Tsitsiklis Chap. 4 4.1 DERIVED DISTRIBUTIONS Calculation of the PDF of a Function Y = g(X) of a Continuous Random Variable X 1. Calculate the CDF FY of Y using the formula FY (y) = P ( g(X) ≤ y) = ∫ {x | g(x)≤y} fX (x) dx. 2. Diﬀerentiate to obtain the PDF of Y : fY (y) = dFY Sec. 4.2 Covariance and Correlation 31 PDF Formula for a Strictly Monotonic Function of a Continuous Random Variable Suppose that g is strictly monotonic and that for some function h and all x in the range of X we have y = g(x) if and only if x = h(y). Assume that h is diﬀerentiable. Then, the PDF of Y in the region where fY (y) > 0 is given by fY (y) = fX( h(y) ) ∣ ∣ ∣ ∣ dh 32 From Introduction to Probability, by Bertsekas and Tsitsiklis Chap. 4 4.3 CONDITIONAL EXPECTATION AND VARIANCE REVISITED Law of Iterated Expectations: E[E[X | Y ]] = E[X]. Law of Total Variance: var(X) = E[var(X | Y ) ] + var ( E[X | Y ]) . Properties of the Conditional Expectation and Variance • E[X | Y = y] is a number whose value depends on y. • E[X | Y ] is a function of the random variable Y , hence a random vari- able. Its value is E[X | Y = y] whenever the value of Y is y. • E[E[X | Y ]] = E[X] (law of iterated expectations). • E[X | Y = y] may be viewed as an estimate of X given Y = y. The corresponding error E[X | Y ] − X is a zero mean random variable that is uncorrelated with E[X | Y ]. • var(X | Y ) is a random variable whose value is var(X | Y = y) whenever the value of Y is y. • var(X) = E[ var(X | Y ) ] + var ( E[X | Y ]) (law of total variance). Sec. 4.4 Transforms 33 4.4 TRANSFORMS Summary of Transforms and their Properties • The transform associated with a random variable X is given by MX(s) = E[esX ] =    ∑ x esxpX (x), X discrete, ∫ ∞ −∞ esxfX (x) dx, X continuous. • The distribution of a random variable is completely determined by the corresponding transform. • Moment generating properties: MX (0) = 1, d 34 From Introduction to Probability, by Bertsekas and Tsitsiklis Chap. 4 Transforms for Common Discrete Random Variables Bernoulli(p) (k = 0, 1) pX (k) = { p, if k = 1, 1 − p, if k = 0, MX(s) = 1 − p + pes. Binomial(n, p) (k = 0, 1, . . . , n) pX (k) = ( n k ) pk(1 − p)n−k, MX (s) = (1 − p + pes)n. Geometric(p) (k = 1, 2, . . .) pX (k) = p(1 − p)k−1, MX (s) = pes Sec. 4.6 Summary and Discussion 35 4.5 SUM OF A RANDOM NUMBER OF INDEPENDENT RANDOM VARIABLES Properties of the Sum of a Random Number of Independent Ran- dom Variables Let X1, X2, . . . be identically distributed random variables with mean E[X] and variance var(X). Let N be a random variable that takes nonnegative in- teger values. We assume that all of these random variables are independent, and we consider the sum Y = X1 + · · · + XN . Then: • E[Y ] = E[N ] E[X]. • var(Y ) = E[N ] var(X) + ( E[X])2var(N ). • We have MY (s) = MN ( log MX(s) ). Equivalently, the transform MY (s) is found by starting with the trans- form MN (s) and replacing each occurrence of es with MX(s). 4.6 SUMMARY AND DISCUSSION 5 Limit Theorems Excerpts from Introduction to Probability: Second Edition by Dimitri P. Bertsekas and John N. Tsitsiklis c⃝ Massachusetts Institute of Technology Contents 5.1. Markov and Chebyshev Inequalities . . . . . . . . . . . . p. 265 5.2. The Weak Law of Large Numbers . . . . . . . . . . . . . p. 269 5.3. Convergence in Probability . . . . . . . . . . . . . . . . p. 271 5.4. The Central Limit Theorem . . . . . . . . . . . . . . . p. 273 5.5. The Strong Law of Large Numbers . . . . . . . . . . . . p. 280 5.6. Summary and Discussion . . . . . . . . . . . . . . . . p. 282 Problems . . . . . . . . . . . . . . . . . . . . . . . . p. 284 37 38 From Introduction to Probability, by Bertsekas and Tsitsiklis Chap. 5 5.1 MARKOV AND CHEBYSHEV INEQUALITIES Markov Inequality If a random variable X can only take nonnegative values, then P(X ≥ a) ≤ E[X] Sec. 5.3 Convergence in Probability 39 5.3 CONVERGENCE IN PROBABILITY Convergence of a Deterministic Sequence Let a1, a2, . . . be a sequence of real numbers, and let a be another real number. We say that the sequence an converges to a, or limn→∞ an = a, if for every ǫ > 0 there exists some n0 such that |an − a| ≤ ǫ, for all n ≥ n0. Convergence in Probability Let Y1, Y2, . . . be a sequence of random variables (not necessarily indepen- dent), and let a be a real number. We say that the sequence Yn converges to a in probability, if for every ǫ > 0, we have lim n→∞ P (|Yn − a| ≥ ǫ) = 0. 40 From Introduction to Probability, by Bertsekas and Tsitsiklis Chap. 5 5.4 THE CENTRAL LIMIT THEOREM The Central Limit Theorem Let X1, X2, . . . be a sequence of independent identically distributed random variables with common mean µ and variance σ2, and deﬁne Zn = X1 + · · · + Xn − nµ Sec. 5.6 Summary and Discussion 41 De Moivre-Laplace Approximation to the Binomial If Sn is a binomial random variable with parameters n and p, n is large, and k, l are nonnegative integers, then P(k ≤ Sn ≤ l) ≈ Φ ( l + 1 6 The Bernoulli and Poisson Processes Excerpts from Introduction to Probability: Second Edition by Dimitri P. Bertsekas and John N. Tsitsiklis c⃝ Massachusetts Institute of Technology Contents 6.1. The Bernoulli Process . . . . . . . . . . . . . . . . . . p. 297 6.2. The Poisson Process . . . . . . . . . . . . . . . . . . p. 309 6.3. Summary and Discussion . . . . . . . . . . . . . . . . p. 324 Problems . . . . . . . . . . . . . . . . . . . . . . . . p. 326 43 44 From Introduction to Probability, by Bertsekas and Tsitsiklis Chap. 6 6.1 THE BERNOULLI PROCESS Some Random Variables Associated with the Bernoulli Process and their Properties • The binomial with parameters p and n. This is the number S of successes in n independent trials. Its PMF, mean, and variance are pS(k) = ( n k )pk(1 − p)n−k, k = 0, 1, . . . , n, E[S] = np, var(S) = np(1 − p). • The geometric with parameter p. This is the number T of trials up to (and including) the ﬁrst success. Its PMF, mean, and variance are pT (t) = (1 − p)t−1p, t = 1, 2, . . . , E[T ] = 1 Sec. 6.1 The Bernoulli Process 45 Properties of the kth Arrival Time • The kth arrival time is equal to the sum of the ﬁrst k interarrival times Yk = T1 + T2 + · · · + Tk, and the latter are independent geometric random variables with com- mon parameter p. • The mean and variance of Yk are given by E[Yk] = E[T1] + · · · + E[Tk] = k 46 From Introduction to Probability, by Bertsekas and Tsitsiklis Chap. 6 Poisson Approximation to the Binomial • A Poisson random variable Z with parameter λ takes nonnegative integer values and is described by the PMF pZ(k) = e−λ λk Sec. 6.2 The Poisson Process 47 6.2 THE POISSON PROCESS Deﬁnition of the Poisson Process An arrival process is called a Poisson process with rate λ if it has the fol- lowing properties: (a) (Time-homogeneity) The probability P (k, τ ) of k arrivals is the same for all intervals of the same length τ . (b) (Independence) The number of arrivals during a particular interval is independent of the history of arrivals outside this interval. (c) (Small interval probabilities) The probabilities P (k, τ ) satisfy P (0, τ ) = 1 − λτ + o(τ ), P (1, τ ) = λτ + o1(τ ), P (k, τ ) = ok(τ ), for k = 2, 3, . . . Here, o(τ ) and ok(τ ) are functions of τ that satisfy lim τ →0 o(τ ) 48 From Introduction to Probability, by Bertsekas and Tsitsiklis Chap. 6 Independence Properties of the Poisson Process • For any given time t > 0, the history of the process after time t is also a Poisson process, and is independent from the history of the process until time t. • Let t be a given time and let Sec. 6.3 Summary and Discussion 49 Properties of Sums of a Random Number of Random Variables Let N, X1, X2, . . . be independent random variables, where N takes nonneg- ative integer values. Let Y = X1 + · · · + XN for positive values of N , and let Y = 0 when N = 0. • If Xi is Bernoulli with parameter p, and N is binomial with parameters m and q, then Y is binomial with parameters m and pq. • If Xi is Bernoulli with parameter p, and N is Poisson with parameter λ, then Y is Poisson with parameter λp. • If Xi is geometric with parameter p, and N is geometric with param- eter q, then Y is geometric with parameter pq. • If Xi is exponential with parameter λ, and N is geometric with pa- rameter q, then Y is exponential with parameter λq. 6.3 SUMMARY AND DISCUSSION 7 Markov Chains Excerpts from Introduction to Probability: Second Edition by Dimitri P. Bertsekas and John N. Tsitsiklis c⃝ Massachusetts Institute of Technology Contents 7.1. Discrete-Time Markov Chains . . . . . . . . . . . . . . p. 340 7.2. Classiﬁcation of States . . . . . . . . . . . . . . . . . . p. 346 7.3. Steady-State Behavior . . . . . . . . . . . . . . . . . . p. 352 7.4. Absorption Probabilities and Expected Time to Absorption . p. 362 7.5. Continuous-Time Markov Chains . . . . . . . . . . . . . p. 369 7.6. Summary and Discussion . . . . . . . . . . . . . . . . p. 378 Problems . . . . . . . . . . . . . . . . . . . . . . . . p. 380 51 52 From Introduction to Probability, by Bertsekas and Tsitsiklis Chap. 7 7.1 DISCRETE-TIME MARKOV CHAINS Speciﬁcation of Markov Models • A Markov chain model is speciﬁed by identifying: (a) the set of states § = {1, . . . , m}, (b) the set of possible transitions, namely, those pairs (i, j) for which pij > 0, and, (c) the numerical values of those pij that are positive. • The Markov chain speciﬁed by this model is a sequence of random variables X0, X1, X2, . . ., that take values in §, and which satisfy P(Xn+1 = j | Xn = i, Xn−1 = in−1, . . . , X0 = i0) = pij, for all times n, all states i, j ∈ §, and all possible sequences i0, . . . , in−1 of earlier states. Chapman-Kolmogorov Equation for the n-Step Transition Probabilities The n-step transition probabilities can be generated by the recursive formula rij (n) = m∑ k=1 rik(n − 1)pkj, for n > 1, and all i, j, starting with rij (1) = pij . Sec. 7.2 Classiﬁcation of States 53 7.2 CLASSIFICATION OF STATES Markov Chain Decomposition • A Markov chain can be decomposed into one or more recurrent classes, plus possibly some transient states. • A recurrent state is accessible from all states in its class, but is not accessible from recurrent states in other classes. • A transient state is not accessible from any recurrent state. • At least one, possibly more, recurrent states are accessible from a given transient state. Periodicity Consider a recurrent class R. • The class is called periodic if its states can be grouped in d > 1 disjoint subsets S1, . . . , Sd, so that all transitions from Sk lead to Sk+1 (or to S1 if k = d). • The class is aperiodic (not periodic) if and only if there exists a time n such that rij (n) > 0, for all i, j ∈ R. 54 From Introduction to Probability, by Bertsekas and Tsitsiklis Chap. 7 7.3 STEADY-STATE BEHAVIOR Steady-State Convergence Theorem Consider a Markov chain with a single recurrent class, which is aperiodic. Then, the states j are associated with steady-state probabilities πj that have the following properties. (a) For each j, we have lim n→∞rij (n) = πj, for all i. (b) The πj are the unique solution to the system of equations below: πj = m∑ k=1πkpkj , j = 1, . . . , m, 1 = m∑ k=1πk. (c) We have πj = 0, for all transient states j, πj > 0, for all recurrent states j. Steady-State Probabilities as Expected State Frequencies For a Markov chain with a single class which is aperiodic, the steady-state probabilities πj satisfy πj = lim n→∞ vij(n) Sec. 7.4 Absorption Probabilities and Expected Time to Absorption 55 Expected Frequency of a Particular Transition Consider n transitions of a Markov chain with a single class which is aperi- odic, starting from a given initial state. Let qjk(n) be the expected number of such transitions that take the state from j to k. Then, regardless of the initial state, we have lim n→∞ qjk(n) 56 From Introduction to Probability, by Bertsekas and Tsitsiklis Chap. 7 Equations for the Expected Times to Absorption Consider a Markov chain where all states are transient, except for a single absorbing state. The expected times to absorption, µ1, . . . , µm, are the unique solution to the equations µi = 0, if i is the absorbing state, µi = 1 + m∑ j=1 pijµj, if i is transient. Equations for Mean First Passage and Recurrence Times Consider a Markov chain with a single recurrent class, and let s be a par- ticular recurrent state. • The mean ﬁrst passage times µi to reach state s starting from i, are the unique solution to the system of equations µs = 0, µi = 1 + m∑ j=1 pij µj, for all i ̸= s. • The mean recurrence time µ∗ s of state s is given by µ∗ s = 1 + m∑ j=1 psjµj. Sec. 7.5 Continuous-Time Markov Chains 57 7.5 CONTINUOUS-TIME MARKOV CHAINS Continuous-Time Markov Chain Assumptions • If the current state is i, the time until the next transition is exponen- tially distributed with a given parameter νi, independent of the past history of the process and of the next state. • If the current state is i, the next state will be j with a given probability pij , independent of the past history of the process and of the time until the next transition. 58 From Introduction to Probability, by Bertsekas and Tsitsiklis Chap. 7 Alternative Description of a Continuous-Time Markov Chain Given the current state i of a continuous-time Markov chain, and for any j ̸= i, the state δ time units later is equal to j with probability qij δ + o(δ), independent of the past history of the process. Steady-State Convergence Theorem Consider a continuous-time Markov chain with a single recurrent class. Then, the states j are associated with steady-state probabilities πj that have the following properties. (a) For each j, we have lim t→∞P ( X(t) = j | X(0) = i) = πj, for all i. (b) The πj are the unique solution to the system of equations below: πj ∑ k̸=j qjk = ∑ k̸=jπkqkj , j = 1, . . . , m, 1 = m∑ k=1πk. (c) We have πj = 0, for all transient states j, πj > 0, for all recurrent states j. 7.6 SUMMARY AND DISCUSSION 8 Bayesian Statistical Inference Excerpts from Introduction to Probability: Second Edition by Dimitri P. Bertsekas and John N. Tsitsiklis c⃝ Massachusetts Institute of Technology Contents 8.1. Bayesian Inference and the Posterior Distribution . . . . . p. 412 8.2. Point Estimation, Hypothesis Testing, and the MAP Rule . . p. 420 8.3. Bayesian Least Mean Squares Estimation . . . . . . . . . p. 430 8.4. Bayesian Linear Least Mean Squares Estimation . . . . . . p. 437 8.5. Summary and Discussion . . . . . . . . . . . . . . . . p. 444 Problems . . . . . . . . . . . . . . . . . . . . . . . . p. 446 59 60 From Introduction to Probability, by Bertsekas and Tsitsiklis Chap. 8 Major Terms, Problems, and Methods in this Chapter • Bayesian statistics treats unknown parameters as random variables with known prior distributions. • In parameter estimation, we want to generate estimates that are close to the true values of the parameters in some probabilistic sense. • In hypothesis testing, the unknown parameter takes one of a ﬁnite number of values, corresponding to competing hypotheses; we want to choose one of the hypotheses, aiming to achieve a small probability of error. • Principal Bayesian inference methods: (a) Maximum a posteriori probability (MAP) rule: Out of the possible parameter values/hypotheses, select one with maximum conditional/posterior probability given the data (Section 8.2). (b) Least mean squares (LMS) estimation: Select an estimator/fun- ction of the data that minimizes the mean squared error between the parameter and its estimate (Section 8.3). (c) Linear least mean squares estimation: Select an estimator which is a linear function of the data and minimizes the mean squared error between the parameter and its estimate (Section 8.4). This may result in higher mean squared error, but requires simple calculations, based only on the means, variances, and co- variances of the random variables involved. 8.1 BAYESIAN INFERENCE AND THE POSTERIOR DISTRIBUTION Summary of Bayesian Inference • We start with a prior distribution pΘ or fΘ for the unknown random variable Θ. • We have a model pX|Θ or fX|Θ of the observation vector X. • After observing the value x of X, we form the posterior distribution of Θ, using the appropriate version of Bayes’ rule. Sec. 8.1 Bayesian Inference and the Posterior Distribution 61 The Four Versions of Bayes’ Rule • Θ discrete, X discrete: pΘ|X (θ | x) = pΘ(θ)pX|Θ(x | θ) 62 From Introduction to Probability, by Bertsekas and Tsitsiklis Chap. 8 8.2 POINT ESTIMATION, HYPOTHESIS TESTING, AND THE MAP RULE The Maximum a Posteriori Probability (MAP) Rule • Given the observation value x, the MAP rule selects a value ˆθ that maximizes over θ the posterior distribution pΘ|X (θ | x) (if Θ is discrete) or fΘ|X (θ | x) (if Θ is continuous). • Equivalently, it selects ˆθ that maximizes over θ: pΘ(θ)pX|Θ(x | θ) (if Θ and X are discrete), pΘ(θ)fX|Θ(x | θ) (if Θ is discrete and X is continuous), fΘ(θ)pX|Θ(x | θ) (if Θ is continuous and X is discrete), fΘ(θ)fX|Θ(x | θ) (if Θ and X are continuous). • If Θ takes only a ﬁnite number of values, the MAP rule minimizes (over all decision rules) the probability of selecting an incorrect hypothesis. This is true for both the unconditional probability of error and the conditional one, given any observation value x. Sec. 8.3 Bayesian Least Mean Squares Estimation 63 Point Estimates • An estimator is a random variable of the form ˆΘ = g(X), for some function g. Diﬀerent choices of g correspond to diﬀerent estimators. • An estimate is the value ˆθ of an estimator, as determined by the realized value x of the observation X. • Once the value x of X is observed, the Maximum a Posteriori Probability (MAP) estimator, sets the estimate ˆθ to a value that maximizes the posterior distribution over all possible values of θ. • Once the value x of X is observed, the Conditional Expectation (LMS) estimator sets the estimate ˆθ to E[Θ | X = x]. The MAP Rule for Hypothesis Testing • Given the observation value x, the MAP rule selects a hypothesis Hi for which the value of the posterior probability P(Θ = θi | X = x) is largest. • Equivalently, it selects a hypothesis Hi for which pΘ(θi)pX|Θ(x | θi) (if X is discrete) or pΘ(θi)fX|Θ(x | θi) (if X is continuous) is largest. • The MAP rule minimizes the probability of selecting an incorrect hy- pothesis for any observation value x, as well as the probability of error over all decision rules. 64 From Introduction to Probability, by Bertsekas and Tsitsiklis Chap. 8 8.3 BAYESIAN LEAST MEAN SQUARES ESTIMATION Key Facts About Least Mean Squares Estimation • In the absence of any observations, E[(Θ − ˆθ)2] is minimized when ˆθ = E[Θ]: E[( Θ − E[Θ])2] ≤ E[(Θ − ˆθ)2] , for all ˆθ. • For any given value x of X, E[(Θ − ˆθ)2 | X = x ] is minimized when ˆθ = E[Θ | X = x]: E[( Θ − E[Θ | X = x])2 ∣ ∣ X = x ] ≤ E[ (Θ − ˆθ)2 | X = x ], for all ˆθ. • Out of all estimators g(X) of Θ based on X, the mean squared esti- mation error E[( Θ − g(X) )2] is minimized when g(X) = E[Θ | X]: E[( Θ − E[Θ | X])2] ≤ E[(Θ − g(X) )2], for all estimators g(X). Sec. 8.5 Summary and Discussion 65 Properties of the Estimation Error • The estimation error ˜Θ is unbiased, i.e., it has zero unconditional and conditional mean: E[ ˜Θ] = 0, E[ ˜Θ | X = x] = 0, for all x. • The estimation error ˜Θ is uncorrelated with the estimate ˆΘ: cov( ˆΘ, ˜Θ) = 0. • The variance of Θ can be decomposed as var(Θ) = var( ˆΘ) + var( ˜Θ). 8.4 BAYESIAN LINEAR LEAST MEAN SQUARES ESTIMATION Linear LMS Estimation Formulas • The linear LMS estimator ˆΘ of Θ based on X is ˆΘ = E[Θ] + cov(Θ, X) 9 Classical Statistical Inference Excerpts from Introduction to Probability: Second Edition by Dimitri P. Bertsekas and John N. Tsitsiklis c⃝ Massachusetts Institute of Technology Contents 9.1. Classical Parameter Estimation . . . . . . . . . . . . . . p. 460 9.2. Linear Regression . . . . . . . . . . . . . . . . . . . . p. 475 9.3. Binary Hypothesis Testing . . . . . . . . . . . . . . . . p. 485 9.4. Signiﬁcance Testing . . . . . . . . . . . . . . . . . . . p. 495 9.5. Summary and Discussion . . . . . . . . . . . . . . . . p. 506 Problems . . . . . . . . . . . . . . . . . . . . . . . . p. 507 67 68 From Introduction to Probability, by Bertsekas and Tsitsiklis Chap. 9 Major Terms, Problems, and Methods in this Chapter • Classical statistics treats unknown parameters as constants to be determined. A separate probabilistic model is assumed for each pos- sible value of the unknown parameter. • In parameter estimation, we want to generate estimates that are nearly correct under any possible value of the unknown parameter. • In hypothesis testing, the unknown parameter takes a ﬁnite number m of values (m ≥ 2), corresponding to competing hypotheses; we want to choose one of the hypotheses, aiming to achieve a small probability of error under any of the possible hypotheses. • In signiﬁcance testing, we want to accept or reject a single hypoth- esis, while keeping the probability of false rejection suitably small. • Principal classical inference methods in this chapter: (a) Maximum likelihood (ML) estimation: Select the parame- ter that makes the observed data “most likely,” i.e., maximizes the probability of obtaining the data at hand (Section 9.1). (b) Linear regression: Find the linear relation that matches best a set of data pairs, in the sense that it minimizes the sum of the squares of the discrepancies between the model and the data (Section 9.2). (c) Likelihood ratio test: Given two hypotheses, select one based on the ratio of their “likelihoods,” so that certain error probabil- ities are suitably small (Section 9.3). (d) Signiﬁcance testing: Given a hypothesis, reject it if and only if the observed data falls within a certain rejection region. This re- gion is specially designed to keep the probability of false rejection below some threshold (Section 9.4). Sec. 9.1 Classical Parameter Estimation 69 9.1 CLASSICAL PARAMETER ESTIMATION Terminology Regarding Estimators Let ˆΘn be an estimator of an unknown parameter θ, that is, a function of n observations X1, . . . , Xn whose distribution depends on θ. • The estimation error, denoted by ˜Θn, is deﬁned by ˜Θn = ˆΘn − θ. • The bias of the estimator, denoted by bθ( ˆΘn), is the expected value of the estimation error: bθ( ˆΘn) = Eθ[ ˆΘn] − θ. • The expected value, the variance, and the bias of ˆΘn depend on θ, while the estimation error depends in addition on the observations X1, . . . , Xn. • We call ˆΘn unbiased if Eθ[ ˆΘn] = θ, for every possible value of θ. • We call ˆΘn asymptotically unbiased if limn→∞ Eθ[ ˆΘn] = θ, for every possible value of θ. • We call ˆΘn consistent if the sequence ˆΘn converges to the true value of the parameter θ, in probability, for every possible value of θ. Maximum Likelihood Estimation • We are given the realization x = (x1, . . . , xn) of a random vector X = (X1, . . . , Xn), distributed according to a PMF pX(x; θ) or PDF fX (x; θ). • The maximum likelihood (ML) estimate is a value of θ that maximizes the likelihood function, pX (x; θ) or fX (x; θ), over all θ. • The ML estimate of a one-to-one function h(θ) of θ is h(ˆθn), where ˆθn is the ML estimate of θ (the invariance principle). • When the random variables Xi are i.i.d., and under some mild addi- tional assumptions, each component of the ML estimator is consistent and asymptotically normal. 70 From Introduction to Probability, by Bertsekas and Tsitsiklis Chap. 9 Estimates of the Mean and Variance of a Random Variable Let the observations X1, . . . , Xn be i.i.d., with mean θ and variance v that are unknown. • The sample mean Mn = X1 + · · · + Xn Sec. 9.2 Linear Regression 71 9.2 LINEAR REGRESSION Linear Regression Given n data pairs (xi, yi), the estimates that minimize the sum of the squared residuals are given by ˆθ1 = n∑ i=1(xi − 72 From Introduction to Probability, by Bertsekas and Tsitsiklis Chap. 9 Bayesian Linear Regression • Model: (a) We assume a linear relation Yi = Θ0 + Θ1xi + Wi. (b) The xi are modeled as known constants. (c) The random variables Θ0, Θ1, W1, . . . , Wn are normal and inde- pendent. (d) The random variables Θ0 and Θ1 have mean zero and variances σ2 0, σ2 1, respectively. (e) The random variables Wi have mean zero and variance σ2. • Estimation Formulas: Given the data pairs (xi, yi), the MAP estimates of Θ0 and Θ1 are ˆθ1 = σ2 1 Sec. 9.4 Signiﬁcance Testing 73 Neyman-Pearson Lemma Consider a particular choice of ξ in the LRT, which results in error proba- bilities P ( L(X) > ξ; H0) = α, P ( L(X) ≤ ξ; H1) = β. Suppose that some other test, with rejection region R, achieves a smaller or equal false rejection probability: P(X ∈ R; H0) ≤ α. Then, P(X /∈ R; H1) ≥ β, with strict inequality P(X /∈ R; H1) > β when P(X ∈ R; H0) < α. 74 From Introduction to Probability, by Bertsekas and Tsitsiklis Chap. 9 9.4 SIGNIFICANCE TESTING Signiﬁcance Testing Methodology A statistical test of a hypothesis H0 is to be performed, based on the obser- vations X1, . . . , Xn. • The following steps are carried out before the data are observed. (a) Choose a statistic S, that is, a scalar random variable that will summarize the data to be obtained. Mathematically, this involves the choice of a function h : ℜn → ℜ, resulting in the statistic S = h(X1 . . . , Xn). (b) Determine the shape of the rejection region by specifying the set of values of S for which H0 will be rejected as a function of a yet undetermined critical value ξ. (c) Choose the signiﬁcance level, i.e., the desired probability α of a false rejection of H0. (d) Choose the critical value ξ so that the probability of false re- jection is equal (or approximately equal) to α. At this point, the rejection region is completely determined. • Once the values x1, . . . , xn of X1, . . . , Xn are observed: (i) Calculate the value s = h(x1, . . . , xn) of the statistic S. (ii) Reject the hypothesis H0 if s belongs to the rejection region. Sec. 9.5 Summary and Discussion 75 The Chi-Square Test: • Use the statistic S = m∑ k=1 Nk log ( Nk","libVersion":"0.3.2","langs":""}