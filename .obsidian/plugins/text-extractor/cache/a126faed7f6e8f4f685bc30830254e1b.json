{"path":"Books and Papers/Mathematics/George B. Arfken, Hans J. Weber, Frank E. Harris - Mathematical Methods for Physicists - Solutions-Elsevier (2013).pdf","text":"Instructor’s Manual MATHEMATICAL METHODS FOR PHYSICISTS A Comprehensive Guide SEVENTH EDITION George B. Arfken Miami University Oxford, OH Hans J. Weber University of Virginia Charlottesville, VA Frank E. Harris University of Utah, Salt Lake City, UT; University of Florida, Gainesville, FL AMSTERDAM • BOSTON • HEIDELBERG • LONDON NEW YORK • OXFORD • PARIS • SAN DIEGO SAN FRANCISCO • SINGAPORE • SYDNEY • TOKYO Academic Press is an imprint of Elsevier Academic Press is an imprint of Elsevier 225 Wyman Street, Waltham, MA 02451, USA The Boulevard, Langford Lane, Kidlington, Oxford, OX5 1GB, UK c⃝ 2013 Elsevier Inc. All rights reserved. No part of this publication may be reproduced or transmitted in any form or by any means, electronic or mechanical, including photocopying, recording, or any information storage and retrieval system, without permission in writing from the publisher. Details on how to seek permission and further information about the Publishers permissions policies and our arrangements with organi- zations such as the Copyright Clearance Center and the Copyright Licensing Agency, can be found at our website: www.elsevier.com/permissions. This book and the individual contributions contained in it are protected under copyright by the Publisher (other than as may be noted herein). Knowledge and best practice in this ﬁeld are constantly changing. As new research and experience broaden our understanding, changes in research meth- ods, professional practices, or medical treatment may become necessary. Practitioners and researchers must always rely on their own experience and knowledge in evaluating and using any information, methods, compounds, or experiments described herein. In using such information or methods they should be mindful of their own safety and the safety of others, including parties for whom they have a professional responsibility. To the fullest extent of the law, neither the Publisher nor the authors, con- tributors, or editors, assume any liability for any injury and/or damage to persons or property as a matter of products liability, negligence or otherwise, or from any use or operation of any methods, products, instructions, or ideas contained in the material herein. For information on all Academic Press publications, visit our website: www.books.elsevier.com Contents 1 Introduction 1 2 Errata and Revision Status 3 3 Exercise Solutions 7 1. Mathematical Preliminaries . . . . . . . . . . . . . . . . . . . 7 2. Determinants and Matrices . . . . . . . . . . . . . . . . . . . . 27 3. Vector Analysis . . . . . . . . . . . . . . . . . . . . . . . . . . 34 4. Tensors and Diﬀerential Forms . . . . . . . . . . . . . . . . . . 58 5. Vector Spaces . . . . . . . . . . . . . . . . . . . . . . . . . . . 66 6. Eigenvalue Problems . . . . . . . . . . . . . . . . . . . . . . . 81 7. Ordinary Diﬀerential Equations . . . . . . . . . . . . . . . . . 90 8. Sturm-Liouville Theory . . . . . . . . . . . . . . . . . . . . . . 106 9. Partial Diﬀerential Equations . . . . . . . . . . . . . . . . . . 111 10. Green’s Functions . . . . . . . . . . . . . . . . . . . . . . . . . 118 11. Complex Variable Theory . . . . . . . . . . . . . . . . . . . . 122 12. Further Topics in Analysis . . . . . . . . . . . . . . . . . . . . 155 13. Gamma Function . . . . . . . . . . . . . . . . . . . . . . . . . 166 14. Bessel Functions . . . . . . . . . . . . . . . . . . . . . . . . . . 192 15. Legendre Functions . . . . . . . . . . . . . . . . . . . . . . . . 231 16. Angular Momentum . . . . . . . . . . . . . . . . . . . . . . . . 256 17. Group Theory . . . . . . . . . . . . . . . . . . . . . . . . . . . 268 18. More Special Functions . . . . . . . . . . . . . . . . . . . . . . 286 19. Fourier Series . . . . . . . . . . . . . . . . . . . . . . . . . . . 323 20. Integral Transforms . . . . . . . . . . . . . . . . . . . . . . . . 332 21. Integral Equations . . . . . . . . . . . . . . . . . . . . . . . . . 364 22. Calculus of Variations . . . . . . . . . . . . . . . . . . . . . . . 373 23. Probability and Statistics . . . . . . . . . . . . . . . . . . . . . 387 4 Correlation, Exercise Placement 398 5 Unused Sixth Edition Exercises 425 iv Chapter 1 Introduction The seventh edition of Mathematical Methods for Physicists is a substantial and detailed revision of its predecessor. The changes extend not only to the topics and their presentation, but also to the exercises that are an important part of the student experience. The new edition contains 271 exercises that were not in previous editions, and there has been a wide-spread reorganization of the previously existing exercises to optimize their placement relative to the material in the text. Since many instructors who have used previous editions of this text have favorite problems they wish to continue to use, we are providing detailed tables showing where the old problems can be found in the new edition, and conversely, where the problems in the new edition came from. We have included the full text of every problem from the sixth edition that was not used in the new seventh edition. Many of these unused exercises are excellent but had to be left out to keep the book within its size limit. Some may be useful as test questions or additional study material. Complete methods of solution have been provided for all the problems that are new to this seventh edition. This feature is useful to teachers who want to determine, at a glance, features of the various exercises that may not be com- pletely apparent from the problem statement. While many of the problems from the earlier editions had full solutions, some did not, and we were unfortunately not able to undertake the gargantuan task of generating full solutions to nearly 1400 problems. Not part of this Instructor’s Manual but available from Elsevier’s on-line web site are three chapters that were not included in the printed text but which may be important to some instructors. These include • A new chapter (designated 31) on Periodic Systems, dealing with mathe- matical topics associated with lattice summations and band theory, • A chapter (32) on Mathieu functions, built using material from two chap- ters in the sixth edition, but expanded into a single coherent presentation, 1 CHAPTER 1. INTRODUCTION 2 • A chapter (33) on Chaos, modeled after Chapter 18 of the sixth edition but carefully edited. In addition, also on-line but external to this Manual, is a chapter (designated 1) on Inﬁnite Series that was built by collection of suitable topics from various places in the seventh edition text. This alternate Chapter 1 contains no material not already in the seventh edition but its subject matter has been packaged into a separate unit to meet the demands of instructors who wish to begin their course with a detailed study of Inﬁnite Series in place of the new Mathematical Preliminaries chapter. Because this Instructor’s Manual exists only on-line, there is an opportunity for its continuing updating and improvement, and for communication, through it, of errors in the text that will surely come to light as the book is used. The authors invite users of the text to call attention to errors or ambiguities, and it is intended that corrections be listed in the chapter of this Manual entitled Errata and Revision Status. Errata and comments may be directed to the au- thors at harris⟨at⟩qtp.ufl.edu or to the publisher. If users choose to forward additional materials that are of general use to instructors who are teaching from the text, they will be considered for inclusion when this Manual is updated. Preparation of this Instructor’s Manual has been greatly facilitated by the eﬀorts of personnel at Elsevier. We particularly want to acknowledge the assis- tance of our Editorial Project Manager, Kathryn Morrissey, whose attention to this project has been extremely valuable and is much appreciated. It is our hope that this Instructor’s Manual will have value to those who teach from Mathematical Methods for Physicists and thereby to their students. Chapter 2 Errata and Revision Status Last changed: 06 April 2012 Errata and Comments re Seventh Edition text Page 522 Exercise 11.7.12(a) This is not a principal-value integral. Page 535 Figure 11.26 The two arrowheads in the lower part of the circular arc should be reversed in direction. Page 539 Exercise 11.8.9 The answer is incorrect; it should be π/2. Page 585 Exercise 12.6.7 Change the integral for which a series is sought to ∫ ∞ 0 e −xv 1 + v2 dv. The answer is then correct. Page 610 Exercise 13.1.23 Replace (−t) ν by e −πiνt ν. Page 615 Exercise 13.2.6 In the Hint, change Eq. (13.35) to Eq. (13.44). Page 618 Eq. (13.51) Change l.h.s. to B(p + 1, q + 1). Page 624 After Eq. (13.58) C1 can be determined by requiring consistency with the recurrence formula zΓ(z) = Γ(z + 1). Consistency with the duplication formula thenC2. Page 625 Exercise 13.4.3 Replace “(see Fig. 3.4)” by “and that of the recurrence formula”. Page 660 Exercise 14.1.25 Note that α2 = ω2/c 2, where ω is the angular frequency, and that the height of the cavity is l. 3 CHAPTER 2. ERRATA AND REVISION STATUS 4 Page 665 Exercise 14.2.4 Change Eq. (11.49) to Eq. (14.44). Page 686 Exercise 14.5.5 In part (b), change l to h in the formulas for amn and bmn (denominator and integration limit). Page 687 Exercise 14.5.14 The index n is assumed to be an integer. Page 695 Exercise 14.6.3 The index n is assumed to be an integer. Page 696 Exercise 14.6.7(b) Change N to Y (two occurrences). Page 709 Exercise 14.7.3 In the summation preceded by the cosine function, change (2z) 2s to (2z)2s+1. Page 710 Exercise 14.7.7 Replace nn(x) by yn(x). Page 723 Exercise 15.1.12 The last formula of the answer should read P2s(0)/(2s + 2) = (−1) s(2s − 1)!!/(2s + 2)!!. Page 754 Exercise 15.4.10 Insert minus sign before P 1 (cos θ). Page 877 Exercise 18.1.6 In both (a) and (b), change 2π to √2π. Page 888 Exercise 18.2.7 Change the second of the four members of the ﬁrst display equation to ( x + ip √2 ) ψn(x), and change the corresponding member of the second display equation to ( x − ip √2 ) ψn(x). Page 888 Exercise 18.2.8 Change x + ip to x − ip. Page 909 Exercise 18.4.14 All instances of x should be primed. Page 910 Exercise 18.4.24 The text does not state that the T0 term (if present) has an additional factor 1/2. Page 911 Exercise 18.4.26(b) The ratio approaches (πs) −1/2, not (πs) −1. Page 915 Exercise 18.5.5 The hypergeometric function should read 2F1 ( ν 2 + 1 2 , ν 2 + 1; ν + 3 2 ; z−2). Page 916 Exercise 18.5.10 Change (n − 1 2 )! to Γ(n + 1 2 ). Page 916 Exercise 18.5.12 Here n must be an integer. Page 917 Eq. (18.142) In the last term change Γ(−c) to Γ(2 − c). Page 921 Exercise 18.6.9 Change b to c (two occurrences). Page 931 Exercise 18.8.3 The arguments of K and E are m. Page 932 Exercise 18.8.6 All arguments of K and E are k2; In the integrand of the hint, change k to k2. CHAPTER 2. ERRATA AND REVISION STATUS 5 Page 978 Exercise 20.2.9 The formula as given assumes that Γ > 0. Page 978 Exercise 20.2.10(a) This exercise would have been easier if the book had mentioned the integral representation J0(x) = 2 π ∫ 1 0 cos xt √1 − t2 dt. Page 978 Exercise 20.2.10(b) Change the argument of the square root to x 2 − a 2. Page 978 Exercise 20.2.11 The l.h.s. quantities are the transforms of their r.h.s. counterparts, but the r.h.s. quantities are (−1)n times the transforms of the l.h.s. expressions. Page 978 Exercise 20.2.12 The properly scaled transform of f (µ) is (2/π) 1/2i njn(ω), where ω is the transform variable. The text assumes it to be kr. Page 980 Exercise 20.2.16 Change d3x to d3r and remove the limits from the ﬁrst integral (it is assumed to be over all space). Page 980 Eq. (20.54) Replace dk by d3k (occurs three times) Page 997 Exercise 20.4.10 This exercise assumes that the units and scaling of the momentum wave function correspond to the formula(p) = 1 (2πℏ)3/2 ∫ ψ(r) e −ir·p/ℏ d3r . Page 1007 Exercise 20.6.1 The second and third orthogonality equa- tions are incorrect. The right-hand side of the second equation should read:, p = q = (0 or N/2); N/2, (p + q = N ) or p = q but not both; 0, otherwise. The right-hand side of the third equation should read: N/2, p = q and p + q ̸= (0 or N ); −N/2, p ̸= q and p + q = N ; 0, otherwise. Page 1007 Exercise 20.6.2 The exponentials should be e 2πipk/N and e −2πipk/N . Page 1014 Exercise 20.7.2 This exercise is ill-deﬁned. Disregard it. Page 1015 Exercise 20.7.6 Replace (ν − 1)! by Γ(ν) (two occurrences). Page 1015 Exercise 20.7.8 Change M (a, c; x) to M (a, c, x) (two CHAPTER 2. ERRATA AND REVISION STATUS 6 occurrences). Page 1028 Table 20.2 Most of the references to equation numbers did not get updated from the 6th edition. The column of references should, in its entirety, read: (20.126), (20.147), (20.148), Exercise 20.9.1, (20.156), (20.157), (20.166), (20.174), (20.184), (20.186), (20.203). Page 1034 Exercise 20.8.34 Note that u(t − k) is the unit step function. Page 1159 Exercise 23.5.5 This problem should have identiﬁed m as the mean value and M as the “random variable” describing individual student scores. Corrections and Additions to Exercise Solutions None as of now. Chapter 3 Exercise Solutions 1. Mathematical Preliminaries 1.1 Inﬁnite Series 1.1.1. (a) If un < A/np the integral test shows ∑n un converges for p > 1. (b) If un > A/n, ∑ n un diverges because the harmonic series diverges. 1.1.2. This is valid because a multiplicative constant does not aﬀect the conver- gence or divergence of a series. 1.1.3. (a) The Raabe test P can be written 1 + (n + 1) ln(1 + n−1) ln n . This expression approaches 1 in the limit of large n. But, applying the Cauchy integral test, ∫ dx x ln x = ln ln x, indicating divergence. (b) Here the Raabe test P can be written 1 + n + 1 ln n ln ( 1 + 1 n ) + ln 2(1 + n−1) ln 2 n , which also approaches 1 as a large-n limit. But the Cauchy integral test yields ∫ dx x ln 2 x = − 1 ln x , indicating convergence. 1.1.4. Convergent for a1 − b1 > 1. Divergent for a1 − b1 ≤ 1. 1.1.5. (a) Divergent, comparison with harmonic series. 7 CHAPTER 3. EXERCISE SOLUTIONS 8 (b) Divergent, by Cauchy ratio test. (c) Convergent, comparison with ζ(2). (d) Divergent, comparison with (n + 1) −1. (e) Divergent, comparison with 1 2 (n + 1)−1 or by Maclaurin integral test. 1.1.6. (a) Convergent, comparison with ζ(2). (b) Divergent, by Maclaurin integral test. (c) Convergent, by Cauchy ratio test. (d) Divergent, by ln ( 1 + 1 n ) ∼ 1 n . (e) Divergent, majorant is 1/(n ln n). 1.1.7. The solution is given in the text. 1.1.8. The solution is given in the text. 1.1.10. In the limit of large n, un+1/un = 1 + 1 n + O(n−2). Applying Gauss’ test, this indicates divergence. 1.1.11. Let sn be the absolute value of the nth term of the series. (a) Because ln n increases less rapidly than n, sn+1 < sn and limn→∞ sn = 0. Therefore this series converges. Because the sn are larger than corre- sponding terms of the harmonic series, this series is not absolutely con- vergent. (b) Regarding this series as a new series with terms formed by combin- ing adjacent terms of the same sign in the original series, we have an alternating series of decreasing terms that approach zero as a limit, i.e., 1 2n + 1 + 1 2n + 2 > 1 2n + 3 + 1 2n + 4 , this series converges. With all signs positive, this series is the harmonic series, so it is not aboslutely convergent. (c) Combining adjacent terms of the same sign, the terms of the new series 2 ( 1 2 ) > 1 2 + 1 3 > 2 ( 1 3 ) , 3 ( 1 4 ) > 1 4 + 1 5 + 1 6 > 3 ( 1 6 ) , etc. The general form of these relations is 2n n2 − n + 2 > sn > 2 n + 1 . CHAPTER 3. EXERCISE SOLUTIONS 9 An upper limit to the left-hand side member of this inequality is 2/(n−1). We therefore see that the terms of the new series are decreasing, with limit zero, so the original series converges. With all signs positive, the original series becomes the harmonic series, and is therefore not absolutely convergent. 1.1.12. The solution is given in the text. 1.1.13. Form the nth term of ζ(2)−c1α1 −c2α2 and choose c1 and c2 so that when placed over the common denominator n2(n + 1)(n + 2) the numerator will be independent of n. The values of the ci satisfying this condition are c1 = c2 = 1, and our resulting expansion is ζ(2) = α1 + α2 + ∞∑ n=1 2 n2(n + 1(n + 2) = 5 4 + ∞∑ n=1 2 n2(n + 1(n + 2) . Keeping terms through n = 10, this formula yields ζ(2) ≈ 1.6445; to this precision the exact value is ζ(2) = 1.6449. 1.1.14. Make the observation that ∞∑ n=0 1 (2n + 1)3 + ∞∑ n=1 1 (2n)3 = ζ(3) and that the second term on the left-hand side is ζ(3)/8). Our summation therefore has the value 7ζ(3)/8. 1.1.15. (a) Write ζ(n) − 1 as ∑∞=2 p−n, so our summation is ∞∑ n=2 ∞∑ p=2 1 pn = ∞∑ p=2 ∞∑ n=2 1 pn . The summation over n is a geometric series which evaluates to p−2 1 − p−1 = 1 p2 − p . Summing now over p, we get ∞∑ p=2 1 p(p − 1) = ∞∑ p=1 1 p(p + 1) = α1 = 1 . (b) Proceed in a fashion similar to part (a), but now the geometric series has sum 1/(p2 + p), and the sum over p is now lacking the initial term of α1, so ∞∑ p=2 1 p(p + 1) = α1 − 1 (1)(2) = 1 2 . CHAPTER 3. EXERCISE SOLUTIONS 10 1.1.16. (a) Write(3) = 1 + ∞∑ n=2 1 n3 − ∞∑ n=2 1 (n − 1)n(n + 1) + α′ 2 = 1 + ∞∑ n=2 [ 1 n3 − 1 n(n2 − 1) ] + 1 4 = 1 + 1 4 − ∞∑ n=2 1 n3(n2 − 1) . (b) Now use α′ 2 and α′ 4 = ∞∑ n=3 1 n(n2 − 1)(n2 − 4) = 1 96 : ζ(3) = 1 + 1 23 + ∞∑ n=3 1 n3 − ∞∑ n=3 1 n(n2 − 1) + [α′ 2 − 1 6 ] − ∞∑ n=3 B n(n2 − 1)(n2 − 4) + Bα′ 4 = 29 24 + B 96 + ∞∑ n=3 [ 1 n3 − 1 n(n2 − 1) − B n(n2 − 1)(n2 − 4) ] = 29 24 − B 96 + ∞∑ n=3 4 − (1 + B)n2 n(n2 − 1)(n2 − 4) . The convergence of the series is optimized if we set B = −1, leading to the ﬁnal result ζ(3) = 29 24 − 1 96 + ∞∑ n=3 4 n(n2 − 1)(n2 − 4) . (c) Number of terms required for error less than 5 × 10−7: ζ(3) alone, 999; combined as in part (a), 27; combined as in part (b), 11. 1.2 Series of Functions 1.2.1. (a) Applying Leibniz’ test the series converges uniformly for ε ≤ x < ∞ no matter how small ε > 0 is. (b) The Weierstrass M and the integral tests give uniform convergence for 1 + ε ≤ x < ∞ no matter how small ε > 0 is chosen. 1.2.2. The solution is given in the text. 1.2.3. (a) Convergent for 1 < x < ∞. (b) Uniformly convergent for 1 < s ≤ x < ∞. CHAPTER 3. EXERCISE SOLUTIONS 11 1.2.4. From | cos nx| ≤ 1, | sin nx| ≤ 1 absolute and uniform convergence follow for −s < x < s for any s > 0. 1.2.5. Since | uj+2 uj | ∼ |x|2, |x| < 1 is needed for convergence. 1.2.6. The solution is given in the text. 1.2.7. The solution is given in the text. 1.2.8. (a) For n = 0, 1, 2, . . . we ﬁnd d4n+1 sin x dx4n+1 ∣0 = cos x|0 = 1, d4n+2 sin x dx4n+2 ∣0 = − sin x|0 = 0, d4n+3 sin x dx4n+3 ∣0 = − cos x|0 = −1, d4n sin x dx4n ∣0 = sin x|0 = 0. Taylor’s theorem gives the absolutely convergent series sin x = ∞∑ n=0(−1) n x2n+1 (2n + 1)! . (b) Similar derivatives for cos x give the absolutely convergent series cos x = ∞∑ n=0(−1)n x 2n (2n)! . 1.2.9. cot x = 1 x − x 3 − x 3 45 − 2x5 945 − · · · , −π < x < π. 1.2.10. From coth y = η0 = e y + e −y ey − e−y = e 2y + 1 e2y − 1 we extract y = 1 2 ln η0 + 1 η0 − 1 . To check this we substitute this into the ﬁrst relation, giving η0 + 1 η0 − 1 + 1 η0 + 1 η0 − 1 − 1 = η0. The series coth−1 η0 = ∞∑ n=0 (η0) −2n−1 2n + 1 follows from Exercise 1.6.1. CHAPTER 3. EXERCISE SOLUTIONS 12 1.2.11. (a) Since d√x dx ∣0 = 1 2√x ∣0 does not exist, there is no Maclaurin expan- sion.|x − x0| < x0 because the origin must be excluded. 1.2.12. lim x→x0 f (x) g(x) = f (x + (x0 − x)) g(x + (x0 − x) = lim x→x0 f (x) + (x0 − x)f ′(x) + · · · g(x) + (x0 − x)g′(x) + · · · = lim x→x0 f ′(x) g′(x) , where the intermediate formal expression f (x + (x0 − x)) g(x + (x0 − x) may be dropped. 1.2.13. (a) − ln n n − 1 = ln ( 1 − 1 n ) = − ∞∑ ν=1 1 νnν . Hence 1 n − ln n n − 1 = − ∞∑ ν=2 1 νnν < 0. (b) ln n + 1 n = ln(1 + 1 n ) = ∞∑ ν=2 (−1) ν−1 νnν , 1 n − ln n + 1 n = ∞∑ ν=2 (−1)ν νnν > 0. Summing (a) yields 0 > n∑ m=2 1 m − ln 2 · 3 · · · n 1 · 2 · · · (n − 1) = n∑ m=2 1 m − ln n → γ − 1. Thus, γ < 1. Summing (b) yields 0 < n−1∑ m=2 1 m − ln 2 · 3 · · · n 1 · 2 · · · (n − 1) = n−1∑ m=2 1 m − ln n → γ. Hence 0 < γ < 1. 1.2.14. The solution is given in the text. 1.2.15. The solutions are given in the text. 1.2.16. If ∣ an+1 an ∣ → 1 R then ∣ (n + 2)an+1 (n + 1)an ∣ → 1 R and ∣ an+1/(n + 2) an/(n + 1) ∣ → 1 R . 1.3 Binomial Theorem 1.3.1. P (x) = C { x 3 − x 3 45 + · · · }. 1.3.2. Integrating termwise tan −1 1 = π 4 = ∞∑ n=0(−1) n ∫ 1 0 x 2ndx = ∞∑ n=0 (−1)n 2n + 1 . CHAPTER 3. EXERCISE SOLUTIONS 13 1.3.3. The solution is given in the text. Convergent for 0 ≤ x < ∞. The upper limit x does not have to be small, but unless it is small the convergence will be slow and the expansion relatively useless. 1.3.4. sinh −1 x = x − 1 2 x 3 3 + 1 · 3 2 · 4 x 5 5 − · · · , −1 ≤ x ≤ 1. 1.3.5. The expansion of the integral has the form ∫ 1 0 dx 1 + x2 = ∫ 1 0 (1 − x 2 + x 4 − x 6 + · · · ) dx = 1 − 1 3 + 1 5 − 1 7 + · · · . 1.3.6. For m = 1, 2, . . . the binomial expansion gives (1+x)−m/2 = ∞∑ n=0 ( −m/2 n ) x n. By mathematical induction we show that ( −m/2 n ) = (−1) n (m + 2n − 2)!! 2n(m − 2)!!n! . 1.3.7. (a) ν′ = ν { 1 ± ν c + ν2 c2 + · · · } . (b) ν′ = ν {1 ± ν c } . (c) ν′ = ν { 1 ± ν c + 1 2 ν2 c2 + · · · } . 1.3.8. (a) ν1 c = δ + 1/2δ2. (b) ν2 c = δ − 3/2δ2 + · · · . (c) ν3 c = δ − 1/2δ2 + · · · . 1.3.9. w c = 1 − α2 2 − α3 2 + · · · . 1.3.10. x = 1 2 gt2 − 1 8 g3t4 c2 + 1 16 g5t 6 c4 − · · · . 1.3.11. E = mc 2 [1 − γ2 2n2 − γ4 2n4 ( n |k| − 3 4 ) + · · · ] . 1.3.12. The solution is given in the text. 1.3.13. The two series have diﬀerent, nonoverlapping convergence intervals. 1.3.14. (a) Diﬀerentiating the geometric series ∞∑ n=0 x n = 1 1 − x for x = exp(−ε0/kT ) yields x (1 − x)2 = ∞∑ n=1 nx n. Therefore, ⟨ε⟩ = ε0x 1 − x = ε0 eε0/kT − 1 . CHAPTER 3. EXERCISE SOLUTIONS 14 (b) Expanding y ey − 1 = 1 + y 2 + · · · we ﬁnd ⟨ε⟩ = kT (1 + ε0 2kT + · · · ) = kT + ε0 + · · · . 1.3.15. (a) tan −1 x = ∞∑ n=0(−1) n ∫ x 0 t 2ndt = ∞∑ n=0 (−1) n 2n + 1 x2n+1, |x| ≤ 1. (b) Writing x = tan y as ix = e 2iy + 1 e2iy − 1 we extract y = − i 2 ln 1 + ix 1 − ix . 1.3.16. Start by obtaining the ﬁrst few terms of the power-series expansion of the expression within the square brackets. Write 2 + 2ε 1 + 2ε = 1 + 1 1 + 2ε = 2 − 2ε + (2ε) 2 − · · · , ln(1 + 2ε ε = 1 ε [2ε − (2ε) 2 2 + (2ε) 3 3 − · · · ] [ 2 + 2ε 1 + 2ε − ln(1 + 2ε ε ] = 4 3 ε2 + O(ε3) . Inserting this into the complete expression for f (ε), the limit is seen to be 4/3. 1.3.17. Let x = 1/A, and write xi1 = 1 + (1 − x) 2 2x ln 1 − x 1 + x . Expanding the logarithm, ξ1 = 1 + (1 − x) 2 2x (−2x − 2x3 3 − · · · ) = 2x − 4 3 x 2 + 2 3 x 3 − · · · . The similar expansion of ξ2 = 2x 1 + 2x/3 yields ξ2 = 2x − 4 3 x 2 + 8 9 x 3 − · · · . Comparing these expansions, we note agreement through x 2, and the x 3 terms diﬀer by (2/9)x 3, or 2/9A3. 1.3.18. (a) Insert the power-series expansion of arctan t and carry out the inte- gration. The series for β(2) is obtained. (b) Integrate by parts, converting ln x into 1/x and 1/(1+x2) into arctan x. The integrated terms vanish, and the new integral is the negative of that already treated in part (a). CHAPTER 3. EXERCISE SOLUTIONS 15 1.4 Mathematical Induction 1.4.1. Use mathematical induction. First evaluate the claimed expression for the sum for both n − 1 and n: Sn−1 = n − 1 30 (2n − 1)n [ 3(n − 1) 2 + 3(n − 1) − 1 ] = n5 5 − n4 2 + n3 3 − n 30 Sn = n 30 (2n + 1)(n + 1)(3n 2 + 3n − 1) = n 5 5 + n 4 2 + n 3 3 − n 30 Next verify that Sn = Sn−1 + n4. Complete the proof by verifying that S1 = 1. 1.4.2. Use mathematical induction. First, diﬀerentiate the Leibniz formula for− 1, getting the two terms n−1∑ j=0 ( n − 1 j ) [( d dx )j+1 f (x) ] [( d dx )n−1−j g(x) ] + n−1∑ j=0 ( n − 1 j ) [( d dx )j f (x) ] [( d dx )n−j g(x) ] Now change the index of the ﬁrst summation to (j − 1), with j ranging from 1 to n; the index can be extended to j = 0 because the binomial coeﬃcient (n−1 −1 ) vanishes. The terms then combine to yield n∑ j=0 [(n − 1 j − 1 ) + ( n − 1 j )] [( d dx )j f (x) ] [( d dx )n−j g(x) ] The sum of two binomial coeﬃcients has the value ( n j ) , thereby conﬁrming that if the Leibnize formula is correct for n − 1, it is also correct for n. One way to verify the binomial coeﬃcient sum is to recognize that it is the number of ways j of n objects can be chosen: either j − 1 choices are made from the ﬁrst n − 1 objects, with the nth object the jth choice, or all j choices are made from the ﬁrst n − 1 objects, with the nth object remaining unchosen. The proof is now completed by noticing that the Leibniz formula gives a correct expression for the ﬁrst derivative. 1.5 Operations on Series Expansions of Functions 1.5.1. The partial fraction expansion is 1 1 − t2 = 1 2 [ 1 1 + t + 1 1 − t ] , CHAPTER 3. EXERCISE SOLUTIONS 16 with integral ∫ x −x dt 1 − t2 = 1 2 [ ln(1 + x) − ln(1 − x)]∣ x x = 1 2 ln ( 1 + x 1 − x )x x . The upper and lower limits give the same result, canceling the factor 1/2. 1.5.2. Start by writing the partial-fraction expansion for p + 1 using the assumed form of that for p multiplied by an additional factor 1/(n + p + 1). Thus, we want to see if we can simplify 1 p ! p∑ j=0 (p j ) (−1)j n + j ( 1 n + p + 1 ) to get the expected formula. Our ﬁrst step is to expand the two factors containing n into partial fractions: 1 (n + j)(n + p + 1) = ( 1 p + 1 − j ) ( 1 n + j − 1 n + p + 1 ) Replacing the 1/(n + j) term of our original expansion using this result and adding a new 1/(n + p + 1) term which is the summation of the above result for all j, we reach p∑ j=0 (−1) j n + j [ 1 p ! ( p j ) 1 p + 1 − j ] + p∑ j=0 [ 1 p ! (p j ) 1 p + 1 − j ] (−1)j−1 n + p + 1 Using the ﬁrst formula supplied in the Hint, we replace each square bracket by the quantity 1 (p + 1)! ( p + 1 j ) , thereby identifying the ﬁrst summation as all but the last term of the partial-fraction expansion for p + 1. The second summation can now be written 1 (p + 1)!  p∑ j=0(−1)j−1( p + 1 j ) 1 n + p + 1 . Using the second formula supplied in the Hint, we now identify the quan- tity within square brackets as p+1∑ j=1(−1) j−1( p + 1 j ) − (−1)p( p + 1 p + 1 ) + (−1) −1( p + 1 0 ) = 1 + (−1)p+1 − 1 = (−1) p+1, CHAPTER 3. EXERCISE SOLUTIONS 17 so the second summation reduces to (−1)p+1 (p + 1)! 1 n + p + 1 , as required. Our proof by mathematical induction is now completed by observing that the partial-fraction formula is correct for the case p = 0. 1.5.3. The formula for un(p) follows directly by inserting the partial fraction decomposition. If this formula is summed for n from 1 to inﬁnity, all terms cancel except that containing u1, giving the result ∞∑ n=1 un(p) = u1(p − 1) p . The proof is then completed by inserting the value of u1(p − 1). 1.5.4. After inserting Eq. (1.88) into Eq. (1.87), make a change of summation variable from n to p = n − j, with the ranges of j and p both from zero to inﬁnity. Placing the p summation outside, and moving quantities not dependent upon j outside the j summation, reach f (x) = ∞∑ p=0(−1) pcp x p (1 + x)p+1 ∞∑ j=0 ( p + j j ) ( x 1 + x )j . Using now Eq. (1.71), we identify the binomial coeﬃcient in the above equation as (p + j j ) = (−1)j( −p − 1 j ) , so the j summation reduces to ∞∑ j=0 ( −p − 1 j ) (− x 1 + x )j = ( 1 − x 1 + x )−p−1 = (1 + x)p+1. Insertion of this expression leads to the recovery of Eq. (1.86). 1.5.5. Applying Eq. (1.88) to the coeﬃcients in the power-series expansion ofx), the ﬁrst 18 an (a0 through a17) are: 0, −1, 2, −8/3, 8/3, −28/15, 8/15, 64/105, −64/105,−368/15, 1376/315, 1376/315, −25216/3465, 25216/3465, −106048/45045, −305792/45045, 690176/45045, −690176/45045, 201472/765765. Using these in Eq. (1.87) for x = 1, the terms through a17 yield the approximate value arctan(1) ≈ 0.785286, fairly close to the exact value at this precision, 0.785398. For this value of x, the 18th nonzero term in the power series is −1/35, showing that a power series for x = 1 cut oﬀ after 18 terms would barely give a result good to two signiﬁcant ﬁgures. The 18-term Euler expansion yields arctan(1/ √ 3) ≈ 0.523598, while the exact value at this precision is 0.523599. CHAPTER 3. EXERCISE SOLUTIONS 18 1.6 Some Important Series 1.6.1. For |x| < 1, ln 1 + x 1 − x = ∞∑ ν=0 x ν ν [ (−1) ν−1 + 1 ] = 2 ∞∑ n=0 x 2n+1 2n + 1 . 1.7 Vectors 1.7.1. Ax = Ay = Az = 1. 1.7.2. The triangle sides are given by AB = B − A, BC = C − B, CA = A − C with AB + BC + CA = (B − A) + (C − B) + (A − C) = 0. 1.7.3. The solution is given in the text. 1.7.4. If v′ i = vi − v1, r ′ = ri − r1, are the velocities and distances, respectively, from the galaxy at r1, then v′ i = H0(ri − r1) = H0r ′ holds, i.e., the same Hubble law. 1.7.5. With one corner of the cube at the origin, the space diagonals of length 3 are: (1, 0, 1) − (0, 1, 0) = (1, −1, 1), (1, 1, 1) − (0, 0, 0) = (1, 1, 1), (0, 0, 1) − (1, 1, 0) = (−1, −1, 1), (1, 0, 0) − (0, 1, 1) = (1, −1, −1). The face diagonals of length √2 are: (1, 0, 1) − (0, 0, 0) = (1, 0, 1), (1, 0, 0) − (0, 0, 1) = (1, 0, −1); (1, 0, 0) − (0, 1, 0) = (1, −1, 0), (1, 1, 0) − (0, 0, 0) = (1, 1, 0); (0, 1, 0) − (0, 0, 1) = (0, 1, −1), (0, 1, 1) − (0, 0, 0) = (0, 1, 1). 1.7.6. (a) The surface is a plane passing through the tip of a and perpendicular to a. (b) The surface is a sphere having a as a diameter: (r − a) · r = (r − a/2)2 − a2/4 = 0. 1.7.7. The solution is given in the text. 1.7.8. The path of the rocket is the straight line r = r1 + tv, or in Cartesian coordinates x(t) = 1 + t, y(t) = 1 + 2t, z(t) = 1 + 3t. CHAPTER 3. EXERCISE SOLUTIONS 19 We now minimize the distance |r − r0| of the observer at the point r0 = (2, 1, 3) from r(t), or equivalently (r−r0)2 =min. Diﬀerentiating the rocket path with respect to t yields ˙r = ( ˙x, ˙y, ˙z) = v. Setting d dt (r − r0) 2 = 0 we obtain the condition 2(r − r0) · ˙r = 2[r1 − r0 + tv] · v = 0. Because ˙r = v is the tangent vector of the line, the geometric meaning of this condition is that the shortest distance vector through r0 is perpendicular to the line, or the velocity of the rocket. Now solving for t yields the ratio of scalar products t = − (r1 − r0) · v v2 = − (−1, 0, −2) · (1, 2, 3) (1, 2, 3) · (1, 2, 3) = 1 + 0 + 6 1 + 4 + 9 = 1 2 . Substituting this parameter value into the rocket path gives the points = (3/2, 2, 5/2) on the line that is closest to r0. The shortest distance is d = |r0 − rs| = |(−1/2, 1, −1/2)| = √ 2/4 + 1 = √ 3/2. 1.7.9. Consider each corner of the triangle to have a unit of mass and be locatedai from the origin where, for example, a1 = (2, 0, 0), a2 = (4, 1, 1), a3 = (3, 3, 2). Then the center of mass of the triangle is 1 3 (a1 + a2 + a3) = acm = 1 3 (2 + 4 + 3, 1 + 3, 1 + 2) = ( 3, 4 3 , 1 ) . The three midpoints are located at the point of the vectors 1 2 (a1 + a2) = 1 2 (2 + 4, 1, 1) = ( 3, 1 2 , 1 2 ) 1 2 (a2 + a3) = 1 2 (4 + 3, 1 + 3, 1 + 2) = ( 7 2 , 2, 3 2 ) 1 2 (a3 + a1) = 1 2 (2 + 3, 3, 2) = ( 5 2 , 3 2 , 1) . CHAPTER 3. EXERCISE SOLUTIONS 20 We start from each corner and end up in the center as follows (2, 0, 0) + 2 3 [( 7 2 , 2, 3 2 ) − (2, 0, 0) ] = ( 3, 4 3 , 1 ) a1 + 2 3 ( 1 2 (a2 + a3) − a1 ) = 1 3 (a1 + a2 + a3), (4, 1, 1) + 2 3 [( 5 2 , 3 2 , 1 ) − (4, 1, 1) ] = ( 3, 4 3 , 1 ) a2 + 2 3 ( 1 2 (a1 + a3) − a2 ) = 1 3 (a1 + a2 + a3), (3, 3, 2) + 2 3 [(3, 1 2 , 1 2 ) − (3, 3, 2) ] = ( 3, 4 3 , 1 ) a3 + 2 3 ( 1 2 (a1 + a2) − a3 ) = 1 3 (a1 + a2 + a3). 1.7.10. A2 = A2 = (B − C) 2 = B2 + C 2 − 2BC cos θ with θ the angle between ˆB and ˆC. 1.7.11. P and Q are antiparallel; R is perpendicular to both P and Q. 1.8 Complex Numbers and Functions 1.8.1. (a) (x + iy) −1 = x − iy x2 + y2 . (b) x + iy = reiθ gives (x + iy) −1 = e −iθ r = 1 r (cos θ − i sin θ) = x − iy r2 = x − iy x2 + y2 . 1.8.2. If z = reiθ, √z = √reiθ/2 = √r(cos θ/2 + i sin θ/2). In particular, √i = e iπ/4 = 1 + i √2 or √i = e −i3π/4. 1.8.3. e inθ = cos nθ+i sin nθ = (e iθ)n = (cos θ+i sin θ) n = n∑ ν=0 (n ν) cosn−ν θ(i sin θ)ν. Separating real and imaginary parts we have cos nθ = [n/2]∑ ν=0 (−1) ν( n 2ν ) cosn−2ν θ sin 2ν θ, sin nθ = [n/2]∑ ν=0 (−1) ν( n 2ν + 1 ) cosn−2ν−1 θ sin 2ν+1 θ. CHAPTER 3. EXERCISE SOLUTIONS 21 1.8.4. N −1∑ n=0 (e ix) n = 1 − e iN x 1 − eix = e iN x/2 eix/2 e iN x/2 − e −iN x/2 eix/2 − e−ix/2 = e i(N −1)x/2 sin(N x/2)/ sin(x/2). Now take real and imaginary parts to get the result. 1.8.5. (a) sinh(iz) = ∞∑ n=0 (iz)2n+1 (2n + 1)! = i ∞∑ n=0(−1) n z2n+1 (2n + 1)! = i sin z. All other identities are shown similarly.e i(z1+z2) = cos(z1 + z2) + i sin(z1 + z2) = e iz1e iz2 = (cos z1 + i sin z1)(cos z2 + i sin z2) = cos z1 cos z2 − sin z1 sin z2 + i(sin z1 cos z2 + sin z2 cos z1). Separating this into real and imaginary parts for real z1, z2 proves the addition theorems for real arguments. Analytic continuation extends them to the complex plane. 1.8.6. (a) Using cos iy = cosh y, sin iy = i sinh y, etc. and the addition theorem we obtain sin(x + iy) = sin x cosh y + i cos x sinh y, etc. (b) | sin z| 2 = sin(x + iy) sin(x − iy) = sin 2 x cosh2 y + cos2 x sinh 2 y = sin 2 x(cosh2 y − sinh 2 y) + sinh 2 y = sin2 x + sinh2 y, etc. 1.8.7. (a) Using cos iy = cosh y, sin iy = i sinh y, etc. and the addition theorem we obtain sinh(x + iy) = sinh x cos y + i cosh x sin y, etc. (b) | cosh(x+iy)| 2 = cosh(x+iy) cosh(x−iy) = cosh2 x cos2 y+sinh 2 x sin 2 y = sinh2 x + cos2 y, etc. 1.8.8. (a) Using Exercise 1.8.7(a) and rationalizing we getx + iy) = sinh x cos y + i cosh x sin y cosh x cos y + i sinh x sin y = 1 2 sinh 2x(cos2 y + sin 2 y) + i 2 sin 2y(cosh2 x − sinh 2 x) cosh2 x cos2 y + sinh2 x sin 2 y = 1 2 sinh 2x + i sin 2y cos2 y + sinh 2 x = sinh 2x + sin 2y cos 2y + cosh 2x . (b) Starting from cosh(x + iy) sinh(x + iy) this is similarly proved. CHAPTER 3. EXERCISE SOLUTIONS 22 1.8.9. The expansions relevant to this exercise are tan −1 x = x − x 3 3 + x5 5 − · · · ln(1 − ix) = −ix + x 2 2 + ix 3 3 − · · · ln(1 + ix) = ix + x 2 2 − ix 3 3 − · · · The desired identity follows directly by comparing the expansion of tan −1 x with i/2 times the diﬀerence of the other two expansions. 1.8.10. (a) The cube roots of −1 are −1, e πi/3 = 1/2 + i √3/2, and e −πi/3 = 1/2 − i√3/2, so our answers are −2, 1 + i √3, and 1 − i √3. (b) Write i as e πi/2; its 1/4 power has values e (πi/2+2nπ)/4 for all integer n; there are four distinct values: e iπ/8 = cos π/8 + i sin π/8, e 5iπ/8 = cos 5π/8 + i sin 5π/8, e 9iπ/8 = −e iπ/8, and e 13iπ/8 = −e 5iπ/8. (c) e iπ/4 has the unique value cos π/4 + i sin π/4 = (1 + i)/ √2. 1.8.11. (a) (1 + i) 3 has a unique value. Since 1 + i has magnitude √2 and is at an angle of 45 ◦ = π/4, (1 + i)3 will have magnitude 2 3/2 and argument 3π/4, so its polar form is 2 3/2e 3iπ/4. (b) Since −1 = e πi, its 1/5 power will have values e (2n+1)πi for all integer n. There will be ﬁve distinct values: e kπi/5 with k = 1, 3, 5, 7, and 9. 1.9 Derivatives and Extrema 1.9.1. Expand ﬁrst as a power series in x, with y kept at its actual value. Then expand each term of the x expansion as a power series in y, regarding x as ﬁxed. The nth term of the x expansion will be x n n! ( ∂ ∂x )n f (x, y) ∣x=0,y=0 The mth term in the y expansion of the xn term is therefore xn n! ym m! ( ∂ ∂y )m ( ∂ ∂x )n f (x, y) ∣x=0,y=0 The coeﬃcient in the above equation can be written 1 (m + n)! (m + n)! m!n! = 1 (m + n)! ( m + n n ). Using the right-hand side of the above equation and collecting together all terms with the same value of m + n, we reach the form given in the exercise. CHAPTER 3. EXERCISE SOLUTIONS 23 1.9.2. The quantities αi are regarded as independent of the xi when the diﬀer- entiations are applied. Then, expansion of the diﬀerential operator raised to the power n will, when combined with t n, produce terms with a total of n derivatives applied to f , with each term containing a power of each xi equal to the number of times xi was diﬀerentiated. The coeﬃcient of each distinct term in the expansion of this nth order derivative will be the number of ways that derivative combination occurs in the expansion; the term in which each xj derivative is applied nj times occurs in the following number of ways: n! n1!n2! · · · , with the sum of the ni equal to n. Inserting this formula, we obtain the same result that would be obtained if we expanded, ﬁrst in x1, then in x2, etc. 1.10 Evaluation of Integrals 1.10.1. Apply an integration by parts to the integral in Table 1.2 deﬁning the gamma function, for integer n > 0: Γ(n) = ∫ ∞ 0 t n−1e −tdt = ( t n n ) e −t∣ ∞ + ∫ ∞ 0 tn n e −xdx = Γ(n + 1) n . Rearranging to Γ(n + 1) = nΓ(n), we apply mathematical induction, not- ing that if Γ(n) = (n − 1)!, then also Γ(n + 1) = n!. To complete the proof, we directly evaluate the integral Γ(1) = ∫ ∞ 0 e −xdx = 1, which is 0!. 1.10.2. This integral can also be evaluated using contour integration (see Exam- ple 11.8.5). A method motivated by the discussion of this section starts by multiplying the integrand by e −αx and considering the value of this integral when α = 0. We can start by diﬀerentiating the integral by the parameter α, corresponding to I(α) = ∫ ∞ 0 sin xe −αx x dx, I ′(α) = − ∫ ∞ 0 e −αx sin x dx = − 1 α2 + 1 , where the integral for I ′ is ientiﬁed as having the value found in Example 1.10.4. We now integrate the expression for I ′, writing it as the indeﬁnite integral I(α) = − tan −1 α + C . The value of C is now determined from the value of I(∞), which from the form of I must be zero. Thus, C = tan −1 ∞ = π/2, and, since tan −1 0 = 0, we ﬁnd I(0) = π/2. 1.10.3. Write the integrand as 1 cosh x = 2 ex + e−x = 2e −x 1 + e−2x = 2(e −x − e −3x + e −5x − · · · ). CHAPTER 3. EXERCISE SOLUTIONS 24 Now integrate term by term; each integrand is a simple exponential. The result is 2 ( 1 − 1 3 + 1 5 − 1 7 + · · · ) . The series in parentheses is that discussed in Exercise 1.3.2, with value π/4. Our integral therefore has value π/2. 1.10.4. Expand the integrand as a power series in e −ax and integrate term by term: ∫ ∞ 0 dx eax + 1 = ∫ ∞ 0 (e −ax − e −2ax + e −3ax − · · · ) = 1 a − 1 2a + 1 3a − · · · After factoring out (1/a), the series that remains is that identiﬁed in Eq. (1.53) as ln 2, so our integral has value ln(2)/a. 1.10.5. Integrate by parts, to raise the power of x in the integrand: ∫ ∞ π sin x x2 dx = ∫ ∞ π cos x x dx . Note that the integrated terms vanish. The integral can now be recognized (see Table 1.2) as −Ci(π). 1.10.6. This is a case of the integral I(α) deﬁned in the solution of Exercise 1.10.2, with α = 1. We therefore have I(α) = π 2 − tan −1 α; I(1) = π 2 − π 4 = π 4 . 1.10.7. Write erf as an integral and interchange the order of integration. We get ∫ x 0 erf(t) dt = 2 √π ∫ x 0 dx ∫ t 0 e −u2 du = 2 √π ∫ x 0 e −u2 du ∫ x u dt = 2 √π ∫ x 0 e −u2(x − u)du = x erf(x) − 1 √π ∫ x 0 2ue−u 2 du = x erf(x) + 1 √π (e −x2 − 1 ) . 1.10.8. Write E1 as an integral and interchange the order of integration. Now the outer (u) integration must be broken into two pieces: ∫ x 1 E1(t)dt = ∫ x 1 dt ∫ ∞ t e −u u du = ∫ x 1 e −u u du ∫ u 1 dt + ∫ ∞ x e −u u du ∫ x 1 dt = ∫ x 1 e −u u (u − 1) du + ∫ ∞ x e −u u (x − 1) du = e −1 − e −x − E1(1) + E1(x) + (x − 1)E1(x) = e −1 − e −x − E1(1) + xE1(x). CHAPTER 3. EXERCISE SOLUTIONS 25 1.10.9. Change the variable of integration to y = x + 1, leading to ∫ ∞ 0 e −x x + 1 dx = ∫ ∞ 1 e −y+1 y dy = e E1(1). 1.10.10. After the integration by parts suggested in the text, with [tan −1 x]2 dif- ferentiated and dx/x 2 integrated, the result is I(1), where I(a) = ∫ ∞ 0 2 tan −1 ax x(x2 + 1) dx We now diﬀerentiate I(a) with respect to the parameter a, reaching after a partial-fraction decomposition I ′(a) = 2 ∫ ∞ 0 dx (x2 + 1)(a2x2 + 1) = 2 1 − a2 ∫ ∞ 0 [ 1 x2 + 1 − a2 a2x2 + 1 ] dx = 2 1 − a2 [ π 2 − a 2 ( π 2a )] = π 1 + a . Integrating with respect to a, we get I(a) = π ln(1 + a) + C, with C set to zero to obtain the correct result I(0) = 0. Then, setting a = 1, we ﬁnd I(1) = π ln 2, as required. 1.10.11. Integrating over one quadrant and multiplying by four, the range of x is (0, a) and, for given x, the range of y is from 0 to the positive y satisfying the equation for the ellipse. Thus, A = 4 ∫ a 0 dx ∫ b√a2−x2/a 0 dy = 4b a ∫ a 0 √ a2 − x2 dx = 4b a ( a 2π 4 ) = πab. 1.10.12. Draw the dividing line at y = 1/2. Then the contribution to the area for each y between 1/2 and 1 is 2 √ 1 − y2, so A = 2 ∫ 1 1/2 √1 − y2 dy = π 3 − √3 4 . A simple explanation of these two terms is that π/3 is the area of the sector that includes the piece in question, while √3/4 is the area of the triangle that is the part of the sector not included in that piece. 1.11 Dirac Delta Function 1.11.1. The mean value theorem gives lim n→∞ ∫ f (x)δn(x)dx = lim n→∞ n ∫ 1/2n −1/2n f (x)dx = lim n→∞ n n f (ξn) = f (0), as − 1 2n ≤ ξn ≤ 1 2n . CHAPTER 3. EXERCISE SOLUTIONS 26 1.11.2. Use the elementary integral ∫ dx 1 + x2 = arctan z, thus reaching ∫ ∞ −∞ dx 1 + n2x2 = π n . 1.11.4. ∫ ∞ −∞ f (x)δ(a(x − x1))dx = 1 a ∫ ∞ −∞ f ((y + y1)/a)δ(y)dy = 1 a f ( y1 a ) = 1 a f (x1) = ∫ ∞ −∞ f (x)δ(x − x1) dx a . 1.11.5. The left-hand side of this equation is only nonzero in the neighborhoodx = x1, where it is a case of Exercise 1.11.4, and in the neighborhood of x = x2, where it is also a case of Exercise 1.11.4. In both cases, the quantity playing the role of a is |x1 − x2|. 1.11.7. Integrating by parts we ﬁnd ∫ ∞ −∞ δ′(x)f (x) dx = − ∫ ∞ −∞ f ′(x)δ(x)dx = −f ′(0). 1.11.9. (a) Inserting the given form for δn(x) and changing the variable of inte- gration to nx, we obtain a result that is independent of n. The indeﬁnite integral of 1/ cosh 2 x is tanh(x), which approaches +1 as x → +∞ and −1 as x → −∞, thus conﬁrming the normalization claimed for δn. (b) The behavior of tanh(x) causes the right-hand side of this equation to approach zero for large n and negative x, but to approach +1 for large n and positive x. CHAPTER 3. EXERCISE SOLUTIONS 27 2. Determinants and Matrices 2.1 Determinants 2.1.1. (a) −1. (b) −11. (c) 9/ √2. 2.1.2. The determinant of the coeﬃcients is equal to 2. Therefore no nontrivial solution exists. 2.1.3. Given the pair of equations x + 2y = 3, 2x + 4y = 6. (a) Since the coeﬃcients of the second equation diﬀer from those of the ﬁrst one just by a factor 2, the determinant of (lhs) coeﬃcients is (b) Since the inhomogeneous terms on the right-hand side diﬀer by the same factor 2, both numerator determinants also vanish. (c) It suﬃces to solve x + 2y = 3. Given x, y = (3 − x)/2. This is the general solution for arbitrary values of x. 2.1.4. (a) Cij is the quantity that multiplies aij in the expansion of the deter- minant. The sum over i collects the quantities that multiply all the aij in column j of the determinant. (b) These summations form determinants in which the same column (or row) appears twice; the determinant is therefore zero, 2.1.5. The solution is given in the text. 2.1.6. If a set of forms is linearly dependent, one of them must be a linear combination of others. Form the determinant of their coeﬃcients (with each row describing one of the forms) and subtract from one row the linear combination of other rows that reduces that row to zero. The determinant (whose value is not changed by the operation) will be seen to be zero. 2.1.7. The Gauss elimination yields 10x1 + 9x2 + 8x3 + 4x4 + x5 = 10, x2 + 2x3 + 3x4 + 5x5 + 10x6 = 5, 10x3 + 23x4 + 44x5 − 60x6 = −5, 16x4 + 48x5 − 30x6 = 15, 48x5 + 498x6 = 215, −11316x6 = −4438, so x6 = 2219/5658, x5 = (215 − 498x6)/48, x4 = (15 + 30x6 − 48x5)/16, CHAPTER 3. EXERCISE SOLUTIONS 28 x3 = (−5 + 60x6 − 44x5 − 23x4)/10, x2 = 5 − 10x6 − 5x5 − 3x4 − 2x3, x1 = (10 − x5 − 4x4 − 8x3 − 9x2)/10. 2.1.8. (a) δii = 1 (not summed) for each i = 1, 2, 3. (b) δijεijk = 0 because δij is symmetric in i, j while εijk is antisymmetric in i, j. (c) For each ε in εipqεjpq to be non-zero, leaves only one value for i and j, so that i = j. Interchanging p and q gives two terms, hence the factor 2. (d) There are 6 permutations i, j, k of 1, 2, 3 in εijkεijk = 6. 2.1.9. Given k implies p ̸= q for εpqk ̸= 0. For εijk ̸= 0 requires either i = p and so j = q, or i = q and then j = p. Hence εijkεpqk = δipδjp − δiqδjp. 2.2 Matrices 2.2.1. Writing the product matrices in term of their elements, AB = ( ∑ m aimbmk), BC = ( ∑ n bincnk), (AB)C = ( ∑ n ( ∑ m aimbmn ) cnk ) = ∑ mn aimbmncnk = A(BC) = ( ∑ m aim ( ∑ n bmncnk )) , because products of real and complex numbers are associative the paren- theses can be dropped for all matrix elements. 2.2.2. Multiplying out (A + B)(A − B) = A 2 + BA − AB − B 2 = A 2 − B 2 + [B, A]. 2.2.3. (a) (a1 + ib1) − (a2 + ib2) = a1 − a2 + i(b1 − b2) corresponds to ( a1 b1 −b1 a1 ) − ( a2 b2 −b2 a2 ) = ( a1 − a2 b1 − b2 −(b1 − b2) a1 − a2 ) , i.e., the correspondence holds for addition and subtraction. Similarly, it holds for multiplication because ﬁrst (a1 + ib1)(a2 + ib2) = (a1a2 − b1b2) + i(a1b2 + a2b1) and matrix multiplication yields ( a1 b1 −b1 a1 ) ( a2 b2 −b2 a2 ) = ( a1a2 − b1b2 a1b2 + a2b1 −(a1b2 + a2b1) a1a2 − b1b2 ) . CHAPTER 3. EXERCISE SOLUTIONS 29 (b) (a + ib) −1 ←→ ( a/(a 2 + b 2) −b/(a 2 + b2) b/(a2 + b2) a/(a 2 + b2) ) . 2.2.4. A factor (−1) can be pulled out of each row giving the (−1) n overall. 2.2.5. (a) First we check that ( ab b2 −a2 −ab ) ( ab b 2 −a 2 −ab ) = ( a2b 2 − a2b2 ab 3 − ab 3 −a3b + a 3b −a2b 2 + a2b2 ) = 0. Second, to ﬁnd the constraints we write the general matrix as ( A B C D ) ( A B C D ) = ( A2 + BC B(A + D) C(A + D) BC + D2 ) = 0 giving D = −A, D2 = −BC = A2. This implies, if we set B = b 2, C = −a2 without loss of generality, that A = ab = −D. 2.2.6. n = 6. 2.2.7. Expanding the commutators we ﬁnd [A, [B, C]] = A[B, C] − [B, C]A = ABC − ACB − BCA + CBA, [B, [A, C]] = BAC − BCA − ACB + CAB, [C, [A, B]] = CAB − CBA − ABC + BAC, and subtracting the last double commutator from the second yields the ﬁrst one, since the BAC and CAB terms cancel. 2.2.8. By direct multiplication of the matrices we ﬁnd [A, B] = AB = C, BA = 0, etc. 2.2.9. These results can all be veriﬁed by carrying out the indicated matrix multiplications. 2.2.10. If aik = 0 = bik for i > k, then also ∑ m aimbmk = ∑ i≤m≤k aimbmk = 0, as the sum is empty for i > k. 2.2.11. By direct matrix multiplications and additions. 2.2.12. By direct matrix multiplication we verify all claims. 2.2.13. By direct matrix multiplication we verify all claims. CHAPTER 3. EXERCISE SOLUTIONS 30 2.2.14. For i ̸= k and aii ̸= akk we get for the product elements (AB)ik = ( ∑ n ainbnk) = (aiibik) = (BA)ik = ( ∑ n binank) = (bikakk). Hence bik = 0 for i ̸= k. 2.2.15. ∑ m aimbmk = aiibiiδik = ∑ m bimamk. 2.2.16. Since trace ABC = trace BCA, choose one of the foregoing in which two commuting matrices appear adjacent to each other and interchange their order. Then make a cyclic permutation if needed to reach CBA. 2.2.17. Taking the trace, we ﬁnd from [Mi, Mj] = iMk that i trace(Mk) = trace(MiMj − MjMi) = trace(MiMj) − trace(MiMj) = 0. 2.2.18. Taking the trace of A(BA) = −A 2B = −B yields −tr(B) = tr(A(BA)) = tr(A 2B) = tr(B). 2.2.19. (a) Starting from AB = −BA, multiply on the left by B −1 and take the trace. After simpliﬁcation, we get trace B = −trace B, so trace B = 0. 2.2.20. This is proved in the text. 2.2.21. (a) A unit matrix except that Mii = k, (b) A unit matrix except that Mim = −K, (c) A unit matrix except that Mii = Mmm = 0 and Mmi − Mim = 1. 2.2.22. Same answers as Exercise 2.2.21. 2.2.23. A−1 = 1 7  7 −7 0 −7 11 −1 0 −1 2  . 2.2.24. (a) The equation of part (a) states that T moves people from area j but does not change their total number. (b) Write the component equation ∑ j TijPj = Qi and sum over i. This summation replaces Tij by unity, leaving that the sum over Pj equals the sum over Qi, hence conserving people. 2.2.25. The answer is given in the text. 2.2.26. If O −1 i = ˜Oi, i = 1, 2, then (O1O2)−1 = O −1 2 O−1 1 = ˜O2 ˜O1 = ̃O1O2. 2.2.27. Taking the determinant of ˜AA = 1 and using the product theorem yields det(˜A) det(A) = 1 = det 2(A) implying det(A) = ±1. 2.2.28. If ˜A = −A, ˜S = S, then trace( ̃SA) = trace(SA) = trace(˜A˜S) = −trace(AS). CHAPTER 3. EXERCISE SOLUTIONS 31 2.2.29. From ˜A = A −1 and det(A) = 1 we have A −1 = ( a22 −a12 −a21 a11 ) = ˜A = ( a11 a21 a12 a22 ) . This gives det(A) = a2 + a2 = 1, hence a11 = cos θ = a22, a12 = sin θ = −a21, the standard 2 × 2 rotation matrix. 2.2.30. Because ε is real, det(A ∗) = ∑ ik εi1i2...ina∗i1a∗i2 · · · a ∗ n = ( ∑ ik εi1i2...ina1i1 a2i2 · · · anin )∗ = (det A) ∗ . Because, for any A, det(A) = det(˜A), det(A ∗) = det(A †). 2.2.31. If Jx and Jy are real, so also must be their commutator, so the commuta- tion rule requires that Jz be pure imaginary. 2.2.32. (AB)† = ̃A∗B∗ = ˜B ∗ ˜A ∗ = B †A †. 2.2.33. As Cjk = ∑ n S∗ njSnk, trace (C) = ∑ nj |Snj| 2. 2.2.34. If A † = A, B † = B, then (AB + BA)† = B †A † + A †B † = AB + BA, −i(B †A † − A †B †) = i(AB − BA). 2.2.35. If C† ̸= C, then (iC−)† ≡ (C † − C)† = C − C† = −iC † , i.e. (C−)† = C−. Similarly C † = C+ = C + C †. 2.2.36. −iC † = (AB − BA) † = B †A † − A †B † = BA − AB = −iC. 2.2.37. (AB)† = B †A † = BA = AB yields [A, B] = 0 as the condition, that is, the answer in the text. 2.2.38. (U †) † = U = (U −1) †. 2.2.39. (U1U2) † = U †U † = U −1 2 U −1 1 = (U1U2)−1. 2.2.40. Start by noting the relationships σiσj + σjσi = 0 if i ̸= j, and σ2 i = 12; see Eq. (2.59); for proof add Eqs. (2.29) and (2.30). Then, (p · σ) 2 = (pxσ1 + pyσ2 + pzσ3)2 expands to p2 σ2 1 + p2σ2 2 + p2σ2 3 + pxpy(σ1σ2 + σ2σ1) + pxpz(σ1σ3 + σ3σ1) + pypz(σ1σ2 + σ2σ1) = p2 + p2 + p2 = p 2 . CHAPTER 3. EXERCISE SOLUTIONS 32 2.2.41. Writing γ0 = σ3 ⊗ 1 and γi = γ ⊗ σi (i = 1, 2, 3), where γ = ( 0 1 −1 0 ) , and noting fron Eq. (2.57) that if C = A ⊗ B and C ′ = A ′ ⊗ B ′ then CC′ = AA ′ ⊗ BB ′, (γ0)2 = σ2 3 ⊗ 12 = 12 ⊗ 12 = 14, (γi) 2 = γ2 ⊗ σ2 i = (−12) ⊗ 12 = −14 γ0γi = σ3γ ⊗ 12σi = σ1 ⊗ σi, γiγ0 = γσ3 ⊗ σi12 = (−σ1) ⊗ σi γiγj = γ2 ⊗ σiσj γjγi = γ2 ⊗ σjσi It is obvious from the second line of the above equation set that γ0γi + γiγ0 = 0; from the third line of the equation set we ﬁnd γiγj + γjγi is zero if j ̸= i because then σjσi = −σiσj. 2.2.42. The anticommutation can be demonstrated by matrix multiplication. 2.2.43. These results can be conﬁrmed by carrying out the indicated matrix op- 2.2.44. Since γ2 5 = 14, 1 4 (14 + γ5) 2 = 1 4 (14 + 2γ5 + 14) = 1 2 (14 + γ5). 2.2.47. Since ˜C = −C = C −1, and Cγ0C−1 = −γ0 = −˜γ0, Cγ2C−1 = −γ2 = −˜γ2, Cγ1C−1 = γ1 = −˜γ1, Cγ3C−1 = γ3 = −˜γ3, we have ̃CγµC−1 = ˜C −1˜γµ ˜C = C˜γµC −1 = −˜γµ. 2.2.48. (a) Written as 2 × 2 blocks, the matrices αi and the wave function Ψ are αi = ( 0 σi σi 0 ) and Ψ = ( ΨL ΨS ) . In block form, Eq. (2.73) becomes [ ( mc2 0 0 −mc2 ) + ( 0 σ1px σ1px 0 ) + ( 0 σ2py σ2py 0 ) + ( 0 σ3pz σ3pz 0 ) ] ( ΨL ΨS ) = E ( ΨL ΨS ) CHAPTER 3. EXERCISE SOLUTIONS 33 The solution is completed by moving the right-hand side of the above equation to the left, written in the form ( −E 0 0 −E ) and combining all the terms by matrix addition. 2.2.49. The requirements the gamma matrices must satisfy are Eqs. (2.74) and (2.75). Use the same process that was illustrated in the solution to Exer- cise 2.2.41, but now with γ0 = σ1 ⊗ 12. 2.2.50. In the Weyl representation, the matrices αi and the wave function Ψ, written as 2 × 2 blocks, take the forms αi = ( −σi 0 0 σi ) and ( Ψ1 Ψ2 ) . Then proceed as in the solution to Exercise 2.2.48, obtaining the matrix [( 0 mc 2 mc2 0 ) + ( −σ · p 0 0 σ · p )] ( Ψ1 Ψ2 ) = E ( Ψ1 Ψ2 ) . Here we wrote σ · p for σ1px + σ2py + σ3pz. If m is negligible, this matrix equation becomes two independent equa- tions, one for Ψ1, and one for Ψ2. In this limit, one set of solutions will be with Ψ2 = 0 and Ψ1 a solution to −σ · pΨ1 = EΨ1; a second set of solutions will have zero Ψ1 and a set of Ψ2 identical to the previously found set of Ψ1 but with values of E of the opposite sign. 2.2.51. (a) Form r ′†r ′ = (Ur)†Ur = r †U †Ur = r †r. (b) If for all r, r ′†r = r †U †Ur, then we must have U †U = 1. CHAPTER 3. EXERCISE SOLUTIONS 34 3. Vector Analysis 3.1 Review of Basic Properties (no exercises) 3.2 Vectors in 3-D Space 3.2.1. P × Q = (PxQy − PyQx)ˆx × ˆy = (PxQy − PyQx)ˆz. 3.2.2. (A × B) 2 = A 2B2 sin 2 θ = A2B2(1 − cos2 θ) = A2B2 − (A · B) 2 with θ the angle between ˆA and ˆB. 3.2.3. The vector P is at an angle θ (in the positive direction) from the x axis, while Q is at an angle −ϕ. The angle between these vectors is therefore θ + ϕ. Both vectors are of unit length. Therefore P · Q = cos(θ + ϕ) and the z component of Q × P is sin(θ + ϕ). 3.2.4. A = U × V = −3ˆy − 3ˆz, A/A = −(ˆy + ˆz)/ √2. 3.2.5. If a and b both lie in the xy-plane their cross product is in the z-direction. The same is valid for c × d ∼ ˆz. The cross product of two parallel vectors is zero. Hence (a × b) × (c × d) = 0. 3.2.6. Cross A − B − C = 0 into A to get −A × C = A × B, or C sin β = B sin γ, etc. 3.2.7. B = ˆx + 2ˆy + 4ˆz. 3.2.8. (a) A · B × C = 0, A is the plane of B and C. The parallelpiped has zero height above the BC plane and therefore zero volume. (b) A × (B × C) = −ˆx + ˆy + 2ˆz. 3.2.9. Applying the BAC-CAB rule we obtain [a · cb − a · bc] + [b · ac − b · ca] + [c · ba − c · ab] = 0. 3.2.10. (a) ˆr · Ar = A · ˆr. (b) ˆr · At = −ˆr · [ˆr × (ˆr × A)] = 0. 3.2.11. The scalar triple product A · B × C is the volume spanned by the vectors. 3.2.12. A · B × C = −120, A × (B × C) = −60ˆx − 40ˆy + 50ˆz, C × (A × B) = 24ˆx + 88ˆy − 62ˆz, B × (C × A) = 36ˆx − 48ˆy + 12ˆz. 3.2.13. (A × B) · (C × D) = [(A × B) × C] · D = [(A · C)B − (B · C)A] · D = (A · C)(B · D) − (A · D)(B · C). CHAPTER 3. EXERCISE SOLUTIONS 35 3.2.14. Using the BAC-CAB rule with A × B as the ﬁrst vector we obtain (A × B) × (C × D) = (A × B) · DC − (A × B) · CD. 3.2.15. The answer is given in the text. 3.3 Coordinate Transformations 3.3.1. The trigonometric identities follow from the rotation matrix identity  cos(ϕ1 + ϕ2) sin(ϕ1 + ϕ2) − sin(ϕ1 + ϕ2) cos(ϕ1 + ϕ2)  =  cos ϕ2 sin ϕ2 − sin ϕ2 cos ϕ2   cos ϕ1 sin ϕ1 − sin ϕ1 cos ϕ1  =  cos ϕ1 cos ϕ2 − sin ϕ1 sin ϕ2 sin ϕ1 cos ϕ2 + cos ϕ1 sin ϕ2 − cos ϕ1 sin ϕ2 − sin ϕ1 cos ϕ2 − sin ϕ1 sin ϕ2 + cos ϕ1 cos ϕ2  . 3.3.2. Align the reﬂecting surfaces with the xy, xz, and yz planes. If an incoming ray strikes the xy plane, the z component of its direction of propagation is reversed. A strike on the xz plane reverses its y component, and a strike on the yz plane reverses its x component. These properties apply for an arbitrary direction of incidence, and together the reverse the propagation direction to the opposite of its incidence orientation. 3.3.3. Because S is orthogonal, its transpose is also its inverse. Therefore (x′)T = (Sx) T = x T S T = x T S −1. Then (x′) T y′ = x T S −1Sy = x T y. 3.3.4. (a) det(S) = 1 (b) a′ = Sa =  0.80 0.60 0.00 −0.48 0.64 0.60 0.36 −0.48 0.80   1  =  0.80 0.12 1.16 , CHAPTER 3. EXERCISE SOLUTIONS 36 b ′ = Sb =  0.80 0.60 0.00 −0.48 0.64 0.60 0.36 −0.48 0.80   0 −1  =  1.20 0.68 −1.76 , a · b = ( 1 0 1 )  0 −1  = −1, a′ · b ′ = ( 0.80 0.12 1.16 )  1.20 0.68 −1.76  = −1. 3.3.5. (a) det(S) = −1 a ′ = Sa =  0.60 0.00 0.80 −0.64 −0.60 0.48 −0.48 −0.80 0.36   1  =  1.40 −0.16 −0.12  , b ′ = Sb =  0.60 0.00 0.80 −0.64 −0.60 0.48 −0.48 −0.80 0.36   0 −1  =  −0.80 −1.68 1.24  , c′ = Sc =  0.60 0.00 0.80 −0.64 −0.60 0.48 −0.48 −0.80 0.36   2  =  3.60 −0.44 0.92  . (b) a × b =  −2  , a′ × b ′ =  −0.40 −1.64 −2.48 . Compare with S(a × b) =  0.60 0.00 0.80 −0.64 −0.60 0.48 −0.48 −0.80 0.36   −2  =  0.40 1.64 2.48  . (c) (a × b) · c = 3, (a′ × b′) · c′ = −3. (d) a × (b × c) =  2 11 −2  , a′ × (b′ × c′) =  −0.40 −8.84 7.12  . Compare with S(a × (b × c)) =  0.60 0.00 0.80 −0.64 −0.60 0.48 −0.48 −0.80 0.36   2 11 −2  =  −0.40 −8.84 7.12  . CHAPTER 3. EXERCISE SOLUTIONS 37 (e) Note that S is an improper rotation. The fact that S(a × b) has components of opposite sign to a′×b′ shows that a×b is a pseudovector. The diﬀerence in sign between (a × b) · c and (a ′ × b′) · c′ shows that (a × b) · c is a pseudoscalar. The equality of the vectors S(a × (b × c)) and a′ × (b ′ × c′) shows that a × (b × c) is a vector. 3.4 Rotations in IR3 3.4.1. The Euler rotations deﬁned here diﬀer from those in the text in that the inclination of the polar axis (in amount β, in now about the x ′ axis rather than the x ′ axis. Therefore, to achieve the same polar orientation, we must place the x ′ axis where the x ′ axis was using the text rotation. This requires an additional ﬁrst rotation of π/2. After inclining the polar axis, the rotational position is now π/2 greater (counterclockwise) than from the text rotation, so the third Euler angle must be π/2 less than its original value. 3.4.2. (a) α = 70◦, β = 60◦, γ = −80◦. (b) The answer is in the text. 3.4.3. The angle changes lead to cos α → − cos α, sin α → − sin α; cos β → cos β, sin β → − sin β; sin γ → − sin γ, cos γ → − cos γ. From these we verify that each matrix element of Eq. (3.37) stays the same. 3.4.4. (a) Each of the three Euler rotations is an orthogonal matrix, so their matrix product must also be orthogonal. Therefore its transpose, ˜S, must equal its inverse, S −1. (b) This equation simply carries out the three Euler rotations in reverse order, each in the opposite direction. 3.4.5. (a) The projection of r on the rotation axis is not changed by the rotation; it is (r · ˆn)ˆn. The portion of r perpendicular to the rotation axis can be written r − (r · ˆn)ˆn. Upon rotation through an angle Φ, this vector perpendicular to the rotation axis will consist of a vector in its original direction (r − (r · ˆn)ˆn) cos Φ plus a vector perpendicular both to it and to ˆn given by (r − (r · ˆn)ˆn) sin Φ × ˆn; this reduces to r × ˆn sin Φ. Adding these contributions, we get the required result. (b) If ˆn = ˆez, the formula yields r ′ = x cos Φˆex+y cos Φˆey+z cos Φˆez +y sin Φˆex−x sin Φˆey+z(1−cos Φ)ˆez . Simplifying, this reduces to r ′ = (x cos Φ + y sin Φ)ˆex + (−x sin Φ + y cos Φ)ˆey + zˆez . This corresponds to the rotational transformation given in Eq. (3.35). CHAPTER 3. EXERCISE SOLUTIONS 38 (c) Expanding r ′2, recognizing that the second term of r ′ is orthogonal to the ﬁrst and third terms, r′2 = r2 cos2 Φ + (r × ˆn) · (r × ˆn) sin2 Φ + (ˆn · r) 2(1 − cos Φ)2 + 2(ˆn · r)2 cos Φ(1 − cos Φ) . Using an identity to make the simpliﬁcation (r × ˆn) · (r × ˆn) = (r · r)(ˆn · n) − (r · ˆn)2 = r2 − (r · ˆn) 2 , we get r′2 = r2 + (r · ˆn)2(− sin 2 Φ + 1 + cos2 Φ − 2 cos2 Φ) = r2 . 3.5 Diﬀerential Vector Operators 3.5.1. (a) −3(14)−5/2(ˆx + 2ˆy + 3ˆz). (b) 3/196. (c) −1/(14)1/2, −2/(14) 1/2, −3/(14) 1/2. 3.5.2. The solution is given in the text. 3.5.3. From r12 = √(x1 − x2)2 + (y1 − y2)2 + (z1 − z2)2 we obtain ∇1r12 = r1 − r2 r12 = ˆr12 by diﬀerentiating componentwise. 3.5.4. dF = F(r + dr, t + dt) − F(r,t) = F(r + dr, t + dt) − F(r,t + dt) + F(r,t + dt) − F(r,t) = (dr · ∇)F + ∂F ∂t dt. 3.5.5. ∇(uv) = v∇u + u∇v follows from the product rule of diﬀerentiation. (a) Since ∇f = ∂f ∂u ∇u + ∂f ∂v ∇v = 0, ∇u and ∇v are parallel so that (∇u) × (∇v) = 0, and vice versa. (b) If (∇u)×(∇v) = 0, the two-dimensional volume spanned by ∇u and ∇v, also given by the Jacobian J ( u, v x, y ) = ∣ ∂u ∂x ∂u ∂y ∂v ∂x ∂v ∂y ∣ , vanishes. CHAPTER 3. EXERCISE SOLUTIONS 39 3.5.6. (a) From ˙r = ωr(−ˆx sin ωt + ˆy cos ωt), we get r × ˙r = ˆzωr2(cos2 ωt + sin 2 ωt) = ˆzωr2. (b) Diﬀerentiating ˙r above we get ¨r = −ω2r(ˆx cos ωt + ˆy sin ωt) = −ω2r. 3.5.7. The time derivative commutes with the transformation because the coef- ﬁcients aij are constants. Therefore dVj/dt satisﬁes the same transforma- tion law as Vj. 3.5.8. The product rule directly implies (a) and (b). 3.5.9. The product rule of diﬀerentiation in conjunction with (a × b) · c = a · (b × c), etc. gives ∇ · (a × b) = b · (∇ × a) − a · (∇ × b). 3.5.10. If L = −ir × ∇, then the determinant form of the cross product gives Lz = −i ( x ∂ ∂y − y ∂ ∂x ) , (in units of ℏ), etc. 3.5.11. Carry out the indicated operations, remembering that derivatives operate on everything to their right in the current expression as well as on the function to which the operator is applied. Therefore, LxLy = − [ y ∂ ∂z − z ∂ ∂y ] [ z ∂ ∂x − x, ∂ ∂z ] = − [ y ∂ ∂x + yz ∂2 ∂z∂x − z2 ∂2 ∂y∂x − xy ∂2 ∂z2 + zx ∂2 ∂y∂z ] . LyLx = − [ z ∂ ∂x − x, ∂ ∂z ] [ y ∂ ∂z − z ∂ ∂y ] = − [ zy ∂2 ∂x∂z − xy ∂2 ∂z2 − z2 ∂2 ∂x∂y + xz ∂2 ∂z∂y + x ∂ ∂y ] . Combining the above, LxLy − LyLx = x ∂ ∂y − u ∂ ∂x = iLz. 3.5.12. [a · L, b · L] = aj[Lj, Lk]bk = iεjklajbkLl = i(a × b) · L. 3.5.13. The stream lines of b are solutions of the diﬀerential equation dy dx = by bx = x −y . Writing this diﬀerential equation as xdx + ydy = 0, we see that it can be integrated to yield x 2/2 + y2/2 =constant, equivalent to x 2 + y2 = C 2, CHAPTER 3. EXERCISE SOLUTIONS 40 the equation for a family of circles centered at the coordinate origin. To determine the direction of the stream lines, pick a convenient point on a circle, e.g., the point (+1, 0). Here bx = 0, by = +1, which corresponds to counterclockwise travel. 3.6 Diﬀerential Vector Operators: Further Properties 3.6.1. By deﬁnition, u × v is solenoidal if ∇ · (u × v) = 0. But we have the identity ∇ · (u × v) = v · (∇ × u) − u · (∇ × v) . If a vector w is irrotational, ∇×w = 0, so if u and v are both irrotational, the right-hand side of the above equation is zero, proving that u × v is solenoidal. 3.6.2. If ∇ × A = 0, then ∇ · (A × r) = r · ∇ × A − A · (∇ × r) = 0 − 0 = 0. 3.6.3. From v = ω × r we get ∇ · (ω × r) = −ω · (∇ × r) = 0. 3.6.4. Forming the scalar product of f with the identity ∇ × (gf ) = g∇ × f + (∇g) × f ≡ 0 we obtain the result, because the second term of the identity is perpen- dicular to f . 3.6.5. Applying the BAC-CAB rule naively we obtain (∇ · B)A − (∇ · A)B, where ∇ still acts on A and B. Thus, the product rule of diﬀerentiation generates two terms out of each which are ordered so that ∇ acts only on what comes after the operator. That is, (∇ · B)A → A(∇ · B) + (B · ∇)A, and similarly for the second term. Hence the four terms. 3.6.6. Write the x components of all the terms on the right-hand side of this equation. We get [(A × ∇) × B]x = Az ∂Bz ∂x − Ax ∂Bz ∂z − Ax ∂By ∂y + Ay ∂By ∂x , [(B × ∇) × A]x = Bz ∂Az ∂x − Bx ∂Az ∂z − Bx ∂Ay ∂y + By ∂Ay ∂x , [A(∇ · B)]x = Ax ∂Bx ∂x + Ax ∂By ∂y + Ax ∂Bz ∂z , [B(∇ · A)]x = Bx ∂Ax ∂x + Bx ∂Ay ∂y + Bx ∂Az ∂z . All terms cancel except those corresponding to the x component of the left-hand side of the equation. CHAPTER 3. EXERCISE SOLUTIONS 41 3.6.7. Apply the BAC-CAB rule to get A × (∇ × A) = 1 2 ∇(A 2) − (A · ∇)A. The factor 1/2 occurs because ∇ operates only on one A. 3.6.8. ∇(A · B × r) = ∇(r · A × B) = ˆex(A × B)x + ˆey(A × B)y + ˆez(A × B)z = A × B. 3.6.9. It suﬃces to check one Cartesian component; we take x. The x component of the left-hand side of Eq. (3.70) is ∂ ∂y (∇ × V)z − ∂ ∂z (∇ × V)y = ∂2Vy ∂y∂x − ∂2Vx ∂y2 − ∂2Vx ∂z2 + ∂2Vz ∂z∂x . The x component of the right-hand side is ∂ ∂x [ ∂Vx ∂x + ∂Vy ∂y + ∂Vz ∂z ] − [ ∂2Vx ∂x2 + ∂2Vx ∂y2 + ∂2Vx ∂z2 ] . After canceling the two right-hand-side occurrences of ∂2Vx/∂x 2 these two expressions contain identical terms. 3.6.10. ∇ × (ϕ∇ϕ) = ∇ϕ × ∇ϕ + ϕ∇ × (∇ϕ) = 0 + 0 = 0. 3.6.11. (a) If F or G contain an additive constant, it will vanish on application of any component of ∇. (b) If either vector contains a term ∇f , it will not aﬀect the curl because ∇ × (∇f ) = 0. 3.6.12. Use the identity v × (∇ × v) = ∇(v · v) − (v · ∇)v . Taking the curl and noting that the ﬁrst term on the right-hand side then vanishes, we obtain the desired relation. 3.6.13. Using Exercise 3.5.9, ∇ · (∇u × ∇v) = (∇v) · (∇ × ∇u) − (∇u) · (∇ × ∇v) = 0 − 0 = 0. 3.6.14. ∇2ϕ = ∇ · ∇ϕ = 0, and ∇ × ∇ϕ = 0. 3.6.15. From Eq. (3.70), ∇ × (∇ × A) = −∇2A if ∇ · A = 0. 3.6.16. Use the identity ∇2(f g) = f ∇ 2g + g∇ 2f + 2(∇f ) · (∇g) with f = g = Φ. Then we ﬁnd ∇2Ψ = k 2 [ 2Φ∇ 2Φ + 2(∇Φ) · (∇Φ)] , which satisﬁes the heat conduction equation because ∇ 2Φ = 0. CHAPTER 3. EXERCISE SOLUTIONS 42 3.6.17. Start by forming the matrix M · ∇. We obtain M · ∇ =  1 c ∂ ∂t −i ∂ ∂z i ∂ ∂y i ∂ ∂z 1 c ∂ ∂t −i ∂ ∂x −i ∂ ∂y i ∂ ∂x 1 c ∂ ∂t  . Apply this matrix to the vector ψ. The result (after multiplication by c) is cM · ∇ψ =  ∂Bx ∂t − ∂Ey ∂z + ∂Ez ∂y + i [ − 1 c2 ∂Ex ∂t − ∂By ∂z + ∂Bz ∂y ] ∂By ∂t − ∂Ez ∂x + ∂Ex ∂z + i [ − 1 c2 ∂Ey ∂t − ∂Bz ∂x + ∂Bx ∂z ] ∂Bz ∂t − ∂Ex ∂y + ∂Ey ∂x + i [ − 1 c2 ∂Ez ∂t − ∂Bx ∂y + ∂By ∂x ]  . Equating to zero the real and imaginary parts of all components of the above vector, we recover two Maxwell equations. 3.6.18. By direct matrix multiplication we verify this equation. 3.7 Vector Integration 3.7.1. A triangle ABC has area 1 2 |B − A| |C − A| sin θ, where θ is the angle between B−A and C−A. This area can be written |(B−A)×(C−A)|/2. Expanding, Area ABC = |A × B + B × C + C × A|/2 . Applying this formula to OAB, we get just |A × B|/2. Continuing to the other three faces, the total area is Area = |A × B| + |B × C| + |C × A| + |A × B + B × C + C × A| 2 . 3.7.2. Let us parameterize the circle C as x = cos ϕ, y = sin ϕ with the polar angle ϕ so that dx = − sin ϕ dϕ, dy = cos ϕ dϕ. Then the force can be written as F = −ˆx sin ϕ + ˆy cos ϕ. The work becomes − ∫ C xdy − ydx x2 + y2 = ∫ −π 0 (− sin 2 ϕ − cos2 ϕ) dϕ = π. Here we spend energy. If we integrate counterclockwise from ϕ = 0 to π we ﬁnd the value −π, because we are riding with the force. The work is path dependent which is consistent with the physical interpretation that CHAPTER 3. EXERCISE SOLUTIONS 43 F · dr ∼ xdy − ydx = Lz is proportional to the z-component of orbital angular momentum (involving circulation, as discussed in Section 3.5). If we integrate along the square through the points (±1, 0), (0, −1) sur- rounding the circle we ﬁnd for the clockwise lower half square path − ∫ F · dr = − ∫ −1 0 Fydy|x=1 − ∫ −1 1 Fxdx|y=−1 − ∫ 0 −1 Fydy|x=−1 = ∫ 1 0 dy 1 + y2 + ∫ 1 −1 dx x2 + (−1)2 + ∫ 0 −1 dy (−1)2 + y2 = arctan(1) + arctan(1) − arctan(−1) − arctan(−1) = 4 · π 4 = π, which is consistent with the circular path. 3.7.3. The answer depends upon the path that is chosen. A simple possibility is to move in the x direction from (1,1) to (3,1) and then in the y direction from (3,1) to (3,3). The work is the integral of F·ds. For the ﬁrst segment of the path the work is ∫ Fx dx; for the second segment it is ∫ Fy dy. These correspond to the speciﬁc integrals1 = ∫ 3 1 (x−1) dx = x 2 2 − x ∣ 3 = 2, w2 = ∫ 3 1 (3+y) dy = 3y + y2 2 ∣ 3 = 10. 3.7.4. Zero. 3.7.5. 1 3 ∫ r · dσ = x 3 ∫ dydz + y 3 ∫ dzdx + z 3 ∫ dxdy = 1 3 ∫ 1 0 dy ∫ 1 0 dz + · · · = 3 3 = 1. Here the factor x in the ﬁrst term is constant and therefore outside the integral; it is 0 for one face of the cube and unity for the opposite one. Similar remarks apply to the factors y, z in the other two terms which contribute equally. 3.8 Integral Theorems 3.8.1. For a constant vector a, its divergence is zero. Using Gauss’ theorem we have 0 = ∫ V ∇ · adτ = a · ∫ S dσ, where S is the closed surface of the ﬁnite volume V . As a ̸= 0 is arbitrary,∫ S dσ = 0 follows. CHAPTER 3. EXERCISE SOLUTIONS 44 3.8.2. From ∇ · r = 3 in Gauss’ theorem we have ∫ V ∇ · rdτ = 3 ∫ V dτ = 3V = ∫ S r · dσ, where V is the volume enclosed by the closed surface S. 3.8.3. Cover the closed surface by small (in general curved) adjacent rectanglesi whose circumference are formed by four lines Li each. Then Stokes’ theorem gives ∫ S(∇ × A) · dσ = ∑ i ∫ Si(∇ × A) · dσ = ∑ i ∫ Li A · dl = 0 because all line integrals cancel each other. 3.8.4. Apply Gauss’ theorem to ∇ · (ϕE) = ∇ϕ · E + ϕ∇ · E = −E 2 + ε −1 0 ϕρ, where ∫ S→∞ ϕE · dσ = 0. 3.8.5. First, show that Ji = ∇ · (xJ) by writing ∇ · (xJ) = x∇ · J + (∇x) · J = 0 + ˆex · J = Jx . Since J is zero on the boundary, so is xJ, so by Gauss’ theorem we have ∫ ∇ · (xJ)dτ = 0, equivalent to ∫ Jx dτ = 0. 3.8.6. By direct calculation we can ﬁnd that ∇ × t = 2ez. Then, by Stokes’ theorem, the line integral has the value 2A. 3.8.7. (a) As r × dr/2 is the area of the inﬁnitesimal triangle, ∮ r × dr is twice the area of the loop. (b) From dr = (−ˆxa sin θ + ˆyb cos θ)dθ and ˆx × ˆy = ˆz we obtain r × dr = ˆzab(cos2 θ + sin 2 θ) and ∮ r × dr = ˆzab ∫ 2π 0 dθ = ˆz2abπ. 3.8.8. We evaluate the surface integral with P = r. Note that dσ = ˆez dA, and that, evaluating components, dσ × ∇ = [−ˆex ∂ ∂y + ˆey ∂ ∂x ] . Then form (dσ × ∇) × r. The x and y components of this expression vanish; the z component is ( − ∂ ∂y ) y − ( ∂ ∂x ) x = −2 . The surface integral then has the value −2A, where A is the area of the loop. Note that the alternate form of Stokes’ theorem equates this surface integral to − ∮ r × dr. CHAPTER 3. EXERCISE SOLUTIONS 45 3.8.9. This follows from integration by parts shifting ∇ from v to u. The inte- grated term cancels for a closed loop. 3.8.10. Use the identity of Exercise 3.8.9, i.e. ∮ ∇(uv)·dλ = 0, and apply Stokes’ theorem to 2 ∫ S u∇v · dσ = ∫ (u∇v − v∇u) · dλ = ∫ S ∇ × (u∇v − v∇u) · dσ = 2 ∫ S(∇u × ∇v) · dσ. 3.8.11. Starting with Gauss’ theorem written as ∮ ∂V B · dσ = ∫ V ∇ · B dτ, substitute B = a × P, where a is a constant vector and P is arbitrary. The left-hand integrand then becomes (a × P) · dσ = (P × dσ) · a. The right-hand integrand expands into P · (∇ × a) − a · (∇ × P), the ﬁrst term of which vanishes because a is a constant vector. Our Gauss’ theorem equation can then be written a · ∮ ∂V P × dσ = −a · ∫ V ∇ × P dτ . Rearranging to a · [∮ ∂V P × σ + ∫ V ∇ × P dτ ] = 0, we note that because the constant direction of a is arbitrary the quantity in square brackets must vanish; its vanishing is equivalent to the relation to be proved. 3.8.12. Start from Stokes’ theorem, ∫ S(∇ × B · dσ = ∮ ∂S B · dr and substitute B = ϕ a, where a is a constant vector and ϕ is an arbitrary scalar function. Because a is constant, the quantity ∇ × ϕ a reduces to (∇ϕ) × a, and the left-side integrand is manipulated as follows: (∇ϕ) × a · dσ = (dσ × ∇ϕ) · a. The Stokes’ theorem formula can then be written a · ∫ S dσ × ∇ϕ = a · ∮ ∂S ϕ dr. Because a is arbitrary in direction, the integrals on the two sides of this equation must be equal, proving the desired relation. CHAPTER 3. EXERCISE SOLUTIONS 46 3.8.13. Starting from Stokes’ theorem as written in the solution to Exercise 3.8.12,B = a × P. This substitution yields ∫ S(∇ × (a × P)) · dσ = ∮ ∂S(a × P) · dr Applying vector identities and remembering that a is a constant vector, the left- and right-side integrands can be manipulated so that this equation becomes − ∫ S a · ((dσ × ∇) × P) = ∮ ∂S(P × dr) · a. Bringing a outside the integrals and rearranging, we reach a · [∫ S(dσ × ∇) × P − ∮ ∂S dr × P ] = 0 . Since the direction of a is arbitrary, the quantity within the square brackets vanishes, thereby conﬁrming the desired relation. 3.9 Potential Theory 3.9.1. The solution is given in the text. 3.9.2. ϕ(r) = Q 4π ε0r , a ≤ r < ∞, ϕ(r) = Q 4π ε0a [ 3 2 − 1 2 r2 a2 ] , 0 ≤ r ≤ a. 3.9.3. The gravitational acceleration in the z-direction relative to the Earth’s surface is − GM (R + z)2 + GM R2 ∼ 2z GM R3 for 0 ≤ z ≪ R. Thus, Fz = 2z GmM R3 , and Fx = −x GmM (R + x)3 ∼ −x GmM R3 , Fy = −y GmM (R + x)3 ∼ −y GmM R3 . Integrating F = −∇V yields the potential V = GmM R3 ( z2 − 1 2 x 2 − 1 2 y2) = GmM r2 2R3 (3z2−r2) = GmM r2 R3 P2(cos θ). 3.9.4. The answer is given in the text. 3.9.5. The answer is given in the text. CHAPTER 3. EXERCISE SOLUTIONS 47 3.9.6. A = 1 2 (B × r) for constant B implies B = ∇ × A = 1 2 B∇ · r − 1 2 B · ∇r = ( 3 2 − 1 2 ) B. 3.9.7. (a) This is proved in Exercise 3.6.14. (b) 2∇ × A = ∇ × (u∇v − v∇u) = ∇u × ∇v − ∇v × ∇u = 2∇u × ∇v. 3.9.8. If A′ = A + ∇Λ, then B′ = ∇ × A′ = ∇ × A + ∇ × ∇Λ = B because ∇ × ∇Λ = 0, and ∮ A′ · dr = ∮ A · dr + ∮ ∇Λ · dr = ∮ A · dr because ∫ b a ∇Λ · dr = Λ| b = 0 for b = a in a closed loop. 3.9.9. Using Green’s theorem as suggested in the problem and the formula for the Laplacian of 1/r (where r is the distance from P), the volume integral of Green’s theorem reduces to ∫ V (−ϕ) ∇2 ( 1 r ) dτ = ∫ V (−ϕ) [−4πδ(r)] dτ = 4πϕ(P) . The surface integrals, for a sphere of radius a centered at P, are ∫ S [ 1 a ∇ϕ − ϕ ∇ ( 1 r )] dσ . Using ∇(1/r) = −ˆer/r2, the second term of the surface integral yields 4π times ⟨ϕ⟩, the average of ϕ on the sphere. The ﬁrst surface-integral term vanishes by Gauss’ theorem because ∇ · ∇ϕ vanishes everywhere within the sphere. We thus have the ﬁnal result 4πϕ0 = 4π⟨ϕ⟩. 3.9.10. Use ∇ × A = B = µH, D = εE with ∂E ∂t = 0 in ∇ × H = ∂D ∂t + J = ∇ × (∇ × A)/µ = (∇∇ · A − ∇ 2A)/µ = J so that −∇ 2A = µJ follows. 3.9.11. Start from Maxwell’s equation for ∇ × B and substitute for the ﬁelds B and E in terms of the potentials A and ϕ. The relevant equations are ∇ × B = 1 c2 ∂E ∂t + µ0J, B = ∇ × A, E = −∇ϕ − ∂A ∂t ∇ × (∇ × A) = −∇ ( 1 c2 ∂ϕ ∂t ) − 1 c2 ∂2A ∂t2 + µ0J CHAPTER 3. EXERCISE SOLUTIONS 48 Next manipulate the left-hand side using Eqs. (3.70) and (3.109): ∇ × (∇ × A) = −∇2A + ∇(∇ · A = −∇ 2A − ∇ ( 1 c2 ∂ϕ ∂t ) . Inserting this result for ∇ × (∇ × A), the terms in ∂ϕ/∂t cancel and the desired formula is obtained. 3.9.12. Evaluate the components of ∇ × A. (∇ × A)x = ∂Az ∂y − ∂Ay ∂z = ∂Az ∂y = − ∂ ∂y [∫ x x0 By(x, y0, z) dx − ∫ y y0 Bx(x, y, z) dy] = 0 + Bx(x, y, z) , (∇ × A)y = ∂Ax ∂z − ∂Az ∂x = − ∂ ∂z ∫ y y0 Bz(x, y, z) dy + ∂ ∂x [∫ x x0 By(x, y0, z) dx − ∫ y y0 Bx(x, y, z) dy] = − ∫ y y0 ∂Bz ∂z dy + By(x, y0, z) − ∫ y y0 ∂Bx ∂x dy . The evaluation of (∇ × A)y is now completed by using the fact that ∇ · B = 0, so we continue to (∇ × A)y = ∫ y y0 ∂By ∂y dy + By(x, y0, z) = By(x, y, z), (∇ × A)z = ∂Ay ∂x − ∂Ax ∂y = − ∂Ax ∂y = ∂ ∂y ∫ y y0 Bz(x, y, z) dy = Bz(x, y, z). 3.10 Curvilinear Coordinates 3.10.1. (a) In the xy-plane diﬀerent u, v values describe a family of hyperbolas in the ﬁrst and third quadrants with foci along the diagonal x = y and asymptotes given by xy = u = 0, i.e. the x- and y-axes, and orthogonal hyperbolas with foci along the x-axis with asymptotes given by v = 0, i.e. the lines x ± y. The values z =constant describe a family of planes parallel to the xy-plane. (c) For u =const. and v =const. we get from x 2 − y2 = v, xdx − ydy = 0, or dx/dy = y/x, dy/dx = x/y. Thus, on the x-axis these hyperbolas have a vertical tangent. Similarly xy = u =const. gives xdy + ydx = 0, or dy/dx = −y/x. The product of these slopes is equal to −1, which proves CHAPTER 3. EXERCISE SOLUTIONS 49 orthogonality. Alternately, from ydx + xdy = du, 2xdx + 2ydy = dv we get by squaring and adding that (x2 + y2)(dx2 + dy2) = du2 + dv2/4. Here, the mixed terms dudv, dxdy drop out, proving again orthogonality. (d) The uvz-system is left-handed. This follows from the negative Jaco- bian ∂(x, y) ∂(u, v) = − 1 x2 + y2 . To prove this, we diﬀerentiate the hyperbolas with respect to u and v giving, respectively, y ∂x ∂u + x ∂y ∂u = 1, y ∂x ∂v + x ∂y ∂v = 0, x ∂x ∂u − y ∂y ∂u = 0, x ∂x ∂v − y ∂y ∂v = 1 2 . Solving for the partials we obtain ∂x ∂u = y x2 + y2 = y x ∂y ∂u , ∂x ∂v = x 2(x2 + y2) = − x y ∂y ∂u . From these we ﬁnd the Jacobian given above. The coordinate vectors are ∂r ∂u = ( ∂x ∂u , ∂y ∂u ) = ∂x ∂u ( 1, x y ) , ∂r ∂v = ( ∂x ∂v , ∂y ∂v ) = ∂x ∂v ( 1, − y x ) . 3.10.2. These elliptical cylinder coordinates can be parameterized as x = c cosh u cos v, y = c sinh u sin v, z = z, (using c instead of a). As we shall see shortly, the parameter 2c > 0 is the distance between the foci of ellipses centered at the origin of the x, y-plane and described by diﬀerent values of u =const. Their major and minor half-axes are respectively a = c cosh u and b = c sinh u. Since b a = tanh u = √ 1 − 1 cosh2 u = √ 1 − ε2, the eccentricity ε = 1/ cosh u, and the distance between the foci 2aε = 2c, proving the statement above. As u → ∞, ε → 0 so that the ellipses become circles. As u → 0, the ellipses become more elongated until, at u = 0, they shrink to the line segment between the foci. Diﬀerent values of v =const. describe a family of hyperbolas. To show orthogonality of the ellipses and hyperbolas we square and add the coordinate diﬀerentials dx = c sinh u cos vdu − c cosh u sin vdv, dy = c cosh u sin vdu + c sinh u cos vdv, CHAPTER 3. EXERCISE SOLUTIONS 50 to obtain dx2 + dy2 = c 2(sinh 2 u cos2 v + cosh2 u sin 2 v)(du2 + dv2) = c 2(cosh2 u − cos2 v)(du2 + dv2). Since there is no cross term dudv, these coordinates are locally orthogonal. Diﬀerentiating the ellipse and hyperbola equations with respect to u and v we can determine ∂x/∂u, . . . , just as in Exercise 3.10.1, and obtain the coordinate vectors ∂r/∂u and ∂r/∂v. 3.10.3. From the component deﬁnition (projection) a = ∑ i ˆqia · ˆqi ≡ ∑ i aqi ˆqi and a similar expression for b, get a · b = ∑ ij ˆqi · ˆqja · ˆqib · ˆqj = ∑ i a · ˆqib · ˆqi = ∑ i aqibqi using orthogonality, i.e. ˆqi · ˆqj = δij. 3.10.4. (a) From Eq. (3.141) with ˆe1 = ˆq1 and (ˆe1)1 = 1, (ˆe1)2 = (ˆe1)3 = 0, we get ∇ · ˆe1 = 1 h1h2h3 ∂(h2h3) ∂q1 . (b) From Eq. (3.143) with h2V2 → 0, h3V3 → 0, we get ∇ × ˆe1 = 1 h1 [ˆe2 1 h3 ∂h1 ∂q3 − ˆe3 1 h2 ∂h1 ∂q2 ] . 3.10.5. This problem assumes that the unit vectors ˆqi are orthogonal. From dr = ∂r ∂qi dqi we see that the ∂r ∂qi are tangent vectors in the directions ˆei = ˆqi with lengths hi. This establishes the ﬁrst equation of this problem. Writing (for any i) ˆei · ˆei = 1 h2 [ ∂r ∂qi · ∂r ∂qi ] = 1 h2 [( ∂x ∂qi )2 + ( ∂y ∂qi )2 + ( ∂z ∂qi )2] = 1 , we conﬁrm the formula for hi. If we now diﬀerentiate hiˆei = ∂r/∂qi with respect to qj (with j ̸= i) and note that the result is symmetric in i and j, we get ∂(hiˆei) ∂qj = ∂2r ∂qi∂qj = ∂(hj ˆej) ∂qi . Expanding the diﬀerentiations of the left and right members of this equa- tion and equating the results, ∂hi ∂qj ˆei + hi ∂ˆei ∂qj = ∂hj ∂qi ˆej + hj ∂ˆej ∂qi . CHAPTER 3. EXERCISE SOLUTIONS 51 Since ∂ˆei/∂qj must be a vector in the ˆej direction, we are able to establish the second equation of the exercise. To prove the last relation, we diﬀerentiate ˆei · ˆei = 1 and ˆei · ˆej = 0 with respect to qi. We ﬁnd ˆei · ∂ˆei ∂qi = 0, ∂ˆei ∂qi · ˆej = −ˆei · ∂ˆej ∂qi . These equations show that ∂ˆei/∂qi has no component in the ˆei direction and that its components in the ˆej directions are −ˆei · ∂ˆej/∂qi. Using the second formula to write these derivatives in terms of the hi, we reach the ﬁnal equation of this exercise. 3.10.6. The solution is given in the text. 3.10.7. The solution is given in the text. 3.10.8. Using the formulas from Exercise 3.10.5, with hρ = hz = 1 and hϕ = ρ, nonzero terms only result if the hi being diﬀerentiated is hϕ, and then only if diﬀerentiated with respect to ρ. These conditions cause all the ﬁrst derivatives of the unit vectors to vanish except for the two cases listed in the exercise; those cases are straightforward applications of the formulas. 3.10.9. The formula given in the exercise is incorrect because it neglects the ϕ- dependence of ˆeρ. When this is properly included, instead of ∂Vρ/∂ρ we get ρ−1∂(ρVρ)/∂ρ. 3.10.10. (a) r = (x, y, z) = (x, y) + zˆz = ρ ˆρ + zˆz. (b) From Eq. (3.148) we have ∇ · r = 1 ρ ∂ρ2 ∂ρ + ∂z ∂z = 2 + 1 = 3. From Eq. (3.150) with Vρ = ρ, Vϕ = 0, Vz = z we get ∇ × r = 0. 3.10.11. (a) The points x, y, z and −x, −y, −z have the same value of ρ, values of z of opposite sign, and if x = ρ cos ϕ, y = ρ sin ϕ, then −x and −y must have a value of ϕ displaced from the original ϕ value by π. (b) A unit vector ˆez will always be in the same (the +z) direction, but the change by π in ϕ will cause the ˆeρ unit vector to change sign under inversion. The same is true of ˆeϕ. 3.10.12. The solution is given in the text. 3.10.13. The solution is given in the text. CHAPTER 3. EXERCISE SOLUTIONS 52 3.10.14. Using Vz ≡ 0 we obtain ∇ × V|ρ = 1 ρ ∂(ρVϕ(ρ, ϕ)) ∂z = 0, ∇ × V|ϕ = 1 ρ ∂(Vρ(ρ, ϕ)) ∂z = 0, ∇ × V|z = 1 ρ ( ∂(ρVϕ(ρ, ϕ)) ∂ρ − ∂Vρ(ρ, ϕ) ∂ϕ ) . 3.10.15. The solution is given in the text. 3.10.16. (a) F = ˆϕ 1 ρ . (b) ∇ × F = 0, ρ ̸= 0. (c) ∫ 2π 0 F · ˆϕρdϕ = 2π. (d) ∇ × F is not deﬁned at the origin. A cut line from the origin out to inﬁnity (in any direction) is needed to prevent one from encircling the origin. The scalar potential ψ = ϕ is not single-valued. 3.10.17. The solution is given in the text. 3.10.18. The solution is given in the text. 3.10.19. Resolving the unit vectors of spherical polar coordinates into Cartesian components was accomplished in Exercise 3.10.18 involving an orthogonal matrix. The inverse is the transpose matrix, i.e. ˆx = ˆr sin θ cos ϕ + ˆθ cos θ cos ϕ − ˆϕ sin ϕ, ˆy = ˆr sin θ sin ϕ + ˆθ cos θ sin ϕ + ˆϕ cos ϕ, ˆz = ˆr cos θ − ˆθ sin θ. 3.10.20. (a) The transformation between Cartesian and spherical polar coordinates is not represented by a constant matrix, but by a matrix whose compo- nents depend upon the value of r. A matrix equation of the indicated type has no useful meaning because the components of B depend upon both r and r ′. (b) Using the fact that both the Cartesian and spherical polar coordinate systems are orthogonal, the transformation matrix between a Cartesian- component vector A and its spherical-polar equivalent A′ must have the form A ′ = UA, with U =  ˆer · ˆex ˆer · ˆey ˆer · ˆez ˆeθ · ˆex ˆeθ · ˆey ˆeθ · ˆez ˆeϕ · ˆex ˆeϕ · ˆey ˆeϕ · ˆez  CHAPTER 3. EXERCISE SOLUTIONS 53 Using the data in Exercise 3.10.19, we have U =  sin θ cos ϕ sin θ sin ϕ cos θ cos θ cos ϕ cos θ sin ϕ − sin θ − sin ϕ cos ϕ 0  Note that both A and A′ are associated with the same point, whose angular coordinates are (θ, ϕ). To check orthogonality, transpose and check the product U T U. We ﬁnd U T U = 1. 3.10.21. One way to proceed is to ﬁrst obtain the transformation of a vector A to its representation A′′ in cylindrical coordinates. Letting V be the trans- formation matrix satisfying A′′ = VA, with V =  ˆeρ · ˆex ˆeρ · ˆey ˆeρ · ˆez ˆeϕ · ˆex ˆeϕ · ˆey ˆeϕ · ˆez ˆez · ˆex ˆez · ˆey ˆez · ˆez  Using data given in the answer to Exercise 3.10.6, V evaluates to V =  cos ϕ sin ϕ 0 − sin ϕ cos ϕ 0 0 0 1  Note that A and A′′ are associated with the same point, which has angular coordinate ϕ. We now convert from spherical polar to cylindrical coordi- nates in two steps, of which the ﬁrst is from spherical polar to Cartesian coordinates, accomplished by the transformation U T , the inverse of the transformation U of Exercise 3.10.20(b). We then apply transformation V to convert to cylindrical coordinates. The overall transformation matrixis then the matrix product VU T . Thus, W =  cos ϕ sin ϕ 0 − sin ϕ cos ϕ 0 0 0 1   sin θ cos ϕ cos θ cos ϕ − sin ϕ sin θ sin ϕ cos θ sin ϕ cos ϕ cos θ − sin θ 0  =  sin θ cos θ 0 0 0 1 cos θ − sin θ 0  The inverse of this transformation is represented by the transpose of W. CHAPTER 3. EXERCISE SOLUTIONS 54 3.10.22. (a) Diﬀerentiating ˆr 2 = 1 we get ∂r ∂r = (sin θ cos ϕ, sin θ sin ϕ, cos θ) = ˆr, ∂r ∂θ = r(cos θ cos ϕ, cos θ sin ϕ, − sin θ) = r ˆθ, ∂r ∂ϕ = r(− sin θ sin ϕ, sin θ cos ϕ, 0) = r sin θ ˆϕ. (b) With ∇ given by ˆr ∂ ∂r + ˆθ 1 r ∂ ∂θ + ˆϕ 1 r sin θ ∂ ∂ϕ , the alternate derivation of the Laplacian is given by dotting this ∇ into itself. In conjunction with the derivatives of the unit vectors above this gives ∇ · ∇ = ˆr · ∂ ∂rˆr ∂ ∂r + ˆθ · 1 r ∂ˆr ∂θ ∂ ∂r + ˆϕ · 1 r sin θ ∂ˆr ∂ϕ ∂ ∂r + ˆϕ · 1 r sin θ ∂ ˆθ ∂ϕ 1 r ∂ ∂θ + ˆϕ · 1 r sin θ ∂ ∂ϕ ( ˆϕ 1 r sin θ ∂ ∂ϕ ) = ∂2 ∂r2 + 1 r2 ∂2 ∂θ2 + 2 r ∂ ∂r + tan θ r2 ∂ ∂θ + 1 r2 sin 2 θ ∂2 ∂ϕ2 . Note that, with 1 r2 sin 2 θ ∂ ∂θ ( sin θ ∂ ∂θ ) = tan θ r2 ∂ ∂θ + 1 r2 ∂2 ∂θ2 , we get the standard result using Exercise 3.10.34 for the radial part. 3.10.23. The solution is given in the text. 3.10.24. Vθ, Vϕ ∼ 1/r. 3.10.25. (a) Since r = √x2 + y2 + z2, changes of sign in x, y, and z leave r un- changed. Since z → −z, cos θ changes sign, converting θ into π − θ. Sign changes in x and y require that both sin ϕ and cos ϕ change sign; this requires that ϕ change to ϕ ± π. (b) Since the coordinate point is after inversion on the opposite side of the polar axis, increases in r or ϕ correspond to displacements in directions opposite to their eﬀect before inversion. Both before and after inversion, an increase in θ is in a direction tangent to the same circle of radius r that CHAPTER 3. EXERCISE SOLUTIONS 55 passes through both the north and south poles of the coordinate system. The two tangent directions are parallel because they are at opposite points of the circle, and both are in the southerly tangent direction. They are therefore in the same direction. 3.10.26. (a) A · ∇r = Ax ∂r ∂x + Ay ∂r ∂y + Az ∂r ∂z = A because ∂r ∂x = ˆx, ∂r ∂y = ˆy, ∂r ∂z = ˆz. (b) Using ∂ˆr ∂θ = ˆθ, ∂ˆr ∂ϕ = sin θ ˆϕ and ∇ in polar coordinates from Exer- cise 3.10.22 we get A · ∇r = A · ˆr ∂r ∂r + A · ˆθ ∂ˆr ∂θ + A · ˆϕ sin θ ∂ˆr ∂ϕ = Arˆr + Aθ ˆθ + Aϕ ˆϕ = A. 3.10.27. The solution is given in the text. 3.10.28. The solution is given in the text. 3.10.29. From Exercise 3.10.32 and using the Cartesian decomposition in Exerciseˆθz = − sin θ we get Lz = −i sin θ sin θ ∂ ∂ϕ . 3.10.30. Use Exercise 3.10.32 to get this result. 3.10.31. Solving this problem directly in spherical coordinates is somewhat chal- lenging. From the deﬁnitions of the unit vectors, one can establish ∂ˆeθ ∂ϕ = cos θˆeϕ , ∂ˆeϕ ∂ϕ = − sin θ ˆer − cos θˆeθ , ∂ˆeθ ∂θ = −ˆer, ∂ˆeϕ ∂θ = 0 , ˆer × ˆeθ = ˆeϕ, ˆeθ × ˆeϕ = ˆer, ˆeϕ × ˆer = ˆeθ. We now write L × L and expand it into its four terms, which we process individually. When a unit vector is to be diﬀerentiated, the diﬀerentiation should be carried out before evaluating the cross product. This ﬁrst term only has a contribution when the second ˆeθ is diﬀerentiated: − ( ˆeθ sin θ ∂ ∂ϕ ) ( ˆeθ sin θ ∂ ∂ϕ ) = − ( ˆeθ sin θ ) × ( ∂ˆeθ ∂ϕ ) 1 sin θ ∂ ∂ϕ = −(ˆeθ × ˆeϕ) cos θ sin 2 θ ∂ ∂ϕ . CHAPTER 3. EXERCISE SOLUTIONS 56 Next we process − (ˆeϕ ∂ ∂θ ) (ˆeϕ ∂ ∂θ ) = −ˆeϕ × ( ∂ˆeϕ ∂θ ) ∂ ∂θ − (ˆeϕ × ˆeϕ) ∂2 ∂θ2 = 0 . Then ( ˆeθ sin θ ∂ ∂ϕ ) (ˆeϕ ∂ ∂θ ) = ˆeθ × ˆeϕ sin θ ∂2 ∂ϕ∂θ ˆeθ sin θ × (−ˆer sin θ − ˆeθ cos θ) ∂ ∂θ = ˆer sin θ ∂2 ∂ϕ∂θ + ˆeϕ ∂ ∂θ . Finally, (ˆeϕ ∂ ∂θ ) ( ˆeθ sin θ ∂ ∂ϕ ) = −ˆer sin θ ∂2 ∂θ∂ϕ − (ˆeϕ × ˆeθ) ( − cos θ sin 2 θ ) ∂ ∂ϕ + (ˆeϕ × (−ˆer) 1 sin θ ∂ ∂ϕ . Several of the terms in the above expressions cancel. The remaining terms correspond to iL. 3.10.32. (a) Using ∇ = ˆr ∂ ∂r + ˆθ 1 r ∂ ∂θ + ˆϕ 1 r sin θ ∂ ∂ϕ and r = rˆr, ˆr × ˆθ = ˆϕ, ˆr × ˆϕ = − ˆθ, we ﬁnd L = −i(r × ∇) = −i ˆϕ ∂ ∂θ − ˆθ 1 sin θ ∂ ∂ϕ . (b) Using Eq. (2.44), ˆθz = − sin θ we ﬁnd Lz = −i ∂ ∂ϕ , and from ˆθx = cos θ cos ϕ, ˆϕx = − sin ϕ we get Lx = i sin ϕ ∂ ∂θ + i cot θ cos ϕ ∂ ∂ϕ ; from ˆθy = cos θ sin ϕ, ˆϕy = cos ϕ we get Ly = −i cos ϕ ∂ ∂θ + i cot θ sin ϕ ∂ ∂ϕ . (c) Squaring and adding gives the result. CHAPTER 3. EXERCISE SOLUTIONS 57 3.10.33. (a) Using ˆr × r = 0 and ∇ = ˆr ∂ ∂r − i r × L r2 and the BAC-CAB rule we get −ir × ∇ = − 1 r2 r × (r × L) = − 1 r2 (r · Lr − r2L) = L because L · r = 0. (b) It suﬃces to verify the x-component of this equation. Substituting the formula for L, the result to be proved is ∇ × (r × ∇) = r∇2 − ∇ (1 + r · ∇) . The x-component of the left-hand side expands into [ ∇ × (r × ∇) ] x = ∂ ∂y (x ∂ ∂y − y ∂ ∂x ) − ∂ ∂z ( z ∂ ∂x − x ∂ ∂z ) = x ∂2 ∂y2 − ∂ ∂x − y ∂2 ∂y∂x − ∂ ∂x − z ∂2 ∂z∂x + x ∂2 ∂z2 . The x-component of the right-hand side is x [ ∂2 ∂x2 + ∂2 ∂y2 + ∂2 ∂z2 ] − ∂ ∂x − ∂ ∂x [x ∂ ∂x + y ∂ ∂y + z ∂ ∂z ] . The left- and right-hand sides simplify to identical expressions. 3.10.34. From (a) 1 r2 d dr r2 = d dr + 2 r we get (c), and vice versa. From the inner d dr r = r d dr + 1 in (b) we get 1 r d2 dr2 r = 1 r d dr + d2 dr2 + d dr , hence (c), and vice versa. 3.10.35. (a) ∇ × F = 0, r ≥ P/2. (b) ∮ F · dλ = 0. This suggests (but does not prove) that the force is conservative. (c) Potential = P cos θ/r2, dipole potential. 3.10.36. Solutions are given in the text. 3.10.37. E(r) = 3ˆr(p · ˆr) − p 4π ε0r3 . CHAPTER 3. EXERCISE SOLUTIONS 58 4. Tensors and Diﬀerential Forms 4.1 Tensor Analysis 4.1.1. This is a special case of Exercise 4.1.2 with B0 ij = 0. 4.1.2. If A 0 = B0 ij in one frame of reference, then deﬁne a coordinate transfor- mation from that frame to an arbitrary one: xi = xi(x 0), so that Aij = ∂xi ∂x0 ∂xj ∂x0 A0 = ∂xi ∂x0 ∂xj ∂x0 B0 αβ = Bij. 4.1.3. Make a boost in the z-direction. If Az = A ′ = A 0 = 0, then A ′0 = 0 in the boosted frame by the Lorentz transformation, etc. 4.1.4. Since T ′ 12 = ∂x′ ∂x1 ∂x ′ ∂x2 Tik = cos θ sin θ T11 + cos2 θ T12 sin 2 θ T21 − sin θ cos θ T22 we ﬁnd T ′ 12 = T12 for a rotation by π, but T12 = −T21 for a rotation by π/2. Isotropy demands T21 = 0 = T12. Similarly all other oﬀ-diagonal components must vanish, and the diagonal ones are equal. 4.1.5. The four-dimensional fourth-rank Riemann–Christoﬀel curvature tensor of general relativity, Riklm has 44 = 256 components. The antisymmetry of the ﬁrst and second pair of indices, Riklm = −Rikml = −Rkilm, reduces these pairs to 6 values each, i.e. 62 = 36 components. They can be thought of as a 6 × 6 matrix. The symmetry under exchange of pair indices, Riklm = Rlmik, reduces this matrix to 6 · 7/2 = 21 components. The Bianchi identity, Riklm + Rilmk + Rimkl = 0, reduces the independent components to 20 because it represents one constraint. Note that, upon using the permutation symmetries one can always make the ﬁrst index equal to zero followed by the other indices which are all diﬀerent from each other. 4.1.6. Each component has at least one repeated index and is therefore zero. 4.1.7. As the gradient transforms like a vector, it is clear that the gradient of a tensor ﬁeld of rank n is a tensor of rank n + 1. 4.1.8. The contraction of two indices removes two indices, while the derivative adds one, so (n + 1) − 2 = n − 1. 4.1.9. The scalar product of the four-vectors ∂µ = ( 1 c ∂ ∂t , −∇ ) and ∂µ = ( 1 c ∂ ∂t , ∇ ) is the scalar ∂2 = 1 c2 ∂2 ∂t2 − ∇ 2. CHAPTER 3. EXERCISE SOLUTIONS 59 4.1.10. The double summation KijAiBj is a scalar. That Kij is a second-rank tensor follows from the quotient theorem. 4.1.11. Since KijAjk = Bik is a second-rank tensor the quotient theorem tells us that Kij is a second-rank tensor. 4.2 Pseudotensors, Dual Tensors 4.2.1. The direct product εijkClm is a tensor of rank 5. Contracting 4 indices leaves a tensor of rank 1, a vector. Inverting gives Cjk = εjkiCi, a tensor of rank 2. 4.2.2. The generalization of the totally antisymmetric εijk from three to n di- mensions has n indices. Hence the generalized cross product εijk...AiBj is an antisymmetric tensor of rank n − 2 ̸= 1 for n ̸= 3. 4.2.3. The solution is given in the text. 4.2.4. (a) As each δij is isotropic, their direct product must be isotropic as well. This is valid for any order of the indices. The last statement implies (b) and (c). 4.2.5. The argument relating to Eq. (4.29) holds in two dimensions, too, with ′ ij = det(a)aipajqδpq. No contradiction arises because εij is antisymmetric while δij is symmetric. 4.2.6. ǫij = ( 0 1 −1 0 ) . If R = ( cos ϕ sin ϕ − sin ϕ cos ϕ ) is a rotation, then ( cos ϕ sin ϕ − sin ϕ cos ϕ ) ( 0 1 −1 0 ) ( cos ϕ − sin ϕ sin ϕ cos ϕ ) = ( 0 1 −1 0 ) . 4.2.7. If Ak = 1 2 εijkBij with Bij = −Bji, then 2εmnkAk = εmnkεijk = (δmiδnj − δmjδni)Bij = Bmn − Bnm = 2Bmn. 4.3 Tensors in General Coordinates 4.3.1. The vector εi is completely speciﬁed by its projections onto the three linearly independent εk, i.e., by the requirements that εi · εj = δi j. Taking the form given in the exercise, we form ε i · εi = (εj × εk) · εi (εj × εk) · εi = 1 , εi · εj = (εj × εk) · εj (εj × εk) · εi = 0 , the zero occurring because the three vectors in the scalar triple product are not linearly independent. The above equations conﬁrm that εi is the contravariant version of εi. CHAPTER 3. EXERCISE SOLUTIONS 60 4.3.2. (a) From the deﬁning formula, Eq. (4.40), the orthogonality of the εi im- plies that gij = 0 when i ̸= j. (b) See the answer to part (c). (c) From Eq. (4.46) with the εi orthogonal, the ε i must also be orthog- onal and have magnitudes that are the reciprocals of the εi. Then, from Eq. (4.47), the gii must be the reciprocals of the gii. 4.3.3. This exercise assumes use of the Einstein summation convention. Inserting the deﬁnitions of the εi and ε i and evaluating the scalar products, we reach (εi · εj)(εj · εk) = ( ∂qi ∂x ∂qj ∂x + ∂qi ∂y ∂qj ∂y + ∂qi ∂z ∂qj ∂z ) ( ∂x ∂qj ∂x ∂qk ∂qi ∂x ∂qj ∂x + ∂y ∂qj ∂y ∂qk + ∂z ∂qj ∂z ∂qk ) The term of the product arising from the ﬁrst term of each factor has the ∂qi ∂x ∂qj ∂x ∂x ∂qj ∂x ∂qk = ∂qi ∂x ∂x ∂qk ∑ j ∂x ∂qj ∂qj ∂x = ∂qi ∂x ∂x ∂qk , where we have noted that the j summation is the chain-rule expansion for ∂x/∂x, which is unity. The products arising from the second terms and third terms of both factors have analogous forms, and the sum of these “diagonal” terms is also a chain-rule expansion: ∂qi ∂x ∂x ∂qk + ∂qi ∂y ∂y ∂qk + ∂qi ∂z ∂z ∂qk = ∂qi ∂qk = δi k . The remaining terms of the original product expression all reduce to zero; we illustrate with ∂qi ∂x ∂qj ∂x ∂y ∂qj ∂y ∂qk = ∂qi ∂x ∂y ∂qk ∑ j ∂y ∂qj ∂qj ∂x . Here the j summation is the chain-rule expansion of ∂y/∂x and therefore vanishes. 4.3.4. Starting from Eq. (4.54), Γ m jk = εm · (∂εk/∂qj), we see that a proof that ∂εk/∂qj = ∂εj/∂qk would also demonstrate that Γ m jk = Γm kj. From the deﬁnition of εk, we diﬀerentiate with respect to qj, reaching ∂εk ∂qj = ∂2x ∂qj∂qk ˆex + ∂2y ∂qj∂qk ˆey + ∂2z ∂qj∂qk ˆez . Because the coordinates are diﬀerentiable functions the right-hand side of this equation is symmetric in j and k, indicating that j and k can be interchanged without changing the value of the left-hand side of the CHAPTER 3. EXERCISE SOLUTIONS 61 4.3.5. The covariant metric tensor is diagonal, with nonzero elements gii = h2, so gρρ = gzz = 1 and gϕϕ = ρ2. The contravariant metric tensor is also diagonal, with nonzero elements that are the reciprocals of the gii. Thus, gρρ = gzz = 1 and gϕϕ = 1/ρ2. 4.3.6. Let s be the proper time on a geodesic and uµ(s) the velocity of a mass in free fall. Then the scalar d ds (V · u) = dV ds · u + Vβ d2x β ds2 = ( ∂µVα dxµ ds ) uα − VβΓ β uαuµ = uµuα ( ∂µVα − Γ β Vβ) involves the covariant derivative which is a four-vector by the quotient theorem. Note that the use of the geodesic equation for d2x β/ds 2 is the key here. 4.3.7. For this exercise we need the identity ∂gik ∂qj = εi · ∂εk ∂qj + εk · ∂εi ∂qj , which can be proved by writing gik = εi · εk and diﬀerentiating. We now write ∂Vi ∂qj = ∂(gikV k) ∂qj = gik ∂V k ∂qj + V k ∂gik ∂qj = gik ∂V k ∂qj + V kεi · ∂εk ∂qj + V kεk · ∂εi ∂qj = gik ∂V k ∂qj + V kgilεl · ∂εk ∂qj + Vkεk · ∂εi ∂qj = gik ∂V k ∂qj + gilV kΓl kj + VkΓk . In the above we have used the metric tensor to raise or lower indices and the relation AkBk = AkBk, and have identiﬁed Christoﬀel symbols using the deﬁnition in Eq. (4.54). The last line of the above series of equations can be rearranged to the form constituting a solution to the exercise. 4.3.8. Γ1 = −ρ, Γ 2 = 1/ρ. 4.3.9. All but three of the covariant derivative components of a contravariant vector V are of the form V i ;j = ∂V i ∂qj . CHAPTER 3. EXERCISE SOLUTIONS 62 The remaining three components are V ϕ ;ϕ = ∂V ϕ ∂ϕ + V ρ ρ , V ϕ ;ρ = ∂V ϕ ∂ρ + V ϕ ρ , V ρ ;ϕ = ∂V ρ ∂ϕ − ρV ϕ. 4.3.10. gij;k = ∂kgij − Γ α gαj − Γα jkgiα = ∂kgij − 1 2 gjαgαβ (∂igβk + ∂kgβi − ∂βgik) − 1 2 giαgαβ (∂jgβk + ∂kgβj − ∂βgjk) = ∂kgij − 1 2 (∂igjk + ∂kgji − ∂jgik) − 1 2 (∂jgik + ∂kgij − ∂igjk) ≡ 0. In order to ﬁnd gij ;k = 0 take the covariant derivative of the identity gimgmj = δj i . This gives 0 = gim;kgmj + gimgmj ;k = gimgmj ;k . Multiply- ing this by gni and using gnigim = δn m gives gnj ;k = 0. 4.3.11. To start, note that the contravariant V k are, in the notation of Eq. (3.157), Vr, Vθ/r, Vϕ/r sin θ and that [det)g)] 1/2 = r2 sin θ. Then the tensor deriva- tive formula, Eq. (4.69), evaluates straightforwardly to Eq. (3.157). 4.3.12. ∂µΦ;ν = ∂ν∂µΦ − Γα ∂αΦ ≡ ∂νΦ;µ = ∂µ∂νΦ − Γα νµ∂αΦ. 4.4 Jacobians 4.4.1. ∇(uv) = v∇u + u∇v follows from the product rule of diﬀerentiation. (a) Since ∇f = ∂f ∂u ∇u + ∂f ∂v ∇v = 0, ∇u and ∇v are parallel, so that (∇u) × (∇v) = 0. (b) If (∇u)×(∇v) = 0, the two-dimensional volume spanned by ∇u and ∇v, also given by the Jacobian ∂(u, v) ∂(x, y) = ∣ ∂u ∂x ∂u ∂y ∂v ∂x ∂v ∂y ∣ , vanishes. 4.4.3. (a) The direct computation of ∂(x, y)/∂(u, v) requires derivatives of x and y with respect to u and v. To get these derivatives, it is convenient to get explicit formulas for x and y in terms of u and v: these formulas are CHAPTER 3. EXERCISE SOLUTIONS 63 x = uv/(v + 1), y = u/(v + 1). Now, J = ∂(x, y) ∂(u, v) = ∣ ∂x ∂u ∂x ∂v ∂y ∂u ∂y ∂v ∣ = ∣ v v + 1 u (v + 1)2 1 v + 1 −u (v + 1)2 ∣ = − uv (v + 1)3 − u (v + 1)3 = − u (v + 1)2 . (b) Here we ﬁrst need J −1, computed as follows: J −1 = ∂(u, v) ∂(x, y) = ∣ ∂u ∂x ∂u ∂y ∂v ∂x ∂v ∂y ∣ = ∣ 1 1 y − x y2 ∣ = − x y2 − 1 y = − x + y y2 . Taking the reciprocal to obtain J, and rewriting in terms of u and v (the form usually needed if J is to be inserted into an integral over u and v), we get J = − y2 x + y = − ( u v + 1 )2 ( 1 u ) = − u (v + 1)2 , in agreement with the answer to part (a). 4.5 Diﬀerential Forms 4.5.1. The results for ∗1 and ∗(dt ∧ dx1 ∧ dx2 ∧ dx3) were explicitly discussed in Example 4.5.2, as was the value of ∗dx1. The results for ∗dxi (i ̸= 1) correspond in sign, since the ordering dxi, dt, dxj, dxk with i, j, k cyclic has the same parity as dx1, dt, dx2, dx3. For ∗dt, dt followed by the other diﬀerentials produces a standard ordering, and dt (the only diﬀerential in the expression being starred) has the metric tensor element gtt = +1. This conﬁrms the value given for ∗dt. Example 4.5.2 derived a value for ∗(dt ∧ dx1). Corresponding results for ∗(dt ∧ dxi) hold because the cyclic ordering of dxi, dxj, dxk causes the permutation to standard order to be the same for all i. To verify that ∗(dxj∧dxk) = dt∧dxi, note that the ordering dxj, dxk, dt, dxi is an even permutation of the standard order, and that both gjj and gkk are −1, together producing no sign change. Turning now to ∗(dx1 ∧ dx2 ∧ dx3), we note that dx1, dx2, dx3, dt is an odd permutation of the standard order, but the quantity being starred is associated with three negative diagonal metric tensor elements. The result therefore has positive sign, as shown in Eq. (4.82). The ﬁnal case to be considered is ∗(dt∧dxi∧dxj). Note that dt, dxi, dxj, dxk is an even permutation of the standard order, and that dt, dxi, dxj con- tribute two minus signs from metric tensor elements. The overall sign is therefore plus, as shown in Eq. (4.82). CHAPTER 3. EXERCISE SOLUTIONS 64 4.5.2. Since the force ﬁeld is constant, the work associated with motion in thedirection will have the form ax dx, where ax is a constant. Similar statements apply to motion in y and z. Thus, the work w is described by the 1-form w + a 3 dx + b 2 dy + c dz . 4.6 Diﬀerentiating Forms 4.6.1. (a) dω1 = dx ∧ dy + dy ∧ dx = 0. (b) dω2 = dx ∧ dy − dy ∧ dx = 2 dx ∧ dy. (c) d(dx ∧ dy) = d(dx) ∧ dy − dx ∧ d(dy) = 0. 4.6.2. dω3 = y dx ∧ dz + xdy ∧ dz + z dx ∧ dy + xdz ∧ dy − z dy ∧ dx − zdy ∧ dx = 2y dx ∧ dz + 2z dx ∧ dy. d(dω3) = 2 dy ∧ dx ∧ dz + 2 dz ∧ dx ∧ dy = 0. 4.6.3. (a) (xdy − ydx) ∧ (xy dz + xz dy − yz dx) = x 2y dy ∧ dz − xy2 dx ∧ dz + x 2z dy ∧ dy − xyz dx ∧ dy − xyz dy ∧ dx + y2z dx ∧ dx = x2y dy ∧ dz − xy2 dx ∧ dz. Apply d: d(x 2y dy ∧ dz) − d(xy2 dx ∧ dz) = 2xy dx ∧ dy ∧ dz + x 2 dy ∧ dy ∧ dz − y2 dx ∧ dx ∧ dz − 2xy dy ∧ dx ∧ dz = 4xy dx ∧ dy ∧ dz. (b) dω2 ∧ ω3 − ω2 ∧ dω3 = 2 dx ∧ dy ∧ (xy dz + xz dy − yz dx) − (x dy − y dx) ∧ (2y dx ∧ dz + 2z dx ∧ dy) = 2xy dx ∧ dy ∧ dz − 2xy dy ∧ dx ∧ dz = 4xy dx ∧ dy ∧ dz. 4.7 Integrating Forms 4.7.1. Let dx = a1du + a2dv + a3dw, dy = b1du + b2dv + b3dw, and dz = c1du + c2dv + c3dw. Then, dx∧dy∧dz = (a1du+a2dv+a3dw)∧(b1du+b2dv+b3dw)∧(c1du+c2dv+c3dw). Expanding the right-hand side, discarding terms with duplicate diﬀer- entials, and arranging the wedge products to standard order with the necessary sign assignments, we reach∧dy∧dz = (a1b2c3−a1b3c2−a2b1c3+a2b3c1+a3b1c2−a3b2c1)du∧dv∧dw . CHAPTER 3. EXERCISE SOLUTIONS 65 We recognize the coeﬃcient of du ∧ dv ∧ dw as the determinant J = ∣ a1 a2 a3 b1 b2 b3 c1 c2 c3 ∣ . To complete the idenﬁcation of J as a Jacobian, note that a1 = ∂x/∂u, a2 = ∂x/∂v, and so on, and therefore J = ∂(x, y, z)/∂(u, v, w). 4.7.2. See Example 4.6.2. 4.7.3. ydx + xdy: Closed; exact because it is d(xy). ydx + xdy x2 + y2 : Not closed because ∂A ∂y = ∂ ∂y y x2 + y2 = x 2 − y2 (x2 + y2)2 , ∂B ∂x = ∂ ∂x x x2 + y2 = y2 − x 2 (x2 + y2)2 . [ln(xy) + 1]dx + x y dy: Closed because ∂A/∂y = 1/y = ∂B/∂x. It is exact, being d(x ln xy). −ydx + xdy x2 + y2 : Noting that this is similar to a previous diﬀerential form of this exercise except for the sign of the dx term, we see that this form is closed. It is exact, being d tan(y/x). f (z)dz = f (x + iy)(dx + idy): ∂A/∂y = ∂B/∂x = if ′(z). It is closed; also exact because A and B can be obtained as derivatives of the indeﬁnite integral ∫ f (z) dz. CHAPTER 3. EXERCISE SOLUTIONS 66 5. Vector Spaces 5.1 Vectors in Function Spaces 5.1.1. Using orthogonality the ⟨φn|f ⟩ = an = ∫ b a w(x)f (x)φn(x)dx are derived from f and therefore unique. 5.1.2. If f (x) = ∑ i ciφi(x) = ∑ j c ′ φj, then ∑ i (ci − c ′ )φi = 0. Let ck − c ′ ̸= 0 be the ﬁrst non-zero term. Then φk = − 1 ck − c′ ∑ i>k(ci − c ′ )φi would say that φk is not linearly independent of the φi, i > k, which is a contradiction. 5.1.3. For f (x) = n−1∑ i=0 cix i we have bj = ∫ 1 0 x jf (x)dx = ∑ i ci ∫ 1 0 x i+jdx = n−1∑ i=0 ci i + j + 1 = Ajici. This results also from minimizing the mean square error ∫ 1 0 [ f (x) − n−1∑ i=0 cix i]2 dx upon varying the ci. 5.1.4. From 0 = ∂ ∂cl ∫ b a [F (x) − m∑ n=0 cnφn(x)] 2w(x)dx = 2 ∫ b a [ F (x) − m∑ n=0 cnφn(x) ] φnw(x) dx we obtain cn = ∫ b a F (x)φn(x)w(x)dx. CHAPTER 3. EXERCISE SOLUTIONS 67 5.1.5. (a) and (b) ∫ π −π f (x) 2dx = ( h 2 )2 2π ∞∑ m,n=0 1 (2m + 1)(2n + 1) × ∫ π −π sin(2m + 1)x sin(2n + 1)x dx = 4h2 π ∞∑ n=0 1 (2n + 1)2 = h2π 2 . Using ∞∑ n=0 1 (2n + 1)2 = 3 4 ζ(2), we reach ζ(2) = π2 6 . 5.1.6. |⟨f |g⟩| 2 = ⟨f 2⟩⟨g2⟩ − 1 2 ∫ b a ∫ b a |f (x)g(y) − f (y)g(x)| 2dxdy implies |⟨f |g⟩| 2 ≤ ⟨f 2⟩⟨g2⟩ because the double integral is nonnegative. 5.1.7. The ϕj are assumed to be orthonormal. Expanding I, we have I = ⟨f |f ⟩ − ∑ i a ∗⟨ϕi|f ⟩ − ∑ i ai⟨f |ϕi⟩ + ∑ ij a∗aj⟨ϕi|ϕj⟩ ≥ 0 . Using the relation ai = ⟨ϕi|f ⟩ and the orthonormality condition ⟨ϕi|ϕj⟩ = δij, I = ⟨f |f ⟩ − ∑ i a ∗ai − ∑ i aia∗ + ∑ i a ∗ai = ⟨f |f ⟩ − ∑ i |ai| 2 ≥ 0 . 5.1.8. The expansion we need is sin πx = ∑ i ⟨ϕi| sin πx⟩ ⟨ϕi|ϕi⟩ ϕi(x) . The necessary integrals are ⟨ϕ0|ϕ0⟩ = ∫ 1 0 dx = 1, ⟨ϕ1|ϕ1⟩ = ∫ 1 0 (2x − 1) 2 dx = 1 3 , ⟨ϕ2|ϕ2⟩ = ∫ 1 0 (6x 2 − 6x + 1)2 dx = 1 5 , ⟨ϕ3|ϕ3⟩ = 1 7 ⟨ϕ0|f ⟩ = ∫ 1 0 sin πx dx = 2 π , ⟨ϕ1|f ⟩ = ∫ 1 0 (2x − 1) sin πx dx = 0, ⟨ϕ2|f ⟩ = 2 π − 24 π3 , ⟨ϕ3|f ⟩ = 0 CHAPTER 3. EXERCISE SOLUTIONS 68 0.2 0.4 0.6 0.8 1 0.5 1 x Figure 5.1.8. Red line is approximation through ϕ3, black line is exact. sin πx = 2/π 1 ϕ0+ 2/π − 24/π3 1/5 ϕ2+· · · = 0.6366−0.6871(6x 2−6x+1)+· · · . This series converges fairly rapidly. See Fig. 5.1.8. 5.1.9. e −x = a0L0(x) + a1L1(x) + a2L2(x) + a3L3(x) + · · · , ai = ∫ ∞ 0 Li(x)e −2x dx . By integration we ﬁnd a0 = 1/2, a1 = 1/4, a2 = 1/8, a3 = 1/16. Thus, e −x = 1 2 (1) + 1 4 (1 − x) + 1 8 2 − 4x + x 2 2 + 1 16 6 − 18x + 9x2 − x 3 6 + · · · . This expansion when terminated after L3 fails badly beyond about x = 3. See Fig. 5.1.9. 5.1.10. The forms ∑ i |ϕi⟩⟨ϕi| and ∑ j |χj⟩⟨χj| are resolutions of the identity. Therefore |f ⟩ = ∑ ij |χj⟩⟨χj|ϕi⟩⟨ϕi|f ⟩ . The coeﬃcients of f in the ϕ basis are ai = ⟨ϕi|f ⟩, so the above equation is equivalent to f = ∑ j bjχj, with bj = ∑ i ⟨χj|ϕi⟩ai . 5.1.11. We assume the unit vectors are orthogonal. Then, ∑ j |ˆej⟩⟨ˆej|a⟩ = ∑ j (ˆej · a) ˆej . This expression is a component decomposition of a. CHAPTER 3. EXERCISE SOLUTIONS 69 0.2 0.4 0.6 0.8 1 2 4 6 x Figure 5.1.9. Red line is approximation through L3, black line is exact. 5.1.12. The scalar product ⟨a|a⟩ must be positive for every nonzero vector in the space. If we write ⟨a|a⟩ in the form (a1 − a2) 2 + (k − 1)a 2, this condition will be violated for some nonzero a unless k > 1. 5.2 Gram-Schmidt Orthogonalization 5.2.1. The solution is given in the text. Note that a10 = −1/2, a20 = −1/3, a21 = −1/2, a30 = −1/4, a31 = −9/20, a32 = −1/4. 5.2.2. The solution is given in the text. Note that a10 = −1, a20 = −2, a21 = 4. 5.2.3. The solution is given in the text. Note that a10 = −2, a20 = −6, a21 = −6 √2. 5.2.4. The solution is given in the text. Note that a10 = 0, a20 = −1/2, a21 = 0. 5.2.5. Relying without comment on the integral formulas in Exercise 13.3.2, we compute ﬁrst ⟨x0|x 0⟩ = ∫ 1 −1(1 − x 2) −1/2 dx = π, ⟨x1|x 1⟩ = ⟨x 0|x 2⟩ = ∫ 1 −1 x 2(1 − x 2)−1/2 dx = π/2, ⟨x2|x 2⟩ = ∫ 1 −1 x 4(1 − x 2) −1/2 dx = 3π/8, ⟨x0|x 1⟩ = ⟨x 2|x 1⟩ = 0 . CHAPTER 3. EXERCISE SOLUTIONS 70 Note that some integrals are zero by symmetry. The polynomial T0 is of the form c0x 0, with c0 satisfying ⟨c0x 0|c0x0⟩ = |c0|2⟨x 0|x 0⟩ = π, so c0 = 1 and T0 = 1. By symmetry, the polynomial T1, which in principle is a linear combination of x0 and x 1, must actually be an odd function that depends only on x 1, so is of the form c1x. It is automatically orthogonal to T0, and c1 must satisfy ⟨c1x|c1x⟩ = |c1| 2⟨x|x⟩ = π 2 . Because ⟨x|x⟩ = π/2, we have c1 = 1 and T1 = x. The determination of T1 is a bit less trivial. T2 will be an even function of x, and will be of the general form T2 = c2 [x 2 − ⟨T0|x 2⟩ ⟨T0|T0⟩ T0 ] = c2 [ x2 − π/2 π T0 ] = c2 [ x2 − 1 2 ] . The constant c2 is now determined from the normalization condition: ⟨T2|T2⟩ = |c2| 2 〈( x 2 − 1 2 ) ∣ ( x 2 − 1 2 ) 〉 = |c2| 2 ( 3π 8 − π 2 + 1 4 π) = |c2|2 π 8 = π 2 , from which we ﬁnd c2 = 2 and T2 = 2x 2 − 1. 5.2.6. From the formula given in the Hint, we have ⟨x 0|x0⟩ = ∫ 1 −1(1 − x 2)1/2 dx = π 2 , ⟨x 0|x 2⟩ = ⟨x1|x 1⟩ = π 8 , ⟨x 2|x 2⟩ = π 16 . Taking U0 = c0x 0, we ﬁnd |c0|2⟨x 0|x 0⟩ = π/2, so c0 = 1 and U0 = 1. The Un have even/odd symmetry, so U1 = c1x, and |c1|2⟨x|x⟩ = π/2, so |c1| 2π/8 = π/2, and c1 = 2, U1 = 2x. Finally, U2 = c2 [x 2 − ⟨U0|x 2⟩ ⟨U0|U0⟩ U0 ] = c2 [x 2 − π/8 π/2 U0 ] = c2 [x 2 − 1 4 ] . CHAPTER 3. EXERCISE SOLUTIONS 71 We determine c2 from ⟨U2|U2⟩ = |c2| 2 〈( x2 − 1 4 ) ∣ ( x 2 − 1 4 ) 〉 = |c2|2π 32 = π 2 , so c2 = 4, U2 = 4x 2 − 1. 5.2.7. The solution is given in the text. Note that a10 = −1/ √π. 5.2.8. Let the orthonormalized vectors be denoted bi. First, Make b1 a nor- malized version of c1: b1 = c1/ √3 . Then obtain b2 (denoting b2 before normalization) as b2 = c2 − (b1 · c2)b1 =  1  − (4√ 3)  1/ √ 3 1/ √3 1/ √3  =  −1/3 −1/3 2/3  . Normalizing, b2 = √ 3/2 b2 . Finally, form b3 = c3 − (b1 · c3)b1 − (b2 · c3)b2 =  1  − ( √ 3)  1/ √ 3 1/ √3 1/ √3  − (√ 3/2)  −1/√ 6 −1/√6 2/√6  =  1/2 −1/2 0  . Normalizing, b3 = √ 2 b3. Collecting our answers, the orthonormal vec- tors are b1 =  1/ √ 3 1/ √3 1/ √3  , b2 =  −1/√ 6 −1/√6 2/√6  , b3 =  1/ √ 2 −1/ √2 0  . 5.3 Operators 5.3.1. For arbitrary ϕ and ψ within our Hilbert space, and an arbitrary operator A, ⟨ϕ|A ψ⟩ = ⟨A†ϕ|ψ⟩ = ⟨ψ|A †ϕ⟩ ∗ = ⟨(A†) †ψ|ϕ⟩ ∗ = ⟨ϕ|(A †) †ψ⟩. Since the ﬁrst and last expressions in this chain of equations are equal forA, ψ, and ϕ, we may conclude that (A†)† = A. 5.3.2. ⟨ψ2|V †(U †ψ1)⟩ = ∫ (V ψ2)∗(U †ψ1)d3r = ∫ (U V ψ2) ∗ψ1d3r = ⟨ψ2|(U V ) †ψ1⟩. CHAPTER 3. EXERCISE SOLUTIONS 72 5.3.3. (a) (A1)ij = ⟨xi|A1|xj⟩. A corresponding formula holds for A2. Comput- ing for each i and j, we ﬁnd A1 =  1 0 0 0 1 0 0 0 1  , A2 =  0 1 0 −1 0 0 0 0 0  . (b) ψ =  1 −2 . (c) (A1 − A2)ψ =  1 −1 0 1 1 0 0 0 1   1 −2  =  3 −1  = χ. Check: A1ψ = x1 − 2x2 + 3x3; A2ψ = −2x1 − x2; (A1 − A2)ψ = 3x1 − x2 + 3x3. 5.3.4. (a) First compute APn (Pn are the normalized polynomials). AP0 = 0, AP1 = √3/2 x = P1 AP2 = √ 5/2(3x 2) = 2P2 + √ 5 P0, AP3 = √ 7/2 ( 15 2 x 3 − 3 2 x) = 3P3 + √21 P1. Using the above and noting that our basis is the Pn, we construct A =  0 0 √ 5 0 0 1 0 √21 0 0 2 0 0 0 0 3  Note: We built the matrix of A directly from the expansions. An alternate and equally valid approach would be to identify the matrix elements as scalar products. (b) To expand x 3 we need ⟨P3|x 3⟩ = 2 √ 14/35 and ⟨P1|x 3⟩ = √6/5; the coeﬃcients of P2 and P0 vanish because x 3 is odd. From the above data, we get x 3 = (2√14/35)P3(x) + (√6/5)P1(x). Thus, the column vector representing x3 is x3 ←→  0√ 6/5 0 2 √14/35  . CHAPTER 3. EXERCISE SOLUTIONS 73 (c) Ax3 =  0 0 √ 5 0 0 1 0 √21 0 0 2 0 0 0 0 3   0√ 6/5 0 2√14/35  =  0 3√ 6/5 0 6 √14/35 . Inserting the explicit forms of P1 and P3, we ﬁnd Ax 3 = (3√ 6/5)( √ 3/2 x) + (6 √14/35)√7/2 ( 5 2 x 3 − 3 2 x) = 3x 3, in agreement with the directly computed value. 5.4 Self-Adjoint Operators 5.4.1. (a) (A + A†)† = A + A†, [i(A − A†)] † = −i(A† − A) = i(A − A †). (b) A = 1 2 (A + A†) − i 2 i(A − A†). 5.4.2. (AB) † = B†A † = BA = AB if and only if [B, A] = 0. 5.4.3. (AB − BA) † = (iC)† = B†A† − A †B† = −iC † = BA − AB = −iC. 5.4.4. If L † = L then ⟨ψ|L 2ψ⟩ = ⟨ψ|L †(Lψ)⟩ = ⟨Lψ|Lψ⟩ = ∫ b a |Lψ(x)|2dx ≥ 0. 5.4.5. (a) For the normalization of ϕ3 = Cz/r = C cos θ, we need the following integral: 〈 z r ∣ z r 〉 = ∫ 2π 0 dϕ ∫ π 0 sin θ dθ cos2 θ = 2π [ − cos3 θ 3 ]π = 4π 3 . The normalized form of ϕ3 is therefore √ 3/4π(z/r). To check orthogo- nality, we need integrals such as 〈 x r ∣ y r 〉 = ∫ 2π 0 cos ϕ sin ϕ dϕ ∫ π 0 sin 3 θ dθ . The ϕ integral vanishes; one easy way to see this is to note that cos ϕ sin ϕ = sin(2ϕ)/2; the ϕ integral is over two complete periods of this function. An appeal to symmetry conﬁrms that all the other normalization and orthg- onality integrals have similar values. (b) It is useful to note that ∂(1/r)/∂x = −x/r3; similar expressions are obtained if x is replaced by y or z. Now, Lzϕ1 = Lz ( x r ) = −i [x ∂x/r ∂y − y ∂x/r ∂x ] = i y r = iϕ2. Because Lz is antisymmetric in x and y, we also have Lzϕ2 = Lz ( y r ) = −i x r = −iϕ1 CHAPTER 3. EXERCISE SOLUTIONS 74 Finally, Lzϕ3 = Lz ( z r ) = −i [x ∂(1/r) ∂y − y ∂(1/r) ∂x ] = 0. Combining the above into a matrix representation of Lz, Lz =  0 −i 0 i 0 0 0 0 0  . Similar processes (or cyclic permutation of x, y, z) lead to the matrix representations Lx =  0 0 0 0 0 −i 0 i 0  , Ly =  0 0 i 0 0 0 −i 0 0  . (c) Form the matrix operations corresponding to LxLy − Ly − Lx:  0 0 0 0 0 −i 0 i 0   0 0 i 0 0 0 −i 0 0  −  0 0 i 0 0 0 −i 0 0   0 0 0 0 0 −i 0 i 0  . Carrying out the matrix multiplication and subtraction, the result is i times the matrix of Lz. 5.5 Unitary Operators 5.5.1. (a) (1) The column vector representing f (θ, ϕ) is c =  3 2i −1 . (2) c′ =  −1/√ 2 −i/ √2 0 0 0 1/√2 −i/ √2 0 0 0 0 0 i/√2 1/√2 0 0 0 −i √2 1/√2 0 0 0 0 0 1   3 2i −1  =  −1/ √ 2 5/ √2 −i/ √2 i/ √2 1 . (3) Check: ∑ i c ′ χ ′ = ∑ i ciχi. (b) Form U † and verify that U U† = 1:  −1/ √ 2 −i/√2 0 0 0 1/ √2 −i/√2 0 0 0 0 0 i √2 1/√2 0 0 0 −i/ √2 1/√2 0 0 0 0 0 1   −1/√ 2 1/ √2 0 0 0 i/ √2 i/ √2 0 0 0 0 0 −i/ √2 i/ √2 0 0 0 1/ √2 1/ √2 0 0 0 0 0 1  = 1. CHAPTER 3. EXERCISE SOLUTIONS 75 5.5.2. (a) The ith column of U describes ϕi in the new basis. Thus, U =  0 0 −1 0 1 0 1 0 0  . (b) The transformation is a counterclockwise rotation of the coordinate system about the y axis; this corresponds to the Euler angles α = 0, β = π/2, γ = 0. The above U is reproduced when these angles are substituted into Eq. (3.37).c =  2 −3 . U c =  0 0 −1 0 1 0 1 0 0   2 −3  =  −1 −3  . This vector corresponds to f ′ = −x − 3y + 2z, which is consistent with application of the relevant basis transformation to f . 5.5.3. Since the matrix U for the transformation of Exercise 5.5.2 is unitary, the inverse transformation has matrix U †, which is U † =  0 0 1 0 1 0 −1 0 0  . Multiplying, we ﬁnd that UU † = 1. 5.5.4. (a) Uf =  i sin θ cos θ 0 − cos θ i sin θ 0 0 0 1   3 −1 −2  =  cos θ + 3i sin θ −3 cos θ + i sin θ −2 , V(Uf ) =  1 0 0 0 cos θ i sin θ 0 cos θ −i sin θ   cos θ + 3i sin θ −3 cos θ + i sin θ −2  =  cos θ + 3i sin θ −3 cos2 θ + i sin θ(cosθ − 2) 3 cos2 θ + i sin θ(cos θ + 2)  . The above indicates that f (x) = (cos θ+3i sin θ)χ1+(−3cos 2θ+i sin θ(cos θ− 2))χ2 + (3 cos2 θ + i sin θ(cos θ + 2))χ3. (b) UV =  i sin θ cos2 θ i sin θ cos θ − cos θ i sin θ cos θ − sin 2 θ 0 cos θ −i sin θ  CHAPTER 3. EXERCISE SOLUTIONS 76 VU =  i sin θ cos θ 0 − cos2 θ i sin θ cos θ i sin θ − cos2 θ i sin θ cos θ −i sin θ . Using the above, we ﬁnd UV  3 −1 −2  =  cos2 θ + i sin θ(3 − 2 cos θ) 2 sin 2 θ − 3 cos θ + i sin θ cos θ cos θ + 2i sin θ  , VU  3 −1 −2  =  cos θ + 3i sin θ −3 cos2 θ + i sin θ(cosθ − 2) 3 cos2 θ + i sin θ(cos θ + 2)  . Only VUf gives the correct result that we found in part (a). 5.5.5. (a) The normalized versions of the Pn, denoted Pn, are Pn = √(2n + 1)/2 Pn. The normalized versions of the Fn, denoted Fn, are F0 = √ 5/2 F0, F1 = √3/2 F1, and F2 = √1/8 F2. (b) The transformation matrix U has elements uij = ⟨Fi|Pj⟩. For exam- ple, u02 = ∫ 1 −1 F0 P2 dx = √5 2 ∫ 1 −1(x 2)(1) dx = √5 3 . The complete transformation matrix is U =  √ 5/3 0 2/3 0 1 0 −2/3 0 √5/3  . (c) V has elements vij = ⟨Pi|Fj⟩. Thus, V =  √ 5/3 0 −2/3 0 1 0 2/3 0 √5/3  . (d) By matrix multiplication we can verify that UV = 1, showing that V = U −1. Since V is also U †, we can also conclude that U and V are unitary.f (x) = 8 √ 2 3 P0(x) − √6 P1(x) + 2 √10 3 P2(x) = 4√10 3 F0(x) − √6 F1(x) − 2 √2 3 F2(x). Letting c and c′ be the vectors describing the expansions of f (x) respec- tively in the Pn and the Fn bases, c =  8√ 2/3 −√6 2 √10/3  , c′ =  4 √ 10/3 − √6 −2 √2/3  , CHAPTER 3. EXERCISE SOLUTIONS 77 we check that c′ = Uc, i.e.,  4 √ 10/3 −√6 −2√2/3  =  √ 5/3 0 2/3 0 1 0 −2/3 0 √5/3   8√ 2/3 − √6 2 √10/3  . 5.6 Transformations of Operators 5.6.1. (a) The ﬁrst column of Sx shows the result of its operation on α; the second column describes Sxβ. Similar observations apply to Sy amd Sz. We get Sx = 1 2 ( 0 1 1 0 ) , Sy = 1 2 ( 0 −i i 0 ) , Sz = 1 2 ( 1 0−1 ) . (b) (1) Check that ⟨α + β|α − β⟩ = 0. Expanding, we have ⟨α|α⟩ − ⟨α|β⟩ + ⟨β|α⟩ − ⟨β|β⟩ = 1 + 0 + 0 − 1 = 0. (2) A similar expansion shows that ⟨α + β|α + β⟩ = 2, so a proper value of C is 1/ √ 2. The same result is obtained for ⟨ϕ′ |ϕ′ ⟩. (3) The matrix elements of the transformation are uij = ⟨ϕ ′ |ϕj⟩. These evaluate to U = ( 1/ √ 2 1/ √2 1/ √2 −1/ √2 ) = 1 √2 ( 1 1−1 ) . (c) In the transformed basis, the matrix of an operator S becomes S ′ = U S U −1. Noting that U −1 = U, we compute S′ = U SxU −1 = 1 4 ( 1 1−1 ) ( 0 1 1 0 ) ( 1 1−1 ) = 1 4 ( 2 0−2 ) = 1 2 ( 1 0−1 ) = Sz . Similar operations for Sy and Sz yield S ′ = U SyU −1 = 1 2 ( 0 i −i 0 ) = −Sy . S′ = U SzU −1 = 1 2 ( 0 1 1 0 ) = Sx . 5.6.2. (a) Apply Lx to the ϕi: Lxϕ1 = 0, Lxϕ2 = iϕ3, and Lxϕ3 = −iϕ2. Therefore the matrix of Lx for this basis is Lx =  0 0 0 0 0 −i 0 i 0  . CHAPTER 3. EXERCISE SOLUTIONS 78 (b) Form ULxU −1. U is unitary; this can be checked by verifying that UU † = 1. Thus, ULxU −1 =  1 0 0 0 1/√ 2 −i/ √2 0 1/√2 i/ √2   0 0 0 0 0 −i 0 i 0   1 0 0 0 1/√ 2 1/ √2 0 i/√2 −i/√2  =  0 0 0 0 1 0 0 0 −1  . (c) The new basis functions have coeﬃcients (in terms of the original basis) that are the columns of U †. Reading them out, we have ϕ′ = Cxe−r2 , ϕ′ = C √2 (y + iz)e −r2 , ϕ′ = C √2 (y − iz)e −r2. Applying Lx, Lxϕ ′ = 0 , Lxϕ ′ = Lx C √2 (y + iz)e −r2 = C √2 [iz + i(−iy)]e −r2 = C √2 (y + iz)e −r2 , Lxϕ ′ = C √2 (y − iz)e −r2 = C √2 [iz − i(−iy)]e −r2 = − C √2 (y − iz)e −r2. 5.6.3. Deﬁne D1, D2, D3 as the determinants formed from the overlap matrix elements of the ﬁrst, the ﬁrst two, and all three basis functions. Letting sij = ⟨χi|χj⟩ be the elements of this overlap matrix, D1 = S11, D2 = S11S22 − S12S21 etc. By substitution into the formulas obtained as in Section 5.2, we ﬁnd the systematic formulas for the ϕi: ϕ1 = χ1√D1 ϕ2 = χ2 − S12χ1 D1√D2/D1 , ϕ3 = χ3 − S13χ1 D1 − D1S23χ2 D2 + S12S23χ1 D2 + S21S13χ2 D2 − S12S21S13χ1 D1D2√D3/D2 . Comparing with the matrix T as deﬁned in Example 5.6.1, we see that its jth column consists of the coeﬃcients of the χi in the formula for ϕj. From the above formulas, we ﬁnd T =  T11 T12 T13 0 T22 T23 0 0 T33  , CHAPTER 3. EXERCISE SOLUTIONS 79 with T11 = 1 √D1 , T12 = − S12√D1D2 , T22 = √ D1 D2 , T13 = −D2S13 + D1S12S23 − S12S21S13 D1√D2D3 , T23 = −D1S23 + S21S13√D2D3 , T33 = √ D2 D3 . 5.7 Invariants 5.7.1. Replace x by x ′ = UxU −1 and p′ = p by UpU −1, so [x ′, p′] = x ′p′ − p ′x ′ = ( UxU −1) (UpU −1) − (UpU −1) (UxU −1) = U(xp − px)U −1 = iUU −1 = i1 . 5.7.2. We need σ′ = Uσ1U † = ( sin 2θ cos 2θ cos 2θ − sin 2θ ) , σ′ = Uσ2U † = ( 0 −i i 0 ) , σ′ = Uσ3U † = ( cos 2θ − sin 2θ − sin 2θ − cos 2θ ) . Now form σ′ σ′ = ( i cos 2θ −i sin 2θ −i sin 2θ −i cos 2θ ) = iσ′ , σ′ σ′ = ( −i cos 2θ i sin 2θ i sin 2θ i cos 2θ ) = −iσ′ . From the above, σ′ σ′ − σ′ σ′ = 2iσ′ . 5.7.3. (a) From the equations Lxϕ1 = 0, Lxϕ2 = iϕ3, Lxϕ3 = −iϕ2, we see that Lx applied to any function in the space spanned by ϕ1, ϕ2, ϕ3 a function that remains within that space. The above equations correspond to the action on the ϕ basis of the matrix Lx =  0 0 0 0 0 −i 0 i 0  . (b) Lx(ϕ1 + iϕ2) = 0 + i(iϕ3) = −ϕ3 = −ze −r2 . CHAPTER 3. EXERCISE SOLUTIONS 80 (c)  0 0 0 0 0 −i 0 i 0   1 i 0  =  0 −1  . If this equation is transformed by U, the quantities in it become L′ =  0 0 0 0 1 0 0 0 −1  ,  1 i 0  −→  1 i/ √ 2 i/ √2  ,  0 −1  −→  0 i/ √ 2 −i/ √2  , and the transformed matrix equation is  0 0 0 0 1 0 0 0 −1   1 i/√ 2 i/√2  =  0 i/ √ 2 −i/ √2  . (d) The ϕ ′ are those linear combinations of the ϕ with coeﬃcients that are complex conjugates of the corresponding row of U, and are ϕ ′ = ϕ1 = x e −r2, ϕ′ = (ϕ2 + iϕ3)/ √ 2 = (y + iz)e −r2 / √2, ϕ ′ = (ϕ2 − iϕ3)/ √ )2 = (y − iz)e −r2/√2. (e) The matrix equation is equivalent to Lx ( [x + i √2 ( y + iz √2 ) + i √2 ( y − iz √2 )] e −r2) = [ i √2 ( y + iz √2 ) − i √2 ( y − iz √2 )] e −r2 , which simpliﬁes to Lx [ (x + iy)e −r2 ] = −ze −r2 . This is a result that was proved in part (b). 5.8 Summary—Vector Space Notation (no exercises) CHAPTER 3. EXERCISE SOLUTIONS 81 6. Eigenvalue Problems 6.1 Eigenvalue Equations (no exercises) 6.2 Matrix Eigenvalue Problems The solutions to matrix eigenvalue problems consist of the eigenvalues λi, and associated with each a normalized eigenvector ri. The eigenvectors corresponding to degenerate eigenvalues are not unique. 6.2.1. λ1 = 0, r1 = (1, 0, −1)/ √2 λ2 = 1, r2 = (0, 1, 0) λ3 = 2, r3 = (1, 0, 1)/ √2. 6.2.2. λ1 = −1, r1 = (1, − √2, 0)/√3 λ2 = 0, r2 = (0, 0, 1) λ3 = 2, r3 = ( √2, 1, 0)/√3. 6.2.3. λ1 = −1, r1 = (1, −2, 1)/√6 λ2 = 1, r2 = (1, 0, −1)/ √2 λ3 = 2, r3 = (1, 1, 1)/ √3. 6.2.4. λ1 = −3, r1 = (1, − √2, 1) ∕2 λ2 = 1, r2 = (1, 0, −1) ∕√2 λ3 = 5, r3 = (1, √2, 1)∕ 2. 6.2.5. λ1 = 0, r1 = (0, 1, −1)∕√2 λ2 = 1, r2 = (1, 0, 0) λ3 = 2, r3 = (0, 1, 1) ∕√2. 6.2.6. λ1 = −1, r1 = (0, 1, −√2) ∕√3 λ2 = +1, r2 = (1, 0, 0) λ3 = 2, r3 = (0, √2, 0)∕√3. 6.2.7. λ1 = −√2, r1 = (1, −√2, 1)/2 λ2 = 0, r2 = (1, 0, −1)/ √2 λ3 = √2, r3 = (1, √2, 1)/2. 6.2.8. λ1 = 0, r1 = (0, 1, −1)/√2 λ2 = 2, r2 = (0, 1, 1)/ √2 λ3 = 2, r3 = (1, 0, 0). CHAPTER 3. EXERCISE SOLUTIONS 82 6.2.9. λ1 = 2, r1 = (1, 1, 1)/√3 λ2 = −1, r2 = (1, −1, 0)/ √2 λ3 = −1, r3 = (1, 1, −2)/ √6. 6.2.10. λ1 = −1, r1 = (1, 1, 1)/ √3 λ2 = 2, r2 = (1, −1, 0)/ √2 λ3 = 2, r3 = (1, 1, −2)/ √6. 6.2.11. λ1 = 3, r1 = (1, 1, 1)/ √3 λ2 = 0, r2 = (1, −1, 0)/ √2 λ3 = 0, r3 = (1, 1, −2)/ √6. 6.2.12. λ1 = 6, r1 = (2, 0, 1)/√5 λ2 = 1, r2 = (1, 0, −2)/ √5 λ3 = 1, r3 = (0, 1, 0). 6.2.13. λ1 = 2, r1 = (1, 1, 0)/√2 λ2 = 0, r2 = (1, −1, 0)/√2 λ3 = 0, r3 = (0, 0, 1). 6.2.14. λ1 = 2, r1 = (1, 0, −√3)/2 λ2 = 3, r2 = (0, 1, 0) λ3 = 6, r3 = ( √3, 0, 1)/2. 6.2.15. Since the quadratic form x2 + 2xy + 2y2 + 2yz + z2 = 1 deﬁning the surface is obviously positive deﬁnite upon writing it as a sum of squares,x + y) 2 + (y + z) 2 = 1, it is an ellipsoid or an ellipse. Finding the orientation in space amounts to diagonalizing the symmetric 3 × 3 matrix of coeﬃcients. The characteristic polynomial is λ(1 − λ)(λ − 3) = 0, so that the eigenvalues are λ = 0 implying an ellipse, and λ = 1, and 3. For λ = 1 an eigenvector is v1 = (1, 0, −1) giving one of its axes, for λ = 3 an eigenvector is v3 = (1, 2, 1) giving the other axis. v1 × v3 = (2, −2, 2) is normal to the plane of the ellipse. 6.3 Hermitian Eigenvalue Problems (no exercises) 6.4 Hermitian Matrix Diagonalization 6.4.1. This follows from the invariance of the characteristic polynomial under similarity transformation. CHAPTER 3. EXERCISE SOLUTIONS 83 6.4.2. The orthonormality of the eigenvectors implies that the transformationU diagonalizing our matrix H is unitary. Since the diagonal ma- trix is made up by the real eigenvectors, it is Hermitian, and so is the transformed matrix H. 6.4.3. Assume that a unitary matrix U causes the real nonsymmetric matrix A to be diagonal, i.e., that UAU T = D, a diagonal matrix. If we apply the inverse transformation to D, to recover A, we would have A = U T DU. But this form for A is symmetric: (U T DU)T = U T DU. 6.4.4. First, note that L 2 has the same eigenvectors as Lx, with eigenvalues that are the squares of the (real) Lx eigenvalues. Therefore, L 2 (and for the same reason, L 2 and L 2) have only nonnegative eigenvalues. Second, for vectors |x⟩ of unit length, the expectation value ⟨x|L 2 |x⟩ will be real and have as its smallest possible value the smallest eigenvalue of L 2 . Proof of this statement is the topic of Exercise 6.5.5. Similar statements are true for L 2 and L 2, so ⟨x|L 2 + L 2 + L 2|x⟩ must always be nonnegative. We therefore may conclude that all the eigenvalues of L 2 + L 2 + L 2 are nonnegative. 6.4.5. If A|xi⟩ = λi|xi⟩, then |xi⟩ = λiA −1|xi⟩ upon multiplying with the inverse matrix. Moving the (non-zero) eigenvalue to the left-hand side proves the 6.4.6. (a) If A is singular, its determinant is zero. If A is transformed to diagonal form, its determinant is seen to be the product of its eigenvalues, so a zero determinant indicates that at least one eigenvalue is zero. The eigenvector corresponding to a zero eigenvalue will have the property that A|v⟩ = 0. (b) If A|v⟩ = 0, then |v⟩ is an eigenvector with eigenvalue zero, the deter- minant of A will be zero, and A will be singular. 6.4.7. If U1AU † = [λ1, · · · , λn] = U2BU † with unitary matrices Ui, then A = U †U2BU †U1 = U †U2B(U †U2) †. 6.4.8. For Mx, λ1 = +1, r1 = (1, +√2, 1)/2 λ2 = 0, r2 = (1, 0, −1)/ √2 λ3 = −1, r3 = (1, −√2, 1)/2. For My, λ1 = +1, r1 = (1, +i √2, −1)/2 λ2 = 0, r2 = (1, 0, 1)/ √2 λ3 = −1, r3 = (1, −i √2, −1)/2. 6.4.9. (a) Form a ′ = ⟨ϕi cos θ − ϕj sin θ|A|ϕi sin θ + ϕj cos θ⟩. CHAPTER 3. EXERCISE SOLUTIONS 84 Using the fact that ⟨ϕµ|A|ϕν⟩ = aµν and remembering that aνµ = aµν, we expand the expression for a′ and set it equal to zero, getting (aii − ajj) sin θ cos θ + aij(cos2 θ − sin 2 θ) = 0 . Using the trigonometric double-angle formulas and rearranging, we reach tan 2θ = 2aij ajj − aii . (b) Since only the basis functions ϕi and ϕj are altered by the Jacobi transformation, all matrix elements of A not involving i and not involving j remain unchanged. (c) Proceeding as in part (a), we ﬁnd a ′ = aii cos2 θ + ajj sin 2 θ − 2aij sin θ cos θ, a ′ jj = aii sin 2 θ + ajj sin 2 θ + 2aij sin θ cos θ. Forming a ′ + a′ jj, the aij terms cancel and, using the identity sin 2 θ + cos2 θ = 1, the remaining terms are seen to add to aii + ajj, as required. (d) Form the squares of a′ and a′ : a ′ = aµi cos θ − aµj sin θ, (a ′ ) 2 = (aµi) 2 cos2 θ + (aµj)2 sin 2 θ − 2aµiaµj sin θ cos θ, a ′ = aµj cos θ + aµi sin θ, (a′ ) 2 = (aµi) 2 sin 2 θ + (aµj) 2 cos2 θ + 2aµiaµj sin θ cos θ . Thus, a 2 + a2 is not changed by the transformation, and the sum of the squares of the oﬀ-diagonal elements has been changed only by the replacement of aij and aji by zero, a net decrease of 2(aij) 2. 6.5 Normal Matrices 6.5.1. The solution is given in the text. 6.5.2. The characteristic polynomial isλ − λ1)(λ − λ2) = λ2 − (λ1 + λ2)λ + λ1λ2 = λ2 − trace(A)λ + det(A) = 0. 6.5.3. If Ur = λr with |r|2 = 1, then 1 = r †r = r †U †Ur = |λ|2r †r = |λ|2. 6.5.4. Choose a coordinate system in which the rotation is about the z-axis, and transform our rotation matrix to these coordinates. This transformation CHAPTER 3. EXERCISE SOLUTIONS 85 will not change the trace of the rotation matrix. Now the rotation matrix will have the form U =  cos ϕ sin ϕ 0 − sin ϕ cos ϕ 0 0 0 1  , and the trace of U is obviously 1 + 2 cos ϕ. 6.5.5. Expand |y⟩ in the eigenvectors: |y⟩ = ∑ i ci|xi⟩. Then note that, because |y⟩ is of unit magnitude and the |xi⟩ are or- thonormal, ⟨y|y⟩ = ∑ ij c∗cj⟨xi|xj⟩ = ∑ i |c 2| = 1 . Moreover, because the |xi⟩ are orthonormal eigenvectors, ⟨y|A|y⟩ = ∑ ij c ∗cj⟨xi|A|xj⟩ = ∑ i |c 2|λi . Lower and upper bounds for this expression can now be obtained by re-λi by the smallest or the largest eigenvalue, after which the |c 2| can be summed (yielding unity). 6.5.6. From Exercise 6.5.3 the eigenvalues have |λ| = 1. If U is Hermitian, then λ is real, hence ±1. 6.5.7. If γµ and γν anticommute, γµγν = −γνγµ. Take the determinants of the two sides of this equation: det(γµγν) = det(γµ) det(γν) = det(−γνγµ) = (−1) n det(γν) det(γµ). Here we have used the fact that the determinant is not a linear operator, and that the determinant of −A is (−1) n det(A), where n is the dimension of the determinant. Since the γ are unitary, they cannot be singular, and the anticommutation leads to an inconsistency unless n is even, making (−1) n = +1. 6.5.8. Expand |y⟩ in the eigenfunctions: A|y⟩ = ∑ n cnA|xn⟩ = ∑ n λncn|xn⟩, with cn = ⟨xn|y⟩. We get the same result from the eigenvector form of A: A|y⟩ = ∑ n λn|xn⟩⟨xn|y⟩ = ∑ n λncn|xn⟩ . 6.5.9. The solution is given in the text. CHAPTER 3. EXERCISE SOLUTIONS 86 6.5.10. Write ⟨vi|A|uj⟩ = λj⟨vi|uj⟩ = ⟨A †vi|uj⟩ = λ∗⟨vi|uj⟩ . Subtracting the right-hand side of the second line from that of the ﬁrst (λj − λ∗)⟨vi|uj⟩ = 0 , from which we conclude that ⟨vi|uj⟩ = 0 unless λ∗ = λj. 6.5.11. (a) and (b) Apply ˜A to the ﬁrst equation and A to the second: ˜AA|fn⟩ = λn ˜A|gn⟩ = λ2 |fn⟩ , A˜A|gn⟩ = λnA|fn⟩ = λ2 |gn⟩ . (c) Because A is real, ˜AA and A˜A are both self-adjoint (Hermitian), and therefore have eigenvectors that have real eigenvalues and form an orthog- onal set. 6.5.12. If the given formula for A gives the required result for every member of an orthogonal set it is a valid expression for A. Apply the formula to an |fj⟩ of arbitrary j. Because the fn⟩ are orthonormal, the result reduces to λj|gj⟩. 6.5.13. (a) A˜A = 1 5 ( 8 −6 −6 17 ) ˜AA = (1 0 0 4 ) , (b) λ1 = 1 |g1 >= 1 √5 ( 2 ) , |f1 >= ( 1 ) , (c) λ2 = 2, |g2 >= 1 √5 ( 1 −2 ) , |f2 >= ( 0 ) . 6.5.14. Disregard this exercise (it is ill-deﬁned). 6.5.15. (a) Take the adjoint of U; because H is self-adjoint, the result is U † = exp(−iaH). Note that an exponential can be interpreted as its power- series expansion and the adjoint taken termwise, thus validating the pro- cessing applied to the exponent. The result shows that U † = U −1. (b) Form UU T = exp(iaH) exp(−iaH). Because H commutes with itself, this product reduces to exp(iaH − iaH) = 1. Note that exponentials can be combined in this way only if the exponents commute. (c) If H is diagonalized by a similarity transformation, the zero trace CHAPTER 3. EXERCISE SOLUTIONS 87 implies that the sum of its eigenvalues λn is zero. Then U, which is also diagonal, will have diagonal elements exp(iaλn), and its determi- nant, which will then be the product of its diagonal elements, will beia ∑ λn) = exp(0) = +1. (d) Conversely, in a basis in which H and U are diagonal, a unit determi- nant for U implies an exponential in which exp(ia ∑ λn) = 1; this condi- tion does not quite imply that trace H = 0, but only that a(trace H) = 0 is an integer multiple of 2π. 6.5.16. From Avi = Aivi we obtain A n = A nvi for i = 0, 1, 2, . . . . From B = exp(A) = ∞∑ n=0 A n/n! we get B = ∞∑ n=0 A nvi/n! = ∞∑ n=0 [An/n!] vi = (e Ai)vi. 6.5.17. For any operator A, the eigenvalues of A 2 are the squares of the eigenvalues of A. 6.5.18. Inserting the indicated expansion and using the orthogonality property of the eigenvectors, ⟨x|A|x⟩ = λ1⟨x1|x1⟩ + n∑ i=2 |δi|2λn⟨xi|xi⟩ , ⟨x|x⟩ = ⟨x1|x1⟩ + n∑ i=2 |δi|2⟨xi|xi⟩ . Because all λi for i > 1 are smaller than λ1, ⟨x|A|x⟩ < λ1 ( ⟨x1|x1⟩ + n∑ i=2 |δi|2⟨xi|xi⟩ ) , so ⟨x|A|x⟩ ⟨x|x⟩ < λ1 . The error when this ratio is used to approximate λ1 is approximately 1 ⟨x|x⟩ n∑ i=2(λ1 − λi)|δi| 2⟨xi|xi⟩ , which is of order |δi| 2. CHAPTER 3. EXERCISE SOLUTIONS 88 6.5.19. (a) Letting x1 and x2 be the displacements of the two moveable masses, each of the same mass m, measured from their equilibrium positions (with the positive direction for both xi the same), the equations of motion are m¨x1 = −kx1 + k(x2 − x1) , m¨x2 = −kx2 − k(x2 − x1) . In a normal mode of oscillation xi = Xie iωt, with the same angular fre- quency ω for both masses. Inserting these expressions, − mω2 k X1 = −2X1 + X2 , − mω2 k X2 = X1 − 2X2 . These equations are equivalent to the matrix equation ( 2 −1 −1 2 ) ( X1 X2 ) = λ ( X1 X2 ) , with λ = mω2/k. (b) This is an eigenvalue equation which has solutions only if ∣ 2 − λ −1 −1 2 − λ ∣ = 0 , with eigenvalues λ = 1 and λ = 3. (c) For λ = 1, the equation solution is X1 = X2, corresponding to the two masses moving, in phase, back and forth. For λ = 3, the equation solution is X1 = −X2, corresponding to a periodic motion in which the masses oscillate relative to each other. 6.5.20. Relying on the proof that a normal matrix A and its adjoint have the same eigenvectors xj, ⟨xj|A|xj⟩ = λj⟨xj|xj⟩ = ⟨A †xj|xj⟩ = µ ∗⟨xj|xj⟩ , where µj is the eigenvalue of A † corresponding to xj. We see that µ∗ = λj. Since A and A † have common eigenvectors, (A + A †)|xj⟩ = (λj + λ∗)|xj⟩ = 2ℜe λj . Likewise, A − A † has eigenvalues λj − λ∗, or 2i ℑm λj. CHAPTER 3. EXERCISE SOLUTIONS 89 6.5.21. (a) Using Eq. (3.37), the matrix U of the rotation is U =  1/2 −1/2 1/√ 2 1/2 −1/2 −1/√2 1/ √2 1/√2 0  . U has the following eigenvalues and eigenvectors: λ1 = 1 r1 = √ 2/3 ˆex + √1/3 ˆez λ2 = 1 2 (−1 + i √3) r2 = − √1/6 ˆex + i √ 1/2 ˆey + √ 1/3 ˆez λ3 = 1 2 (−1 − i √3) r3 = − √1/6 ˆex − i √ 1/2 ˆey + √ 1/3 ˆez From these data we see that the rotation of the coordinate axes corre- sponding to U is equivalent to a single rotation about ϕ1 by an angle given as the phase of λ2 (the angle it makes with the real axis), which is 120 ◦. CHAPTER 3. EXERCISE SOLUTIONS 90 7. Ordinary Diﬀerential Equations 7.1 Introduction (no exercises) 7.2 First-Order Equations 7.2.1. (a) Separating the variables obtain I(t) = I0e −t/RC, where I0 is the inte- gration constant. (b) Here Ω = 106 Ohm, then I0 = 10−4 Amp, RC = 104 sec and at t = 100, e −t/RC = e −0.01 ≈ 0.99. Thus, I = 0.99 × 10 −4 Amp. The time 100 sec is only 1% of the time constant RC. 7.2.2. Separating variables obtain ln f (s) = ∫ f ′(s) f (s) ds = − ∫ sds s2 + 1 = − 1 2 ln(s 2 + 1) + ln C, implying f (s) = C √s2 + 1 . 7.2.3. ∫ N N0 dN N 2 = − ∫ t 0 kdt = −kt = − 1 N + 1 N0 . Thus, N = N0 1 + t/τ , τ = (kN0) −1. 7.2.4. (a) Set A0 = A(0), B0 = B(0). Separating variables and using a partial fraction expansion obtain α ∫ dt = αt = ∫ dC (A0 − C)(B0 − C) = 1 B0 − A0 ∫ ( 1 A0 − C − 1 B0 − C ) dC. Thus ln A0 − C B0 − C = (A0 − B0)αt + ln A0 B0 . Rewrite this as C(t) = A0B0[e (A0−B0)αt − 1] A0e(A0−B0)αt − B0 . Then C(0) = 0. (b) From ∫ dC (A0 − C)2 = αt get 1 A0 − C = αt + 1 A0 , which yields C(t) = αA2t 1 + αA0t . Again C(0) = 0. CHAPTER 3. EXERCISE SOLUTIONS 91 7.2.5. The values n < 0 are unphysical as the acceleration diverges. The case n = 0 gives m[v − v(0)] = −kt, v(t) = v(0) − kt/m, x(t) = x(0) + v(0)t − kt2/2m . The case n = 1 gives v(t) = v(0)e −kt/m, x(t) = x(0) + mv(0) k (1 − e −kt/m) . For n ̸= 0, 1, 2 and n > 0 we integrate to get v1−n − v(0)1−n) 1 − n = ∫ dv vn = − k m t, v(t) = v(0) [1 + (n − 1) kt m v(0)n−1]1/(1−n) . Integrating again gives x(t) = x(0) + mv(0)2−n (2 − n)k [ 1 − ( 1 + (n − 1) kt m v(0)n−1)(n−2)/(n−1)] . The case n = 2 leads to ˙x = v(0) 1 + αt , x(t) = x(0) + m k ln (1 + kv(0)t m ) . 7.2.6. The substitution u = y/x, or y = xu, corresponds to dy = xdu + udx, and our ODE assumes the form x du + u dx = g(u) dx , or x du = [g(u) − u] dx , which is separable. 7.2.7. If ∂ϕ ∂x = P (x, y) then ϕ(x, y) = ∫ x x0 P (X, y)dX + α(y) follows. Diﬀerentiating this and using ∂ϕ ∂y = Q(x, y) we obtain Q(x, y) = dα dy + ∫ x x0 ∂P (X, y) ∂y dX, so dα dy = Q(x, y) − ∫ x x0 ∂Q(X, y) ∂X dX. CHAPTER 3. EXERCISE SOLUTIONS 92 So dα dy = Q(x0, y) and α(y) = ∫ y y0 Q(x0, Y ) dY. Thus ϕ(x, y) = ∫ x x0 P (X, y)dX + ∫ y y0 Q(x0, Y )dY. From this we get ∂ϕ ∂x = P (x, y) and ∂ϕ ∂y = ∫ x x0 ∂P (X, y) ∂y dX+Q(x0, y) = ∫ x x0 ∂Q(X, y) ∂X dX+Q(x0, y) = Q(x, y). 7.2.8. See proof of Exercise 7.2.7. 7.2.9. For α dy + α(py − q) dx = 0 to be exact requires ∂α ∂x = ∂ ∂y α(x)(py − q) = α p, which is Eq. (7.14). 7.2.10. For f (x)dx + g(x)h(y)dy = 0 to be exact requires ∂f (x) ∂y = 0 = ∂g(x)h(y) ∂x = h(y) ∂g(x) ∂x , i.e., g =const. 7.2.11. y′ = −pe − ∫ x pdt [∫ x e ∫ s p(t)dtq(s)ds + C] + e − ∫ x pdte ∫ x pdtq(x) implies y′ + p(x)y(x) = q(x). 7.2.12. Separating variables we get − bt m = ln(g − b m v) − ln(A b m ) with A an integration constant. Exponentiating this we obtain v(t) = mg b − Ae −bt/m, thus v0 = v(0) = mg b − A. Hence v(t) = (v0 − mg b ) e −bt/m + mg b . Set v0 = 0 here. The velocity dependent resistance force opposes the gravitational acceler- ation implying the relative minus sign. 7.2.13. Solve ﬁrst for N1, which is separable and has the general solution N1 = Ce −λ1t. Since N1(0) = N0, we have N1(t) = N0e −λ1t . Substitute this result into the equation for N2, which is now an inhomoge- neous equation in which N2 is the only unknown. We look for a particular CHAPTER 3. EXERCISE SOLUTIONS 93 integral of the inhomogeneous equation, guessing the form of the solution to be N2 = A exp(−λ1t). Thus, dN2 dt +λ2N2 = λ1N0e −λ1t becomes −Aλ1e −λ1t+Aλ2e −λ1t = λ1N0e −λ1t , conﬁrming that with a proper choice of A our guess will work. We ﬁnd that A = λ1N0/(λ2 − λ1). To this particular integral we must add the multiple of the solution to the homogeneous equation that is needed to satisfy the condition N2(0) = 0. The homogeneous equation has solution e −λ2t, so our complete solution is N2(t) = λ1N0 λ2 − λ1 (e −λ1t − e −λ2t) . 7.2.14. We have dV /dt = −C4πr2 with V = 4πr3/3 the volume and C a positive constant. So dr/dt = −C and r(t) = r0 − Ct. 7.2.15. (a) Separating variables, dv/v = −a dt yields ln v v0 = −at, v = v0e −at. (b) dv/v + a dt = 0 yields ϕ(t, v) = ln v + at. ϕ(t, v) = ln v0 =const. is equivalent to (a). (c) Substituting into the form of solution written in Exercise 7.2.11 with= 0, p = a we get v(t) = Ce−at. Setting t = 0 we identify C as c0. 7.2.16. Separating variables as in Example 7.2.1 we get the velocity v(t) = v0 tanh [ t T + tanh −1 ( vi v0 )] for vi ≥ 0. 7.2.17. This ODE is isobaric, and becomes separable under the substitution v = xy. Removing x via this substitution, the ODE becomes (vy − y) ( dv y − v dy y2 ) + v dy y = 0 . This equation separates into ( v − 1 v2 − 2v ) dv + dy y = 0 , with integral − 1 2 ln(v2 −2v)+ln y = ln C . Exponentiating, we get y2 v2 − 2v = C, or y x2y − 2x = C . CHAPTER 3. EXERCISE SOLUTIONS 94 7.2.18. This ODE is homogeneous, so we substitute y = vx, obtaining initially (x2 − v2x 2e v)dx + (x 2 + x 2v)e v(x dv + v dx) = 0 . This rearranges to dx x + (1 + v)e v dv 1 + vev = 0 with integral ln x + ln(1 + ve v) = ln C . Thus, x(1 + ve v) = C , or x + ye y/x = C . 7.3 ODEs with Constant Coeﬃcients 7.3.1. Try solution e mx. The condition on m is m 3 − 2m 2 − m + 2 = 0, with roots m = 2, m = 1, m = −1. The general solution to the ODE is therefore c1e 2x + c2e x + c3e −x. 7.3.2. Try solution e mx. The condition on m is m3 − 2m 2 + m − 2 = 0, with roots m = 2, m = i, m = −i. The solutions e ix and e −ix can be expressed in terms of the real quantities sin x and cos x, so the general solution to the ODE is c1e 2x + c2 sin x + c3 cos x. 7.3.3. Try solution e mx. The condition on m is m 3 − 3m + 2 = 0, with roots m = 1, m = 1, m = −2. Two independent solutions for m = 1 are e x and xe x, so the general solution to the ODE is c1e x + c2xe x + c3e −2x. 7.3.4. Try solution e mx. The condition on m is m 2 + 2m + 2 = 0, with roots m = −1 + i and m = −1 − i. We can combine e (−1+i)x and e (−1−i)x to form e −x sin x and e −x cos x, so the general solution to the ODE is c1e −x sin x + c2e −x cos x. 7.4 Second-Order Linear ODEs 7.4.1. For P (x) = − 2x 1 − x2 , Q(x) = l(l + 1) 1 − x2 , (1 ∓ x)P and (1 ∓ x) 2Q are regular at x = ±1, respectively. So these are regular singularities.z → 0, 2z − 2/z 1 − 1 z2 = 2(z + z 1 − z2 ) is regular, and Q(z−1) z4 = l(l + 1) z2(z2 − 1) ∼ z−2 diverges. So ∞ is a regular singularity. 7.4.2. For P = 1 − x x , Q = n x , x = 0 is a regular singularity. For z → 0, 2z − P (z−1) z2 = z + 1 z2 ∼ 1/z2 diverges more rapidly than 1/z, so ∞ is an irregular singularity. CHAPTER 3. EXERCISE SOLUTIONS 95 7.4.3. Writing the Chebyshev equation in the form y′′ + ( x 1 − x2 ) y′ + ( n2 1 − x2 ) y = 0 , we see that the coeﬃcients of y′ and y become singular (for ﬁnite x) only at x = ±1 and that each singularity is ﬁrst order, so the ODE has regular singularities at these points. At inﬁnity, we apply the criterion given after Eq. (7.22). For the present ODE, 2x − P (x−1) x2 = 2 x − 1/x x2 − 1 , Q(x−1) x4 = n2 x4 − x2 . These have, at x = 0, singularities that are respectively of ﬁrst and second order, indicating that the ODE has a regular singularity at inﬁnity. 7.4.4. Hermite’s ODE (as given in Table 7.1) has no coeﬃcients that are singular at ﬁnite x, and therefore is regular for all ﬁnite x. At inﬁnity, 2x − P (x−1) x2 = 2 x + 2 x3 has a singularity of order 3 at x = 0, so the ODE will have an irregular singularity at inﬁnity. 7.4.5. x(1 − x) d2 dx2 + [c − (a + b + 1)x] d dx − ab → (1 − x2) d2 dx2 − 2x d dx + l(l + 1) because d2 dx2 → 4 d2 dx2 , d dx → −2 d dx , −ab → l(l + 1), x(1 − x) → 1 − x 2 ( 1 − 1 − x 2 ) = 1 4 (1 − x 2), c − (a + b + 1)x → 1 − (l + 2 − l) 1 − x 2 = x. 7.5 Series Solutions—Frobenius’ Method 7.5.1. If initial conditions are y(x0) = y0, y′(x0) = y′ 0 are given, the solutions’ Taylor expansions are identical provided x0 is no worse than a regular singularity. The factor x k from the indicial equation does not aﬀect this. 7.5.2. Under the translation x1 = x − x0, d/dx1 = d/dx, etc. the ODE is invariant and y(x − x0) = y(x1) has the same Maclaurin expansion as y(x) at x = 0. As a result, the recursion relations for the coeﬃcients and the indicial equation stay the same. CHAPTER 3. EXERCISE SOLUTIONS 96 7.5.3. If a1k(k + 1) = 0 with a1 ̸= 0, then k = 0 or k = −1. (a) k = 0 sets a1k(k + 1) = 0 where a1 remains undetermined. (b) If k = 1 then the indicial equation a1k(k + 1) = 0 requires a1 = 0. 7.5.4. The two indicial equations for Legendre’s ODE are k(k − 1)a0 = 0 and k(k + 1)a1 = 0. For Bessel’s ODE they are (k2 − n 2)a0 = 0 and [(k + 1) 2 − n2)]a1 = 0. For Hermite’s ODE they are the same as Legendre’s. The rest of the solution is given in the text. 7.5.5. Compare with Eq. (18.120). Convergent for |x| < 1, also at x = 1 for c > a + b and at x = −1 for c > a + b − 1. 7.5.6. Compare with Eq. (18.136). Convergent for all ﬁnite x provided the se- ries exists [c ̸= − n, a negative integer, in Eq. (18.137), 2 − c ̸= − n in Eq. (18.136)]. 7.5.7. The point ξ = 0 is a regular singularity of the ODE. The trial solution∑ j ajξk+j yields the given indicial equation. For k = m/2, a0 ̸= 0 and non-negative m we set the coeﬃcient of the term ξk+1 to zero. This gives a1 = −αa0/(m+1). Setting the coeﬃcient of ξk+2 to zero gives the second given term, etc. 7.5.8. Substituting ∞∑ j=0 ajηj+k and its derivatives into d dη (1 − η2) du dη + αu + βu2 = 0, we obtain the recursion relation aj+2(j + k + 2)(j + k + 1) − aj[(j + k)(j + k + 1) − α] + βaj−2 = 0. For j = −2, a−2 = 0 = a−4 by deﬁnition and the indicial equation k(k − 1)a0 = 0 comes out, i.e. k = 0 or k = 1 for a0 ̸= 0. For j = −1 with a−3 = 0 = a−1 we have a1k(k + 1) = 0. If k = 1, then a1 = 0 implying a3 = 0 = a5. For j = 0, k = 0 we get 2a2 = −a0α and 6a2 = a0(2 − α) for k = 1. For j = 1, k = 0 we ﬁnd 6a3 = 12a3 = a1(6 − α) for k = 1. Finally, for j = 2, k = 1 we have 20a4 − (12 − α)a2 + βa0 = 0, giving the expansion listed in the problem set. 7.5.9. Substituting ψ = a0 + a1x + a2x 2 + a3x3 + · · · , and setting A ′ = 2mA ℏ2 , E′ = 2mE ℏ2 , V = A x e −ax, A < 0, a > 0, we obtain 2a2+6a3x+· · ·+[−A′ + (E′ + aA ′)x − 1 2 A′a 2x 2 + · · · ] (a1+a2x+· · · ) = 0, CHAPTER 3. EXERCISE SOLUTIONS 97 where the coeﬃcients of all powers of x vanish. This implies a0 = 0, 2a2 = A ′a1, 6a3 + a1(E′ + aA′) − A′a2 = 0, etc. Thus, we get the given series. 7.5.10. Even though the point x = 0 is an essential singularity we try substituting ∞∑ j=0 ajx j+k, y′ = ∞∑ j=0 aj(j +k)x j+k−1, y′′ = ∞∑ j=0 aj(j +k)(j +k −1)x j+k into our ODE we obtain the recursion relation aj[(j + k)(j + k − 1) − 2] + aj+1(j + k + 1) = 0. For j = −1, a−1 = 0 by deﬁnition, so k = 0 for a0 ̸= 0 is the indicial equation. For j = 0, −2a0 + a1 = 0, and for j = 1, −2a1 + 2a2 = 0, while j = 2 yields a3 = 0, etc. Hence our solution is y = a0(1 + 2x + 2x 2), and this is readily veriﬁed to be a solution. 7.5.11. Writing the solution to the ODE as e x √2πx f (x), we ﬁnd that f (x) satisﬁes the ODE x2f ′′ + 2x 2f ′ + f /4 = 0. Substituting into this ODE the series expansion f (x) = b0 + b1/x + b2/x 2 + · · · , we ﬁnd that the bn satisfy the recurrence formula bn+1 = n(n + 1) + 1 4 2n + 2 bn , which, with the initial value b0 = 1, we can use to obtain the coeﬃcients in the asymptotic expansion. The ﬁrst two coeﬃcients are b1 = (1/4)/2 = 1/8 and b2 = (2 + 1 4 )b1/4 = 9/128. 7.6 Other Solutions 7.6.1. aˆx + bˆy + cˆz =  a b c  = 0 implies a = b = c = 0. 7.6.2. If A, B, C are linearly independent, geometry tells us that their volume (A × B) · C ̸= 0, and vice versa. 7.6.3. Using yn = x n n! , y′ n = x n−1 (n − 1)! , etc. for n = 0, 1, . . . , N we get W1 = ∣ 1 x 0 1 ∣ = 1, W2 = ∣ 1 x x2 2 0 1 x 0 0 1 ∣ = ∣ 1 x 0 1 ∣ = W1 = 1, and, continuing, W2 = · · · = WN = 1. CHAPTER 3. EXERCISE SOLUTIONS 98 7.6.4. If W = y1y′ 2 − y′ 1y2 = 0, then y′ 1 y1 = y′ 2 y2 . Integrating gives ln y1 = ln y2 + ln C. Hence y1 = Cy2, and vice versa. 7.6.5. If the Wronskian W (x) is written as a Taylor series at x0, all of its coeﬃ- cients must be zero. 7.6.6. The answer is given in the text. 7.6.7. ϕ′ does not exist at x = 0.. 7.6.8. These functions are related by 2y1(x) − y2(x) − 1 y2(x) = 0, which is non- linear. 7.6.9. PnQ ′ − P ′ nQn = W (x) = Ane − ∫ x P dt = An 1 − x2 because − ∫ x P dt = ∫ x 2t 1 − t2 dt = − ln(1 − x 2). 7.6.10. Assuming there to be three linearly independent solutions, construct their Wronskian. It will be identically zero. 7.6.11. From ( d dx p(x) d dx + q(x) ) u = 0 we have (a) ∫ dW W = − ∫ x p′ p dx = ln 1 p + ln C = ln W. Hence W = W (a) p(x) with W (a) = C. (b) y2 = W (a)y1 ∫ x ds p(s)y1(s)2 follows from W (y1, y2) = y2 1(x) d dx y2(x) y1(x) . 7.6.12. Using y = zE, E = e − 1 2 ∫ x P dt, y′ = z′E − 1 2 zP E, y′′ = z′′E − P z′E − z 2 P ′E + z 4 P 2E, we obtain y′′ + P y′ + Q = E [ z′′ − z 2 P ′ − z 4 P 2 + Qz] = 0. 7.6.13. Since ∇ 2 = ∂2 ∂r2 + 2 r ∂ ∂r + L 2 r2 we have − 1 2 ∫ r P dt = − ∫ r dr r = − ln r, e− 1 2 ∫ r P dt = 1 r , so that ϕ(r) = ψ(r)/r. Equivalently ∇2ϕ(r) = 1 r d2 dr2 (rϕ) + L 2 r2 ϕ. CHAPTER 3. EXERCISE SOLUTIONS 99 7.6.14. Deﬁning E1 = ∫ x e − ∫ s P dt y1(s)2 ds, E(x) = e − ∫ x P dt and using y2 = y1(x)E1, y′ 2 = y′ 1E1 + E y1 , y′′ 2 = y′′ 1 E1 − P E y1 , we obtain y′′ 2 + P y′ 2 + Qy2 = E1(y′′ 1 + P y′ 1 + Qy1) = 0. 7.6.15. Changing the lower limit from a to b changes the integral that multiplies y2 by a constant: ∫ s a P dt = ∫ s b P dt + ∫ b a P dt and via ∫ x a e − ∫ s a P dt y2 1(s) ds = e − ∫ b a P dt ∫ x b e − ∫ s b P dt y2 1(s) ds + ∫ b a e − ∫ s a dt y2 1(s) ds adds a constant to y2. 7.6.16. Using − ∫ r dr r = − ln r, e − ∫ r P dt = 1 r , ∫ r ds s · s2m = − r−2m 2m , we have y2 = −rm r−2m 2m = − 1 2mrm . 7.6.17. As P = 0, y1 = sin x, e − ∫ x P dt =const. and y2 = sin x ∫ x ds sin 2 s = sin x cot x = cos x. Using the series expansions with p−1 = 0 = q−2 gives the indicial equation k(k − 1) = 0. Thus k = α = 1 = n and y2(x) = y1(x) c1 ln x + ∞∑ j=0,j̸=1 cj j − 1 x j−1  . Substituting these y2, y′ 2, y′′ 2 into the classical harmonic oscillator ODE yields 2y′ 2  c1 x + ∞∑ j=0,j̸=1 cjx j−2  + y1 − c1 x2 + ∞∑ j=0,j̸=1 cj(j − 2)x j−3  = 0. The Taylor series for y1 = sin x gives 2c1 − c1 = c1 = 0 for the coeﬃcient of 1/x. Thus, y2 does not contain a term proportional to ln x. CHAPTER 3. EXERCISE SOLUTIONS 100 7.6.18. Since Bessel’s ODE is invariant under n → −n we expect and verify that J−n(x), deﬁned by its Taylor series, is a solution along with Jn(x). From the lowest power series coeﬃcients we obtain W (Jn, J−n) = An x = −2 sin πn πx ̸= 0, so that they are independent if n ̸= integer. This is Eq. (14.67). The standard series y = ∞∑ j=0 ajxj+k leads to the indicial equation [k(k − 1) + k − N 2]a0 = 0. For a0 ̸= 0 we obtain k = ±N, N ≥ 0. The roots are α = N, n = 2N, consistent with pj = δj,−1, qj = δj0 + N 2δj,−2, n − 2α = p−1 − 1, α(α − n) = q−2. The second solution is y2 = y1(x) ∞∑ j=0 cj ∫ x x j−n−1 1 dx1. If n ̸=integer there is no ln x term in y2. Since n = 2N, if N is neither an integer nor half of an odd integer, there is no logarithmic term in y2. It remains for us to show that when N =half an odd integer there is no ln x term in y2. Since WN (x) ̸= 0 for N ̸=integer, this is clear from our ﬁrst part. 7.6.19. (a) If y1 = 1 for α = 0 then ∫ x P dt = −x 2,and y2 = ∫ x e s2ds, y′ 2 = e x 2 , y′′ 2 = 2xe x 2 . Hence y′′ 2 − 2xy′ 2 = 0. Integrating the power series for e s 2 yields y2(x) = ∞∑ j=0 x2j+1 (2j + 1)j! = ∞∑ j=0 a2jx2j+1 with aj+2 aj = 2(j + 1) (j + 2)(j + 3) , j even, which is the recursion for the k = 1 case of Exercise 8.3.3 (a) for α = 0. (b) If α = 1 then y1 = x is a solution of the ODE, as is easily veriﬁed, and y2 = x ∫ x e s2 s2 ds. CHAPTER 3. EXERCISE SOLUTIONS 101 Integrating the power series yields y2(x) = ∞∑ j=0 a2jx 2j = −1 + ∞∑ j=1 x 2j (2j − 1)j! with aj+2 aj = 2(j − 1) (j + 1)(j + 2) , j even, which is the recursion for k = 0 of Exercise 8.3.3 (a) for α = 1. 7.6.20. For n = 0, y1 = 1 is veriﬁed to be a solution of Laguerre’s ODE where P (x) = 1 x − 1. As ∫ x P dt = ln x − x, y2(x) = ∫ x e x x dx = ln x + 1 + x 2 + · · · . = ln x + ∞∑ n=1 x n n · n! . 7.6.21. (a) See the solution of Exercise 7.6.20.y′ 2 = e x x , y′′ 2 = e x x − e x x2 = y′ 2 − y′ 2 x . Hence y′′ 2 + ( 1 x − 1 ) y′ 2 = 0. (c) y2 = ∫ x e s s ds = ∞∑ n=1 1 n! ∫ x s n−1 ds = ln x + ∞∑ n=0 x n n!n , y′ 2 = e x x = ∞∑ n=0 x n−1 n! , and y′′ 2 = − 1 x2 + ∞∑ n=2 x n−2 (n − 2)!n imply y′′ 2 + ( 1 x − 1) y′ 2 = ∞∑ n=2 x n−2 (n − 2)! ( 1 n + 1 n(n − 1) − 1 n − 1 ) = 0. 7.6.22. (a) The coeﬃcient P (x1) is the coeﬃcient of y′ when the ODE is written in a form such that the coeﬃcient of y′′ is unity; thus, P (x) = −x/(1−x 2), and therefore ∫ P (x) dx = ln(1 − x 2)/2. Then the formula of Eq. (7.67) becomes (for n = 0, y1 = 1), y2(x) = ∫ x e − ln(1−x 2)/2 dx2 = ∫ (1 − x2)−1/2 dx = sin−1 x . CHAPTER 3. EXERCISE SOLUTIONS 102 (b) Letting v = y′, our ODE becomes (1 − x2)v′ − xv = 0, which is separable, of the form dv v = x dx 1 − x2 , with integral ln v = − 1 2 ln(1 − x 2) . Exponentiating both sides, and then writing y2 as the integral of v, we reach the same integral as in part (a). 7.6.23. The value of exp(− ∫ P dx) has the same value as in Exercise 7.6.22, namely (1 − x 2) −1/2. Therefore our solution y2 (for n = 1, y1 = x) is y2 = x ∫ x du u2(1 − u2)1/2 = −(1 − x 2) 1/2 . 7.6.24. Rescale the ODE by multiplying by 2m/ℏ2 so that E′ = 2mE/ℏ2, b′ 1 = 2mb−1/ℏ2, etc. The indicial equation has roots −(p−1 − 1) ∓ √ (p−1 − 1)2 − 4q−2 2 , with p−1 = 0 and q−2 = −l(l + 1). The root for the regular solution is α1 = l + 1 and that of the irregular solution is α2 = −l. Since P (r) = 0 we have y2(r) = y1(r) ∫ r ds y1(s)2 . This leads to y2(r) ∼ r−l[1 + O(r)] as well. 7.6.25. y′ 2 = y1f implies y′ 2 = y′ 1f + y1f ′, y′′ 2 = y′′ 1 f + 2y′ 1f ′ + y1f ′′, and so y′′ 2 + P y′ 2 + Qy2 = f (y′′ 1 + P y′ 1 + Qy1) + P y1f ′ + 2y′ 1f ′ + y1f ′′ = 0. Thus f ′′y1 + f ′(2y′ 1 + P y1) = 0. Separating variables and integrating yields ln f ′ = −2 ln y1 − ∫ x P dt, f ′ = 1 y1(x)2 e − ∫ x P dt, and f as given. 7.6.26. (a) From y1 = a0x(1+α)/2, we have y′ 1 = a0 2 (1 + α)x (α−1)/2, y′′ 1 = a0 4 (α2 − 1)x(α−3)/2. CHAPTER 3. EXERCISE SOLUTIONS 103 Hence y′′ 1 + 1 − α2 4x2 y1 = a0 4 x (α−3)/2(α2 − 1)(1 − 1) = 0. Similarly,2 = a0x(1−α)/2, y′ 2 = a0 2 (1 − α)x −(α+1)/2, y′′ 2 = a0 4 (α2 − 1)x −(α+3)/2. Hence y′′ 2 + 1 − α2 4x2 y2 = a0 4 x −(α+3)/2(α2 − 1)(1 − 1) = 0. Alternatively, a solution y ∼ xp leads to p(p − 1) + (1 − α2)/4 = 0 with the roots p = (1 ± α)/2. (b) y10 = a0x1/2, P = 0 give ∫ x P dt = 0, e − ∫ x P dt = 1. Hence y20 = a0x 1/2 ∫ x ds a2s = 1 a0 x 1/2 ln x. (c) L’Hˆopital’s rule gives lim α→0 y1 − y2 α = lim α→0 x (α+1)/2 − x(−α+1)/2 α = 1 2 x1/2 ln x. 7.7 Inhomogeneous Linear ODEs 7.7.1. Denoting E1 = ∫ x y1F ds W (y1, y2) , E2 = ∫ x y2F ds W (y1, y2) , we check that y′ p = y′ 2E1 − y′ 1E2 + y2y1F W − y1y2F W = y′ 2E1 − y′ 1E2, y′′ p = y′′ 2 E1 − y′′ 1 E2 + F W (y′ 2y1 − y2y′ 1) = y′′ 2 E1 − y′′ 1 E2 + F. Hence y′′ p + P y′ p + Qyp = E1(y′′ 2 + P y′ 2 + Qy2) − E2(y′′ 1 + P y′ 1 + Qy1) + F = F. This is the generalization of the variation of the constant method of solving inhomogeneous ﬁrst-order ODEs to second-order ODEs. If we seek a particular solution of the form yp(x) = y1(x)v(x) with y1(x) a solution of the homogeneous ODE y′′ + P y + Qy = 0, then v obeys d dx (y2 1v′) + P y2 1v′ = y1F, CHAPTER 3. EXERCISE SOLUTIONS 104 from which there follows d dx (y2 1v′e ∫ x P (t) dt) = y1(x)F (x)e ∫ x P (t) dt = y1F W (y1, y2) . Integrating this gives y2 1v′ W = ∫ x y1(s)F (s) W (y1(s), y2(s)) ds. Rewriting this as v′(x) = d dx y2(x) y1(x) ∫ x y1(s)F (s) W (y1(s), y2(s)) ds and integrating a second time yields v(x) = y2(x) y1(x) ∫ x y1(s)F (s) W (y1(s), y2(s)) ds − ∫ x y2(s)F (s) W (y1(s), y2(s)) ds. Hence the desired yp. 7.7.2. We need the general solution to the related homogeneous equation and a particular integral of the complete inhomogeneous ODE. The homoge- neous equation y′′ + y = 0 has solutions y1 = cos x and y2 = sin x. We might be able to guess a particular integral (y = 1) but we can also use the method of variation of parameters. This method assumes a particular integral of the form y(x) = u1(x)y1(x) + u2(x)y2(x), and leads to the two equations u′ y1 + u′ y2 = u′ cos x + u′ sin x = 0 , u′ y′ 1 + u′ y′ 2 = −u′ sin x + u′ cos x = 1 . These equations have solution u′ = − sin x, u′ = cos x; these can be integrated to obtain u1 = cos x, u2 = sin x. Inserting these into the expression for y(x), we get y(x) = cos2 x+sin2 x = 1. The general solution to the original ODE is therefore c1 cos x + c2 sin x + 1. 7.7.3. Following the strategy and notation of the answer to Exercise 7.7.2, wey1 = cos 2x, y2 = sin 2x, from which we ﬁnd u′ = −e x sin(2x)/2 and u′ = e x sin(2x)/2. We integrate these expressions to ﬁnd u1 = (e x/10)(2 cos 2x − sin 2x), u2 = (e x/10)(cos 2x + 2 sin 2x), so y = u1y1 + u2y2 = e x/5. The original ODE has general solution c1 cos 2x + c2 sin 2x + e x/5. 7.7.4. Following the strategy and notation of the answer to Exercise 7.7.2, we ﬁnd1 = e x, y2 = e 2x, from which we ﬁnd u′ = −e −x sin x and u′ = e −2x sin x. We integrate these expressions to ﬁnd u1 = (e −x/2)(cos x + sin x), u2 = −(e −2x/5)(cos x + 2 sin x), so y = u1y1 + u2y2 = (3 cos x + sin x)/10. The original ODE has general solution c1e x + c2e 2x + (3 cos x + sin x)/10. CHAPTER 3. EXERCISE SOLUTIONS 105 7.7.5. Following the strategy and notation of the answer to Exercise 7.7.2, we ﬁnd by inspection y1 = x + 1; using the Wronskian method we get the second solution y2 = e x. Remembering that the inhomogeneous term is to be determined when the original ODE is in standard form (coeﬃcienty′′ equal to 1) we set up the equations for the u′ and ﬁnd u′ = −1, u′ = (x + 1)e −x, so u1 = −x and u2 = −(x + 2)e −x. Thus, y = u1y1 + u2y2 = −(x 2 + 2x + 2). We can, without generating an error, remove from y the 2x + 2 since it is just 2y1. Thus, the original ODE has general solution c1(x + 1) + c2e x − x 2. 7.8 Nonlinear Diﬀerential Equations 7.8.1. A more general solution to this Riccati equation is y = 2 + u, where u is a general solution to the Bernoulli equation u′ = 3u + u2. See Eq. (7.104). In the notation of Eq. (7.101), p = 3, q = 1, and n = 2, and the Bernoulli equation has solution u = 1/v, where v is a solution of v′+3v = −1, namely v = Ce −3x + 1 3 . Therefore u = 3/(Ce−3x − 1) and y = 2 + 3/(Ce−3x − 1). 7.8.2. A more general solution to this Riccati equation is y = x2 + u, where u is a general solution to the Bernoulli equation u′ = u2/x 3 + u/x. See Eq. (7.104). In the notation of Eq. (7.101), p = 1/x, q = 1/x 3, and n = 2, and the Bernoulli equation has solution u = 1/v, where v is a solution of v′ + v = −1/x3, namely v = (Cx + 1)/x2. Therefore u = x 2/(Cx + 1) and y = x 2 + x2 Cx + 1 = Cx3 + 2x 2 Cx + 1 . 7.8.3. This ODE corresponds to Eq. (7.101) with p = −x, q = x, and n = 3. Thus, with u = y−2, Eq. (7.102) becomes u′ − 2xu = −2x. The homoge- neous equation for u has solution e x 2 , and from the method of variation of parameters or by inspection, a particular integral of the inhomogeneous equation is u = 1. Thus the general solution for u is u = Cex2 + 1. Since y = u−1/2, the general solution for y is y = 1/ √Cex2 + 1. 7.8.4. (a) The general solution comes from y′′ = 0, and therefore has the form y = ax + b. However, not all values of a and b lead to solutions of the original Clairaut equation. Substituting into y = xy′ + (y′) 2, we ﬁnd ax + b = xa + a 2, which shows that y is a solution only if b = a 2. (b) The singular solution comes from 2y′ = −x, which integrates to y = −x 2/4 + C. Substituting into y = xy′ + (y′) 2, we get −x 2/4 + C = x(−x/2) + x 2/4, which shows that this y is a solution only if C = 0. The singular and a general solution coincide only if −x 2/4 = ax0 + a2, the solution to which is x0 = −2a. At x0, both solutions have slope a, so the singular solution is tangent to each instance of the general solution and is therefore referred to as their envelope. CHAPTER 3. EXERCISE SOLUTIONS 106 8. Sturm-Liouville Theory 8.1 Introduction (no exercises) 8.2 Hermitian Operators 8.2.1. Using ψ(x) = e −x/2y(x) in the ODE xy′′ + (1 − x)y′ + ny = 0 gives the equivalent self-adjoint ODE d dx ( x dψ dx ) + (n + 1 2 − x 4 )ψ = e −x/2 [xy′′ + (1 − x)y′ + ny] = 0. The weight function w = e −x and the interval are also obvious from the orthogonality relation, Eq. (18.55). Note also that d dx ( xe −xy′(x)) = e −x[(1 − x)y′ + xy′′] from which p(x) = xe −x follows. Note that multiplying the wave function by e −x/2 and the ODE by e −x leads to the same results. 8.2.2. Using ψn(x) = e −x 2/2Hn(x) in the ODE H ′′ n − 2xH ′ n + 2nHn = 0 gives the equivalent self-adjoint Hermite ODE ψ′′ n + (2n + 1 − x 2)ψn = e −x2/2[H ′′ n − 2xH ′ n + 2nHn] = 0. The weight function w = e −x2 and the interval are obvious from the orthogonality relation in Eq. (18.11). Note that multiplying the wave function by e −x 2/2 and the ODE by e −x 2 leads to the same results. 8.2.3. The Chebyshev ODE in Table 7.1 is that whose polynomial solutions are the Type I Chebyshev polynomials Tn. Multiplying the ODE (1−x 2)T ′′ n − xT ′ n +n2Tn = 0 by (1−x 2) −1/2, we obtain the equivalent self-adjoint ODE d dx [(1 − x 2) 1/2 dTn dx ] + n2(1 − x 2) −1/2Tn = 0 . The coeﬃcient of Tn has the functional form of the scalar-product weight- ing function. 8.2.4. (a) For Legendre’s ODE p(x) = 1 − x 2, which is zero for x = ±1. Thus x = ±1 can be the endpoints of the interval. Since polynomial solutions of the ODE will be ﬁnite and have ﬁnite derivatives at x = ±1, then v∗pu′|x=±1 = ∓ 1 n(n + 1) 2 (1 − x 2)|x=±1v∗(±1)u(±1) = 0, and Sturm-Liouville boundary conditions will be satisﬁed for the interval−1, 1]. CHAPTER 3. EXERCISE SOLUTIONS 107 (b) We consider here the Chebyshev polynomials Tn(x). When the Cheby- shev ODE is written in self-adjoint form, the coeﬃcient p(x) is (1 −x 2) 1/2, which is zero at x = ±1. Therefore the Sturm-Liouville boundary condi- tions are satisﬁed at x = ±1 because the polynomials remain ﬁnite there and have ﬁnite derivatives. (c) For Hermite’s ODE p(x) = e −x2 → 0 only for x ± ∞., and p(x) goes to zero faster than any polynomial. Thus, the boundary conditions are satisﬁed for the interval (−∞, ∞). (d) For Laguerre’s ODE p(x) = xe −x is zero for x = 0 and p(x) goes to zero as x → ∞ faster than ay polynomial, so the boundary conditions are satisﬁed for the interval [0, ∞). 8.2.5. If u2 = Cu1, then Hu2 = C(Hu1) = λ1Cu1 = λ1u2, i.e., λ1 = λ2. Thus, two linearly dependent eigenfunctions cannot have diﬀerent eigenvalues. 8.2.6. (a) Use integration by parts, integrating the factor x and writing the result as (x2 − 1)/2, and diﬀerentiating the logarithms. This yields ∫ 1 −1 x 2 ln 1 + x 1 − x dx = x 2 − 1 4 ln 1 + x 1 − x ∣ 1 1 − ∫ 1 −1 x2 − 1 4 ( 1 1 − x + 1 1 + x ) dx = 1 2 ∫ 1 −1 dx = 1, the integrated term being zero. Alternatively, we can expand Q0(x) as a power series and then integrate xQ0(x) term by term. We get ∫ 1 −1 P1Q0 dx = lim ǫ→0 ∞∑ ν=0 ∫ 1−ǫ −1+ǫ x 2ν+2 2ν + 1 dx = 2 ∞∑ ν=0 1 (2ν + 1)(2ν + 3) = 1 ̸= 0. (b) The necessary boundary conditions are violated because Q0 is singular at x = ±1. 8.2.7. Dividing (1 − x2)y′′ − xy′ + n 2y = 0 by (1 − x 2) 1/2 puts the Chebyshev ODE in self-adjoint form with p(x) = (1 − x 2) 1/2, q(x) = 0, w(x) = (1 − x 2) −1/2, λ = n2. The boundary condition p(v∗u′ − v′∗u) ∣ 1 1 = 0 is not satisﬁed when u = T0(x) and v = V1(x). In this particular case, u′ = 0, u = 1, and v′ is an odd function which becomes inﬁnite at x = ±1 at a rate that is proportional to 1/p(x). The result is that the Sturm- Liouville boundary condition is not satisﬁed. 8.2.8. By integrating by parts the ﬁrst term of ∫ b a um d dx p(x)u′ dx + λn ∫ b a umw(x)un dx = 0, CHAPTER 3. EXERCISE SOLUTIONS 108 we obtain ump(x)u′ |b − ∫ b a u′ pu′ dx + λn ∫ b a umw(x)un dx = 0. The ﬁrst term is zero because of the boundary condition, while the third term reduces to λnδnm by orthogonality. Hence the orthogonality relation ∫ b a u′ pu′ dx = λnδmn. 8.2.9. If ψn = n−1∑ i=1 aiψi then Aψn = λnψn = n−1∑ i=1 aiλiψi. Comparing both ex- pansions, aiλi/λn = ai, i.e., λi = λn for those i for which ai ̸= 0. This contradicts our hypothesis. 8.2.10. (a) Multiply by (1 − x2)α−1/2. 8.3 ODE Eigenvalue Problems 8.3.1. Using y = ∞∑ j=0 ajxj+k to solve (1 − x 2)y′′ − 2xy′ + n(n + 1)y = 0 yields aj+2 = (j + k)(j + k + 1) − n(n + 1) (j + k + 2)(j + k + 1) aj. (a) For j = −2, a−2 = 0 sets up the indicial equation k(k − 1)a0 = 0, with solutions k = 0 and k = 1 for a0 ̸= 0. (b) The case k = 0 gives the recursion formula aj+2 = j(j + 1) − n(n + 1) (j + 2)(j + 1) aj. Hence y(x) has even parity. (c) If k = 1 then we get the recursion formula aj+2 = (j + 1)(j + 2) − n(n + 1) (j + 2)(j + 3) aj. Hence y(x) has odd parity. (d) If the numerator of either recursion formula is always nonzero, then the ratio aj+2/aj → 1 as j → ∞, implying divergence for x = 1. Both the above series also diverge at x = −1. (e) If n is a non-negative integer one of the two series of cases (b) and (c) breaks oﬀ at j = n, generating in case (b) the Legendre polynomials containing even powers of x, and in case (c) the Legendre polynomials containing odd powers of x. CHAPTER 3. EXERCISE SOLUTIONS 109 8.3.2. If the Hermite ODE is multiplied through by exp(−x 2), it becomes e −x2y′′ − 2xe −x2 y′ + 2αe −x2 y = 0 −→ [ e −x2y′]′ + 2αe −x2y = 0, a manifestly self-adjoint ODE. This eigenvalue problem will be Hermi- tian if the weight factor exp(−x 2) is included in the scalar product and the ODE is solved subject to Sturm-Liouville boundary conditions. The requirement that the scalar product exist will necessarily mean that the boundary terms must vanish at x = ±∞, thereby deﬁning a Hermitian problem. 8.3.3. (a) The trial solution ∑ j ajx k+j yields the recursion formula aj+2 = 2(k + j − α) aj (k + j + 1)(k + j + 2) . For k = 0, a0 ̸= 0, a1 = 0 we get the given yeven. For k = 1, a0 ̸= 0, a1 = 0 we get the given yodd. (b) For j ≫ α, k the recursion yields aj+2/aj → 2/j, just like the coeﬃ- cients of e x2, viz. (j/2)!/( j 2 + 1)! → 1/( j 2 + 1). (c) If α =non-negative integer, then the series break oﬀ. 8.3.4. Let n be a non-negative integer. Then the ODE is Eq. (18.44) and its solutions are given in Eqs. (18.46), (18.53) and Table 18.2. The trial ∑ j a(n) j xk+j yields the recursion formula a(n) j+2 = (k + j − n)a(n) j (k + j + 1)2 . For k = 0 and n a non-negative integer the series breaks oﬀ. 8.3.5. The inﬁnite series does converge for x = ±1. Hence this imposes no restriction on n. Compare with Exercise 1.2.6. If we demand a polynomial solution then n must be a nonnegative integer. 8.3.6. For k = 1, take n to be a positive odd integer. Compare with Eq. (18.98). Here a0 = (−1) (n−1)/2(r + 1). 8.4 Variation Method 8.4.1. (a) The normalization integral is 4α3 ∫ ∞ 0 x 2e −2αx dx = 4α3 ( 2! (2α)3 ) = 1. (b) ⟨x−1⟩ = 4α3 ∫ ∞ 0 xe −2αx dx = 4α3 ( 1! (2α)2 ) = α. CHAPTER 3. EXERCISE SOLUTIONS 110 (c) d2ψ dx2 = 2α3/2(α2x − 2α), and therefore 〈 d2 dx2 〉 = 4α3 ∫ ∞ 0 (α2x 2 − 2αx)e −2αx dx = α2 − 2α2 = −α2. (d) For general α, W (α) = 〈ψ ∣− 1 2 d2 dx2 − 1 x ∣ ψ〉 = α2 2 − α . The value of α that minimizes W (α) is obtained by setting dW/dα = 0; the result is α = 1, from which we ﬁnd W (1) = −1/2. 8.5 Summary, Eigenvalue Problems (no exercises) CHAPTER 3. EXERCISE SOLUTIONS 111 9. Partial Diﬀerential Equations 9.1 Introduction (no exercises) 9.2 First-Order Equations 9.2.1. Introduce variables s = x + 2y, t = 2x − y. Then ∂ψ ∂x + 2 ∂ψ ∂y = 5 ( ∂ψ ∂s ) t , and our PDE becomes an ODE in s with parametric dependence on t: 5 dψ ds + tψ = 0 , so ln ψ = − ts 5 + C(t) or ψ = f (t)e −ts/5 , where f (t) is arbitrary. In terms of x and y, the general solution of this PDE is ψ(x, y) = f (2x − y) e −(2x2−2y2+3xy)/5 . This solution assumes a somewhat simpler form if we multiply the expo- nential by exp(−2t2/5) = exp(−[8x 2 + 2y2 − 8xy]/5) (incorporating the change into f ), reaching ψ(x, y) = f (2x − y) exp(−2x 2 + xy). 9.2.2. Following a procedure similar to that in the solution to Exercise 9.2.1, set s = x − 2y and t = 2x + y, and note that x + y = (3t − s)/5. The PDE reduces to 5 dψ ds + 3t − s 5 = 0 . This ODE has solution ψ = (s − 3t) 2/50 + f (t) = (x + y)2/2 + f (2x + y), with f arbitrary. 9.2.3. Here s = x + y − z; t and u can be t = x − y, u = x + y + 2z. The PDE reduces to 3 dψ/ds = 0, with solution ψ = f (t, u) = f (x − y, x + y + 2z), with f arbitrary. 9.2.4. Here s = x + y + z, take t = x − y, u = x + y − 2z. The PDE reduces to 3 dψ ds = t , with solution ψ = ts 3 + C . The solution can be simpliﬁed by subtracting tu/3 and making the obser- vation that t(s−u)/3 = tz. We then have ψ = z(x−y)+f (x−y, x+y−2z), with f arbitrary. 9.2.5. (a) It is useful to note that= 2x dx−2y dy −→ 2x ( ∂x ∂u ) v−2y ( ∂y ∂u ) v = 0 −→ ( ∂y ∂u ) v = x y ( ∂x ∂u ) v . CHAPTER 3. EXERCISE SOLUTIONS 112 Then we form ( ∂ψ ∂u ) v = [( ∂ψ ∂x ) y + x y ( ∂ψ ∂y ) x ] ( ∂x ∂u ) v = 0 , where the right-hand side of this equation vanishes because the quantity within the square brackets is zero according to the PDE. We now eﬀec- tively have an ODE in u with solution ψ = f (v) = f (x 2 − y2), with f arbitrary. (b) The lines of constant v are characteristics of this equation; they diﬀer from our earlier examples in that they are not straight lines, but curves deﬁned by x 2 − y2 = constant. 9.2.6. Deﬁne u and v as in Exercise 9.2.5, and from du = x dy + y dx ﬁnd ( ∂y ∂v ) u = − y x ( ∂x ∂v ) u . Now we form ( ∂ψ ∂v ) u = [( ∂ψ ∂x ) y − y x ( ∂ψ ∂y ) x ] ( ∂x ∂v ) u = 0 , where the quantity within square brackets vanishes by virtue of the PDE. Integrating the resulting ODE, we get ψ = f (u) = f (xy), with f arbitrary. 9.3 Second-Order Equations 9.3.1. It may be easiest to multiply out the factored expression for L and start from Lf = afxx + 2bfxy + cfyy, where the subscripts identify diﬀerentia- tions. Then, using the deﬁnitions of ξ and η, we have fx = c 1/2fξ , fy = c −1/2(−b fξ + fη) , fxx = c fξξ fxy = −b fξξ + fξη , fyy = c−1(b2fξξ − 2bfξη + fηη) . Substituting into the original expression for L, we get Lf = (ac − b2)fξξ + fηη . 9.4 Separation of Variables 9.4.1. (∇2 + k2)(a1ψ1 + a2ψ2) = a1∇2ψ1 + a1k2ψ1 + a2∇2ψ2 + a2k2ψ2. 9.4.2. If ψ = R(ρ)Φ(ϕ)Z(z) then ( 1 Rρ d dρ ρ dR dρ + f (ρ) + k2) + 1 ρ2 ( 1 Φ d2Φ dϕ2 + g(ϕ) ) + ( 1 Z d2Z dz2 + h(z)) = 0 CHAPTER 3. EXERCISE SOLUTIONS 113 leads to the separated ODEs d2Z dz2 + h(z)Z = n2Z, d2Φ dϕ2 + g(ϕ)Φ = −m2Φ, ρ d dρ ρ dR dρ + [(n2 + f (ρ) + k2)ρ2 − m2]R = 0. 9.4.3. Writing ψ(r, θ, ϕ) = R(r)Y (θ, ϕ), and noting that L 2Y (θ, ϕ) = l(l + 1)Y (θ, ϕ), L 2 = − 1 sin θ ∂ ∂θ sin θ ∂ ∂θ − 1 sin 2 θ ∂2 ∂ϕ2 , we have (∇2 + k2)ψ(r, θ, ϕ) = ( 1 r2 ∂ ∂r r2 ∂ ∂r − L 2 r2 + k2) R(r)Y (θ, ϕ), d dr r2 dR dr + (k2r2 − l(l + 1))R = 0. The order in which variables are separated doesn’t matter. 9.4.4. Separating 1 R d dr r2 dR dr + (k2 + f (r))r2 = L 2 r2 − g(θ) − h(ϕ) sin 2 θ = l(l + 1) implies d dr r2 dR dr + [(k2 + f (r))r2 − l(l + 1)]R = 0, − sin θ ∂ ∂θ sin θ ∂P ∂θ − P [(g(θ) + l(l + 1)] sin 2 θ + m 2P = 0, d2Φ dϕ2 + h(ϕ)Φ = −m 2Φ. 9.4.5. ψ = Ae ik·r obtained from separating the Cartesian coordinates gives ∇ψ = ikψ, ∇2ψ = −k2ψ, with kx = π a nx, . . . , E = ℏ2k2/2m, k2 = π2 ( n 2 a2 + n2 b2 + n2 c2 ) . The case nx = ny = nz = 1 gives the answer in the text. CHAPTER 3. EXERCISE SOLUTIONS 114 9.4.6. Writing L 2 = 1 sin θ ∂ ∂θ sin θ ∂ ∂θ + 1 sin 2 θ ∂2 ∂ϕ2 with ∂2e imϕ ∂ϕ2 = −m2e imϕ for ψ ∼ e imϕP m l gives the ODE for the associated Legendre polynomials. 9.4.7. (a) bψ′′ − mk ℏ2 x2ψ = − 2mE ℏ2 ψ becomes α2 d2ψ dξ2 − α4x 2ψ = −α2λψ. (b) ψ(ξ) = y(ξ)e −ξ2/2 implies ψ′ = y′e −ξ2/2 − ξye −ξ2/2, ψ′′ = y′′e −ξ2/2 − 2ξy′e −ξ2/2 − ye−ξ2/2 + ξ2ye −ξ2/2, and e −ξ2/2(y′′ + λy − 2ξy′ − y) = 0, which is Hermite’s ODE for y. 9.5 Laplace and Poisson Equations 9.5.1. (a) ∇ 2 1 r = − 2 r 1 r2 − d dr 1 r2 = 0 for r > 0. See Example 3.6.1. Or use ∇2f (r) = 1 r d2 dr2 [ rf (r)] for f (r) = r, r > 0. For r = 0 there is a singularity described by ∇ 2 1 r = −4πδ(r). (b) In spherical polar coordinates z = r cos θ, so ψ2 = 1 2r ln 1 + cos θ 1 − cos θ . For r ̸= 0, ∇ 2ψ2 = 1 r2 sin θ ∂ ∂θ ( sin θ ∂ψ2 ∂θ ) = 1 2r3 sin θ d dθ [sin θ ( − sin θ 1 + cos θ − sin θ 1 − cos θ )] = − 1 2r3 sin θ d dθ ( 2 sin 2 θ 1 − cos2 θ ) = 0. CHAPTER 3. EXERCISE SOLUTIONS 115 For r = 0, ∫ r≤R ∇2ψ2d3r = ∮ ˆr · ∇ψ2 = − R2 2R2 ∫ 2π 0 dϕ ∫ π 0 sin θ ln 1 + cos θ 1 − cos θ dθ = −π ∫ 1 −1 ln 1 + z 1 − z dz = 0 because ln 1 + z 1 − z is odd in z. 9.5.2. ∇2 ∂ ∂z ψ = ∂ ∂z ∇2ψ = 0 because [∇ 2, ∂ ∂z ] = 0. 9.5.3. Taking ψ to be the diﬀerence of two solutions with the same Dirichlet boundary conditions, we have for ψ a Laplace equation with ψ = 0 on an entire closed boundary. That causes the left-hand side of Eq. (9.88) to vanish; the ﬁrst integral on the right-hand side also vanishes, so the remaining integral must also be zero. This integral cannot vanish unlessψ vanishes everywhere, which means that ψ can only be a constant. 9.6 Wave Equation 9.6.1. The most general solution with ψ(x, 0) = sin x is ψ = A sin(x − ct) + (1 − A) sin(x + ct); for this solution ∂ψ/∂t evaluated at t = 0 is (1 − 2A)c cos x. The condition on ∂ψ/∂t requires that we set (1 − 2A)c = 1, or A = (c − 1)/2c. Thus, ψ(x, t) = ( c − 1 2c ) sin(x − ct) + ( c + 1 2c ) sin(x + ct) = sin x cos ct + c −1 cos x sin ct . 9.6.2. Given a general solution of the form f (x − ct) + g(x + ct) we require f (x) + g(x) = δ(x) and f ′(x) − g′(x) = 0, i.e., f ′(x) = g′(x). This second condition leads to g(x) = f (x) + constant, and the ﬁrst condition then yields f (x) = g(x) = δ(x)/2. Therefore, ψ(x, t) = 1 2 [ δ(x − ct) + δ(x − ct) ] . 9.6.3. By a process similar to that for Exercise 9.6.2, we have ψ(x, t) = 1 2 [ ψ0(x − ct) + ψ0(x + ct)] . 9.6.4. The functions f (x − ct) and g(x + ct) with t derivatives equal to sin x at t = 0 are (apart from a constant) c −1 cos(x − ct) and −c −1 cos(x + ct). CHAPTER 3. EXERCISE SOLUTIONS 116 Thus, we must have ψ(x, 0) = c −1[A cos(x − ct) − (1 − A) cos(x + ct)]; to make ψ(x, 0) = 0 we take A = 1/2, so ψ(x, t) = 1 2c [ cos(x − ct) − cos(x + ct)] = 1 c sin x sin ct . 9.7 Heat Flow, or Diﬀusion PDE 9.7.1. From 1 KT dT dt = 1 Rr2 d dr r2 dR dr − L 2Y Y r2 = −α2, it follows that dT dt = −α2KT, L 2Y = l(l + 1)Y, d dr r2 dR dr + α2r2R = l(l + 1)R. By spherical symmetry l = 0, Y = Y00 = 1/ √4π. So l = m = 0. 9.7.2. Without z, ϕ-dependence and denoting λ = κ/σρ we have ∂ψ ∂t = λ∇ 2ψ with ψ = P (ρ)T (t) so that 1 λT dT dt = −α2 = 1 Rρ d dρ ρ dP dρ . Hence dT dt = −λα2T, d dρ ρ dP dρ + α2ρP = 0 = ρ d2P dρ2 + dP dρ + α2ρP. 9.7.3. Equation (9.114) applies to this problem, as it is for the 1-D boundary con- dition that ψ → 0 at x = ±∞ and is written in terms of the temperature distribution at t = 0. Thus, with ψ0 = Aδ(x), we have ψ(x, t) = 1 √π ∫ ∞ −∞ A δ(x − 2aξ√t) e −ξ2 dξ . Using the relation ∫ δ(at − b)f (t) dt = a−1f (b/a), we ﬁnd ψ(x, t) = A 2a√πt e −x2/4a 2t . This has the expected properties: at t = 0 it is zero everywhere except at x = 0; it approaches zero everywhere at t → ∞; for all t the integral of ψ over x is A. CHAPTER 3. EXERCISE SOLUTIONS 117 9.7.4. This problem becomes notationally simpler if the coordinates of the ends of the rod are placed at −L/2 and L/2, with the end at −L/2 kept at T = 0 and the end at L/2 kept at T = 1. We write the initial temperature distribution in terms of the spatial eigenfunctions of the problem as ψ0 = x L + 1 2 − ∑ j cjϕj(x) , where the j summation is the expansion of x/L+1/2 in the eigenfunctions of nonzero ω. This mode of organization makes explicit that all the terms in the j sum must decay exponentially in t, leaving in the large-t limit the steady-state temperature proﬁle that connects the ﬁxed temperatures at the ends of the rod.ϕj must be chosen subject to the boundary condition that they vanish at x = ±L/2; those representing the expansion of 1/2 must be cosine functions, while those for the expansion of x/L must be sine functions. Speciﬁcally, Expansion of 1/2: ϕj= cos jπx/L, j odd Expansion of x/L: ϕj = sin jπx/L, j even Making use of the orthogonality properties of these functions and changing the indices to account for the restriction to odd and even values, we have 1 2 = ∞∑ j=0 c2j+1 cos (2j + 1)πx L , c2j+1 = 2(−1)j π(2j + 1) , x L = ∞∑ j=1 c2j sin 2jπx L , c2j = (−1) j+1 πj . To form ψ(x, t) we now attach to each term in the summations the de- caying exponential factor shown in Eq. (9.101) and append the time- independent terms corresponding to ω = 0: ψ(x, t) = x L + 1 2 − ∞∑ j=0 2(−1)j π(2j + 1) cos (2j + 1)πx L e −t[(2j+1)πa/L]2 − ∞∑ j=1 (−1)j+1 πj sin 2jπx L e −t(2jπa/L)2 . 9.8 Summary (no exercises) CHAPTER 3. EXERCISE SOLUTIONS 118 10. Green’s Functions 10.1 One-Dimensional Problems 10.1.1. The general solution to −d2y/dx2 = 0 is y = c1x + c0; a solution u with u(0) = 0 is u(x) = x; a solution v with v′(1) = 0 is v(x) = 1. Thus the form of the Green’s function must be G(x, t) = Ax for x < t and G(x, t) = At for x > t. To ﬁnd A we note that for the given L, p = −1 and that A = p(t)[uv′ − u′v] = (−1)[0 − 1] = +1. We recover the required formula for G(x, t). 10.1.2. (a) G(x, t) =  − sin x cos(1 − t) cos 1 , 0 ≤ x ≤ t, − sin t cos(1 − x) cos 1 , t ≤ x ≤ 1. (b) G(x, t) = { −e x−t/2, −∞ < x < t, −e t−x/2, t < x < ∞. 10.1.3. Our expression for y(x) is y(x) = ∫ x 0 sin(x − t)f (t) dt. Its derivatives are y′(x) = sin(x − x)f (x) + ∫ x 0 cos(x − t)f (t) dt = ∫ x 0 cos(x − t)f (t) dt. y′′(x) = cos(x − x)f (x) − ∫ x 0 sin(x − t)f (t) dt = f (x) − y(x) . This equation shows that y(x) satisﬁes Eq. (10.24) and the formulas for y(0) and y′(0) show that both vanish. 10.1.4. The solutions to the homogeneous ODE of this exercise (that with f (x) = 0) are y1(x) = sin(x/2) and y2(x) = cos(x/2). To satisfy the boundary condition at x = 0 we take G(x, t) = sin(x/2)h1(t) for x < t; to satisfy the boundary condition at x = π we take G(x, t) = cos(x/2)h2(t) for x > t. To achieve continuity at x = t we take h1(t) = A cos(t/2) and h2(t) = A sin(t/2). The value of A must cause ∂G/∂x to have a discontinuous jump of −1 at x = t (the coeﬃcient p of the ODE is −1). The diﬀerence in those derivatives is ∂G(x, t) ∂x ∣ x=t+ − ∂G(x, t) ∂x ∣ x=t− = − A 2 sin(x/2) sin(t/2) − A 2 cos(x/2) cos(t/2) −→ − A 2 = −1, so A = 2. CHAPTER 3. EXERCISE SOLUTIONS 119 10.1.5. With L = x d2 dx2 + d dx + k2x 2 − 1 x , L = 0 has solutions J1(kx) and Y1(kx). We use J1(kx) as a solution that vanishes at x = 0; we form a linear combination of J1(kx) and Y1(kx) that vanishes at x = 1. The constant π/2 comes from an evaluation of the Wronskian of these two solutions, most easily evaluated from their asymptotic forms, see Eqs. (14.140) and G(x, t) =  π 2 [ Y1(kt) − Y1(k)J1(kt) J1(k) ] J1(kx), 0 ≤ x < t, π 2 [Y1(kx) − Y1(k)J1(kx) J1(k) ] J1(kt), t < x ≤ 1. 10.1.6. L is the operator deﬁning the Legendre equation. This equation has sin- gular points at x = ±1 and there is only one solution that is ﬁnite at these points. Hence u(x)v(t) = v(x)u(t) and it is not possible to obtain a discontinuity in the derivative at x = t. 10.1.7. The homogeneous equation corresponding to this ODE can be solved by integrating once to get y′ + ky = C and then rearranging to the form dy = (C − ky)dx. We identify the general solution to this equation as y(t) = C(1 − he−kt). Letting the Green’s function be written in the form G(t, u), we note that the only solution for 0 ≤ t < u that satisﬁes the boundary conditions y(0) = y′(0) = 0 is the trivial solution y(t) = 0. For u < t < ∞ there is no boundary condition at t = ∞, so G(t, u) can have the general form G(t, u) = C(u)(1 − h(u)e −kt), with C(u) and h(u) determined by the connection conditions at t = u. Continuity at t = u leads to 1 − h(u)e −ku = 0, or h(u) = e ku, so G(t, u) has for t > u the more explicit form G(t, u) = C(u) ( 1 − e −k(t−u)) . To determine C(u) from the discontinuity in the derivative of G(t, u) we must ﬁrst ﬁnd the quantity p when the homogeneous ODE is written in self-adjoint form. That value of p is e kt, and our ODE is modiﬁed to d dt [ e ktψ′(t)] = e ktf (t). We now determine C(u) from ∂ ∂t [C(u) (1 − e −k(t−u))] t=u = k C(u) = 1 p(u) = e −ku. The ﬁnal form for our Green’s function is therefore G(t, u) =  0, 0 ≤ t < u, e −ku − e −kt k , t > u, CHAPTER 3. EXERCISE SOLUTIONS 120 and the inhomogeneous equation has the solution ψ(t) = ∫ t 0 G(t, u)e kuf (u) du . Note that we would have gotten the same overall result if we had sim- ply taken p to be the coeﬃcient of y′′ in the original equation and not multiplied f (u) by the factor needed to make the ODE self-adjoint. Finally, with f (t) = e −t, we compute ψ(t) = 1 k ∫ t 0 ( e −ku − e −kt) e (k−1)u du = 1 k [ 1 − 1 k − 1 ( ke−t − e −kt) ] . 10.1.8. The answer is given in the text. 10.1.9. The answer is given in the text. 10.1.10. The answer is given in the text. 10.1.11. The answer is given in the text. 10.1.12. If a1 = 0, the diﬀerential equation will be self-adjoint and K(x, t) will be symmetric. Cf. Section 21.4. 10.1.13. Start by ﬁnding the Green’s function of the ODE without the V0 term. The truncated ODE has solutions e ±kr. A solution satisfying the boundary condition at r = 0 is e kr − e −kr, equivalent (except for a factor 2) to sinh kr. A solution satisfying the boundary condition at r = ∞ is e −kr. The Wronksian of sinh kr and e −kr is −k, so the Green’s function is G(r, t) =  − 1 k e −kt sinh kr, 0 ≤ r < t, − 1 k e −kr sinh kt, t < r < ∞ . We now treat our ODE as an inhomogeneous equation whose right-hand side is −V0e −ry(r)/r. Using the Green’s function to form its solution, we obtain the integral equation given in the text. Note that G(r, t) of the exercise is −1 times the Green’s function. 10.2 Problems in Two and Three Dimensions 10.2.1. This problem was solved in Example 10.2.1. 10.2.2. The operator L is Hermitian if, for all ϕ(r) and ψ(r) satisfying the bound- ary conditions, ⟨ϕ|Lψ⟩ = ⟨Lϕ|ψ⟩. To show this, use the identity f ∇ · U = ∇ · (f U) − ∇f · U, recognize that one of the integrals is zero because from CHAPTER 3. EXERCISE SOLUTIONS 121 Gauss’ theorem it is equivalent to a surface integral on the boundary, andϕ|Lψ⟩ = ∫ V ∇ · [ϕ ∗∇ · (ρ∇ψ)] dτ − ∫ V ∇ϕ ∗ · (ρ∇ψ)dτ = − ∫ V ρ∇ϕ ∗ · ∇ψ dτ ⟨Lϕ|ψ⟩ = ∫ V ∇ · [ψ∇ · (ρ∇ϕ ∗)] dτ − ∫ V ∇ψ · (ρ∇ϕ∗)dτ = − ∫ V ρ∇ψ · ∇ϕ ∗ dτ The fact that these two integrals are identical conﬁrms that L is Hermitian. 10.2.3. Using the Fourier transform of the Green’s function and of the delta func- tion we ﬁnd ∫ G(r1, r2)d3r2 = ∫ d3p (2π)3 ∫ e ip·(r1−r2) k2 − p2 d3r2 = ∫ d3p e ip·r1 k2 − p2 δ(p) = 1 k2 . 10.2.4. Using Example 20.3.3 we have (∇2 + k2) ∫ d3p (2π)3 e ip·(r−r ′) k2 − p2 = δ(r − r ′). 10.2.5. G(r1, r2) = − cos k|r1 − r2| 4π|r1 − r2| . 10.2.6. Integrate the equation for the modiﬁed Helmholtz Green’s function over a sphere of radius a, using Gauss’ theorem to avoid the necessity of eval- uating the Laplacian at the origin, where it is singular. We must have: ∫ Va ∇ · ∇G(r12)dτ − k2 ∫ Va G(r12) dτ = ∫ ∂Va ∇G(r12) · dσ − k2 ∫ Va G(r12) dτ = ∫ Va δ(r12)dτ = 1. Using the form given for G(r12) and recognizing the spherical symmetry, the integrals become ∫ ∂Va ∇G(r12) · dσ = 4πa2 [ ke−kr12 4πr12 + e −kr12 4πr2 12 ] r12=a = (ka + 1)e −ka ∫ Va G(r12) dτ = − ∫ a 0 e −kr12 4πr12 4πr2 12 dr12 = −1 + (1 + ka)e −ka k2 . Inserting these results, we verify the initial equation of this problem solu- 10.2.7. The answer is given in the text. CHAPTER 3. EXERCISE SOLUTIONS 122 11. Complex Variable Theory 11.1 Complex Variables and Functions (no exercises) 11.2 Cauchy-Riemann Conditions 11.2.1. f (z) = x implies u = x, v = 0, ∂u ∂x = 1 ̸= ∂v ∂y = 0. Hence f is not analytic. 11.2.2. This follows from Exercise 6.2.4. 11.2.3. (a) w = f (z) = z3 = (x + iy) 3 = x 3 − 3xy2 + i(3x 2y − y3). (b) w = f (z) = e iz = e i(x+iy) = e −y(cos x + i sin x). 11.2.4. ∂u ∂x = ∂v ∂y = − ∂u ∂x implies ∂u ∂x = 0. Similarly, ∂u ∂y = 0 follows. Therefore, both u and v must be constants, and hence w1 = w2 =constant. 11.2.5. Write 1/(x + iy) as u + iv with u = x/(x2 + y2), v = −y/(x 2 + y2) and check that the Cauchy-Riemann equations are satisﬁed. ∂u ∂x = 1 x2 + y2 − 2x 2 (x2 + y2)2 = −x 2 + y2 (x2 + y2)2 , ∂u ∂y = −2xy (x2 + y2)2 , ∂v ∂y = −[ 1 x2 + y2 + 2y2 (x2 + y2)2 = −x 2 + y2 (x2 + y2)2 , ∂v ∂x = 2xy (x2 + y2)2 . 11.2.6. Write f = u + iv; the derivative in the direction a dx + ib dy is f ′ = a ( ∂u ∂x + i ∂v ∂x ) dx + b ( ∂u ∂y + i ∂v ∂y ) dy a dx + ib dy . Inserting the Cauchy-Riemann equations to make all the derivatives with respect to x, we get f ′ = a ( ∂u ∂x + i ∂v ∂x ) dx + b ( − ∂v ∂x + i ∂u ∂x ) dy a dx + ib dy . = ∂u ∂x (a dx + ib dy) + i ∂v ∂x (a dx + ib dy) a dx + ib dy = ∂u ∂x + i ∂v ∂x . The derivative has the same value as in the x direction. CHAPTER 3. EXERCISE SOLUTIONS 123 11.2.7. The real and imaginary parts of a analytic function must satisfy the Cauchy-Riemann equations for an arbitrary orientation of the coordinate system. Take one coordinate direction to be in the direction of ˆr and the other in the direction of ˆθ, and note that the derivatives of displacement in these directions are respectively ∂/∂r and r−1 ∂/∂θ. Noting also that the real and imaginary parts of ReiΘ are respectively R cos Θ and R sin Θ, the Cauchy-Riemann equations take the form ∂R cos Θ ∂r = ∂R sin Θ r ∂θ , ∂R cos Θ r∂θ = − ∂R sin Θ ∂r . Carrying out the diﬀerentiations and rearranging, these equations become ∂R ∂r − R r ∂Θ ∂θ = tan Θ [ R ∂Θ ∂r + 1 r ∂R ∂θ ] , ∂R ∂r − R r ∂Θ ∂θ = − cot Θ [ R ∂Θ ∂r + 1 r ∂R ∂θ ] . Multiplying together the left-hand sides of both these equations and set- ting the result equal to the product of the right-hand sides, we get [ ∂R ∂r − R r ∂Θ ∂θ ]2 = − [R ∂Θ ∂r + 1 r ∂R ∂θ ]2 . The quantities in square brackets are real, so the above equation is equiv- alent to the requirement that they must both vanish. These relations are the Cauchy-Riemann equations in polar coordinates. 11.2.8. Diﬀerentiating the ﬁrst Cauchy-Riemann equation from Exercise 11.2.7 with respect to θ and rearranging, we get 1 r2 ∂2Θ ∂θ2 = 1 rR ∂2R ∂r∂θ − 1 r2R ∂R ∂θ ∂Θ ∂θ = 1 rR ∂2R ∂r∂θ + 1 R ∂R ∂r ∂Θ ∂r , where we reached the last member of the above equation by substituting from the polar Cauchy-Riemann equations. Diﬀerentiating the second Cauchy-Riemann equation with respect to r and simplifying, we get after rearrangement ∂2Θ ∂r2 = − 1 R ∂Θ ∂r ∂R ∂r + 1 r2R ∂R ∂θ − 1 rR ∂2R ∂r∂θ . We also need, from the second Cauchy-Riemann equation, 1 r ∂Θ ∂r = − 1 r2R ∂R ∂θ . Adding together the three foregoing equations, the left-hand sides combine to give the Laplacian operator, while the right-hand sides cancel to give CHAPTER 3. EXERCISE SOLUTIONS 124 11.2.9. (a) f ′(z) = cos z z − sin z z2 . Analytic everywhere except at inﬁnity. Note that f (z) approaches a ﬁnite limit at z = 0 and has Taylor expansion 1 − z2/3! + · · · . At z = 0 the formula for f ′ must be interpreted as its limit (which is zero). (b) f ′(z) = −2z (z2 + 1)2 . Analytic everywhere except at z = i and z = −i (becomes inﬁnite at those values of z). (c) f ′(z) = − 1 z2 + 1 (z + 1)2 . Analytic everywhere except at z = 0 and z = −1. (d) f ′(z) = e −1/z z2 . Analytic everywhere except at z = 0. (e) f ′(z) = 2z − 3. Analytic everywhere except at z = ∞. (f) f ′(z) = 1 cos2 z . Analytic everywhere except at inﬁnity and at the zeros of cos z, which are at (n + 1 2 )π, for n any positive or negative integer or zero. (g) f ′(z) = 1 cosh2 z . Analytic everywhere except at inﬁnity and at the zeros of cosh z, which are at (n + 1 2 )iπ, for n any positive or negative integer or zero. 11.2.10. (a) For all ﬁnite z except z = 0. Even though z1/2 is zero at z = 0, this function does not have a well-deﬁned derivative there. (b) For all ﬁnite z except z = 0. (c) From the formula tan −1 z = 1 2i ln ( 1 + iz 1 − iz ) , we identify singularities at z = ±i; at these points tan −1 z has no deriva- tive. (d) From the formula tanh −1 z = 1 2 ln ( 1 + z 1 − z ) , we identify singularities at z = ±1; at these points, tanh −1 z has no deriva- tive. 11.2.11. (a) Since f ′(z) is independent of direction, compute it for an inﬁnitesimal CHAPTER 3. EXERCISE SOLUTIONS 125 displacement in the x direction. We have ∂f ∂z = ∂f ∂x = ∂u ∂x + i ∂v ∂x = ∂u ∂x − i ∂u ∂y , where the last member was obtained using a Cauchy-Riemann equation. Now identify ∂u/∂x as (∇u)x = Vx and ∂u/∂y as (∇u)y = Vy to obtain f ′ = Vx − iVy. (b) Use the fact that the real and imaginary parts of an analytic function each satisfy the Laplace equation. Therefore ∇ · V = ∇ · ∇u = 0. (c) ∇ × V = ∂ ∂x Vy − ∂ ∂y Vx = ∂2u ∂x∂y − ∂2u ∂y∂x = 0. 11.2.12. Equate the derivatives of f (z) = u + iv with respect to z∗ in the x and y directions: ∂u ∂x + i ∂v ∂x dx = ∂u ∂y + i ∂v ∂y −i dy . This yields equations similar to the Cauchy-Riemann equations, but with opposite signs. The derivative with respect to z∗ does not exist unless these equations are satisﬁed. The only way to satisfy both the Cauchy- Riemann equations and their sign-reversed analogs is to have all the deriva- tives in these equations vanish, equivalent to the requirement that f be a constant. 11.3 Cauchy’s Integral Theorem 11.3.1. ∫ z1 z2 f (z)dz = − ∫ z2 z1 [ (udx − vdy) + i(vdx + udy) ] . 11.3.2. ∣ ∫ C f (z)dz∣ ≤ ∫ C |f (z)| ds ≤ |f |maxL with L the length of the path C. 11.3.3. (a) In terms of x and y, F = 4z2 − 3iz = 4(x2 − y2) + 3y + (8xy − 3x)i . On the straight-line path, x and y are related by y = −7x + 25, so F has the two representations F1(x) = −192x2 + 1379x − 2425 + (−56x 2 + 197x)i , F2(y) = −192y2 − 53y + 2500 49 + (−8y2 + 203y − 75)i 7 . CHAPTER 3. EXERCISE SOLUTIONS 126 Integrating, ∫ 4−3i 3+4i F (z) dz = ∫ 4−3i 3+4i F (z)(dx + idy) = ∫ 4 3 F1(x) dx + i ∫ −3 4 F2(y) dy = ( 67 2 − 7i 6 ) + ( − 49 6 − 469i 2 ) = 76 − 707i 3 . (b) To integrate on the circle |z| = 5, use the polar representation z = 5e iθ. The starting point of the integral is at θ1 = tan −1(4/3) and its end point is at θ2 = tan−1(−3/4). F can now be written F3(θ) = 4(5 2e 2iθ) − 3i(5e iθ). The integral then takes the form ∫ θ2 θ1 F3(θ)(5ie iθ) dθ = ∫ θ2 θ1 (500ie 3iθ + 75e 2iθ)dθ = 500 3 (e 3iθ2 − e 3iθ1 ) − 75i 2 ( e 2iθ2 − e 2iθ1 ) . These expressions simplify, because e 3iθ1 = −117 + 44i 125 , e3iθ2 = −44 − 117i 125 , e 2iθ1 = −7 + 24i 25 , e 2iθ2 = 7 − 24i 25 , and we get ∫ θ2 θ1 F3(θ)(5ie iθ) dθ = 76 − 707i 3 , the same result as in part (a). Note that this integral is far easier if we integrate directly in z: ∫ 4−3i 3+4i (4z2 − 3iz) dz = [ 4z3 3 − 3iz2 2 ]4−3i 3+4i = 76 − 707i 3 . 11.3.4. The integrand is an analytic function for all ﬁnite z, so its integral between the given endpoints can be deformed in any way without changing its value. We may therefore evaluate F (z) using the indeﬁnite integral F (z) = (sin 2z)/2 + C, so F (πi) = sin(2πi)/2 − sin(2π[1 + i])/2. This expression can be simpliﬁed using the formula sin(a + b) = sin a cos b + cos a sin b; the second term reduces to − sin(2πi)/2, and we get F (πi) = 0. 11.3.5. (a) To integrate around the unit circle, set x = cos θ, y = sin θ, dz = ie iθdθ = i(cos θ + i sin θ)dθ, and (because the integration is clockwise) integrate from θ = 0 to θ = −2π. The integral will vanish because every term contains one odd power of either sin θ or cos θ and the integral is CHAPTER 3. EXERCISE SOLUTIONS 127 over an interval of length 2π. (b) For the square, taking ﬁrst the horizontal lines at y = 1 and y = −1, we note that for any given x the integrand has the same value on both lines, but the dz values are equal and opposite; these portions of the contour integral add to zero. Similar remarks apply to the vertical line segmentsx = ±1, giving an overall result of zero. These integrals are equal because of symmetry, and not because of ana- lyticity; the integrand is not analytic. 11.3.6. ∫ C z∗dz = ∫ 1 0 xdx + ∫ 1 0 (1 − iy)idy = 1 2 + i + 1 2 = 1 + i, whereas ∫ C′ z∗dz = ∫ 1 0 (−iy)dy + ∫ 1 0 (−i + x)dx = − i 2 + 1 2 − i = 1 2 − 3 2 i . 11.3.7. Since the contour is assumed to be a circle of radius greater than unity, it will surround both the points z = 0 and z = −1 for which the integrand becomes inﬁnite. Using Cauchy’s integral theorem, deform the contour (without changing the value of the integral) until the upper and lower arcs of the circle touch each other at some point between z = 0 and z = −1, and then further deform the left-hand and right-hand loops of the integral to convert them into separate circles surrounding these two values of z. Finally, write the contour integral as ∮ [ 1 z − 1 z + 1 ] dz and expand into two separate integrals (each over both circles). For the circle about z = 0 only the ﬁrst integral contributes; for the circle about z = −1 only the second integral contributes. Because of the minus sign in the partial fraction expansion, these integrals will be equal and opposite and therefore sum to zero. Note that if the original contour was a circle of radius less than unity, only the ﬁrst of the two partial fractions would be within the contour, so Cauchy’s integral theorem tells us that the integral of the second partial fraction must vanish and we do not know until reading Section 11.3 how to evaluate the nonzero integral of the ﬁrst partial fraction. 11.4 Cauchy’s Integral Formula 11.4.1. 1 2πi ∮ C(0) zm−n−1dz = { 1 m = n, 0 otherwise, which is δmn by deﬁnition. 11.4.2. 0. CHAPTER 3. EXERCISE SOLUTIONS 128 11.4.3. First, note that ∮ f ′(z) dz z − z0 = 2πif ′(z0) , where the contour surrounds z0. This formula is legitimate since f ′ must be analytic because f is. Now apply Eq. (11.32) to identify f ′(z0) = 1 2πi ∮ f (z) dx (z − z0)2 . 11.4.4. Diﬀerentiating with respect to z0, f (n+1)(z0) = n! 2πi ∫ (n + 1)f (z) (z − z0)n+2 dz is the step from n to n + 1 in a proof by mathematical induction. 11.4.6. The detailed description of the contour is irrelevant; what is important is that it encloses the point z = 0. Using Eq. (11.33), this integral evaluates to 2πi 2! d2 dz2 e iz∣z=0 = −πi . 11.4.7. This integral is a case of Eq. (11.33). We need the second derivative of 2 z − z2, evaluated at z = a; it is 2 cos 2a − 2. Thus, our integral is (2πi/2!)(2 cos 2a − 2) = 2πi(cos 2a − 1). 11.4.8. Make a partial fraction decomposition of the integrand. We have 1 z(2z + 1) = 1 z − 2 2z + 1 = 1 z − 1 z + 1 2 . Both denominators are of the form z − a with a within the unit circle, and the integrals of the partial fractions are cases of Cauchy’s formula with the respective functions f (z) = 1 and f (z) = −1. Therefore the value of the integral is zero. 11.4.9. After the partial fraction decomposition we have ∮ f (z) [ 1 z − 2 2z + 1 − 2 (2z + 1)2 ] dz = ∮ f (z) dz z − ∮ f (z) dz z + 1 2 − ∮ 1 2 f (z) dz (z + 1 2 )2 . Each integral is now a case of Cauchy’s formula (in one case, for a deriva- tive). Termwise evaluation yields 2πif (0) − 2πif (− 1 2 ) − πi f ′(− 1 2 ). CHAPTER 3. EXERCISE SOLUTIONS 129 11.5 Laurent Expansion 11.5.1. The solution is given in the text. 11.5.2. From d dz (1 + z)m∣0 = m(1 + z) m−1|0 = m, d2 dz2 (1 + z) m∣0 = m(m − 1), dν dzν (1 + z) m∣0 = m(m − 1) · · · (m − ν + 1), Taylor’s theorem yields for |z| < 1 (1 + z) m = 1 + mz + m(m − 1) 1 · 2 z2 + · · · = ∞∑ n=0 ( m n ) zn . 11.5.3. ∣ f (z0) z0 ∣ n = ∣ 1 2πi ∫ C1(0) ( f (z) z )n dz (z − z0) ∣ ≤ 1 1 − |z0| implies |f (z0)| ≤ |z0| (1 − |z0|)1/n . For n → ∞ this yields |f (z0)| ≤ |z0|. 11.5.4. znf (z) = ∞∑ ν=0 aνzν is analytic and real for real z. Hence aν are real. 11.5.5. (z − z0) N f (z) is analytic and its power series is unique. 11.5.6. Make the Taylor series expansion of e z and divide by z2: e z z2 = 1 z2 ∞∑ n=0 zn n! = 1 z2 + 1 z + ∞∑ n=0 zn (n + 2)! . 11.5.7. One way to proceed is to write z = (z −1)+1 and e z = e· e z−1. Expanding the exponential, we have e ( 1 + 1 z − 1 ) ∞∑ n=0 (z − 1) n n! = e z − 1 + e ∞∑ n=0 ( n + 2 n + 1 ) (z − 1)n n! . 11.5.8. Expand e 1/z in powers of 1/z, then multiply by z − 1: (z − 1) e 1/z = (z − 1) ∞∑ n=0 z−n n! = z − ∞∑ n=1 ( n n + 1 ) z−n n! . CHAPTER 3. EXERCISE SOLUTIONS 130 11.6 Singularities 11.6.1. Truncating e 1/z ≈ 1 + 1 z + 1 2z2 + 1 6z3 + · · · + 1 n!zn = z0, multiplying this by zn and solving the resulting nth-order polynomial yields n diﬀerent solutions z = zj, j = 1, 2, . . . , n. Then we let n → ∞. 11.6.2. If the branch points at ±1 are linked by a cut line one cannot have a path around them separately, only around both. As a result w(z) remains single-valued. The phases are shown in Example 11.6.4. 11.6.3. f2(z) = f ′ 2(z0)(z − z0) + · · · implies that f1(z)/f2(z) = f1(z)/f ′ 2(z0)(z −z0) −1 +· · · = f1(z0)/f ′ 2(z0)(z −z0) −1 +· · · , where the ellipses stand for some function that is regular at z0. 11.6.4. With the branch cuts of Example 11.6.4 and with √z2 − 1 chosen (as in that example) to be on the branch that gives it positive values for large real, its value at z = i (where the angles shown in Fig. 11.12 are ϕ = 3π/4, θ = π/4 and r1 = r2 = √ 2) is f (i) = (√2 e πi/8)(√2 e 3πi/8) = 2e πi/2 = 2i . For all points in the upper half-plane, both the branch cuts of Exam- ple 11.6.4 and Exercise 11.6.2 will yield the same angle assignments and therefore, once the branches are chosen so f (i) has the same value, the two function deﬁnitions will agree. However, points in the lower half-plane will have diﬀerent angle assignments in the two branch-cut schemes: In Example 11.6.4, both ϕ and θ will have values in the lower half-plane that are both reached by counterclockwise (or both by clockwise) rota- tion. But in Exercise 11.6.2, points in the lower half-plane are reached by counterclockwise rotation in ϕ and clockwise rotation in θ. This changes the sum of the two angles by an amount 2π; half of this (because of the square root) produces a sign change. Thus, the two function deﬁnitions are opposite in sign in the lower half-plane. 11.6.5. The ﬁrst two terms both have fractional powers of z and therefore indicate the existence of a branch point at z = 0. The original value of both terms cannot be recovered simultaneously until the number of circuits around the branch point is the smallest common multiple of 3 and 4, i.e., 12. There is also a third-order pole at z = 3 and a second-order branch point at z = 2. To determine the singularity structure at inﬁnity, replace z by 1/w and check for singularities at w = 0. All three terms exhibit branching at w = 0; since the smallest common multiple of 2, 3, and 4 is 12, the branch point at inﬁnity will be of order 12. CHAPTER 3. EXERCISE SOLUTIONS 131 11.6.6. Write z2 + 1 = (z − i)(z + i) = (r1e iϕ) (r2e iθ) . At z = 0, ϕ = −π/2, θ = π/2, and r1 = r2 = 1. The most general possibility for the argument of z2 + 1 st z = 0 is therefore ϕ + θ + 2nπ = 2nπ. Since we are to be on the branch of ln(z2 + 1) that is −2πi at z = 0, we must take n = −1, and for all points on this branch its argument must be ϕ + θ − 2π. If we now move to z = −2 + i, ϕ becomes −π while θ becomes 3π/4. The argument of z2 + 1 at this point is therefore −π + 3π/4 − 2π = −9π/4. Thus, F (i − 2) = ln |z2 + 1| − 9iπ/4 = ln(4 √2) − 9iπ/4. 11.6.7. The solution is given in the text. 11.6.8. (1 + z) m = e m ln(1+z) = (1 + r2 + 2r cos θ) m/2e im arg(1+z) has a branch point at z = −1. A cut line is drawn from −1 to −∞ along the negative real axis, and |z| < 1 is the convergence region. An additional phase e 2πimn is present for branches other than the standard binomial expansion of Exercise 11.5.2 (n an integer). 11.6.9. The extra phase e 2πimn mentioned in the solution of Exercise 11.6.8 mul- tiplies each coeﬃcient of the Taylor expansion. 11.6.10. (a) f (z) = ∞∑ n=−1(−1)n+1(z − 1) n, 0 < |z − 1| < 1. (b) f (z) = ∞∑ n=−2(−1) n(z − 1) −n, |z − 1| > 1. 11.6.11. (a) This representation of f (z) diverges when ℜ(z) ≤ 0. However, f (z) can be analytically continued to all the remainder of the ﬁnite z-plane except for singularities at z = 0 and all negative integers. (b) f1(z) = ∫ ∞ 0 e −ztdt = − 1 z e −zt∣ ∞=0 = 1 z , provided ℜ(z) > 0. (c) 1 z = 1 z − i + i = 1 i 1 1 − i(z − i) = −i ∞∑ n=0[−i(z − i)] n, |z − i| < 1. 11.7 Calculus of Residues 11.7.1. (a) z0 = ±ia, simple poles a−1 = ± 1 2ai . (b) z0 = ±ia, second-order poles a−1 = ± 1 4a3i . (c) z0 = ±ia, second-order poles CHAPTER 3. EXERCISE SOLUTIONS 132 a−1 = ± 1 4ai . (d) z0 = ±ia, simple poles a−1 = − sinh(1/a) 2a . (e) z0 = ±ia, simple poles a−1 = 1/2e ±a. (f) z0 = ±ai, simple poles a−1 = −i/2e ∓a. (g) z0 = ±a, simple poles a−1 = ± 1 2a e ∓ia. (h) z0 = −1, simple poles a−1 = e −ikπ for z = e iπ. z0 = 0 is a branch point. 11.7.2. Start by making a partial fraction expansion on the integrand: π cot πz z(z + 1) = π cot πz z − π cot πz z + 1 . For the residue at z = 0, note that because cot z is a odd function of z, the ﬁrst term when expanded in powers of z will contain only even powers and therefore has zero residue. Inserting the power series expansion ofz into the second term, we get − π z + 1 ( 1 πz + O(z)) , with residue −1. At z = −1, we use the periodicity of the cotangent to replace cot πz by cot π(z +1), after which we note that if expanded about z = −1 the second term will have only even powers of z + 1 and have zero residue. The ﬁrst term expands to π z ( 1 π(z + 1) + O(z + 1)) , also with residue −1. 11.7.3. Divide the principal-value integral into three parts and combine the last two into a single integral (possible because both involve the same value of): Ei(x) = ∫ −x −∞ e t t dt + ∫ −ε −x e t t dt + ∫ x ε e t t dt = ∫ −x −∞ e t t dt + ∫ x ε e t − e −t t dt . CHAPTER 3. EXERCISE SOLUTIONS 133 In the last member of this equation both the integrals are convergent (the integrand of the second integral has a Taylor series expansion in t). 11.7.4. Break the integral into its two parts and for each part make a binomial expansion of the denominator in a form that will converge for the region of integration: ∫ x −p 1 − x dx = lim ε→0 [∫ 1−ε 0 x−p 1 − x dx + ∫ ∞ 1+ε x −p 1 − x dx ] = lim ε→0 [∫ 1−ε 0 ∞∑ n=0 x n−p dx − ∫ ∞ 1+ε ∞∑ n=0 x −n−p−1 dx ] = lim ε→0 ∞∑ n=0 [ (1 − ε) n−p+1 n − p + 1 − (1 + ε) −n−p−1 n + p ] . Combining terms appropriately and taking the limit, we ﬁnally arrive at ∫ x −p 1 − x dx = − 1 p − ∞∑ n=1 2p p2 − n2 = −π cot p π , where the ﬁnal step is carried out by invoking Eq. (11.81) with pπ substi- tuted for z in that equation. 11.7.5. An attempt to use sin z directly in Eq. (11.88) cannot be carried out because we would need to insert f (0) = 0 into that equation. However, if our function is sin z/z, then we can proceed with f (0) = 1, f ′(0) = 0, and with the zeros of f at nπ (n ̸= 0). 11.7.6. The observations we are starting from are suﬃcient to enable the applica- tion of Rouch´e’s theorem to conclude that every polynomial ∑n =0 amzm has n zeros within the region bounded by some suﬃciently large |R|. 11.7.7. We start by noting that f (z) = z6 + 10 has all its six zeros on a circle about z = 0 of radius 10 1/6, which is between 1 and 2. Next we note that |f (z)| > | − 4z3| for all z within the circle |z| = 2. Therefore F (z) = z6 − 4z3 + 10 has, like f (z), no zeros inside the circle |z| = 1 and six zeros inside |z| = 2, and therefore also outside |z| = 1. 11.7.8. Applying Eq (11.79) to f (z) = sec z, we note that f (0) = 1, and that f (z) has poles at (n + 1 2 )π for all integer n. The residue of f (z) at (n + 1 2 )π is lim z→(n+ 1 2 )π z − (n + 1 2 )π cos z = 1 − sin[(n + 1 2 )π] = (−1) n+1 . Thus, sec z = 1 + ∞∑ n=−∞(−1) n+1 ( 1 z − (n + 1 2 )π + 1 (n + 1 2 )π ) . CHAPTER 3. EXERCISE SOLUTIONS 134 The terms of the summation not containing z can be brought to the form ∞∑ −∞ (−1)n+1 (n + 1 2 )π = − 4 π ( 1 − 1 3 + 1 5 − · · · ) = − 4 π ( π 4 ) = −1 . This cancels the +1 from f (0); the z-containing terms of +n and −n can be combined over a common denominator to obtain the successive terms of the summation in Eq. (11.82). Treating now csc z, it is convenient to consider the expansion of f (z) = csc z − z−1, which is regular at z = 0, with the value f (0) = 0. The function f (z) has poles at z = nπ for all nonzero integers n, with residues (−1) n. The pole expansion of f (z) is therefore f (z) = csc z − 1 z = 0 + ∞∑ n=1(−1) n [( 1 z − nπ + 1 nπ ) + ( 1 z + nπ − 1 nπ )] = ∞∑ n=1(−1) n 2z z2 − (nπ)2 , a result clearly equivalent to Eq. (11.83). 11.7.9. It is clear that the function f has a simple pole at z = 0 and zeros at z = 1 and z = 2. From f = (z2 − 3z + 2)/z = z − 3 + (2/z), we ﬁnd f ′ = 1 − (2/z2) and (making a partial-fraction decomposition) f ′ f = z2 − 2 z(z − 2)(z − 1) = − 1 z + 1 z − 2 + 1 z − 1 . Therefore, the integral of f ′/f on any contour that encloses z = 0 will have from that source a contribution −2πi, while the integral will have contributions 2πi for each of z = 1 and z = 2 that are enclosed. These observations are consistent with the formula ∮ f ′(z)f (z) dz = 2πi(Nf − Pf ) . 11.7.10. Integrating over the upper half circle we obtain ∫ (z − z0) −mdz = ∫ π 0 ireiθdθ rmeimθ = r1−m 1 − m e i(1−m)θ∣ π = r1−m 1 − m [ (−1) 1−m − 1] =  0, m odd, ̸= 1 − 2r1−m 1 − m , m even. For m = 1, i ∫ π 0 dθ = iπ = 1 2 ∫ 2π 0 dθ. CHAPTER 3. EXERCISE SOLUTIONS 135 11.7.11. (a) This follows for δ → 0, Λ → ∞ from ∫ x0−δ −Λ+x0 dx x − x0 + ∫ Λ+x0 x0+δ dx x − x0 = ln(x − x0)∣ x0−δ −Λ+x0 + ln(x − x0) ∣ Λ+x0 x0+δ = ln ( −δ −Λ ) + ln Λ δ = 0 and ∫ x0−δ −Λ+x0 dx (x − x0)3 + ∫ Λ+x0 x0+δ dx (x − x0)3 = − 1 2(x − x0)2 ∣ x0−δ −Λ+x0 − 1 2(x − x0)2 ∣ Λ+x0 x0+δ = − 1 2δ2 + 1 2Λ2 − 1 2Λ2 + 1 2δ2 = 0. (b) ∫ C(x0) dz z − x0 = ∫ π 0 ireiθdθ reiθ = iπ, ∫ C(x0) dz (z − x0)3 = ∫ π 0 ireiθdθ r3e3iθ = − e −2iθ 2r2 ∣ π = 0 . 11.7.12. (a) The integral should not have been designated as a principal value. Irrespective of the sign of s, the integrand will have a pole in the upper half-plane, with a residue that for small ε will approach unity. If s > 0, integrate over the entire real axis and close the contour with a large semicircle in the upper half-plane, where the complex exponential becomes small. The semicircle does not contribute to the integral, and the contour encloses the pole, so our formula for u(s) will be equal to the residue, namely unity. However, if s < 0, close the contour with a semicircle in the lower half-plane, thereby causing the semicircle not to contribute to the integral. But now the pole is not within the contour, so our expression for(s) will evaluate to zero. (b) If s > 0, consider a contour integral that includes the principal-value integral, a large semicircle in the upper half-plane, and a small clockwise semicircle that connects the two pieces of the principal-value integral by passing above the pole at z = 0. This contour encloses no singularities and therefore evaluates to zero. Thus, the principal-value integral will be equal to that over the small semicircle (traversed counterclockwise). The integral over the small semicircle will contribute πi times the (unit) residue at the pole, so u(s) = 1 2 + 1 2πi πi = 1 . If s < 0, we must close the contour in the lower half-plane. If we still connect the pieces of the principal-value integral by a small semicircle CHAPTER 3. EXERCISE SOLUTIONS 136 passing above the pole at z = 0, our contour integral will now encircle (in the negative direction) the pole (with unit residue), and the sum of all the contributions to the principal-value integral will now be πi − 2πi, leading to u(s) = 0. 11.8 Evaluation of Deﬁnite Integrals 11.8.1. This is a case of Example 11.8.1; to make the correspondence exact, bring a factor 1/a outside the integral and note that 1 a ∫ 2π 0 dθ a ± (b/a) cos θ = 2π a√ 1 − b2/a2 = 2π √a2 − b2 . The integral containing the sine instead of the cosine can be regarded as having the same integrand, but for an interval of length 2π ranging from −π/2 to 3π/2. Since the integrand is periodic (with period 2π), this shifted interval yields the same value for the integral.|b| > |a|, there are singularities on the integration path and the integral does not exist. 11.8.2. For the special case b = 1, diﬀerentiate the formula of Exercise 11.8.1 with respect to a. Changing the upper limit of the integral from 2π to π and therefore dividing the result by 2, we have d da ∫ π a dθ a + cos θ = π (a2 − 1)1/2 −→ − ∫ π 0 dθ (a + cos θ)2 = − πa (a2 − 1)3/2 , equivalent to the required result. 11.8.3. For a = 1 + t 2, b = 2t we have 0 ≤ (1 − t)2 = a − b and 1 + t2 − 2t cos θ = a − b cos θ in Exercise 11.8.1 with a2 − b 2 = (1 − t 2) 2. Hence the result. If |t| > 1, then the integral equals 2π/(t 2 − 1). If t = 1 the denominator has a singularity at θ = 0 and 2π; if t = −1 there is a singularity at θ = π. In both these cases the integral does not exist. 11.8.4. Introduce the complex variable z = e iθ; integration from 0 to 2π in θ corresponds in z to a closed counterclockwise contour around the unit circle. Then write cos θ = (z + z−1)/2, cos 3θ = (z3 + z−3)/2, dθ = dz/iz, and ∫ ∞ 0 cos 3θ dθ 5 − 4 cos θ = 1 2 ∮ z3 + z−3 dz iz[5 − 2(z + z−1)] = i 2 ∮ (z6 + 1) dz z3(2z2 − 5z + 2) = i 2 ∮ (z6 + 1) dz z3(z − 2)(2z − 1) . CHAPTER 3. EXERCISE SOLUTIONS 137 The integrand of this contour integral has a pole of order 3 at z = 0 and simple poles at z = 1/2 and z = 2. The poles at 0 and 1/2 are enclosed by the contour. The residue at the pole of order 3 is 1 2! lim z→0 d2 dz2 [ z6 + 1 (z − 2)(2z − 1) ] = 1 2! lim z→0 d2 dz2 [ 1 3(z − 2) − 2 3(2z − 1) ] = 1 2! lim z→0 [ 1 3(z − 2)3 − 8 3(2z − 1)3 ] = 21 8 . In the above analysis we took advantage of the fact that z6 does not get diﬀerentiated enough to permit it to contribute to the residue at z = 0, and we simpliﬁed the diﬀerentiation by ﬁrst making a partial fraction decomposition. The residue at the pole at z = −1/2 is 2−6 + 1 (−2)−3(− 1 2 + 2)2 = − 65 24 , so ∫ ∞ 0 cos 3θ dθ 5 − 4 cos θ = i 2 2πi ( 21 8 − 65 24 ) = π 12 . 11.8.5. 2 ∫ π 0 cos2n θ dθ = ∫ 2π 0 cos2n θ dθ = −i ∮ dz z [ 1 2 (z + 1 z ) ]2n = −2−2ni ∮ dz z2n+1 (z2 + 1) 2n = −2 −2ni ( 2n n ) 2πi = 2π 22n (2n n ) = 2π(2n)! 22nn! 2 = 2π(2n − 1)!! (2n)!! , using (z2 + 1)2n = 2n∑ m=0 (2n n )z2m in conjunction with Cauchy’s integral. 11.8.6. Substituting e ±2πi/3 = − 1 2 ± i√3/2 and solving for I, the result follows immediately. 11.8.7. At large |z|, the integrand of the contour integral of Example 11.8.8 asymp- totically approaches 1/z2−p. Since 0 < p < 1, this power of z is more negative than −1 so the large circle makes no contribution to the integral. At small |z|, the denominator of the integrand approaches unity, so the integrand is basically of the form zp. Writing the integral over the small circle in polar coordinates, it becomes ∫ 0 2π(reiθ) p(ireiθ) dθ, CHAPTER 3. EXERCISE SOLUTIONS 138 which has r dependence rp+1 and vanishes in the limit of small r. To reconcile Eqs. (11.115) and (11.116), multiply Eq. (11.115) through by −πi, reaching after minor rearrangement ( e −pπi − e pπi 2i ) 2i I = 2πi ( e −pπi/2 − e pπi/2 2i ) . The quantities in large parentheses can now be identiﬁed as (minus) the sine functions that appear in Eq. (11.116). 11.8.8. The integral has no singularity at x = 0 because cos bx − cos ax x2 = 1 2 (a 2 − b2) + O(x 2). Next write the integral as shown below, note that its integrand is an even function of x, and break the integral into two parts, in one of which replaceby x and in the other replace ax by x: I = ∫ ∞ −∞ (cos bx − 1) − (cos ax − 1) x2 dx = 2(b − a) ∫ ∞ 0 cos x − 1 x2 dx . Now replace cos x − 1 by −2 sin2(x/2) and continue as follows: I = 4(a − b) ∫ ∞ 0 sin 2(x/2) x2 dx = 2(a − b) ∫ ∞ 0 sin 2 x x2 dx . This integral, which is the topic of Exercise 11.8.9, has value π/2, so I = (a − b)π. 11.8.9. The answer in the text is incorrect; the correct value of the integral in the text is π. The integral has value 2I, where I = ∫ ∞ 0 sin 2 x x2 dx . Integrating by parts,= − sin 2 x x ∣ ∞+∫ ∞ 0 2 sin x cos x x dx = ∫ ∞ 0 sin 2x x dx = ∫ ∞ 0 sin x x dx = π 2 . 11.8.10. Write sin x = (e ix − e −ix)/2i, and write the integral we require as follows: I = ∫ ∞ 0 x sin x x2 + 1 dx = 1 2i ∫ ∞ 0 xe ix x2 + 1 dx − 1 2i ∫ ∞ 0 xe −ix x2 + 1 dx = 1 2i ∫ ∞ 0 xe ix x2 + 1 dx + 1 2i ∫ 0 −∞ (−x)e ix (−x)2 + 1 (−dx) = 1 2i ∫ ∞ −∞ ze iz z2 + 1 dz . CHAPTER 3. EXERCISE SOLUTIONS 139 Figure 11.8.10. Contour encloses pole at z = i. Because the above integral has an integrand that contains a complex ex- ponential and approaches zero for large |z| as z−1, we do not change its value if we close its contour by a large semicircle in the upper half-plane (where the complex exponential becomes negligible). Thus, we consider I = 1 2i ∮ ze iz z2 + 1 dz , where the contour is that of Fig. 11.8.10 of this manual. The integrand has two poles, at z = i and z = −i, both of ﬁrst order, but only the pole at z = i lies within the contour. Writing z2 + 1 = (z + i)(z − i), we identify the residue at z = i as ie i(i)/2i = 1/2e. Therefore, I = 1 2i (2πi) 1 2e = π 2e . 11.8.11. Using ∫ ω 0 sin xt dx = − cos xt t ∣ ω we integrate by parts: ∫ ∞ −∞ 1 − cos ωt ω2 dω = − 1 − cos ωt ω ∣ ∞ + t ∫ ∞ −∞ sin ωt ω dω = t ∫ ∞ −∞ sin ω ω dω = πt . Note that the integrated term vanishes. 11.8.12. (a) Using cos x = (e ix + e −ix)/2 we integrate e ix along the real axis and over a half circle in the upper half-plane and e −ix over a half circle in the lower half-plane getting, by the residue theorem, 1 2πi ∫ u.h.c. e iz z2 + a2 dz = e −a 2ia , ∫ ∞ −∞ e −ix x2 + a2 dx = π a e −a, CHAPTER 3. EXERCISE SOLUTIONS 140 and 1 2πi ∫ l.h.c. e iz z2 + a2 dz = − e −a (−2ia) , ∫ ∞ −∞ e −ix x2 + a2 dx = π a e −a. Combining the above, we obtain the answer in the text. For cos kx we rescale: ∫ ∞ −∞ cos kx x2 + a2 dx = k ∫ ∞ −∞ cos x dx x2 + k2a2 . (b) This result is obtained similarly. 11.8.13. Because the integrand is even, change the lower limit of the integral to= 0 and multiply the result by 2. Then substitute sin x = (e ix −e −ix)/2i and rearrange to a principal-value integral: ∫ ∞ −∞ sin x x dx = ∫ ∞ 0+ e ix dx ix + ∫ ∞ 0+ e −ix dx ix = ∫ ∞ 0+ e ix dx ix + ∫ 0− −∞ e ix dx ix = 1 i ∫ ∞ e ix dx x . Consider now the integral of e iz/z over the contour of Fig. 11.28. The small semicircle passes above the pole at z = 0, at which the residue is unity. Thus, the contour encloses no singularities, so the contour integral vanishes. Since the closure of the integral in the upper half-plane makes no contribution, the principal-value integral (along the real axis) plus the contribution from the small clockwise semicircle (namely, −πi) must add to zero. Thus, 1 i ∫ ∞ e ix dx x = 1 i πi = π. 11.8.14. For p > 1 we integrate over the real axis from −R to R and a half circle in the upper plane, where e −pℑt| sin t| → 0 for R → ∞ and the integral over the half circle vanishes. Since there are no singularities, the residue theorem gives zero for the loop integral. Thus ∫ ∞ −∞ sin t t e iptdt = 0. For 0 < p < 1 we use e ipt = cos pt + i sin pt and notice that the integral over the imaginary part vanishes as sin(−pt) = − sin pt. Finally, we use 2 sin t cos pt = sin(1 + p)t + sin(1 − p)t. Each integral including sin(1 ± p)t yields π. 11.8.15. Diﬀerentiating ∫ ∞ 0 dx a2 + x2 = 1 a arctan x a ∣ ∞ = π 2a we get d da ∫ ∞ 0 dx a2 + x2 = ∫ ∞ 0 (−2a)dx (a2 + x2)2 = − π 2a2 , equivalent to the answer in the text. CHAPTER 3. EXERCISE SOLUTIONS 141 Figure 11.8.17. Contour surrounds branch cut and two poles. 11.8.16. We factor 1 + x 4 = (x 2 − i)(x 2 + i) and use the partial fraction expansion x 2 1 + x4 = 1 2 ( 1 x2 − i + 1 x2 + i ) . Applying Exercise 11.8.15 for each term with a = e ±π/4 we obtain for the integral 2π 4 ( e −iπ/4 + e iπ/4) = π cos π 4 = π √2 . 11.8.17. We approach this problem by considering the integral ∮ zp ln z z2 + 1 dz on an appropriate contour. The integrand has a branch point at the origin and we choose a contour of the form shown in Fig. 11.8.17 of this manual, corresponding to making the branch cut along the positive real axis andθ = 0 as the argument of points on the real axis just above the cut. Points on the positive real axis just below the cut will therefore have argument 2π. The contour consists of four pieces: (1) A line from 0+ to inﬁnity above the cut; the integral on this line is equal to the integral we wish to evaluate: I = ∫ ∞ 0 x p ln x x2 + 1 dx . (2) A 360 ◦ counterclockwise arc at large |z| to reach x = +∞ just below the cut (this makes no contribution to the integral); (3) A line from x = +∞ to x = 0+ below the cut, whose contribution to the contour integral will be discussed shortly, and (4) A clockwise 360◦ arc at small |z| to close the contour (this also make no contribution because limz→0 zp ln z = 0). On the line below the cut, zp = (xe 2πi) p = x pe 2πip, and ln z = ln x + 2πi. CHAPTER 3. EXERCISE SOLUTIONS 142 Taking these observations into account, ∫ 0+ ∞−εi zp ln z z2 + 1 dz = − ∫ ∞ 0 xpe 2πip[ln(x) + 2πi] x2 + 1 dx = −e 2πipI − 2πie 2πip ∫ ∞ 0 xp x2 + 1 dx . The integral on the last line was the topic of Example 11.8.8, where it was shown to have the value π/2 cos(pπ/2). Putting all this information together, we have ∮ zp ln z z2 + 1 dz = I − e 2πipI − iπ2e 2πip cos(pπ/2) , We now evaluate the contour integral using the residue theorem. The integrand has ﬁrst-order poles at i = e πi/2 and −i = e 3πi/2, and we must use these representations to obtain the correct arguments for the pole locations. Both poles lie within the contour; the residues are Residue (z = i) = e πip/2(πi/2) 2i , Residue (z = −i) = e 3πip/2(3πi/2) −2i . Setting the contour integral to its value from the residue theorem, I (1 − e 2πip) − iπ2e 2πip cos(pπ/2) = iπ2 2 ( e πip/2 − 3e 3πip/2) . Multiplying through by e −πip and rearranging slightly, I sin pπ = π2 4 ( 3e πip/2 − e −πip/2 − 2 e πip cos(pπ/2) ) . Writing all the complex exponentials in the above equation as trigonomet- ric functions and using identities to make all the trigonometric functions have argument pπ/2, the above equation reduces to 2I sin(pπ/2) cos(pπ/2) = π2 4 ( 2 sin 2(pπ/2) cos(pπ/2) ) , or I = π2 sin(pπ/2) 4 cos2(pπ/2) . 11.8.18. (a) See solution of Exercise 12.4.3. (b) It is useful to form the integral IC = ∮ ln 3 z 1 + z2 dz over the contour of Fig. 11.8.17 of this Manual. The integrand has a branch point at z = 0 and we are making a cut along the positive real CHAPTER 3. EXERCISE SOLUTIONS 143 axis. It also has simple poles at z = i = e iπ/2 and at z = −i = e 3iπ/2; we must use these exponential forms when computing the residues at the two poles. The small and large arcs of the contour do not contribute to the integral; for the segment from x = 0+ to inﬁnity aboe the branch cut ln 3 z can be represented as ln3 x; for the segment from inﬁnity to x = 0+ we must write ln3 z = (ln x + 2πi) 3. Keeping in mind that ln i = πi/2 and that ln(−i) = 3πi/2, we note that the residue of the integrand at z = i is (πi/2) 3/2i and that the residue at z = −i is (3πi/2)3/(−2i). Now we writeC = ∫ ∞ 0 ln 3 x 1 + x2 dx− ∫ ∞ 0 (ln x + 2πi) 3 1 + x2 dx = 2πi ( πi 2 )3 ( 1 − 33 2i ) = 13iπ4 4 . Expanding the left-hand side of the above equation, −6πi ∫ ∞ 0 ln 2 x 1 + x2 dx + 12π2 ∫ ∞ 0 ln x 1 + x2 dx + 8π3i ∫ ∞ 0 dx 1 + x2 = 13iπ4 4 . Our present interest is in the imaginary part of this equation, which is −6π ∫ ∞ 0 ln 2 x 1 + x2 dx + 8π3 ∫ ∞ 0 dx 1 + x2 = 13π4 4 . The ﬁrst of the two integrals on the left-hand side is that whose value we seek; the second is an elementary integral with value π/2. The equation therefore reduces to ∫ ∞ 0 ln 2 x 1 + x2 dx = −8π3(π/2) + 13π4/4 −6π = π3 8 . 11.8.19. Use the symmetry of the integrand to extend the integral from −∞ to ∞, and write the logarithm as a sum of two terms: I = ∫ ∞ 0 ln(1 + x 2) 1 + x2 dx = 1 2 [∫ ∞ −∞ ln(x + i) x2 + 1 dx + ∫ ∞ −∞ ln(x − i) x2 + 1 dx] . The ﬁrst integrand has a branch point at x = −i and its integral can be evaluated by the residue theorem using a contour that is closed in the upper half-plane (causing the branch point to lie outside the contour). The second integrand has a branch point at x = i and its integral can be evaluated using a contour that is closed in the lower half-plane. We must choose branches for the logarithms that are consistent with their sum being real; a simple way to do this is to assign branches in a way such that the arguments of both x − i and x + i approach zero at large positive x. CHAPTER 3. EXERCISE SOLUTIONS 144 The contour for the ﬁrst integral encloses a ﬁrst-order pole at z = i; the residue there is ln(2i)/2i, with the logarithm on the branch such that ln i = πi/2. The residue therefore evaluates to (ln 2)/2i + π/4. The contour for the second integral encloses a ﬁrst-order pole at z = −i, with residue ln(−2i)/(−2i), with the logarithm on the branch such that ln(−i) = −πi/2. This residue is therefore −(ln 2)/2i + π/4. Noting that the contour for the second integral circles the pole in the clockwise (math- ematically negative) direction, application of the residue theorem leads I = 1 2 2πi ( ln 2 2i + π 4 + ln 2 2i − π 4 ) = π ln 2 . 11.8.20. Use the contour of Fig. 11.26. The small and large circles do not contribute to the integral; the path element A evaluates to I, our integral, while the path element B contributes −e 2πiaI. The contour encloses a second-order pole at z = −1, at which the residue is d dz za∣z=−1 = a (e iπ(a−1)) = −ae iπa . Therefore, ( 1 − e 2πia) I = 2πi ( −ae iπa) , or e −πia − e πia = −2πia , or I sin πa = πa, equivalent to the result we are to prove. 11.8.21. Start by ﬁnding the zeros of the denominator: z2 = cos 2θ ± √cos22θ − 1 = e ±2iθ . From this we ﬁnd z = ±e ±iθ. Thus the integrand has (for most values of θ) four ﬁrst-order poles, two in the upper half-plane and two in the lower half-plane. For simplicity we consider only the case that e iθ and −e −iθ are distinct and in the upper half-plane, and we take a contour that includes the real axis and a large semicircle in the upper half-plane. The large semicircle does not contribute to the integral. Writing our integral in the I = ∮ z2 dz (z − eiθ)(z + e−iθ)(z + eiθ)(z − e−iθ) , application of the residue theorem yields= 2πi [ e 2iθ (eiθ + e−iθ)(2eiθ)(eiθ − e−iθ) + e −2iθ (−e−iθ − eiθ)(−e−iθ + eiθ)(−2e−iθ) ] = 2πi [ e iθ 8i sin θ cos θ + e −iθ 8i sin θ cos θ ] = π 2 sin θ . CHAPTER 3. EXERCISE SOLUTIONS 145 Figure 11.8.22. Sector contour. 11.8.22. If L denotes the triangular path of Fig. 11.8.22 of this manual with the angle θ set to 2π/n, we ﬁnd for R → ∞, IL = ∮ L dz 1 + zn = (1 − e 2πi/n) ∫ ∞ 0 dx 1 + xn . The contour encloses a simple pole at z0 = e πi/n; we can ﬁnd the residue there as the limit Residue = lim z→z0 z − z0 1 + zn . Using l’Hˆopital’s rule to evaluate the limit, we ﬁnd the residue to be 1−n 0 /n, or, since z−n 0 = −1, the residue is e iπ/n/n. Thus, IL = (1 − e 2πi/n) ∫ ∞ 0 dx 1 + xn = 2πie iπ/n n , which rearranges to ∫ ∞ 0 dx 1 + xn = π n 2i e iπ/n (1 − e2πi/n) = π n sin(π/n) . 11.8.23. This problem is similar to Exercise 11.8.21 except for the absence of thex2 in the numerator of the integrand. This change causes the last line of the solution of Exercise 11.8.21 to be changed to I = 2πi [ e −iθ 8i sin θ cos θ + e iθ 8i sin θ cos θ ] = π 2 sin θ , which is the same answer as that found for Exercise 11.8.21. 11.8.24. Use the contour in Fig. 11.8.17 of this manual. Letting I be the integral we want, path element A contributes I to the contour integral, while path CHAPTER 3. EXERCISE SOLUTIONS 146 Figure 11.8.25. Lower line is on real axis; upper line is at y = π. element B contributes −e −2πiaI to the contour integral. The value of the contour integral is 2πi times the residue of the integrand at z = −1 = e πi, which is e −πia. Therefore, I ( 1 − e −2πia) = 2πie −πia , which rearranges to I = π/ sin πa. 11.8.25. Write cosh bx = (e bx + e −bx)/2, so I = ∫ ∞ 0 cosh bx cosh x dx = 1 2 ∫ ∞ 0 e bx cosh x dx + 1 2 ∫ ∞ 0 e −bx cosh x dx = 1 2 ∫ ∞ −∞ e bx cosh x dx . Evaluate this integral by considering it on a contour that takes account of the periodicity of cosh z (it has period 2π in the imaginary direction). Take the contour to be that shown in Fig. 11.8.25 of this manual. This contour consists of four line segments: (1) From −R to R along the real axis, in the limit of large R; the integral of this segment is I; (2) From R to R + iπ; this segment makes no contribution to the integral; (3) From R + iπ to −R + iπ on a line parallel to the real axis; the travel is toward negative x but the denominator is cosh(x + iπ) = − cosh x, and (noting that the numerator is e b(x+πi)) this segment evaluates to +Ie ibπ; (4) From −R+iπ to −R; the integral on this segment is zero. Combining the above, 1 2 ∮ e bz cosh z dz = I ( 1 + e ibπ) . We now evaluate the contour integral using the residue theorem. The integrand has poles at the zeros of cosh z; the only pole within the contour is at z = πi/2, with residue (evaluated by l’Hˆopital’s rule) lim z→πi/2 (z − πi/2)e bz cosh z = e ibπ/2 sinh(πi/2) = −ie ibπ/2 . We therefore have I ( 1 + e ibπ) = 1 2 (2πi) ( −ie ibπ/2) . CHAPTER 3. EXERCISE SOLUTIONS 147 Figure 11.8.27. Contours for Exercise 11.8.27. Solving for I, I = πeibπ/2 1 + eibπ = π 2 cos(πb/2) . 11.8.26. Consider the integral ∮ e −z2 dz on the sector contour in Fig. 11.8.22 of this manual, with θ set to π/4 (45◦). This contour encloses no singularities, and the arc at inﬁnity does not contribute to the integral. We therefore have ∮ e −z2 dz = ∫ ∞ 0 e −x 2 dx − ∫ ∞ 0 e −ir2e iπ/4 dr = 0 . The x integration evaluates to √π/2, and we can write the integrand of the last integral in terms of its real and imaginary parts: √π 2 − ∫ ∞ 0 [ cos r2 − i sin r2] 1 + i √2 dr = 0 . Letting Ic and Is respectively stand for ∫ ∞ 0 cos2 r dr and ∫ ∞ 0 sin 2 r dr, the real and imaginary parts of the above equation take the forms √π 2 − Ic√2 − Is√2 = 0, Ic√2 − Is√2 = 0, from which we deduce Ic = Is and √π/2 = 2Ic/ √2, which reduce to the stated answers. 11.8.27. Consider ∮ dz z2/3(1 − z)1/3 , with the contour the two closed curves shown in Fig. 11.8.27 of this man- ual. Note that together these curves enclose a region in which the inte- grand is analytic, so the line integrals on the two curves are equal and CHAPTER 3. EXERCISE SOLUTIONS 148 opposite. We pick a branch of the integrand which is real and positive above the branch cut, so the integral on the straight line above the cut from 0 to 1 is the integral we seek, I = ∫ 1 0 dx (x2 − x3)1/3 . The small circular arcs around z = 0 and z = 1 do not contribute to the integral; in polar coordinates about these respective points the singular factors are of order r−2/3 and r−1/3, while dz = ire iθ dθ. On the straight line from 1 to 0 below the branch cut, we still have z2/3 = x 2/3, but instead of (1 − x) 1/3 we have e −2πi/3(1 − x) 1/3, the minus sign in the exponent arising because the branch point at z = 1 was circled clockwise. On this line below the cut, the integrand is therefore e 2πi/3/(x2 − x3) 1/3, and this segment of the integral can be identiﬁed as −e 2πi/3I (the new minus sign because the integration is toward negative x). On the large circle the integrand becomes 1/(−1) 1/3z, and we must select the proper branch for (−1) 1/3. To do so, note that at large real positive z, z2/3 remains x2/3, but (1 − x) 1/3 becomes |1 − x|1/3e −πi/3, so the entire integrand asymptotically becomes 1/e −πi/3z. Since the integral of 1/z around any circle (counterclockwise) is 2πi, our integral over the large circle will have the value 2πi eπi/3. Combining the above, ∮ dz z2/3(1 − z)1/3 = I − e 2πi/3I + 2πie πi/3 = 0 , which we can solve for I to obtain I = −2πie πi/3 1 − e2πi/3 = π sin(πi/3) = 2π √3 . 11.8.28. The key to this problem is the evaluation of the diﬀerence between the values of tan −1 az on the two sides of its branch cut in the upper half- plane. Referring to Fig. 11.8.28a of this manual and Eq. (1.137), deﬁne1 = |z − a −1i|, r2 = |z + a −1i|, θ1 = arg(z − a−1i), θ2 = arg(z + a −1i), write tan −1 az = 1 2i [ ln r1 + iθ1 − ln r2 − iθ2 + πi ] , and note that for z just to the right of the cut in the upper half-plane the values of θ1 and θ2 are both +π/2, while for a corresponding value of z just to the left of the cut θ1 = −3π/2 and θ2 remains +π/2. We therefore see that tan −1 az(left of cut) − tan −1 az(right of cut) = −π . We are now ready to evaluate the integral ∮ tan −1 az z(z2 + b2) dz CHAPTER 3. EXERCISE SOLUTIONS 149 Figure 11.8.28a. Arguments and moduli of singular factors. for the contour of Fig. 11.8.28b of this manual. The small arc around the branch point at a −1 and the large arcs at inﬁnity do not contribute to the integral; the line along the real axis evaluates to I, the integral we seek. Writing z = iy on segments B and B′ of the contour, and combining these segments so that the diﬀerence of the arctangents can be replaced by −π, we reach ∮ tan −1 az z(z2 + b2) dz = I − π ∫ ∞ a−1 i dy iy(b2 − y2) = I − π 2b2 ln(1 − a2b 2) , where we have evaluated the y integral, which is elementary. The contour integral encloses a region in which the integrand is analytic everywhere except for a ﬁrst-order pole at z = ib, at which its residue is 1 ib(2ib) 1 2i ln ( 1 + i(iab) 1 − i(iab) ) = i 4b2 ln ( 1 − ab 1 + ab ) . Finally, from I − π 2b2 ln(1 − a 2b 2) = 2πi i 4b2 ln ( 1 − ab 1 + ab ) we solve for I, getting the relatively simple result I = (π/b2) ln(1 + ab). There is no singularity at z = 0 because for small z, tan −1 az ≈ az. 11.9 Evaluation of Sums 11.9.1. Here g(z) has, about z0, the Laurent expansion b0(z − z0) −1 + c0 + c1(z − z0) + · · · , while f (z) has a Taylor series f (z0) + f ′(z0)(z − z0) + · · · . Mul- tiplying these expansions, the only term singular at z = z0 is b0f (z0)(z − z0) −1, which corresponds to a simple pole with residue b0f (z0). CHAPTER 3. EXERCISE SOLUTIONS 150 Figure 11.8.28b. Contour avoiding branch cut. 11.9.2. The limiting behavior for IN that is needed for the contour-integral eval- uation of sums is produced by the behavior of f (z) for large |z|, which in applicable cases becomes small rapidly enough that the integrand of IN becomes negligible on its entire contour and therefore evaluates to zero. To see that cot πz remains of order of magnitude unity for large |z| and does not aﬀect this analysis, write it in terms of exponentials: | cot πz| = ∣ e iz + e −iz eiz − e−iz ∣ . Because each of these exponentials occurs in both the numerator and denominator, this expression will remain of order unity except where the denominator approaches zero (i.e., near the poles of cot πz). 11.9.3. Deﬁning S = 1 13 − 1 33 + 1 53 − · · · , note that 1 8 ∞∑ n=−∞ (−1) n (n + 1 2 )3 = 2S . Therefore 2S = 1 8 ∑ (residue of z−3π sec πz at z = 0) . This residue is 1 2! d2 dz2 π sec πz∣z=0 = π3 2 , and S = 1 16 π3 2 = π3 32 . 11.9.4. This summation is most easily done by decomposing the summand into partial fractions: S = ∞∑ n=1 1 n(n + 2) = 1 2 ∞∑ n=1 ( 1 n − 1 n + 2 ) = 1 2 ( 1 + 1 2 ) = 3 4 . CHAPTER 3. EXERCISE SOLUTIONS 151 If it is desired to use the contour-integral method for this summation, consider (for nonzero a) S(a) = ∞∑ n=1 1 (n + a)(n + a + 2) , S(−a) = ∞∑ n=1 1 (n − a)(n − a + 2) = −3∑ n=−∞ 1 (n + a)(n + a + 2) , ∞∑ n=−∞ 1 (n + a)(n + a + 2) = S(a) + S(−a) + 1 (−2 + a)a + 1 (−1 + a)(1 + a) + 1 a(a + 2) . The summation in the last of the above equations can now be evaluated as minus the sum of the residues of π cot πz/[(z + a)(z + a + 2)] at z = −a and z = −a − 2. These residues are respectively π cot(−πa)/2 and π cot(−πa − 2π)/(−2). Invoking the periodicity of the cotangent, these are seen to add to zero. Finally, setting the right-hand side of the last above equation to zero and then taking the limit a → 0, we ﬁnd 2S − 1 + lim a→0 1 a [ 1 a − 2 + 1 a + 2 ] = 2S − 3 2 = 0, or S = 3 4 . 11.9.5. Our summation S is minus the residue of π csc πz at z = −a. This residue is π d dz csc πz∣ −a = − π2 cos(−πa) sin 2(−πa) , so S = π2 cos πa sin 2 πa . 11.9.6. (a) Note that our summation S is 1/2 times the result of extending the indicated summation to −∞. Writing S = 1 8 ∞∑ −∞ 1 (n + 1 2 )2 = 1 8 ( residue of π tan πz z2 at z = 0) . This residue is π2 cos2 πz ∣ z=0 = π2, so S = π2 8 . (b) Write S = ∞∑ n=1 1 n2 − ∞∑ n=1 1 (2n)2 = ζ(2) − 1 4 ζ(2) = 3 4 ζ(2) = 3 4 π2 6 = π2 8 . 11.9.7. The summation is of the form S = ∞∑ n=0 (−1) n 2n + 1 1 cosh(n + 1 2 )π = 1 2 ∞∑ −∞ (−1)n 2n + 1 1 cosh(n + 1 2 )π . CHAPTER 3. EXERCISE SOLUTIONS 152 Thus, 2S = ∑ ( residues of π sec πz 2z cosh πz at the singularities of 1 2z cosh πz ) . These singularities occur at z = 0 and and zn = (n + 1 2 )i, for all integer n from −∞ to ∞. The residue at z = 0 is π/2. The residues at z = zn can be calculated using l’Hˆopital’s rule: residue at zn = lim z→zn π(z − zn) 2z cos πz cosh πz = π 2πzn cos πzn sinh πzn = 1 (2n + 1)i cos[(n + 1 2 )πi][i(−1)n] = − (−1)n (2n + 1) cosh(n + 1 2 )π . When these residues are summed over n, the result is −2S, so we ﬁnally reach 2S = −2S + π 2 , or S = π 8 . 11.9.8. The summand of our sum S is even, so ∞∑ n=−∞ ′ (−1) n sin nϕ n3 = 2S, where the prime indicates omission of the term n = 0. Therefore, since sin ϕz/z3 has only a pole at z = 0, 2S = −(residue of π csc πz sin ϕz/z3 at z = 0). The pole at z = 0 is of third order, so the residue we seek is lim z→0 π 2! d2 dz2 ( sin ϕz sin πz ) = π 2 lim z→0 [ (π2 − ϕ2) sin ϕz sin πz + 2π cos πz sin 3 πz (π sin ϕz cos πz − ϕ cos ϕz sin πz) ] = ϕ(π2 − ϕ 2) 6 . From this result we get S = ϕ 12 (ϕ2 − π2) . 11.10 Miscellaneous Topics 11.10.1. f ∗(z∗) = f (z) is equivalent to u(x, −y) − iv(x, −y) = u(x, y) + iv(x, y) , which in turn impliesu(x, −y) = u(x, y) and (b) v(x, −y) = −v(x, y). CHAPTER 3. EXERCISE SOLUTIONS 153 11.10.2. Given that f (z) = ∑ n anzn, with an real, then f (z∗) = ∑ n an(z∗) n = [∑ n anzn]∗ . (a) If f (z) = zn, then f (z∗) = (z∗) n = (zn) ∗, as predicted. (b) If f (z) = sin z = ∞∑ n=0 zn (2n + 1)! , then f (z∗) = [f (z)] ∗. But if f (z) = iz, then f (z∗) = iz∗ while [f (z)] ∗ = −iz∗. 11.10.3. (a) f ∗(x) = −f (x) implies (if (x)) ∗ = −i(−f (x)) = if (x), i.e., that if (x) is real and its power series expansion will have real coeﬃcients an. Thus, if (z) meets the conditions of Exercise 11.10.2, so (if (z)) ∗ = if (z∗) and therefore also f ∗(z) = −f (z∗). (b) f (z) = iz = ix − y, f (z∗) = iz∗ = ix + y, and f ∗(z) = (iz) ∗ = −i(x − iy) = −ix − y. 11.10.4. |z| 2 = r2 = x 2 + y2 . (a) w1(z) = z + 1 z yields w1 = u1 + iv1 = z + 1 z = x + iy + x − iy x2 + y2 = x (1 + 1 r2 ) + iy ( 1 − 1 r2 ) . Parameterizing the circle as x = r cos θ, y = r sin θ we obtain u1 = r cos θ ( 1 + 1 r2 ) , v1 = r sin θ ( 1 − 1 r2 ) . For r ̸= 1, u2 r2 (1 + 1 r2 )2 + v2 1 r2 ( 1 − 1 r2 )2 are ellipses centered at the origin. For r → 1, v1 → 0, the ellipses ﬂatten to the u1−axis. (b) This map leads to z − 1 z = x ( 1 − 1 r2 ) + iy ( 1 + 1 r2 ) = u2 + iv2. The curves u2 = r (1 − 1 r2 ) cos θ, v2 = r ( 1 + 1 r2 ) sin θ are ellipses for r ̸= 1 and ﬂatten to the v2-axis for r → 1 because u2 → 0. CHAPTER 3. EXERCISE SOLUTIONS 154 11.10.5. (a) x > 0. (b) y > 0. 11.10.6. (a) From 1/z = (x − iy)/(x 2 + y2), or u = x/(x 2 + y2) , v = −y/(x2 + y2) , we obtain x = u/(u2 + v2) , y = −v/(u2 + v2) . Substituting these expressions into the equation (x−a) 2 +(y−b) 2 −r2 = 0, we initially have ( u u2 + v2 − a)2 + ( −v u2 + v2 − b)2 − r2 = 0 . Expanding this expression, clearing the denominators by multiplying through by (u2 + v2) 2, cancelling common factors, and completing the squares on the terms involving u and those involving v, we ultimately reach (u − A) 2 + (v − B) 2 = R2, with A = −a r2 − a2 − b2 , B = b r2 − a2 − b2 , R = r r2 − a2 − b2 . (b) The transformation produced a circle whose center is at A + iB. The center before transformation was at a + ib. The transformation of a + ib is to (a − ib)/(a2 + b 2), which is not at A + iB. 11.10.7. If two curves in the z plane pass through a point z0, one in the direction dz1 = e iθ1ds and the other in the direction dz2 = e iθ2 ds, the angle from the ﬁrst curve to the second will be θ2 − θ1. If these curves are mapped into the w plane, with w = f (z), then dw1 = f ′(z0)e iθ1 ds and dw2 = f ′(z0)e iθ2ds . Writing f ′(z0) in polar form as |f ′(z0)|e iϕ, we see that dw1 = |f ′(z0)|e i(θ1+ϕ)ds, dw2 = |f ′(z0)|e i(θ2+ϕ)ds , and, because f ′(z0) was assumed nonzero, the angle from the ﬁrst curve to the second in the w plane will also be θ2 − θ1. That is why mappings by an analytic function are termed conformal. CHAPTER 3. EXERCISE SOLUTIONS 155 12. Further Topics in Analysis 12.1 Orthogonal Polynomials 12.1.1. We express the derivative in the Rodrigues formula for Hn as a contour integral, and then form the sum g(x, t) = Hn(x)tn/n!, g(x, t) = ∞∑ n=0 Hn(x)t n n! = ∞∑ n=0(−1) ne x2 n! 2πi ∮ e −z2 (z − x)n+1 tn n! dz . The contour must enclose the point z = x; there are no other singular- ities at ﬁnite z to be avoided. Next we interchange the summation and integration and evaluate the sum, which is ∞∑ n=0 (−1) ntn (z − x)n+1 = 1 z − x + t . Inserting this result, g(x, t) = e x 2 2πi ∮ e −z2 dz z − x + t = e x2 e −(x−t)2 = e −t 2+2xt . 12.1.2. (a) Since the Laguerre ODE has the form xy′′ + (1 − x)y + ny = 0, we calculate the weight function w as w = 1 x exp [∫ x 1 − t t dt] = e −x . Then form Ln(x) = constant · 1 w ( d dx )n (x n w) = constant · e x ( d dx )n (x n e −x) . The constant is assiged the value 1/n! to produce the Laguerre polynomi- als at the conventional scaling. (b) We obtain the generating function by using a contour integral to rep- resent the diﬀerentiation in the Rodrigues formula: g(x, t) = ∞∑ n=0 Ln(x)t n = ∞∑ n=0 e x n! n! 2πi ∮ zne −ztn (z − x)n+1 dz . The contour must enclose the point z = x; there are no other ﬁnite singu- larities. We now interchange the summation and integration and evaluate the sum: ∞∑ n=0 (zt) n (z − x)n+1 = 1 z(1 − t) − x . Then we have g(x, t) = e x 2πi ∮ e −z dz z(1 − t) − x = e x 1 − t e −x/(1−t) = e −tx/(1−t) 1 − t . CHAPTER 3. EXERCISE SOLUTIONS 156 12.1.3. The three terms on the left-hand side of Eq. (12.11) respectively corre- spond to (1) Applying all n + 1 diﬀerentiations to wpn, (2) Applying n diﬀerentiations to wpn and one to p, and (3) Note that n−1 diﬀerentiations of wp n and two of p; the two right-hand terms respectively correspond to (i) all n + 1 diﬀerentiations to wpn, and (ii) n diﬀerentiations of wp n and one of (n − 1)p′ + q. To reach Eq. (12.12), we combined or canceled similar terms and insertedn from Eq. (12.9) in the term involving n-fold diﬀerentiation of wpn. Note that we are not assuming that yn is a solution to our ODE; at this point we treat it solely as a deﬁned quantity. 12.1.4. The unnumbered identity following Eq. (12.12) is conﬁrmed by regarding its left-hand side as involving a two-fold diﬀerentiation of the nth deriva- tive of wpn. Equation (12.13) is obtained by recognizing yn and using Eq. (12.6) to evaluate the derivatives of w−1. Equation (12.15) can be interpreted as involving a single diﬀerentiation of the n-fold derivative of wpn. 12.1.5. Using the Cauchy integral for the power series for the generating functions yields the results. 12.1.6. The solution is given in the text. 12.1.7. Diﬀerentiate the generating-function formula with respect to t: 2x − 2t (1 − 2xt + t2)2 = ∞∑ n=0 nUn(x)tn−1 . Multiply both sides of this equation by 1 − 2xt + t 2, then identify the left-hand side as 2x − 2t times the generating-function expansion. The resulting equation has the form 2x ∞∑ n=0 Un(x)tn − 2 ∞∑ n=0 Un(x)tn+1 = ∞∑ n=0 nUn(x)tn−1 − 2x ∞∑ n=0 nUn(x)tn + ∞∑ n=0 nUn(x)t n+1 . Combining similar terms and collecting the coeﬃcient of each power of t, we ﬁnd Un−1(x) − 2xUn(x) + Un+1(x) = 0 . CHAPTER 3. EXERCISE SOLUTIONS 157 12.2 Bernoulli Numbers 12.2.1. Eq. (12.32): Multiply numerator and denominator of the fraction on the right-hand side by e t and then put both right-hand terms over a common denominator. Eq. (12.46): Multiply numerator and denominator of the right-hand side by e t. 12.2.2. Using the power series for x ex − 1 e xs we get ∞∑ n=0 Bn(s) x n n! = (1 − x 2 ) ( 1 + xs + x 2s 2 2 + · · · ) + ∞∑ n=1 B2n x 2n (2n)! ( 1 + xs + x 2s 2 2 + · · · ) = 1 + ( xs − x 2 ) + 1 2 x 2 ( s 2 − s + 1 6 ) + · · · . Reading oﬀ coeﬃcients of xn/n! we ﬁnd B0(s) = 1, B1(s) = s − 1 2 , B2(s) = s 2 − s + 1 6 , etc. 12.2.3. Checking ﬁrst the identity we then use it to get from the power series x tan x = x cot x − 2x cot 2x = ∞∑ n=0(−1) nB2n (2x) 2n (2n)! ( 1 − 22n) . 12.3 Euler-Maclaurin Integration Formula 12.3.1. (a) n∑ m=1 m = ∫ n 0 mdm + ∫ n 0 (x − [x])dx = 1 2 n2 + n−1∑ m=0 ∫ m+1 m ( x − [x]) dx = 1 2 n2 + 1 2 n = 1 2 n(n + 1), because ∫ m+1 m (x − m) dx = ∫ 1 0 y dy = 1 2 . (b) n∑ m=1 m2 = ∫ n 0 m 2 dm + 2 n−1∑ m=0 ∫ m+1 m (x − m)x dx CHAPTER 3. EXERCISE SOLUTIONS 158 = 1 3 n3 + 2 n−1∑ m=0 ∫ m+1 m [ (x − m) 2 + m(x − m) ] dx = 1 3 n3 + 2 n−1∑ m=0 [∫ 1 0 y2 dy + m ∫ 1 0 y dy] = 1 3 n3 + 2 3 n + 1 2 n(n − 1) = 1 6 n(n + 1)(2n + 1). (c) Omitting steps but working as before we obtain n∑ m=1 m3 = ∫ n 0 m 3 dm + 3 ∫ n 0 ( x − [x]) x 2 dx = 1 4 n4 + 3 n−1∑ m=0 [∫ 1 0 y3 dy + 2m ∫ 1 0 y2 dy + m 2 ∫ 1 0 y dy] = n2 4 (n + 1)2. (d) n∑ m=1 m4 = ∫ n 0 m 4 dm + 4 ∫ n 0 ( x − [x]) x 3 dx = n 30 (n + 1)(2n + 1)(3n2 + 3n − 1). 12.3.2. The solution is given in the text. 12.4 Dirichlet Series 12.4.1. Simplifying the formula given in the exercise, we have ζ(2n) = π2n 2 2n−1 (2n)! |Bn| . The Bn can be read out of Table 12.2. 12.4.2. Make the substitution 1−x = e −t. The limits x = 0 and x = 1 correspond respectively to t = 0 and t = ∞. The integral becomes I = ∫ ∞ 0 [ln e −t]2 1 − e−t e −t dt = ∫ ∞ 0 t2e −t 1 − e−t dt . Now expand the denominator as a geometric series and make the further change of variable to u = nt: I = ∞∑ n=1 ∫ ∞ 0 t2e −nt dt = ∞∑ n=1 1 n3 ∫ u2e −u du = ∞∑ n=1 2! n3 = 2ζ(3) . CHAPTER 3. EXERCISE SOLUTIONS 159 12.4.3. For convergence, we split up the integral ∫ ∞ 0 = ∫ 1 0 + ∫ ∞ 1 and substitute y = 1/x, dy = −dx/x 2 in the ﬁrst integral. This gives ∫ 1 0 ln 2 y 1 + y2 dy = ∫ ∞ 1 ln 2 x 1 + x−2 dx x2 = ∫ ∞ 1 ln 2 x 1 + x2 dx. Upon substituting x = e t, dx = e tdt and using the geometric series for (1 + e −2t) −1, we obtain ∫ ∞ 0 ln 2 x 1 + x2 dx = 2 ∫ ∞ 0 t 2dt et(1 + e−2t) = 2 ∞∑ n=0(−1)n ∫ ∞ 0 t 2e −(2n+1)tdt = 2 ∞∑ n=0 (−1)n (2n + 1)3 ∫ ∞ 0 t 2e −tdt = 4 ∞∑ n=0 (−1) n (2n + 1)3 , using ∫ ∞ 0 t2e −tdt = Γ(3) = 2. 12.4.4. Starting from the deﬁnition, rearrange β(2) as follows: β(2) = 1 − 1 32 + 1 52 − 1 72 + 1 92 − · · · = 2 [1 + 1 52 + 1 92 + · · · ] − [1 + 1 32 + 1 52 + 1 72 + · · · ] = 2 ∞∑ k=1 1 (4k − 3)2 − π2 8 , where we have reecognized the last sum as the known series λ(2). 12.4.5. (a) Insert a series expansion for ln(1 + x): I = ∫ 1 0 ln(1 + x) x dx = ∞∑ n=1 ∫ 1 0 (−1) n+1x n−1 n dx = ∞∑ n=1 (−1) n+1 n2 = 1 12 − 2 22 + 1 32 − · · · = [ 1 12 + 2 22 + · · · ] − 2 [ 1 22 + 1 42 + · · · ] = ζ(2) − 2 ( 1 22 ) ζ(2) = 1 2 ζ(2) . (b) Note that the answer in the text is missing a minus sign. Use the series expansion for ln(1 − x): I = ∫ 1 0 ln(1 − x) x dx = − ∞∑ n=1 ∫ 1 0 x n−1 x dx = − ∞∑ n=1 1 n2 = −ζ(2) . CHAPTER 3. EXERCISE SOLUTIONS 160 12.4.6. Starting from the summation (from s = 2 to s = n) of 2−sζ(s), insert the expansion of the zeta function (using p as the expansion index) and then perform the summation over s. A convenient way to organize the process is to write the terms of 2−sζ(s) in a two-dimensional array: + 1 22 + 1 42 + 1 62 + 1 82 + 1 23 + 1 43 + 1 63 + 1 83 · · · · · · · · · · · · + 1 2n + 1 4n + 1 6n + 1 8n Now sum the entries in each vertical column; they form ﬁnite geometric 1 22 − 1 2n+1 1 − 1 2 1 42 − 1 4n+1 1 − 1 4 1 62 − 1 6n+1 1 − 1 6 1 82 − 1 8n+1 1 − 1 8 Collecting now the ﬁrst term of each of these column sums, we get 1/2 2 1 − 1 2 + 1/4 2 1 − 1 4 + · · · = 1 1 · 2 + 1 3 · 4 + 1 5 · 6 + · · · = ( 1 1 − 1 2 ) + ( 1 3 − 1 4 ) + ( 1 5 − 1 6 ) + · · · = ln 2 . The second terms of the column sums can be identiﬁed as − 1 2n+1(1 − 1 2 ) − 1 4n+1(1 − 1 4 ) − · · · = − ∞∑ p=1(2p) −n−1 [1 − 1 2p ]−1 . Putting everything together, we get n∑ s=2 2 −sζ(s) = ln 2 − ∞∑ p=1(2p) −n−1 [1 − 1 2p ]−1 , equivalent to the stated answer for the exercise. 12.4.7. This problem can be approached in a way similar to the solution of Exer- cise 12.4.6. If ζ(2s) is expanded (with expansion index p) and the terms of each p are summed over s, we ﬁnd n∑ s=1 4 −2sζ(2s) = [ 1 42 − 1 + 1 82 − 1 + · · · ] − ∞∑ p=1(4p) −2n−2 [ 1 − 1 (4p)2 ]−1 . CHAPTER 3. EXERCISE SOLUTIONS 161 The summation in square brackets expands into 1 2 ( 1 3 − 1 5 + 1 7 − · · · ) = 1 − π/4 2 , leading to the stated answer for the exercise. 12.5 Inﬁnite Products 12.5.1. Writing ln P = ∞∑ n=1 ln(1 ± an), insert the power-series expansion of the logarithm. As an becomes small (a necessary condition for convergence), only the leading term (linear inn) remains signiﬁcant. Thus, P will be ﬁnite only if the sum of the an converges. 12.5.2. Expand 1/(1 + b/n) and examine the leading terms of (1 + a/n)/(1 + b/n), which are of the form 1 + (a − b)/n + O(n−2). The tests series for convergence will be the (divergent) harmonic series unless a = b. 12.5.3. Form 2 sin x cos x, using for each its inﬁnite product formula. The result (with factors of two inserted in a way that does not change the value of the expression) is 2 sin x cos x = 2x ∏ ( 1 − 4x 2 (2n)2π2 ) (1 − 4x 2 (2n − 1)2π2 ) . Each term of the above inﬁnite product corresponds to two consecutive terms of the expansion of sin 2x, consistent with the relation sin 2x = 2 sin x cos x. 12.5.4. 1. 12.5.5. ∞∏ n=2 {1 − 2 /[n(n + 1)]} = ∞∏ n=2 (1 − 1)/n[1 + 1 /(n + 1)] = ∞∏ n=2 n − 1 n · n + 2 n + 1 = 2 2 · 3 ∞∏ n=2 n − 1 n · n n − 1 = 1 3 upon shifting n in the second product down to n – 2 and correcting for the two ﬁrst terms. 12.5.6. ∞∏ n=2 (1 − 1/n2) = ∞∏ n=2 (1 − 1 / n) (1 + 1 / n) = ∞∏ n=2 n − 1 n · n + 1 n = 1 2 ∞∏ n=2 n − 1 n · n n − 1 = 1 2 after shifting n in the second product term down to n – 1 and correcting for the ﬁrst missing term. CHAPTER 3. EXERCISE SOLUTIONS 162 12.5.7. Write 1 + zp = 1 − z2p 1 − zp . When this is inserted into the inﬁnite product the numerators cancel against the even powers in the denominator, leaving 1 (1 − z)(1 − z3)(1 − z5) · · · , as found by Euler. 12.5.8. Expand the exponential in powers of x/r. The leading terms that are signiﬁcant for large r are 1 − x 2/2r2. Since ∑r x 2/2r2 converges for all x, so also does the inﬁnite product. 12.5.9. Find the indeﬁnite integral of cot t, by integrating the expansion given in Eq. (12.35) and, alternatively, as its closed-form expression: ∫ x cot t dt = ln x + ∞∑ n=1(−1) n 22nB2n (2n)! x 2n 2n + C = ln sin x . The constant of integration is zero, since limx→0(sin x/x) = 1 and ln 1 = 0. Thus, the explicit form for the coeﬃcients an is a0 = 0, a2n+1 = 0, a2n = (−1) n 2 2nB2n 2n(2n)! , n ≥ 1. 12.5.10. The key to this problem is to recognize that d ln sin x/dx = cot x. Taking the logarithm of the inﬁnite product formula for sin x and expanding the logarithm, we get ln sin x = ln x − ∞∑ m,n=1 1 m ( x nπ )2m . Diﬀerentiating, and then multiplying by x, we reach x cot x = 1 − ∞∑ m,n=1 2 ( x nπ )2m . 12.6 Asymptotic Series 12.6.1. (a) C(x) = 1 2 + S1 cos ( πx 2 2 ) − S2 sin ( πx 2 2 ) . (b) S(x) = 1 2 + S1 sin ( πx 2 2 ) + S2 cos ( πx 2 2 ) CHAPTER 3. EXERCISE SOLUTIONS 163 with S1 = 1 πx ∞∑ n=0 (−1)n+1 1 · 3 · 5 · · · (4n + 1) (πx2)2n+1 , S2 = 1 πx ∞∑ n=0 (−1)n+1 1 · 3 · 5 · · · (4n − 1) (πx2)2n . Hint: C(x) + iS(x) = C(∞) + iS(∞) − ∫ ∞ x exp[iπu2/2] du. 12.6.2. Consider the repeated application of an integration by parts to the integral representation of Ci(x) + isi(x). Letting I0 = e it and D0 = 1/t, the ﬁrst integration by parts yields − ∫ ∞ x e it t dt = D0(x)I1(x) + ∫ ∞ x D1(t)I1(t) dt , where In = ∫ In−1(t) dt and Dn = dDn−1/dt. Continuing, − ∫ ∞ x e it t dt = D0(x)I1(x) − D1(x)I2(x) + · · · , where In = (−i) ne it and Dn = (−1)nn!/tn+1. Proceeding through N steps, we reach Ci(x) + isi(x) = e ix N∑ n=0 (−i) n+1 n! xn+1 . Writing e ix = cos(x) + i sin(x) and identifying the real and imaginary parts of the eight-hand side of the above equation, we get the formulas in Eqs. (12.93) and (12.94). 12.6.3. As suggested in the Hint, we consider the integral ∫ ∞ x e −t 2 dt. To facilitate repeated integration by parts, we multiply the factor e −t 2 by t dt and then integrate, thereby requiring that we divide the remainder if the integrand by t before diﬀerentiating it. Our scheme is therefore to de- ﬁne I0 = e −t 2 and D0 = 1, with In = ∫ t In−1 dt and Dn = d[Dn−1/t]/dt. This partial integration scheme corresponds to ∫ ∞ x e −t 2 dt = − I1(x)D0(x) x + I2(x)D1(x) x − · · · , where In(x) = (−1) n 2n e −t 2 , Dn(x) = (−1) n(2n − 1)!! t2n . Substitution of these quantities leads to the expected result. CHAPTER 3. EXERCISE SOLUTIONS 164 12.6.4. In the limit of large n, the ratio of the (n + 1)th term of P to its nth term is (in relevant part) term n + 1 term n ≈ (4n + 3)2(4n + 1) 2 (2n + 1)(2n + 2)(8z)2 , the value of which approaches constant × n2/z2. Since this ratio increases without limit, the series can only be asymptotic. A similar analysis applies to the function Q. 12.6.5. For |x| > 1, 1 1 + x = 1 x(1 + 1/x) = ∞∑ n=0 (−1) n xn+1 converges, so is not an asymptotic series. 12.6.6. Writing −γ = [∫ n 1 dx x − n∑ s=1 1 s ] + [∫ ∞ n dx x − ∞∑ s=n+1 1 s ] , and apply the Euler-Maclaurin formula to the quantity in the second set of square brackets. Noting that the derivatives in the Euler-Maclaurin formula vanish at x = ∞ and that f (2k−1)(n) = (−1) 2k−1(2k − 1)! n2k , the second bracketed quantity is identiﬁed as ∫ ∞ n dx x − ∞∑ s=n+1 1 s = 1 2n + N∑ k=1 B2k (2k)! f (2k−1)(n) = 1 2n − N∑ k=1 B2k (2k)n2k , equivalent to the desired result. 12.6.7. The answer given in the text is incorrect; it applies when the denominator of the integral is 1 + v2, not the speciﬁed (1 + v2) 2. Applying a binomial expansion to the denominator, the integral is asymp- totically represented by the series N∑ n=0 ( −2 n ) ∫ ∞ 0 v2ne −xv dv = N∑ n=0 (−1)n(n + 1)(2n)! x2n+1 . 12.7 Method of Steepest Descents 12.7.2. Substituting z = x/s, dz = dx/s we have ∫ s 0 cos x 2dx = s ∫ 1 0 cos(s 2z2) dz, CHAPTER 3. EXERCISE SOLUTIONS 165 and the corresponding result is valid for the sine integral. Now we replace s 2 → s and apply the saddle point method to I = ∫ 1 0 e isz2 dz = ∫ 1 0 [ cos(sz2) + i sin(sz2)] dz. With f (z) = iz2, f ′(z) = 2iz, f ′′(z) = 2i, we have a saddle point at z = 0 and α = π/2 − π/4. Thus I = √2π eiπ/4 |2is|1/2 = √ π 2s (i + 1). This implies ∫ s 0 cos x 2dx ∼ √ π 2 ∼ ∫ s 0 sin x 2dx. 12.7.3. Eq. (12.109) is valid for ℜ(s) > 0 and, therefore, this asymptotic result is valid for large ℜ(s) > 0. 12.8 Dispersion Relations 12.8.1. The answer is given in the text. 12.8.2. The integral over the small semicircle evaluates to f (x0)/2, so we have f (x0) 2 = 1 2πi ∫ ∞ −∞ f (x) x − x0 dx , equivalent to the answer we seek. CHAPTER 3. EXERCISE SOLUTIONS 166 13. Gamma Function 13.1 Deﬁnitions, Properties 13.1.1. Γ(z + 1) = ∫ ∞ 0 e −ttz dt = −e −ttz∣ ∞ + z ∫ ∞ 0 e −ttz−1 dt = zΓ(z). 13.1.2. (a) In terms of factorials, (s + n)! (n + 2s)! (2n + 1)! s! n! n! (2s + 2n + 1)! . (b) Using Pochhammer symbols, this expression can be written (n + 1)2s(s + 1)n (2n + 2)2s(1)n . 13.1.3. Substituting t2 = u, 2t dt = du we get for ℜe(z) > 0 Γ(z) = 2 ∫ ∞ 0 e −u2u2z−1du . (b) Substituting ln(1/t) = u, dt = −e −u du we get Γ(z) = ∫ 1 0 ( ln 1 u )z−1 du . Note that t = 0 corresponds to u → ∞ and t = 1 to u = 0. 13.1.4. The expectation value of vn, ⟨vn⟩, is given by ⟨vn⟩ = 4π ( m 2πkT )3/2 ∫ ∞ 0 e −mv2/2kT vn+2 dv = 4π ( m 2πkT )3/2 ( m 2kT )−(n+3)/2 ∫ ∞ 0 e −u 2 un+2 du . Making a change of variable in the u integral to x = u2, that integral becomes ∫ ∞ 0 e −u2 un+2 du = 1 2 ∫ ∞ 0 e −x x (n+1)/2 dx = 1 2 Γ ( n + 3 2 ) . To bring this expression to the form given as the answer in the text, replace/√ π by 1/Γ(3/2). 13.1.5. For k > −1, − ∫ 1 0 x k ln x dx = − ∫ 0 −∞ e (k+1)tt dt = (k + 1)−2 ∫ ∞ 0 e −tt dt = Γ(2) (k + 1)2 = 1 (k + 1)2 , using the substitution x = e t, dx = e t dt. CHAPTER 3. EXERCISE SOLUTIONS 167 13.1.6. ∫ ∞ 0 e −x4dx = 1 4 ∫ ∞ 0 e −tt −3/4 dt = Γ(1/4) 4 = Γ(5/4) , where we have made the substitution t = x 4, dt = 4x 3 dx. 13.1.7. Write Γ(ax) = Γ(1 + ax) ax and Γ(x) = Γ(1 + x) x , after which both gamma functions approach the limit unity, and we are left with the easily reduciblex/ax. 13.1.8. The denominator of Eq. (13.1) shows that Γ(z) has simple poles at z = 0, −1, −2, · · · . To ﬁnd the residues, divide the Euler integral into two parts, integrating from 0 to 1, and from 1 to ∞. For the integral from 0 to 1 insert the power-series expansion of e −t. Γ(z) = ∫ ∞ 0 e −ttz−1dt = ∫ 1 0 ∞∑ n=0 (−t) n n! tz−1dt + ∫ ∞ 1 e −ttz−1dt The integral from 1 to ∞ exhibits no singularities and we need not consider it further. Evaluating the integral from 0 to 1, we get ∫ 1 0 ∞∑ n=0 (−t) n n! tz−1dt = ∞∑ n=0 (−1) n n!(z + n) , which displays ﬁrst-order poles at all negative integers z = −n with re- spective residues (−1)n/n!. 13.1.9. From Fig. 13.1 we see qualitatively that, for negative z, the lobes of Γ(z) move closer to the horizontal axis as −z increases in magnitude. To prove that the line representing any nonzero value of k will have an inﬁnite number of intersections with the curve for Γ(z), we need to show that its positive minima and negative maxima (near the half-integer values of −z) become arbitrarily small for large negative values of z. Using Eq. (13.23) for z = 2n + 1 2 , with n a positive integer, we ﬁnd that Γ(−2n + 1 2 ) = π Γ(2n + 1 2 ) → 0 as n → ∞ and is positive because sin(π/2) = +1, while, for x = 2n + 3 2 , Γ(−2n − 1 2 ) = − π Γ(2n + 3 2 ) → 0 as n → ∞ and is negative because sin(3π/2) = −1. See also Exercise 13.1.14(a). 13.1.10. In both parts of this exercise, make a change of integration variable to 2 = u, with dx = du/2u1/2. Then, CHAPTER 3. EXERCISE SOLUTIONS 168 (a) ∫ ∞ 0 x 2s+1 e −ax2 dx = 1 2as+1 ∫ ∞ 0 us e −u du = s! 2as+1 . (b) ∫ ∞ 0 x 2s e −ax2 dx = 1 2as+1/2 ∫ ∞ 0 us−1/2 e −u du = Γ(s + 1 2 ) 2as+1/2 = (2s − 1)!! 2s+1as √ π a . 13.1.11. The answer is given in the text. 13.1.12. The answer is given in the text. 13.1.13. The coeﬃcient of cos(n − 2k)θ in the expansion has the form 2 (2n − 1)!! (2n)!! 1 · 3 · · · (2k − 1) 1 · 2 · · · k n(n − 1) · · · (n − k + 1) (2n − 1)(2n − 3) · · · (2n − 2k + 1) = 2 (2n − 1)!! (2n)!! (2k − 1)!! k! n! (2n − 2k − 1)!! (n − k)! (2n − 1)!! . Cancelling where possible, and changing notation to s and m, where n = 2s + 1 and n − 2k = 2m + 1 (so k = s − m), we get P2s+1(cos θ) = s∑ m=0 (2s − 2m − 1)!!(2s + 2m + 1)!! 22s(s − m)! (s + m + 1)! cos(2m + 1)θ . 13.1.14. Using the identities Γ( 1 2 + n) = Γ( 1 2 ) [ 1 2 · 3 2 · · · (2n − 1) 2 ] , Γ( 1 2 − n) = Γ( 1 2 ) ( − 1 2 ) (− 3 2 ) · · · ( − 2n − 1 2 ) , we form Γ( 1 2 + n)Γ( 1 2 − n) = Γ( 1 2 )2 (−1) n = (−1)nπ . 13.1.15. Within the region of convergence of the Euler integral, [∫ ∞ 0 tx+iy+1 e −t dt]∗ = ∫ ∞ 0 tx−iy+1 e −t dt . By analytic continuation this relation extends to all nonsingular values ofz). CHAPTER 3. EXERCISE SOLUTIONS 169 13.1.16. Letting z and z∗ respectively stand for α + iβ and α − iβ, and using the inﬁnite-product formula, Eq. (13.15), 1 Γ(z)Γ(z∗) = zz∗e γ(z+z∗) ∞∏ n=1 (1 + z n ) ( 1 + z∗ n ) e −(z+z∗)/n . Writing z + z∗ = 2α and zz∗ = α2 + β2 and identifying much of the above equation as similar to the product form of 1/Γ(α) 2, we ﬁnd 1 Γ(z)Γ(z∗) = 1 Γ(α)2 ( α2 + β2 α2 ) ∞∏ n=1 ( 1 + α + iβ n ) (1 + α − iβ n ) (1 + α n )2 . The argument of the inﬁnite product simpliﬁes to the form given in the exercise, so we reach 1 Γ(z)Γ(z∗) = 1 Γ(α)2 ( α2 + β2 α2 ) ∞∏ n=1 [1 + β2 (n + α)2 ] . We now notice that the factor preceding the inﬁnite product is exactly what we would get if we evaluated the product argument for n = 0. We therefore remove this factor and change the product lower limit to n = 0. Our formula is then entirely equivalent to that in the exercise. 13.1.17. As a ﬁrst step, examine |Γ(1 + ib)|. Using Exercise 13.1.16, |Γ(1 + ib)|−2 = ∞∏ n=0 [ 1 + b2 (n + 1)2 ] . Comparing with the inﬁnite-product representation of sin x, Eq. (12.77), the above product is identiﬁed as sin(iπb)/iπb = sinh(πb)/πb, so |Γ(1 + ib)| 2 = πb sinh πb . We now use the functional relation Γ(z + 1) = zΓ(z) for each of the two factors in |Γ(1 + ib)|2 = Γ(1 + ib)Γ(1 − ib), thereby reaching |Γ(n + 1 + ib)|2 = [(1 + ib)(2 + ib) · · · (n + ib)] × [(1 − ib)(2 − ib) · · · (n − ib)] |Γ(1 + ib)|2 = (1 + b2)(22 + b2) · · · (n2 + b 2) πb sinh πb , equivalent to the result we seek. CHAPTER 3. EXERCISE SOLUTIONS 170 13.1.18. Referring to the solution of Exercise 13.1.16, we see that Γ(x + iy) is reached from Γ(x) by multiplying the latter by an inﬁnite series of factors each of which is smaller than unity. 13.1.19. Using the formula of Exercise 13.1.16 with α = 1/2, |Γ( 1 2 + iy)|−2 = 1 π ∞∏ n=0 [1 + y2 (n + 1 2 )2 ] . Comparing with the inﬁnite-product expansion of cos x in Eq. (12.77), we identify the product here as cos iπy = cosh πy. Inserting this and taking the reciprocal, we conﬁrm the desired answer. 13.1.20. (a) The mean is obtained from the integral ∫ x f (x) dx. Writing this integral and making a change of variable to y = x − µ, we get ⟨x⟩ = 1 σ(2π)1/2 ∫ ∞ −∞ x e −(x−µ)2/2σ2 dx = 1 σ(2π)1/2 ∫ ∞ −∞(y+µ)e −y2/2σ2 dy . The y in the integrand can be dropped because, by symmetry, it makes no net contribution to the integral. The remainder of the expression now contains an integral of the form treated in Exercise 13.1.10(b); it simpliﬁes⟨x⟩ = µ. (b) To continue, we need to evaluatex2⟩ = 1 σ(2π)1/2 ∫ ∞ −∞ x2 e −(x−µ)2/2σ2 dx = 1 σ(2π)1/2 ∫ ∞ −∞(y+µ)2e −y2/2σ2 dy . We now expand (y + µ)2, drop the linear (odd) term, and evaluate the in- tegrals using Exercise 13.1.10(b). The result is ⟨x 2⟩ = σ2 + µ 2. Therefore, ⟨x 2⟩ − ⟨x⟩ 2 = (σ2 + µ 2) − µ 2 = σ2 , so (⟨x 2⟩ − ⟨x⟩ 2) 1/2 = σ . 13.1.21. (a) Here ⟨x⟩ = ∫ ∞ 0 x α βαΓ(α) e −x/β dx = β Γ(α) ∫ ∞ 0 uαe −u du = β Γ(α + 1) Γ(α) = αβ . (b) For σ2, we need ⟨x2⟩ = ∫ ∞ 0 x α+1 βαΓ(α) , which by the same technique as used for part (a) is found to have the value ⟨x 2⟩ = β2 Γ(α + 2) Γ(α) = α(α + 1)β2 . Thus, ⟨x2⟩ − ⟨x⟩ 2 = α(α + 1)β2 − α2β2 = αβ2. CHAPTER 3. EXERCISE SOLUTIONS 171 13.1.22. Referring to the ﬁrst part of the solution to Exercise 13.1.17, we have |Γ(1 + iγ)| 2 = πγ sinh πγ . Multiplying by e −πγ and writing sinh πγ as exponentials, the result is immediate. 13.1.23. This problem would be speciﬁed more precisely if, instead of (−t) ν, it had contained e −πiνtν. Starting from Eq. (13.30), consider a contour that starts at +∞ + ε i, con- tinues (segment A) nearly to the origin, which it circles counterclockwise (B), then returning (segment C) to +∞ − ε i. For suitable values of ν, part B of the contour will make a negligible contribution, while part A will contribute −Γ(ν + 1). On part C, arg t = 2π, and that segment will make a contribution e 2πiνΓ(ν + 1). All together, these contributions to Eq. (13.30) conﬁrm its right-hand side. Then, multiplying both sides of that equation by e −πiν, its right-hand side becomes 2i sin νπ, and its left hand side is consistent with the value with which we replaced (−t) ν. 13.2 Digamma and Polygamma Functions 13.2.1. The answer is given in the text. 13.2.2. (a) Use Eq. (12.38) to rewrite ζ(2n) in terms of the Bernoulli numbers: ln Γ(x + 1) = −γx + ∞∑ n=2(−1) n ζ(n) n x n = −γx − ∞∑ n=1 ζ(2n + 1) 2n + 1 x 2n+1 + ∞∑ n=1(−1) n−1 B2n 4n(2n)! (2πx) 2n . The sum involving the Bernoulli numbers closely resembles the expansion for cot πx, Eq. (12.35), diﬀering therefrom primarily by the factor 4n in the denominator. This observation indicates that our Bernoulli sum will be related to ∫ cotπx dx = −π−1 ln sin πx . The precise relationship needed here is ∞∑ n=1(−1)n−1 B2n 4n(2n)! (2πx)2n = 1 2 ln πx sin πx , which can be veriﬁed by diﬀerentiating both sides and invoking Eq. (12.35). Substituting this expression for the Bernoulli sum, we reach the answer in the text, in which there is a remaining summation of the zeta functions of CHAPTER 3. EXERCISE SOLUTIONS 172 odd argument. That series has the range of convergence −1 < x < 1. (b) This formula exhibits better convergence than that of part (a). The replacement of ζ(2n + 1) by ζ(2n + 1) − 1 is equivalent to adding the series ∞∑ n=1 x 2n+1 2n + 1 = 1 2 ln ( 1 + x 1 − x ) − x . We therefore also subtract the right-hand side of this equation from the formula of part (a). The inﬁnite series of part (b) will converge for −2 < x < 2 but the terms sin πx, ln(1 + x), and ln(1 − x) still limit x to −1 < x < 1. 13.2.3. For x = n a positive integer, ψ(n + 1) = ∞∑ r=1( 1 r − 1 r + n ) − γ = −γ + n∑ r=1 1 r . 13.2.4. Expanding 1 z + n = 1 n ∞∑ ν=0 (− z n )ν in a geometric series we obtain d dz ln z! = ψ(z + 1) = −γ + ∞∑ n=1 ( 1 n − 1 z + n ) = −γ − ∞∑ ν=1(−z)ν ∞∑ n=1 1 nν+1 = −γ − ∞∑ n=2(−z) n−1ζ(n). Interchanging the summations is justiﬁed by absolute and uniform con- vergence for |z| ≤ 1 − ε, with ε > 0 arbitrarily small. 13.2.5. (a) Using ln(1 + z) = ∞∑ n=1(−1) n−1 zn n , we add ln(1 + z) to both sides of Eq. (13.44): ln Γ(z + 1) + ln(1 + z) = −γz + ∞∑ n=2(−1) n zn n ζ(n) + [ z − ∞∑ n=2(−1) n, zn n ] = z(1 − γ) + ∞∑ n=2(−1)m[ ζ(m) − 1 ] zn n . This is the relation we were asked to conﬁrm. (b) Since ζ(n) − 1 ∼ 1/2n for n → ∞ the radius of convergence is R = 2. CHAPTER 3. EXERCISE SOLUTIONS 173 13.2.6. Using Eq. (13.44), rather than the equation suggested in the Hint, we obtain ln [ Γ(1 + z)Γ(1 − z) ] = ∞∑ n=2(−1) nζ(n) [ zn n + (−z)n n ] = 2 ∞∑ n=2 ζ(2n) z2n 2n . But, from Eq. (13.23), multiplied by z to change Γ(z) to Γ(1 + z), ln [ Γ(1 + z)Γ(1 − z) ] = πz sin πz , thereby establishing the relation to be proved. 13.2.7. The logarithm of the Weierstrass inﬁnite-product form, after combining z and Γ(z) to make Γ(z + 1), is ln Γ(z + 1) = −γz + ∞∑ n=1 [ z n − ln (1 + z n )] . Now expand ln (1 + z n ) in powers of z, reaching ln Γ(z + 1) = −γz + ∞∑ n=1 ∞∑ ν=2 (−1) ν ν zν nν = −γz + ∞∑ ν=2(−1) ν zν ν ∞∑ n=1 1 nν = −γz + ∞∑ ν=2(−1) ν zν ν ζ(ν) , which is Eq. (13.44). 13.2.8. First form, using Eq. (13.38) and expanding into partial fractions, most terms of which cancel, ψ(z + 2) − ψ(z + 1) = ∞∑ m=1 z + 1 m(m + z + 1) − ∞∑ m=1 z m(m + z) = ∞∑ m=1 [ 1 m − 1 m + z + 1 − 1 m + 1 m + z ] = 1 z + 1 . Now diﬀerentiate this result m times: dm dzm [ ψ(z + 2) − ψ(z + 1) ] = dm dzm ( 1 z + 1 ) = (−1) m m! (z + 1)m+1 . CHAPTER 3. EXERCISE SOLUTIONS 174 13.2.9. (a) We have (a)n = (a + n − 1)! (a − 1)! = Γ(a + n) Γ(a) . (b) d(a)n da = 1 Γ(a) dΓ(a + n) da − Γ(a + n) Γ(a)2 dΓ(a) da = Γ(a + n) Γ(a) [ ψ(a + n) − ψ(a)] = (a)n[ ψ(a + n) − ψ(a) ] . 13.2.10. Setting z = 0 in the solution to Exercise 13.2.4 we conﬁrm ψ(1) = −γ. Setting z = 0 in Eq. (13.41), the summation in that equation becomes ζ(m + 1), as also written in Eq. (13.43). Evaluation from that equation gives the results for ψ(1)(1) and ψ(2)(1). 13.2.11. (a) One way to proceed is to start by integrating the subject integral by parts. The integral is convergent at r = 0 but to avoid divergences in some of the steps to be taken we change its lower limit to ε and later take the limit ε → 0. Thus, ∫ ∞ ε e −r ln r dr = −e −r ln r∣ ∞ + ∫ ∞ ε e −r r dr = e −ε ln ε + E1(ε) . Inserting the expansion for E1 from Eq. (13.83) and noting that the entire summation in that equation is O(ε), we have ∫ ∞ ε e −r ln r dr = e −ε ln ε − γ − ln ε + O(ε) . Expanding e −ε = 1 − ε + · · · , we see that in the limit ε → 0 the only nonvanishing contribution is −γ. (Note that limε→0 ε ln ε = 0.) (b) This part is most easily approached after solving part (c). (c) Introduce the notation In = ∫ ∞ 0 rne −r ln r dr . Integrate In by parts, diﬀerentiating rn ln r and integrating e −r. In = [ − rn ln r e −r] ∞ + ∫ ∞ 0 rn−1e −r(n ln r + 1) dr = 0 + nIn−1 + ∫ ∞ 0 rn−1e −r dr = n In−1 + (n − 1)! . From part (a) we have I0 = −γ. Then the integral of part (b) is I1 = 0! + 1 I0 = 1 − γ . CHAPTER 3. EXERCISE SOLUTIONS 175 13.2.12. Deﬁning x = α2Z 2 and z = 2(1 − x)1/2, we need the ﬁrst few terms in the Maclaurin series (in powers of x) of Γ(z + 1). To start, when x = 0, z = 2, so Γ(z + 1) = Γ(3) = 2. From the deﬁnition of the digamma function, we also have dΓ(z + 1) dz = Γ(z + 1)ψ(z + 1) , dΓ(z + 1) dx = Γ(z + 1)ψ(z + 1) dz dx = Γ(z + 1)ψ(z + 1) [−(1 − x)−1/2] , which at x = 0 has the value −Γ(3)ψ(3) = −2(−γ + 3 2 ). Continuing to the second derivative, d2Γ(z + 1) dx2 = d dz [Γ(z + 1)ψ(z + 1)] [ −(1 − x) −1/2]2 + Γ(z + 1)ψ(z + 1) d dx [−(1 − x)−1/2] = Γ(z + 1) ([ψ(z + 1)]2 + ψ(1)(z + 1) ) [−(1 − x) −1/2]2 + Γ(z + 1)ψ(z + 1) [ − (1 − x)−3/2 2 ] . At x = 0, z = 2, ψ(1)(z + 1) = ζ(2) − 5 4 , and d2Γ(z + 1) dx2 = 2 [γ2 − 5γ 2 + ζ(2) + 1 4 ] . Forming the Maclaurin series,−α2Z 2) 1/2+1] = 2+(2γ−3)α2Z 2+( γ2 − 5γ 2 + ζ(2) + 1 4 ) α4Z 4+· · · . 13.2.13. One way to obtain the argument of a complex quantity is to identify it as the imaginary part of its logarithm. Using Eq. (13.44) for z = ib, we have ln Γ(1 + ib) = −γib + ∞∑ n=2(−1)n (ib)n n ζ(n) . The imaginary part of this expression is −γ b + ζ(3) b3 3 − · · · . 13.2.14. From Eqs. (13.38) and (13.40), ψ(n + 1) = −γ + ∞∑ m=1 n m(n + m) = −γ + n∑ m=1 1 m . CHAPTER 3. EXERCISE SOLUTIONS 176 (a) Taking n = 1 in the above equation, the inﬁnite sum is that whose value is sought; we identify its value as that of the ﬁnite sum on the right- hand side, here, 1. (b) Writing n2 − 1 = (n − 1)(n + 1), this summation is equivalent to ∞∑ n=1 1 n(n + 2) , which is (1/2) times the summation associated with ψ(2), and thereby has the value (1 + 1 2 )/2 = 3/4. 13.2.15. ψ(a + 1) − ψ(b + 1) = ∞∑ n=1 ( 1 b + n − 1 a + n ) = (a − b) ∞∑ n=1 1 (a + n)(b + n) . 13.3 The Beta Function 13.3.1. Expanding all the beta functions, and using Eq. (13.2) to make the gamma functions have similar arguments, we reduce these expressions to identities: Γ(a)Γ(b) Γ(a + b) = aΓ(a)Γ(b) (a + b)Γ(a + b) + bΓ(a)Γ(b) (a + b)Γ(a + b) . (b) Γ(a)Γ(b) Γ(a + b) = ( a + b b ) bΓ(a)Γ(b) (a + b)Γ(a + b) . (c) Γ(a)Γ(b) Γ(a + b) = aΓ(a)(b − 1)−1Γ(b) Γ(a + b) . (d) Γ(a)Γ(b) Γ(a + b) Γ(a + b)Γ(c) Γ(a + b + c) = Γ(a)Γ(b)Γ(c) Γ(a + b + c . This is symmetric in a, b, and c, so the presumed relation must be correct. 13.3.2. (a) This is a case of Eq. (13.50); the “2” in that equation compensates for the range of integration, in this exercise (−1, +1). The values of p and q in the equation are p = n − 1 2 , q = 1 2 , so the integral has the value B(n + 1 2 , 3 2 ) = Γ(n + 1 2 ) Γ( 3 2 ) Γ(n + 2) = √π (2n − 1)!! 2n √π 2 1 (n + 1)! , equivalent to the desired answer. (b) This problem is similar, reducing to B(n + 1 2 , 1 2 ). 13.3.3. This is a case of Eq. (13.50), with p = − 1 2 , q = n, and thereby reduces to B( 1 2 , n + 1) = Γ( 1 2 )Γ(n + 1) Γ(n + 3 2 ) = √π n! √π (2n + 1)!!/2n+1 = 2(2 n n!) (2n + 1)!! . CHAPTER 3. EXERCISE SOLUTIONS 177 13.3.4. Setting x = cos θ, we identify 1 + x as 2 cos2 χ and 1 − x as 2 sin2 χ, where χ = θ/2. We then write dx as − sin θ dθ = −4 sin χ cos χ dχ. The integration range, from −1 to 1 in x, is π/2 to 0 in χ. With these changes, the integral under study becomes ∫ 1 −1(1 + x)a(1 − x) b dx = 2a+b+2 ∫ π/2 0 cos2a+1 χ sin 2b+1 χ dχ , which is a case of Eq. (13.47) with p = a + 1 and q = b + 1. The integral therefore has value B(a + 1, b + 1)/2; when the power of 2 multiplying the integral is taken into account, we obtain the answer in the text. 13.3.5. Make a change of the variable of integration to make the integration limits zero and one: u = (x−t)/(z−t). Then x−t = (z−t)u, z−x = (z−t)(1−u), dx = (z − t) du, and the integral becomes ∫ z t dx (z − x)1−α(x − t)α = ∫ 1 0 du (1 − u)1−αuα , which is a case of Eq. (13.49) with p = −α and = α − 1. Therefore, using Eq. (13.23), ∫ z t dx (z − x)1−α(x − t)α = B(1 − α, α) = Γ(1 − α) Γ(α) Γ(1) = π sin πα . 13.3.6. Writing this integral with limits deﬁning the triangular integration region, and using Eq. (13.49), ∫ 1 0 dx xp ∫ 1−x 0 yq dy = ∫ 1 0 dx xp(1 − x) q+1 q + 1 = ( 1 q + 1 ) B(p + 1, q + 2) = B(p + 1, q + 1) p + q + 2 , where the last step uses the identity of Exercise 13.3.1(b). 13.3.8. The integrals at issue here are cases of Eq. (13.47), which for the integral of part (b) with general n has p = (n + 1)/2, q = 1/2, and ∫ π/2 0 cosn θ dθ = 1 2 B ( n + 1 2 , 1 2 ) = Γ( n+1 2 ) Γ( 1 2 ) Γ( n 2 + 1) . (a) For n = 1/2, ∫ π/2 0 cos1/2 θ dθ = √π 2 Γ(3/4) Γ(5/4) , which can be converted into the listed answer using the reﬂection formula, Eq. (13.23). CHAPTER 3. EXERCISE SOLUTIONS 178 (b) For n odd, the gamma function in the denominator can be written Γ ( n 2 + 1 ) = √π 2 n!! 2(n+1)/2 , and the net overall power of 2 can be used to convert ( n − 1 2 ) ! to (n−1)!!, thereby reaching the listed answer. For n even, a similar process can be used to convert the gamma function of half-integer argument to the more convenient form given as the listed answer. 13.3.9. Make the substitution x2 = y, so dx = dy/2y1/2, and the integral becomes ∫ 1 0 (1 − x 4) −1/2 dx = 1 2 ∫ 1 0 (1 − y2)−1/2 y−1/2 dy . This is a case of Eq. (13.50) with p = −3/4 and q = −1/2, and the integral has the value B( 1 4 , 1 2 )/4. This can be brought to the form in the text using Eq. (13.23); the potential advantage in doing so is that then, only one gamma function of fractional argument enters a numerical evaluation. 13.3.10. This problem can be approached by expanding cos(z cos θ) in powers of z, resulting in a series each term of which contains a trigonometric integralθ. The expansion yields Jν(z) = 2 π1/2Γ(ν + 1 2 ) ( z 2 )ν ∞∑ n=0 (−1) nz2n (2n)! ∫ π/2 0 sin 2ν θ cos2n θ dθ . This integral is a case of Eq. (13.47) with value ∫ π/2 0 sin 2ν θ cos2n θ dθ = 1 2 B(ν + 1 2 , n + 1 2 ) = 1 2 Γ(ν + 1 2 ) Γ(n + 1 2 ) Γ(n + ν + 1) . When this is combined with the other factors in the representation ofν(z), the standard Bessel series deﬁnition is obtained. 13.3.11. These integrals are cases of Eq. (13.50); since the present integrands are even functions of x, the fact that the integration range is from −1 to 1 instead of 0 to 1 is compensated by the factor of 2 multiplying the integral in Eq. (13.50). (a) This integral is [ (2m−1)!! ] 2 B( 1 2 , m+1) = [ (2m−1)!! ] 2 Γ( 1 2 ) Γ(m + 1) Γ(m + 3 2 ) = [ (2m − 1)!! ] 2 √π 2m+1 m! √π (2m + 1)!! = (2m − 1)!! 2 (2m)!! 2m + 1 = 2 (2m)! 2m + 1 . CHAPTER 3. EXERCISE SOLUTIONS 179 (b) This is [ (2m − 1)!! ] 2 B( 1 2 , m) . A reduction similar to that of part (a) leads to the listed answer. 13.3.12. These integrals are cases of Eq. (13.50). ∫ 1 0 x 2p+1(1 − x 2)−1/2 dx = 1 2 B(p + 1, 1 2 ) = Γ(p + 1) Γ( 1 2 ) 2Γ(p + 3 2 ) , which reduces to the listed answer. ∫ 1 0 x 2p(1 − x 2)q dx = 1 2 B(p + 1 2 , q + 1) . This reduces in a way similar to part (a). 13.3.13. Change the integration variable to y = Ax n/E, so dx = (x/ny) dy, and thereby make the integral a case of Eq.!(13.49): τ = 2 √ 2m E ∫ 1 0 (x/ny) dy (1 − y)1/2 = 2 n √ 2m E ( E A )1/n ∫ 1 0 y(1/n)−1(1 − y) −1/2 dy = 2 n √ 2m E ( E A )1/n B(1/n, 1/2) . This beta function has value Γ ( 1 n ) √π∕ Γ ( 1 n + 1 2 ) ; when inserted we conﬁrm the answer given for τ . 13.3.14. (a) Write the potentially singular part of the n dependence of τ as 1 n Γ(1/n) Γ( 1 n + 1 2 ) = Γ(1 + 1/n) Γ( 1 n + 1 2 ) → Γ(1) Γ(1/2) = 1 √π . Combining with the other factors, the limit simpliﬁes to τ → 2 √ 2m E . (b) In the limit of large n the potential is zero between the turning points (which are then at x = ±1) and inﬁnite elsewhere; the integral for τ reduces to τ∞ = 2√2m ∫ 1 0 E−1/2 dx = 2 √ 2m E . (c) At inﬁnite n the particle will be moving with kinetic energy mv2/2 = E, so v = √2E/m. At this velocity, the time to travel 4 units of distance (one period) will be 4/v = 4√ m/2E = 2√2m/E. CHAPTER 3. EXERCISE SOLUTIONS 180 13.3.15. Following the Hint, let sinh 2 x = u, 2 sinh x cosh x dx = du, and the inte- gral becomes (using the identity cosh2 x = sinh 2 x + 1) ∫ ∞ 0 sinh α x coshβ x dx = ∫ ∞ 0 uα/2 (1 + u)β/2 du 2[u(1 + u)]1/2 = 1 2 ∫ ∞ 0 u(α−1)/2 du (1 + u)(β+1)/2 . This is a case of Eq. (13.51) with p = (α − 1)/2, p + q + 2 = (β + 1)/2, corresponding to q = (β − α)/2 − 1. The integral of this exercise therefore has the value ∫ ∞ 0 sinhα x coshβ x dx = 1 2 B ( α + 1 2 , β − α 2 ) . 13.3.16. The integrals occurring here are cases of Eq. (13.49).⟨x⟩ = ∫ 1 0 x f (x) dx = Γ(α + β) Γ(α) Γ(β) ∫ 1 0 x α(1 − x) β−1 dx = Γ(α + β) Γ(α) Γ(β) Γ(α + 1) Γ(β) Γ(α + β + 1) = α α + β . (b) ⟨x 2⟩ = Γ(α + β) Γ(α) Γ(β) ∫ 1 0 xα+1(1−x) β−1 dx = Γ(α + β) Γ(α) Γ(β) Γ(α + 2) Γ(β) Γ(α + β + 2) = α(α + 1) (α + β)(α + β + 1) . We now form 2 = ⟨x 2⟩−⟨x⟩ 2 = α(α + 1) (α + β)(α + β + 1) − α2 α + β)2 = αβ (α + β)2)(α + β + 1) . 13.3.17. The integrals of this exercise are cases of Eq. (13.47); both are for p = 1/2; the numerator has q = n + 1 2 , while the denominator has q = n + 1. The ratio of the two integrals is B( 1 2 , n + 1 2 ) B( 1 2 , n + 1) = Γ( 1 2 ) Γ(n + 1 2 ) Γ(n + 1) Γ(n + 3 2 ) Γ( 1 2 ) Γ(n + 1) = [Γ(n + 1 2 )] 2 (n!)2 (n + 1 2 ) . To reach the Wallis formula, write Γ(n + 1 2 ) as √π (2n − 1)!!/2 n and write n + 1 2 = (2n + 1)/2. Then B( 1 2 , n + 1 2 ) B( 1 2 , n + 1) = π 2 (2n − 1)!! (2n + 1)!! 2nn! 2nn! = π 2 (2n − 1)!! (2n + 1)!! (2n)!! (2n)!! . We now set this result (in the limit of inﬁnite n) equal to unity and solve for π/2. CHAPTER 3. EXERCISE SOLUTIONS 181 13.4 Stirling’s Series 13.4.1. The answer is given in the text. 13.4.2. Use Eq. (13.60) with z = 52; it is not necessary to keep any of the terms with negative powers of z. Compute the logarithm, then exponentiate. The result is 8.1 × 1067. 13.4.3. Keeping only terms that do not vanish in the limit of large z, the logarithm of the gamma function recurrence formula can be written ln Γ(z + 1) − ln z − ln Γ(z) = C2 + (z + 1 2 ) ln z + (C1 − 1)z − ln z − [ C2 + (z − 1 2 ) ln(z − 1) + (C1 − 1)(z − 1) ] = 0 . The above simpliﬁes immediately to (z − 1 2 ) ln z − (z − 1 2 ) ln(z − 1) + C1 − 1 = 0 . Noting now that ln(z − 1) = ln z + ln (1 − 1 z ) = ln z − 1 z − O(z−2), our equation further simpliﬁes in the limit of large z to (z − 1 2 ) ln z − (z − 1 2 ) (ln z − 1 z ) + C1 − 1 = 0 −→ C1 = 0 , conﬁrming the asserted value C1 = 0. We now prepare to use the duplication formula by writing ln Γ(z + 1) ∼ C2 + (z + 1 2 ) ln z − z ln Γ(z + 1 2 ) ∼ C2 + z ln(z − 1 2 ) − (z − 1 2 ) ln Γ(2z + 1) ∼ C2 + (2z + 1 2 ) ln 2z − 2z Substitute the above into the Legendre duplication formula ln Γ(z + 1) + ln Γ(z + 1 2 ) = 1 2 ln π − 2z ln 2 + ln Γ(2z + 1) . Many terms now cancel; to complete the cancellation we need to expandz − 1 2 ) in a way similar to our earlier treatment of ln(z − 1). After this further simpliﬁcation we get C2 = 1 2 ln 2π , the other required result. CHAPTER 3. EXERCISE SOLUTIONS 182 13.4.4. Because ln x is a monotone increasing function, ln n < ∫ n+1 n ln x dx < ln(n + 1) . Since ln(n!) = ln 1+ln 2+· · ·+ln n, ln(n!) will lie between the two integrals of the present exercise. 13.4.5. Using Stirling’s asymptotic formula we ﬁnd that Γ(p + 1/2) Γ(p + 1) ∼ √e ( p + 1/2 p + 1 )p+1/2 /√ p + 1 ∼ constant √p for p ≫ 1. Hence the series diverges. 13.4.6. As n is increased, the asymptotic formula given by Stirling’s series (trun- cated before some negative power of the expansion argument) can be brought arbitrarily close to the inﬁnite-n limit. Including all the terms that do not go to zero at large n, our current expression has the asymp- totic limit ln [x b−a Γ(x + a + 1) Γ(x + b + 1) ] ∼ (b − a) ln x + (x + a + 1 2 ) ln(x + a) − (x + a) − (x + b + 1 2 ) ln(x + b) + (x + b) = (b − a) ln x + (a − b) ln x . To simplify this, write ln(x + a) = ln x + ln (1 + a x ) ≈ ln x + a x + · · · , and the same for ln(x + b). We can then verify that all the terms that survive at large x add to zero, so the limit we seek is exp(0) = 1. 13.4.7. Write this expression in terms of factorials so that Stirling’s formula can be used. It is convenient to work with logarithms of the factors. L = (2n − 1)!! (2n)!! n1/2 = (2n)! n1/2 22n[n!]2 . Then ln L ∼ ln(2π) 2 + (2n + 1 2 ) ln(2n) − 2n + ln n 2 − 2n ln 2 − ln(2π) − 2(n + 1 2 ) ln n + 2n + · · · . This simpliﬁes to − ln π/2, consistent with the listed answer. 13.4.8. (a) Using Stirling’s formula, dropping all terms of scaling lower than N , we have N ! ≈ N ln N − N and then (for arbitrary ni but subject to the condition that ∑i ni = N ) S = k ln W = k [ N ln N − N − M∑ i=1(ni ln ni − ni) ] = k M∑ i=1 ni(ln N −ln ni). CHAPTER 3. EXERCISE SOLUTIONS 183 Introducing the notation pi = ni/N , this equation becomes S = −N k M∑ i=1 pi ln pi . If the number of states M is ﬁxed, this expression scales as N and is therefore extensive. Note that the individual terms of scaling greater thanhave combined in a way that makes S an extensive quantity. (b) We must maximize S subject to the constraint P = ∑ i pi = 1. We proceed by obtaining an unconstrained maximum of S − λP , after which we set λ (called a Lagrange multiplier) to a value consistent with the constraint. For details, see Section 22.3. We have for each state i ∂ ∂pi [ W − λP ] = ln pi − 1 − λ = 0 , indicating that the extremum of S is reached when all the pi are the same; since there are M pi, each must have the value 1/M . Inserting these pi values into the formula for S, we get S = −N k M∑ i=1 1 M ln(1/M ) = N k ln M . 13.5 Riemann Zeta Function 13.5.1. Starting from the equation given as a starting point, divide both sides by 2ie πiz, converting the parenthesized quantities containing complex ex- ponentials into sine functions. Then replace each sine function by its equivalent as given by the reﬂection formula. Eq. (13.23). These steps proceed as follows: e 2πiz − 1 2ieπiz = sin πz = π Γ(z)Γ(1 − z) e 3πiz/2 − e πiz/2 2ieπiz = sin(πz/2) = π Γ(z/2)Γ(1 − 1 2 z) π Γ(z)Γ(1 − z) ζ(z) = 2 zπz Γ(z) π Γ(z/2)Γ(1 − 1 2 z) ζ(1 − z) . Next, use the Legendre duplication formula to replace Γ(1 − z): Γ(1 − z) = Γ ( 1 − z 2 ) Γ (1 − z 2 ) 2z π1/2 After this result is inserted into the equation preceding it, a rearrangement without further analysis yields the desired formula. CHAPTER 3. EXERCISE SOLUTIONS 184 13.5.2. Integrating by parts, using d dx ( 1 ex − 1 ) = − e x (ex − 1)2 , we obtain ∫ ∞ 0 x ne x (ex − 1)2 dx = − x n ex − 1 ∣ ∞ + n ∫ ∞ 0 x n−1 ex − 1 dx. Here the integrated term vanishes and the second term contains the inte- gral of Eq. (13.62) and has value n!ζ(n). 13.5.3. We treat only the limiting cases T → ∞ and T → 0. (a) For T → ∞, we need the value of the integral when the upper limit is small. Expanding the denominator and keeping only the leading terms, ∫ x 0 x5 dx (ex − 1)(1 − e−x) ≈ ∫ x 0 x 5 dx (x)(x) = ∫ x 0 x 3 dx = x 4 4 . Setting x = Θ/T , we get ρ ≈ C ( T 5 Θ6 ) 1 4 ( Θ T )4 = C 4 T Θ2 . (b) The upper integration limit is now inﬁnity. Start with an integration by parts, to bring the integrand to a form that can be identiﬁed, using Eq. (13.62), as leading to a zeta function. I = ∫ ∞ 0 x 5 e x dx (ex − 1)2 = [ −x 5 ex − 1 ]∞ + ∫ ∞ 0 5x4 dx ex − 1 = 5Γ(5) ζ(5) = 5! ζ(5) . Therefore, ρ ≈ 5! ζ(5) C T 5 Θ6 . 13.5.4. The denominator of the integrand (with a factor t in the numerator) is the generating function for the Bernoulli numbers, so we can introduce that expansion and integrate termwise. ∫ x 0 t n dt et − 1 = ∫ x 0 t n−1 dt ∞∑ p=0 Bptp p! = ∞∑ p=0 x n+p n + p Bp p! . Using the facts that B0 = 1, B1 = −1/2, and that the Bp of odd p > 1 vanish, we can bring the above expansion to the form given in the text. 13.5.5. The integral in this expression is a case of Eq. (13.62) with z = 4. It therefore has the value Γ(4) ζ(4) = 3! ζ(4). 13.5.6. Summing ∫ ∞ 0 e −nxx s−1dx = Γ(s) ns over the positive integers n we obtain ∞∑ n=1 ∫ ∞ 0 e −nxxs−1 dx = ζ(s)Γ(s) = ∫ ∞ 0 x s−1 ex − 1 dx for ℜe(s) > 1. CHAPTER 3. EXERCISE SOLUTIONS 185 13.5.7. Make a binomial expansion of the denominator of the integrand as given in the exercise: 1 ex + 1 = e −x 1 + e−x = ∞∑ n=1(−1) n+1e −nx . Insert this into the integral of this exercise and integrate termwise:∞ 0 xs dx ex + 1 = ∞∑ n=1(−1)n+1 ∫ ∞ 0 x se −nx dx = [ ∞∑ n=1(−1)n+1 1 ns+1 ] Γ(s + 1) . Referring to Eq. (12.62), we identify the sum over n as the Dirichlet series η(s + 1), with sum (1 − 2 −s) ζ(s + 1), so ∫ ∞ 0 xs dx ex + 1 = (1 − 2 −s) ζ(s + 1) Γ(s + 1) , equivalent to the result to be proved. 13.5.8. Changing the integration variable to t = x/kT , ρν = 4π(kT ) 4 h3 ∫ ∞ 0 x 3 dx ex + 1 . This integration is a case of Exercise 13.5.7, and ρν therefore has the value ρν = 4π(kT )4 h3 3!(1 − 2 −3) ζ(4) = 4π(kT )4 h3 ( 7 8 ) π4 90 = 7π5 30h3 (kT ) 4 . 13.5.9. Use the binomial theorem to expand the denominator of the integrand and then integrate termwise. (−1) n+1 ∫ ∞ 0 tn e −zt dt 1 − e−t = (−1)n+1 ∫ ∞ 0 tn e −zt ∞∑ p=0 e −pt dt = (−1)n+1 ∞∑ p=0 ∫ ∞ 0 t n e −(z+p)t dt = (−1)n+1 ∞∑ p=0 n! (z + p)n+1 . To identify this summation as a polygamma function we need to change the indexing to move the lower summation limit from 0 to 1. We then have (−1) n+1n! ∞∑ p=1 1 (z − 1 + p)n+1 , which corresponds to Eq. (13.41) for z − 1. CHAPTER 3. EXERCISE SOLUTIONS 186 13.5.10. The alternating series for ζ(z), Eq. (13.68), converges for all ℜe z > 0, and provides a deﬁnition for that entire region except at z = 1, where the factor multiplying the series becomes singular. The reﬂection formula, Eq. (13.67), extends the analyticity to ℜe z ≤ 0 (except for the point z = 0). Returning to the point z = 1, we show it to be a simple pole with residue +1 by taking the limit, applying l’Hˆopital’s rule: lim z→1 (z − 1) 1 − 21−z ∞∑ n=1 (−1) n−1 nz = 1 ln 2 ∞∑ n=1 (−1)n−1 n = 1 ln 2 ln 2 = 1 . Finally, we establish ζ(0) as regular by taking the limit ζ(0) = lim z→0 πz−1/2Γ((1 − z)/2) Γ(z/2) ζ(1 − z) = π−1/2Γ(1/2) lim z→0 ζ(1 − z) Γ(z/2) = lim z→0 1 (1 − z) − 1 1 Γ(z/2) = lim z→0 1 −z Γ(z/2) = − lim z→0 1 2 Γ(1 + z/2) = − 1 2 . 13.6 Other Related Functions 13.6.1. Integrate by parts the integral deﬁning γ(a, x): γ(a, x) = ∫ x 0 t a−1e −t dt = t a a (−e t) ∣ x + 1 a ∫ x 0 ta e −t dt = x a e −x a + 1 a ∫ x 0 ta e −t dt . Further integrations by parts leads to the series γ(a, x) = x a e −x a + x a+1 e −x a(a + 1) + · · · = e −x ∞∑ n=0 x a+n Γ(a) Γ(a + n + 1) . When a is an integer, this reduces to the answer in the text. 13.6.2. (a) Starting with the case m = 1, d dx [ x−aγ(a, x) ] = −ax −a−1γ(a, x) + x−ax a−1e −x . CHAPTER 3. EXERCISE SOLUTIONS 187 Using the formula of Exercise 13.6.3(a), the above simpliﬁes to d dx [ x −aγ(a, x ] ) = −x −a−1γ(a + 1, x) . Applying this result m times in succession yields the formula to be proved. (b) Start with d dx [ e xγ(a, x) ] = e xγ(a, x) + xa−1e −x . Substitute the formula of Exercise 13.6.3(a), with a changed to a − 1, thereby reaching d dx [ e xγ(a, x) ] = (a − 1)e xγ(a − 1, x) . Applying this result m times in succession, we get dm dxm [ e xγ(a, x) ] = (a − 1)(a − 2) · · · (a − m) e xγ(a − m, x) , equivalent to the formula given in the text. 13.6.3. (a) The integration by parts exhibited as the ﬁrst equation in the solution to Exercise 13.6.1 is equivalent to the formula to be proved, as it can be γ(a, x) = xae −x a + γ(a + 1, x) a . (b) This result can be proved via an integration by parts. It can also be conﬁrmed by adding together the formulas of parts (a) and (b) of this exercise. Applying Eq. (13.74), the addition yields the familiar functional relation Γ(a + 1) = aΓ(a). 13.6.4. In Eq. (13.73) deﬁning Γ(a, x), change the integration variable to u, with t = u + x and the integral now for u from zero to inﬁnity. Then Γ(a, x) = ∫ ∞ 0 (u + x) a−1e −u−x du = x a−1e −x ∫ ∞ 0 (1 + u x )a−1 e −u du . We now introduce the binomial expansion for (· · · ) a−1; because the ex- pansion does not converge for all u (for nonintegral a), further steps will lead to an asymptotic formula. We get Γ(a, x) ∼ xa−1e −x ∞∑ n=0 (a − 1 n ) 1 xn ∫ ∞ 0 une −u du . The integral evaluates to n! and yields the required answer when combined with the binomial coeﬃcient. The alternate form involving a Pochhammer symbol follows immediately from the formula Γ(a) = (a − n)nΓ(a − n). CHAPTER 3. EXERCISE SOLUTIONS 188 13.6.5. The ratio of successive terms is term n − 1 term n = n x n − q p + n p + n − 1 . This ratio approaches x as a limit for large n, so the series converges for x < 1. For x = 1 the ratio test is indeterminate, and we resort to the Gauss test. The expansion of this ratio in powers of 1/n is 1 + (q + 1)/n + · · · ; since the coeﬃcient of 1/n is larger than unity this series converges at x = 1. 13.6.6. Starting from E1(z) = ∫ ∞ z e −t t dt , note that E1(ix) = ∫ ∞ ix e −t t dt = ∫ ∞ x e −it it d(it) = ∫ ∞ x e −it t dt = ∫ ∞ x cos t − i sin t t dt = −Ci(x) + i si(x). This is the answer to part (c). Replacing i by −i in this formula, to get E1(−ix) = −Ci(x) − i si(x) , we can form E1(ix) − E1(−ix) to obtain the answer to part (a) or add these quantities to prove the result of part (b). 13.6.7. (a) For small x, the leading term in the series expansion of γ(a, x) is, from Eq. (13.76), xa/a. Use this initial term for γ(3, 2r) and rewrite Γ(2, 2r) as Γ(2) − γ(2, 2r) so that we can use the initial term of γ(2, 2r). We then have γ(3, 2r) 2r + Γ(2, 2r) = γ(3, 2r) 2r + Γ(2) − γ(2, 2r) = (2r) 2 3 + 1 − (2r) 2 2 = 1 − 2r2 3 . This result corresponds to the answer we require. (b) For large r, Γ(2, 2r) becomes negligible, while γ(3, 2r) approaches Γ(3) = 2!. Therefore, as required, γ(3, 2r) 2r + Γ(2, 2r) → 2! 2r = 1 r . 13.6.8. (a) For small x, the leading term in the series expansion of γ(a, x) is, from Eq. (13.76), xa/a. Use this initial term for γ(5, r) and γ(7, r) and rewrite CHAPTER 3. EXERCISE SOLUTIONS 189 Γ(4, r) = Γ(4) − γ(4, r)and r2Γ(2, r) = r2Γ(2) − r2γ(2, r). We then have (to terms through order r2) 1 r γ(5, r) + Γ(4, r) = O(r4) + 3! − O(r4) ≈ 6 , 1 r3 γ(7, r) + r2Γ(2, 4) = O(r4) + 1! r2 + O(r4) ≈ r2 . When these expressions are substituted into the form for V (r) we recover the answer in the text. At large x, γ(a, r) ≈ Γ(a) and Γ(a, r) goes to zero as e −r. Therefore 1 r γ(5, r) + Γ(4, r) ≈ 4! r = 24 r , 1 r3 γ(7, r) + r2Γ(2, 4) ≈ 6! r3 = 120 · 6 r3 . When these expressions are substituted into the form for V (r) we recover the answer in the text. 13.6.9. This is shown in Eqs. (13.81), (13.82) and (13.73). 13.6.10. Write the formula given in the exercise as E1(z) = ∫ ∞ 0 e −z(1+t) 1 + t dt and make a change of variable to u = z(t + 1), with dt = du/z. The range of u is (z, ∞), and our formula becomes E1(z) = ∫ ∞ z e −u u du , corresponding to the deﬁning equation for E1, Eq. (13.79). 13.6.11. Integrating by parts,n(x) = ∫ ∞ 1 e −xt tn dt = − e −xt xtn ∣ ∞ − n x ∫ ∞ 1 e −xt tn+1 dt = e −x x − n x En+1(x) . Rearranging, we reach the desired expression: En+1(x) = e −x n − x n En(x) . 13.6.12. En(0) = ∫ ∞ 1 dt tn = t 1−n 1 − n ∣ ∞ = 1 n − 1 , n > 1. CHAPTER 3. EXERCISE SOLUTIONS 190 13.6.13. (a) Bring the integral representation of si(x) to a more convenient term for our present purpose by writing it as si(x) = − ∫ ∞ x sin t t dt = ∫ x 0 sin t t dt − ∫ ∞ 0 sin t t dt = ∫ x 0 sin t t dt − π 2 . Now introduce the Maclaurin series for sin t and integrate termwise. The result is the answer in the text. (b) Insert the expansion of E1(x), Eq. (13.83), into the expression for Ci(x) in Eq. (13.87): Ci(x) = − 1 2 [ −γ − ln(xe iπ/2) − ∞∑ n=1 (−ix) n n · n! ] − 1 2 [ −γ − ln(xe −iπ/2) − ∞∑ n=1 (+ix) n n · n! ] = γ + ln x + ∞∑ p=1 (−1) px 2p 2p (2p)! . 13.6.14. Expanding cos t in the integral and integrating termwise, we get ∫ x 0 1 − cos t t dt = − ∞∑ n=1 (−1) nx2n (2n)(2n)! , The summation in the above equation is that found in part (b) of Exercise 13.6.13, and can therefore be identiﬁed as γ + ln x − Ci(x). 13.6.15. Insert the relation connecting the incomplete gamma functions to the iden- tity of part (a) of Exercise 13.6.2. We have initially dm dxm x−aΓ(a) − dm dxm x −aΓ(a, x) = (−1) mx −a−mΓ(a + m) − (−1) mx −a−mΓ(a + m, x) . If the identity of part (a) is also to apply for Γ(a, x), it is then necessary that dm dxm x −aΓ(a) = (−1) mx −a−mΓ(a + m) . The diﬀerentiation of x −a provides the factors necessary to convert Γ(a) into Γ(a + m), so the formula is proved. A similar approach can be used to verify that part (b) of Exercise 13.6.2 also applies for Γ(a, x). CHAPTER 3. EXERCISE SOLUTIONS 191 13.6.16. The formula indicates that n must be a nonnegative integer. Start by expanding the denominator in the integrand: 1 et − 1 = ∞∑ k=1 e −kt . Then make the substitution t = u + x; after these steps we have ∫ ∞ x tn dt et − 1 = ∞∑ k=1 ∫ ∞ 0 e −k(u+x)(u + x)n du . Next introduce the binomial expansion for (u + x)n. We get ∫ ∞ x tn dt et − 1 = ∞∑ k=1 e −kx n∑ j=0 ( n j ) x n−j ∫ ∞ 0 uje −ku du . The u integral evaluates to j!/kj+1; insertion of this value into the above equation leads directly to the problem answer. CHAPTER 3. EXERCISE SOLUTIONS 192 14. Bessel Functions 14.1 Bessel Functions of the First Kind 14.1.1. The product g(x, t)g(x, −t) = e (x/2)(t−1/t−t+1/t) = 1 = ∑ m,n Jm(x)t mJn(x)(−t) n has zero coeﬃcients of t m+n for m = −n ̸= 0. This yields 1 = ∞∑ n=−∞ J 2 n(x) = J 2 0 (x) + 2 ∞∑ n=1 J 2 n(x) , using (−1)nJ−n = Jn. For real x the inequalities follow. 14.1.2. The Bessel function generating function satisﬁes the indicated relation. (a) Therefore, using Eq. (14.2), ∞∑ n=−∞ Jn(u + v)t n = ∞∑ ν=−∞ Jν(u)tν ∞∑ µ=−∞ Jµ(v)tµ . Equating the coeﬃcients of t n on the two sides of this equation, which for the right-hand side involves terms for which µ = n − ν, so Jn(u + v) = ∞∑ ν=−∞ Jν(u)Jn−ν(v) . (b) Applying the above formula for n = 0, note that for |ν| ̸= 0, the summation contains the two terms Jν(u)J−ν(v) and J−ν(u)Jν(v). But because for any x, J−ν(x) = (−1)νJν(x), both these terms are equal, with value (−1) νJν(u)Jν(v). Combining them yields the answer to this part of the exercise. 14.1.3. The generating function remains unchanged if we change the signs of bothand t,and therefore ∞∑ n=−∞ Jn(x)t n = ∞∑ n=−∞ Jn(−x)(−t)n = (−1) nJn(−x)tn . For this equation to be satisﬁed it is necessary that, for all n, Jn(x) = (−1) nJn(−x). 14.1.4. (a) d dx [x nJn(x)] = nx n−1Jn(x) + x nJ ′ n(x) = x n 2 [ 2n x Jn(x) + 2J ′ n(x) ] . CHAPTER 3. EXERCISE SOLUTIONS 193 Replace (2n/x)Jn(x) using Eq. (14.7) and 2J ′ n(x) using Eq. (14.8): d dx [x nJn(x)] = x n 2 [Jn−1(x) + Jn+1(x) + Jn−1(x) − Jn+1(x)] = xnJn−1(x) . (b) d dx [ x −nJn(x) ] = −nx −n−1Jn(x) + x−nJ ′ n(x) = x −n 2 [− 2n x Jn(x) + 2J ′ n(x) ] . Replace −(2n/x)Jn(x) using Eq. (14.7) and 2J ′ n(x) using Eq. (14.8): d dx [ x −nJn(x) ] = x −n 2 [−Jn−1(x) − Jn+1(x) + Jn−1(x) − Jn+1(x)] = −x −nJn+1(x) . (c) Start from Eq. (14.8) with n replaced by n + 1, and use Eq. (14.7) to replace Jn+2(x) by its equivalent in terms of Jn+1 and Jn: 2J ′ n+1(x) = Jn(x) − Jn + 2(x) = Jn(x) − 2(n + 1) x Jn+1(x) + Jn(x) . Collecting terms and dividing through by 2 yields the desired result. 14.1.5. In the generating function for the Jn as given in Eq. (14.2), make the substitution t = ie iϕ, leading (with x replaced by ρ) to the formula e (ρ/2)(ieiϕ−1/ieiϕ) = e iρ cos ϕ = ∞∑ m=−∞ Jm(ρ) [ ie iϕ]m , equivalent to the required expansion. 14.1.6. Set ϕ = 0 in the plane wave expansion of Exercise 14.1.5 and separate into real and imaginary parts. This yieldse ix = ∞∑ m=−∞ imJm(x), cos x = J0(x) + 2 ∞∑ m=1(−1) mJ2m(x) ; (b) sin x = 2 ∞∑ m=0(−1)mJ2m+1(x) , using J−2m−1 = −J2m+1, i−2m−1 = −(−1) mi. 14.1.7. Following the procedure outlined in the hint, we have after step (b) t ∞∑ n=−∞ tn−1Jn − 1(x) + t−1 ∞∑ n=−∞ t n+1Jn + 1(x) = ∞∑ n=−∞ 2n x t nJn(x) . CHAPTER 3. EXERCISE SOLUTIONS 194 Writing as in part (c) and separating variables in the resulting ODE: dg g = x 2 (1 + t−2) dt , with solution ln g = x 2 ( t − 1 t ) + C0(x) −→ g = C(x) e (x/2)(t−1/t) , where C(x) = exp(C0(x)) is an integration constant. The coeﬃcient of t0 can be found by expanding e xt/2 and e −x/2t separately, multiplying the expansions together, and extracting the t 0 term: e xt/2e −x/2t = ∞∑ n=0 ( x 2 )n tn n! ∞∑ m=0 ( x 2 )m t −m m! −→ ∞∑ n=0 ) − 1) n n! n! ( x 2 )2n t0+· · · . This is the series expansion of J0(x), so we set C(x) = 1. 14.1.8. Write out the term containing x ν+2s+1 in Jν±1(x), (2ν/x)Jν(x), and 2J ′ ν(x): Jν−1(x) = · · · + (−1) s+1 (s + 1)!Γ(s + ν + 1) ( x 2 )ν+2s+1 + · · · Jν+1(x) = · · · + (−1) s s!Γ(s + ν + 1) ( x 2 )ν+2s+1 + · · · ( 2ν x ) Jν(x) = · · · + (−1) s+1ν (s + 1)!Γ(s + ν + 2) ( x 2 )ν+2s+1 + · · · 2J ′ ν(x) = ∞∑ s=0 (−1) s(ν + 2s) s!Γ(s + ν + 1) ( x 2 )ν+2s−1 = · · · + (−1)s+1(ν + 2s + 2) (s + 1)!Γ(s + ν + 2) ( x 2 )ν+2s+1 + · · · Note that in several of the above formulas we redeﬁned the summations so that corresponding powers of x were associated with the same index value. Combining the corresponding powers of x, the recurrence formulas are easily conﬁrmed. 14.1.9. Introduce the power-series expansions of the Bessel functions and then integrate over θ. The ﬁrst integral assumes the form sin x x = ∞∑ n=0 (−1)n n! n! x 2n 22n ∫ π/2 0 cos2n+1 θ dθ = ∞∑ n=0 (−1) n 2nn! 2nn! (2n)!! (2n + 1)!! x 2n . CHAPTER 3. EXERCISE SOLUTIONS 195 This simpliﬁes to sin x x = ∞∑ n=0 (−1) nx 2n (2n + 1)! , which is the power-series expansion of sin x/x. The second integral can be written 1 − cos x x = ∞∑ n=0 (−1)n n!(n + 1)! x2n+1 22n+1 ∫ π/2 0 cos2n+1 θ dθ = ∞∑ n=0 (−1)n 2nn! 2nn!(2n + 2) (2n)!! (2n + 1)!! x 2n+1 . This simpliﬁes to 1 − cos x x = (−1) n x2n+1 (2n + 2)! , which is the power-series expansion of the left-hand side. 14.1.10. To use mathematical induction, assume the formula for Jn is valid for index value n and then verify that, under that assumption, it is also valid for index value n + 1. Proceed by applying Eq. (14.11) with the Jn on its left-hand side given the assumed form: −x −nJn+1(x) = d dx [ x −nJn(x) ] = (−1) n d dx [( 1 x d dx )n J0(x) ] = (−1)nx ( 1 x d dx ) ( 1 x d dx )n J0(x) . This equation easily rearranges to Jn+1(x) = (−1) n+1x n+1 ( 1 x d dx )n+1 J0(x) , conﬁrming the veriﬁcation. To complete the proof by induction, we must show that the formula of this exercise is valid for n = 0; for that case it is trivial. 14.1.11. We consider for now only the zeros of Jn(x) for x > 0. Other cases can be treated by obvious extensions of the method to be used here. There must be at least one zero of J ′ n(x) between two consecutive zeros of Jn(x), and, by Eq. (14.10) this implies that at least one zero of Jn−1(x) lies in this interval. From Eq. (14.11) we may in a similar fashion conclude that at least one zero of Jn(x) lies between two consecutive zeros of Jn−1. For these observations to be mutually consistent the zeros of Jn and Jn−1 must alternate, i.e., there must be exactly one zero of Jn−1 between two consecutive zeros of Jn. CHAPTER 3. EXERCISE SOLUTIONS 196 14.1.12. Rewrite the integral of this exercise in terms of the integration variable= ur: I = 1 u2 ∫ u 0 ( 1 − x 2 u2 ) xJ0(x) dx . Then note that by Eq. (14.10) xJ0(x) = [xJ1(x)] ′, and integrate by parts. The integration that remains can also be rewritten using Eq. (14.10): I = 1 u2 [ xJ1(x) ( 1 − x 2 u2 )]u + 1 u2 ∫ u 0 ( 2x u2 ) xJ1(x) dx = 0 + 2 u4 ∫ u 0 [ x 2J2(x)]′ dx = 2 u4 u2J2(u) , equivalent to the answer we seek. 14.1.13. Write f (θ) as f (θ) = − ik 2π ∫ R 0 ρ dρ ∫ 2π 0 dϕ[ cos(kρ sin θ sin ϕ) + i sin(kρ sin θ sin ϕ) ] . From Eqs. (14.18) and (14.19) with n = 0, note that the integral of the cosine has value 2πJ0(kρ sin θ), and the integral of the sine vanishes. We now make a change of variable from ρ to x = kρ sin θ, and then note, applying Eq. (14.10), that xJ0(x) = [xJ1(x)] ′, so f (θ) = − i k sin 2 θ ∫ kR sin θ 0 xJ0(x) dx = − i k sin 2 θ [ xJ1(x)] kR sin θ 0 = − iR sin θ J1(kR sin θ) . We now form |f (θ)|2, obtaining the desired result. 14.1.14. (a) We perform operations similar to those used to obtain Eq. (14.13). To do so it will be convenient to have a formula similar to that of Eq. (14.12). Adding or subtracting the two recurrence formulas of this exercise, we Cn(x) = C ′ n±1(x) ± n ± 1 x Cn±1(x) . Now we form x2C ′′ n as x 2/2 times the derivative of the second recurrence formula of this exercise, xC ′ n from that second recurrence formula times x/2, and n2Cn by multiplying the ﬁrst recurrence formula by nx/2. In this way we reach x 2C ′′ n + xC ′ n − n2Cn = x 2 2 [ C ′ n−1 − n − 1 x Cn−1 + C ′ n+1 + n + 1 x Cn+1 ] . CHAPTER 3. EXERCISE SOLUTIONS 197 Using the formula derived earlier in this problem solution, the right-hand side of the above equation simpliﬁes to x 2Cn, so we have x 2C ′′ n(x) + x2C ′ n(x) − (x 2 + n2) Cn(x) = 0 . This is the linear ODE we seek. (b) The ODE found in part (a) becomes the Bessel equation if we make the change of variable t = ix. This substitution causes x 2(d2/dx 2) → t2(d2/dt2) and x(d/dx) → t(d/dt), but x2 → −t2, so t2 d2 dt2 Cn(it) + t d dt Cn(it) + (t2 − n2) Cn(it) = 0 . 14.1.15. (a) Using the Schlaeﬂi integral representation and writing only the inte- grand, we have J ′ ν(x) −→ 1 2 ( t − 1 t ) e (x/2)(t−1/t) tν+1 , J ′′ ν (x) −→ 1 4 ( t − 1 t )2 e (x/2)(t−1/t) tν+1 , x 2J ′′ ν (x) + xJ ′ ν(x) + (x 2 − ν2)Jν(x) −→ [ x2 4 ( t − 1 t )2 + x 2 ( t − 1 t ) + x2 − ν2] e (x/2)(t−1/t) tν+1 −→ [ x2 4 ( t + 1 t )2 + x 2 ( t − 1 t ) − ν2] e (x/2)(t−1/t) tν+1 . Evaluating the derivative in Eq. (14.38), again writing only the integrand, d dt { e (x/2)(t−1/t) tν [ ν + x 2 (t + 1 t )]} = e (x/2)(t−1/t) tν {(− ν t ) [ν + x 2 ( t + 1 t )] + x 2 ( 1 − 1 t2 ) + x 2 ( 1 + 1 t2 ) [ν + x 2 ( t + 1 t )]} These two expressions are now easily shown to be equal, permitting us to proceed to the analysis following Eq. (14.38). The representation given in the text as an integral over s can be reached CHAPTER 3. EXERCISE SOLUTIONS 198 from the Schlaeﬂi integral by changing the integration variable to s = xt/2. Then ds = (x/2) dt. The contour in s is the same as the contour for t. (b) Make the change of variable t = e iθ. Then dt = ie iθ; because n is integral, there is no cut and the integral is a counterclockwise traverse of the unit circle; the limits on θ are 0 and 2π. The exponential now becomes (x/2)(e iθ − e −iθ) = ix sin θ. Also, dt/tn+1 = ie −inθ dθ. With these changes, we recover the ﬁrst integral of part (b) for Jn. Make now a further change of variable to θ′ = (π/2)−θ; then sin θ = cos θ′ and −nθ = −n(π/2) + nθ′. Noting that e −nπ/2 = i −n, we obtain the ﬁnal formula of part (b). 14.1.16. The contour consists of three parts: (1) z = e −iπ+u, with u ranging from +∞ to zero; (2) z = e iθ, with θ ranging from −π to π; and (3) z = e iπ+u, with u ranging from zero to +∞. The ﬁrst contour integral of Exercise 14.1.15 is therefore the sum of the following three integrals: Range (1): 1 2πi ∫ 0 ∞ e (x/2)(e−iπ+u−eiπ−u) (e−iπ+u)ν+1 e −iπ+u du , Range (2): 1 2πi ∫ π −π e (x/2)(eiθ−e−iθ) eiθ(ν+1) ie iθ dθ , Range (3): 1 2πi ∫ ∞ 0 e (x/2)(eiπ+u−e −iπ−u) (eiπ+u)ν+1 e iπ+u du . Introducing trigonometric and hyperbolic functions where appropriate, and adding together the three contributions to the overall contour integral,I, we reach I = e iνπ 2πi ∫ 0 ∞ e −x sinh u−νu du + 1 2π ∫ π −π e ix sin θ−iνθ dθ + e −iνπ 2πi ∫ ∞ 0 e −x sinh u−νu du . The ﬁrst and third integrals can now be combined to yield 1 π ∫ ∞ 0 e −vu−x sinh u [ −e iνπ + e −iνπ 2i ] du , which reduces to − sin(νπ) π ∫ ∞ 0 e −vu−x sinh u du . The second integral can be expanded into real and imaginary parts. Rec- ognizing symmetry, the imaginary part is seen to vanish, while the real CHAPTER 3. EXERCISE SOLUTIONS 199 part can be written as twice an integral over half the original range: 1 2π ∫ π −π [cos(x sin θ − νθ) + i sin(x sin θ − νθ)] dθ = 1 π ∫ π 0 cos(x sin θ − νθ) dθ . Putting together the above results, we obtain Bessel’s integral. 14.1.17. (a) Expand cos(x sin θ): Jν(x) = 2 π1/2Γ(ν + 1 2 ) ( x 2 )ν ∞∑ k=0 (−1)kx 2k (2k)! ∫ π/2 0 sin 2k θ cos2ν θ dθ = 2 π1/2Γ(ν + 1 2 ) ( x 2 )ν ∞∑ k=0 (−1)kx 2k (2k)! Γ(k + 1 2 ) Γ(ν + 1 2 ) 2 Γ(k + ν + 1) . Writing Γ(k + 1 2 ) = π1/2(2k − 1)!!/2 k, substituting for the double factorial from Eq. (1.76) and simplifying, Jν(x) = ∞∑ k=0 (−1) k k! Γ(k + ν + 1) ( x 2 )ν+2k , the series expansion of Jnu(x). (b) Change the integration variable to χ = π/2 − θ and therefore change sin θ and cos θ respectively to cos χ and sin χ. The integrand is now sym- metric about π/2 so the integration range can be extended to (0, π) and the result then divided by 2. This establishes the ﬁrst formula of part (b). The second formula follows because the real part of e ±ix cos θ is cos(x cos θ and the integral of the imaginary part, ± sin(x cos θ), vanishes by symme- try. The last formula of part (b) follows directly from the change of integration variable to p = cos θ, taking note that dp = − sin θ dθ. 14.1.18. (a) Diﬀerentiate the integral representation of this exercise with respectx. Diﬀerentiation of the factor (x/2) ν returns the original integral, but multiplied by ν/x. Diﬀerentiation of the x dependence within the integral causes the integrand to be multiplied by −x/2t. That factor causes the expression to represent −Jν+1. (b) Diﬀerentiation of the integral representation with respect to x causes us to reach J ′ ν(x) = 1 2πi ∫ C 1 2 ( t − 1 t ) t −ν−1 e (x/2)(t−1/t) dt . CHAPTER 3. EXERCISE SOLUTIONS 200 Expanding the integrand into its two terms, we identify them respectivelyJν−1/2 and Jν+1/2, conﬁrming the desired result. 14.1.19. Diﬀerentiating the integral representation of Jn(x), we get J ′ n(x) = 1 π ∫ π 0 sin(nθ − x sin θ) sin θ dθ . In the integral representations of Jn±1(x), introduce the trigonometric formulas cos[(n ± 1)θ − x cos θ] = cos θ cos(nθ − x sin θ) ∓ sin θ sin(nθ − x sin θ) . When we form Jn−1 − Jn+1, the cos θ terms cancel and the sin θ terms add, giving the desired result. 14.1.20. Write J0(bx) as its series expansion, and integrate termwise, recognizing the integrals as factorials. Considering for the moment the case a > b > 0, we have∞ 0 e −axJ0(bx) dx = ∞∑ n=0 (−1) nb2n 22nn! n! ∫ ∞ 0 e −axx 2n dx = ∞∑ n=0 (−1)nb 2n 22nn! n! (2n)! a2n+1 = 1 a ∞∑ n=0 (−1) n(2n)! (2n)!!(2n)!! ( b 2 a2 )n = 1 a ∞∑ n=0 (−1)n(2n − 1)!! (2n)!! ( b 2 a2 )n . We now identify the ﬁnal form of the summation as the binomial expansion ( 1 + b 2 a2 )−1/2 = ∞∑ n=0 ( −1/2 n ) ( b2 a2 )n , where, from Eq. (1.74), the binomial coeﬃcient has the value ( −1/2 n ) = (−1) n(2n − 1)!! (2n)!! . Inserting the value of the summation and multiplying it by 1/a, we obtain ∫ ∞ 0 e −axJ0(bx) dx = 1 (a2 + b2)1/2 . This result can now be analytically continued to the entire region for which the integral representation converges. 14.1.21. Expand the integrand: F (θ) = cos(x sin θ − nθ) = cos(x sin θ) cos(nθ) + sin(x sin θ)sin(nθ) . Compare the above with the result if θ is replaced by 2π − θ: F (2π−θ) = cos(x sin[2π−θ]) cos(n[2π−θ])+sin(x sin[2π−θ])sin(n[2π−θ]). CHAPTER 3. EXERCISE SOLUTIONS 201 Now note that sin(2π − θ) = − sin θ, cos(n[2π − θ]) = cos(nθ), and sin(n[2π − θ]) = − sin(nθ), so the above equation becomes F (2π − θ) = cos(−x sin θ) cos(nθ) − sin(−x sin θ) sin(nθ) = cos(x sin θ) cos(nθ) + sin(x sin θ) sin(nθ) = F (θ) . This relation causes the integral from π to 2π to be equal to the integral from 0 to π, thereby conﬁrming the desired result. 14.1.22. (a) The minima occur at the zeros of J1[(2πa/λ) sin α]. The ﬁrst two zeros of J1(x) are x = 3.8317 and 7.0156. See Table 14.1. (b) The contribution to the intensity for Bessel-function argument x in the region (0, x0) is (because the aperture is circular and the element of area is proportional to x) Intensity (0, x0) ∼ ∫ x0 0 [ J1(x) x ]2 x dx = ∫ x0 0 J1(x) 2 dx x . The total intensity is the integral of Φ 2 over the entire diﬀraction pattern, which if a/λ is small can be approximated by setting x0 = ∞. The integral in question is elementary, with value ∫ x0 0 [J1(x)] 2 dx x = − 1 2 [ J0(x) 2 + J1(x) 2] x0 0 ∼ 1 − J0(x0) 2 − J1(x0) 2 . Using the above expression, the total intensity of the diﬀraction pattern corresponds to unity, while that out to the ﬁrst zero of J1 will correspond to 1 − J0(3.8317)2 = 0.838. This, therefore, is the fraction of the intensity in the central maximum. 14.1.23. In the ﬁrst integral, replace J2(x)/x by (−J1(x)/x) ′: 2 ∫ 2ka 0 J2(x) x dx = −2 [ J1(x) x ]2ka 0 = − J1(2ka) ka + 1 , where the +1 results from the lower limit because limx→0 J1(x)/x = 1/2. We now rewrite the second integral as − 1 2ka ∫ 2ka 0 J2(x) dx = − 1 2ka ∫ 2ka 0 [J0(x) − 2J ′ 1(x)] dx = − 1 2ka ∫ 2ka 0 J0(x) dx + J1(2ka) ka . Combining these forms of the two integrals, the J1 terms cancel, leaving the result given for part (b) of the exercise. To reach the result for part CHAPTER 3. EXERCISE SOLUTIONS 202 (a), replace J0 in the integrand of the answer for part (b) by 2J ′ 1 + J2, then replace J2 by 2J ′ 3 + J4, and continue indeﬁnitely, to reach T = 1 − 1 ka ∫ 2ka 0 [J ′ 1(x) + J ′ 3(x) + · · · ] dx . The integrals evaluate to J1(2ka) − J1(0) + J3(2ka) − J3(0) + · · · ; since all these Jn(x) vanish at x = 0, we recover the answer given for part (a). 14.1.24. Solve by the method of separation of variables, taking U = P (ρ)Φ(ϕ)T (t). The separated equations are 1 v2 d2T dt2 = −k2 , d2Φ dϕ2 = −m 2 , d2P dρ2 + 1 ρ dP dρ − m 2 ρ2 P = −k2P . The t equation has solution b1e iωt + b2e −iωt, with k2 = ω2/v2. The ϕ equation has solution c1e imϕ + c2e −imϕ, with m an integer to assure con- tinuity at all ϕ. The ρ equation is a Bessel ODE in the variable kρ, with solution Jm(kρ) that is nonsingular everywhere on the membrane. The function Jm(kρ) must vanish at ρ = a, so the points ka must be zeros of Jm. The exercise asks for the allowable values of k, to which the foregoing provides an answer. More relevant is that these values of k determine the values of ω that are the oscillation frequencies of the membrane. If αmn is the nth zero of Jm, then kn = αmn/a and ωn = αmnv/a. 14.1.25. This problem seeks periodic solutions at angular frequency ω, with time dependence e ±ωt; we then have α2 = ω2/c 2. Solving by the method of sep- aration of variables, write Bz = P (ρ)Φ(ϕ)Z(z). The separated equations are d2Z dz2 = −g2 , d2Φ dϕ2 = −m 2 , d2P dρ2 + 1 ρ dP dρ + [ (α2 − g2) − m2 ρ2 ] P = 0 . The z equation has solution C sin(pπ/l), where p must be a positive integer in order to satisfy the boundary conditions at z = 0 and z = l. The corresponding values of g2 are p2π2/l2. The ϕ equation has solutions e ±imϕ, with m an integer to assure continuity at all ϕ. The ρ equation can be written as a Bessel ODE of order m in the variable kρ, where k2 = α2 − g2; it will only have solutions with dP/dρ zero on a ﬁnite boundary if k2 > 0, and a zero derivative will then occur at ρ = a if ka = βmn, where βmn is the nth positive zero of Jm. With these values of k, we can solve for ω, getting the result given in the text. 14.1.26. In order for a wave guide to transmit electromagnetic waves it must be consistent with solutions of Maxwell’s equations that do not decay expo- nentially in the z direction (the axial direction of the wave guide). From CHAPTER 3. EXERCISE SOLUTIONS 203 Example 14.1.2 we see that the boundary conditions on the cylindrical surface of the wave guide (at radius a) require that the traveling-wave TM solutions be of the form Ez = Jm(αmjρ/a)e ±imϕe ilze −iωt , with (ω2/c 2) − l2 = (αmj/a) 2 and αmj the jth positive zero of Jm. It is necessary that l be real to avoid a decay of Ez as z increases, so the minimum possible value of ω/c consistent with an oscillatory solution in the TM mode characterized by m and j is ω/c = αmj/a. Since ω = 2πν, where ν is the frequency of the electromagnetic oscillation, we have νmin(m, j) = αmj/2πa. 14.1.28. Rewrite the integrand as x m−n−1[xn+1Jn(x)] and integrate by parts, dif- ferentiating the ﬁrst factor and using Eq. (14.10) to integrate the second factor. The result isa 0 x mJn(x) dx = x m−n−1 x n+1Jn+1(x) ∣ a−(m−n−1) ∫ a 0 xm−1Jn+1(x) dx . Whether or not m ≥ n, this process can be continued until the only integration is that of Jm+n(x). We may then use Eq. (14.8) to write ∫ a 0 Jn+m(x) dx = −2 ∫ a 0 J ′ n+m−1(x) dx + ∫ a 0 Jn+m−2(x) dx = −2Jn+m−1(x) ∣ a + ∫ a 0 Jn+m−2(x) dx , continuing until the only unintegrated quantity is either J0 or J1. (a) If n + m is odd, the ﬁnal integration is ∫ a 0 J1(x) dx = − ∫ a 0 J ′ 0(x) dx = 1 − J0(a) . (b) If n+m is even, the ﬁnal integration is ∫ a 0 J0(x) dx; this integral cannot be written as a ﬁnite linear combination of a pJq(a). 14.1.29. Write yJ0(y) = [yJ1(y)] ′ and integrate by parts, simplifying the result using the fact that the upper integration limit is a zero of J0, then replacing CHAPTER 3. EXERCISE SOLUTIONS 204 J1 by −J ′ 0 and integrating by parts a second time. ∫ α0 0 ( 1 − y α0 ) J0(y)y dy = ( 1 − y α0 ) yJ1(y) ∣ α0 0 + 1 α0 ∫ α0 0 yJ1(y) dy = − 1 α0 ∫ α0 0 yJ ′ 0(y) dy = − yJ0(y) α0 ∣ α0 0 + 1 α0 ∫ α0 0 J0(y) dy = 1 α0 ∫ α0 0 J0(y) dy . 14.2 Orthogonality 14.2.1. Write the Bessel equation of order ν, with solutions Jν(kρ) and Jν(k′ρ) as d dρ (ρ dJν(kρ) dρ ) + ( k2ρ − ν2 ρ ) Jν(kρ) = 0 , d dρ ( ρ dJν(k′ρ) dρ ) + ( k′2ρ − ν2 ρ ) Jν(k′ρ) = 0 , and form ∫ a 0 Jv(k′ρ) d dρ ( ρ dJν(kρ) dρ ) dρ = −k2 ∫ a 0 Jν(k′ρ)Jν(kρ) ρ dρ + ν2 ∫ a 0 Jν(k′ρ)Jν(kρ) ρ−1 dρ , ∫ a 0 Jv(kρ) d dρ ( ρ dJν(k′ρ) dρ ) dρ = −k′2 ∫ a 0 Jν(kρ)Jν(k′ρ) ρ dρ + ν2 ∫ a 0 Jν(kρ)Jν(k′ρ) ρ−1 dρ . Subtract the ﬁrst of these two equations from the second, reaching (k2 − k′2) ∫ a 0 Jν(kρ)Jν(k′ρ) ρ dρ = ∫ a 0 Jv(kρ) d dρ ( ρ dJν(k′ρ) dρ ) dρ − ∫ a 0 Jv(k′ρ) d dρ ( ρ dJν(kρ) dρ ) dρ . CHAPTER 3. EXERCISE SOLUTIONS 205 The ﬁrst of the two integrals on the right hand side can be converted via two integrations by parts into (plus) the second integral, so they cancel, leaving only the integrated boundary terms, which are [Jν(kρ)ρ dJν(k′ρ) dρ − ρ dJν(kρ) dρ Jν(k′ρ) ]a = ρ [Jν(kρ)k′J ′ ν(k′ρ) − kJ ′ ν(kρ)Jν(k′ρ)] ∣ a . Note the factors k and k′ that arise because now the derivatives are taken with regard to the function arguments (kρ or k′ρ). The terms from the boundary ρ = 0 vanish; those from ρ = a constitute the value of the ﬁrst Lommel integral. To evaluate the second Lommel integral, start from the equation at the bottom of page 662 of the text, which is the result of applying l’Hˆopital’s rule to the indeterminate form obtained when we divide the ﬁrst Lommel formula by k2 − k′2 and take the limit k′ → k. Note that d dk′ [ k′J ′ ν(k′a) ] = 1 a d dk′ ( k′ dJν(k′a) dk′ ) = − 1 a ( a 2k′ − ν2 k′ ) Jν(k′a) , a result of the same type as the ﬁrst formulas of this exercise solution (but now with k′ the variable). Substituting into the equation on page 662, and setting k′ = k, we obtain ∫ a 0 ρ [Jν(kρ)] 2 dρ = Jν(ka) ( −a2k + ν2 k ) Jν(ka) − ka 2 [J ′ ν(ka)] 2 −2k . This expression reduces to the value given for the second Lommel integral. 14.2.2. (a) From Exercise 14.2.1, with k = βνm/a and k′ = βνn/a, we have (for m ̸= n, and therefore k ̸= k′) ∫ a 0 Jν(ka))Jν(k′a)ρ dρ = a k2 − k′2 [k′Jν(ka)J ′ v(k′a) − kJ ′ ν(ka)Jν(k′a)] . But ka = βνm and therefore J ′ ν(ka) = 0, and k′a = βνn and therefore J ′ ν(k′a) = 0, so the right-hand side of the above equation vanishes, estab- lishing the result of part (a). (b) This normalization integral is a case of the second Lommel integral of Exercise 14.2.1. In the value given for that integral, the J ′ ν(ka) term vanishes because ka = βνm, leaving only the second term, which is the desired answer. 14.2.3. This result is proved in Exercise 14.2.1. CHAPTER 3. EXERCISE SOLUTIONS 206 14.2.4. The equation referenced in this exercise should have been Eq. (14.44). Pure imaginary roots can be excluded because when z is pure imaginary, all terms of the power-series expansion have the same sign and therefore cannot sum to zero. Because all coeﬃcients in the power-series expansion are real, complex roots must occur in complex-conjugate pairs. If there were such a pair, the orthogonality integral would involve |Jν| 2 and could not be zero; hence a contradiction. 14.2.5. (a) This is an expansion in functions that are orthogonal, but not normal- ized. The coeﬃcients are therefore given as cνm = ⟨Jν(ανmρ/a)|f (ρ)⟩ ⟨Jν(ανmρ/a)|Jν(ανmρ/a)⟩ . The normalization integral in the denominator has the value given in Eq. (14.46). (b) This is also an expansion in functions that are orthogonal, but not normalized; see Exercise 14.2.2. A formula similar to that of part (a) ap- plies, but the Bessel function arguments are βνmρ/a. The normalization integral in the denominator has the value given in the solution to Exercise 14.2.6. Take our cylinder to have radius a and to have end caps at z = ±h. The potential satisﬁes Laplace’s equation, which has the separated-variable form given in Example 14.2.1, at Eqs. (14.49)–(14.51). As in the example, the ODE for P (ρ) has solutions that are Bessel functions Jm(lρ), with l chosen to make Jm(la) = 0; thus, l must have one of the values αmj/a, where j refers to the jth positive zero of Jm. The general solution for Zl is a linear combination of e ±lz; that consistent with the symmetry of the present problem is cosh lz. The most general solution that vanishes on the curved surface and satisﬁes the problem symmetry is ∑ mj cmjJm(αmjρ/a) e imϕ cosh(αmjz/a) . We must now choose the coeﬃcients cmj so as to reproduce the potential ψ(ρ, ϕ) at z = h (and, by symmetry, also at z = −h). This requirement corresponds to ψ(ρ, ϕ) = ∑ mj cmjJm(αmjρ/a) e imϕ cosh(αmjh/a) . Exploiting the orthogonality of the Φm(ϕ) and of the Bessel functions (as CHAPTER 3. EXERCISE SOLUTIONS 207 in Example 14.2.1), we ﬁnd cmj = [ πa 2 cosh(αmjh/a)J 2 m+1(αmj) ]−1 × ∫ 2π 0 dϕ ∫ a 0 ψ(ρ, ϕ)Jm(αmjρ/a)e −imϕρ dρ . 14.2.7. Substitute the Bessel series for f (x) into the integral for the Parseval relation and invoke orthogonality of the Bessel functions: ∫ 1 0 [f (x)] 2 dx = ∞∑ n=1 ∞∑ n′=1 anan′ ∫ 1 0 Jm(αmn)x)Jm(αmn′x) x dx = ∞∑ n=1 a 2 ∫ 1 0 [Jm(αmn)] 2 dx . Now invoking Eq. (14.46) with a = 1, we recover the desired result. 14.2.8. Following the hint, we write x m = ∞∑ n=1 anJm(αmn(x) . We now evaluate the coeﬃcients an: an = ∫ 1 0 x mJm(αmn(x) x dx 1 2 [Jm+1(αmn)] 2 . The integrand of the numerator can be identiﬁed as a derivative using Eq. (14.10), which in the present context can be written d d(αx) [ (αx) m+1Jm+1(αx) ] = (αx)m+1Jm(αx) −→ 1 α d dx [ x m+1Jm+1(αx) ] = x m+1Jm(αx) . Inserting this expression and thereby evaluating the integral, we get an = Jm+1(αmn)/αmn [Jm+1(αmn)] /2 = 2 αmnJm+1(αmn) . CHAPTER 3. EXERCISE SOLUTIONS 208 Next, also as suggested by the hint, we form the Parseval integral1 0 x m x m x dx = 1 2m + 2 = ∞∑ n=1 ∞∑ n′=1 anan′ ∫ 1 0 Jm(αmnx)Jm(αmn′x) x dx = ∞∑ n=1 a2 ∫ 1 0 [Jm(αmnx)] 2 x dx = 1 2 ∞∑ n=1 a2 [Jm+1(αmnx)] 2 . Finally. we insert the expression previously found for an, reaching 1 2(m + 1) = 1 2 ∞∑ n=1 4 α2 mn , equivalent to the answer we seek. 14.3 Neumann Functions 14.3.1. Use the recursion relations, Eqs. (14.7) and (14.8), which are obeyed for both positive and negative ν. Changing ν to −ν, we have J−ν−1(x) + J−ν+1(x) = − 2ν x J−ν(x) , J−ν−1(x) − J−ν+1(x) = − 2ν x J ′ ν(x) . Hence Yν+1 + Yν−1 = cos(ν + 1)πJν+1 − J−ν−1 sin(ν + 1)π + cos(ν − 1)πJν−1 − J−ν+1 sin(ν − 1)π = cos νπ(Jν+1 + Jν−1) sin νπ + J−ν−1 + J−ν+1 sin νπ = cos νπ(2ν/x)Jν sin νπ + (−2ν/x)J−ν sin νπ = 2ν x Yν . The second recursion is proved similarly. 14.3.2. Proceed by mathematical induction using the recursion formula Yn−1(x) + Yn+1(x) = 2n x Yn(x), which is valid for both positive and negative n. Assume that Y−k(x) = (−1)kYk(x) CHAPTER 3. EXERCISE SOLUTIONS 209 for k = n and k = n − 1. Then use the above recurrence formula to form Y−n−1(x) from Y−n(x) and Y−n+1(x): Y−n−1 = (−2n) x Y−n − Y−n+1 = (−2n x (−1)nYn(x) − (−1)n−1Yn−1 = (−1) n+1 [ 2n x Yn − Yn−1 ] = (−1) n+1Yn+1 . To complete the proof we need to establish the two starting values Y0(x) = (−1) 0Y0(x) (which is trivial), and Y1(x) = −Y−1(x), which follows directly from the recurrence formula ﬁrst mentioned above with n = 0. 14.3.3. From Exercise 14.3.2 we know that Y−1(x) = −Y1(x). Using this result, the second formula in Exercise 14.3.1 with n = 0 yields −2J1(x) = 2J ′ 0(x), equivalent to the result we seek. 14.3.4. The left-hand side of the formula of this exercise is the Wronskian W of the two solutions. For an ODE in the form y′′ + P (x)y′ + Q(x)y = 0, we found in Section 7.6 that its Wronskian has the form W (x) = A exp ( − ∫ x P (x1) dx1 ) , where A is independent of x. Applying this formula to Bessel’s equation, for which P (x) = x −1, we have ∫ x P (x1) dx1 = ln x , exp(− ln x) = 1 x , and the constant A in the Wronskian formula may depend upon the spe- ciﬁc solutions X and Z and on the index ν. 14.3.5. In principle we need to begin by verifying that the left-hand side of the ﬁrst of the two formulas given for this exercise is actually a Wronskian. From Eq. (14.12), with (1) n = −ν + 1 and the minus sign of the symbol ±, and (2) n = ν − 1 and the plus sign of the symbol ±, we get (1) J−ν+1 = −J ′ −ν + −ν x J−ν , (2) Jν−1 = J ′ ν + ν x Jν . Inserting these expressions into the ﬁrst formula of the exercise and noting that two terms cancel, we have JνJ−ν+1 + J−νJν−1 = −JνJ ′ −ν − J−νJ ′ ν , which is indeed a Wronskian, as Jν and J−ν are solutions of the same Bessel equation. CHAPTER 3. EXERCISE SOLUTIONS 210 We now continue by observing that from Exercise 14.3.4 we know that these Wronskian formulas must have right-hand sides whose x dependence is 1/x. We may determine the coeﬃcient of 1/x by examining the lead- ing term in a power-series expansion of the left-hand side. For the ﬁrst formula, we need Jν(x) = xν 2νΓ(ν + 1) + · · · . Since the leading power of x in Jν(x) is x ν, the leading power for small x (the lowest power) will come only from the second term of the Wronskian; we get J−ν(x)Jν−1(x) = x −ν 2−νΓ(−ν + 1) x ν−1 2ν−1Γ(ν) = 2 xΓ(ν)Γ(1 − ν) . We now replace the product of gamma functions using the reﬂection for- mula, Eq. (13.23), reaching the result given in the text. Inserting the deﬁnition of Yν into the second Wronskian formula of the exercise and noting that two terms cancel, we get JνY ′ ν − J ′ νYν = −JνJ ′ −ν + J ′ νJ−ν sin νπ , which can be further simpliﬁed by using Eq. (14.67) to replace the numer- ator by 2 sin νπ/πx. The result is the answer given in the text. 14.3.6. Since the power-series expansions of Jν(x) involve powers of x that increase in steps of 2 and the leading power is x −1, the coeﬃcient of x 0 will vanish and we need only to conﬁrm the vanishing of the coeﬃcient of x 1. To conﬁrm this we will need to keep two terms in the expansions of the Jν and J ′ ν, and keep only the second terms of their products. The expansions of Jν and J ′ −ν are Jν(x) = (x/2) ν Γ(ν + 1) − (x/2)ν+2 1!Γ(ν + 2) + · · · , J ′ −ν(x) = − ν x (x/2) −ν Γ(1 − ν) + ν − 2 x (x/2) −ν+2 1!Γ(2 − ν) + · · · . Showing explicitly only the x1 term in the product of these functions, JνJ ′ −ν = · · · + x 4 [ 1 Γ(ν + 1) ν − 2 Γ(2 − ν) + ν Γ(1 − ν) 1 Γ(ν + 2) ] + · · · . The other product in the Wronskian can be obtained by replacing ν in the above expression by −ν, yielding J−νJ ′ ν = · · · + x 4 [ 1 Γ(1 − ν) −ν − 2 Γ(ν + 2) − ν Γ(ν + 1) 1 Γ(2 − ν) ] + · · · . CHAPTER 3. EXERCISE SOLUTIONS 211 The x1 contribution to the Wronskian becomes JνJ ′ −ν − J−νJ ′ ν = · · · + x 4 [ 2ν − 2 Γ(ν + 1)Γ(2 − ν) + 2ν + 2 Γ(1 − ν)Γ(ν + 2) ] + · · · . The coeﬃcient of x 1 reduces to zero. 14.3.7. Let y denote the integral of this exercise. We wish to verify that I = x 2y′′ + xy′ + x 2y = −x 2 ∫ ∞ 0 cos(x cosh t) cosh2 t dt − x ∫ ∞ 0 sin(x cosh t) cosh t dt + x2 ∫ ∞ 0 cos(x cosh t) dt = 0 . Integrate by parts the second term of the above expression, diﬀerentiatingx cosh t) and integrating cosh t. The integrated boundary terms vanish, and we have −x ∫ ∞ 0 sin(x cosh t) cosh t dt = x ∫ ∞ 0 cos(x cosh t)(x sinh t)(sinh t) dt = x 2 ∫ ∞ 0 cos(x cosh t) sinh 2 t dt . Combining this result with the other two terms, we have x 2 ∫ ∞ 0 cos(x cosh t) [ − cosh2 t + sinh 2 t + 1] dt . The integrand is identically zero. 14.3.8. Starting from the power-series expansion of Jν(x), we get ∂Jν ∂ν = ∞∑ s=0 (−1) s s!Γ(ν + s + 1) ( x 2 )2s+ν ln ( x 2 ) − ∞∑ s=0 (−1) s s! ( x 2 )2s+ν W , where W is shorthand for an expression that can be written in terms of the gamma and digamma functions: W = 1 [Γ(ν + s + 1)]2 dΓ(ν + s + 1) dν = ψ(ν + s + 1) Γ(ν + s + 1) . The term of the above equation containing ln(x/2) is just Jν(x) ln(x/2), and in the limit that ν is a positive integer, the ﬁrst equation above sim- pliﬁes to ( ∂Jν ∂ν ) ν=n = Jn ln(x/2) − ∞∑ s=0 (−1) sψ(n + s + 1) s!(s + n)! ( x 2 )2s+n . CHAPTER 3. EXERCISE SOLUTIONS 212 Similar processing of (∂J−ν/∂ν produces ( ∂J−ν ∂ν ) ν=n = −J−n ln(x/2) + ∞∑ s=0 (−1)s s! ( x 2 )2s−n lim k→s−n ψ(k + 1) Γ(k + 1) . The ratio ψ/Γ is written as a limit because it is an indeterminate form for negative k. To proceed further we divide the summation in ∂J−ν/∂ν into parts s < n and s ≥ n, in the latter part changing the summation index to t = s−n and the associated range to t = [0, ∞]. For the ﬁrst part of the summation we insert the relationship (given in the Hint) ψ(−m)/Γ(−m) → (−1) m+1m!. In addition, we write J−n = (−1) nJn. With these adjustments, we reach ( ∂J−ν ∂ν ) ν=n = (−1)n+1Jn ln(x/2) + n−1∑ s=0 (−1) s s! ( x 2 )2s−n (−1) n−s(n − s − 1)! + ∞∑ t=0 (−1)t+n (t + n)! ( x 2 )2t+n ψ(t + 1) t! , which can be further simpliﬁed to (−1) n+1 ( ∂J−ν ∂ν ) ν=n = Jn ln(x/2) − n−1∑ s=0 (n − s − 1)! s! ( x 2 )2s−n − ∞∑ s=0 (−1) sψ(s + 1) s!(s + n)! ( x 2 )2s+n . We now add our ﬁnal derivative expressions and divide by π, thereby obtaining Eq. (14.61). 14.3.9. We need both the equation given in the exercise and a similar formula for−ν which we can obtain by diﬀerentiating the solution J−ν to Bessel’s ODE: x 2 d2 dx2 ( ∂J−ν ∂ν ) + x d dx ( ∂J−ν ∂ν ) + (x 2 − ν2) ∂J−ν ∂ν = 2νJ−ν . If we now form the sum of the equation given in the exercise and (−1) n+1 times the equation given above, we get x2 d2 dx2 Yn + x d dx Yn + (x 2 − n2)Yn = 2n [ Jn + (−1) n+1J−n] . The right-hand side of this equation vanishes because J−n = (−1) nJn, showing that Yn is, as claimed, a solution to Bessel’s ODE. CHAPTER 3. EXERCISE SOLUTIONS 213 14.4 Hankel Functions 14.4.1. Parts (a) through (e) of this exercise are easily proved using the Wronskian formula, Eq. (14.70): Jν(x)Y ′ ν (x) − J ′ ν(x)Yν(x) = 2 πx , together with the deﬁnitions of the Hankel functions, Eqs. (14.76) and (14.77). As an example, the formula of part (a) can be written Jν(J ′ ν + iY ′ ν ) − J ′ ν(Jν + iYν) = i(JνY ′ ν − J ′ νY ν) = i ( 2 πx ) . Similar processes prove parts (b) through (e). For parts (f) and (g) we need the relationship in Eq. (14.71). As an example, write the formula of part (g) as follows: Jν−1(Jν + iYν) − Jν(Jν−1 + iYν−1 = i(Jν−1Yν − JνYν−1) = i (− 2 πx ) . The formula of part (f) is proved similarly. 14.4.2. The solutions to both parts of this problem are justiﬁed by the discussion on pages 676 and 677 of the text. 14.4.3. The substitution s = e iπ/t maps t = 0+ into s = ∞ e iπ, t = i into s = i, and t = ∞ e iπ into s = 0+. Thus, the s and t contours are identical except that they are traversed in opposite directions, which can be compensated by introducing a minus sign. Substituting into Eq. (14.90), we have H (1) ν (x) = − 1 πi ∫ C1 e (x/2)(s−1/s) ds/s 2 (eiπ/s)ν+1 = e −νπi πi ∫ C1 e (x/2)(s−1/s) ds s−ν+1 = e −νπiH (1) −ν (x) . 14.4.5. Changing the integration variable by the substitution t = e γ, the integrals of this problem have the integrand shown. (a) The point t = 0, approached from the ﬁrst quadrant, can be trans- formed into γ = −∞ e +πi, and (for positive x) the integrand becomes negligible at that integration limit. The point t = ∞ e πi transforms into γ = +∞ + πi and the integrand of the contour integral will remain ana- lytic if we get to that endpoint on the path in the γ-plane shown as C3 in Fig. 14.11. (b) Here t = 0 is approached from the fourth quadrant, and t = ∞ e −πi transforms into γ = +∞ − πi, so the path in the γ-plane is C4. CHAPTER 3. EXERCISE SOLUTIONS 214 14.4.6. (a) In Eq. (14.90) for n = 0, make a change of variable deﬁned by t = ie s = e s+iπ/2, causing (x/2)(t − t−1 to become (x/2)(ie t − 1/ie t) = ix cosh t. Then note that dt/t = ie s ds/ie s = ds, so the integration assumes the form H (1) 0 (x) = 1 πi ∫ C′ e ix cosh s ds . To determine the contour C ′, note that t = 0 (approached from positive t) corresponds to s = −∞−iπ/2, while t = −∞ corresponds to s = ∞+iπ/2. The contour is in the upper half-plane because s = 0 corresponds to t = i. (b) Since cosh s = cosh(−s) and each point s of the contour in the right half-plane corresponds to a point −s on the contour of the left half-plane, we can restrict the integral to the right half-plane and multiply by 2. 14.4.7. (a) Since J0 is the real part of H (1) 0 (when x is real), we need only take the real part of the integral given for H (1) 0 . (b) Make a change of variable to t = cosh s, dt = sinh s ds. But sinh s = √cosh2 s − 1 = √ t2 − 1 , and we obtain the integral representation required here. 14.4.8. (a) Y0(x) is the imaginary part of the integral representation given for H (1) 0 (x). Writing H (1) 0 (x) = 2 iπ ∫ ∞ 0 [cos(x cosh s) + i sin(x cosh s)] ds, we identify the imaginary part as the formula given in part (a). (b) Change the integration variable to t = cosh s. Then dt = sinh s ds. Since sinh2 s = cosh2 s − 1 = t 2 − 1, we have ds = dt/√t2 − 1. This substitution leads to the integral of part (b). The lower limit t = 1 corresponds to s = 0. 14.5 Modiﬁed Bessel Functions 14.5.1. In the generating function formula, change x to ix and t to −it; that formula then becomes e (x/2)(t+1/t) = ∞∑ n=−∞ Jn(ix)(−it)n = ∞∑ n=−∞ i −nJn(ix)tn = ∞∑ n=−∞ In(x)tn . 14.5.2. (a) Using the expansion of Exercise 14.1.5 with ϕ = π/2, we have, setting ρ = ix, e −x cos(π/2) = 1 = ∞∑ n=−∞ i mJm(ix) e imπ/2 = ∞∑ n=−∞ (−1) mJm(ix) . CHAPTER 3. EXERCISE SOLUTIONS 215 Because J−m(ix) = (−1)mJm(ox), the summands for +m and −m cancel when m is odd but are equal when m is even and nonzero, so we have 1 = J0(ix) + 2 ∞∑ m=1 J2m(ix) = I0(x) + 2 ∞∑ m=1(−1)mI2m(x) . (b) A process similar to that for part (a), but with ϕ = 0 and ρ = −ix, yields the expansion in the text for e x. (c) Inserting −x for x in part (b) and noting that In has the parity of (−1) n, the result is immediate. (d) Using the result of Exercise 14.1.6, with ρ = ix, we have cos ix = cosh x = J0(ix) + 2 ∞∑ n=1(−1) nJ2n(ix) = I0(x) + 2 ∞∑ n=1 I2n(x) . (e)A process for sin ix = i sinh x similar to that employed in part (d) leads to the answer in the text. 14.5.3. (a) The integrand of the integral of this exercise has a pole at t = 0 whose residue is the coeﬃcient of t n in the expansion of the exponential, namely In(x). Thus the contour integral and the factor preceding it, 1/2πi, yield the required result. (b) A procedure similar to that developed at Eqs. (14.38)–(14.40) conﬁrms that the integral representation is that of Iν. 14.5.4. Expand the exponential in the integrand of the ﬁrst expression for Iν(z) in a power series; the odd powers vanish upon integration; the even powers lead to Iν(z) = 1 π1/2Γ(ν + 1 2 ) ∞∑ k=0 ( z 2 )ν+2k ∫ π 0 cos2k θ sin 2ν θ dθ . The integral is the beta function B(k + 1 2 , ν + 1 2 ), so Iν(z) = 1 π1/2Γ(ν + 1 2 ) ∞∑ k=0 ( z 2 )ν+2k Γ(k + 1 2 )Γ(ν + 1 2 ) Γ(ν + k + 1) . If we now write Γ(k + 1 2 ) = √π (2k)! 22kk! , the right-hand side of the equation for Iν(z) reduces to its power-series expansion. The second expression for Iν(z) can be obtained from the ﬁrst by the sub- stitution p = cos θ in the integral; then sin θ = (1 − p2) 1/2. CHAPTER 3. EXERCISE SOLUTIONS 216 The third expression for Iν(z) can be obtained from the ﬁrst expression if we remember that in the ﬁrst expression we could drop the odd pow- ers of z from the power-series expansion. That corresponds to replacing exp(±z cos θ) by cosh(z cos θ). After making this replacement we note that the integral from π/2 to π is equal to that from 0 to π/2, so we can use the latter integration range and append a factor 2, thereby conﬁrming the given result. 14.5.5. (a) When Laplace’s equation is written in separated-variable form in cylin- drical coordinates, the ϕ equation has periodic solutions am sin mϕ + bm cos mϕ, with m required to be an integer so that the solutions will be continuous and diﬀerentiable for all ϕ. The separation constant of the ϕ equation is −m 2. The solutions that are needed for the z equation must be zero at z = 0 and z = h; these solutions are of the form sin nπz/h, with n a positive integer; the separation constant of the z equation is therefore −n2π2/h2 ≡ −k2 n. With these separation constants, the ρ equation becomes ρ2P ′′ + ρP − (ρ2k2 n + m 2)P = 0 , showing that P must be a solution of the modiﬁed Bessel equation, of the form Im(knρ). We must choose the solution to be Im so that it will be regular at ρ = 0. The most general solution of the Laplace equation sat- isfying the ϕ and z boundary conditions is therefore a linear combination of the solutions we have found, i.e., the form shown in the exercise. (b) The unique solution also satisfying the boundary condition at ρ = a can be found using the fact that the set of sin knz are orthogonal, as is the set of functions sin mϕ and cos mϕ. Thus, if we regard V (ϕ, z) as the expansion V (ϕ, z) = ∞∑ m=0 ∞∑ n=1 Im(kna)(amn sin mϕ + bmn cos mϕ) sin knz , the coeﬃcients amn and bmn are obtained by the type of expression writ- ten as the answer to this problem. Because the functions of z and ϕ are not normalized, we must divide the integral in the answer to part (b) by the normalization integral for sin knz (which is h/2) and by that of {sin/cos}mϕ, which is π for m ̸= 0 and 2π for m = 0. After this divi- sion, we get the answer shown in the text (after making a typographical correction to change l into h). 14.5.6. Write the deﬁnition of Kν from Eq. (14.106) and insert the deﬁnition of CHAPTER 3. EXERCISE SOLUTIONS 217 Yν from Eq. (14.57): Kν(x) = π 2 i ν+1[ Jν(ix) + iYν(ix) ] = π 2 i ν+1 [Jν(ix) + i cos νπ sin νπ Jν(ix) − iJ−ν(ix) sin νπ ] = π 2 sin νπ i ν+1[ ie −iνπJν(ix) − iJ−ν(ix)] = π 2 sin νπ [ I−ν(x) + i ν+2e −iνπIν(x) ] . Noting that e −iνπ = i −2ν, we obtain the required result. 14.5.7. Here use the recurrence relations for Iv, Eq. (14.104) and (14.105), and note that sin(ν ± 1)π = − sin νπ. The veriﬁcation is then straightforward. 14.5.8. The Kν recurrence formulas diﬀer from those for Iν only in the signs of their right-hand members. If these formulas are rewritten in terms of Kν, the right-hand sides will acquire a factor e πνi while the terms on the left- hand sides will have additional factors e π(ν±1)i = −e πνi. These additions change only the relative signs of the two sides of the equations. 14.5.9. We have K0(x) = πi 2 H (1) 0 (ix) = πi 2 [ 2i π ln(ix) + 1 + 2i π (γ − ln 2) + · · · ] = − ln x − ln i + πi 2 − (γ − ln 2) + · · · . Agreement with Eq. (14.110) is only achieved if we use the principal branch of ln x and take ln i to be on the branch with value πi/2. 14.5.10. Proof of the second formula for Kν(z) is the topic of the subsection that starts on page 690 of the text, where the validity of that integral represen- tation is discussed in detail. The ﬁrst formula for Kν(z) can be obtained from the second by the substitution ρ = cosh t. 14.5.11. Write Kν(x) = (π/2)i ν+1H (1) ν (ix), Iν(x) = i −νJν(ix). Thus, Iν(x)K ′ ν(x) − I ′ ν(x)Kν(x) = iπ 2 [ Jν(ix)iH (1)′ ν (ix) − iJ ′ ν(ix)H (1) ν (ix) ] . Note the factors i that accompany the derivatives. Because notations like J ′ ν(ix) refer to derivatives with respect to the Bessel function argument (here ix), a derivative with respect to x generates an additional factor i. Now, using the Wronskian formula for Jν and H (1) ν from Exercise 14.4.1(a) CHAPTER 3. EXERCISE SOLUTIONS 218 replace the quantity within square brackets by i[2i/π(ix)], obtaining the ﬁnal result Iν(x)K ′ ν(x) − I ′ ν(x)Kν(x) = iπ 2 2i πx = − 1 x . 14.5.12. The coeﬃcient in the axial Green’s function is a constant, and we can evaluate it using any convenient value of its argument kρ. Let’s take kρ small enough that we can use the limiting forms given in Eq. (14.100) form and in Eqs. (14.110) and (14.111) for Km. For positive integers m, we have (for small x) Im = x m 2mm! + · · · , I ′ m = x m−1 2m(m − 1)! + · · · , Km = 2m−1(m − 1)! x −m + · · · , K ′ m = −2 m−1m! x −m−1 + · · · . From the above data we get K ′ mIm − KmI ′ m = −x −1; taking x = kρ and multiplying by p = kρ, we ﬁnd the coeﬃcient to be −1. The index value m = 0 is a special case. The formula for Im still applies; we get I0 = 1 + · · · , I ′ 0 = 0 + · · · . But K0 = − ln x + · · · and K ′ 0 = −x −1. We still get K ′ 0I0 − K0I ′ 0 = −x −1, leading to the coeﬃcient value −1. 14.5.13. Start from the integral representation, Eq. (14.113); multiply by cos xu and integrate with respect to x. Simpliﬁcation occurs because the integral over x deﬁnes a Dirac delta function. Thus, ∫ ∞ 0 cos(zu)K0(z) dz = ∫ ∞ 0 cos(zu) du ∫ ∞ 0 cos(zt) dt √t2 + 1 = ∫ ∞ 0 dt √t2 + 1 ∫ ∞ 0 cos(zu) cos(zt) dz = ∫ ∞ 0 dt √t2 + 1 π 2 δ(t−u) = π 2 1 √u2 + 1 . Now set u = x/y and z = yt, so zu = xt and dz = y dt. Then the ﬁrst and last members of the above equation set translate into ∫ ∞ 0 cos(xt) K0(yt) y dt = π 2 y √x2 + y2 , which is equivalent to the relation to be proved. 14.5.14. In this exercise n is assumed to be an integer. Starting from the generating function for In given in Exercise 14.5.1, divide by tn+1 and integrate in t (regarded as a complex variable) over the unit CHAPTER 3. EXERCISE SOLUTIONS 219 circle, thereby obtaining a Schlaeﬂi integral representation for In. Then write t = e iθ and take the range of θ as (−π, π). These steps lead to In(x) = 1 2πi ∮ e (x/2)(t+1/t) tn+1 dt = 1 2πi ∫ π −π e (x/2)(eiθ+e−iθ) e(n+1)iθ ie iθ dθ = 1 2π ∫ π −π e x cos θ eniθ dθ = 1 2π ∫ π −π e x cos θ(cos nθ − i sin nθ) dθ . Expanding the integrand into two terms, that involving sin nθ vanishes due to its odd symmetry, and the integration range of the cos nθ term can be changed to (0, π) with insertion of a factor 2. These steps lead to the claimed result. 14.5.15. Substituting into the modiﬁed Bessel equation and carrying out the indi- cated diﬀerentiations, we get, letting y stand for K0(z), 0 = z2y′′ + zy′ − z2y = ∫ ∞ 0 e −z cosh t [ z2 cosh2 t − z cosh t − z2] dt = ∫ ∞ 0 e −z cosh t [ z2 sinh 2 t − z cosh t] dt . Now integrate by parts the z cosh t term of the integral, diﬀerentiating e −z cosh t and integrating z cosh t. The integrated terms vanish, and the resultant integration cancels the z2 sinh 2 t term of the original integral. We thereby attain the desired zero result. 14.6 Asymptotic Expansions 14.6.1. The function relevant for the saddle-point behavior is w = (x/2)(t + 1/t). Saddle points are where w′ = 0, namely t = ±x. We cannot go through t = −1 because there is a cut there; we therefore consider only the saddle point at t = +1. Here, w = x and w′′ = x. Assuming x to be positive, arg(x) = 0, and the angle θ needed for the steepest-descents formula is, from Eq. (12.106), π/2. The slowly-varying quantity g(t) is t −ν−1; at t = 1, g(t) = 1. Inserting these data into the steepest-descents formula, Eq. (12.108), we ﬁnd Iν(x) ∼ ( 1 2πi ) e xe iπ/2√ 2π x = e x √2πx . 14.6.2. This problem can be solved by deforming the integration contour as needed to pass through a saddle point and use the steepest descents method. Tak-w = −(x/2)(s + 1/s), there is a saddle point at s = 1, where w = −x and w′′ = −x/s 3 = −x. Assuming x to be positive, arg(x) = π, and the angle θ needed for the steepest-descents formula is, from Eq. (12.106), CHAPTER 3. EXERCISE SOLUTIONS 220 zero. The slowly-varying quantity g(s) is s 1−ν; at s = 1, g(s) = 1. In- serting these data into the steepest-descents formula, Eq. (12.108), we Kν(x) ∼ 1 2 e −x√ 2π | − x| = √ π 2x e −x . 14.6.3. The modiﬁed Bessel ODE of order ν for y(z) is x2y′′ +xy′ −(z2 +ν2)y = 0. Letting y ﬁrst stand for the integral representation of In(z) and noting that, though not stated in the exercise, n is assumed to be a nonnegative integer, write z2y′′ − z2y = z2 π ∫ π 0 e z cos t(cos2 t − 1) cos(nt) dt = − z2 π ∫ π 0 e z cos t sin 2 t dt zy′ = z π ∫ π 0 e z cos t cos t cos(nt) dt . The remaining term of the ODE is processed by carrying out two successive integrations by parts, with cos nt or sin nt integrated and the remainder of the integrand diﬀerentiated. the result is −n2y = − n2 π ∫ π 0 e z cos t cos(nt) dt = − n2 π [ sin(nt) n e z cos t]π − nz π ∫ π 0 e z cos t sin t sin(nt) dt = − nz π [( − cos(nt) n ) e z cos t sin t]π − z π ∫ π 0 e z cos t [ cos t − z sin 2 t ] cos(nt) dt = − z π ∫ π 0 e z cos t [ cos t − z sin 2 t] cos(nt) dt . In writing these equations we have used the fact that the integrated end- point terms all vanish. Here is where it is necessary that n be an integer. Both integrals in the ﬁnal expression for −n2y cancel against the other terms of the ODE, indicated that the ODE is satisﬁed. The demonstration for the integral representation of Kν(z) proceeds upon entirely similar lines. Because the upper integration limit is inﬁnity, the endpoint terms in the integrations by parts vanish whether or not ν is an integer. The vanishing occurs because (for nonzero z) the factor e −z cosh t approaches zero faster than ﬁnite powers of the hyperbolic functions di- verge. CHAPTER 3. EXERCISE SOLUTIONS 221 14.6.4. (a) Diﬀerentiate the integral representation for K0(z), Eq. (14.128), to obtain dK0(z) dz = − ∫ ∞ 1 xe −zx(x2 − 1) 1/2 dx . Integrate this expression by parts, integrating x/(x 2 − 1) 1/2 and diﬀer- entiating e −zx. The integrated term vanishes, and the integral can be identiﬁed as the integral representation of −K1(z). (b) To ﬁnd the small-z behavior of K1, change the integration variable from x to u = zx, after which the integral representation for K1 takes the form1(z) = π1/2 Γ(3/2) ( z 2 ) ∫ ∞ z e −u ( u2 z2 − 1 )1/2 du z = 1 z ∫ ∞ z e −u(u2−z2) 1/2 du . In the limit of small z, the integral becomes 1!, and K1(z) ≈ 1/z. In this limit the indeﬁnite integral of K1 is therefore ln z + C, and K0(z) −→ − ln z + C, which is the scaling identiﬁed in Eq. (14.110). 14.6.5. When r ̸= 0, the quotient of two factorials occurring in Eq. (14.132) is (ν + r − 1 2 )(ν + r − 3 2 ) · · · (ν + 1 2 )(ν − 1 2 ) · · · (ν − r + 3 2 )(ν − r + 1 2 ) = (ν + r − 1 2 )(ν − r + 1 2 )(ν + r − 3 2 )(ν − r + 1 2 ) · · · (ν + 1 2 )(ν − 1 2 ) = ( 4ν2 − (2r − 1) 2 4 ) ( 4ν2 − (2r − 3)2 4 ) · · · ( 4ν2 − 1 4 ) . The term of any given r will therefore contain in its denominator 4 r which combines with the remaining factors of the summation in Eq. (14.132),/[r!(2z) r], to give the result shown in Eq. (14.133). 14.6.6. (a) The modiﬁed Bessel ODE of order ν for y(z) is L(y) = z2y′′ + zy′ − z2y − ν2y = 0 . Inserting the form given for y(z), we get initially z2y′′ = ν(ν + 1)y + 2νzν+1 ∫ (−te−zt) (t2 − 1) ν−1/2 dt + zν+2 ∫ (t 2e −zt) (t2 − 1) ν−1/2 dt , zy′ = νy + zν+1 ∫ ( −te −zt) (t2 − 1) ν−1/2 dt , and, after cancellations and minor rearrangement, we obtain(y) = zν+2 ∫ e −zt(t2 −1) ν+1/2 dt−(2ν +1)zν+1 ∫ e −zt t (t2 −1) ν−1/2 dt . CHAPTER 3. EXERCISE SOLUTIONS 222 We now integrate the ﬁrst integral of L by parts, integrating e −zt and diﬀerentiating the remainder of the integrand. The new integral obtained in this way cancels against the second integral of L, leaving only the endpoint term [ − e −zt z (t2 − 1)ν+1/2]z2 z1 . If this term is zero (i.e., has the same value at both endpoints), Bessel’s modiﬁerd ODE will be satisﬁed. 14.6.7. We only need the initial term of each asymptotic expansion. (a) From Eq. (14.144), Jν(x) ∼ √ 2 πx cos [x − (ν + 1 2 ) π 2 ] , we get the following products of cosine functions which are simpliﬁed using trigonometric identities: JνJ−ν−1 + J−νJν+1 ∼ 2 xπ cos [x − ( ν + 1 2 ) π 2 ] cos [x + ( ν + 1 2 ) π 2 ] + 2 xπ cos [x + (ν − 1 2 ) π 2 ] cos [x − (ν + 3 2 ) π 2 ] ∼ 1 xπ [cos 2x + cos ( ν + 1 2 ) π + cos(2x − π) + cos ( ν + 1 2 ) π] ∼ − 2 sin πν xπ using the cosine addition theorem. In Part (b), N should be replaced by Y . Parts (b), (c), (d) and (e) are proved similarly, using the asymptotic formsKν and H (2) ν in Eqs. (14.126) and (14.127), and for Iν and Yν the leading terms of Eqs. (14.141) and (14.143): Iν ∼ √ 1 2πz e z , Yν ∼ √ 2 πz sin [ z − ( ν + 1 2 ) π 2 ] . We also need the derivatives I ′ ν and K ′ ν, obtained by keeping the most divergent term when the leading terms of Iν and Kν are diﬀerentiated: I ′ ν ∼ Iν , K ′ ν ∼ −Kν . 14.6.8. The Green’s function for an outgoing wave with no ﬁnite boundary must have the form C H (1) 0 (k(|ρ1 − ρ2|), because this function is an outgoing- wave solution of the homogeneous Helmholtz equation that is circularly CHAPTER 3. EXERCISE SOLUTIONS 223 symmetric in ρ1 − ρ2 and satisﬁed wherever ρ1 ̸= ρ2. To ﬁnd the propor- tionality constant C, we evaluate the integral (in ρ1) of (∇2+k2)G(ρ1, ρ2) over the area enclosed by a circle of radius a centered at ρ2. Transforming the integral of ∇2 to a line integral over the circular perimeter and letting r stand for |ρ1 − ρ2|, our computation takes the form ∫ a 0 (∇2 + k2)C H (1) 0 (kr)(2πr) dr = 2πaC d dr H (1) 0 (kr) ∣ r=a + k2C ∫ a 0 H (1) 0 (kr)(2πr) dr . Because at small r H (1) 0 (kr) = 2i π ln kr + constant + · · · , the integral of H (1) 0 (kr) over the circular area vanishes, but the radial derivative term has the following small-r limit: 2πaC ( 2i πa ) = 4iC , corresponding to C = − i 4 . 14.6.9. Substitute −ix for z in Eq. (14.134), writing −ix = e −πi/2x so as to be on the same branch of Kν as that taken for real arguments as its deﬁnition. Then √ π 2(−ix) = √ π 2x e πi/4 and the veriﬁcation of Eq. )14.138) becomes immediate. 14.6.10. (a) This is veriﬁed by direct substitution.an+1 = i 2(n + 1) [v2 − (2n + 1)2 22 ]an. (c) From Eq. (14.125), we have a0 = √ 2 π e −i(ν+1/2)(π/2) . 14.6.11. The answer is given in the text. 14.6.13. The answer is given in the text. 14.7 Spherical Bessel Functions 14.7.1. Here we essentially reverse the process that was used in solving Exercise 14.6.5, writing for the term in P or Q whose largest odd integer squared CHAPTER 3. EXERCISE SOLUTIONS 224 was (2s − 1) 2, (4ν2 − 12) 4 (4ν2 − 32) 4 · · · = · · · (ν + 1 2 )(ν − 1 2 ) · · · = Γ(ν + s + 1 2 ) Γ(ν − s + 1 2 ) . Since these quantities are needed for ν = n + 1 2 , the ratio of gamma func- tions becomes a ratio of factorials: (n + s)!/(n − s)!. The sign alternation in P and Q and the presence of the i multiplying Q are both accounted for by the factor i s in Eq. (14.162). 14.7.2. Using the deﬁnitions in Eqs. (14.57) and (14.151), yn(x) = √ π 2x Yn+1/2(x) = √ π 2x cos(n + 1/2)πJn+1/2(x) − J−n−1/2(x) sin(n + 1/2)π = (−1) n+1√ π 2x J−n−1/2(x) , where we have simpliﬁed the formula using the relationships sin(n+ 1 2 )π = (−1) n and cos(n + 1 2 )π = 0. 14.7.3. Start from Eq. (14.140) for the expansion of Jν(z). Application to jn(z) is as follows:n(z) = √ π 2z Jn+1/2(z) = 1 z [ Pn+1/2(z) cos ( z − (n + 1) π 2 ) − Qn+1/2(z) sin (z − (n + 1) π 2 )] = 1 z [ Pn+1/2(z) sin (z − nπ 2 ) + Qn+1/2(z) cos (z − nπ 2 )] . The expansion of Pn+1/2(z) is that given in Eq. (14.135), but for half- integer ν the series terminates. The individual factors in the numerators of the terms of Pν involve µ = (2n+1)2 and are of forms (2n+1) 2−(2j+1) 2, which factor into (2n − 2j)(2n + 2j + 2). We now see that the series for Pν terminates when 2j reaches 2n. Taking all the above into account, and noting that each term has four more linear factors than its predecessor, the series for Pn+1/2 can be written Pn+1/2(z) = ∑ k (−1)k (2n + 4k)!! (2k)!(2z)2k24k(2n − 4k)!! = ∑ k (−1) k(n + 2k)! (2k)!(2z)2k(n − 2k)! . The second line of the above equation is reached by writing the double factorials (2p)!! = 2 pp !. The lower limit of the k summation is k = 0; the CHAPTER 3. EXERCISE SOLUTIONS 225 upper limit is the largest value of k for which the term is nonzero; from the denominator of the ﬁnal expression it is clear that contributions are restricted to k such that n − 2k ≥ 0. A similar analysis yields the formula for Qn+1/2, which, written ﬁrst using double factorials, is Qn+1/2(z) = ∑ k (−1) k (2n + 4k + 2)!! (2k + 1)!(2z)2k+124k+2(2n − 4k − 2)!! = ∑ k (−1) k(n + 2k + 1)! (2k + 1)!(2z)2k+1(n − 2k − 1)! , thereby completing the formula for jn(z). Note that the second term of the formula in the text (arising from Qn+1/2) is incorrect; the power of 2z should be 2s + 1. 14.7.4. Since ν = n + 1/2, the integral contains an integer power of (1 − p2) and therefore it will expand into integrals of forms ∫ 1 −1 p2k(cos xp ± i sin xp) dp . The imaginary parts of these integrals vanish due to symmetry; via re- peated integrations by parts (diﬀerentiating p2k) the real parts will have integrated terms dependent on cos x and/or sin x. When the integrations by parts have reduced the power of p to zero, the ﬁnal integral will also involve a trigonometric function. 14.7.5. The functions Jν, Yν, and H (i)ν all satisfy the same recurrence formulas, and all are related to the corresponding spherical Bessel functions in iden- tical ways, so a proof for jn can be extended to yn and h(i) n . From the Jν recurrence formula, Eq. (14.7), written for ν = n + 1 2 , √ 2x π jn−1(x) + √ 2x π jn+1(x) = 2(n + 1 2 x √ 2x π jn(x) , which easily simpliﬁes to the ﬁrst recurrence formula of this exercise. The second recurrence formula is a bit less trivial, since j′ n(x) = − 1 2x jn(x) + √ π 2x J ′ n+ 1 2 (x) . Using Eq. (14.8), with J n− 1 2 and J n+ 3 2 written in terms of jn±1, and also using the newly found recurrence formula to rewrite jn in terms of jn±1, our formula for j′ n reduces to the result shown in the exercise. CHAPTER 3. EXERCISE SOLUTIONS 226 14.7.6. Assume the validity of the formula given for jn(x) with n = k, and then use Eq. (14.172) to obtain a formula for jk+1(x). We have jk+1(x) = −x k d dx [ x −kjk(x) ] = −x k d dx [ (−1) k ( 1 x d dx )k ( sin x x )] = (−1) k+1xn+1 ( 1 x d dx ) [( 1 x d dx )k ( sin x x )] , which is the assumed formula for k + 1. To complete the proof by math- ematical induction, we need a starting value. For k = 0 the assumed formula is simply the explicit form for j0(x). 14.7.7. Since each spherical Bessel function is proportional to a conventional Bessel function divided by x 1/2 and since Wronskian formulas are quadratic in the Bessel functions, all spherical Bessel Wronskians must be propor- tional to conventional Bessel Wronskians divided by x, i.e., proportional to 1/x2. We can determine the proportionality constant most easily from the behavior at x → 0 or at x → ∞. For small x, the limiting behavior of jn and yn is given by Eqs. (14.177) and (14.178). Diﬀerentiating these expressions gives values for j′ n and y′ n. The four results we need are jn(x) ≈ xn (2n + 1)!! , j′ n(x) ≈ n xn−1 (2n + 1)!! , yn(x) ≈ − (2n − 1)!! xn+1 , y′ n(x) ≈ (n + 1)(2n − 1)!! xn+2 . Then our Wronskian takes the form jn(x)y′ n(x) − j′ n(x)yn(x) ≈ x n (2n + 1)!! (n + 1)(2n − 1)!! xn+2 + nx n−1 (2n + 1)!! (2n − 1)!! xn+1 = 1 x2 ( n + 1 2n + 1 + n 2n + 1 ) = 1 x2 , the result in the text. 14.7.8. Writing the Wronskian in the notation W (y1, y2) = y1y′ 2 − y′ 1y2, we note that from Exercise 14.7.7, W (jn(x), yn(x)) = 1/x 2 . Moreover, W (y2, y1) = −W (y1, y2) and W (y, y) = 0 . CHAPTER 3. EXERCISE SOLUTIONS 227 Therefore, suppressing arguments x, W (h(1), h(2)) = W (jn + iyn, jn − iyn) = −2iW (jn, yn) = − 2i x2 . 14.7.9. Introduce a power-series expansion of cos(z cos θ) in the integrand of Pois- son’s representation of jn: jn(z) = zn 2n+1n! ∞∑ k=0 (−1)kz2k (2k)! ∫ π 0 cos2k θ sin 2n+1 θ dθ . The integral can now be recognized as the beta function B(k+ 1 2 , n+1). (To make this identiﬁcation, we can start from Eq. (13.47), remove the factor 2, and extend the upper integration limit to π, because in the present case the cosine occurs to an even integer power.) The beta function can be written B(k + 1 2 , n + 1) = √π (2k)! 22kk! n! Γ(n + k + 3 2 ) . Substituting this form for the integral, we reach jn(z) = √ π 2z ∑ k=0∞ (−1) k k! Γ(n + k + 3 2 ) ( z 2 )n+2k+1/2 . This is the correct power-series expansion of jn(z). 14.7.10. From the deﬁnition, form kn(x) = 2 n+1n! πxn+1 ∫ ∞ 0 cos xt (t2 + 1)n+1 dt . Integrate the t integral by parts, integrating the factor cos xt and diﬀer- entiating the factor (t 2 + 1)−n−1. We then have kn(x) = 2 n+1n! πxn+1 ∫ ∞ 0 2(n + 1)t sin tx x(t2 + 1)n+2 dt = 2n+2(n + 1)! πxn+1 ∫ ∞ 0 t2j0(tx) (t2 + 1)n+2 dt . 14.7.11. Write Bessel’s ODE in self-adjoint form for Jµ(x) and Jν(x), and multiply the Jµ equation by Jν and the Jν equation by Jµ: Jν(x)[xJ ′ µ(x)] ′ + xJν(x)Jµ(x) = µ 2 x Jν(x)Jµ(x) , Jµ(x)[xJ ′ ν(x)] ′ + xJµ(x)Jν(x) = ν2 x Jµ(x)Jν(x) . Subtract the second of these equations from the ﬁrst and integrate from= 0 to x = ∞: (µ 2 − ν2) ∫ ∞ 0 Jµ(x)Jν(x) dx x = ∫ ∞ 0 Jν[xJ ′ µ]′ dx − ∫ ∞ 0 Jµ[xJ ′ ν]′ dx . CHAPTER 3. EXERCISE SOLUTIONS 228 Integrate each right-hand-side integral by parts, integrating the explicit derivative and diﬀerentiating the other Bessel function. The resultant integrals are equal in magnitude but opposite in sign; all that remains are the endpoint terms: (µ 2 − ν2) ∫ ∞ 0 Jµ(x)Jν(x) dx x = xJν(x)J ′ µ∣ ∞ − xJµ(x)J ′ ν(x) ∣ ∞ . The endpoint at zero makes no contribution to either term; that at inﬁnity is ﬁnite because the asymptotic limit of each Bessel function contains ax −1/2. From the asymptotic forms Jµ(x) ∼ √ 2 πx cos (x − (µ + 1 2 ) π 2 ) , J ′ µ(x) ∼ − √ 2 πx sin (x − (µ + 1 2 ) π 2 ) , we have (µ2 − ν2) ∫ ∞ 0 Jµ(x)Jν(x) dx x = 2 π [ − cos (x − (ν + 1 2 ) π 2 ) sin (x − (µ + 1 2 ) π 2 ) + cos (x − (µ + 1 2 ) π 2 ) sin (x − (ν + 1 2 ) π 2 ) ] = 2 π sin [ x − (ν + 1 2 ) π 2 − x + (µ + 1 2 ) π 2 ] = 2 π sin[(µ − ν)π/2] . This equation rearranges to the answer in the text. 14.7.12. The integral under consideration vanishes due to symmetry if m − n is odd. If m − n is even, then we identify the integral as proportional to that evaluated in Exercise 14.7.11: ∫ ∞ 0 Jm+1/2Jn+1/2 dx x = 2 π sin[(m − n)π/2] m2 − n2 . Because m − n is even, the sine function in the above formula is zero, conﬁrming the desired result. 14.7.13. Consider the result in Exercise 14.7.11 in the limit µ → ν. Introducing the leading term in the power-series expansion of sin[(ν − ν)π/2], we get lim µ→ν ∫ ∞ 0 Jµ(x)Jν(x) dx x = lim µ→ν 2 π (µ − ν)π/2 (µ − ν)(µ + ν) = 1 2ν . Use the above result to evaluate ∫ ∞ 0 [jn(x)] 2 dx = π 2 ∫ ∞ 0 [ Jn+1/2]2 dx x = π 2(2n + 1) . Extending the integration range to −∞ (and thereby multiplying the re- sult by 2), we reach the result given in the text. CHAPTER 3. EXERCISE SOLUTIONS 229 14.7.14. The integrals given for x(s) and y(s) follow directly from making the substitution v2 = u into x(t) and y(t), and then identifying u−1 cos u as j−1(u) and u−1 sin u as j0(u). Rewrite the expansion formulas in terms of Jn and cancel the constant factors √π/2. We then have ∫ s 0 J−1/2(u) du = 2 ∞∑ n=0 J2n+1/2(s) , ∫ s 0 J1/2(u) du = 2 ∞∑ n=0 J2n+3/3(s) . Now diﬀerentiate both sides of these equations with respect to s, reaching J−1/2(s) = 2 ∞∑ n=0 J ′ 2n+1/2(s) , J1/2(s) = 2 ∞∑ n=0 J ′ 2n+3/2(s) . Now use Eq. (14.8) to replace 2J ′ ν(x) by Jν−1(x) − Jν+1(x). When the sums are evaluated, everything cancels except the initial instance of Jν−1, conﬁrming these equations. 14.7.15. For a standing-wave solution with time dependence e iωt, the wave equation becomes a spherical Bessel equation with radial solutions (regular at thejm(ωr/v). Here m can be any nonnegative integer and v is the velocity of sound. The solutions satisfying a Neumann boundary conditionr = a will have a vanishing value of j′ m(ωa/v), and the minimum value of ω that meets this condition will correspond to the smallest zero of j′ m for any m. Consulting the list of zeros of j′ given in Table 14.2, we see that the smallest zero is for m = 1, which occurs at b11 = 2.0816. Note that the smallest zero of j′ 0 is larger; that is because j0 has a maximum at r = 0 while j1 has no extrema at arguments smaller than b11. Writing ω = 2πν, where ν is the oscillation frequency, we ﬁnd 2πνa v = b11 , or ν = b11 2π v a . Note also that the wavelength given in the answer to this problem corre- sponds to unconstrained waves of frequency ν. 14.7.16. (a) The power-series expansion of x −1/2Jn+ 1 2 (ix) will start with (ix)n and continue with powers n + 2s. Therefore, in(x) will have parity (−1) n. (b) Ir is clear from the explicit forms shown in Eq. (14.196) that kn(x) has no deﬁnite parity. CHAPTER 3. EXERCISE SOLUTIONS 230 14.7.17. We check the formula for n = 0. The relevant quantities are i0(x) = sinh x x , i′ (x) = cosh x x − sinh x x2 , k0(x) = e −x x , k′ 0(x) = −e −x ( 1 x + 1 x2 ) . Inserting these into the Wronskian, i0(x)k′ 0(x) − i ′ (x)k0(x) = − sinh x e −x ( 1 x2 + 1 x3 ) − e −x cosh x x2 + e −x sinh x x3 = − e −x x2 (cosh x + sinh x) = − 1 x2 . CHAPTER 3. EXERCISE SOLUTIONS 231 15. Legendre Functions 15.1 Legendre Polynomials 15.1.1. Diﬀerentiate Eq. (15.25), obtaining (1 − x 2)P ′′ n (x) − 2xP ′ n(x) = nP ′ n−1(x) − nPn(x) − nxP ′ n(x) . Use Eq. (15.24) to replace nP ′ n−1x by −n2Pn(x) + nxP ′ n(x). After remov- ing canceling terms, what remains is the Legendre ODE. 15.1.2. Expand (−2xt + t 2)n in Eq. (15.12), obtaining g(x, t) = ∞∑ n=0 ( −1/2 n ) n∑ j=0 ( n j ) t 2j(−2xt) n−j . Now change the summation variable n to m = n + j; the range of m will be from zero to inﬁnity, but the range of j will now only include values no larger than m/2. Also writing the binomial coeﬃcient involving −1/2 using a Pochhammer symbol, we reach g(x, t) = ∞∑ m=0 [m/2]∑ j=0 (− 1 2 )m−j (m − j)! (m − j)! (m − 2j)!j! tm(−2x) m−2j . The coeﬃcient of t m in this expression for g(x, t) is Pm(x). Inserting (− 1 2 )m−j = (−1)m−j(2m − 2j)! 22m−2j(m − j)! , we obtain the required formula. 15.1.3. Start by writing P ′′ n in series form, using the notation of Exercise 15.1.2. It is convenient to change the summation index to k′, with k replaced by k′ − 1, so that the power of x in the summand will be n − 2k′. This change causes P ′′ n to take the form P ′′ n (x) = [n/2]∑ k=0 (−1) k(2n − 2k)!xn−2k−2 2nk!(n − k)!(n − 2k − 2)! = ∑ k′ (−1)k′(2n − 2k′)!x n−2k′ 2n(k′)!(n − k′)!(n − 2k′)! [ − 2k′(2n − 2k′ + 1) ] . We have organized the k′ summation in a way that retains the factors present in the original summation for Pn. Formally the k′ summation ranges from k′ = 1 to k′ = [n/2] + 1, but the presence of an extra factor k′ enables us to extend the lower limit to k′ = 0 and the factorial (n − 2k′)! in the denominator causes the contribution at k′ = [n/2] + 1 to vanish. CHAPTER 3. EXERCISE SOLUTIONS 232 When we use the above form in the work that follows we will remove the prime from the summation index. We are now ready to write all the terms in the Legendre ODE. Only the term we have already processed causes a change in the indicated powersx. P ′′ n − x 2P ′′ n − 2xP ′ n + n(n + 1)Pn = [n/2]∑ k=0 [ (−1)k(2n − 2k)!x n−2k 2nk!(n − k)!(n − 2k)! ] × [ − 2k(2n − 2k + 1) − (n − 2k)(n − 2k − 1) − 2(n − 2k) + n(n + 1) ] . The quantity in the last set of square brackets vanishes, conﬁrming that the expansion satisﬁes the Legendre ODE. 15.1.4. If we set P ∗(x) = P (y), where y = 2x − 1 then ∫ 1 0 P ∗ n (x)P ∗ m(x) dx = 1 2 ∫ 1 −1 Pn(y)Pm(y) dy = 1 2 2 2n + 1 δnm . This equation conﬁrms the orthogonality and normalization of the P ∗ n (x). (a) Replacing x by 2x − 1 in the Pn recurrence formula, Eq. (15.18), we ﬁnd (n + 1)P ∗ n+1(x) − (2n + 1)(2x − 1)P ∗ n (x) + nP ∗ n−1(x) = 0 . (b) By examination of the ﬁrst few P ∗ n , we guess that they are given by the general formula P ∗ n (x) = n∑ k=0(−1) n−k( n k )( n + k k ) x k . This formula is easily proved by mathematical induction, using the recur- rence formula. First, we note from the explicit formula for P ∗ n that it gives correct results for P ∗ 0 (x) and P ∗ 1 (x). For n > 1, the recurrence formula for P ∗ n+1(x) yields P ∗ n+1(x) = 1 n + 1 (2n + 1)(2x − 1) n∑ k=0 ( n k )( n + k k ) (−1)n−k xk − n n + 1 n−1∑ k=0 ( n − 1 k )(n + k − 1 k ) (−1) n−1−k x k . Collecting the contributions for each power of x, we conﬁrm that the formula for P ∗ n+1(x) is correct, thereby completing the proof. Finally, the form of the explicit formula for P ∗ n shows that the coeﬃcients of all the x k are products of binomial coeﬃcients, which reduce to integers. CHAPTER 3. EXERCISE SOLUTIONS 233 15.1.5. Aeven =  1 1 / 3 7 / 35 33 / 231 0 2 / 3 20 / 35 110 / 231 0 0 8 / 35 72 / 231 0 0 0 16/ 231  Beven =  1 −1 /2 3 / 8 −5 /16 0 3 / 2 −30 / 8 105 /16 0 0 35/ 8 −315 /16 0 0 0 231 /16  Aodd =  1 3 / 5 27 / 63 143 /429 0 2 / 5 28 / 63 182 /429 0 0 8 / 63 88 /429 0 0 0 16 /429  Bodd =  1 −3 /2 15 /8 −35/ 16 0 5 /2 −70 /8 315/ 16 0 0 63 /8 −693/ 16 0 0 0 429 / 16 . 15.1.6. 2t ∂g(t, x) ∂t + g = 1 − t2 (1 − 2xt + t2)3/2 = ∞∑ n=0(2nPnt n + Pnt n) = ∞∑ n=0(2n + 1)Pnt n. 15.1.7. (a) Substituting nPn−1(x) = (2n + 1)xPn(x) − (n + 1)Pn+1(x) from Eq. (15.18) into Eq.(15.25) yields (1 − x 2)P ′ n(x) = (2n + 1)xPn(x) − (n + 1)Pn+1(x) − nxPn(x) = (n + 1)Pn(x) − (n + 1)Pn+1(x), i.e. Eq. (15.26). (b) (15.24)n→n+1+x·(15.23)→ (15.26). 15.1.8. For n = 1, we establish P ′ 1(1) = (1 · 2)/2 = 1 as the ﬁrst step of a proof by mathematical induction. Now assuming P ′ n(1) = n(n + 1)/2 and using Eq. (15.23), ′ n+1(1) = (n + 1)Pn(1) + P ′ n(1) = (n + 1) + n 2 (n + 1) = 1 2 (n + 1)(n + 2) , which proves our assumed formula for n + 1. CHAPTER 3. EXERCISE SOLUTIONS 234 15.1.9. For a proof by mathematical induction we start by verifying that P0(−x) = P0(x) = 1 and that P1(−x) = −P1(x) = −x. We then need to show that if Pm(−x) = (−1) mPm(x) for m = n − 1 and m = n, the relationship also holds for m = n + 1. Applying Eq. (15.18) with x replaced by −x we have −(2n + 1)xPn(−x) = (n + 1)Pn+1(−x) + nPn−1(−x) −→ (−1) n+1(2n + 1)xPn(x) = (n + 1)Pn+1(−x) + (−1) n−1nPn−1(x). We have used our assumed relationship for Pn and Pn−1. Since this last equation has to agree with Eq. (15.18) we conclude that Pn+1(−x) = (−1) n+1Pn+1(x). This completes the proof. 15.1.10. P2(cos θ) = 3 cos 2θ + 1 4 . 15.1.11. Derivation of this formula is presented in the footnote referenced just after Eq. (15.22). 15.1.12. The solution is given in the text. There is a misprint in the answer: For n = 2s + 1 a correct version of the second form of the answer is (−1) s(2s − 1)!!/(2s + 2)!!. 15.1.13. The sum contains only powers xi with i < n. If n is even, the smallest value of r is (n/2) + 1; if n is odd, it is (n − 1)/2 + 1 = (n + 1)/2. In either case, imax = 2n − 2rmin < n. 15.1.14. Expand x m = ∑ l≤m alPl(x). Now orthogonality gives ∫ 1 −1 x mPn dx = 0, m < n. 15.1.15. Following the directions in the exercise to use a Rodrigues formula and perform integrations by parts, Fn = ∫ 1 −1 x nPn dx = 1 2nn! ∫ 1 −1 x n ( d dx )n (x 2 − 1) n dx = 1 2nn! [ x n ( d dx )n−1 (x2 − 1) n∣ 1 1 − ∫ 1 −1 nx n−1 ( d dx )n−1 (x 2 − 1) n dx ] . The integrated terms vanish; a second integration by parts (for which the integrated terms also vanish) yields Fn = + 1 2nn! ∫ 1 −1 n(n − 1)xn−2 ( d dx )n−2 (x2 − 1) n dx . CHAPTER 3. EXERCISE SOLUTIONS 235 Further integrations by parts until the diﬀerentiation within the integral has been completely removed lead to Fn = (−1)n 2n n! ∫ 1 −1 n! (x 2 − 1)n dx = 2−n [2 ∫ 1 0 (1 − x 2) n dx ] . This integral (including the premultiplier “2”) is of the form given in Eq. (13.50), where it is identiﬁed as the beta function B(1/2, n + 1), with value B(1/2, n + 1) = 2n+1n! (2n + 1)!! , causing F to have the value claimed. 15.1.16. Introduce the Rodrigues formula for the Legendre polynomial and inte- grate by parts 2n times to remove the derivatives from the Rodrigues formula. The boundary terms vanish, so I = ∫ 1 −1 x 2rP2n(x) = 1 22n(2n)! ∫ 1 −1 x 2r ( d dx )2n (x 2 − 1) 2n dx = (2r)! 22n(2n)!(2r − 2n)! ∫ 1 −1 x 2r−2n(1 − x 2) 2n dx . The integral is a beta function with value ∫ 1 −1 x 2r−2n(1 − x 2) 2n dx = 24n+1(2n)! (r + n)!(2r − 2n)! (r − n)!(2r + 2n + 1)! . Substituting this into I, we get after cancellation I = 2 2n+1(2r)!(r + n)! (r − n)!(2r + 2n + 1)! . 15.1.17. Using integration by parts, orthogonality and mathematical induction as in Exercise 15.1.15, we obtain the solutions given in the text. 15.1.18. A continuous and diﬀerentiable function that is zero at both ends of an interval must have a derivative that is zero at some point within the in- terval. A continuous and diﬀerentiable function that is zero at both ends of an interval and at p intermediate points must have a derivative with p + 1 zeros within the overall interval. Applying these observations to (x 2 − 1)n with n > 0, its ﬁrst derivative must have one zero at a point intermediate to ±1. If n > 1, this derivative will also be zero at the endpoints, so the second derivative of (x 2 − 1)n must have two intermediate zeros. Continuing to the (n − 1)th derivative (which will be zero at the endpoints and at n − 1 intermediate points), we ﬁnd that the nth derivative (that relevant for Pn) will have n zeros between −1 and +1. CHAPTER 3. EXERCISE SOLUTIONS 236 15.2 Orthogonality 15.2.1. For n > m ∫ 1 −1 PmPn dx = 1 2m+nm!n! ∫ 1 −1 ( d dx )m (x2 − 1)m ( d dx )n (x 2 − 1) n dx = 0 because ( d dx )n+m (x 2 − 1) m = 0 and, upon integrating by parts, the integrated terms vanish. For n = m, the repeated integrations by parts yield (−1) n 22nn!n! ∫ 1 −1(x 2 − 1) n ( d dx )2n (x 2 − 1) n dx = (2n)! 22nn!n! ∫ 1 −1(1 − x2)n dx = (2n)! 22nn!n! B(1/2, n + 1) = (2n)! 22nn!n! 2n+1n! (2n + 1)!! = 2 2n + 1 . The beta function enters the solution because the integral can be identiﬁed as a case of Eq. (13.50). 15.2.2. The space spanned by {x j}, j = 0, 1, · · · , n is identical with the space spanned by {Pj(x)} for the same value of n. If the Gram-Schmidt pro- cess as described in this problem has produced functions ϕj(x) that are respectively proportional to Pj(x) through j = n − 1, then the remainder of the space (known formally as the orthogonal complement) is one- dimensional and ϕn(x) must be proportional to Pn(x). To complete the proof, we need only observe that if n = 0 we have P0(x) = x 0. 15.2.3. δ(x) = ∞∑ l=0(−1) l (4l + 1)(2l − 1)!! 2(2l)!! P2l(x), − 1 ≤ x ≤ 1. 15.2.4. Insert the expansions to be veriﬁed, and then note that the expansion of(x) in Legendre polynomials takes the form f (x) = ∑ n anPn(x), where an = 2n + 1 2 ∫ 1 −1 f (x)Pn(x) dx . ∫ 1 −1 f (x)δ(1 − x)dx = ∞∑ n=0 2n + 1 2 ∫ 1 −1 f (x)Pn(x)dx = ∞∑ n=0 an = ∞∑ n=0 anPn(1) = f (1). ∫ 1 −1 f (x)δ(1 + x)dx = ∞∑ n=0(−1)n 2n + 1 2 ∫ 1 −1 f (x)Pn(x)dx = ∞∑ n=0(−1)nan CHAPTER 3. EXERCISE SOLUTIONS 237 = ∞∑ n=0 anPn(−1) = f (−1). 15.2.5. (A2 + 2A cos θ + 1)−1/2 = 1 A ( 1 + 2 A cos θ + 1 A2 )−1/2 = 1 A ∞∑ n=0 Pn(cos θ) ( − 1 A )n ; ⟨cos ψ⟩ = 1 2A ∞∑ n=0 ( − 1 A )n ∫ π 0 (A cos θ + 1) Pn(cos θ) sin θ dθ = 1 2A ( 2 − 2 3 ) = 2 3A . 15.2.6. This follows from Eq. (15.40). 15.2.7. 5If f (x) = ∞∑ n=0 anPn, then ∫ 1 −1[f (x)] 2 dx = ∞∑ m,n=0 aman ∫ 1 −1 PmPn dx = ∞∑ n=0 2a 2 2n + 1 . 15.2.8. (a) Expand f (x) in a Legendre series ∞∑ n=0 anPn(x). This gives an = 2n + 1 2 ∫ 1 −1 f (t)Pn(t) dt = 2n + 1 2 [∫ 1 0 Pn(t) dt − ∫ 0 −1 Pn(t) ] dt . For n even, an = 0 but for n = 2s + 1 a2s+1 = (4s+3) ∫ 1 0 P2s+1(t)dt = (4s + 3)P2s(0) 2s + 2 = (4s + 3)(−1) s(2s − 1)!! (2s + 2)!! See Exercise 15.1.12. We now use the result of Exercise 15.2.7 to obtain the answer given in the text. (b) Using Stirling’s asymptotic formula for the ratio (2n − 1)!! (2n + 2)!! = (2n − 1)! 22n(n − 1)!(n + 1)! ≈ 1 2n √nπ , we see that the terms of the series approach zero as 1/n 2. (c) The sum of the ﬁrst ten terms of the series is 1.943 · · · , as compared to the exact value, 2. CHAPTER 3. EXERCISE SOLUTIONS 238 15.2.9. Because P ′ n is a polynomial of degree n − 1 with the parity of n − 1, the integral I of this problem will vanish unless n − m is an odd integer. Choose n to be the larger of the two indices. Then use Eq. (15.26) to write I = ∫ 1 −1 x(1 − x 2)P ′ nP ′ m dx = ∫ 1 −1 xP ′ m [(n + 1)xPn − (n + 1)Pn+1] dx . From this equation we note that in the integrand, Pn is multiplied by a polynomial in x of degree m + 1 and that Pn+1 is multiplied by one of degree m. The integral I will vanish by orthogonality if n − m > 1, and if n = m+1 only the Pn term of the integrand will contribute to the integral. To evaluate the nonzero case of this integral we therefore set m = n − 1 and continue by replacing P ′ n−1 using Eq. (15.24). With these changes we now have I = ∫ 1 −1 [ P ′ n−2 + (n − 1)Pn−1] (n + 1)xPn dx . In the integrand of this expression the term arising from P ′ n−2 consists of a polynomial of degree n − 2 multiplying Pn and therefore does not contribute to the integral. We are left with I = (n2 − 1) ∫ 1 −1 Pn−1xPn dx , which we can evaluate invoking orthogonality, using Eq. (15.18) to expressn in terms of Pn+1 and Pn−1 and getting the normalization constant from Eq. (15.38). Thus, I = (n 2 − 1) ∫ 1 −1 Pn−1 (n + 1)Pn+1 + nPn−1 2n + 1 dx = n(n2 − 1) 2n + 1 2 2n − 1 . The answer given for m = n + 1 can be obtained from that already given by the substitution n → n + 1. 15.2.10. Because P2n(x) is an even function of x, P2n(cos[π − θ]) = P2n(− cos θ) = P2n(cos θ) , so data for θ > π/2 add no new information. 15.2.11. With the conducting sphere centered at r = 0, the previously uniform electric ﬁeld E0 (assumed to be in the z direction) will be the value for large r of −∂V /∂z, where V is the electrostatic potential. The charge density σ on the conducting sphere (of radius r0) is given by −ε0 ∂V /∂r; and the induced dipole moment of the sphere is the coeﬃcient of cos θ/4πε0r2 in the region external to the sphere. CHAPTER 3. EXERCISE SOLUTIONS 239 The potential V must be a solution to Laplace’s equation with symmetry about the z-axis, and it can therefore be described by an expansion of the form V = a0 + ∞∑ n=1 [anrn + bn rn+1 ] Pn(cos θ) . The value of a0 is irrelevant; we set it to zero. At large r, V approaches −E0 z = −E0 r cos θ = −E0 r P1(cos θ), thereby showing that a1 = −E0 and all other an = 0 The bn terms become negligible at large r so they are not determined by the large-r limit of V . The condition that the sphere be an equipotential leads to the conclusion that all the bn other than b1 vanish, and that a1r0 + b1/r2 0 = 0, so b1 = E0r3 0 . The potential is therefore V = E0 ( r3 0 r2 − r) cos θ . (a) The induced charge density is σ = −ε0E0 cos θ d dr ( r3 0 r2 − r) = −ε0E0 cos θ(−2 − 1) = 3ε0E0 cos θ . (b) The coeﬃcient of cos θ/4πε0r2 is 4πε0b1 = 4πε0(E0r3 0). 15.2.12. For the region r < a, the potential must be described by a series of the form V (r, θ) = ∞∑ n=0 cnrnPn(cos θ) . The coeﬃcients cn can be determined by making them yield a potential that is correct on the polar axis θ = 0, where the potential is easy to calculate. On the axis, r = z and Pn(cos θ) = Pn(1) = 1, so V (z, 0) = ∞∑ n=0 cnzn . The point z on the polar axis is at the same distance √z2 + a2 from every point on the charged ring. Letting q be the total charge on the ring, by direct computation we ﬁnd V (z, 0) = q 4πε0 1 √z2 + a2 = q 4πε0a ∞∑ n=0 ( −1/2 n ) ( z a )2n = q 4πε0a ∞∑ n=0 (−1) n(2n − 1)!! (2n)!! ( z a )2n , CHAPTER 3. EXERCISE SOLUTIONS 240 where we have written V (z, 0) as its power-series expansion valid for z < a and used Eq. (1.74) to obtain an explicit formula for the binomial coeﬃ- cients. Comparing this expansion with that from the Legendre series, we note that cn = 0 for all odd n, and c2n = ( q 4πε0 ) (−1)n(2n − 1)!! (2n)!! a2n+1 . 15.2.13. Compute Er = −(∂ψ/∂r), Eθ = (sin θ/r)(∂ψ/∂ cos θ). (a) For r > a, Er(r, θ) = q 4πε0r2 ∞∑ s=0(−1) s (2s + 1)!! (2s)!! ( a r )2s P2s(cos θ), Eθ(r, θ) = q 4πε0r2 ∞∑ s=0(−1) s (2s − 1)!! (2s)!! ( a r )2s sin θ dP2s(cos θ) d cos θ . (b) For r < a, Er(r, θ) = q 4πε0a2 ∞∑ s=1(−1)s−1 (2s − 1)!! (2s − 2)!! ( r a )2s−1 P2s(cos θ) Eθ(r, θ) = q 4πε0a2 ∞∑ s=1(−1) s (2s − 1)!! (2s)!! ( r a )2s−1 sin θ dP2s(cos θ) d cos θ . The derivative of P2s leads to associated Legendre functions, Section 15.4. 15.2.14. The answer is given in the text. 15.2.15. Writing the potential in a form valid for r < a, V = ∞∑ n=0 cn ( r a )n Pn(cos θ) , . determine the coeﬃcients cn by requiring that at r = a they yield V = V0 for θ < π/2 and V = −V0 for θ > π/2. Because the distribution of V is an odd function of cos θ, all c2n must vanish, and c2n+1 can be found using the formulas for orthogonal expansions. Setting cos θ = x, we have c2n+1 = 2(2n + 1) + 1 2 [V0 ∫ 1 0 P2n+1(x) dx − V0 ∫ 0 −1 P2n+1(x) dx] = (4n + 3)V0 ∫ 1 0 P2n+1(x) dx . CHAPTER 3. EXERCISE SOLUTIONS 241 This integral, which was the topic of Exercise 15.1.12, has the value2n(0)/(2n + 2), so V = V0 ∞∑ n=0 4n + 3 2n + 2 P2n(0) ( r a )2n+1 P2n+1(cos θ) . The second form of the answer is obtained using Eq. (15.11) to introduce an explicit formula for P2n(0). 15.2.16. The answer is given in the text. 15.2.17. If |f ⟩ = ∑ n a ′ |ϕn⟩, then projecting yields |ϕs⟩⟨ϕs|f ⟩ = a′ |ϕs⟩. 15.2.18. The answer is given in AMS-55. 15.2.19. The answer is given in the text. 15.2.20. The answer is given in the text. 15.2.21. The answer is given in the text. 15.2.22. The answer is given in the text. 15.2.24. The expansion e ikr cos γ = ∞∑ n=0 anjn(kr)Pn(cos γ) involves the angular solutions Pn(cos γ) and radial solutions jn(kr) of Helmholtz’s PDE for which the plane wave on the left-hand side of the equation is also a solution. Setting cos γ = x and using orthogonality we have ∫ 1 −1 e ikrxPn(x) dx = 2an 2n + 1 jn(kr) , which implies, setting k = 1, ( d dr )n ∫ 1 −1 e irxPn(x)dx = an ( d dr )n jn(r) = ∫ 1 −1(ix) ne irxPn(x) dx. Using Eq. (14.177) ( d dr )n jn(r) ∣r=0 = n! (2n + 1)!! , we have 2an 2n + 1 n! (2n + 1)!! = in ∫ 1 −1 xnPn(x) dx = 2i nn! (2n + 1)!! . This gives an = i n(2n + 1). CHAPTER 3. EXERCISE SOLUTIONS 242 15.2.25. Diﬀerentiating the Rayleigh equation with respect to kr, we get i cos γ e ikr cos γ = i ∞∑ n=0 anjn(kr) cos γPn(cos γ) = ∞∑ n=0 anj′ n(kr)Pn(cos γ) . Now, replacing cos γ by x, insert Eq. (15.18), (2n + 1)xPn(x) = (n + 1)Pn+1(x) + nPn−1(x) , in the left-hand member of the diﬀerentiated equation and Eq. (14.170), (2n + 1)j′ n = njn−1 − (n + 1)jn+1 , in the right member, thereby reaching i ∞∑ n=0 anjn(kr) [ n 2n + 1 Pn−1(x) + n + 1 2n + 1 Pn+1(x)] = ∞∑ n=0 an [ n 2n + 1 jn−1(kr) − n + 1 2n + 1 jn+1(kr) ] Pn(x) . Shifting the index deﬁnitions in the left-hand side of this equation, it can be written i ∞∑ n=0 an+1 ( n + 1 2n + 3 ) jn+1(kr)Pn(x)+i ∞∑ n=0 an−1 ( n 2n − 1 ) jn−1(kr)Pn(x) = ∞∑ n=0 an [ n 2n + 1 jn−1(kr) − n + 1 2n + 1 jn+1(kr) ] Pn(x) . Comparing coeﬃcients of like terms yields the two equations i an+1 n + 1 2n + 3 = −an n + 1 2n + 1 , i an−1 n 2n − 1 = an n 2n + 1 . These equations are mutually consistent, indicative of the validity of the Rayleigh expansion, and correspond to the explicit formula an = i n(2n + 1)a0 . Setting kr = 0 in the Rayleigh formula, we complete the veriﬁcation by noting that jn(0) = δn0 and that therefore a0 = 1. CHAPTER 3. EXERCISE SOLUTIONS 243 15.2.26. Starting from the solution to Exercise 15.2.24 (with cos γ renamed µ), mul- tiply by Pm(µ) and integrate, thereby taking advantage of orthogonality. We get ∫ 1 −1 e ikrµ Pm(µ) dµ = ∞∑ n=0 i n(2n + 1)jn(kr) ∫ 1 −1 Pnµ)Pm(µ dµ = i m(2m + 1)jm(kr) ( 2 2m + 1 ) . This equation rearranges into the required answer. 15.2.27. Write the integral I that is the starting point for this problem using the Rodrigues formula for the Legendre polynomial and with t = cos θ: I = (−i)n 2 ∫ 1 −1 e izt 1 2n n! ( d dt )n (t2 − 1) n dt . Integrate by parts n times, thereby removing the indicated derivatives and diﬀerentiating the exponential. The boundary terms vanish, so we get I = (−i) n 2 (−iz)n 2n n! ∫ 1 −1 e izt(t 2 − 1)n dt . Next we write e izt = cos zt + i sin zt and note that the part of the integral containing the sine vanishes due to its odd parity. Thus, I = zn 2n+1 n! ∫ 1 −1 cos zt(1 − t2) n dt = zn 2n+1 n! ∫ π 0 cos(z cos θ) sin2n+1 θ dθ . This last form is Poisson’s integral representation of jn(z), which was derived in Exercise 14.7.9. 15.3 Physical Interpretation, Generating Function 15.3.1. V = q 4πε0 ( 1 |r + aˆz| − 2 r + 1 |r − aˆz| ) = q 4πε0r ([ 1 − 2a r cos θ + ( a r )2]−1/2 − 2 + [1 + 2a r cos θ + ( a r )2]−1/2) = q 4πε0r [ ∞∑ l=0 Pl(cos θ) ( a r )l − 2 + ∞∑ l=0 Pl(cos θ) (− a r )l] = q 2πε0r ∞∑ l=1 P2l ( a r )2l . CHAPTER 3. EXERCISE SOLUTIONS 244 15.3.2. V = q 4πε0r ( − [ 1 + 4a r cos θ + ( 2a r )2]−1/2 + [ 1 − 4a r cos θ + ( 2a r )2]−1/2 +2 [ 1 + 2a r cos θ + ( a r )2]−1/2 − 2 [1 − a r cos θ + ( a r )2]−1/2 ) = q 4πε0r [ − ∞∑ l=0 Pl(cos θ) ( − 2a r )l + ∞∑ l=0 Pl(cos θ) ( 2a r )l + 2 ∞∑ l=0 Pl(cos θ) (− a r )l − 2 ∞∑ l=0 Pl(cos θ) ( a r )l ] = q 4πε0r [ 2 ∞∑ l=0 P2l+1 ( 2a r )2l+1 − 4 ∞∑ l=0 P2l+1 ( a r )2l+1] = q πε0r ∞∑ l=1 P2l+1(cos θ) ( a r )2l+1 (22l − 1) . 15.3.3. V = q 4πε0 (r2 − 2ar cos θ + a2)−1/2 = q 4πε0a ∞∑ l=0 Pl(cos θ) ( r a )l . 15.3.4. E = −∇φ = − 2aq 4πε0 ∇ cos θ r2 . Using the gradient in polar coordinates from Section 3.10 gives the result given in the text. 15.3.5. Using ∂ ∂z = cos θ ∂ ∂r − sin θ r ∂ ∂θ , we obtain ∂ ∂z Pl rl+1 = − l + 1 rl+2 cos θPl + sin 2 θ rl+2 P ′ l (cos θ) = − l + 1 rl+2 Pl+1(cos θ), in conjunction with Eq. (15.26), (1 − x2)P ′ n(x) − (n + 1)xPn(x) = −(n + 1)Pn+1(x) . 15.3.6. A dipole at z = a may be generated by opposite charges ±q at z = a ± δ for δ → 0. Expanding the diﬀerence of Coulomb potentials in Legendre polynomials yields q 4πε0r ∞∑ l=0 [( a + δ r )l − ( a + δ r )l] Pl(cos θ). CHAPTER 3. EXERCISE SOLUTIONS 245 For δ → 0, this becomes 2qδ 4πε0r ∞∑ l=1 ∂ ∂a ( a r )l Pl(cos θ) −→ p(1) 4πε0ra ∞∑ l=1 l ( a r )l Pl(cos θ), with 2qδ approaching the ﬁnite limit p(1). For small a the leading term, p(1) 4πε0 P1(cos θ) r2 cancels against the point dipole at the origin. The next term, 2ap (1) 4πε0 P2(cos θ) r3 , is the point quadrupole potential at the origin corresponding to the limit→ 0 but with 2ap(1) approaching the nonzero limit p(2). 15.3.7. ϕ(3) = 48a 3q 4πε0r4 P3(cos θ) + · · · . 15.3.8. A charge q and its image charge q′ are placed as shown in Fig. 15.3.8 of this manual. The respective distances between the charges and a point P on a sphere of radius r0 are r1 and r2 when P is at the angle θ shown in the ﬁgure. The charge q is at a distance a from the center of the sphere, its image q′ is at the distance a ′ = r2 0/a from the sphere center, and q′ = −qr0/a. Our task is to show that the potentials produced at P from the two charges add to zero. What we need to prove is that q/r1 = −q′/r2, i.e., q2r2 2 = q′2r2 1, equivalent to a2r2 2 = r2 0r2 1. Now use the law of cosines and the geometry of Fig. 15.3.8 to write r2 1 = r2 0 + a 2 − 2r0a cos θ , r2 2 = r2 0 + a ′2 − 2r0a ′ cos θ . Then form r2 0r2 1 and a2r2 2, replacing a ′ by r2 0/a. The results are r2 0r2 1 = r4 0 + a 2r2 0 − 2r3 0a cos θ, a 2r2 2 = a 2r2 0 + a2 ( r2 0 a2 ) − 2a2r0 ( r2 0 a ) cos θ . These two expressions are clearly equal, completing our proof. CHAPTER 3. EXERCISE SOLUTIONS 246 15.4 Associated Legendre Equation 15.4.1. Assuming a power series solution P = ∑ j ajxk+j to Eq. (15.72), we obtain (1 − x 2) ∞∑ j=0 aj(k + j)(k + j − 1)xk+j−2 − 2x(m + 1) ∞∑ j=0 aj(k + j)x k+j−1 + [λ − m(m + 1)] ∞∑ j=0 ajx k+j = 0 . For this equation to be satisﬁed for all x the coeﬃcient of each power of x must individually vanish. From the coeﬃcient of x k−2 we obtain the indicial equation k(k − 1)a0 = 0. Since a0 was assumed not to vanish, the indicial equation has solutions k = 0 and k = 1. Taking k = 0 and shifting the summation indices to exhibit equal powers of j, the above equation takes the form ∞∑ j=0 [ (j +2)(j +1)aj+2 −j(j −1)aj −2(m+1)jaj +[λ−m(m+1)]aj] x j = 0 . Since the coeﬃcient of each x j must vanish, we have the recurrence formula given as Eq. (15.73). Just as for the Legendre equation, this recurrence relation leads to an inﬁnite series that diverges at x = ±1, so we must choose a value of λ that causes the right-hand side of Eq. (15.73) to vanish for some j. The value needed for λ is (j +m)(j +m+1), as is easily veriﬁed. It is customary to identify j + m = l, so we can write λ = l(l + 1). 15.4.2. We start from the recurrence formula, Eq. (15.87), that connects associ- ated Legendre functions of the same l but diﬀering m: P m+1 l (x) + 2mx √1 − x2 P m l + (l + m)(l − m + 1)P m−1 l (x) = 0 . Figure 15.3.8. Image charge geometry. CHAPTER 3. EXERCISE SOLUTIONS 247 Using expressions for P 2 2 and P 1 1 from Table 15.3, we properly reproduce P2(x) = (3x 2 − 1)/2. Continuing, we get P −1 2 = x √1 − x2/2 and P −2 2 = (1 − x 2)/8. These are related to the corresponding functions with +m as required by Eq. (15.81). 15.4.3. Taking P −m l ﬁrst (with m ≥ 0), and taking note of the Hint, we will need to evaluate ( d dx )l−m (x − 1) l(x + 1)l . Leibniz’s formula gives this derivative as a sum (over j) of all the ways j of the diﬀerentiations can be applied to the ﬁrst factor, with l − m − j diﬀerentiations applied to the second factor. Appending to the Leibniz formula the remaining factors in P −m l , we have P −m l = (x − 1) −m/2(−1)−m/2(x + 1)−m/2 × l−m∑ j=0 (l − m j ) l! (l − j)! (x − 1) l−j l! (m + j)! (x − 1)m+j = (−1) −m/2 l−m∑ j=0 (l − m)! l! l! (x − 1)l−j−m/2(x + 1) j+m/2 j! (l − m − j)! (l − j)! (m + j)! . We now apply a similar procedure to P m l . However, this time the total number of diﬀerentiations exceeds l, so the j summation must reﬂect the fact that neither factor can be diﬀerentiated more than l times. We have P m l = (x − 1) m/2(−1) m/2(x + 1)m/2 × l∑ j=m ( l + m j ) l! (l − j)! (x − 1) l−j l! (j − m)! (x − 1) j−m = (−1) m/2 l∑ j=m (l + m)! l! l! (x − 1) l−j+m/2(x + 1) j−m/2 j! (l + m − j)! (l − j)! (j − m)! . Next we replace the summation index j by k + m; this causes P m l to assume the form P m l = (−1) m/2 l−m∑ k=0 (l + m)! l! l! (x − 1) l−k−m/2(x + 1) k+m/2 (m + k)! (l − k)! (l − m − k)! k! . Comparing the ﬁnal forms of the expressions for P m l and P −m l , we conﬁrm that P −m l (x) = (−1)m (l − m)! (l + m)! P m l (x) . CHAPTER 3. EXERCISE SOLUTIONS 248 15.4.4. (a) From Eq. (15.88) with x = 0 and m = 1, P 1 l+1(0) = − l + 1 l P 1 l−1(0) . Starting from P 1 1 (0) = −1, we have P 1 3 (0) = +3/2, P 1 5 (0) = −3 · 5/2 · 4, or in general P 1 2l+1(0) = (−1)l+1(2l + 1)!!/(2l)!!. The functions P 1 2l(0) vanish because they have odd parity. (b) At x = 0, the generating function for m = 1 has the form g1(0, t) = −1 (1 + t2)3/2 = − ∞∑ s=0 (−3/2 s ) t2s ∞∑ s=0 P 1 2s+1(0)t 2s . From this equation we see that P 1 2s+1(0) = −( −3/2 s ) = (−1) s+1 (2s + 1)!! (2s)!! . 15.4.5. Using the generating function, gm(0, t) = (−1) m(2m − 1)!! (1 + t2)m+1/2 = (−1) m(2m − 1)!! ∞∑ s=0 (−m − 1/2 s ) t2s = ∞∑ s=0 P m 2s+m(0)t2s , we read out P m 2s+m(0) = (−1) m(2m − 1)!! ( −m − 1/2 s ) = (−1)m(2m − 1)!! (−1) s(2s + 2m − 1)!! (2s)!!(2m − 1)!! , which simpliﬁes to the given answer for l + m even. P m l (0) vanishes due to its odd parity when l + m is odd. 15.4.6. The ﬁeld has only r and θ components, with Er = −∂ψ/∂r and Eθ = −(1/r)∂ψ/∂θ. Thus, Er = − 2q 4πε0 [ P1(cos θ) −2a r3 + P3(cos θ) −4a3 r5 + · · · ] , in agreement with Eq. (15.130). Then, Eθ = − 2q 4πε0r2 [ a r dP1(cos θ) dθ + a3 r3 dP3(cos θ) dθ + · · · ] = − 2q 4πε0r2 [ a r P 1 1 (cos θ) + a 3 r3 P 1 3 (cos θ) + · · · ] , CHAPTER 3. EXERCISE SOLUTIONS 249 in agreement with Eq. (15.131). The second line of the above equation was obtained by substituting dP1/dθ = − sin θ = P 1 1 (cos θ) and dP3/dθ = P 1 3 (cos θ). 15.4.7. Using the Rodrigues formula and noting that the 2lth derivative of (x 2−1) l is (2l)!, we have P l l (x) = (−1)l(1 − x 2) l/2(2l)! 2ll! = (−1) l(2l − 1)!!(1 − x 2) l/2 , equivalent to the given answer when x = cos θ. 15.4.8. There are many ways to prove this formula. An approach that relies on the Rodrigues formulas and the fact that P m l satisﬁes the associated Legendre ODE is the following, in which D is used as shorthand for the operator d/dx. From the ODE, written in self-adjoint form, we have initially D(1 − x 2)D(1 − x 2) m/2DmPl + [l(l + 1) − m2 1 − x2 ] (1 − x2)m/2DmPl = 0 . Evaluating all the derivatives except those that apply only to Pn, we reach (1 − x 2) m/2+1Dm+2Pl − m(1 − x 2) m/2DmPl − 2(m + 1)x(1 − x2)m/2Dm+1Pl + m 2x 2(1 − x 2) m/2−1DmPl + [l(l + 1) − m2 1 − x2 ] (1 − x2)m/2DmPl = 0 . Rewriting this equation using the Rodrigues formulas (remembering that they contain a factor (−1) m), we get P m+2 l −mP m l + 2(m + 1)x (1 − x2)1/2 P m+1 l + m 2x 2 1 − x2 P m l +[ l(l + 1) − m 2 1 − x2 ] P m l = 0 . Combining the P m l terms, we have P m+2 l + 2(m + 1)x (1 − x2)1/2 P m+1 l + [l(l + 1) − m(m + 1)] P m l = 0 . If m is replaced by m − 1 we recover the formula as presented in the text. 15.4.9. The answer is given in the text. 15.4.10. The formula given here needs a minus sign to be consistent with the sign conventions used throughout the text. 15.4.11. These integrals can be rewritten using the relation dP (cos θ) dθ = − sin θ dP (x) dx = (1 − x 2) 1/2 dP (x) dx , CHAPTER 3. EXERCISE SOLUTIONS 250 where x = cos θ. Moreover, ∫ π 0 · · · sin θ dθ −→ ∫ 1 −1 · · · dx. (a) The ﬁrst integral then assumes the form I = ∫ 1 −1 [ (1 − x 2) dP m l (x) dx dP m l′ (x) dx + m 2 1 − x2 P m l (x)P m l′ (x)] dx . Integrate the ﬁrst term by parts, diﬀerentiating (1 − x 2) dP m l /dx and integrating dP m l′ /dx. The boundary terms vanish and we get I = ∫ 1 −1 ( − d dx [(1 − x2) dP m l (x) dx ] + m 2 1 − x2 P m l (x) ) P m l′ dx . The ﬁrst term of the integrand is the diﬀerential-operator part of the as- sociated Legendre ODE, so we replace it by the properly signed remainder of that ODE: I = ∫ 1 −1 ([l(l + 1) − m 2 1 − x2 ] P m l (x) + m2 1 − x2 P m l (x) ) P m l′ dx . We now cancel the m2 terms and identify what is left as an orthogonality integral, with the result I = l(l + 1) ( 2 2l + 1 ) (l + m)! (l − m)! δll′ . (b) This integral assumes the form ∫ 1 −1 [P 1 l (x) dP 1 l′ (x) dx + P 1 l′ (x) dP 1 l (x) dx ] dx = ∫ 1 −1 d dx [ P 1 l (x)P 1 l′ (x)] dx . This integrates to P 1 l (x)P 1 l′ (x), a quantity that vanishes at x = ±1, so the value of the integral is zero. 15.4.12. Rewrite this integral using P m l with m = 1: I = ∫ 1 −1 x(1 − x 2)P ′ n(x)P ′ m(x) dx = ∫ 1 −1 xP 1 n(x)P 1 m(x) dx . Use Eq. (15.88) to bring I to the form I = ∫ 1 −1 [ n 2n + 1 P 1 n+1(x) + n + 1 2n + 1 P 1 n−1(x) ] P 1 m(x) dx . If m = n + 1 the ﬁrst term is nonzero; with the help of Eq. (15.104) we get n 2n + 1 ∫ 1 −1 P 1 n+1(x)P 1 n+1(x) dx = n 2n + 1 2 2n + 3 (n + 2)! n! . The only other nonzero case is when m = n−1; a similar analysis conﬁrms the answer given in the text. CHAPTER 3. EXERCISE SOLUTIONS 251 15.4.13. 4 3 δn,1. 15.4.14. Use the ⟨ ⟩ notation to denote a scalar product with unit weight, and write the self-adjoint ODE as LP m l = ( l(l + 1) − m 2 1 − x2 ) P m l . We then write 〈 P m l | LP k l 〉 = 〈P m l ∣ ( l(l + 1) − k2 1 − x2 ) P k l 〉 , 〈 P k l ∣ LP m l 〉 = 〈P k l ∣ (l(l + 1) − m 2 1 − x2 ) P m l 〉 . Because L is self-adjoint and the Legendre functions are real, ⟨P k l |LP m l ⟩ = ⟨P m l |LP k l ⟩, and the above equations can be rewritten 〈 P m l | LP k l 〉 = 〈 P m l ∣ l(l + 1) − k2 1 − x2 ∣ P k l 〉 , 〈 P m l | LP k l 〉 = 〈 P m l ∣ l(l + 1) − m 2 1 − x2 ∣ P k l 〉 . If we now subtract the second of these equations from the ﬁrst, we get (m 2 − k2) 〈P m l ∣ 1 1 − x2 ∣ P k l 〉 = 0 , showing that functions with m ̸= k are orthogonal on (−1, 1) with weight 1/(1 − x 2). 15.4.15. The answer is given in the text. 15.4.16. (a) Br(r, θ) = ∞∑ n=0 d2n+1(2n + 1) (2n + 2) r2n a2n+1 P2n+1(cos θ). Bθ(r, θ) = − ∞∑ n=0 d2n+1(2n + 2) r2n a2n+1 P 1 2n+1(cos θ) with d2n+1 = (−1) n µ0I 2 (2n − 1)!! (2n + 2)!! . 15.4.17. The answer is given in the text. 15.4.18. The answer is given in the text. CHAPTER 3. EXERCISE SOLUTIONS 252 15.4.19. Let ω be the angular velocity of the rotating sphere, σ its surface charge density, and a the radius of the sphere. (a) B is in the z direction, with Bz = 2µ0ωσ 3 a 4 3z3 . (b) Aϕ(r, θ) = µ0ωσ 3 a 4 r2 P 1 1 (cos θ) , Br(r, θ) = 2µ0ωσ 3 a4 r3 P1(cos θ) , Bθ(r, θ) = µ0ωσ 3 a 4 r3 P 1 1 (cos θ) . 15.4.20. The answer is given in the text. 15.5 Spherical Harmonics 15.5.1. Starting from the relations P m l (− cos θ) = (−1) l+mP m l (cos θ) , e im(π+ϕ) = (−1) me imϕ , we ﬁnd Y m l (π − θ, π + ϕ) = (−1) lY m l (θ, ϕ). 15.5.2. Since Y m l (θ, ϕ) contains the factor sin m θ, Y m l (0, ϕ) = 0 for m ̸= 0. Also Y 0 l (θ, ϕ) = √ 2l + 1 4π Pl(cos θ) with Pl(1) = 1. Hence Y m l (0, ϕ) = √ 2l + 1 4π δm0. 15.5.3. Y m l ( π 2 , 0) = P m l (0) [ 2l + 1 4π (l − m)! (l + m)! ]1/2 . Using Eq. (15.4.5) to substitute for P m l (0), we get the value zero unless l + m is even. For even l + m, we get Y m l ( π 2 , 0 ) = (−1) (l+m)/2 (l + m − 1)!! (l − m)!! [ 2l + 1 4π (l − m)! (l + m)! ]1/2 , which can be brought to the form shown in the text as the answer to this 15.5.4. Substituting the delta-function formula: ∫ π −π f (ϕ2)δ(ϕ1 − ϕ2) dϕ2 = ∞∑ m=−∞ e imϕ1 1 2π ∫ π −π f (ϕ2)e −imϕ2 dϕ2 = ∑ m cme imϕ1 with cm = 1 2π ∫ π −π f (ϕ2)e −imϕ2 dϕ2 . CHAPTER 3. EXERCISE SOLUTIONS 253 Since the cm are the coeﬃcients in the expansion of f (ϕ) in the orthogonal functions χm(ϕ) = e imϕ, this sum reduces to f (ϕ1). 15.5.5. We can demonstrate the validity of the closure relation by verifying that it gives correct results when used with an arbitrary function f (θ, ϕ). Mul- tiplying the assumed relation by f (θ1, ϕ1) and integrating, ∞∑ l=0 +l∑ m=−l (∫ [ Y m l (θ1, ϕ1) ] ∗f (θ1, ϕ1) dΩ1 ) Y m l (θ2, ϕ2) = ∞∑ l=0 +l∑ m=−l almY m l (θ2ϕ2) = f (θ2, ϕ2) , where we have observed that that the Ω1 integral is that which deﬁnes the coeﬁcients alm of the spherical harmonic expansion. Since this result obtains for arbitrary f (θ, ϕ) and is that required of the delta function, our veriﬁcation is complete. 15.5.6. Y e 04 = P4(cos θ) = 35 cos2 θ − 30 cos2 θ + 3 8 Y e 24 = P 2 4 (cos θ) cos 2ϕ = 15(7 cos2 θ − 1) sin2 θ cos 2ϕ 2 Y e 44 = 105 sin 4 θ cos 4ϕ 15.5.7. The angular average of Y m l vanishes except for l = m = 0 by orthogo- nality of Y m l and Y 0 0 = 1/√4π. Thus, when f (r, θ, ϕ) is written as its Laplace expansion, only the term a00Y 0 0 will contribute to the average. This implies ⟨f ⟩sphere = 1 4π ∫ f (r, θ, ϕ) d cos θ dϕ = a00√4π = a00Y 0 0 . But setting r = 0 in the Laplace series, we also have f (0, 0, 0) = a00Y 0 0 , so ⟨f ⟩sphere = f (0, 0, 0). 15.6 Legendre Functions of the Second Kind 15.6.1. First, note that Q0(x) is odd; changing the sign of x interchanges the numerator and denominator of the logarithm deﬁning Q0. Next, note that Q1(x) is even. Then, the recurrence formula yielding Qn for n ≥ 2 causes Qn+2(x) to have the same parity as Qn(x). Thus, in general Qn has a parity opposite to that of n. 15.6.2. First verify by explicit computation that the formulas give correct resultsQ0 and Q1. For Q0, the ﬁrst summation contains a single term equal CHAPTER 3. EXERCISE SOLUTIONS 254 to x, while the second sum starts with s = 1. Together they yield Q0 = x + ∞∑ s=1 x 2s+1 2s + 1 , which is the power-series expansion of Q0(x). A similar check conﬁrms Q1(x). We next check that the formulas of parts (a) and (b) are consistent with the recurrence formula. We need to examine both 2nQ2n − (4n − 1)xQ2n−1 + (2n − 1)Q2n−2 = 0 and (2n + 1)Q2n+1 − (4n + 1)xQ2n + 2nQ2n−1 = 0 . Each check involves three parts: (1) Coeﬃcients of powers of x that arise from the ﬁrst (ﬁnite) summations only; (2) Coeﬃcients that arise from the second (inﬁnite) summation only; and (3) coeﬃcients for values of s near n that do not fall into the previous two cases. The veriﬁcation is straightforward but tedious. It may be useful to organize the terms in a fashion similar to that illustrated in the solution to Exercise 15.6.3. 15.6.3. We use the formula scaled as in part (b) so that a check of Q0, Q1, and the recurrence formula veriﬁes both the general formula and its scaling. For Q0, we get Q0(x) = ∞∑ s=0 (2s)!x−2s−1 (2s)!!(2s + 1)!! = ∞∑ s=0 x −2s−1 2s + 1 = 1 2 ln ( 1 + x −1 1 − x−1 ) = 1 2 ln ( x + 1 x − 1 ) , which is the form for Q0 which is standard for |x| > 1. The veriﬁcation of Q1 = xQ0 − 1 is similar. To complete the proof we now write the three terms of the recurrence formula as summations and equate the coeﬃcients of individual powers of CHAPTER 3. EXERCISE SOLUTIONS 255 x. We have (2l + 1)xQl = ∞∑ s=0 [ (l + 2s)! x −2s−l (2s)!!(2l + 2s + 1)!! ] (2l + 1) , lQl−1 = l ∞∑ s=0 (l + 2s − 1)! x −2s−l (2s)!!(2l − 2s − 1)!! = ∞∑ s=0 [ (l + 2s)! x −2s−l (2s)!!(2l + 2s + 1)!! ] l(2l + 2s + 1) l + 2s , (l + 1)Ql+1 = (l + 1) ∞∑ s=0 (l + 2s + 1)! x−2s−l−2 (2s)!!(2l + 2s + 3)!! . To make the exponents correspond for the same index values we replace s by s ′ − 1 in the Ql+1 summation; formally the s ′ sum then starts from s ′ = 1 but the summand vanishes for s ′ = 0 so we can without error use zero as the lower summation limit. With these changes, we have (l + 1)Ql+1 = ∞∑ s′=0 [ (l + 2s ′)! x −2s′−l (2s′)!!(2l + 2s′ + 1)!! ] (l + 1)(2s ′) l + 2s′ . Forming now (l + 1)Ql+1 − (2l + 1)xQl + lQl−1 , we ﬁnd that the coeﬃcient of each power of x evaluates to zero. 15.6.4. (a) Apply the recurrence formula, Eq. (15.18), to both Pn and Qn: n [Pn(x)Qn−1(x)] = (2n − 1)xPn−1(x)Qn−1(x) − (n − 1)Pn−2(x)Qn−1(x) , n [Pn−1(x)Qn(x)] = (2n − 1)xPn−1(x)Qn−1(x) − (n − 1)Pn−1(x)Qn−2(x) . Using the above, we ﬁnd n [Pn(x)Qn−1(x) − Pn−1(x)Qn(x)] = (n − 1) [Pn−1(x)Qn−2(x) − Pn−2(x)Qn−1(x)] . Applying repeatedly, we ﬁnally get to n [Pn(x)Qn−1(x) − Pn−1(x)Qn(x)] = [P1(x)Q0(x) − P0(x)Q1(x)] . (b) From P0 = 1, P1 = x, Q0 = 1 2 ln ( 1 + x 1 − x ) , Q1 = x 2 ln ( 1 + x 1 − x ) − 1, we directly verify P1Q0 − P0Q1 = 1. CHAPTER 3. EXERCISE SOLUTIONS 256 16. Angular Momentum 16.1 Angular Momentum Operators 16.1.1. (a) and (b) are Eqs.(16.30) and (16.31) applied to j = L, m = M. 16.1.2. This problem is interpreted as requiring that the form given for L± be shown to convert Y l l as given by Eq. (15.137) into Y m l as given by that equation (and not by the use of general operator formulas). We consider explicitly L+. The procedure for L− is similar. Applying L+ to Y m l , noting that dP m l (cos θ) dθ = − sin θ (P m l ) ′ , i cot θ d dϕ e imϕ = −m cot θ eimϕ , and using Eqs. (15.87) and (15.91), written here as −m cot θ P m l = 1 2 P m+1 l + (l + m)(l − m + 1) 2 P m−1 l , − sin θ (P m l ) ′ = 1 2 P m+1 l − (l + m)(l − m + 1) 2 P m−1 l , we obtain L+Y m l = √ 2l + 1 4π (l − m)! (l + m)! [ ∂ ∂θ + i cot θ ∂ ∂ϕ ] P m l e imϕ = √ (l − m)(l + m + 1) √ 2l + 1 4π (l − m − 1)! (l + m + 1)! P m+1 l e (m+1)ϕ = √(l − m)(l + m + 1) Y m+1 l . The corresponding result for L− is L−Y m l = √ (l + m)(l − m + 1) Y m−1 l . Continuing now, (a) Apply L− k times to Y l l . We get (L−) kY l l = [ (2l)(2l − 1) · · · (2l − k + 1)(1)(2) · · · (k) ] 1/2Y l−k l = √ (2l)! k! (2l − k)! Y l−k l . Setting l − k = m, we recover the answer to part (a). (b) Applying L+ k times to Y −l l , we get by a similar procedure the expected result. CHAPTER 3. EXERCISE SOLUTIONS 257 16.1.3. The equation of this exercise, written in Dirac notation, is 〈 Y M L ∣ L− L+Y M L 〉 = 〈 L+Y M L ∣ L+Y M L 〉 . This equation is valid because Lx and Ly are Hermitian, so (L−) † = L+. 16.1.4. (a) Insert J+ = Jx + iJy and J− = Jx − iJy into the formula for J2 and expand, maintaining the operator order in all terms. After cancellation we reach J 2 x + J 2 y + J 2 z . (b) One way to proceed is to start by building the operator L+L−: L+L− = −e iϕ [ ∂ ∂θ + i cot θ ∂ ∂ϕ ] e −iϕ [ ∂ ∂θ − i cot θ ∂ ∂ϕ ] = − ∂2 ∂θ2 − cot θ ∂ ∂θ − cot2 θ ∂2 ∂ϕ2 − i ∂ ∂ϕ . Then L−L+ is obtained from the above by changing the sign of i, so (L+L− − L−L+)/2 is simply the ﬁrst three terms of the above expression. We also need an expression for L 2 = −∂2/∂ϕ2, and can then write L 2 = − ∂2 ∂θ2 − cot θ ∂ ∂θ − cot2 θ ∂2 ∂ϕ2 − ∂2 ∂ϕ2 = − ∂2 ∂θ2 − cot θ ∂ ∂θ − 1 sin 2 θ ∂2 ∂ϕ2 , where the second line of the above equation results from application of a trigonometric identity. Now we can apply this operator to the θ and ϕ dependence of the spherical harmonics of l = 2 from Table 15.4. Y 2 2 : L 2 sin 2 θe2iϕ = (−2 cos2 θ + 2 sin2 θ)e 2iϕ − cot θ(2 sin θ cos θ)e 2iϕ + 4 e 2iϕ = (2 sin2 θ − 4 cos2 θ + 4)e 2iϕ = 6 sin 2 θ e2iϕ Y 1 2 : L 2 sin θ cos θeiϕ = 4 sin θ cos θ eiϕ − cot θ(cos2 θ − sin 2 θ)e iϕ − sin θ cos θ sin 2 θ (−e iϕ) = sin θ cos θ [4 − cos2 θ sin 2 θ + 1 + 1 sin 2 θ ] e iϕ = 6 sin θ cos θ eiϕ Y 0 2 : L 2(3 cos2 θ − 1) = 6(cos2 θ − sin 2 θ) + 6 cot θ(cos θ sin θ) = 12 cos2 θ − 6 sin2 θ = 6(3 cos2 θ − 1). The evaluations for Y −M 2 are similar to those for the corresponding +M . CHAPTER 3. EXERCISE SOLUTIONS 258 16.1.5. This problem is interpreted as referring to general angular momentum eigenfunctions, with L 2ψLM = L(L + 1)ψLM and LzψLM = M ψLM , and with the eﬀect of L+ and L− as shown in Eq. (16.25). From these equations we proceed as in Exercise 16.1.2, getting (in the present notation) the formulas of that exercise. 16.1.6. Use mathematical induction, assuming the equations of this exercise to be valid for n − 1. We apply L+ to the (L+) n−1 equation. Treating the two terms of L+ individually, Term 1: e iϕ ∂ ∂θ (−1)n−1 sin M +n−1 θ ( d d cos θ )n−1 sin −M θ ΘLM e i(M +n−1)ϕ = e i(M +n)ϕ(−1) n−1(M +n−1) sinM +n−2 θ cos θ ( d d cos θ )n−1 sin −M θ ΘLM + e i(M +n)ϕ(−1) n−1 sin M +n−1 θ (− sin θ) ( d d cos θ )n sin −M θ ΘLM , Term 2: − (M +n−1)e i(M +n)ϕ(−1) n−1 cot θ sin M +n−1 θ × ( d d cos θ )n−1 sin −M θ ΘLM Term 2 cancels against the ﬁrst part of Term 1, leaving (−1)n sin M +n θ ( d d cos θ )n sin −M θ ΘLM e i(M +n)ϕ . This is the formula for (L+)n. Since the formula is clearly valid for n = 0, the proof by mathematical induction is complete. A similar proof can be developed for the (L−) n equation. 16.1.7. Start from Y 0 0 and compare the result of applying (L+)M and that ob- tained by applying (L−) M , using the formulas in Exercise 16.1.6. (L+) M Y 0 L = (−1) M e iM ϕ sin M θ dM Y 0 L d cos θM , (L−) M Y 0 L = e −iM ϕ sin M θ dM Y 0 L d cos θM . These repeated applications of L± produce Y M L and Y −M L with equal scale factors, as can be seen by examination of the formulas in Exercise 16.1.1. We also note that the expressions diﬀer only by a factor (−1)M and the sign of the exponent in e ±iM ϕ, as required to obtain the desired answer. CHAPTER 3. EXERCISE SOLUTIONS 259 16.1.8. (a) L+Y 0 1 = e iϕ [ ∂ ∂θ + i cot θ ∂ ∂ϕ ] √ 3 4π cos θ = √ 3 4π e iϕ(− sin θ) = √2 Y 1 1 . (b) L−Y 0 1 = −e −iϕ [ ∂ ∂θ − i cot θ ∂ ∂ϕ ] √ 3 4π cos θ = − √ 3 4π e −iϕ(− sin θ) = √2 Y −1 1 . 16.2 Angular Momentum Coupling 16.2.1. We apply J+ = J1+ + J2+ to the state |(j1j2)JM ⟩ using the ⟨J+⟩ matrix element that we know. This yields+|JM ⟩ = [(J −M )(J +M +1)] 1/2∑ m1m2 C(j1j2J|m1, m2, M +1)|j1m1⟩|j2m2⟩ = ∑ m1m2 C(j1j2J|m1m2M ) { [(j1 − m1)(j1 + m1 + 1)] 1/2|j1, m1 + 1⟩|j2m2⟩ + [(j2 − m2)(j2 + m2 + 1)] 1/2|j1m1⟩|j2, m2 + 1⟩ } , from which we project with |j1, m1 + 1⟩|j2m2⟩ to get [(J − M )(J + M + 1)] 1/2C(j1j2J|m1 +1, m2, M +1) = C(j1j2J|m1m2M )[(j1 − m1)(j1 + m1 + 1)] 1/2 + C(j1j2J|m1 +1, m2 −1, M )[(j2 − m2 + 1)(j2 + m2)] 1/2. To avoid introducing additional indexing symbols we have used the fact that the projection corresponds, for the ﬁrst right-hand term, to reducing the sum to a single term in which m1 and m2 have the index values shown in the sum, while for the second term, the sum becomes a single term with1 replaced by m1 + 1 and with m2 replaced by m2 − 1. Using this recursion we check that C(111|000) = 0, C(111|101) = 1/√ 2, etc. Projecting |j1m1⟩|j2, m2 + 1⟩ gives a similar recursion. Using J2 → J(J +1) = j1(j1+1)+j2(j2+1)+2m1m2+J1+J2−+J1−J2+ in conjunction with the matrix elements of Ji± given in Eqs. (16.30) and (16.31) yields a third recursion relation. 16.2.2. The formula of this exercise is that for angular momentum coupling, so the result must be a spherical tensor of rank J. 16.2.3. Denote the p states p+, p0, p− and the spin states α, β. Note that j+ = l+ + s+ and j− = l− + s−, so we will need, applying Eqs. (16.30) and CHAPTER 3. EXERCISE SOLUTIONS 260 (16.31): l+p+ = 0, l+p0 = √2 p+, l+p− = √2 p0, l−p+ = √2 p0, l−p0 = √2 p−, l−p− = 0, s+α = 0, s+β = α, s−α = β, s−β = 0. The ml, ms state of maximum m = ml + ms is p+α, so this is a state with j = m = 3/2. Applying j−, we form the ( 3 2 , m) states of smaller m: j = 3 2 , m = 1 2 : (l− + s−)p+α = √2 p0α + p+β, j = 3 2 , m = − 1 2 : (l− + s−)( √2 p0α + p+β) = 2p−α + √2 p0β + √2 p0β = 2(p−α + √2 p0β), j = 3 2 , m = − 3 2 : 2(p−β + 2p−β) = 6p−β . These states are not yet normalized. Each state with j = 1 2 will be orthog- onal to the j = 3 2 state of the same m, so we have (also unnormalized) j = 1 2 , m = 1 2 : p0α − √2 p+β, j = 1 2 , m = − 1 2 : p0β − √2 p−α . Normalizing all these states and using the conventional labeling: 2p3/2 : m = 3 2 , p+α, m = 1 2 , √ 2/3 p0α + √ 1/3 p+β, m = − 1 2 , √ 2/3 p0β + √ 1/3 p−α, m = − 3 2 , p−β, 2p1/2 : m = 1 2 , √ 1/3 p0α − √ 2/3 p+β, m = − 1 2 , √ 1/3 p0β − √ 2/3 p−α . 16.2.4. The p states are designated as in Exercise 16.2.3 and the spin states are given the (nonstandard) designations [ 3 2 ], [ 1 2 ], etc. The deﬁnitions of j± are as in Exercise 16.2.3 and the behavior of l± is as listed there; we need the additional relationships s−[ 3 2 ] = √3 [ 1 2 ], s−[ 1 2 ] = 2[− 1 2 ], s−[− 1 2 ] = √3 [− 3 2 ], s−[− 3 2 ] = 0. The largest possible value of m = ml + ms is 5 2 , so that the (j, m) state CHAPTER 3. EXERCISE SOLUTIONS 261 of largest j and m is ( 5 2 , 5 2 ) = p+[ 3 2 ]. Applying j−, we reach j = 5 2 , m = 3 2 , √2 p0[ 3 2 ] + √3 p+[ 1 2 ], j = 5 2 , m = 1 2 , 2p−[ 3 2 ] + 2 √6 p0[ 1 2 ] + 2√3 p+[− 1 2 ], j = 5 2 , m = − 1 2 , 6 √3 p−[ 1 2 ] + 6 √6 p0[− 1 2 ] + 6p+[− 3 2 ] j = 5 2 , m = − 3 2 , 24 √2 p0[− 3 2 ] + 24 √3 po[− 1 2 ] j = 5 2 , m = − 5 2 , 120p−[− 3 2 ]. We next need to identify the state ( 3 2 , 3 2 ) as that of m = 3 2 that is orthog- onal to √2 p0[ 3 2 + √3 p+[ 1 2 ]. It is ( 3 2 , 3 2 ) = √3 p0[ 3 2 ] − √2 p+[ 1 2 ]. Applying j−, we now generate the states of j = 3 2 of smaller m: j = 3 2 , m = 1 2 , √6 p−[ 3 2 ] + p0[ 1 2 ] − 2√2 p+[− 1 2 ], j = 3 2 , m = − 1 2 , 4 √2 p−[ 1 2 ] − 2p0[− 1 2 ] − 2√6 p+[− 3 2 ], j = 3 2 , m = − 3 2 , 6 √2 p−[− 1 2 ] − 6 √3 p0[− 3 2 ]. Finally, we construct the states with j = 1 2 , starting from the state ( 1 2 , 1 2 ) that is orthogonal to both ( 5 2 , 1 2 ) and ( 3 2 , 1 2 ). Writing this state as p−[ 3 2 ] + b p0[ 1 2 + c p+[− 1 2 ], the orthogonality requirement is 〈 p−[ 3 2 ] + b p0[ 1 2 ] + c p+[− 1 2 ]∣ p−[ 3 2 ] + √6 p0[ 1 2 ] + √3 p+[− 1 2 ] 〉 = 1 + √6 b + √3 c = 0, 〈 p−[ 3 2 ] + b p0[ 1 2 ] + c p+[− 1 2 ]∣ √ 6 p−[ 3 2 ] + p0[ 1 2 ] − 2√2 p+[− 1 2 ] 〉 = √6 + b − 2 √2 c = 0 . These equations have solution b = − √2/3 , c = √ 1/3 , so ( 1 2 , 1 2 ) = p−[ 3 2 ] − √2/3 p0[ 1 2 ] + √1/3 p+[− 1 2 ] . Operating on this with j−, we get ( 1 2 , − 1 2 ) = p+[− 3 2 ] − √ 2/3 p0[− 1 2 ] + √1/3 p0[ 1 2 ] . CHAPTER 3. EXERCISE SOLUTIONS 262 Collecting the above results and normalizing, our ﬁnal result is: 4p5/2 : m = 5 2 , p+[ 3 2 ], m = 3 2 , √2/5 p0[ 3 2 ] + √3/5 p+[ 1 2 ], m = 1 2 , √1/10 p−[ 3 2 ] + √3/5 p0[ 1 2 ] + √ 3/10 p+[− 1 2 ], m = − 1 2 , √3/10 p−[ 1 2 ] + √3/5 p0[− 1 2 ] + √1/10 p+[− 3 2 ], m = − 3 2 , √2/5 p0[− 3 2 ] + √3/5 p−[− 1 2 ], m = − 5 2 , p−[− 3 2 ], 4p3/2 : m = 3 2 , √3/5 p0[ 3 2 ] − √2/5p+[ 1 2 ], m = 1 2 , √2/5 p−[ 3 2 ] + √ 1/15 p0[ 1 2 ] − √ 8/15 p+[− 1 2 ], m = − 1 2 , √8/15 p−[ 1 2 ] − √1/15 p0[− 1 2 ] − √ 2/5 p+[− 2 5 ], m = − 3 2 , √2/5 p−[− 1 2 ] − √ 3/5 p0[− 3 2 ], 4p1/2 : m = 1 2 , √1/2 p−[ 3 2 ] − √ 1/3 p0[ 1 2 ] + √ 1/6 p+[− 1 2 ], m = − 1 2 , √1/2 p+[− 3 2 ] − √1/3 p0[− 1 2 ] + √ 1/6 p−[ 1 2 ]. 16.2.5. (a) Writing the three-particle states in the mp, mn, me basis, putting the states of the same M = mp + mn + me in the same row, we construct the diagram M = 3/2 pαnαeα M = 1/2 pαnαeβ pαnβeα pβnαeα M = −1/2 pαnβeβ pβnαeβ pβnβeα M = −3/2 pβnβeβ The diagram shows that there is one set of states with J = 3/2 (a quartet) and two additional sets of states with J = 1/2 (doublets). (b) Finding the states reached by coupling the proton and neutron spins is the same as the problem discussed in Exercise 16.2.2; writing the results of that exercise in a notation reﬂecting the current situation, we have a nuclear triplet, (pn)+ = pαnα, (pn)0 = √ 1/2 (pαnβ + pβnα), (pn)− = pβnβ, and a nuclear singlet: (pn)s = √ 1/2(pαnβ − pβnα). Coupling the triplet nuclear state with the electron spin produces a quartet state and a doublet state. Finding the quartet and doublet states is the same problem as CHAPTER 3. EXERCISE SOLUTIONS 263 Exercise 16.2.3; the results are ( 3 2 , 3 2 ) : (pn)+eα, ( 3 2 , 1 2 ) : √2/3 (pn)0eα + √ 1/3 (pn)+eβ, ( 3 2 , − 1 2 ) : √2/3 (pn)0eβ + √ 1/3 (pn)−eα, ( 3 2 , − 3 2 ) : (pn)−eβ , ( 1 2 , 1 2 ) : √1/3 (pn)0eα − √ 2/3 (pn)+eβ, ( 1 2 , − 1 2 ) : √1/3 (pn)0eβ − √ 2/3 (pn)−eα . The singlet nuclear state has no spin angular momentum, so coupling it with the electron spin produces the doublet (which we mark with a prime) ( 1 2 , 1 2 ) ′ : (pn)seα, ( 1 2 , − 1 2 )′ : (pn)seβ. All these states can now be expanded into weighted sums of the (mp, mn, me) states. We get ( 3 2 , 3 2 ) : pαnαeα ( 3 2 , 1 2 ) : √ 1/3 (pαnβeα + pβnαeα + pαnαeβ) ( 3 2 , − 1 2 ) : √ 1/3 (pαnβeβ + pβnαeβ + pβnβeα) ( 3 2 , − 3 2 ) : pβnβeβ ( 1 2 , 1 2 ) : √ 1/6 (pαnβeα + pβnαeα) − √2/3 pαnαeβ ( 1 2 , − 1 2 ) : √ 1/6 (pαnβeβ + pβnαeβ) − √ 2/3 pβnβeα ( 1 2 , 1 2 ) ′ : √ 1/2 (pαnβeα − pβnαeα) ( 1 2 , − 1 2 ) ′ : √ 1/2 (pαnβeβ − pβnαeβ . (c) This part of the exercise is the same as part (b) except that the roles of the neutron and electron are interchanged. Thus, replace the (pn) states by corresponding (pe) states and change eα and eβ to nα and nβ. After these changes, one can expand the resulting states. The quartet states are the same in both coupling schemes, but the doublets found here, marked with multiple primes, ( 1 2 , 1 2 ) ′′ : √1/6 (pαnαeβ + pβnαeα) − √2/3 pαnβeα ( 1 2 , − 1 2 ) ′′ : √1/6 (pαnβeβ + pβnβeα) − √ 2/3 pβnαeβ ( 1 2 , 1 2 ) ′′′ : √1/2 (pαnαeβ − pβnαeα) ( 1 2 , − 1 2 ) ′′′ : √1/2 (pαnβeβ − pβnβeα . CHAPTER 3. EXERCISE SOLUTIONS 264 diﬀer from those of part (b). (d) The diﬀerence in the two coupling schemes is only in the doublet states; those associated with the triplet nuclear state of part (b) are the states of most interest since they correspond to observed states of the deuterium atom. One way to show that these doublets span the same space is to write those from part (c) as linear combinations of those from part (b). We illustrate for M = + 1 2 : ( 1 2 , 1 2 ) ′′ = − 1 2 ( 1 2 , 1 2 ) − √3 2 ( 1 2 , 1 2 ) ′, ( 1 2 , 1 2 ) ′′′ = − √3 2 ( 1 2 , 1 2 ) + 1 2 ( 1 2 , 1 2 ) ′ . 16.3 Spherical Tensors 16.3.2. The set of Y m l for given l is closed under rotation. This must be the case, because L 2, a scalar, has a value that is independent of the orientation of the coordinate system. 16.3.3. This problem is a special case of Eq. (16.53) with Ω1 = Ω2. The quantity A is shown in Eq. (16.55) to be rotationally invariant (i.e., spherically symmetric). 16.3.4. This formula is derived at Eq. (16.66). 16.3.5. Note that this problem uses a hybrid unit system and is neither in MKS units (it lacks the factor 1/4πε) nor in the hartree unit system common in electronic structure computations (having a value of e not set to unity). To solve the problem, use the Laplace expansion, Eq. (16.66), and note that the only term that survives upon integration is that with l = 0, for which the product of the two spherical harmonics becomes 1/4π. There- fore, after performing the angular integrations for both r1 and r2, what remains is E = ( 3e 4πR3 )2 (4π)2 ∫ R 0 r2 1dr1 ∫ R 0 r2 2dr2 1 r> , where r> is the larger of r1 and r2. To evaluate the integral, break it into the two regions r1 < r2 and r1 > r2: E = 9e 2 R6 [∫ R 0 r1 dr1 ∫ r1 0 r2 2 dr2 + ∫ R 0 r2 dr2 ∫ r2 0 r2 1 dr1 ] = 18e 2 R6 ∫ R 0 r1 dr1 ∫ r1 0 r2 2 dr2 . Note that we have written the integrations in a way that shows them to be equal. The double integral evaluates to R5/15, so E = 6e 2/5R. CHAPTER 3. EXERCISE SOLUTIONS 265 16.3.6. Note that this problem uses a hybrid unit system and is neither in MKS units (it lacks the factor 1/4πε) nor in the hartree unit system common in electronic structure computations (having a value of e not set to unity). This problem proceeds in a way similar to Exercise 16.3.5. It is convenient to change the integration variables to x = 2Zr1/a0 and y = 2Zr2/a0, and the integral we seek can then be written V = e 2Z a0 ∫ ∞ 0 x 2e −x dx ∫ ∞ x ye−y dy . The y integral has the value (x + 1)e −x, so we have V = e 2Z a0 ∫ ∞ 0 e −2x(x 3 + x2) dx = e 2Z a0 [ 3! 24 + 2! 23 ] = 5e 2Z 8a0 . 16.3.7. This problem is presented in MKS units, with q denoting the electron charge. As in Exercises 16.3.5 and 16.3.6, only the spherically symmetric term of the Laplace expansion survives the integration, and we have V (r1) = q 4πε0 1 πa3 [ 4π ∫ r1 0 r2 2 r1 e −2r2/a0 dr2 + 4π ∫ ∞ r1 r2 e −2r2/a0 dr2 ] . Changing the integration variable to x = 2r2/a0, we get V (r1) = q 4πε0 4 a3 [( a0 2 )3 1 r1 ∫ 2r1/a0 0 x 2e −x dx + ( a0 2 )2 ∫ ∞ 2r1/a0 x e −x dx ] = q 4πε0 [ 1 2r1 γ(3, 2r1/a0) + 1 a0 Γ(2, 2r1/a0) ] . We have identiﬁed the integrals as incomplete gamma functions. Alter- natively, because the ﬁrst arguments of these functions are integers, they can be written entirely in terms of elementary functions. 16.3.8. ψ(r1) = 1 4πε0 · 1 24 [ 1 r1 γ (5, r1 a0 ) + 1 a0 Γ ( 4, r1 a0 )] √4π Y 0 0 (θ1, ϕ1) − 1 4πε0 · 1 120 [ a 2 r3 1 γ (7, r1 a0 ) + r2 1 a3 Γ ( 2, r1 a0 )] √ 4π 5 Y 0 2 (θ1, ϕ1). 16.3.9. (a) Place this alleged delta function into the integral of an arbitrary(Ω2) = f (θ2, ϕ2): ∞∑ l=0 l∑ m=−l Y m l (Ω1) ∫ Y m l (Ω2) ∗f (Ω2) dΩ2 = ∞∑ l=0 l∑ m=−l Y m l (Ω1) clm , CHAPTER 3. EXERCISE SOLUTIONS 266 where we now recognize clm as the coeﬃcient of Y m l in the Laplace ex- pansion of f (Ω). The summations will therefore yield Y m l (Ω1); this result is the deﬁning property of the delta function. (b) Use Eq. (16.57) to replace the summation over m with its equivalent in terms of Pl(cos χ), where χ is the angle between Ω1, i.e., (θ1, ϕ1), and Ω2, i.e., (θ2, ϕ2). 16.3.10. (a) Replace Y 0 0 by 1/√4π; there remains only a normalization integral. (b) Replace Y 0 1 by √ 3/4π cos θ and use Eq. (15.150), after which the integral reduces due to the orthonormality of the remaining factors. (c) and (d) Replace Y 1 1 by −√ 3/8π sin θ eiϕ and use Eq. (15.151). 16.3.11. (a) Use the recurrence formula for the Legendre polynomials, Eq. (15.18), to convert xPL into a linear combination of PL+1 and PL−1. Then invoke orthogonality and use the normalization of PN , given in Eq. (15.38). (b) Apply the recurrence formula twice, converting x2PL into a linear combination of PL and PL±2 and simplify using orthogonality and nor- malization. 16.3.12. (a) From the recurrence formula, Eq. (15.18), xPn is a linear combination of only Pn−1 and Pn+1, so these are the only nonvanishing coeﬃcients in its expansion (which is unique). 16.4 Vector Spherical Harmonics 16.4.1. The answers are given in the text. 16.4.2. The parity is the same as that of the spherical harmonic, whose parity is controlled by its value of the lower index L (which is the second index of the vector spherical harmonic). Therefore the parity of YLLM is (−1) L, while YL,L+1,M and YL,L−1,M have parity (−1) L+1. 16.4.3. The orthogonality integral is ∫ Y∗ JLMJ · YJ ′L′M ′ J dΩ = ∑ m ∑ µ,µ′ C(L1J|µmMJ )C(L ′1J ′|µ ′mM ′ J ) ∫ (Y µ L ) ∗Y µ′ L′ dΩ = ∑ m,µ C(L1J|µmMJ )C(L1J ′|µmM ′ J )δLL′ . At least one of the Clebsch-Gordan coeﬃcients is zero unless MJ = MJ ′, we must have µ = Mj − m, and the sum of the squares of the Clebsch- CHAPTER 3. EXERCISE SOLUTIONS 267 Gordan coeﬃcients is δJJ ′. Thus, ∫ Y∗ JLMJ · YJ ′L′M ′ J dΩ = δJJ ′ δLL′ δMJ MJ′ . 16.4.5. Write ∑ M Y∗ LLM YLLM = ∑ µmM C(L1L|µmM ) 2(Y µ L ) ∗Y µ L . We have used the condition µ+m = M on the Clebsch-Gordan coeﬃcients to set equal the upper indices of the Y µ L . The sum over M of the squares of the Clebsch-Gordan coeﬃcients (for any ﬁxed µ) yields unity, and we are left with ∑ M Y∗ LLM YLLM = ∑ µ (Y µ L ) ∗Y µ L = 2L + 1 4π , where we have recognized the ﬁnal sum over µ as a special case of Eq. (16.57) for Ω1 = Ω2 (thereby making it a case for which cos γ = 1). 16.4.6. The cross product is orthogonal to both its vectors, so the dot product in the integrand yields zero. CHAPTER 3. EXERCISE SOLUTIONS 268 17. Group Theory 17.1 Introduction to Group Theory 17.1.1. From Table 17.2 of the text, we see that for any element R of the Vier- ergruppe, R2 = I, so we cannot reach all elements of the group as powers of any one element; that means the group is not cyclic. Moreover, the table shows that for any elements R and R′, RR′ = R′R, so the group is abelian. 17.1.2. (a) The group operation here is the successive application of two permu- tations. (1) Successive permutations result in a permutation, so the set of permutations is closed under the group operation. (2) We get the same result if we carry out three permutations in order, i.e., as c ∗ (b ∗ a), or ﬁrst identify the permutation (c ∗ b) and make the successive permutations corresponding to (c ∗ b) ∗ a. (3) The identity I is the “permutation” that does not change the ordering of the objects; I ∗ a and a ∗ I are both A. (4) The inverse of a permutation is clearly also a permutation; it restores the original order. (b) Name the permutations I (no reordering), P12 (interchange objects 1 and 2, leaving 3 in its original position), P13, P23, P123 (move 1 to the orig- inal position of 2, 2 to the original position of 3, 3 to the original position of 1), so P123abc = cab, and P321 (move 3 to the original position of 2, 2 to the original position of 1, 1 to the original position of 3), so P321abc = bca. Then build the group multiplication table shown in Table 17.1 of this man- ual by noting that, for example, P12P13abc = P12cba = bca = P321abc, so P12P13 = P321. From this and other successive operations, we can identify all elements of the group multiplication table. (c) The multiplication table for this group S3 can be put into one-one correspondence with that in Table 17.1 of the text for D3, if we identify P12 with C2, P13 with C ′ 2, P23 with C ′′ 2 , P321 with C3, and P123 with C ′ 3. Since the correspondence is one-to-one, the groups are isomorphic. The Table 17.1 Multiplication table, permutations of three objects S3 I P12 P13 P23 P123 P321 I I P12 P13 P23 P123 P321 P12 P12 I P321 P123 P23 P13 P13 P13 P123 I P321 P12 P23 P23 P23 P321 P123 I P13 P12 P123 P123 P13 P23 P12 P321 I P321 P321 P23 P12 P13 I P123 CHAPTER 3. EXERCISE SOLUTIONS 269 correspondence, however, is not unique; we could have associated any oneP12, P13, or P23 with C2, with possible changes in the identiﬁcations of P123 and P321. 17.1.3. Suppose that b and c are diﬀerent elements of our group, and that ab = ac. Multiply each side of this equation on the left by a −1 (which must exist, since a is a member of a group). We then get b = c, which contradicts our initial assumption. Thus, all the elements aI, a 2, ab, . . . must be distinct, and therefore constitute a permutation of the group elements. 17.1.4. We need to verify that the set of xhix−1 satisfy the group conditions. 1. The product of two elements is a group member: (xhix −1)(xhjx−1) = xhihjx−1 = xhkx −1 , where hk = hihj is a member oif H. 2. Since all the multiplications involved are associative, the insertion of x and x −1 cannot aﬀect the associativity. 3. xIx −1 is the unit element of our conjugate subgroup. 4. Direct multiplication shows that xh −1 i x −1 is the inverse of xhix −1. 17.1.5. (a) Because our group is abelian, ab = c implies ba = c. Taking the inverse of this last expression, we have a −1b −1 = c −1, showing that the set of inverses of the group elements forms a group isomorphic with the original group. (b) If the two groups are isomorphic with a ↔ a −1, then ab = c implies a−1b −1 = c −1; taking the inverse of this equation, we reach ba = c, show- ing that the original group is abelian. The isomorphism further implies that the group of inverses must also be abelian. 17.1.6. (a) A 90◦ positive rotation of the cubic crystal (about the z-axis of a right-handed system) causes x −→ y and y −→ −x. Applying this transformation to the atom at (la, ma, na) causes it to now be located at (−ma, la, na), which is a point that contained another atom before the rotation. (b) The positive x-axis of the crystal can be placed in any one of six orientations (the ±x, ±y, or ±z directions of a ﬁxed-space axial system). Then the positive y-axis of the crystal can be placed (applying a rotation) in any one of the four directions perpendicular to the direction chosen for the crystal x-axis. Finally, the positive z-axis of the crystal can be placed in one of the two directions perpendicular to the crystal x- and y-axes (applying a reﬂection if necessary). Thus, the number of possible orientations is 6 · 4 · 2 = 48, and that will be the dimension of the cubic point group. CHAPTER 3. EXERCISE SOLUTIONS 270 17.1.7. (a) Point A of the hexagonal tiling is a three-fold axis (rotation 2π/3, which is 120 ◦). The 2 × 2 matrix transforming a point (x, y) by this rotation is C3 = ( −1/2 − √3/2 √3/2 −1/2 ) . (b) Point B us a six-fold axis (rotation π/3, which is 60◦). Its 2×2 matrix is C6 = ( 1/2 − √3/2 √3/2 1/2 ) . 17.2 Representation of Groups 17.2.1. Because the U K(a) are members of a representation, U K(aa −1) must be equal to U K(a)U K(a−1). But U K(aa −1) = U K(I), which is a unit matrix, which in turn means that U K(a −1) = [ U K(a) ]−1. 17.2.2. Since the matrix of I is a unit matrix, the group operations Ia, aI, Ib, bI, Ic, and cI are consistent with the corresponding matrix products. Since A = −I, it is easy to verify that AB = BA = −B = C and that AC = CA = −C = B, all of which are consistent with the group multiplication table. By matrix multiplication we also ﬁnd that BC = CB = A, completing our check of the representation. 17.2.3. The matrix U = ( 1/√2 1/ √2 1/√2 −1/ √2 ) transforms B and C to B ′ = ( 1 0−1 ) , C ′ = ( −1 0 0 1 ) . The transformation does not change I or A. Because all four representation matrices are now block diagonal (the two blocks are 1 × 1), the elements U11 of the transformed matrices form a one-dimensional representation, as do the U22 elements. 17.2.4. (a) Apply the determinant product theorem: If AB = C, then also det(A) det(B) = det(C). CHAPTER 3. EXERCISE SOLUTIONS 271 (b) From the representation U (I) = ( 1 0 0 1 ) , U (C3) = ( −1/2 − √3/2 √3/2 −1/2 ) , U (C 2 3 ) = ( −1/2 √3/2 − √3/2 −1/2 ) , U (σ) = ( 1 0−1 ) , U (σ′) = ( 1/2 √ 3/2 √3/2 −1/2 ) , U (σ′′) = ( 1/2 − √3/2 −√3/2 −1/2 ) , we take determinants: U (I) = U (C3) = U (C 2 3 ) = 1, U (σ) = U (σ′) = U (σ′′) = −1. 17.2.5. To verify the representation property we note ﬁrst that repeated applica- tion of r, starting from r0 = 1, produces 1, r, r2, etc. It is also necessary that rn = 1. From the form given for r, we have rn = exp(2πis) which, because s is an integer, evaluates to unity. Finally, note that rmrk = rm+k and that if m + k ≥ n we can divide the result by unity (in the form rn) to obtain a element rm ′ with m′ in the range (0, n − 1). 17.2.6. This group, D4, has eight elements, which we denote I, C4, C2, C 3 4 , σx, σy, σd, and σd′ . I is the identity, C4, C2 = C 2 4 , and C 3 4 are rotations, σx is the reﬂection x ↔ −x, σy ia y ↔ −y, σd is a reﬂection about the line x = y, while σ′ d is a reﬂection about the line x = −y. The group multiplication table is D4 I C4 C2 C 3 4 σx σy σd σ′ d I I C4 C2 C 3 4 σx σy σd σ′ d C4 C4 C2 C 3 4 I σ′ d σd σx σy C2 C2 C 3 4 I C4 σy σx σ′ d σd C 3 4 C 3 4 I C4 C2 σd σ′ d σy σx σx σx σd σy σ′ d I C2 C4 C 3 4 σy σy σ′ d σx σd C2 I C 3 4 C4 σd σd σy σ′ d σx C 3 4 C4 I C2 σ′ d σ′ d σx σd σy C4 C 3 4 C2 I CHAPTER 3. EXERCISE SOLUTIONS 272 A 2 × 2 irreducible representation of this group is U (I) = ( 1 0 0 1 ) , U (C4) = ( 0 1 −1 0 ) , U (C2) = ( −1 0−1 ) , U (C 3 4 ) = ( 0 −1 1 0 ) , U (σx) = ( 1 0−1 ) , U (σy) = ( −1 0 0 1 ) , U (σd) = ( 0 1 1 0 ) , U (σ′ d) = ( 0 −1 −1 0 ) . 17.3 Symmetry and Physics 17.3.1. Referring to Fig. 17.2 of the text, the basis functions of the present prob- lem are p orbitals centered at each vertex of the triangle and oriented perpendicular to the plane of the triangle. Since all these orbitals are of opposite sign above and below this plane, they cannot be used to con- struct a representation that does not change sign when the triangle is turned over. Denoting the individual orbitals ϕi, we can form the linear combination ψ0 = ϕ1 + ϕ2 + ϕ3, and it is clear that ψ1 will be invariant with respect to I and the rotations C3 and C ′ 3, but will change sign under the operations C2, C ′ 2, and C ′′ 2 , and will therefore form a basis for the one-dimensional representation we call A2. There are no other linear combinations of the basis functions that remain invariant (except for a possible sign change) under all the operations of D3, so the two members of our basis space independent of ψ0 must be associated with an irreducible representation of dimension 2. Example 17.3.2 provides a clue as to how to proceed. Weψ1 = (ϕ1 − ϕ3)/ √ 2, ψ2 = (−ϕ1 + 2ϕ2 − ϕ3)/ √6, and with Fig. 17.2 at hand, develop relationships such as the following, which may be hard to ﬁnd but are easily checked: C3ψ1 = (ϕ2 − ϕ1)/ √ 2 = − 1 2 ϕ1 + √3 2 ϕ2, C3ψ2 = (−ϕ2 + 2ϕ3 − ϕ1) = − √3 2 ϕ1 − 1 2 ϕ2. These relationships can be expressed as the matrix equation U(C3) ( ϕ1 ϕ2 ) , with U(C3) = ( −1/2 √3/2 −√3/2 −1/2 ) . Some of the operations yield diagonal matrices, such as Iψ1 = ψ1, Iψ2 = ψ2, C ′ 2ψ1 = −ψ1, C ′ 2ψ2 = −ψ2, CHAPTER 3. EXERCISE SOLUTIONS 273 with U(I) = ( 1 0 0 1 ) , U(C ′ 2) = ( −1 0−1 ) . This is the representation of D3 called E and discussed in Example 17.2.1. 17.4 Discrete Groups 17.4.1. (a) Since the Vierergruppe is abelian, all expressions of the form gag−1 reduce to a, so every element is in a class by itself. There are therefore four classes. (b) There are four irreducible representations. The only way the dimen- sionality theorem, Eq. (17.10), can be satisﬁed is for each irreducible rep- resentation to be 1 × 1. (c) There will be one irreducible representation whose characters are all unity (usually called A1). The orthogonality theorem and the fact that all elements are their own inverses means that all other representations must have two classes (here, elements) with character +1 and two with character −1. There are three distinct ways to assign the minus signs (which cannot be assigned to I), leading to the following character table: I A B C A1 1 1 1 1 A2 1 1 −1 −1 A3 1 −1 1 −1 A4 1 −1 −1 1 17.4.2. (a) Denoting the permutation in the problem statement P123, indicating that it is the cycle 1 → 2 → 3 → 1, and writing Pij for the permutation that interchanges i and j, the six members of the D3 group have the 3 × 3 representation U (I) =  1 0 0 0 1 0 0 0 1  , U (P123) =  0 1 0 0 0 1 1 0 0  , U (P132) =  0 0 1 1 0 0 0 1 0  , U (P12) =  0 1 0 1 0 0 0 0 1  , U (P13) =  0 0 1 0 1 0 1 0 0  , U (P23) =  1 0 0 0 0 1 0 1 0  . CHAPTER 3. EXERCISE SOLUTIONS 274 (b) The reduction is to the direct sum of a 1 × 1 and a 2 × 2 representa- tion. The reduction is accomplished by applying the same transformation V U (P )V T to all members of the representation, where V is a unitary ma- trix and all the V U (P )V T have the same block structure. A matrix V that accomplishes the reduction is V =  1/ √ 3 1/√3 1/ √3 1/ √6 −2/ √6 1/ √6 1/ √2 0 −1/ √2  . We check by transforming some of the group elements: V U (P12)V T =  1 0 0−1/2 −√ 3/2 0 − √3/2 1/2  , V U (P13)V T =  1 0 0 0 1 0 0 0 −1  , V U (P123)V T =  1 0 0−1/2 √ 3/2 0 − √3/2 −1/2  . All the transformed matrices have the form of a 1×1 block followed by a 2× 2 block. The block of dimension 1 is the A1 irreducible representation; that of dimension 2 is the E representation. Note that diﬀerent transformations can produce this representation with diﬀerent assignments of the matrices to group operations of the same class, and possibly even with the rows and columns in a permuted order. Comparing with the solution to Exercise 17.2.4, we see that the V we have used makes P123 correspond to C 2 3 , with P13 corresponding to σ. 17.4.3. (a) There are ﬁve classes, hence ﬁve irreducible representations. The group has eight elements, so the squares of the dimensions of the irreducible representations must add to 8. The only possibility is to have four repre- sentations of dimension 1 and one of dimension 2. (b) Since the characters of C4 for the representations of dimension 1 are all ±1, those of C2 can only be +1. The characters for I must all be equal to the dimension of the representation, and one representation, usually called1, must have all its characters equal to 1. Then, applying Eq. (17.9), the character of C2 for representation E must be −2 and the remaining CHAPTER 3. EXERCISE SOLUTIONS 275 characters for representation E must all vanish. This leaves us needing to assign one +1 and two (−1)s to the remaining items in the columns 2C4, 2C ′ 2, and 2C ′′ 2 ; this can be done in three diﬀerent ways. The result is the following character table (in which two of the representations are, for reasons we do not discuss, conventionally labeled B1 and B2. (The last row is not part of the table but is relevant to Exercise 17.4.4.) D4 I C2 2C4 2C ′ 2 2C ′′ 2 A1 1 1 1 1 1 A2 1 1 1 −1 −1 B1 1 1 −1 1 −1 B2 1 1 −1 −1 1 E 2 −2 0 0 0 Γ 8 0 0 4 0 17.4.4. We start by ﬁnding the characters of the representation spanned by the eight functions; we do so by determining how many of the eight func- tions remain unchanged when we perform an operation on a member of each class. For the class containing I all eight basis functions remain un- changed, so Γ(I) = 8. Taking next C4, under which x → y and y → −x, no basis function remains unchanged, so Γ(C4) = 0. For C2 under which x → −x and x → −y, no function remains unchanged, so Γ(C2) = 0. For C ′ 2, x 2y, −x 2y, y3, and −y3 remain unchanged, so Γ(C ′ 2) = 4. And for C ′′ 2 , no function remains unchanged, so Γ(C ′′ 2 ) = 0. These data are appended to the D4 character table generated in the solution to Exercise 17.4.3. Applying Eq. (17.12) successively for each irreducible representation, we ﬁnd Γ = 2A1 ⊕ 2B1 ⊕ 2E. This result can be checked by adding (with appropriate coeﬃcients) entries from the character table. 17.4.5. (a) Denote the four orbitals x, y, −x, −y, where these names indicate the locations of their centers. We identify the rows and columns of our representation matrices as corresponding to the basis in the above-given order. Thus, the matrix of C4, in which x → y, y → −x, −x → −y, −y → x, is C4 =  0 0 0 1 1 0 0 0 0 1 0 0 0 0 1 0  . The matrix of I, in which all basis functions remain unchanged, and that of C2, in which x ↔ −x and y ↔ −y, are I =  1 0 0 0 0 1 0 0 0 0 1 0 0 0 0 1  , C2 =  0 0 1 0 0 0 0 1 1 0 0 0 0 1 0 0  . CHAPTER 3. EXERCISE SOLUTIONS 276 Next we take the member of the σv class that corresponds to reﬂection about the y axis. For this operation, y → y and −y → −y, but x ↔ −x. And ﬁnally, we take the σd operation that is a reﬂection over a plane containing the line x = y. For this operation, x ↔ y and −x ↔ −y. These operations are represented by σv =  0 0 1 0 0 1 0 0 1 0 0 0 0 0 0 1  , σd =  0 1 0 0 1 0 0 0 0 0 0 1 0 0 1 0  . Taking the traces of the above matrices, we have Γ(I) = 4, Γ(C4) = Γ(C2) = Γ(σd) = 0, and Γ(σv) = 2. (b) Applying Eq. (17.12), using the above Γ and the characters in the table included in this exercise, we ﬁnd Γ = A1 ⊕ B1 ⊕ E. (c) At arbitrary scale, ψA1 = (x) + (y) + (−x) + (−y). We note that ψB1 must change sign on application of C4 and σd, but not σv, and therefore will have the form ψB1 = (x) − (y) + (−x) − (−y). The two-dimensional space orthogonal to these basis functions will be spanned by a basis for E. One choice is χ1 = (x) + (y) − (−x) − (−y), χ2 = (x) − (y) − (−x) + (−y). 17.4.6. (a) Label the basis functions located at (x, 0) px(x), py(x), where the subscript denotes the orientation of the p orbital and the parenthesized argument denotes its location. We assume that the positive lobe of thex orbital points toward positive x, no matter where it is located. Similar remarks apply to the py orbitals. Note that if px(x) is subjected to the C4 operation that brings it to location y, px is thereby transformed to py, so C4px(x) = py(y). As another example, the operation σv that is reﬂection about the y axis converts px(x) into −px(−x) but changes py(x) into py(−x). this same σv converts px(y) into −px(y) but leaves py(y) unchanged. Using the principles illustrated by the above, and designating the rows and columns of the representation matrices to correspond, in order, to px(x), py(x), px(y), py(y), px(−x), py(−x), px(−y), py(−y), we develop the representation=  1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1  C4 =  0 0 0 0 0 0 0 −1 0 0 0 0 0 0 1 0−1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 −1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 −1 0 0 0 0 0 0 1 0 0 0  CHAPTER 3. EXERCISE SOLUTIONS 277 C2 =  0 0 0 0 −1 0 0 0 0 0 0 0 0 −1 0 0 0 0 0 0 0 0 −1 0 0 0 0 0 0 0 0 −1 −1 0 0 0 0 0 0 0−1 0 0 0 0 0 0 0 0 −1 0 0 0 0 0 0 0 0 −1 0 0 0 0  σv =  0 0 0 0 −1 0 0 0 0 0 0 0 0 1 0 0 0 0 −1 0 0 0 0 0 0 0 0 1 0 0 0 0 −1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 −1 0 0 0 0 0 0 0 0 1  σd =  0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0  (b) From the above matrices, the characters of the reducible basis areI) = 8, Γ(C4) = Γ(C2) = Γ(σv) = Γ(σd) = 0. Using Eq. (17.12), we ﬁnd Γ = A1 ⊕ A2 ⊕ B1 ⊕ B2 ⊕ 2E. (c) All the representations of dimension 1 have basis functions that are invariant under C2. Those named A must also be invariant under C4, while those named B must change sign under C4. These observations suﬃce to identify the following symmetry bases: ψA1 = px(x) + py(y) − px(−x) − py(−y) ψA2 = py(x) − px(y) − py(−x) + px(−y) ψB1 = px(x) − py(y) − px(−x) + py(−y) ψB2 = py(x) + px(y) − py(−x) − px(−y) Both members of each E basis must change sign under C2 and be trans- formed into each other under C4. There are two independent sets of basis functions that satisfy this requirement. Denoting one set (θ1, θ2) and the other (χ1, χ2), they can be θ1 = px(x) + px(y) + px(−x) + px(−y) θ2 = py(x) + py(y) + py(−x) + py(−y) χ1 = px(x) − px(y) + px(−x) − px(−y) χ2 = py(x) − py(y) + py(−x) − py(−y) CHAPTER 3. EXERCISE SOLUTIONS 278 17.5 Direct Products 17.5.1. (a) Squaring the characters for E, we have Γ(I) = Γ(C2) = 4, Γ(C4) = Γ(σv) = Γ(σd) = 0. Applying Eq. (17.12) successively for each irreducible representation, using Table 17.4 of the text, E ⊗ E = A1 ⊕ A2 ⊕ B1 ⊕ B2; there is no E representation in this direct product. (b) Some operations (deﬁned as in Figure 17.6 of the text): C4ϕ1 = ϕ2, C4ϕ2 = −ϕ1, C2ϕ1 = −ϕ1, C2ϕ2 = −ϕ2, σvϕ1 = −ϕ1, σvϕ2 = ϕ2, σdϕ1 = −ϕ2, σdϕ2 = −ϕ1. (c) ϕA1 = x1x2 + y1y2, ϕA2 = x1y2 − y1x2, ϕB1 = x1x2 − y1y2, ϕB2 = x1y2 + y1x2. 17.6 Symmetric Group 17.6.1. (a)  0 0 0 1 1 0 0 0 0 0 1 0 0 1 0 0  (b) even. 17.6.2. (a) The four members of C4 are C4, C 2 4 = C2, and C 3 4 . By considering the cyclic permutations of a four-component vector, we get the representation U (I) =  1 0 0 0 0 1 0 0 0 0 1 0 0 0 0 1  , U (C4) =  0 1 0 0 0 0 1 0 0 0 0 1 1 0 0 0  , U (C2) =  0 0 1 0 0 0 0 1 1 0 0 0 0 1 0 0  , U (C 3 4 ) =  0 0 0 1 1 0 0 0 0 1 0 0 0 0 1 0  . (b) The Note provides an answer to this question. 17.6.3. (a) Because the group must be symmetric in the treatment of its elements, all permutations of the same cycle structure will be in the same class. The basic combinatorial fact we need is that the number of distinct permuta- tions corresponding to a cycle of n objects (linked in any order) is (n − 1)!. The possible cycle structures are: (1) (i)(j)(k)(l), the identity permutation, which forms a one-member class. (2) (i, j)(k)(l), which describes a single permutation. But (i, j) can be chosen in six ways, so this is a six-member class. CHAPTER 3. EXERCISE SOLUTIONS 279 (3) (i, j)(k, l). This also describes a single permutation, but we can assign four objects to this cycle structure in three diﬀerent ways, so we have a three-member class; note that (i, j)(k, l) is the same as (k, l)(i, j). (4) (i, j, k)(l); this cycle structure describes 2! permutations, and can be set up from four objects in four diﬀerent ways (that is the number of ways to choose the object to be left out). This class therefore has eight members; (5) (i, j, k, l); this cycle structure describes 3! permutations and can be set up in only one way, deﬁning a six-member class. Since there are ﬁve classes, there are ﬁve irreducible representations. (b) A1 is the completely symmetric representation, corresponding to all permutations leaving a single basis function unaltered. Its characters are all +1. A2 is the completely antisymmetric representation, with charac- ters of +1 for the even permutations and −1 for the odd permutations. (c) We now know that three of the ﬁve irreducible representations have dimensions 1, 1, and 2, whose squares sum to 6. The group S4 has 24 elements, so the two remaining irreducible representations must be of di-n4 and n5, with n 2 +n 2 = 18. This equation can only be satisﬁed if n4 = n5 = 3. Representations of dimension 3 are customarily labeled T , so our roster of irreducible representations is A1, A2, E, T1, and T2. (d) Setting up a character table and inserting the information we presently have (the complete characters of A1 and A2, the characters of I in all rep- resentations, and the zeros from the Hint), the partially complete table is the following: D4 I 6P12 3P12P34 8P123 6P1234 A1 1 1 1 1 1 A2 1 −1 1 1 −1 E 2 0 0 T1 3 T2 3 The remainder of the table can now be ﬁlled in with signed integers that cause the orthogonality conditions to be satisﬁed. The column 8P123 can only be completed by adding a single ±1; the orthogonality can only be maintained if in that column Γ(E) = −1 and Γ(T1) = Γ(T2) = 0. The columns 6P12 and 6P1234 can only be completed properly if T1 and T2 are assigned +1 and −1 (in opposite order in the two columns). Which column gets the +1 for T1 is not material because the choice only determines the relative meanings of T1 and T2. There is now only one consistent choice CHAPTER 3. EXERCISE SOLUTIONS 280 for the remaining characters; the complete table takes the form D4 I 6P12 3P12P34 8P123 6P1234 A1 1 1 1 1 1 A2 1 −1 1 1 −1 E 2 0 2 −1 0 T1 3 −1 −1 0 1 T2 3 1 −1 0 −1 17.7 Continuous Groups 17.7.1. It is convenient to use the generators of the SU(2) and SU(3) groups to identify the subgroup structure of the latter. As pointed out when writing Eq. (17.54), the Pauli matrices σi form a set of generators for SU(2), and they remain generators if they are expanded to 3 × 3 matrices by inserting a zero row and column before, after, or between the two rows and columns. We now search for SU(2) generators that can be formed from the eight generators of SU(3). One such set consists of λ1, λ2, and λ3. A second set consists of λ4, λ5, and ( √3 λ8 + λ3)/2. A third set is λ6, λ7, and ( √3 λ8 − λ3)/2. 17.7.2. To prove that the matrices U(n) form a group one needs to verify that they satisfy the group postulates: (1) They form a set that is closed under the group operation (matrix mul- tiplication), i.e., that the product of two unitary matrices is also unitary.U and V be unitary, so U † = U −1 and U † = U −1. Then (UV)† = V†U † = V−1U −1 = (UV) −1 , showing that UV is also unitary. (2) The group operation is associative. Matrix multiplication satisﬁes this requirement. (3) There is an identity element; it is the unit matrix 1n. (4) Each element has an inverse; we have an explicit rule for constructing it; it is the matrix adjoint.(n) is the subset of U(n) hose members have determinant +1; to identify that it is a subgroup we need to verify that it satisﬁes the group postulates: (1) From the determinant product theorem, if U and V have determinant +1, so does UV. We have a closed subset. (2) Matrix multiplication is associative.SU(n) includes the identity element. (4) Again invoking the determinant product theorem, if U has determinant +1, so does U −1. CHAPTER 3. EXERCISE SOLUTIONS 281 17.7.3. With the Euler angles deﬁned as in Section 3.4, the coordinate rotationα, β, γ) is deﬁned by a matrix product of the form given in Eq. (3.36), but with the matrices those deﬁned by Eq. (17.56). Thus, U(α, β, γ) = ( e iγσ3/2) (e iβσ2/2) (e iασ3/2) Using Eq. (17.57) to write explicit forms for these matrices, we get U(α, β, γ) = ( e iγ/2 0 0 e −iγ/2 ) ( cos(β/2) sin(β/2) − sin(β/2) cos(β/2) ) ( e iα/2 0 0 e −iα/2 ) Performing the matrix multiplications, U(α, β, γ) = ( e i(α+γ)/2 cos(β/2) e −i(α−γ)/2 sin(β/2) −e i(α−γ)/2 sin(β/2) e −i(α+γ)/2 cos(β/2) ) 17.7.4. (a) Starting from (I, Y ) = ( 3 2 , 1) = uuu, repeatedly apply I− = I−(1) + I−(2)+I−(3) until a further application would produce a zero result. This operator decreases I by 1 and changes u to d. Thus, (I, Y ) = ( 3 2 , 1) : uuu ( 1 2 , 1) : duu + udu + uud (− 1 2 , 1) : 2(ddu + dud + udd) (− 3 2 , 1) : 6ddd Returning to uuu, (1) apply once V−, which decreases I by 1/2, decreases Y by 1, and changes u to s, and then (2) apply I− repeatedly until a zero is produced: (I, Y ) = (1, 0) : suu + usu + uus (0, 0) : sdu + sud + dsu + usd + dus + uds (−1, 0) : 2(sdd + dsd + dds) We continue, applying V−, then I−, and ﬁnally V−, after which the three- quark subspace is exhausted. These steps correspond to (I, Y ) = ( 1 2 , −1) : 2(ssu + sus + uss) (− 1 2 , −1) : 2(ssd + sds + dss) (0, −2) : 6sss (b) The three-quark subspace with (I, Y ) = ( 1 2 , 1) is spanned by uud, udu, and duu. One vector in this subspace is a member of the representation 10; vectors orthogonal to the member of 10 must belong to other repre- sentations. The vectors ψ1 and ψ2 are orthogonal both to uud +udu + duu and to each other. CHAPTER 3. EXERCISE SOLUTIONS 282 (c) The following chart shows how, starting from ψ1, we can make the ﬁve additional members of 8 listed in this part of the exercise. ψ1( 1 2 , 1) : udu − duu I−ψ1( 1 2 , 1) = ψ1(− 1 2 , 1) : udd − dud V−ψ1(− 1 2 , 1) = ψ1(−1, 0) : sdd − dsd U−ψ1(−1, 0) = ψ1(− 1 2 , −1) : sds − dss I+ψ1(− 1 2 , −1) = ψ1( 1 2 , −1) : sus − uss V+ψ1( 1 2 , −1) = ψ1(1, 0) : suu − usu (d) Each of the following operations produces a function with (I, Y ) = (0, 0): V−ψ1( 1 2 , 1) = V−(udu − duu) = sdu + uds − dsu − dus U−ψ1(− 1 2 , 1) = U−(udd − dud) = usd + uds − sud − dus I+ψ1(−1, 0) = I+(sdd − dsd) = sud + sdu − usd − dsu V+ψ1(− 1 2 , −1) = V+(sds − dss) = uds + sdu − dus − dsu U+ψ1( 1 2 , −1) = U+(sus − uss) = dus + sud − uds − usd I−ψ1(1, 0) = I−(suu − usu) = sdu + sud − dsu − usd The fourth of the above expressions is the same as the ﬁrst; the ﬁfth is−1) times the second; the sixth is the same as the third, and the third is equal to the ﬁrst minus the second. So there are two members of the octet at (Y, I) = (0, 0), namely sdu + uds − dsu − dus and usd + uds − sud − dus. These functions are not orthonormal, but can be made so: in orthonormal form, they are (sdu + uds − dsu − dus)/2 and (sdu − uds − dsu + dus − 2usd + 2sud)/ √ 12. (e) Repeating the steps of parts (c) and (d) with ψ2, we ﬁnd ψ2( 1 2 , 1) = 2uud − udu − duu ψ2(− 1 2 , 1) = dud + udd − 2ddu ψ2(−1, 0) = dsd + sdd − 2dds ψ2(− 1 2 , −1) = 2ssd − sds − dss ψ2( 1 2 , −1) = 2ssu − sus − uss ψ2(1, 0) = usu + suu − 2uus The two (0, 0) members of the ψ2 octet are (after orthonormalization) (uds + dus − dsu − sdu)/2 and (uds − 2usd + dus + dsu − 2sud + sdu)/ √12. It is obvious by inspection that the ψ1 and ψ2 functions are linearly inde- pendent. (f) The subspace (Y, I) = (0, 0) is spanned by the six quark products uds, usd, dus, dsu, sud, sdu. In the earlier parts of this exercise we found one CHAPTER 3. EXERCISE SOLUTIONS 283 (0, 0) function in representation 10, and two from each of the representa- tions 8. In normalized form, they are ϕ1 = (uds + usd + dus + dsu + sud + sdu)/ √6 ϕ2 = (uds − dus − dsu + sdu)/2 ϕ3 = (uds + 2usd − dus + dsu − 2sud − sdu)/ √12 ϕ4 = (uds + dus − dsu − sdu)/2 ϕ5 = (uds − 2usd + dus + dsu − 2sud + sdu)/ √12. The function from the (Y, I) = (0, 0) subspace that is orthgonal to all these functions belongs to representation 1, and can be found from the above by the Gram-Schmidt process. Carrying out that process, we ﬁnd6 = (uds − usd − dus + dsu + sud − sdu)/ √ 6. The orthogonality to ϕi, i = 1 to 5, is easily checked. 17.8 Lorentz Group 17.8.1. A reference frame moving at inﬁnitestimal velocity cδρ at an angle θ from the x-axis in the xy plane will cause the x, y, and x0 (= ct) coordinates to transform linearly to ′ = x−cos θ(δρ)x0, y′ = y−sin θ(δρ)x0, x′ = x0−a(δρ)x−b(δρ)y , where a and b are determined by requiring x 2 + y2 − x 2 to remain constant to ﬁrst order in δρ. Writing 2xdx + 2ydy − 2x0dx0 = 0 and inserting the diﬀerentials, we have −2x cos θ(δρ)x0 − 2y sin θ(δρ)x0 + 2x0a(δρ)x + 2x0b(δρ)y = 0, from which we ﬁnd a = cos θ, b = sin θ. The 4 × 4 matrix equation for this linear transformation is  x ′ x ′ y′ z′  =  1 −δρ cos θ −δρ sin θ 0 −δρ cos θ 1 0 0 −δρ sin θ 0 1 0 0 0 0 1   x0 x y z  . If the matrix in the above equation is written 14 + (δρ)iS, S can be identi- ﬁed as the generator of a boost in the direction deﬁned by θ and will have the form given in the exercise. 17.8.2. (a) U = e iρS = e −ρM, where M is the matrix S of Exercise 17.8.1 without the prefactor i. If we calculate powers of M we ﬁnd M =  0 cos θ sin θ 0 cos θ 0 0 0 sin θ 0 0 0 0 0 0 0  , M2 =  1 0 0 0 0 cos2 θ cos θ sin θ 0 0 cos θ sin θ sin 2 θ 0 0 0 0 0  , CHAPTER 3. EXERCISE SOLUTIONS 284 and M 3 = M, so all odd powers of M are equal to M, while all even nonzero powers of M are equal to M 2. This enables us to reduce e −ρM as follows: e −ρM = 14 + M ( − ρ 1! − ρ3 3! − · · · ) + M2 ( ρ2 2! + ρ4 4! + · · · ) = 14 − M sinh ρ + M2( cosh ρ − 1) . Insertion of the explicit forms for M and M 2 lead directly to U as given in the exercise. (b) Rotation to align the boost with the x-axis, followed by an x boost, and then the inverse rotation corresponds to forming R −1UxR, where R −1 = R T and R =  1 0 0 0 0 cos θ sin θ 0 0 − sin θ cos θ 0 0 0 0 1  , Ux =  cosh ρ − sinh ρ 0 0 − sinh ρ cosh ρ 0 0 0 0 1 0 0 0 0 1  . Using the above data to carry out the necessary matrix multiplications, the conﬁrmation of part (a) is immediate. 17.8.3. The transformation matrices arex =  cosh ρ − sinh ρ 0 0 − sinh ρ cosh ρ 0 0 0 0 1 0 0 0 0 1  , Uy =  cosh ρ′′ 0 − sinh ρ′′ 0 0 1 0 0 − sinh ρ′′ 0 cosh ρ′′ 0 0 0 0 1  The successive boosts correspond to the matrix product UyUx: UyUx =  cosh ρ′′ cosh ρ′ − cosh ρ′′ sinh ρ′ − sinh ρ′′ 0 − sinh ρ′ cosh ρ′ 0 0 − sinh ρ′′ cosh ρ′ sinh ρ′′ sinh ρ′ cosh ρ′′ 0 0 0 0 1  . This matrix is not symmetric, and unless either ρ′ or ρ′′ is zero it can- not correspond to any case of the matrix of Exercise 17.8.2, and cannot represent a pure boost. 17.9 Lorentz Covariance of Maxwell’s Equations 17.9.1. Form the transformed electromagnetic tensor as the matrix product F′ = UFU , and bring to ﬁnal form by using the identities βc = v and γ2(1 − β2) = 1. Then F ′ 21 = E′ x, F ′ 31 = E′ y, F ′ 41 = E′ z, CHAPTER 3. EXERCISE SOLUTIONS 285 in agreement with Eq. (17.82). The transformed components of B are obtained from B′ x = c −1F ′ 43, B′ y = c −1F ′ 24, B′ z = c −1F ′ 32; they agree with Eq. (17.83). 17.9.2. It is convenient to introduce the direction cosines of v; denote the angles between v and the coordinate axes χ1, χ2, χ3. Then the generalization of M and M 2 (see the solution to Exercise 17.8.2) to an arbitrary direction of v are M =  0 cos χ1 cos χ2 cos χ3 cos χ1 0 0 0 cos χ2 0 0 0 cos χ3 0 0 0  , M2 =  1 0 0 0 0 cos2 χ1 cos χ1 cos χ2 cos χ1 cos χ3 0 cos χ1 cos χ2 cos2 χ2 cos χ2 cos χ3 0 cos χ1 cos χ3 cos χ2 cos χ3 cos2 χ3  . From these, form U = 14 −M sinh ρ+M2(cosh ρ−1), and use the notations cosh ρ = γ, sinh ρ = βγ. The sum ∑i cos2 χi = 1 is also used to simplify U . The result is  γ −βγ cos χ1 −βγ cos χ2 −βγ cos χ3 −βγ cos χ1 1 + (γ − 1) cos2 χ1 (γ − 1) cos χ1 cos χ2 (γ − 1) cos χ1 cos χ3 −βγ cos χ2 (γ − 1) cos χ1 cos χ2 1 + (γ − 1) cos2 χ2 (γ − 1) cos χ2 cos χ3 −βγ cos χ3 (γ − 1) cos χ1 cos χ3 (γ − 1) cos χ2 cos χ3 1 + (γ − 1) cos2 χ3  . Finally, form the matrix F′ = U FU . This operation produces a relatively complicated matrix that can be simpliﬁed to give the desired result. It becomes easier to ﬁnd simpliﬁcation steps if one identiﬁes the subexpres- sions corresponding to Ev and Bv (the magnitudes of the projections of E and B on v); the formulas for these quantities are Ev = cos χ1Ex+cos χ2Ey+cos χ3Ez, Bv = cos χ1Bx+cos χ2By+cos χ3Bz. Another helpful hint is to recognize that γ2(1 − β2) = 1 and at some point to write β = v/c. 17.10 Space Groups (no exercises) CHAPTER 3. EXERCISE SOLUTIONS 286 18. More Special Functions 18.1 Hermite Functions 18.1.1. It is convenient to use the formula in Eq. (18.4) for H ′ n, but it was not one of the relationships whose validity was to be assumed. However, Eq. (18.4) can be derived from the ODE, assuming the validity for all x of the basic recurrence formula, Eq. (18.3). Proceed by forming (Hn+1 − 2xHn + 2nHn−1)′′ − 2x(Hn+1 − 2xHn + 2nHn−1)′ + 2n(Hn+1 − 2xHn + 2nHn−1) = 0 , then expand the parenthesized derivatives and use the Hermite ODE to cancel as many terms as possible. In this way we reach −2Hn+1 + 4xHn + 4nHn−1 − 4H ′ n = 0 , equivalent, again using Eq. (18.3), to H ′ n = 2nHn−1 . (a) Now diﬀerentiate g(x, t) with respect to x and use the above derivative formula: ∂g ∂x = ∞∑ n=0 H ′ n(x) tn n! = ∞∑ n=0 2nHn−1 tn n! = 2t g(x, t) . (b) This is a separable ﬁrst-order equation with solution g(x, t) = e 2txf (t) . (c) Find f (t) by setting x = 0 and using H2n(0) = (−1) n(2n)!/n! and H2n+1(0) = 0. We get g(x, 0) = f (t) = ∞∑ n=0 (−1)nt 2n n! = e −t 2 . (d) The ﬁnal result is g(x, t) = e 2xt−t 2. 18.1.2. The connection of these starting points can, of course, be accomplished in many ways. Starting with the ODE, one can derive a Rodrigues formula as shown in Eq. (18.8), and therefrom, as in Eq. (12.18), a Schlaeﬂi integral represen- tation. Applying Eq. (12.18), we can use the Schlaeﬂi integral to obtain a generating function, which can in turn be applied, e.g., by developing recurrence formulas and then using them as in the text after Eq. (18.7), to recover the Hermite ODE. Since these steps form a closed loop, we can CHAPTER 3. EXERCISE SOLUTIONS 287 regard any of the four relationships as a valid starting point. From the Rodrigues formula we can also, by repeated integrations by parts, establish the orthogonality of the Hermite polynomials on (−∞, ∞) and note the associated weighting factor; conversely, the weighting factor suf- ﬁces to determine the ODE that yields the orthogonal polynomials. These last relationships mean that we can begin an analysis from any of the ﬁve listed starting points. 18.1.3. From Eq. (18.9) we see that i −n(2x) −nHn(ix) = [n/2]∑ s=0 n!(4x 2)−s (n − 2s)!s! ≥ [n/2]∑ s=0 (−1) s n!(4x 2)−s (n − 2s)!s! = (2x) −nHn(x) because the ﬁrst sum has only positive terms. Taking the absolute values of the ﬁrst and last members of the above relation and multiplying through by |(2x) n| we obtain the desired inequality. 18.1.4. The solution is given in the text. 18.1.5. The solution is given in the text. 18.1.6. The answers in the text are incorrect. In each answer, replace 2π by (2π) 1/2. (a) Using the generating function, form∞ −∞ e −x2/2g(x, t) dx = ∫ ∞ −∞ e −t 2+2tx−x 2/2 dx = ∞∑ n=0 ∫ ∞ −∞ e −x2/2Hn(x) tn n! dx . Now convert the central member of this equation to obtain a power seriest, by ﬁrst completing the square in the exponent and performing the x integration, and then expanding the resultant function of t. Setting y = x − 2t we get ∫ ∞ −∞ e −t 2+2tx−x 2/2 dx = ∫ ∞ −∞ e −(x−2t)2/2+t 2 dx = e t 2 ∫ ∞ −∞ e −y2/2 dy = (2π)1/2e t 2 = (2π)1/2 ∞∑ m=0 t2m m! . We now equate the coeﬃcients of equal powers of t in the last two equa- tions, noting from the second of these equations that the integrals in- volving Hn of odd n vanish, and that those of even n correspond to the CHAPTER 3. EXERCISE SOLUTIONS 288 equation ∫ ∞ −∞ e −x2/2 H2m(x) (2m)! dx = (2π) 1/2 m! . This formula is equivalent to the corrected form of the answer. (b) This part of the exercise can be treated in a way similar to that of part (a). The relevant equation set is ∞∑ n=0 tn n! ∫ ∞ −∞e −x 2/2xHn(x) dx = ∫ ∞ −∞ e −(x−2t)2/2+t 2 x dx = e t 2 ∫ ∞ −∞ e −y2/2(y + 2t) dy = (2π) 1/2 ∞∑ m=0 2 t 2m+1 m! . The term of the integral containing a linear factor y vanishes due to its odd symmetry. The left-hand side of this equation must have zero coeﬃcients for even n, while for odd n (set to 2m + 1) we get 1 (2m + 1)! ∫ ∞ −∞ e −x 2/2 x H2m+1(x) dx = (2π) 1/2 2 m! = (2π) 1/2 2(m + 1) (m + 1)! , which easily rearranges into the corrected form of the answer. 18.1.7. (a) The solution is given in the text. (b) Deﬁning z + x = w, z2 − x2 = w2 − 2xw we have Hn(x) = n! 2πi ∮ e −w2+2xw wn+1 dw , H ′ n(x) = 2 n! 2πi ∮ e −w2+2xw wn dw , H ′′ n(x) = 4 n! 2πi ∮ e −w2+2xw wn−1 dw , and H ′′ n(x) − 2xH ′ n(x) + 2nHn(x) = n! 2πi ∮ e −w2+2xw wn+1 (2n − 4xw + 4w2) dw = −2 n! 2πi ∮ d dw ( e −w2+2xw wn ) dw = 0 , where a zero value is obtained because the start and end points of the contour coincide and the quantity being diﬀerentiated is analytic at all points of the contour. CHAPTER 3. EXERCISE SOLUTIONS 289 18.2 Applications of Hermite Functions 18.2.1. Combining the recursion formulas in Eqs. (18.3) and (18.4), we have Hn+1(x) = (2x − d dx )Hn(x) . This formula suggests that we use mathematical induction, since it shows that if the formula of this exercise is true for Hn(x), it is also true for Hn+1(x). To complete a proof we need to verify that the formula is valid for n = 0, i.e., that H1(x) = 2xH0(x) − H ′ 0(x). Since H0(x) = 1 and H1(x) = 2x, this equation is clearly satisﬁed. 18.2.2. Introduce the expansion x m = m∑ i=1 aiHi(x). Then, for m < n, using or- thogonality we have ∫ ∞ −∞ e −x 2 x mHn(x) dx = . 18.2.3. Using Eq. (18.3) to replace xHn(x) by 1 2 Hn+1(x) + nHn−1(x), then invok- ing orthogonality and inserting the normalization integral from Eq. (18.15), ∫ ∞ −∞ e −x2xHn(x)Hm(x) dx = 1 2 ∫ ∞ −∞ e −x2Hn+1(x)Hm(x) dx + n ∫ ∞ −∞ e −x 2 Hn−1(x)Hm(x) dx = [ 1 2 δn+1,m +nδn−1,m ]π1/22 mm! = 2nn! π1/2[(n + 1)δm,n+1 + 1 2 δm,n−1 ] . 18.2.4. Using Hn+1(x) = 2xHn(x) − 2nHn−1(x) we get I2 = ∫ ∞ −∞ x 2[Hn]2e −x2 dx = 1 4 ∫ ∞ −∞[Hn+1 + 2nHn−1]2e −x2 dx . Expanding, discarding terms that vanish due to orthogonality, and using the normalization integral, Eq. (18.15), I2 = 1 4 ∫ ∞ −∞[Hn+1] 2e −x2dx + n2 ∫ ∞ −∞[Hn−1]2e −x 2 dx = 2n−1√π n!(n + 1 + n) = 2 n−1√π n!(2n + 1) . CHAPTER 3. EXERCISE SOLUTIONS 290 18.2.5. Applying Eq. (18.3) twice, we get x 2Hn(x) = 1 4 Hn+2(x) + ( 2n + 1 2 ) Hn(x) + n(n − 1)Hn−2(x) . Substituting this form into the integral of this exercise, invoking orthogo- nality and using the normalization integral, Eq. (18.15), ∫ ∞ −∞ x 2e − 2 Hn(x)Hm(x) dx = 1 4 ( π1/22 n+2(n + 2)!) δn+2,m + ( 2n + 1 2 ) (π1/22 nn!) δnm + n(n − 1) (π1/22 n−2(n − 2)! ) δn−2,m , equivalent to the answer in the text. 18.2.6. The product x rHn(x) is a polynomial of degree n + r and therefore its expansion in Hermite polynomials cannot involve any Hm with index m > n + r. If n + r < n + p (i.e., if p > r), the integral of the present exercise must vanish due to orthogonality. The other case under consideration here is p = r, for which we need to prove ∫ ∞ −∞ xre −x2Hn(x)Hn+r(x) dx = 2nπ1/2(n + r)! . Using mathematical induction, we start by assuming the above equation to be valid for some r−1 and, subject to that assumption, prove its validity for r. Write ∫ ∞ −∞ x re −x2Hn(x)Hn+r(x) dx = ∫ ∞ −∞ x r−1e −x 2 Hn(x) [ (n + r)Hn+r−1(x) + 1 2 Hn+r+1(x)] dx , where we have used the recurrence formula, Eq. (18.3), to convert xHn+r into a linear combination of Hn+r±1. The second term of the integrand leads to a vanishing integral because r + 1 > r − 1, while the ﬁrst term corresponds to the integral under study for r − 1. Inserting the assumed result, we get ∫ ∞ −∞ xre −x2Hn(x)Hn+r(x) dx = (n + r)2 nπ1/2(n + r − 1)! , which is the correct formula for index value r. To complete the proof, we must verify the formula for r = 0, which is just the normalization formula, Eq. (18.15). CHAPTER 3. EXERCISE SOLUTIONS 291 18.2.7. The signs of the operators ip in these equations should be reversed, and the quantity ψn(x) should be inserted immediately following the operators (x ± ip)/√2. Noting ﬁrst that (d/dx)e −x 2/2 = −xe −x2/2, the expressions of this exercise reduce to aψn(x) = e −x 2 (2n+1n! π1/2)1/2 H ′ n(x) , a†ψn(x) = e −x 2 (2n+1n! π1/2)1/2 [2xHn(x) − H ′ n(x)] . We now replace H ′ n(x) by 2nHn−1(x) by applying Eq. (18.4), and in the second of the two above equations we also use the recurrence formula, Eq. (18.3), to replace 2xHn − 2nHn by Hn+1. When we write the coeﬃ- cients of Hn±1 in forms that include the constant factors in the deﬁnitions of ψn±1, we obtain the required answers. 18.2.8. (a) Since p is conventionally taken to be −i d/dx, the ﬁrst member of this equation should read x − ip. To verify an operator identity we must show that the two operators in- volved produce identical results when applied to an arbitrary function. Applying the operator on the right-hand side to an arbitrary diﬀerentiablef (x), we have −e x 2/2 d dx [ e −x2/2f (x) ] = [ x − d dx ] f (x) , and note that the result is identical to that of applying the left-hand-side operator to f (x). (b) Using the second equation of Exercise 18.2.7 n times, we note that a †ψ0(x) = 1 1/2ψ1(x), [ a †]2 ψ0(x) = [1 · 2] 1/2ψ2(x), · · · , or [ a†]n ψ0(x) = (n!) 1/2ψn(x) . Noting that ψ0(x) = π−1/4e −x2/2 and [a †]n = 2−n/2 ( x − d dx )n , we conﬁrm the formula given in the text. 18.3 Laguerre Functions 18.3.1. Using Leibniz’ rule, (uv) (n) = n∑ m=0 ( n m ) u(m)v(n−m) , CHAPTER 3. EXERCISE SOLUTIONS 292 we get Ln = e x n! dn dxn (x ne −x) = e x n! n∑ m=0 ( n m ) ( n! (n − m)! x n−m) (−1) n−me −x = n∑ m=0 (−1) n−mn! x n−m m! (n − m)!(n − m)! , which is Eq. (18.53). 18.3.2. (a) The value of L ′ (0) is the coeﬃcient of x in the power series, and L ′′(0) is twice the coeﬃcient of x 2. (b) Diﬀerentiating the recurrence formula, Eq. (18.51) and rearranging, we get (then setting x = 0 and Ln(0) = 1) (n + 1) [ L ′ +1(0) − L ′ (0) ] = n [ L ′ (0) − L ′ −1(0) ] − 1 . Using this equation iteratively to further reduce the index values on its right-hand side, we reachn+1) [ L ′ +1(0) − L ′ (0) ] = 1 [L ′ (0) − L ′ (0)]−n = [−1 − 0]−n = −(n+1) . Therefore, for all n we have L ′ +1(0) − L ′ (0) = −1; since L ′ (0) = 0, this proves that L ′ (0) = −n. A similar process can be applied for L ′′(0). 18.3.3. It is convenient to solve this problem using a generating function for L k that is obtained by diﬀerentiating that for Ln+k(x) k times with respect to x. Referring to Eq. (18.49) for the generating function and Eq. (18.58) for the deﬁnition of L k , we have t ke −xt/(1−t) (1 − t)k+1 = ∑ n L k (x)tn+k, equivalent to e −xt/(1−t) (1 − t)k+1 = ∞∑ n=0 L k (x)tn. We next use a product of two generating functions of this type to form orthogonality/normalization integrals for associated Laguerre functions. J = ∫ ∞ 0 x ke −x [ e −xt/(1−t) (1 − t)k+1 ] [ e −xu/(1−u) (1 − u)k+1 ] dx = ∑ nm tnum ∫ ∞ 0 xke −xL k (x)L k (x) dx . We now evaluate J as given in terms of the generating functions, starting this process by collecting the exponentials into the form e −Ax, with A = 1 + t 1 − t + u 1 − u = 1 − tu (1 − t)(1 − u) . CHAPTER 3. EXERCISE SOLUTIONS 293 We then change the integration variable to y = Ax, obtaining J = A −k−1 (1 − t)k+1(1 − u)k+1 ∫ ∞ 0 yke −y dy = k! (1 − tu)k+1 . Then we expand J as a binomial series: J = k! ∑ p ( −k − 1 p ) (−tu)p = ∑ p (k + p)! p! (tu)p . From this expression for J we get ∑ p (k + p)! p! (tu) p = ∑ nm tnum ∫ ∞ 0 x ke −xL k (x)L k (x) dx . Comparing the coeﬃcients of like powers of t and u, we ﬁnd ∫ ∞ 0 x ke −xL k (x)L k (x) dx = (k + n)! n! δmn . 18.3.4. The solution is given in the text. 18.3.5. The solution is given in the text. 18.3.6. When the hint is inserted in the integral, each term can be evaluated using Eq. (18.71). This yields ∫ ∞ 0 e −xx k+1L k (x)L k (x)dx = (2n + k + 1) (n + k)! k! . 18.3.7. (a) For x → ∞, where the x −2, x−1 terms are negligible, solve y′′ −y/4 = 0 and obtain as a solution the negative exponential y = e −x/2 = A(x). (b) For 0 < x ≪ 1, solve y′′ − k2 − 1 4x2 y = 0 , which has the regular solution y = x (k+1)/2 = B(x). Then C(x) = L k (x) will follow. 18.3.8. The solution is given in the text. 18.3.9. The solution is given in the text. 18.3.10. Use mathematical induction. To develop an appropriate formula, write Hn(xy) = 1 2(n + 1) H ′ n+1(xy) = 1 2(n + 1)y dHn+1(xy) dx , CHAPTER 3. EXERCISE SOLUTIONS 294 which we now insert into our integral and integrate by parts. The result ∫ ∞ −∞ x ne −x 2 Hn(xy) dx = 1 2(n + 1)y ∫ ∞ −∞ x ne −x 2 dHn+1(xy) dx dx = − ∫ ∞ −∞(nx n−1 − 2x n+1)e −x 2 Hn+1(xy) dx . Now convert the term containing x n−1 to a more useful form using the Hermite recurrence formula: nx n−1e −x 2 Hn+1(xy) = 2nx nye −x2Hn(xy) − 2n2x n−1Hn−1(xy) . Making this substitution, after minor rearrangement we reach (2n + 1)y ∫ ∞ −∞ x ne −x2Hn(xy) dy = n2 ∫ ∞ −∞ x n−1e −x2Hn−1(xy) dy + ∫ ∞ −∞ x n+1e −x2Hn+1(xy) dy . We now substitute into the above equation the assumed identiﬁcation of these integrals with Pn, ﬁnding that these integrals obey the Legendre polynomial recurrence formula, Eq. (15.18). They are therefore valid rep- resentations of these polynomials if they also give correct results for n = 0 and n = 1. For n = 0 our integral reduces to an error integral of value √π, consistent with the assumed integral representation. For n = 1, our integral has the form ∫ ∞ −∞ xe −x 2 (2xy) dx = √π y = √π P1(y) , also consistent with our assumed formula. This completes the proof. CHAPTER 3. EXERCISE SOLUTIONS 295 18.4 Chebyshev Polynomials 18.4.1. For x = 1, x = −1, and x = 0 the generating function g(x, t) for Tn becomes g(1, t) = 1 − t2 1 − 2t + t2 = 1 + t 1 − t = 1 + 2(t + t2 + t3 + · · · ) = 1 + ∞∑ 1 2tn, g(−1, t) = 1 − t2 1 + 2t + t2 = 1 − t 1 + t = 1 + 2(−t + t 2 − t 3 + · · · ) = 1 + ∞∑ 1 (−1) n2tn, g(0, t) = 1 − t 2 1 + t2 = 1 + 2(−t2 + t 4 − t6 + · · · ) = 1 + ∞∑ 1 (−1)n2t2n. Comparing the above with g(x, t) = T0(x) + ∞∑ n=1 2Tn(x)t n, we see that Tn(1) = 1, Tn(−1) = (−1) n, T2n(0) = (−1) n, T2n+1(0) = 0. 18.4.2. For x = 1, x = −1, and x = 0 the generating function g(x, t) for Un becomes g(1, t) = 1 1 − 2t + t2 = 1 (1 − t)2 = d dt ( 1 1 − t ) = d dt (1 + t + t 2 + t 3 + · · · ) = 0 + 1 + 2t + 3t2 + · · · = ∞∑ n=0(n + 1)tn , g(−1, t) = 1 1 + 2t + t2 = 1 (1 + t)2 = − d dt ( 1 1 + t ) = − d dt (1 − t + t2 − · · · ) = 0 + 1 − 2t + 3t2 − · · · = ∞∑ n=0(−1) n(n + 1)tn , g(0, t) = 1 1 + t2 = ∞∑ n=0(−1) nt 2n . Comparing with g(x, t) = ∞∑ n=0 Un(x)tn, we see that Un(1) = n + 1, Un(−1) = (−1) n(n + 1), U2n(0) = (−1) n, U2n+1(0) = 0. 18.4.3. Xn(x) = Tn(x). 18.4.4. Using Eq. (18.109), evaluate the terms of the ODE for Vn in terms of Un−1 and its derivatives, with the aim of showing that the ODE suggested for CHAPTER 3. EXERCISE SOLUTIONS 296 Vn is automatically satisﬁed, given the ODE given for Un−1. Speciﬁcally, we have Vn(x) = (1 − x 2) 1/2Un−1(x) , V ′ n(x) = (1 − x 2) 1/2U ′ n−1(x) − x (1 − x2)1/2 Un−1(x) , V ′′ n (x) = (1 − x 2) 1/2U ′′ n−1(x) − 2x (1 − x2)1/2 U ′ n−1(x) − ‘1 (1 − x2)3/2 Un−1(x) . Using the above, form−x 2)V ′′ n (x) − xV ′ n(x) + n 2Vn(x) = (1 − x 2) 3/2U ′′ n−1(x) − 3x(1 − x 2)1/2U ′ n−1(x) + (n2 − 1)(1 − x 2) 1/2Un−1(x) = (1 − x 2) 1/2[ (1 − x2)U ′′ n−1(x) − 3xU ′ n−1(x) + (n − 1)(n + 1)Un−1(x) ] . The expression within the square brackets vanishes because of the equation satisﬁed by Un−1(x), conﬁrming that Vn satisﬁes the suggested ODE. 18.4.5. Writing the ODE for Tn and Vn in self-adjoint form, we obtain (calling the dependent variable y) [(1 − x2)1/2y′]′ + n2y (1 − x2)1/2 = [p(x)y′]′ + q(x)y = 0 , we use the fact that the Wronskian of any two solutions to this ODE has the general form A/p(x), in this case W (Tn, Vn) = Tn(x)V ′ n(x) − T ′ n(x)Vn(x) = An (1 − x2)1/2 . To ﬁnd the value of An, evaluate the Wronskian at x = 0, where its value will be An. From Eq. (18.95), we note that T ′ n(0) = nTn−1(0). From Eq. (18.109) we identify Vn(0) = Un−1(0); diﬀerentiating Eq. (18.109) we also ﬁnd V ′ n(0) = U ′ n−1(0), which using Eq. (18.96), can be written V ′ n(0) = nUn−2(0). Our Wronskian can therefore (for x = 0) be written Tn(0)V ′ n(0) − T ′ n(0)Vn(0) = n[ Tn(0)Un−2(0) − Tn−1(0)Un−1(0)] = An . All the function values on the left-hand side of this equation are given in Eq. (18.100); the quantity in square brackets evaluates to −1 for both even and odd n, so W (Tn, Vn) = An (1 − x2)1/2 = n(−1) (1 − x2)1/2 . CHAPTER 3. EXERCISE SOLUTIONS 297 18.4.6. We know that Tn(x) satisﬁes the ODE (1 − x 2)T ′′ n (x) − xT ′ n(x) + n2Tn = 0 , and the exercise gives Wn(x) in terms of Tn+1. We can verify the asserted ODE for Wn by rewriting it as an equation in Tn+1 and comparing with the above ODE. To do so, we need Wn(z) = (1 − x 2) −1/2Tn+1(x) , W ′ n(x) = 1 (1 − x2)1/2 T ′ n+1(x) + x (1 − x2)3/2 Tn+1(x) , W ′′ n (x) = 1 (1 − x2)1/2 T ′′ n+1(x) + 2x (1 − x2)3/2 T ′ n+1(x) + 1 + 2x 2 (1 − x2)5/2 Tn+1(x) . Using the above, form (1 − x 2)W ′′ n (x) − 3xW ′ n(x) + n(n + 2)Wn(x) = (1 − x 2) 1/2T ′′ n+1(x) − x (1 − x2)1/2 T ′ n+1(x) + 1 + n(n + 2) (1 − x2)1/2 Tn+1(x) = (1 − x2)−1/2[ (1 − x 2)T ′′ n+1(x) − xT ′ n+1(x) + (n + 1)2Tn+1(x) ] . The expression in square brackets vanishes because of the equation satis- ﬁed by Tn+1(x), conﬁrming the ODE proposed for Wn. 18.4.7. Compare with the method of solution to Exercise 18.4.5. The ODE forn and Wn is, in self-adjoint form, [ (1 − x2)3/2y′] ′ + n(n + 2)(1 − x 2) 1/2y = 0 , so the Wronskian has the functional form W (Un, Wn) = Un(x)W ′ n(x) − U ′ n(x)Wn(x) = An (1 − x2)3/2 . At x = 0, U ′ n(0) = (n + 1)Un−1(0), and Un(0) is given in Eq. (18.100). In addition, Wn(0) = Tn+1(0), W ′ n(0) = (n + 1)Tn(0), with Tn(0) also given in Eq. (18.100). Thusn(0)W ′ n(0)−U ′ n(0)Wn(0) = (n+1) [ Un(0)Tn(0)−Un−1(0)Tn+1(0) ] = n+1 . Note that we get the same result for both even and odd n, and that it ﬁxes the constant An as n + 1. Therefore, W (Un, Wn) = n + 1 (1 − x2)3/2 . CHAPTER 3. EXERCISE SOLUTIONS 298 18.4.8. Work with the ODE for T0 in the form given in Eq. (18.104), but written as y′′ = 0 to imply that we will search for the general solution. Thus, d2y dθ2 = 0 , with solutions y = c0 and y = c1θ . The solution y = c0 is just c0T0(x); since x = cos θ, the solution y = c1θ is equivalent to y = c1 arccos x. Since π/2 − arccos x is a linear combination of these two solutions, it is also a solution, more compactly written asx. 18.4.9. Write the proposed recurrence relation for Vn with Vn written in terms of Un−1 according to Eq, (18.109). Because Un and Tn satisfy the same recurrence formula, and it is independent of n, so also does Vn. 18.4.10. For Tn(x), using the expansion in Eq. (18.114), we write ﬁrst the entire ODE except the single term 1T ′′ n (x), and then that remaining term: −x 2T ′′ n (x) − xT ′ n(x) + x 2Tn(x) = n 2 [n/2]∑ m=0(−1) m (n − m − 1)! m! (n − 2m)! (2x) n−2m ×[ − (n − 2m)(n − 2m − 1) − (n − 2m) + n 2] , T ′′ n (x) = n 2 [n/2]∑ m=0(−1)m (n − m − 1)! m! (n − 2m)! (2x) n−2m x2 (n − 2m)(n − 2m − 1) . To obtain a ﬁnal expression as a single power series, we rewrite the second of the two above equations with the summation index m changed to m−1, thereby obtaining ′′ n (x) = n 2 [n/2+1]∑ m=1 (−1)m−1(n − m)! (m − 1)! (n − 2m)! (2x)n−2m+2 x2 (n−2m+2)(n−2m+1) . When this form of T ′′ n is added to the remainder of the ODE, the coeﬃcient of each power of x is found to vanish, thereby showing that the series for Tn satisﬁes the ODE. To verify its scale, set x = 0, thereby causing the entire summation to be zero if n is odd, and to the single term m = n/2 if n is even. That single term of the sum evaluates to (−1) n/2 (n/2 − 1)! (n/2)! = (−1) n/2 ( 2 n ) , consistent with T2n(0) = (−1) n, the value given in Eq. (18.100). The series expansion of Un(x) is veriﬁed in a similar fashion. 18.4.11. The answer is given in the text. CHAPTER 3. EXERCISE SOLUTIONS 299 18.4.12. The answer is given in the text. 18.4.13. (a) The equations for Tn and Tm can be written [ (1 − x 2) 1/2T ′ n(x) ]′ = − n2Tn(x) (1 − x2)1/2 , [ (1 − x2) 1/2T ′ m(x) ]′ = − m2Tm(x) (1 − x2)1/2 . Multiplying the ﬁrst of these equations by m2Tm(x) and the second by n2Tn(x), then subtracting the ﬁrst from the second and integrating from −1 to 1, we reach n2 ∫ 1 −1 Tn(x) [(1−x2)1/2T ′ m(x) ]′ dx−m2 ∫ 1 −1 Tm(x)[ (1−x 2) 1/2T ′ n(x) ]′ dx = 0. Note that the right-hand-side integrals are convergent and their cancella- tion is therefore legitimate. Now integrate the integrals in the above equation by parts, integrating the explicit derivatives and diﬀerentiating the other Chebyshev polynomials. The presence of the factor (1 − x2)1/2 causes all the endpoint terms to cancel, and we are left with (m 2 − n2) ∫ 1 −1 T ′ m(x)T ′ n(x)(1 − x 2) 1/2 dx = 0 . The left-hand side of this equation is zero whether or not m = n, but only if m ̸= n does it show that the integral vanishes. (b) Diﬀerentiating Eq. (18.105), we get, noting that x = cos θ and com- paring the result with Eq. (18.107), dTn(x) dx = dTn(θ dθ dθ dx = (−n sin nθ) ( − 1 sin θ ) = n sin nθ sin θ = nUn−1(x) . 18.4.14. Note that all instances of x and dx in the orthogonality integral should have been primed, i.e., written x ′ or dx ′. The shift compresses the original Tn into half the original range; this would decrease the orthogonality integral by a factor of 2. However, 1 (1 − x2)1/2 −→ 1 2 √ x(1 − x) , so the weight factor given in the exercise is twice that of the original Tn. These factors of 2 cancel, so the orthogonality condition given for theTn has the same value as that given for the Tn. CHAPTER 3. EXERCISE SOLUTIONS 300 18.4.15. (a) The expansion of x m cannot include any Chebyshev polynomial of degree higher than m. Therefore if n > m this integral must vanish due to orthogonality. (b) The Chebyshev polynomial Tm has the parity of m; i.e., the Tm(x) of even m are even functions of x; those of odd m are odd functions of x. Therefore the integral will vanish due to symmetry unless n and m have the same parity, meaning that the integral will vanish if m + n is odd. 18.4.16. (a) Introducing the Rodrigues formula for Tn, Imn = (−1) nπ1/2 2nΓ(n + 1 2 ) ∫ 1 −1 x m ( d dx )n (1 − x2)n+1/2 dx . Integrating by parts n times, and noting that the endpoint integrated terms vanish, we reach Imn = π1/2 2nΓ(n + 1 2 ) m! (m − n)! ∫ 1 −1 xm−n(1 − x 2) n+1/2 dx = π1/2 2nΓ(n + 1 2 ) m! (m − n)! B ( m − n + 1 2 , n + 1 2 ) . Here B is a beta function; the integral was evaluated using Eq. (13.50). Inserting the value of B in terms of gamma functions, we reach Imn = π1/2m! 2n(m − n)! Γ ( m − n + 1 2 ) ( m − n 2 ) ! , which when written in terms of double factorials can be seen equivalent to the answer in the text. (b) From Eq. (18.105), write Imn in terms of θ as Imn = ∫ π 0 cosm θ cos nθ dθ . This integral can be evaluated by writing it entirely in terms of complex exponentials, expanding the mth power by the binomial theorem, and noting that nearly all the resulting integrals cancel. Alternatively, it can be recognized as a case of Formula 3.631(9) in Gradshteyn & Ryzhik, Table of Integrals, Series, and Products, 6th ed. (Academic Press, 2000). The result can be brought to the same form as in part (a). 18.4.17. (a) Use the trigonometric form of Un given in Eq. (18.107), and expand sin(n + 1)θ: |Un| = ∣ sin(n + 1)θ sin θ ∣ = ∣ sin nθ cos θ sin θ + cos nθ∣ ≤ ∣ sin nθ sin θ ∣ + 1 = |Un−1| + 1 . CHAPTER 3. EXERCISE SOLUTIONS 301 Applying this result successively to Un−1, Un−2, · · · , we conclude that |Un| ≤ |U0| + n = n + 1, as required. (b) From the result of Exercise 18.4.13(b), we know that ∣ d dx Tn(x)∣ = n |Un−1| . Applying the result from part (a), n |Un−1| ≤ n 2, as given in the text. 18.4.18. (a) From Eqs. (18.107) and (18.109), write Vn = sin nθ. This form is clearly bounded by ±1. (b) Equation (18.110) shows that Wn becomes inﬁnite at x = ±1, so it is clearly unbounded on the speciﬁed range. 18.4.19. (a) Writing as trigonometric integrals, with x = cos θ, dx = − sin θ dθ, and Tn given by Eq. (18.105), ∫ 1 −1 Tm(x)Tn(x)(1 − x 2) −1/2 dx = ∫ π 0 cos mθ cos nθ dθ . Evaluating these integrals leads to the results given in Eq. (18.116). (b) Using Eq. (18.106), ∫ 1 −1 Vm(x)Vn(x)(1 − x2)−1/2 dx = ∫ π 0 sin mθ sin nθ dθ , consistent with the formulas in Eq. (18.117). (c) Using Eq. (18.107), ∫ 1 −1 Um(x)Un(x)(1 − x 2) 1/2 dx = ∫ π 0 sin(m + 1)θ sin(n + 1)θ dθ . Note that the negative powers of sin θ cancel against the weighting func- tion and the representation of dx. This integral leads to the formulas in Eq. (18.118). (d) Using Eq. (18.108), ∫ 1 −1 Wm(x)Wn(x)(1 − x2)1/2 dx = ∫ π 0 cos(m + 1)θ cos(m + 1)θ dθ , consistent with Eq. (18.119). 18.4.20. (a) Using the techniques in parts (a) and (b) of Exercise 18.4.19, we get ∫ 1 −1 Tm(x)Vn(x)(1 − x 2) −1/2 dx = ∫ π 0 cos mθ sin nθ dθ , CHAPTER 3. EXERCISE SOLUTIONS 302 which for many values of m ̸= n is nonzero. (The interval (0, π) is not an interval of orthogonality for this function set.) (b) Orthogonality is not obtained for all Um and Wn. See the solution to part (a). 18.4.21. (a) Using Eq. (18.105), this recurrence formula is equivalent to cos(n + 1)θ + cos(n − 1)θ = 2 cos θ cos nθ . Writing cos(n ± 1)θ = cos θ cos nθ ∓ sin θ sin nθ , the veriﬁcation is immediate. (b) Since the equation of this part can be written cos(m + n)θ + cos(m − n)θ = 2 cos mθ cos nθ , it can be conﬁrmed by the approach of part (a) using the formulas form ± n)θ. 18.4.22. Equation (18.91), the generating function for the Tn, can also be used to develop a formula involving the Un. In particular, 1 − t2 1 − 2xt + t2 = T0 + 2 ∞∑ n=1 Tn(x)t n , = (1 − t2) ∞∑ n=0 Un(x)t n . Equating the coeﬃcients of equal powers of t in these two expansions, we get, for n ≥ 2, Un(x) − Un−2(x) = 2Tn(x) . To reach the form given in the text, use the recurrence formula, Eq. (18.93), to replace Un−2(x) by 2xUn−1(x) − Un(x), and then divide through by 2. To derive the second formula of this exercise, start from Eq. (18.95): (1 − x 2)T ′ n(x) = −nxTn(x) + nTn−1(x) , and use the result from Exercise 18.4.13(b) to replace T ′ n by nUn−1. This yields (1 − x2)Un−1(x) = −xTn(x) + Tn−1(x) = xTn(x) − Tn+1(x) , where the last equality was obtained using the recurrence formula for Tn, Eq. (18.92). Replacing n by n + 1 leads to the formula in the text. CHAPTER 3. EXERCISE SOLUTIONS 303 18.4.23. (a) Diﬀerentiate the trigonometric form for Vn, Eq. (18.106). The result is dVn(x) dx = dVn(θ) dθ dθ dx = (n cos nθ) (− 1 sin θ ) = −n Tn(x) √1 − x2 . (b) Using Eq. (18.109), we write the Rodrigues formula for Vn by multi- plying that for Un−1 i Eq. (18.103) by (1 − x 2) 1/2. Thus, Vn = (−1) n−1nπ1/2 2nΓ(n + 1 2 ) dn−1 dxn−1 [ (1 − x 2)n−1/2] . Diﬀerentiating, multiplying by (1 − x 2) 1/2, and changing the sign, we identify the result as n times the Rodrigues formula for Tn. 18.4.24. Making the binomial expansion of x k, and combining terms with the same value of the binomial coeﬃient, xk = ( e iθ + e −iθ 2 )k = 1 2k k∑ n=0 (k n ) e inθe −i(k−n)θ = 1 2k ∑ 0≤n<k/2 (k n ) [ e i(2n−k)θ + e i(k−2n)θ] +  1 2k ( k k/2 ) , k even, 0 , k odd. The exponentials in the sum combine to form 2 cos(k − 2n)θ = 2Tk−2n(x), yielding a ﬁnal result similar to that shown in the text. However, the text did not make clear that when k is even, the ﬁnal term of the expansion is 1 2k ( k k/2 ) = 1 2k ( k k/2 ) T0(x) , i.e., diﬀerent by a factor 2 from the other terms of the ﬁnite expansion. 18.4.25. (a) Here we need the Chebyshev expansion of sin θ. Letting cl be the coeﬃcient of Tl in the expansion, we have c0 = 1 π ∫ π 0 sin θ dθ = − cos θ π ∣ π = 2 π . For nonzero l, we have cl = 2 π ∫ π 0 sin θ cos(lθ) dθ . This integral vanishes for odd l; for even l it can be evaluated by subjecting it to two integrations by parts, twice diﬀerentiating the factor cos(lθ); this results in an integral proportional to the original one plus an endpoint CHAPTER 3. EXERCISE SOLUTIONS 304 term. Alternatively, the integral can be evaluated by table lookup. The result is (for even nonzero l) cl = − 4 π 1 l2 − 1 , which corresponds to the answer in the text when l is replaced by 2s. (b) This function is odd and its expansion therefore contains only Cheby- shev polynomials of odd order. The expansion coeﬃcients cl can be com- puted as cl = ( 2 π ) 2 ∫ π/2 0 cos(lθ) dθ = 4 πl sin(lπ/2) . This sine function is +1 for l = 1, 5, · · · and −1 for l = 3, 7, · · · ; changing the index from l to 2s + 1 we can write c2s+1 = 4 π (−1)s 2s + 1 , consistent with the answer in the text. 18.4.26. (a) The Legendre expansion of |x| is of the form |z| = ∑ s c2sP2s(x), where c0 = ∫ 1 0 x dx = 1 2 and, for nonzero s, c2s = (4s + 1) ∫ 1 0 xP2s(x) dx = ∫ 1 0 [ (2s + 1)P2s+1(x) + 2sP2s−1(x) ] dx = ∫ 1 0 [ (2s + 1)[P ′ 2s+2(x) − P ′ 2s(x)] 4s + 3 + 2s[P ′ 2s(x) − P ′ 2s−2(x)] 4s − 1 ] dx . The two steps in the forgoing analysis were the use of the basic Legendre recurrence formula, Eq. (15.18), and the derivative recurrence, Eq. (15.22). The reason for taking these steps is that the integration is now trivial; the upper integration limit cancels, as all Pn(1) are unity; the lower limit involves values of Pn(0) which can be obtained either as a coeﬃcient in Eq. (15.14) or from the answer to Exercise 15.1.12. The result we need is P2s(0) = (−1) s (2s − 1)!! (2s)!! . Thus, c2s = − 2s + 1 4s + 3 (−1) s+1 (2s + 1)!! (2s + 2)!! + [ 2s + 1 4s + 3 − 2s 4s − 1 ] (−1) s (2s − 1)!! (2s)!! + 2s 4s − 1 (−1)s−1 (2s − 3)!! (2s − 2)!! . CHAPTER 3. EXERCISE SOLUTIONS 305 This expression simpliﬁes to the form given in the Exercise. The expansion of |x| in Chebyshev polynomials is most easily done using their trigonometric forms, in which the subrange x > 0 corresponds to 0 ≤ θ ≤ π/2. Letting c2s be the coeﬃcient of T2s, we require c0 = 2 π ∫ π/2 0 cos θ dθ = 2 π , and for nonzero s, c2s = 4 π ∫ π/2 0 cos θ cos 2sθ dθ = 2 π ∫ π/2 0 [cos(2s + 1)θ + cos(2s − 1)θ] dθ = 2 π [ sin(s + 1 2 )π 2s + 1 + sin(s − 1 2 )π 2s − 1 ] = 2 π (−1) s [ 1 2s + 1 − 1 2s − 1 ] = 4 π (−1)s+1 4s2 − 1 . (b) The limiting ratio of the coeﬃcients is given incorrectly in the text. The correct value of the ratio in the limit of large s is (πs) −1/2. Foe general s, the ratio of the coeﬃcient of T2s to that of P2s is Ratio = 4 π 1 4s2 − 1 (2s − 3)!! (2s + 2)!! (4s + 1) ≈ 1 πs (2s + 2)!! (2s + 1)!! . The ratio of double factorials can be treated by writing them in terms of factorials and then using Stirling’s formula. We have [ (2s + 2)!! (2s + 1)!! ] = ln [ 2 2s+2[(s + 1)!] 2 (2s + 2)! ] = (2s + 2) ln 2 + 2 ln Γ(s + 2) − ln Γ(2s + 3) = (2s + 2) ln 2 + 2 [ 1 2 ln 2π + ( s + 3 2 ) ln(s + 1) − (s + 1)] − [ 1 2 ln 2π + ( 2s + 5 2 ) ln(2s + 2) − (2s + 2)] = 1 2 ln π + 1 2 ln(s + 1) . The ﬁnal result in the limit of large s is therefore Ratio ≈ (πs) −1 (πs) 1/2 = (πs) −1/2. CHAPTER 3. EXERCISE SOLUTIONS 306 18.4.27. Form ∫ 1 −1 |x|2(1 − x 2) −1/2 dx = ∫ π 0 cos2 θ dθ = π 2 , and then also calculate the same quantity using the expansion of |x| in Chebyshev polynomials from Exercise 18.4.26. We have π 2 = ∫ 1 −1 |x|2(1 − x 2)−1/2 dx = ∫ 1 −1 [ 2 π + 4 π ∞∑ s=1(−1) s+1 1 4s2 − 1 T2s(x) ]2 (1 − x 2) −1/2 dx . Using the orthogonality of the Tn and the values of their normalization integrals, the above equation reduces to π 2 = 4 π2 (π) + 16 π2 ∞∑ s=1 1 (4s2 − 1)2 ( π 2 ) . When this equation is multiplied through by π/4 we get the result given in the text. 18.4.28. (a) Taking x = cos θ, this equation is seen equivalent to θ = π 2 − 4 π ∞∑ n=0 1 (2n + 1)2 T2n+1(cos θ) . To conﬁrm it we therefore need to develop the Chebyshev expansion of θ. The coeﬃcient of T0, c0, is c0 = 1 π ∫ π 0 θ T0(cos θ) dθ = π2 2 . The coeﬃcients of Tl for nonzero l can be developed via an integration by parts (for which the integrated endpoint terms vanish). We have cl = 2 π ∫ π 0 θ cos(lθ) dθ = − 2 πl ∫ π 0 sin(lθ) dθ = 2 πl2 cos(lθ)∣ π =  − 4 πl2 , l odd, 0, l even. Making a change of the index variable from l to 2n + 1, the expansion becomes θ = π 2 T0(cos θ) − 4 π ∞∑ n=0 1 (2n + 1)2 T2n+1(cos θ) , CHAPTER 3. EXERCISE SOLUTIONS 307 equivalent to the answer in the text. (b) We note that sin −1 x = sin−1(cos θ) = π/2 − θ. This observation leads immediately to the expansion in the text. 18.5 Hypergeometric Functions 18.5.1. (a) If c is integral and other than 1, either (c)n or (2 − c)n vanishes for some n, so that one of the two hypergeometric series has inﬁnite terms and cannot represent a function. If c = 1, both series become identical, so then there is also only one series solution. (b) If c = −2 and a = −1, and the series 2F1(−1, b; −2; x) is deemed to terminate when the zero in the numerator is reached, we get 2F1(−1, b; −2; x) = 1 + 1 2 bx , which can be conﬁrmed as a solution to the hypergeometric ODE for= −1, c = −2. Since we still get x32F1(2, b + 3; 4; x) as another series solution, we see that for these values of a and c both solutions can be written in terms of hypergeometric series. 18.5.2. These recurrence relations are those in Eqs. (15.18), (18.92), and (18.93). 18.5.3. It is somewhat easier to work backward from the answers than to derive them. A derivation could use the following notions: (1) A series in x that terminates after x n can be obtained by placing −n within one of the numerator Pochhammer symbols; (2) If the mth term of the expansion involves m!, it can be obtained as (1)m; (3) If the mth term involves (n + m)!/(n − m)!, it can be obtained as (−1)m(−n)m(n + 1)m; (4) If the mth term involves (2m)!, it can be obtained as 2 mm! (2m − 1)!!, with the double factorial generated from a construction such as 2 m(1/2)m. (a) Start from Eq. (18.14), and write T2n(x) as an ascending power series: T2n(x) = (−1) n n∑ m=0 (−1) m2 2mn(n + m − 1)! (n − m)!(2m)! (x2)m . Rearrange the coeﬃcient within the sum to the form 2 2m[ (−n)(−n + 1) · · · (−n + m − 1) ] [ (n)(n + 1) · · · (n + m − 1) ] (2mm!) 2 m ( 1 2 ) ( 3 2 ) · · · ( 2m − 1 2 ) = (−n)m(n)m m! ( 1 2 ) m , CHAPTER 3. EXERCISE SOLUTIONS 308 thereby identifying the summation as a hypergeometric function. Parts (b), (c), and (d) are transformed in a similar fashion. 18.5.4. The representation of part (a) has a leading factor that was obtained while solving Exercise 18.5.3. To obtain the leading factors of the other representations, it suﬃces to check the coeﬃcient of x0, which for all the functions 2F1 is unity. From Eq. (18.114), the coeﬃcient of x 0 in x −1T2n+1(x) is 2n + 1 2 (−1)n n! n! 1! 2 = (−1) n(2n + 1) . The other leading factors are checked in the same way. 18.5.5. The formula for Qν given in this exercise is incorrect; the third argument of the hypergeometric function should be ν + 3 2 . The series in inverse powers for Ql(x) is given in a convenient form in Exercise 15.6.3; it is Ql(x) = x −l−1 ∞∑ s=0 (l + 2s)! (2s)!!(2l + 2s + 1)!! x −2s . The hypergeometric series with which this expansion is to be compared is, from Eq. (18.121), Ql(x) = π1/2l! x −l−1 Γ (l + 3 2 ) 2l+1 ∞∑ s=0 ( l + 1 2 ) s ( l + 2 2 ) s s! ( l + 3 2 ) s x −2s . An initial step toward the veriﬁcation is to make the identiﬁcation 2 l+s+1Γ(l + 3 2 ) ( l + 3 2 ) s = π1/2(2l + 2s + 1)!! . We also note that 2 s s! = (2s)!! and that l! ( l + 1 2 ) s ( l + 2 2 ) s = 2−2s(l + 2s)! . Inserting these relationships, the two forms for Ql are brought into corre- spondence. 18.5.6. Introduce a binomial expansion in the integral for Bx and perform the integration in t termwise. The result is Bx(p, q) = ∞∑ k=0(−1) k( q − 1 k ) x p+k p + k = ∞∑ k=0 (−1)kΓ(q) k! Γ(q − k) (p + k) xp+k . CHAPTER 3. EXERCISE SOLUTIONS 309 From Eq. (18.121), the proposed hypergeometric series is Bx(p, q) = p−1x p ∞∑ k=0 (p)k(1 − q)k k! (p + 1)k x k . Noting that (p)k/(p + 1)k = p/(p + k) and that (1 − q)k = (1 − q)(2 − q) · · · (k − q) = (−1) kΓ(q) Γ(q − k) , the veriﬁcation is straightforward. 18.5.7. Introduce a binomial expansion for (1 − tz) −a and integrate termwise, identifying the integrals as beta functions according to Eq. (13.49): 2F1(a, b; c; z) = Γ(c) Γ(b) Γ(c − b) ∞∑ k=0 ( −a k )(−1) kzk ∫ 1 0 tb−1(1 − t)c−b−1t k dt = Γ(c) Γ(b) Γ(c − b) ∞∑ k=0 ( −a k )(−1) kB(b + k, c − b) zk . Evaluating the beta function and using ( −a k ) = (−1) k(a)k k! , we arrive at 2F1(a, b; c; z) = ∞∑ k=0 (a)k k! Γ(b + k) Γ(b) Γ(c) Γ(c + k) zk . Since Γ(b + k)/Γ(b) = (b)k and Γ(c + k)/Γ(c) = (c)k, the standard expan- sion of the hypergeometric function is recovered. The integral diverges unless the powers of both t and 1 − t are greater than −1. Hence the condition c > b > 0. 18.5.8. If we set z = 1, we have, using the integral representation of Exercise 18.5.7, 2F1(a, b; c; 1) = Γ(c) Γ(b)Γ(c − b) ∫ 1 0 t b−1(1 − t)c−b−a−1 dt = Γ(c) Γ(b)Γ(c − b) B(b, c − b − a) . Inserting the value of the beta function, we obtain the desired result. CHAPTER 3. EXERCISE SOLUTIONS 310 18.5.9. Use the integral representation of Exercise 18.5.7, with z replaced by −x/(1 − x). Then, noting that (1 − tz) −a −→ ( 1 + tx 1 − x )−a = (1 − x) a[ 1 − (1 − t)x ] −a , and changing the integration variable to u = 1 − t, the integral represen- tation assumes the form 2F1 ( a, b; c; −x 1 − x ) = Γ(c)(1 − x)a Γ(b) Γ(c − b) ∫ 1 0 (1 − u) b−1uc−b−1(1 − ux) −a du = (1 − x)a 2F1(a, c − b; c; x) , equivalent to what we are to prove. 18.5.10. To conform to the notation adopted in the text, (n − 1 2 )! should be written Γ(n + 1 2 ). A simple approach is to use Eq. (12.9); for the ODE satisﬁed by Tn, p(x) = (1 − x 2), and the weight function for orthogonality is w(x) = (1 − x2)−1/2. These parameter values make wpn = (1 − x2)n−1/2 and the Rodrigues formula therefore has the form Tn(x) = cn(1 − x 2) 1/2 ( d dx )n (1 − x 2) n−1/2 . The coeﬃcients cn must now be chosen to reproduce the Tn at their con- ventional scaling. It is convenient to use the values Tn(1) = 1 to set the scaling. All terms of the n-fold diﬀerentiation in the Rodrigues formula will contain a net positive power of 1 − x 2 and therefore vanish at x = 1 unless all the n diﬀerentiations are applied to the factor (1−x2)n−1/2 (and none to the factors −2x that are produced by earlier diﬀerentiations). If the n diﬀerentiations are applied in this way, they will produce a ﬁnal re- sult containing (1−x 2) −1/2, which will cancel against the factor (1−x2)1/2 preceding the derivative. The diﬀerentiation also produces a coeﬃcient ( n − 1 2 ) (n − 3 2 ) · · · ( 1 2 ) = Γ(n + 1 2 ) Γ(1/2) = Γ)n + 1 2 ) √π , and a factor (−2x)n from the derivative of 1 − x 2. When we set x = 1, Tn(1) = 1 = cn(−1) n 2 n Γ(n + 1 2 ) √π , from which we obtain the value of cn shown in the exercise. 18.5.11. This summation has a form corresponding to a hypergeometric function, except that the extent of the ν summation does not explicitly extend CHAPTER 3. EXERCISE SOLUTIONS 311 to inﬁnity. However, all terms with ν > min(m, n) vanish because of the vanishing of one or both of the Pochhammer symbols, so formally the summation can be extended to inﬁnity without changing its value. Referring to Eq. (18.121), we identify the summation as 2F1 ( −m, −n; 1 − m − n 2 ; a 2 2(a2 − 1) ) . 18.5.12. Write the formula of this exercise in the form 2F1(−n, b; c; 1) = Γ(c − b + n Γ(c − b) Γ(c) Γ(c + n) . This form is what is obtained if we evaluate 2F1(−n, b; c; 1) using the formula of Exercise 18.5.8. 18.6 Conﬂuent Hypergeometric Functions 18.6.1. The power-series expansion of the error function, Eq. (13.91), is erf(x) = 2 π1/2 ∞∑ n=0 (−1)nx 2n+1 (2n + 1) n! . The form given in the exercise corresponds to the expansion 2x π1/2 ∞∑ n=0 (−1) n(1/2)nx 2n (3/2)n n! . Noting that ( 1 2 )n ( 3 2 )n = 1/2 n + 1 2 = 1 2n + 1 , the conﬂuent hypergeometric representation is conﬁrmed. 18.6.2. From the deﬁnitions in Exercise 12.6.1, we can identify C(x) + is(x) = ∫ x 0 e iπu2/2 du . Making a change of variable to y = e −iπ/4(π/2) 1/2u, this integral becomes C(x) + is(x) = ( 2 π )1/2 e iπ/4 ∫ xe−iπ/4√π/2 0 e −y2 dy = e iπ/4 21/2 erf ( xe −iπ/4√ π 2 ) . CHAPTER 3. EXERCISE SOLUTIONS 312 Using the conﬂuent hypergeometric representation of the error function in Exercise 18.6.1, this expression can be written C(x) + is(x) = e iπ/4 21/2 2 π1/2 ( xe −iπ/4√ π 2 ) M ( 1 2 , 3 2 , − [ xe −iπ/4√ π 2 ]2) = x M ( 1 2 , 3 2 , iπx 2 2 ) . 18.6.3. Starting from the formula for y in the exercise, y′ = − ay x + ae −x x , y′′ = ay x2 − ay′ x − ae −x x2 − ae −x x = a(a + 1)y x2 − a(a + 1)e −x x2 − ae −x x , and therefore xy′′ = a(a + 1)y x − a(a + 1)e −x x − ae −x , (a + 1)y′ = − a(a + 1)y x + a(a + 1)e −x x , xy′ = −ay + ae −x , ay = ay . Adding these equations together, we form the ODE relevant to this exer-xy′′ + (a + 1 + x)y′ + ay = 0. 18.6.4. From Eq. (14.131), Kν(z) = √ π 2z e −z Γ(ν + 1 2 ) ∫ ∞ 0 e −t tν−1/2 ( 1 + t 2z )ν−1/2 dt . Change the integration variable to y = t/2z, reaching Kν(z) = √ π 2z e −z Γ(ν + 1 2 ) (2z)ν+1/2 ∫ ∞ 0 e z−2zyyν−1/2(1 + y) ν−1/2 dy . The integral is now in the form corresponding to the integral representa- tion of U (ν + 1/2, 2ν + 1, 2z) given in Eq. (18.145), and the formula for Kν(z) reduces to that given in the text. CHAPTER 3. EXERCISE SOLUTIONS 313 18.6.5. Using the formulas from Section 13.6, we write Ci(x) + isi(x) = − ∫ ∞ x e it t dt = − ∫ ∞ −ix e −y y dy = −E1(−ix) . Note now that, using Eq. (18.145), U (1, 1, x) = 1 Γ(1) ∫ ∞ 0 e −xt 1 + t dt = e x ∫ ∞ 0 e −x(t+1) t + 1 dt = e x ∫ ∞ 1 e −xt t dt = e xE1(x) . Using this formula, we write −E1(−ix) in terms of U , obtaining the desired result. 18.6.6. (a) Because the conﬂuent hypergeometric function has argument u = x 2, the corresponding ODE is u d2y du2 + (c − u) dy du − ay = 0 , and if y = y(x) the derivatives in this equation take the form dy du = dy dx dx du = 1 2x dy dx , d2y du2 = d2y dx2 ( dx du )2 + dy dx d2x du2 = 1 4x2 d2y dx2 − 1 4x3 dy dx . Now, with c = 3/2, a = −n, and y = H2n+1(x)/x, we have −ay = nH2n+1 x , (c − u) dy du = ( 3 2 − x 2) 1 2x ( H ′ 2n+1 x − H2n+1 x2 ) , u d2y du2 = 1 4 [ H ′′ 2n+1 x − 3H ′ 2n+1 x2 + 3H2n+1 x3 ] . Forming the conﬂuent hypergeometric ODE by adding these terms to- gether and then multiplying through by 4x, we reach H ′′ 2n+1 − 2xH ′ 2n+1 + 2(2n + 1)H2n+1 = 0 , conﬁrming that H2n+1(x)/x is a solution to the speciﬁed conﬂuent hyper- geometric equation (in x2) if H2n+1 is a solution of index 2n + 1 to the Hermite ODE. (b) The parameter value a = −n shows that our conﬂuent hypergeometric CHAPTER 3. EXERCISE SOLUTIONS 314 function will be a polynomial (in x 2) of degree n, so H2n+1 must be a polynomial (in x) of degree 2n + 1. Since M (−n, 3/2, 0) = 1, this part of the exercise is designed to show that Eq. (18.149) yields H2n+1 at its agreed-upon scale. From Eq. (18.9), changing n to 2n + 1 and examining the term with s = n, we have Term containing x 1 = (−1)n(2n + 1)! 1! n! 2x , consistent with the scale of Eq. (18.149). 18.6.7. Use the conﬂuent hypergeometric representation of L m(x) in Eq. (18.151) to rewrite the equation of this exercise in terms of Laguerre functions. The relevant parameter values are a = −n and c = m + 1. We get (m + n + 1) (n + 1)! m! (n + m + 1)! L m+1 − (2n + m + 1 − x) n! m! (n + m)! L m + n (n − 1)! m! (n + m − 1)! L m−1 = 0 . Dividing through by n! m!/(n + m)!, we get the recurrence formula given in Eq. (18.66): (n + 1) L m+1(x) − (2n + m + 1 − x) L m(x) + (n + m) L k −1(x) = 0 . 18.6.8. (a) Use the integral representation in Eq. (18.144) and make a change of the integration variable to s = 1 − t. We get M (a, c, x) = Γ(c) Γ(a)Γ(c − a) ∫ 1 0 e xtta−1(1 − t) c−a−1 dt = Γ(c) Γ(a)Γ(c − a) ∫ 1 0 e x(1−s)(1 − s)a−1s c−a−1 ds = Γ(c) e x Γ(a)Γ(c − a) ∫ 1 0 e −xss c−a−1(1 − s) a−1 ds = e xM (c − a, c, −x) . (b) This part of the exercise uses Eq. (18.142). Note that Eq. (18.142) contains a misprint; the quantity Γ(−c) in its last term should be changed to Γ(2 − c). If in Eq. (18.142) we replace a by a ′ = a + 1 − c and c by c ′ = 2 − c and in addition multiply both terms within the square brackets by x 1−c, the square bracket will remain unchanged except for an overall sign change. But the factor sin πc becomes sin πc′ = sin(2π − πc), so its sign changes also and we have x 1−cU (a′, c′, x) = U (a, c, x), as required. CHAPTER 3. EXERCISE SOLUTIONS 315 18.6.9. (a) On the right-hand side of the equation of this exercise, change b to c (two occurrences). In the integral representation, Eq. (18.144), diﬀerentiation with respect towill cause the power of t to be incremented, but does not change the power of 1 − t. This change corresponds to a unit increase in both a and c in the conﬂuent hypergeometric function. Since the gamma functions pre- ceding the integral have not changed, we need to increment the arguments of Γ(a) and Γ(c) and compensate for these changes through multiplication by a/c. A second derivative will cause a similar index shift, but this time the compensation factor will be (a + 1)/(c + 1). The generalization to arbitrary derivatives corresponds to the formula in the text. (b) This formula can be derived by a procedure similar to that used in part (a). The negative exponential generates a sign change with each diﬀerentiation. 18.6.10. Our procedure will be to verify that the integral representations satisfy the conﬂuent hypergeometric ODE, identify the representation as M or U , and conﬁrm its scale either at x = 0 or asymptotically at large x. (a) Dropping for the moment the constant factors preceding the integral, we consider the eﬀect upon the representation of the operations that cor- respond to the ODE. The diﬀerentiations to produce M ′′ will introduce an additional factor t2 in the integrand, while the diﬀerentiation to produce M ′ will introduce a factor t. Then, assuming the validity of the integral representation, our ODE corresponds to1 0 e xt [ xt a+1(1−t)c−a−1+(c − x)ta(1−t) c−a−1−at a−1(1−t) c−a−1] dt = 0 . We now perform integrations by parts on those terms that contain x, integrating e xt and diﬀerentiating the remainder of the integrand. By choosing these terms, we eliminate all x dependence from the integrand except for the single positive factor e xt. The result is that the entire quantity multiplying e xt now vanishes, and the endpoint integrated terms vanish as well. Thus, the ODE is satisﬁed for the integral representationM (a, c, x). (b) A procedure similar to that given for the integral representation of M can also be carried out for U ; the main diﬀerence is that the minus sign in e −xt and the presence of 1+t rather than 1−t cause some sign diﬀerences, but all terms still cancel. The negative exponential also causes vanishing of the endpoint integrated terms at x = ∞, so the ODE is also satisﬁed for the integral representation of U (a, c, x). The deﬁnition of M (a, c, x) as presented in the text yields a result that can become large for large x (for suitably chosen parameter values) and is regular at x = 0; in fact, its value at x = 0 is unity. The text does CHAPTER 3. EXERCISE SOLUTIONS 316 not show that the formula given for U (a, c, x), Eq. (18.142), has partic- ular properties at x = 0 and x = ∞, but a more detailed analysis (see the additional readings) establishes that U as deﬁned in that equation is singular at x = 0 and approaches zero for a range of parameter values at x = ∞. With these facts available, we can conclude that because the integral representation given for M is nonsingular at x = 0, it cannot con- tain an admixture of U . Moreover, the representation given for U cannot contain M because it vanishes at large x for all parameter values for which the integral converges. Our ﬁnal task is to conﬁrm that these integral representations are properly scaled. The representation for M reduces at x = 0 to a beta function, and the quantity premultiplying the integral is just the inverse of that beta function, leading to M (a, c, 0) = 1. The factor multiplying the integral for U is that needed for correct asymptotic behavior; for a proof see the additional readings. 18.6.11. This procedure was used to solve Exercise 18.6.8. 18.6.12. This formula was derived as a step in the solution of Exercise 18.6.5. 18.6.13. (a) For M (a, c, x), change the integration variable to u = 1 − t and de- velop the integrand as a power series in u. Thus, formally (irrespective of convergence) we have M (a, c, x) ∼ Γ(c) e x Γ(a)Γ(c − a) ∫ 1 0 e −xuuc−a−1(1 − u) a−1 du = Γ(c) e x Γ(a)Γ(c − a) ∞∑ n=0 (a − 1 n )(−1)n ∫ 1 0 e −uxuc−a−1+n du . Changing the integration variable to v = xu and assuming that x is large enough that the upper limit for integration in v can without signiﬁcant error be changed to v = ∞, we have M (a, c, x) ∼ Γ(c) e x Γ(a)Γ(c − a)xc−a nmax∑ n=0 ( a − 1 n ) (−1) n xn ∫ ∞ 0 vc−a−1+ne −v dv ≈ Γ(c) e x Γ(a)Γ(c − a)xc−a nmax∑ n=0 ( a − 1 n ) (−1) n xn Γ(c − a + n) . To reconcile this answer with that given in the text, note that (−1) n( a − 1 n ) = (1 − a)(2 − a) · · · (n − a) n! and Γ(c − a + n) Γ(c − a) = (c − a) · · · (c − a + n − 1) . CHAPTER 3. EXERCISE SOLUTIONS 317 (b) A treatment similar to that used in part(a) conﬁrms the answer given in the text. 18.6.14. When a linear second-order ODE is written in self-adjoint form as [p(x)y′] ′+ q(x)y = 0, the Wronskian of any two linearly independent solutions of the ODE must be proportional to 1/p. For the conﬂuent hypergeometric equa- tion p(x) = x ce −x; this can be found by methods discussed in Chapter 7 and checked by direct evaluation. The proportionality constant, which may depend upon the parameters a and c, may be determined from the behavior of M and U at any convenient value of x. Using the asymptotic values of M and U from Exercise 18.6.13 and the leading terms of their derivatives, we have M (a, c, x) ∼ Γ(c) Γ(a) e x xc−a ∼ M ′(a, c, x) , U (a, c, x) ∼ x −a , U ′(a, c, x) ∼ − a xa+1 . Noting that M U ′ becomes negligible relative to M ′U , we identify the Wronskian as Wronskian(M, U ) = −M ′U = − Γ(c) Γ(a) e x xc−a x−a , equivalent to the formula in the text.a is zero or a negative integer, M does not exist, and the Wronskian evaluates to zero. 18.6.15. The Coulomb wave equation is of the form of Eq. (18.153), so its regu- lar solutions will be Whittaker functions Mkµ of appropriate indices and argument. To convert the term −1/4 of Eq. (18.153) into the +1 of the Coulomb equation, the argument of the Whittaker function needs to beir. This will cause the y′′ term of the ODE to be multiplied by −1/4. We also need to replace x by 2ir in the coeﬃcient of Mkµ. To complete the correspondence of these two ODEs, we set k = iη and µ = L + 1/2. Writing Mkµ in terms of M (a, c, x), we get Miη,L+1/2(2ir) = e −ir(2ir) L+1M (L + 1 − iη, 2L + 2, 2ir) . 18.6.16. (a) Insert the conﬂuent hypergeometric representation of the Laguerre function. The demonstration is straightforward. (b) We need a solution with the opposite sign of n 2, i.e., with n replaced by in. As seen in Exercise 18.6.15, this also corresponds to the replacement of α by iα. 18.6.17. The answers are given in the text. CHAPTER 3. EXERCISE SOLUTIONS 318 18.7 Dilogarithm 18.7.1. Since this series, with z = 1, is convergent, with value ζ(2), the magnitude of its sum for all z of unit magnitude will be no greater than ζ(2) (and equal to ζ(2) only if all its terms have the same phase). Thus, the series is convergent for all z on the unit circle. 18.7.2. Using Eq. (18.161) with z = 1 2 , we get Li2(1/2) = π2 12 − ln 2 2 2 . 18.7.3. The multiple values arise from ln 2 2 = (ln 2 + 2πni) 2 = ln 2 2 + 4nπi ln 2 − 4n2π2 , , so Li2(1/2) = π2 12 − ln 2 2 2 + 2n2π2 − 2nπi ln 2 , where n can be any positive or negative integer or zero. Note that diﬀerent n lead to diﬀerent values of both the real and imaginary parts of Li2(1/2). 18.7.4. The principal branch of Li2 is usually deﬁned to be the result given by the power series expansion and its analytic continuation, with a branch cut extending just below the positive real axis from 1 to inﬁnity. This means that in using Eq. (18.161) we take Li2(1) = ζ(2) = π2/6 and seek to verify that Li2(0) = 0. The veriﬁcation depends upon the fact that limz→0 ln z ln(1 − z) = 0, which can be proved by expanding ln(1 − z) as −z − z2/2 − · · · and noting that the leading term for small z, −z ln z, approaches the limit zero. 18.7.5. Rewrite Eq. (18.163), with z replaced by (1 + y−1)/2. Then z z − 1 = y−1 + 1 2 y−1 − 1 2 = 1 + y 1 − y , 1 − z = 1 − ( 1 + y−1 2 ) = 1 − y−1 2 , and we have Li2 ( 1 + y−1 2 ) + Li2 ( 1 + y 1 − y ) = − 1 2 ln 2 ( 1 − y−1 2 ) , equivalent to the relationship to be proved. 18.7.6. Transform the Li2 functions to forms in which their arguments are real and in the range (−∞, +1). The function needing transformation is Li2(ζj), since ζj can be larger than +1. Using Eq. (18.161) for each j, the three j values together contribute π2/2 (which cancels the −π2/2 in the original CHAPTER 3. EXERCISE SOLUTIONS 319 form. Within the summation, we replace Li2(ζj) with −Li2(1 − ζj) − ln ζj ln(1 − ζj). The ﬁnal result is − 32π3 α1α2α3 3∑ j=1 [ Li2(−ζj) + Li2(1 − ζj) + ln ζj ln(1 + ζj) ] . 18.8 Elliptic Integrals 18.8.1. Writing ds = (dx 2 + dy2) 1/2 as the diﬀerential of distance along the path, we compute for the ellipse at the point described by parameter θ ds dθ = [( dx dθ )2 + ( dy dθ )2]1/2 = [ a2 cos2 θ + b2 sin 2 θ]1/2 . The path length for the ﬁrst quadrant is therefore the integral ∫ π/2 0 [ a2 cos2 θ + b2 sin 2 θ]1/2 dθ = ∫ π/2 0 [ a2 + (b2 − a 2) sin2 θ]1/2 = a ∫ π/2 0 (1 − m sin 2 θ) 1/2 dθ , where m = (a2 − b 2)/a2. This rearrangement is only appropriate if a > b, since we want our elliptic integral to be in the standard form with 0 < m < 1. If b > a, we could interchange the roles of these param- eters by changing the integration variable to π/2 − θ and taking a factor b outside the square root. Completing the analysis for the current case, we identify the elliptic inte- gral as E(m), thereby conﬁrming the answer in the text. 18.8.2. Expand the integrand in the trigonometric form of E(m): E(m) = ∫ π/2 0 (1 − m sin 2 θ)1/2 dθ = π 2 + ∞∑ n=1 ( 1/2 n )(−1) nmn ∫ π/2 0 sin 2n θ dθ . Then use the formulas (valid for n > 0) ( 1/2 n ) = (−1) n−1 (2n − 3)!! (2n)!! , ∫ π/2 0 sin 2n θ dθ = π 2 (2n − 1)!! (2n)!! to bring E(m) to the form given in the text. CHAPTER 3. EXERCISE SOLUTIONS 320 18.8.3. Here the arguments of K and E are implicitly assumed to be m. Form the diﬀerence K = E showing explicitly the ﬁrst two terms of their power-series expansions: K(m) = π 2 [ 1 + ( 1!! 2!! )2 m + · · · ] , E(m) = π 2 [ 1 − ( 1!! 2!! )2 m − · · · ] , so K(m) − E(m) = π 2 [ 2 ( 1!! 2!! )2 m + · · · ] = π 4 m + · · · . Dividing by m and taking the limit m → 0, we get the desired result. 18.8.4. Rewrite the denominator of the integrand of the expression for Aϕ as a 2 + ρ2 + z2 − 2aρ cos α = a2 + ρ2 + 2aρ + z2 − 2aρ(cos α + 1) . Then deﬁne θ = α/2, write cos α + 1 = 2 cos2 θ, and thereby convert Aϕ to the form Aϕ = aµ0I 2π(a2 + ρ2 + 2aρ + z2)1/2 ∫ π 0 cos α dα (1 − k2 cos2 θ)1/2 , where k2, as deﬁned in the exercise, is k2 = 4aρ (a + ρ)2 + z2 . Further simpliﬁcation and a change of the integration variable to θ bring us to Aϕ = µ0Ik 2π ( a ρ )1/2 ∫ π/2 0 (2 cos2 θ − 1) dθ (1 − k2 cos2 θ)1/2 . Now bring the integrand to a more convenient form by identifying 2 cos2 θ − 1 = − 2 k2 (1 − k2 cos2 θ) + 2 k2 − 1 , reaching Aϕ = µ0Ik 2π ( a ρ )1/2 ∫ π/2 0 dθ [ − 2 k2 (1 − k2 cos2 θ) 1/2 + ( 2 k2 − 1) (1 − k2 cos2 θ) −1/2] . CHAPTER 3. EXERCISE SOLUTIONS 321 Finally, we note that because the range of integration is (0, π/2) we can replace cos θ by sin θ without changing the value of the integral, so the two terms of the integrand can be identiﬁed with E(k2) and K(k2), thereby obtaining the result in the text. 18.8.5. Here E(k2) and K(k2) need to be expanded in power series, and the answer given in the text suggests that we must keep explicit terms in the expansions though k4. We therefore write f (k2) = k−2[ (2 − k2) π 2 ( 1 + k2 4 + 9k4 64 + · · · ) − 2 π 2 ( 1 − k2 4 − 3k4 64 − · · · ) ] The leading term in the above expression (that of lowest order in k) is πk2/16. 18.8.6. In this exercise, all instances of E and K without arguments refer respec- tively to E(k2) and K(k2). (a) Starting from the trigonometric form for E(k2), diﬀerentiate, getting dE(k2) dk = ∫ π/2 0 −k sin 2 θ (1 − k2 sin 2 θ)1/2 dθ . Simplify by rewriting the numerator of the integrand: −k sin 2 θ = (1 − k2 sin 2 θ) k − 1 k , after which we get dE(k2) dk = 1 k ∫ π/2 0 dθ [(1 − k2 sin 2 θ)1/2 − 1 (1 − k2 sin 2 θ)1/2 ] = E(k2) − K(k2) k . (b) Note that the formula in the hint contains a misprint: in the integrand,should be replaced by k2. Before solving this problem, we follow the hint and establish the equation it provides. We do so by expanding the integrand of the hint equation in power series, then multiplying the expansion by 1 − k2 and organizing the result in powers of k, and ﬁnally identifying that power series as E(k2). CHAPTER 3. EXERCISE SOLUTIONS 322 Thus, I = ∫ π/2 0 (1 − k2 sin 2 θ) −3/2 dθ = ∫ π/2 0 dθ + ∞∑ n=1(−1) nk2n( −3/2 n ) ∫ π/2 0 sin 2n θ dθ . Using now the formulas (valid for n ≥ 1) (−3/2 n ) = (−1) n(2n + 1)!! (2n)!! , ∫ π/2 0 sin 2n θ dθ = (2n − 1)!! (2n)!! π 2 , we bring I to the form I = π 2 [ 1 + ∞∑ n=1 k2n (2n + 1)!!(2n − 1)!! (2n)!!(2n)!! ] . Next we write (1 − k2)I, grouping terms with equal powers of k: (1 − k2)I = π 2 ( 1 + ∞∑ n=1 k2n [ (2n + 1)!!(2n − 1)!! (2n)!!(2n)!! − (2n − 1)!!(2n − 3)!! (2n − 2)!!(2n − 2)!! ]) = π 2 ( 1 + ∞∑ n=1 k2n (2n − 1)!!(2n − 3)!! (2n)!!(2n)!! [ (2n + 1)(2n − 1) − (2n)(2n) ] ) = π 2 ( 1 − ∞∑ n=1 k2n (2n − 1)!!(2n − 3)!! (2n)!!(2n)!! ) , which is equivalent to E(k2). Proceeding now to the solution of part (b), we write dK(k2) dk = ∫ π/2 0 k sin 2 θ (1 − k2 sin 2 θ)3/2 dθ . Replacing k sin 2 θ as in part (a) of this problem, we have dK(k2) dk = 1 k ∫ π/2 0 [− 1 (1 − k2 sin 2 θ)1/2 + 1 (1 − k2 sin 2 θ)3/2 ] dθ = 1 k [ [−K(k2) + I] , where I is the integral in the hint. Writing I = E(k2)/(1 − k2), we retrieve the answer to this problem. CHAPTER 3. EXERCISE SOLUTIONS 323 19. Fourier Series 19.1 General Properties 19.1.1. By orthogonality 0 = ∂∆p ∂an = −2 ∫ 2π 0 [ f (x) − a0 2 − ∞∑ n=1(an cos nx + bn sin nx) ] cos nx dx = −2 ∫ 2π 0 f (x) cos nx dx + 2πan, 0 = ∂∆p ∂bn = −2 ∫ 2π 0 [ f (x) − a0 2 − ∞∑ n=1(an cos nx + bn sin nx) ] sin nx dx = −2 ∫ 2π 0 f (x) sin nx dx + 2πbn. 19.1.2. Substituting αn cos θn = an, αn sin θn = bn into Eq. (19.1) we have an cos nx + bn sin nx = αn(cos θn cos nx + sin θn sin nx) = αn cos(nx − θn). 19.1.3. The exponential Fourier series can be real only if, for each n, cne inx + c−ne −inx is real. Expanding the complex exponential, cne inx + c−ne −inx = (cn + c−n) cos nx + i(cn − c−n) sin nx . This expression will be real if cn+c−n is real and cn−c−n is pure imaginary. Writing cn = an + ibn with an and bn real, these two conditions on the cn take the form bn + b−n = 0 , an − a−n = 0 , equivalent to a requirement that c−n = c ∗ . 19.1.4. Expand f (x) in a Fourier series. Then if ∫ π −π [ a0 2 + ∞∑ n=1(an cos nx + bn sin nx) ]2 dx = 1 2 a 2π + π ∞∑ n=1(a 2 + b 2 ) < ∞ is absolutely convergent, it is necessary that lim n→∞ an → 0, lim n→∞ bn → 0. CHAPTER 3. EXERCISE SOLUTIONS 324 19.1.5. By parity, an = 0, n ≥ 0, while bn = 1 2π [∫ π 0 (π − x) sin nx dx − ∫ 0 −π(π + x) sin nx dx ] = 1 2π [ − π n cos nx + x n cos nx ]π − 1 2πn ∫ π 0 cos nx dx − 1 2πn ∫ 0 −π cos nx dx − 1 2π [ − π n cos nx − x n cos nx ]0 π = 1 n − sin nx 2πn2 ∣ π − sin nx 2πn2 ∣ 0 π = 1 n . 19.1.6. Writing sin nx in terms of complex exponentials, this summation becomes S = ∞∑ n=1(−1) n+1 sin nx n = 1 2i [ ∞∑ n=1(−1)n+1 e inx n − ∞∑ n=1(−1) n+1 e −inx n ] . These summations correspond to the expansion of ln(1 + e ±ix), so S = 1 2i [ ln(1 + e ix) − ln(1 + e −ix) ] = 1 2i ln ( 1 + e ix 1 + e−ix ) = 1 2i ln e ix . We need the principal value of this logarithm so that S = 0 when x = 0. Thus, S = ix/2i = x/2. 19.1.7. By parity, an = 0 while bn = 1 4 [∫ π 0 sin nx dx − ∫ 0 −π sin nx dx ] = − 1 4 ( cos nx n ∣π − cos nx n ∣0 π ) = − 1 4 [ 2(−1)n − 2] = 1 − (−1) n 2n = { 1/n, n odd 0, n even. 19.1.8. (a) Write 2 cos θ/2 in terms of complex exponentials and rearrange: 2 cos θ/2 = e iθ/2 + e −iθ/2 = e −iθ/2 [ 1 + e iθ] . Take the logarithm of both sides of this equation and use the expansion of ln(1 + e iθ): ln (2 cos θ 2 ) = −iθ 2 + ∞∑ n=1(−1)n+1 e inθ n . Since the left-hand side of this equation is real, it must be equal to the real part of the right-hand side (the imaginary part of the right-hand must CHAPTER 3. EXERCISE SOLUTIONS 325 be zero; this does not concern us here but provides another route to the solution of Exercise 19.1.6). Thus, ln ( 2 cos θ 2 ) = ∞∑ n=1(−1) n+1 cos nθ n . (b) Here we have 2 sin θ 2 = i (e iθ/2 − e −iθ/2) = −ie −iθ/2 ( 1 − e iθ) . Taking the logarithm, noting that the factor preceding the parentheses on the right-hand side has the purely imaginary logarithm −i(π + θ)/2, we get ln ( 2 sin θ 2 ) = − (π + θ)i 2 + ln(1 − e iθ) . Introducing a power series for the logarithmic term and equating the real parts of the two sides of this equation, we reach our desired answer: ln ( 2 sin θ 2 ) = − ∞∑ n=1 cos nθ n . 19.1.9. The solution is given in the text. 19.1.10. The solution is given in the text. 19.1.11. ∫ π −π f (ϕ1)δ(ϕ1 − ϕ) dϕ1 = ∞∑ m=−∞ 1 2π e −imϕ ∫ π −π f (ϕ1)e imϕ1 dϕ1 = ∑ m f−me −imϕ = f (ϕ). 19.1.12. Integrating Example 19.1.1 yields ∫ x 0 x dx = 1 2 x 2 = 2 ∞∑ n=1 (−1) n n2 cos nx ∣ x = 2 ∞∑ n=1 (−1) n n2 (cos nx − 1). For x = π we obtain π2 2 = 2ζ(2) + 2 ∞∑ n=1 (−1) n−1 n2 . Hence π2 2 ( 1 2 − 1 3 ) = ∞∑ n=1 (−1) n−1 n2 . 19.1.13. (a) Using orthogonality givesπ −π [ a0 2 + ∞∑ n=1(an cos nx + bn sin nx) ]2 dx = ( a0 2 )2 2π π + π π ∞∑ n=1(a 2 + b2 ). CHAPTER 3. EXERCISE SOLUTIONS 326 (b) 1 π ∫ π −π x 4dx = x5 5π ∣ π π = 2 5 π4 = 2π4 9 + 42ζ(4). Hence ζ(4) = π4 42 ( 2 5 − 2 9 ) = 4π4 23 · 32 · 5 . (c) 1 π ∫ π −π dx = 2 = ( 4 π )2 ∞∑ n=1 1 (2n − 1)2 . This checks with ζ(2) = 1 22 ζ(2) + ∞∑ n=1 1 (2n − 1)2 = π2 6 . 19.1.14. For 0 < x < π, ∞∑ n=1 ∫ x 0 sin nx n dx = − ∞∑ n=1 cos nx n2 ∣x = π2 6 − ∞∑ n=1 cos nx n2 = ∫ x 0 ( π 2 − x 2 ) dx = xπ 2 − x 2 4 . Hence ∞∑ n=1 cos nx n2 = 1 4 (π − x) 2 − π2 12 . For −π < x < 0, the claim is proved similarly. 19.1.15. (a) ∫ x 0 ψ2s−1(x) dx = ∞∑ n=1 ∫ x 0 cos nx n2s−1 dx = ∞∑ n=1 sin nx n2s ∣ x = ∞∑ n=1 sin nx n2s = ψ2s(x) . (b) ∫ x 0 ψ2s(x) dx = ∞∑ n=1 ∫ x 0 sin nx n2s dx = − ∞∑ n=1 cos nx n2s+1 ∣ x = − ∞∑ n=1 cos nx n2s+1 + ∞∑ n=1 1 2s + 1 = −ψ2s+1(x) + ζ(2s + 1) . This equation rearranges into the required result. 19.1.16. Make the partial fraction decomposition 1 n2(n + 1) = 1 n + 1 − 1 n + 1 n2 . CHAPTER 3. EXERCISE SOLUTIONS 327 Then ∞∑ n=1 cos nx n2(n + 1) = ∞∑ n=1 cos nx n + 1 − ∞∑ n=1 cos nx n + ∞∑ n=1 cos nx n2 = f (x) − ψ1(x) + ϕ2(x), equivalent to the required form. 19.2 Applications of Fourier Series 19.2.1. The Fourier expansion of the present problem is f (x) = h 2 + 2h π [ sin x 1 + sin 3x 3 + · · · ] . The expansions of the ﬁrst few x-containing terms are sin x 1 = x − x 3 3! + x 5 5! − · · · , sin 3x 3 = x − 3 2x 3 3! + 3 4x 5 5! − · · · , sin 5x 5 = x − 5 2x 3 3! + 5 4x 5 5! − · · · . Collecting the coeﬃcients of x, x 3, · · · , we ﬁnd Coeﬃcient of x = 1 + 1 + 1 + · · · , Coeﬃcient of x3 = − 1 3! [ 1 + 3 2 + 5 2 + · · · ] , etc. These expressions diverge. 19.2.2. δ(x) = 1 2π + 1 π ∞∑ n=1 cos nx , − π ≤ x ≤ π. 19.2.3. Solution is given in the text. 19.2.4. ∫ π 0 δ(x − y) dt = ∫ π 0 [ 1 2π + 1 π ∞∑ n=1 cos n(x − t) ] dt = 1 2 − 1 π ∞∑ n=1 sin n(x − t) n ∣ π = 1 2 + 1 π ∞∑ 1 1 − (−1)n n sin nx = 1 2 + 2 π ∞∑ n=0 sin(2n + 1)x 2n + 1 = { 1, for 0 < x < π, 1, for − π < x < 0. CHAPTER 3. EXERCISE SOLUTIONS 328 19.2.5. Subtract the series on line 5 of Table 19.1 from the series on line 4 of that table; the result is ∞∑ n=0 cos nx x [1 − (−1)n] = 2 ∞∑ n=0 cos(2n + 1)x 2n + 1 = − ln [sin |x| 2 ] + ln [ cos x 2 ] = ln [cot |x| 2 ] . Because the cosine is an even function, cos(x/2) = cos(|x|/2). 19.2.6. Solution is given in the text. 19.2.7. The cosine terms of the expansion all vanish because f (x) has odd parity. bn = 1 π ∫ π −π x sin nx dx = − x cos nx nπ ∣π π + 1 nπ ∫ π −π cos nx dx = − 2(−1) n n . 19.2.8. The cosine terms of the expansion all vanish because f (x) has odd parity. bn = 1 π ∫ 0 −π ( − π + x 2 ) sin nx dx + 1 π ∫ π 0 ( π − x 2 ) sin nx dx = 2 π ∫ π 0 ( π − x 2 ) sin nx dx = ∫ π 0 sin nx dx − 1 π ∫ π 0 x sin x dx . The second of these integrals is half the formula for bn in the solution to Exercise 19.2.7, while the ﬁrst integrates to (1−cos nπ)/n = [1−(−1) n]/n. The ﬁnal result is bn = 1/n. 19.2.9. Solution is given in the text. 19.2.10. a0 = 2x0 π , an = 2 π sin nx0 n , n ≥ 1, bn = 0, n ≥ 1. 19.2.11. ψ(r, ϕ) = 4V π ∞∑ m=0 ( r a )2m+1 sin(2m + 1)ϕ 2m + 1 . 19.2.12. (a) ψ(r, ϕ) = −E0r (1 − a2 r2 ) cos ϕ . (b) σ = 2ε0E0 cos ϕ. 19.2.13. (a) an = 1 π ∫ π 0 x cos nx dx = x sin nx nπ ∣ π − 1 nπ ∫ π 0 sin nx dx = cos nx n2π ∣π 0 = (−1) n − 1 n2π , CHAPTER 3. EXERCISE SOLUTIONS 329 bn = 1 π ∫ π 0 x sin nx dx = − x cos nx nπ ∣π + 1 nπ ∫ π 0 cos nx dx = (−1) n−1 n , a0 = 1 π ∫ π 0 x dx = π 2 . Thus, { x, 0 < x < π 0, −π < x < 0 } = π 4 − 2 π ∞∑ n=1 cos(2n − 1)x (2n − 1)2 − ∞∑ n=1 (−1) n sin nx n . (b) is the above at x = 0. 19.2.14. Integrating 1 2 + 2 π ∞∑ n=1 sin(2n − 1)x 2n − 1 = { 0, −π < x < 0 1, 0 < x < π yields 1 2 ∫ x 0 dx − 2 π ∞∑ n=1 cos(2n − 1)x|x (2n − 1)2 = ∞∑ n=1(−1) n−1 sin nx n + 2 π π2 8 − 2 π ∞∑ n=1 cos(2n − 1)x (2n − 1)2 = { 0, −π < x < 0, x, 0 < x < π. 19.2.15. (a) δn(x) = 1 2π + 2n π ∞∑ m=1 sin(m/ 2n) m cos mx. 19.2.16. ∫ π −π f (x) δn(x) dx = ∫ π −π f (x) [ 1 2π + 2n π ∞∑ m=1 sin(m/2n) m cos mx ] dx = a0 2 + 2n π ∞∑ m=1 sin(m/2n) m ∫ π −π f (x) cos mx dx → a0 2 + ∞∑ m=1 1 π ∫ π −π f (x) cos mx dx = f (0) in the limit n → ∞. 19.2.17. (a) The coeﬃcient bn is given as the integral bn = 2 L ∫ L 0 δ(x − a) sin ( nπx L ) dx = 2 L sin ( nπa L ) . (b) Integration of the left-hand side of the delta-function formula from 0x yields unity if a is within the range of the integration and zero other- wise, producing the step function shown in the exercise. A corresponding CHAPTER 3. EXERCISE SOLUTIONS 330 integration of the right-hand side gives the listed result: f (x) = 2 L ∞∑ n=1 sin ( nπa L ) ( L nπ ) [1 − cos ( nπx L )] . (c) Referring to the ﬁrst entry in Table 19.1, the ﬁrst summation of part (b) evaluates to 2 π ( π − πa/L 2 ) = 1 − a L . Since f (x) = 0 on the interval 0 < x < a and 1 elsewhere, this expression gives the average value of f (x), as claimed. 19.2.18. Calculation of the Fourier coeﬃcients with this f (x) is equivalent to inte- grating with f (x) = 1 over the range a ≤ x ≤ L. Thus, a0 = 2 L ∫ L a dx = 2 (1 − a L ) . an = 2 L ∫ L a cos ( nπx L ) dx = − 2 nπ sin ( nπa L ) , n > 0. Inserting this into the formula for the Fourier cosine series, f (x) = (1 − a L ) − 2 π ∞∑ n=1 1 n sin ( nπa L ) cos ( nπx L ) . The correspondence is seen to be exact when we use the observation de- veloped in part (c) of Exercise 19.2.17. 19.2.19. (a) Solution is given in the text. (b) Diﬀerentiation of the solution to part (a) leads directly to the stated result for part (b). 19.2.20. Solution is given in the text. 19.2.21. Solution is given in the text. 19.3 Gibbs Phenomenon 19.3.2. Using the guidance provided in the exercise, write sn(x) = 2h π n∑ p=1 sin(2p − 1)x 2p − 1 = 2h π ∫ x 0 n∑ p=1 cos(2p − 1)y dy = 2h π ∫ x 0 sin 2ny 2 sin y dy ≈ h π ∫ x 0 sin 2ny y dy = h π ∫ 2nx 0 sin ξ ξ dξ, which reaches its maximum value at 2nx = π, with the integral then given by Eq. (19.41). CHAPTER 3. EXERCISE SOLUTIONS 331 19.3.3. Solution is given in the text. CHAPTER 3. EXERCISE SOLUTIONS 332 20. Integral Transforms 20.1 Introduction (no exercises) 20.2 Fourier Transform 20.2.1. (a) If f (x) is real, then f (x) = f ∗(x), and g∗(ω) = [ 1 (2π)1/2 ∫ ∞ −∞f (x)e iωx dx]∗ = 1 (2π)1/2 ∫ ∞ −∞f (x)e −iωx dx = g(−ω) . We must also prove the converse, namely that if g∗(ω) = g(−ω), then f (x) is real. So, making no assumption as to the reality of f (x), the condition g∗(ω) = g(−ω) is equivalent to 1 (2π)1/2 ∫ ∞ −∞ f ∗(x)e −iωx dx = 1 (2π)1/2 ∫ ∞ −∞ f (x)e −iωx dx for all ω. That can only be true if f (x) = f ∗(x); one way to see this is to multiply the above equation by e iωt, with t arbitrary, and integrate in ω from −∞ to ∞, thereby forming 2πδ(t − x). Then the x integration yields f ∗(t) = f (t). (b) A proof can be along the lines of that for part (a). The sign change in going from g(−ω) to g∗(ω) is compensated by that between f (x) and f ∗(x). 20.2.2. (a) gc(ω) = √ 2 π ∫ 1 0 cos ωx dx = √ 2 π sin ω ω . (b) The equation written here is just the inverse cosine transform of gc and therefore has to yield f (x). (c) For all x such that |x| ̸= 1 the integral of this part is (π/2)f (x), in agreement with the answer in the text. For x = 1, the present integral can be evaluated as ∫ ∞ 0 sin ω cos ω ω dω = 1 2 ∫ ∞ 0 sin 2ω ω dω = 1 2 ∫ sin u u du = 1 2 π 2 = π 4 . The u integral is that in Eq. (11.107). 20.2.3. (a) Integrating by parts twice we obtain∞ 0 e −ax cos ωx dx = − 1 a e −ax cos ωx∣ ∞ − ω a ∫ ∞ 0 e −ax sin ωx dx = 1 a − ω a [− 1 a e −ax sin ωx∣ ∞ + ω a ∫ ∞ 0 e −ax cos ωx dx ] . CHAPTER 3. EXERCISE SOLUTIONS 333 Now we combine the integral on the right-hand side with that on the left(1 + ω2 a2 ) ∫ ∞ 0 e −ax cos ωx dx = 1 a , or gc(ω) = √ 2 π ∫ ∞ 0 e −ax cos ωx dx = √ 2 π a a2 + ω2 . A similar process yields the formula for gs(ω). (b) The second integral of this part can be written as half the real part of an integral involving e iωx: I = ∫ ∞ 0 cos ωx ω2 + a2 dω = 1 2 ℜe ∫ ∞ −∞ e iωx ω2 + a2 dx . We now replace ω by a complex variable z and employ a contour along the real axis and closed by an arc of inﬁnite radius in the upper half-plane (on which there is no contribution to the integral). This contour encloses a pole at z = ia; the other pole of the integrand, z = −ia, is external to the contour. Therefore,= 1 2 ℜe ∮ e ixz z2 + a2 dz = ℜe [ 1 2 2πi × (Residue of integrand at z = ia) ] . This residue has the value e −ax/2ia, so I = π 2a e −ax. The ﬁrst integral of this part can now be obtained easily by diﬀerentiating the above result with respect to x. 20.2.4. g(ω) = √ 2 π ha ω2 [ 1 − cos ( ω a )] . 20.2.5. Write the Fourier integral representation of the delta sequence: δ(x) = 1 2π ∫ ∞ −∞ e −iωx dω lim n→∞ ∫ ∞ −∞ δn(t)e iωt dt = 1 2π ∫ ∞ −∞ e −iωx dω . We have used the fact that the integral over t reduces to unity, the value of e iωt at t = 0. 20.2.6. See solution to Exercise 20.2.5. The same result will be obtained for any valid delta sequence. 20.2.7. The solution is given in the text. 20.2.8. The solution is given in the text. CHAPTER 3. EXERCISE SOLUTIONS 334 20.2.9. The answer to this problem depends upon the sign of Γ and it is assumed here that Γ > 0. The integrand of this problem has a simple pole at a = E0 − iΓ/2 ℏ , with residue − exp(iat) , where a is located in the lower half of the ω-plane. The integral in question can be converted into one with a closed contour by connecting the points ±∞ by a large arc; if t > 0 a suitable arc will be clockwise, in the lower half-plane, as e −iωt becomes negligible when ω has a large negative imaginary part. The contour will then enclose the pole in the mathematically negative direction, so the contour integral (and also our original integral) has the value + exp(iat), corresponding to the answer for t > 0 in the text. If, however, t < 0, the contour must be closed in the upper half-plane, the pole is not encircled, and both the contour integral and our original integral will vanish. These observations conﬁrm the answer in the text for t < 0. 20.2.10. (a) A natural approach to this problem is to use the integral representation J0(ay) = 2 π ∫ 1 0 cos ayt √1 − t2 dt . However, all mention of this representation was inadvertently omitted from the present edition, so it may be easier for readers to proceed by recog- nizing the case n = 0 of Exercise 20.2.11 as a starting point. In that transform pair, replacement of t by ay causes the replacement of x by x/a and multiplication of the expression in x by a −1, thereby obtaining the desired answer. If we use the integral representation provided above, we would form the integral producing the transform and interchange the order of the two integrals: [J0(ay)] T (x) = 1 √2π 2 π ∫ 1 0 dt √1 − t2 ∫ ∞ −∞ cos ayt e ixy dy . Replacing cos ayt by (e iayt + e −iayt)/2, we identify the y integral in terms of delta functions, reaching [J0(ay)] T (x) = 1 √2π 2 π 2π a ∫ 1 0 dt √1 − t2 [ δ(t + x/a) + δ(t − x/a) 2 ] = √ 2 π  1 √a2 − x2 , |x| < a, 0 , |x| > a. CHAPTER 3. EXERCISE SOLUTIONS 335 (b) The expression in x is incorrect; the quantity within the square root should be x 2 − a 2. Use the second integral representation given in Eq. (14.63) and proceed as in the second approach given above for part (a). (c) Here use the integral representation given in Eq. (14.113), and proceed as in the earlier parts of this exercise.I0(ay) diverges exponentially at large y and does not have a Fourier transform. 20.2.11. Strictly speaking, these expressions are not Fourier transforms of each other. While i nJn(t) is the transform of the expression opposite it, the transform of inJn is (−1) n times the Chebyshev expression. To establish the transform relationship, start by writing the transform of the right-hand expression in the angular variable θ, where x = cos θ: [√ 2 π Tn(x)(1 − x 2) −1/2]T = 1 π ∫ 1 −1 Tn(x)e itx(1 − x 2) −1/2 dx = 1 π ∫ π 0 cos nθ e it cos θ dθ = 1 π ∫ π 0 e i(t cos θ+nθ) + e i(t cos θ−nθ) 2 dθ = 1 2π ∫ 2π 0 e i(t cos θ+nθ) dθ . We now identify this integral as the integral representation of Jn that was given in Exercise 14.1.15(b), with value 2πi nJn(t), and therefore [√ 2 π Tn(x)(1 − x 2) −1/2]T = i nJn(t) . 20.2.12. The transform as given in the text is improperly scaled. Its correct value is (2/π) 1/2i njn(ω), where ω is the transform variable. The exercise also assumes the transform variable to be kr. The Fourier transform of f (µ) is f T (µ) = 1 √2π ∫ 1 −1 e iωµPn(µ) dµ . This integral was evaluated in Exercise 15.2.26, where it was shown to have the value 2i njn(ω). Inserting this result into the formula for the transform, we verify its value (as corrected). 20.2.13. (a) Consider the integral I = ∫ ∞ 0 z−1/2e izt dz = ∫ ∞ 0 x −1/2(cos xt + i sin xt) dx . CHAPTER 3. EXERCISE SOLUTIONS 336 Make a change of the integration variable to u = −izt and assume t > 0; the range of the integration in u is (0, i∞), and the integral becomes I = e πi/4t−1/2 ∫ i ∞ 0 u−1/2e −u du . Deform the contour to go along the real axis from zero to inﬁnity, and then along a counterclockwise loop at large |u| to the imaginary axis. The large arc does not contribute to the integral, but the path along the real axis evaluates to Γ(1/2) = √π. Thus, I = t1/2 1 + i √2 √π , from which we verify both the integrals of this part of the exercise. (b) In the ﬁrst integral of part (a), make a change of the integration variable to y2 = xt, so x−1/2dx = 2t −1/2dy, and that integral becomes √ 2 π ∫ ∞ 0 x −1/2 cos xt dx = √ 2 π 2t−1/2 ∫ ∞ 0 cos y2 dy = t −1/2 , which rearranges to ∫ ∞ 0 cos(y2) dy = 1 2 √ π 2 . The same result is obtained for ∫ ∞ 0 sin(y2) dy . 20.2.14. We must evaluate f T = 1 (2π)3/2 ∫ e ik·r r2 d3r . Use spherical polar coordinates with axis in the direction of k. After changing the integration variable θ into t = cos θ, integrate over ϕ and t, reaching fT = 1 (2π)3/2 ∫ 2π 0 dϕ ∫ ∞ 0 dr ∫ π 0 sin θ eikr cos θ dθ = 1 (2π)1/2 ∫ ∞ 0 2 sin kr kr dr = 1 (2π)1/2 π k = 1 k √ π 2 . 20.2.15. Write the formula for F (u, v) in polar coordinates, setting x = r cos θ, y = r sin θ, u = ρ cos θ′, v = ρ sin θ′, with f = f (r) and F = F (ρ): F (ρ) = 1 2π ∫ ∞ 0 r dr ∫ 2π 0 dθf (r) e iρr(cos θ cos θ′+sin θ sin θ′) = ∫ ∞ 0 r f (r) dr 1 2π ∫ 2π 0 dθeiρr cos(θ−θ′) . CHAPTER 3. EXERCISE SOLUTIONS 337 We may replace θ − θ′ by θ without changing the value of the θ integral, after which it (including the premultiplier 1/2π) can be identiﬁed as the integral representation of J0(ρr) given as Eq. (14.20). This reduces f (ρ) to the Hankel transform given in the text. A similar procedure can be used to verify the inverse Hankel transform. 20.2.16. Change d3x in this exercise to d3r and remove the integration limits of the d3r integral (they are understood to be the entire 3-D space). Write the integral of this exercise in spherical polar coordinates and make the change of variable cos θ = t: 1 (2π)3/2 ∫ ∞ 0 r2f (r) dr ∫ 2π 0 dϕ ∫ 1 −1 e ikrt dt = 1 (2π)1/2 ∫ ∞ 0 r2f (r) dr e ikr − e −ikr ikr = 1 (2π)1/2 ∫ ∞ 0 r2f (r) 2 sin kr kr , which rearranges to the answer in the text. 20.3 Properties of Fourier Transforms 20.3.1. The following relationships can be established using the methods for the solution of Exercise 20.3.2. [ f (t − a)] T (ω) = e iωtg(ω) , [ f (αt)] T (ω) = 1 α g(α−1ω) , [ f (−t) ] T (ω) = g(−ω) , [ f ∗(−t) ] T (ω) = g∗(ω) . 20.3.2. (a) [ f (r − R) ] T (k) = 1 (2π)3/2 ∫ f (r − R)e ik·rd3r = 1 (2π)3/2 ∫ f (r)e ik·(r+R)d3r = e ik·Rg(k) . (b) [ f (αr) ] T = 1 (2π)3/2 ∫ f (αr)e ik·rd3r = 1 (2π)3/2 ∫ f (r)e ik·r/αα−3d3r = 1 α3 g(α−1k). [ f (−r)] T (k) = 1 (2π)3/2 ∫ f (−r)e ik·rd3r = 1 (2π)3/2 ∫ f (r)e ik·(−r)d3r = g(−k). [ f ∗(−r)] T (k) = 1 (2π)3/2 ∫ f ∗(−r)e ik·rd3r = [ 1 (2π)3/2 ∫ f (−r)e −ik·rd3r]∗ CHAPTER 3. EXERCISE SOLUTIONS 338 = [ 1 (2π)3/2 ∫ f (r)e −ik·(−r)d3r]∗ = g∗(k). 20.3.3. Applying Green’s theorem, Eq. (3.85) and recognizing that its surface terms vanish here, the formal expression for the transform of the Laplacian becomes [ ∇2f (r)] T = 1 (2π)3/2 ∫ ∇2f (r)e ik·r d3r = 1 (2π)3/2 ∫ f (r)∇ 2e ik·r d3r . The easiest way to evaluate ∇2e ik·r is to do so in Cartesian coordi- nates, writing it as ∇2e ikxxe ikyye ikzz, which reduces to (−k2 x − k2 y − k2 z)e ikxxe ikyye ikzz, or −k2e ik·r. When this expression is inserted into the above integral, it is seen to be equivalent to −k2f T (k) = −k2g(k). 20.3.4. We manipulate the transform of f ′(t) by integrating by parts, as follows: [ f ′(t) ] T (ω) = 1 (2π)1/2 ∫ f ′(t)e iωt dt = − 1 (2π)1/2 ∫ f (t)(iω)e iωt dt = −iωf T (ω) = −iωg(ω) . Higher derivatives can be reached by multiple integrations by parts. Each derivative generates a factor −iω in the transform. 20.3.5. Diﬀerentiating the formula for g(ω) n times with respect to ω, dn dωn g(ω) = 1 (2π)1/2 ∫ f (t) dn dωn e iωt dt = 1 (2π)1/2 ∫ f (t)(it)n e iωt dt = i n (2π)1/2 ∫ tnf (t) e iωt dt = in[ t nf (t)] T (ω) . 20.3.6. Letting g(t) be the Fourier transform of ϕ(x), using Eq. (20.56) to identify [ϕ(x) ′′]T = −t2g(t), and noting from Eq. (20.14) that [δ(x)] T = (2π)−1/2, our ODE transforms into Dt2 g(t) + K 2D g(t) = Q √2π , an algebraic equation with solution g(t) = Q D√2π 1 t2 + K 2 , . To recover ϕ(x), we need the inverse transform of g(t). Noting from Eq. (20.13) that 2KDg(t)/Q is the transform of e −K|x| with K then as- sumed to be positive, we get the answer given in the text. CHAPTER 3. EXERCISE SOLUTIONS 339 20.4 Fourier Convolution Theorem 20.4.1. (a) Form the expression on the right-hand side of the formula to be proved, inserting the deﬁnitions of the sine transforms. ∫ ∞ 0 Fs(s)Gs(s) cos xs ds = 2 π ∫ ∞ 0 ds ∫ ∞ 0 dy g(y) sin sy ∫ ∞ 0 dt f (t) sin st cos sx = 2 π ∫ ∞ 0 g(y) dy ∫ ∞ 0 f (t) dt ∫ ∞ 0 sin sy sin st cos sx ds . Now apply a trigonometric addition formula, enabling the identiﬁcation of the s integral in terms of delta functions as shown in Exercise 20.2.7. ∫ ∞ 0 sin sy sin st cos sx ds = ∫ ∞ 0 sin st [ sin s(y + x) + sin s(y − x) 2 ] ds = π 4 [ δ(t − y − x) + δ(t − y + x)] . Inserting this value for the s integral, we then integrate over t and obtain the formula in the text. (b) A similar treatment of the Fourier cosine convolution formula leads to ∫ ∞ 0 Fc(s)Gc(s) cos xs ds = 2 π ∫ ∞ 0 g(y) dy ∫ ∞ 0 f (t) dt ∫ ∞ 0 cos sy cos st cos sx ds and to the delta-function formula ∫ ∞ 0 cos sy cos st cos sx ds = π 4 [ δ(t − y − x) + δ(t − y + x)] . Keeping in mind that f is an even function, we recover the answer in the text. 20.4.2. Insert the deﬁnitions of the Fourier sine transforms into the left-hand side of the Parseval formula, and identify the t integral as a delta function (see CHAPTER 3. EXERCISE SOLUTIONS 340 Exercise 20.2.7). 2 π ∫ ∞ 0 dt ∫ ∞ 0 dx f (x) sin tx ∫ ∞ 0 dy g(y) sin ty = ∫ ∞ 0 f (x) dx ∫ ∞ 0 g(y) dy 2 π ∫ ∞ 0 sin tx sin ty dt = ∫ ∞ 0 f (x) dx ∫ ∞ 0 g(y) dy δ(x − y) = ∫ ∞ 0 f (x)g(x) dx . Proof of the Parseval formula for the cosine transforms is similar. 20.4.3. (a) Compute F (t) = 1 √2π ∫ a −a e itx dx = 1 √2π e ita − e −ita it = 1 √2π 2 sin at t , equivalent to the answer in the text. (b) The Parseval relation, applied to F (t) and F ∗(t), with a = 1, yields 2 π ∫ ∞ −∞ ( sin t t )2 dt = ∫ 1 −1[f (x)] 2 dx = 2 . Minor rearrangement shows that ∫ ∞ −∞ sin 2 t t2 dt = π. 20.4.4. (a) Let ϕ(k) be the Fourier transform of ψ(r), and let ˆρ(k) be the Fourier transform of ρ(r). Using Eq. (20.53), Poisson’s equation becomes −k2ϕ(k) = − ˆρ(k) ε0 , and ϕ(k) = ˆρ(k) ε0 k2 . (b) One could now carry out the inverse transform directly: ψ(r) = 1 (2π)3/2ε0 ∫ ˆρ(k) k2 e −ik·r d3k . It may be more instructive to use the convolution theorem, with F (k) = ˆρ(k)/ε0, f (r) = ρ(r)/ε0, G(k) = 1 k2 , g(r) = (2π)3/2 4πr , where g was obtained using Eq. (20.42). We have ψ(r) = F ∗ G = 1 (2π)3/2ε0 ∫ ρ(r ′) (2π) 3/2 4π 1 |r − r′| d3r′ = 1 4πε0 ∫ ρ(r ′) |r − r′| d3r′ . This is a conﬁrmation that Poisson’s equation is consistent with Coulomb’s law. CHAPTER 3. EXERCISE SOLUTIONS 341 20.4.5. (a) Compute F (t) = 1 √2π [∫ 2 0 (1 − x 2 ) e itx dx + ∫ 0 −2 (1 + x 2 ) e itx dx] = 1 √2π [− e 2it 2t2 + 2it + 1 2t2 − e −2it 2t2 − 2it − 1 2t2 ] = 1 √2π [ e 2it − 2 + e −2it −2t2 ] = √ 2 π ( sin t t )2 . (b) From the Parseval relation, 2 π ∫ ∞ −∞ ( sin t t )2 dx = ∫ 2 −2[f (x)] 2 dx = 2 ∫ 2 0 ( 1 − x + x2 4 ) dx = 4 3 . This equation simpliﬁes to the desired answer. 20.4.6. Setting h(x) = f (x) − g(x), we have H(t) = F (t) − G(t), and Parseval’s relation gives ∫ ∞ −∞ h(x)h∗(x) dx = ∫ ∞ −∞ H(t)H ∗(t) dt , which is the result we need. 20.4.7. (a) Use the cosine-transform Parseval relation ∫ ∞ 0 [Gc(ω)] 2 dω = ∫ ∞ 0 [g(t)] 2 dt , with g(t) = e −at , Gc(ω) = √ 2 π a ω2 + a2 . We get 2 a 2 π ∫ ∞ 0 ( 1 ω2 + a2 )2 dω = ∫ ∞ 0 e −2at dt = 1 2a . Solving for the ω integral and doubling the result, as the range asked for in the text is (−∞, ∞), we get π/2a3. (b) Proceed as in part (a), but use the sine-transform Parseval relation, g(t) = e −at , Gs(ω) = √ 2 π ω ω2 + a2 . This leads to 2 π ∫ ∞ 0 ( ω ω2 + a2 )2 dω = ∫ ∞ 0 e −2at dt = 1 2a , from which the ω integral is found to have the value π/2a. CHAPTER 3. EXERCISE SOLUTIONS 342 20.4.8. The solution is given in the text. 20.4.9. The intent of this problem is to use Fourier convolution methods to write this interaction integral in what may be a more convenient form. A direct- space integral describing the interaction energy is V = 1 4πε0 ∫ ρ(R − A) |r − C| d3r = 1 4πε0 ∫ ρ(R) |C − A − R| d3r . Applying the convolution theorem as given in Eq. (20.72), and noting that/r] T = (2π) −3/2(4π/k2), we get V = 1 (2π)3/2ε0 ∫ ρT (k) k2 e −ik·RAC d3k , where RAC = C − A. 20.4.10. This problem assumes that the momentum wave function is deﬁned (in- cluding its scale) as ϕ(p) = 1 (2πℏ)3/2 ∫ ψ(r) e −ir·p/ℏ d3r . (a) Apply iℏ∇p to both sides of the above equation. When the px compo- nent of the gradient is applied to exp(−i(xpx + ypy + zpz)/ℏ) within the integrand, the result is (−ix/ℏ) exp(−i(xpx + ypy + zpz)/ℏ), so applica- tion of the entire gradient causes the integrand to be multiplied by −ir/ℏ, thereby producing the result in the text. (b) Two successive applications of the gradient in momentum space pro- duce two factors r, as shown in the text. This result can be construed either as involving a scalar product ∇ · ∇ (and correspondingly, r · r), or as the creation of a dyadic (tensor) quantity. 20.4.11. Apply the Fourier transform operator (deﬁned as in the solution of Exer- cise 20.4.10) to both sides of the Schr¨odinger equation. With the scaling in use here, [ ∇ 2ψ]T (p) = − p2 ℏ2 ϕ(p) , and the term V (r)ψ can be expanded in a Maclaurin series with each term treated as in Exercise 20.4.10. 20.5 Signal-Processing Applications 20.5.1. The potential across a capacitor for a current I that is periodic at angular frequency ω is ∫ t(I/C)e iωt = I/iωC. Using Kirchhoﬀ’s equation we have Vin = RI + I/iωC and Vout = I/iωC, so ϕ(ω) = Vout Vin = I/iωC IR + I/iωC = 1 1 + iωRC . Since ϕ(ω) decreases as ω increases, this is a low-pass ﬁlter. CHAPTER 3. EXERCISE SOLUTIONS 343 20.5.2. The potential across an inductor for a current I that is periodic at angular frequency ω is LdI/dt = iωLI. Thus, applying Kirchhoﬀ’s equation, Vin = iωLI + IR and Vout = IR, so ϕ(ω) = Vout Vin = IR IR + iωLI = 1 1 + iωL/R . Since ϕ(ω) decreases as ω increases, this is a low-pass ﬁlter. 20.5.3. Using the potential across a capacitor in the form given in the solution to Exercise 20.5.1, we write Kirchhoﬀ’s equation for each of the two inde- pendent loops in the present circuit, obtaining Vin = I1 + I2 iωC1 + I1R1 , I2R2 + I2 iωC2 − I1R1 = 0 , Vout = I2 iωC2 . Before computing the transfer function it is convenient to solve for I1 in terms of I2: I1 = I2 R1 ( R2 + 1 iωC2 ) , I1 + I2 = I2 R1 (R1 + R2 + 1 iωC2 ) . Now, ϕ(ω) = Vout Vin = I2/iωC2 (I2/iωC1R1) (R1 + R2 + 1 iωC2 ) + I2 (R2 + 1 iωC2 ) = iωR1C1 1 + iω[R1C1 + (R1 + R2)C2] − ω2R1R2C1C2 . This form for ϕ(ω) becomes small for both small and large ω. 20.5.4. The transfer function describes the circuit functionality in the absence of loading, i.e., in the limit that negligible current ﬂows between the output terminals. For a second circuit element not to aﬀect the transfer function of the ﬁrst, it must not load the ﬁrst circuit. Here that means that the current through R2 must be much smaller than the current through R1; this can be assured if R2 ≫ R1. 20.6 Discrete Fourier Transform 20.6.1. The range of p and q for this problem, though not stated, is assumed to be integers satisfying 0 ≤ p, q < N . The second and third orthogonality equations as given in the text are CHAPTER 3. EXERCISE SOLUTIONS 344 incorrect. Corrected versions of these equations are:−1∑ k=0 cos( 2πpk N )cos( 2πqk N ) =  N, p = q = (0 or N/2) N/2, (p + q = N ) or p = q but not both 0, otherwise , N −1∑ k=0 sin ( 2πpk N ) sin ( 2πqk N ) =  N/2, p = q and p + q ̸= (0 or N ) −N/2, p ̸= q and p + q = N 0, otherwise . All these orthogonality equations depend upon the relationships N −1∑ k=0 cos ( 2πpk N ) = N −1∑ k=0 sin ( 2πpk N ) = 0 . The ﬁrst formula is valid for nonzero integers p that are not multiples of N ; the second is valid for all integral p. These relationships become obvious when identiﬁed as the real and imaginary parts of summations of the type discussed at Eq. (20.118). Alternatively, note that when plotted on a complex plane, sums of exp(2πipk/N ) form closed ﬁgures (N -sided regular polygons) and therefore their real and imaginary parts each evaluate to The ﬁrst summation can be written−1∑ k=0 cos( 2πpk N ) sin ( 2πqk N ) = 1 2 N −1∑ k=0 [ sin ( 2π[q+p]k N ) + sin ( 2π[q−p]k N )] . Both these sums vanish for all integral p and q. The second summation can be written−1∑ k=0 cos( 2πpk N ) cos( 2πqk N ) = 1 2 N −1∑ k=0 [cos( 2π[q+p]k N ) + cos( 2π[q−p]k N )] . The ﬁrst summation term on the right-hand side leads to a vanishing contribution unless q + p is zero or N ; in those cases all summands are unity and they together contribute N to the sum. The second summation term makes no contribution unless q = p, in which case it also contributes N to the sum. Thus, the combined contributions of these terms (including the premultiplier 1/2) yield the orthogonality relations, as corrected above. The third summation can be written−1∑ k=0 cos( 2πpk N ) cos( 2πqk N ) = 1 2 N −1∑ k=0 [cos( 2π[q−p]k N ) − cos( 2π[q+p]k N )] . CHAPTER 3. EXERCISE SOLUTIONS 345 A treatment similar to that of the second summation now leads to diﬀerent results than were obtained there because of the presence of a minus sign for the last summation term. The results correspond to the corrected orthogonality formula. 20.6.2. The formulas in this exercise are incorrect. They lack a factor N in the de- nominator of the exponent; the exponentials should read exp(±2πipk/N ). Multiply the formula given for Fp by e −2πipj/N , where j is an integer in the range 0 ≤ j < N , and then divide by N 1/2 and sum over p. Calling the result gj, we have gj = 1 N N −1∑ p=0 e −2πipj/N N −1∑ k=0 fk e 2πipk/N = 1 N N −1∑ k=0 fk N −1∑ p=0 e 2πip(k−j)/N . Using Eq. (20.120), the p summation reduces to N δkj, showing that the formula for gj reduces to fj. 20.6.3. (a) Write the formula for FN −p, and simplify its exponential by removing a factor unity in the form e 2πikN/N : FN −p = 1 N 1/2 N −1∑ k=0 fk e 2πik(N −p)/N = 1 N 1/2 N −1∑ k=0 fk e −2πikp/N . Because fk is real (so f ∗ k = fk), complex conjugation of FN −p changes the above expression only by changing the sign of the exponent, thereby yielding the standard expression for Fp. (b) Using the same expression for Fn−p as in the equation of part (a), com- plex conjugation still changes the sign of the exponent, but also replacesk by f ∗ k = −fk. Thus, F ∗ N −p = −Fp. 20.7 Laplace Transforms 20.7.1. If F (t) = ∞∑ n=0 ant n, then f (s) = ∞∑ n=0 an ∫ ∞ 0 e −sttndt = ∞∑ n=0 ann! sn+1 . Hence for s → ∞, sf (s) → a0, and for t → 0, F (t) → a0. 20.7.2. This problem is ill-deﬁned. 20.7.3. From Table 20.1, we ﬁnd s s2 + a2 − s s2 + b2 b2 − a2 = s (s2 + a2)(s2 + b2) . CHAPTER 3. EXERCISE SOLUTIONS 346 20.7.4. (a) The argument of L −1 has the partial-fraction expansion 1 (s + a)(s + b) = 1 b − a ( 1 s + a − 1 s + b ) . Each term of the above expansion can be identiﬁed as a transform cor- responding to Formula 4 of Table 20.1. Replacing each transform by its inverse leads to the answer in the text. (b) The argument of L −1 for this part has the partial-fraction expansion s (s + a)(s + b) = 1 a − b ( a s + a − b s + b ) , leading to the result in the text. 20.7.5. (a) Make a partial-fraction expansion of the argument of L −1. Do not further factor into quantities linear in s. The result, 1 (s2 + a2)(s2 + b2) = 1 b2 − a2 ( 1 s2 + a2 − 1 s2 + b2 ) , produces factors that correspond to Formula 9 of Table 20.1. (b) This argument of L −1 has partial-fraction expansion s 2 (s2 + a2)(s2 + b2) = 1 a2 − b2 ( a 2 s2 + a2 − b 2 s2 + b2 ) , with terms that also correspond to Formula 9 of Table 20.1. 20.7.6. The notational conventions of the text indicate that the two instances ofν − 1)! in this exercise should be written Γ(ν). The hint suggests writing s −ν as the transform integral s −ν = 1 Γ(ν) ∫ ∞ 0 e −tst ν−1 dt . (a) Use the above to form ∫ ∞ 0 cos s sν ds = 1 Γ(ν) ∫ ∞ 0 tν−1 dt ∫ ∞ 0 cos s e −ts ds = 1 Γ(ν) ∫ ∞ 0 tν−1 ( t t2 + 1 ) dt . We were able to perform the s integral because (in a diﬀerent notation than we usually use) it is the integral deﬁning the Laplace transform ofs. The remaining integral over t is shown at the end of this problem solution to have the value Iν = ∫ ∞ 0 tν t2 + 1 dt = π 2 cos(νπ/2) , CHAPTER 3. EXERCISE SOLUTIONS 347 Figure 20.7.6. Contour for Exercise 20.7.6. so the integral of part (a) evaluates to Iν/Γ(ν). This result agrees with the answer in the text. (b) This integral can be treated in a way similar to that of part (a). The only diﬀerence is that the integral containing sin s leads to an overall power tν−1 instead of tν. Therefore the ﬁnal result will be Iν−1/Γ(ν). Since cos([ν − 1]π/2) = sin(νπ/2), this result can be brought to the form given in the text. The restrictions on ν are needed as otherwise the integrals we were to evaluate would diverge. The integral Iν is most conveniently evaluated by contour integration, using the contour shown in Fig. 20.7.6. Segment A of the contour has contribution Iν, while segment B of the contour contributes −e 2πiνIν. The remainder of the contour makes no contribution to the contour integral. We therefore write Iν ( 1 − e 2πiν) = 2πi(sum of residues at t = ±i) = 2πi [ e πiν/2 2i + e 3πiν/2 −2i ] , which can be manipulated to Iνe πiν ( e −πiν − e πiν) = π eπiν (e πiν/2 − e πiν/2) , after which the exponentials can be identiﬁed as trigonometric functions. With use of the identity sin(πν) = 2 sin(πν/2) cos(πν/2), further simpliﬁ- cation leads to the result given above. CHAPTER 3. EXERCISE SOLUTIONS 348 20.7.7. Make a change of integration variable from t to u = ts in ∫ ∞ 0 e −stt n dt = s −n−1 ∫ ∞ 0 e −uun du . Since n ≥ 0, the power of s cannot exceed −1. L{δ(t)} = 1 = s 0, but this is not in conﬂict with our earlier demonstration because δ(t) does not have a power-series expansion. 20.7.8. Change the semicolon between arguments of M to a comma to be consis- tent with the notational conventions of the text and many reference works. Write the series expansion of M (a, c, x) and apply the Laplace transform operator to it termwise. L{M (a, c, x)} = ∞∑ n=0 (a)n (c)n n! L{x n} = ∞∑ n=0 (a)n n! (c)n n! 1 sn+1 . Since the n! in the numerator can be written (1)n, the summation contains the Pochhammer symbols needed for 2F1(a, 1; c; s −1). However, we need to append a factor 1/s to make the power of s correct. 20.8 Properties of Laplace Transforms 20.8.1. Use the fact that d2 dt2 cos kt = −k2 cos kt . Using the formula for the transform of a second derivative and taking the Laplace transform of both sides of this equation, L { d2 dt2 cos kt} = s 2L{cos kt} − s [ cos kt] t=0 − [ d dt cos kt] t=0 = s 2L{cos kt} − s = −k2L{cos kt} . Solving this equation, we get L{cos kt} = s s2 + k2 . 20.8.2. The solution is given in the text. 20.8.3. The solution is given in the text. 20.8.4. (a) N2(t) = ϕσ1N1(0) 1 − exp[−(λ2 + ϕσ2)t] λ2 + ϕσ2 . (b) N2(1 year) = 1.2 × 1015 atoms of Eu154. N1(1 year) = 10 20 − 1.2 × 1015 ≈ 1020 atoms. This justiﬁes the assumption N1(t) = N1(0). CHAPTER 3. EXERCISE SOLUTIONS 349 20.8.5. (a) NXe(t) = λIγIϕσf NU (λI − λXe − ϕσXe) + (λXe + ϕσXe)e −λIt − λIe −(λrmXe+ϕσXe)t λI(λXe + ϕσXe) (λI − λXe − ϕσXe) +γXeϕσf NU [ 1 − e −(λXe+ϕσXe)t λXe + ϕσXe ] . (b) NXe(∞) = (γI + γXe)ϕσf NU λXe + ϕσXe . (c) NXe(t) = NXe(0) e −λXet + NXe(0) λI λI − λXe (e −λXet − e −λIt), dNXe(t) dt ∣t=0 ≈ γIϕσf NU, for ϕ ≫ λXe/σXe. 20.8.6. (a) The solution is given in the text.X(t) = X0e −(b/2m)t { cosh σt + b 2mσ sinh σt}, where σ2 = b2 4m2 − k m . See Example 20.8.5. 20.8.7. (a) and (b) Solutions are given in the text.X(t) = v0 σ e −(b/2m)t sinh σt, σ2 = b2 4m2 − k m . 20.8.8. Take the Laplace transform of the equation of motion. ms 2x(s) = mg s − bsx(s) . Solve for x(s), x(s) = mg s2(ms + b) , and take the inverse transform: X(t) = mg b t − m 2g b2 (1 − e −bt/m) = m 2g b2 ( b m t − 1 + e −bt/m) . Diﬀerentiating, dX(t) dt = mg b (1 − e −(b/m)t) . 20.8.9. E(t) = − I0 ω1C e −t/2RC sin ω1t, ω2 1 = 1 LC − 1 (2RC)2 . This solution is based on the initial conditions E(0) = 0 (because the idealized inductance L would have zero DC impedance) and IL(0) = I0, limited by a resistance in series with the battery or by the internal resis- tance of the battery. Finally, to be consistent, q0 = 0. CHAPTER 3. EXERCISE SOLUTIONS 350 20.8.10. Start from Eq. (14.20), J0(t) = 1 2π ∫ 2π 0 e it cos θ dθ . form the Laplace transform, interchange the two integrations, and evaluate the integral over t: L{J0(t)} = 1 2π ∫ 2π 0 dθ ∫ ∞ 0 dt e−st+it cos θ = 1 2π ∫ 2π 0 dθ s − i cos θ . The integral over θ can be evaluated by writing it as a contour integral in the variable z = e iθ around the unit circle. Compare with Example 11.8.1. Using the result of that example, namely ∫ 2π 0 dθ 1 + a cos θ = 2π √1 − a2 , we obtain L{J0(t)} = 1 2πs ∫ 2π 0 dθ 1 − (i/s) cos θ = 1 2πs 2π √1 − (i/s)2 , which simpliﬁes to the required result. 20.8.11. Set L{Jn(t)} = gn(s). From Exercise 20.8.10, we have g0(s) = 1 √s2 + 1 . Using the formula J1 = −J ′ 0 of Eq. (14.9) and Eq. (20.147) to transform J ′ 0, we also have g1(s) = − [ s √s2 + 1 − 1 ] = √s2 + 1 − s √s2 + 1 . Next take the transform of the recurrence formula, Eq. (14.8): gn+1 = gn−1 − 2L{J ′ n} = gn−1 − 2sgn , n ≥ 1 , where we have used the formula for the transform of a derivative, Eq. (20.147), and restricted its use to n values for which Jn(0) = 0. Using the recurrence formula for n = 1, we get a result that can be simpliﬁed to g2(s) = ( √s2 + 1 − s)2 √s2 + 1 . The results for g0, g1, and g2 suggest the general formula gn(s) = ( √s2 + 1 − s)n √s2 + 1 . This suggestion can be conﬁrmed by mathematical induction; we already have conﬁrmed it for n = 0, 1, and 2. To conﬁrm it for general n we need only show it to be consistent with the recurrence formula. Substitution of the suggested form into the gn recurrence formula is found to lead to an algebraic identity. CHAPTER 3. EXERCISE SOLUTIONS 351 20.8.12. Setting I = ∫ ∞ 0 e −kzkJ1(ka) dk , we ﬁrst note that I = − d dz ∫ ∞ 0 e −kzK1(ka) dk = + d dz ∫ ∞ 0 e −kz d d(ka) [ J0(ka) ] dk . The last member of this equation was reached by the use of Eq. (14.9). We next integrate by parts and then simplify the result by inserting the value of the Laplace transform of J0 given in Table 20.1: I = 1 a d dz [e −kzJ0(ka)∣ ∞=0 + z ∫ ∞ 0 e −kzJ0(ka) dk] = 1 a d dz [1 + z (z2 + a2)1/2 ] . Evaluating the z derivative, we recover the answer in the text. 20.8.13. Since I0(at) = J0(iat), we may obtain its Laplace transform from the solution to Exercise 20.8.10 by application of Eq. (20.156), with a replaced by ia. We get L{J0(iat)} = 1 ia [( s ia )2 + 1 ]−1/2 = 1 √s2 − a2 . 20.8.14. (a) Use Eq. (20.184), the formula for the integral of a transform, taking(t) = sin at, and (from Table 20.1) f (s) = a/(s 2 + a2). L { sin at at } = 1 a L { sin at t } = 1 a ∫ ∞ s a ds s2 + a2 = 1 a ∫ ∞ s/a du u2 + 1 = 1 a [ π 2 − tan −1 ( s a )] = 1 a cot−1 ( s a ) . (b) The integral deﬁning the transform diverges at t = 0. (c) A procedure similar to that used in part (a) leads to L { sinh at at } = ∫ ∞ s ds s2 − a2 . Make the partial fraction decomposition 1 s2 − a2 = 1 2a [ 1 s − a − 1 s + a ] . Although the insertion of this expression creates two divergent integrals, their divergences (at s = ∞) cancel, and we get L { sinh at at } = 1 2 [ − ln(s − a) + ln(s + a)] , CHAPTER 3. EXERCISE SOLUTIONS 352 equivalent to the answer in the text. (d) The integral deﬁning the transform diverges at t = 0. 20.8.15. Let f (s) denote the Laplace transform of F (t). To deal with the transform of the Laguerre ODE, we need the following transforms, which involve the use of Eqs. (20.147), (20.148), and (20.174). L{F ′(t)} = s f (s) − F (0) , L{t F ′(t)} = − d ds L{F ′(t)} = −f (s) − s f ′(s) , L{F ′′(t)} = s 2f (s) − sF (0) − F ′(0) , L{t F ′′(t)} = − d ds L{F ′′(t)} = −2s f (s) − s 2f ′(s) + F (0) . Combining these to form the transform of the Laguerre equation,tF ′′(t) + F ′(t) − tF ′(t) + nF (t)} = s(1 − s)f ′(s) + (n − s + 1)f (s) = 0 . This is a separable homogeneous ﬁrst-order ODE, which can be written, using a partial fraction decomposition, as df f = − ( n − s + 1 s(1 − s) ) ds = − ( n 1 − s + n + 1 s ) ds . Integrating the ODE, and taking the antilogarithm of the solution, we reach after a few steps f (s) = C s (1 − 1 s )n . Checking this solution for n = 0 (with C = 1), we have f (s) = s −1, corresponding to F0(t) = 1, the correct value of L0(t). Continuing to n = 1, we have f (s) = s −1 − s −2, corresponding to F1(t) = 1 − t, the correct value of L1(t). 20.8.16. Here is a proof using mathematical induction. Writing gn(s) = L{Ln(at)}, we ﬁnd by direct evaluation (use Table 20.1 if necessary) g0(s) = L{1} = 1 s , g1(s) = L{1 − at} = 1 s − a s2 = s − a s2 , thereby establishing the formula of this exercise for n = 0 and n = 1. We now show that for n ≥ 1 the value of gn+1 is consistent with the Laguerre polynomial recurrence formula, Eq. (18.51), using the assumed formulasgn and gn−1. Taking the Laplace transform of that equation, we get (n + 1)gn+1(s) = (2n + 1)gn(s) − ngn−1(s) + L{(−at)Ln(at)} . CHAPTER 3. EXERCISE SOLUTIONS 353 The transform of −tLn(at) can be computed using Eq. (20.174) and the assumed form of gn. We get L{(−at)Ln(at)} = a g′ n = a [ n(s − a) n−1 sn+1 − (n + 1)(s − a) n sn+2 ] . Substituting the assumed forms for all the quantities on the right-hand side of the recurrence formula and simplifying, we conﬁrm that gn+1 also has the assumed form, thereby completing the proof. 20.8.17. Form the Laplace transform, interchange the two integrations, and evalu- ate the integral over t: L{E1(t)} = ∫ ∞ 1 dx ∫ ∞ 0 dt e −xt−ts x = ∫ ∞ 1 dx x(x + s) . Make a partial fraction decomposition of the x integrand; this results in integrals that are individually divergent at large x but with a diﬀerence that is a ﬁnite limit. Thus, L{E1(t)} = lim R→∞ ∫ R 1 1 s [ 1 x − 1 x + s ] dx = 1 s lim R→∞ [ ln R − ln(R + s) + ln(s + 1)] = 1 s ln(s + 1) , because ln R − ln(R + s) = − ln (1 + s R ) = − s R + · · · −→ 0. 20.8.18. (a) This is the case s = 0 of Eq. (20.184). (b) Taking F (t) = sin t, then, from Table 20.1, f (s) = 1/(s 2 + 1), and the formula of this exercise indicates that ∫ ∞ 0 F (t) t dt = ∫ ∞ 0 sin t t dt = ∫ ∞ 0 f (s) ds = ∫ ∞ 0 ds s2 + 1 ds = π 2 . 20.8.19. (a) See Exercise 20.8.14(a). (b) Write si(x) = − ∫ ∞ t sin x x dx = − π 2 + ∫ t 0 sin x x dx . Take the Laplace transform of both sides of this equation, using Formula 3 of Table 20.2 and the result of part (a) for the transform of the integral. We get L{si(t)} = − π 2s + 1 s cot−1 s = − 1 s tan −1(s) . CHAPTER 3. EXERCISE SOLUTIONS 354 20.8.20. Taking note of the periodicity of F (t), we have L{F (t)} = ∫ ∞ 0 e −stF (t, dt = ∞∑ n=0 ∫ (n+1)a na e −stF (t) dt = ∞∑ n=0 e −nas ∫ a 0 e −stF (t) dt . Performing the summation, L{F (t)} = 1 1 − e−as ∫ a 0 e −stF (t) dt . 20.8.21. The solution is given in the text. 20.8.22. (a) Writing cosh at = cos(−iat), using cos at cos(−iat) = cos(1 − i)at + cos(1 + i)at 2 and noting that (1 + i) 2 = 2i, (1 − i) 2 = −2i, we can use the formula for the transform of cos kt to obtain L{cosh at cos at} = 1 2 [ s s2 + (1 − i)2a2 + s s2 + (1 + i)2a2 ] = 1 2 [ s s2 − 2ia2 + s s2 + 2ia2 ] , which simpliﬁes to the formula given in the text. (b) Use an approach similar to that of part (a), but here sin at cos(−iat) = sin(1 − i)at + sin(1 + i)at 2 . Using the transform of sin kt, we now have L{cosh at sin at} = 1 2 [ (1 − i)a s2 + (1 − i)2a2 + (1 + i)a s2 + (1 + i)2a2 ] , which simpliﬁes to the result given in the text. Parts (c) and (d) are handled in ways similar to those used for parts (a) and (b). 20.8.23. The formulas of this exercise can be obtained by evaluating the trans- forms on their right-hand sides. Terms of the forms sin at or cos at have transforms given in Table 20.1; terms of the forms t sin at or t cos at can CHAPTER 3. EXERCISE SOLUTIONS 355 be obtained from the sine and cosine transforms by diﬀerentiating them (see Formula 7, Table 20.2): L{t sin at} = 2as (s2 + a2)2 , L{t cos at} = s 2 − a 2 (s2 + a2)2 . The evaluations are straightforward. 20.8.24. Start from the integral representation of K0(z) obtained by specializing Eq. (14.128): K0(z) = ∫ ∞ 1 e −zx (x2 − 1)1/2 dx . In the above, change z to ks and change the integration variable to t = kx. Our integral representation then becomes K0(ks) = ∫ ∞ k e −st (t2 − k2)1/2 dt . This equation becomes equivalent to that in the text if we introduce a unit step function that permits our changing the lower integration limit to zero. 20.9 Laplace Convolution Theorem 20.9.1. Apply the Laplace convolution theorem with F (t), f (s), G(t) = 1, and g(s) = 1/s: f (s)g(s) = f (s) s = L{G ∗ F } , where G ∗ F = ∫ t 0 G(t − z)F (z) dz = ∫ t 0 F (z) dz . 20.9.2. (a) Write the formula for F ∗ G, then move a factor t a+b+1 outside the integral and change the integration variable to z/t: F ∗ G = ∫ t 0 F (t − z)G(z) dz = ∫ t 0 (t − z) azb dz = ta+b+1 ∫ t 0 (1 − z t )a ( z t )b d ( z t ) = ta+b+1 ∫ 1 0 (1 − y) a yb dy , equivalent to the answer in the text. (b) The functions F and G have the respective Laplace transforms f (s) = Γ(a + 1) sa+1 , g(s) = Γ(b + 1) sb+1 . CHAPTER 3. EXERCISE SOLUTIONS 356 We next form their product and identify it by inspection as a transform: f (s)g(s) = Γ(a + 1)Γ(b + 1) sa+b+2 = L { Γ(a + 1)Γ(b + 1)ta+b+1 Γ(a + b + 2) } . Finally, we take the inverse transform of f (s)g(s) and equate it to the convolution F ∗ G; the result is L −1{f (s)g(s)} = Γ(a + 1)Γ(b + 1)ta+b+1 Γ(a + b + 2) = ta+b+1 ∫ 1 0 (1 − y)a yb dy . This equation is equivalent to the relationship to be proved. 20.9.3. The two factors in the transform product and their respective inverse transforms are f (s) = s s2 + a2 , F (t) = cos at, g(s) = 1 s2 + b2 , G(t) = sin bt b . We now apply the convolution theorem: L −1{f (s)g(s)} = ∫ t 0 F (t − z)G(z) dz = 1 b ∫ t 0 cos a(t − z) sin bz dz . Using a trigonometric identity, this becomes L −1{f (s)g(s)} = 1 2b ∫ t 0 [sin(at − az + bz) − sin(at − az − bz)] dz = [ 1 2b(a − b) cos(at − az + bz) − 1 2b(a + b) (cos at − az − bz) ] t =0 = cos bt − cos at a2 − b2 , equivalent to a result found by other methods in Exercise 20.7.3. 20.9.4. The solution is given in the text. 20.10 Inverse Laplace Transform 20.10.1. Application of L −1 to the integral representation of f (s) can be moved into the integral over z, where it converts (s − z) −1 into e zt, thereby producing the Bromwich formula. 20.10.2. Make the insertion suggested in the problem statement, and interchange the order of the two integrations: 1 2πi ∫ β+i∞ β−i∞ e stf (s) ds = ∫ ∞ 0 F (z) dz 1 2πi ∫ β+i∞ β−i∞ e s(t−z) ds . CHAPTER 3. EXERCISE SOLUTIONS 357 Next make the substitution s = β + iu, with ds = idu; the s integral is thereby changed to ∫ β+i∞ β−i∞ e s(t−z) ds = e β(t−z) ∫ ∞ −∞ e iu(t−z) i du = 2πi e β(t−z)δ(t − z) = 2πi δ(t − z) . We have identiﬁed the u integral as the delta function representation in Eq. (20.20). Use of this delta-function formula brings us to ∫ β+i∞ β−i∞ e s(t−z) ds = ∫ ∞ 0 F (z) δ(t − z) dz = F (t) , which is the Bromwich integral for the inverse Laplace transform. 20.10.3. Let f1(s) And f2(s) be the respective Laplace transforms of F1(t) and F2(t), and use the Bromwich integral for the inverse transform of the product f1(s)f2(s): L −1{f1(s)f2(s)}(t) = 1 2πi ∫ β+i∞ β−i∞ e tsf1(s)f2(s) ds = 1 2πi ∫ β+i∞ β−i∞ e ts ds ∫ ∞ 0 e −xsF1(x) dx ∫ ∞ 0 e −ysF2(y) dy . Collect the factors that depend upon s, move the s integral to the right of the other integrations, and make a change of variable to u, with s = β +iu, so the s integral becomes, with the aid of Eq. (20.20), ∫ β+i∞ β−i∞ e (t−x−y)s ds = e β(t−x−y) ∫ ∞ −∞ e iu(t−x−y) i du = 2πiδ(t − x − y) . Using this delta-function integral, we now have L −1{f1(s)f2(s)}(t) = ∫ ∞ 0 F1(x) dx ∫ ∞ 0 F2(y)δ(t − x − y) dy = ∫ ∞ 0 F1(x)F2(t − x) dx , which is the Laplace convolution theorem. 20.10.4. (a) The partial fraction expansion required here is s s2 − k2 = 1 2 [ 1 s − k + 1 s + k ] . CHAPTER 3. EXERCISE SOLUTIONS 358 Using Table 20.1 to invert the individual terms of this expansion, L −1 { s s2 − k2 } = 1 2 (e kt + e −kt) = cosh kt. (b) Starting from the Bromwich integral L −1 { s s2 − k2 } = 1 2πi ∫ γ+i∞ γ−i∞ se st s2 − k2 ds , close the contour with a counterclockwise arc at inﬁnite s that does not contribute to the integral. The contour then encloses simple poles at s = k and s = −k, with respective residues e kt/2 and e −kt/2, leading to the same result as in part (a). 20.10.5. (a) The partial fraction expansion required here is k2 s(s2 + k2) = 1 s − s s2 + k2 . Using Table 20.1, this can be identiﬁed as the transform of 1 − cos kt. (b) We seek L −1{f (s)g(s)}, where f (s) = 1/x and g(s) = k2/(s 2 + k2) are the transforms of F (t) = 1 and G(t) = k sin kt. Using the convolution theorem, L −1{f (s)g(s)} = F ∗ G = ∫ t 0 k sin kz dz = − cos kz∣ t , which evaluates to the desired result. (c) Form the Bromwich integral, noting that its vertical path in the com- plex plane must fall to the right of all singularities in the integrand, which are ar s = 0 and s = ±ik. We can close the contour of the integral with an arc at inﬁnity in the left half-plane, so we have F (t) = (L) { k2 s(s2 + k2) } = 1 2πi ∮ k2e st ds s(s − ik)(s + ik) , where the contour surrounds the three singularities of s. Applying the residue theorem, F (t) = ∑ (residues) = k2e 0 (−ik)(ik) + k2e ikt (ik)(2ik) + k2e −ikt (−ik)(−2ik) , which simpliﬁes to the required result. 20.10.6. Close the contour for the Bromwich integral as shown in Fig. 20.23 of the text. The contour encloses no singularities, and neither the large nor the small circular arc makes a contribution to the contour integral. However, CHAPTER 3. EXERCISE SOLUTIONS 359 the two horizontal segments above and below the branch cut are nonzero and do not cancel; in fact, because the branch point at s = 0 is of order two, the sum of the contribution of these segments is two times the contribution of either one. Taking the segment below the branch cut, s there has the value re −iπ, ds = −dr, e ts = e −tr, s −1/2 = r−1/2e +iπ/2 = ir−1/2, the integration is from r = 0 to r = ∞, and L −1{s −1/2} = −2 ( 1 2πi ) ∫ ∞ 0 (ir−1/2)e −tr(−dr) = 1 π ∫ ∞ 0 r−1/2e −tr dr = 1 πt1/2 Γ(1/2) = 1 (πt)1/2 . 20.10.7. As indicated by Fig. 20.24 in the text, the Bromwich integral F (t) for this problem is equal to a contour integral (in the mathematically positive di- rection) along a closed path that is adjacent to the singular points and the vertical branch cut that connects them. In the right-hand vertical segment of this closed path, the integrand must (by continuous deformation of the Bromwich integrand) be on the branch for which √1 + s2 is positive; on the other side of the branch cut, this quantity will be negative. Since the circular arcs at ±i do not contribute to the contour integral, its value must be F (t) = 2 [ 1 2πi ∫ i −i e st √1 + s2 ds ] . Now set s = iy, so ds = idy, leading to F (t) = 1 πi ∫ 1 −1 e iyt √ 1 − y2 i dy = 1 π ∫ 1 0 e iyt + e −iyt √1 − y2 dy = 2 π ∫ 1 0 cos yt √1 − y2 dy . This is an integral representation of J0(t). See the solution to Exercise 20.2.10. 20.10.8. (a) Carry out a binomial expansion on f (s) = (s 2 − a 2) −1/2, then invert termwise to obtain F (t). f (s) = 1 s ( 1 − a2 s2 )−1/2 = ∞∑ n=0 ( −1/2 n ) (−1) n a 2n s2n+1 , and, using Table 20.1 to identify the inversions, F (t) = ∞∑ n=0 ( −1/2 n ) (−1) n a 2nt2n (2n)! . Inserting ( −1/2 n ) = (−1)n(2n − 1)!! 2n n! , F (t) = ∞∑ n=0 (2n − 1)!! a2nt2n 2n n! (2n)! = ∞∑ n=0 1 n! n! ( at 2 )2n = I0(at) . CHAPTER 3. EXERCISE SOLUTIONS 360 Figure 20.10.8. Contour for Exercise 20.10.8. (b) The Bromwich integral for this problem is equal to a closed contour integral of the form I = 1 2πi ∮ e tz dz (z − a)1/2(z + a)1/2 , where the contour, shown in Fig. 20.10.8, surrounds a branch cut thatz = −a and z = a. When z = x + iy is on the real axis, with x > a, we are on the branch of the integrand for which both (x + a)1/2 and (x − a) 1/2 are real and positive (i.e., have zero arguments). Above the branch cut but to the right of x = −a, (x + a) 1/2 remains positive, but (x − a) 1/2 becomes +i(a − x) 1/2. Below the branch cut, (x + a) 1/2 is still positive, but (x − a) 1/2 = −i(a − x) 1/2. When all this is taken into account and we note (1) that these square roots occur in the denominator of the integrand and (2) the direction of the integration path, we ﬁnd I = 1 2πi 2 ∫ a −a ie tx dx √a2 − x2 = 1 π ∫ a 0 (e tx + e −tx) √a2 − x2 dx = 2 π ∫ a 0 cosh tx √a2 − x2 dx . Changing the integration variable to u = x/a, we bring I to the form I = 2 π ∫ 1 0 cosh atu √1 − u2 du , which is an integral representation of I0(at). (c) In the new variable z, the points z = β ± i ∞ correspond to s = aβ/2 ± i ∞, ds = (a/2)(1 − z−2) dz, and (s 2 − a 2)1/2 = (a/2)(z − z−1). The Bromwich integral for this problem can therefore be written F (t) = 1 2πi ∫ β′+i∞ β′−i∞ e (a/2)(z+1/z)t (a/2)(z − 1/z) a 2 (1 − z−2) dz = 1 2πi ∫ β′+i∞ β′−i∞ e (a/2)(z+1/z)t z dz . We may close the contour in z by an arc at large |z| in the left half- plane, thereby creating a closed contour containing as its only singularity CHAPTER 3. EXERCISE SOLUTIONS 361 a simple pole at z = 0. F (t) will be the residue at this singularity. To obtain it, write e (a/2)(z+1/z)t = e azt/2e at/2z = ∞∑ n=0 (azt/2)n n! ∞∑ m=0 (at/2z) m m! . The coeﬃcient of z0, which is the residue we seek, is the contribution to the above expression from terms for which m = n. Therefore, F (t) = residue = ∞∑ n=0 (at/2) 2n n! n! = I0(at) . 20.10.9. Start from Eqs. (12.79) and (12.80), E1(t) = ∫ ∞ 1 e −ty y dy = −γ − ln t − ∞∑ n=1 (−1) ntn n n! . Our task is to show that L{−γ − ln t} = L { E1(t) + ∞∑ n=1 (−1) ntn n n! } = L{E1(t)} + ∞∑ n=1 (−1)n n sn+1 = ln s s . We have taken the transform of the power series termwise, using a formula from Table 20.1. Now form the transform of E1(t) using its integral representation and interchange the two integrations:E1(t)} = ∫ ∞ 0 dt e−ts∫ ∞ 1 e −ty y dy = ∫ ∞ 1 dy y ∫ ∞ 0 e −t(s+y) dt = ∫ ∞ 1 dy y(y + s) . Apply a partial fraction decomposition to the y integral; this produces two integrals that are individually divergent, but the divergences cancel. We get L{E1(t)} = 1 s ∫ ∞ 1 [ 1 y − 1 y + s ] dy = 1 s ∫ s+1 1 dy y = ln(s + 1) s . For our present purposes we write this result as an expansion: L{E1(t)} = ln(s + 1) s = ln s s + 1 s ln ( 1 + 1 s ) = ln s s − ∞∑ n=1 (−1) n n sn+1 . Inserting this result into the equation for L{−γ − ln t}, we ﬁnd that the summations in inverse powers of s cancel, leaving the desired result. CHAPTER 3. EXERCISE SOLUTIONS 362 20.10.10. The Bromwich integral can be converted without changing its value into a closed contour integral with an arc at inﬁnity encircling the left half-plane. L −1{f (s)} = 1 2πi ∮ se st (s2 + a2)2 ds , where the contour encloses the singularities of e stf (s), which consist of two second-order poles at the points s = ia and s = −ia. Applying the residue theorem, L −1{f (s)} = d ds [ se st (s + ia)2 ] s=ia + d ds [ se st (s − ia)2 ] s=−ia = e iat [ 1 + iat −4a2 − 2ia (−4a2)(2ia) ] + e −iat [ 1 − iat −4a2 − −2ia (−4a2)(−2ia) ] . The above expression simpliﬁes to L −1{f (s)} = t 2a sin at. 20.10.11. The Bromwich integral is converted without changing its value into a closed contour integral with an arc at inﬁnity encircling the left half-plane. Applying the residue theorem, noting that there are simple poles at thesi of h(s), we get F (t) = 1 2πi ∫ γ+i∞ γ−i∞ e stg(s) h(s) ds = ∑ i g(si) h′(si) e sit . 20.10.12. The Bromwich integral for this problem, L{s −2e −ks} = 1 2πi ∫ β+∞i β−∞i e s(t−k) s2 ds , yields the value zero if t < k, as under that condition its contour can be closed by an arc to the right at large |s| and the contour then includes no singularities. If t > k, the contour can be closed by an arc to the left at large |s|, enclosing a second-order pole at s = 0 with residue t − k (an easy way to obtain the residue is to look at the linear term when the exponential is expanded in a power series). Thus, L{s −2e −ks} = { 0, t < k, t − k, t > k . Both these cases can be incorporated into a single formula by appending a unit step function that is zero for t < k and unity for t > k. 20.10.13. (a) Use the partial fraction identity 1 (s + a)(s + b) = 1 b − a ( 1 s + a − 1 s + b ) . CHAPTER 3. EXERCISE SOLUTIONS 363 Then invert by inspection, using entry 4 of Table 20.1: F (t) = e −bt − e −at a − b . (b) Recognize f (s) = (s + a) −1 and g(s) = (s + b)−1 as the transforms of F (t) = e −at and G(t) = e −bt. The product f (s)g(s) is the transform of the convolution F ∗ G, so this convolution is the inverse transform we seek. Evaluating it, F ∗ G = ∫ t 0 e −a(t−z)−bz dz = e −at e (a−b)z a − b ∣ t = e −bt − e −at a − b . (c) Using Exercise 20.10.11, 1 2πi ∫ γ+i∞ γ−i∞ e st (s + a)(s + b) ds = e −at −a + b + e −bt −b + a . CHAPTER 3. EXERCISE SOLUTIONS 364 21. Integral Equations 21.1 Introduction 21.1.1. (a) Integrate y′′ = y from x = 0 to x = x and set y′(0) = 1: ∫ x 0 y′′(x) dx = y′(x) − y′(0) = ∫ x 0 y(t) dt −→ y′(x) = 1 + ∫ x 0 y(t) dt . Integrate again from 0 to x, setting y(0) = 0: y(x) − y(0) = y(x) = ∫ x 0 du + ∫ x 0 du ∫ u 0 y(t) dt = x + ∫ x 0 dt y(t) ∫ x t du = x + ∫ x 0 (x − t) y(t) dt . (b) Same ODE, but with y′(0) = −1 and y(0) = 1. The ﬁrst integration yields y′(x) = −1 + ∫ x 0 y(t) dt . Integrating again, y(x) − 1 = −x + ∫ x 0 du ∫ u 0 y(t) t = −x + ∫ x 0 dt y(t) ∫ x t du = −x + ∫ x 0 (x − t) y(t) dt . This rearranges into the answer in the text. 21.1.2. (a) From the integral equation, y(x) = ∫ x 0 (x − t)y(t) dt + x, we see that y(0) = 0. Diﬀerentiating, y′(x) = ∫ x 0 y(t) dt + 1 , also showing that y′(0) = 1. Diﬀerentiating again, y′′(x) = y(x) . (b) The integral equation, y(x) = ∫ x 0 (x − t)y(t) dt − x + 1, shows that y(0) = 1. Diﬀerentiating, y′(x) = ∫ x 0 y(t) dt − 1 and y′′(x) = y(x) . The ﬁrst of these equations also shows that y′(0) = −1. CHAPTER 3. EXERCISE SOLUTIONS 365 21.1.3. ϕ(x) = sinh x. 21.2 Some Special Methods 21.2.1. Letting F (t), K(t), and Φ(t) be the Fourier transforms of f (x), k(x), and ϕ(x), the integral equation becomes Φ(t) = F (t) + λ√2π K(t)Φ(t) , where we have used the fact that the integral is of the form of a convolu- tion. Solving for Φ(t), we get Φ(t) = F (t) 1 − λ√2π K(t) . We now take the inverse Fourier transform to reach ϕ(x) = 1 √2π ∫ ∞ −∞ F (t) e −ixt dt 1 − λ√2π K(t) . 21.2.2. (a) Take the Laplace transform of this integral equation, with F (s), K(s), and Φ(s) the transforms of f (x), k(x), and ϕ(x). We get F (s) = K(s)Φ(s) , where we have identiﬁed the integral as a convolution. Solving for Φ(s) and using the Bromwich formula for the inverse transform, ϕ(x) = 1 2πi ∫ λ+i∞ λ−i∞ F (s) K(s) e xs dx . (b) Take the Laplace transform of this integral equation, with F (s), K(s), and Φ(s) the transforms of f (x), k(x), and ϕ(x). We get Φ(s) = F (s) + λK(s)Φ(s) , where we have identiﬁed the integral as a convolution. Solving for Φ(s) and using the Bromwich formula for the inverse transform, ϕ(x) = 1 2πi ∫ λ+i∞ λ−i∞ F (s) 1 − λK(s) e xs ds . 21.2.3. (a) The integral in this equation is of the form of a convolution; since the general form of a Laplace transform convolution is ∫ x 0 f (x − t)ϕ(t) dt , CHAPTER 3. EXERCISE SOLUTIONS 366 we note that f (x) = −x and its transform F (s) is −1/s 2. Since the Laplace transform of x is 1/s 2, the integral equation transforms to Φ(s) = 1 s2 − Φ(s) s2 , so Φ(s) = s −2 1 + s−2 = 1 s2 + 1 . From a table of Lasplace transforms, Φ(s) is identiﬁed as the transform of sin x. (b) A treatment similar to that of part (a) yields Φ(s) = 1 s2 − 1 . This is the Laplace transform of sinh x. 21.2.4. The convolution formula for the Fourier cosine transform can be written in the form 1 2 ∫ ∞ −∞ g(y)f (x − y) dy = ∫ ∞ 0 Fc(s)Gc(s) cos xs ds , where the subscript c denotes the cosine transform and it is assumed that f and g are even functions of their arguments. Consider the integral equation f (x) = ∫ ∞ −∞ k(x − y)ϕ(y) dy , where k(x−y), f (x), and ϕ(y) are assumed to be even functions. Applying the convolution formula, f (x) = 2 ∫ ∞ 0 Kc(s)Φc(s) cos xs ds , and then taking the cosine transform, we reach Fc(ω) = 2√ π 2 Kc(ω)Φc(ω) . Solving for Φ: Φ(ω) = Fc(ω) √2π Kc(ω) , Taking the inverse transform, ϕ(x) = √ 2 π ∫ ∞ 0 Fc(ω) √2π Kc(ω) cos xω dω = 1 π ∫ ∞ 0 Fc(ω) Kc(ω) cos xω dω . 21.2.5. ϕ(t) = δ(t). 21.2.6. Following the procedure suggested for this problem, ∫ z 0 f (x)(z − x) α−1 dx = ∫ z 0 dx ∫ x 0 (z − x)α−1 (x − t)α ϕ(t) dt = ∫ z 0 ϕ(t) dt ∫ z t dx (z − x)1−α(x − t)α = π sin πα ∫ z 0 ϕ(t) dt . CHAPTER 3. EXERCISE SOLUTIONS 367 This last integral over x was evaluated using the formula given in the Note attached to this problem. We next need to diﬀerentiate the ﬁrst and last members of the above equation with respect to z to obtain an explicit formula for ϕ. The left- hand member becomes an indeterminate form when diﬀerentiated; the indeterminacy can be resolved by ﬁrst carrying out an integration by parts: ∫ z 0 f (x)(z − x) α−1 dx = f (0) α zα + 1 α ∫ z 0 f ′(x)(z − x) α dz . Now we diﬀerentiate with respect to z, obtaining ϕ(z) = sin πα π [f (0)zα−1 + ∫ z 0 f ′(x)(z − x) α−1 dx] . 21.2.7. Using the solution to Exercise 21.2.6, we have f (0) = 1, f ′(x) = 0, so ϕ(z) has the value that was given. The solution can be checked by inserting ϕ into the integral equation. The resulting integral is elementary. 21.2.8. Use the generating function formula for the Hermite polynomials to iden- e −(x−t)2 = e −t 2 ∞∑ n=0 Hn(t)xn n! . Also write the Maclaurin expansion of f (x), so our Fredholm equation takes the form ∞∑ n=0 f (n)(0) x n n! = ∞∑ n=0 x n n! ∫ ∞ −∞ e −t 2Hn(t)ϕ(t) dt , equivalent to the set of formulas (for n = 0, 1, · · · ) f (n)(0) = ∫ ∞ −∞ e −t 2Hn(t) ϕ(t) dt . We now recognize the integral over t as proportional to the coeﬃcient an in the Hermite polynomial expansion of ϕ: ϕ(x) = ∞∑ n=0 anHn(x) , an = 1 2n n! π1/2 ∫ ∞ −∞ e −t 2 Hn(t) ϕ(t) dt . In terms of f (n)(0), this is ϕ(x) = 1 √π ∞∑ n=0 f (n)(0) 2n n! Hn(x) . CHAPTER 3. EXERCISE SOLUTIONS 368 21.2.9. The denominator in the integral equation corresponds to the generating function for the Legendre polynomials; introducing that expansion, f (x) = ∞∑ n=0 [∫ 1 −1 Pn(t)ϕ(t) dt] x n . Inserting the Legendre polynomial expansion ϕ(t) = ∑ n anPn(t), we have f (x) = ∞∑ n=0 2 an 2n + 1 x n . Proceeding now to the cases at hand, (a) If f (x) = x2s, all an except a2s vanish, and 1 = 2 a2s 2(2s) + 1 , or a2s = 4s + 1 2 . This in turn means that ϕ(x) = 4s + 1 2 P2s(x). (b) This case is similar, but with 2s replaced by 2s + 1. The ﬁnal result is ϕ(x) = 4s + 3 2 P2s+1(x). 21.2.10. λ1 = i √3/2, ϕ1(x) = 1 − i √3x. λ2 = −i √3/2, ϕ2(x) = 1 + i √3x. 21.2.11. This integral equation has a separable kernel; write cos(x−t) = cos x cos t+ sin x sin t, so the right-hand side of the equation must be a linear combi- nation of sin x and cos x. Inserting ϕ(t) = A cos t + B sin t and evaluating the integral, it becomes π(A cos x + B sin x), so the integral equation is satiﬁed for arbitrary A and B with λ = 1/π. 21.2.12. λ1 = −3/4, y1(x) = x = P1(x). λ2 = −15 + 9 √5 8 , y2(x) = P0(x) + 4 3 λ2P2(x). λ3 = −15 − 9√5 8 , y3(x) = P0(x) + 4 3 λ3P2(x). 21.2.13. We note that ψ(x) must be proportional to cos x. But then the t integral has sin t cos t as its integrand. But sin t is symmetric about π/2, while cos t is antisymmetric; the integral vanishes, forcing ψ(x) = 0. 21.2.14. λ1 = 0.7889, ϕ1 = 1 + 0.5352 x, λ2 = 15.21, ϕ2 = 1 − 1.8685 x (λ1 = 8 − √52, λ2 = 8 + √52). CHAPTER 3. EXERCISE SOLUTIONS 369 21.2.15. λ1 = 0.7889, ϕ1(x) = 1 + 0.5352 x, λ2 = 15.21, ϕ2(x) = 1 − 1.8685 x. 21.2.16. (a) Inserting the expansion of the kernel into the integral, we ﬁnd that it can be written n∑ i=1 Mi(x) ∫ b a Ni(t)ϕ(t) dt = n∑ i=1 Mi(x)Ci , where Ci is the (presently unknown) constant value of the t integral. We therefore have an inconsistency unless f (x) is a linear combination of only the functions Mi(x). (b) The condition that ψ(x) be orthogonal to all Ni(x) causes its addition to a solution not to aﬀect the value of the integral; of course, any function(x) to be added must also be a linear combination of the Mi(x). 21.3 Neumann Series 21.3.1. (a) Solution is given in the text.ϕ(x) = sin x. (c) ϕ(x) = sinh x. 21.3.2. ψ(x) = −2. 21.3.3. (a) Directly from the integral equation, ϕ(0) = 1. Diﬀerentiating, ϕ ′(x) = λ2 ∫ x 0 ϕ(t) dt , from which we deduce ϕ′(0) = 0. Diﬀerentiating again, ϕ ′′(x) = λ2ϕ(x) . This ODE has general solution ϕ = A sinh λx + B cosh λx; the boundary conditions require A = 0, B = 1. (b) The Neumann series for this problem is ϕ(x) = 1+λ2 ∫ x 0 (x−x1) dx1+λ2 ∫ x 0 (x−x2) dx2λ2 ∫ x1 0 (x2−x1) dx1+· · · +λ2 ∫ x 0 (x−xn) dxnλ ∫ xn 0 (xn−xn−1 dxn−1 · · ·+λ2 ∫ x2 0 (x2−x1) dx1+· · · . We can ﬁnd the iterated integral through xn by mathematical induction. By inspection we guess that its value will be (λx)2n/(2n)!. Assuming this CHAPTER 3. EXERCISE SOLUTIONS 370 to be correct for the integral through xn−1, the integral through xn will be λ2 ∫ x 0 (x − xn) (λxn) 2n−2 (2n − 2)! dxn = λ2n ∫ x 0 (x x 2n−2 n − x 2n−1 n ) (2n − 2)! dxn = λ2n [ 1 2n − 1 + 1 2n ] x2n (2n − 2)! = (λx) 2n (2n)! . To complete the proof we note that the general result applies for n = 1. This is the series expansion of cosh λx. (c) Taking Laplace transforms of the individual terms of the integral equa- tion, noting that the integral is a convolution in which x−t corresponds to f (y) for y = x − t and that the transform of f is 1/s 2, and also observing that the transform of unity is 1/s: Φ(s) = 1 s + λ2 Φ(s) s2 . Solving for Φ, we ﬁnd Φ(s) = 1/s 1 − λ2/s2 = s s2 − λ2 . This is the transform of cosh λx. 21.3.4. Assume U (t, t0) = U (t−t0), since the result is expected to be independent of the zero from which t is measured. Then assume that U can be expanded in a power series U (t − t0) = ∞∑ n=0 cn(t − t0) n . Setting V (t1) = V0 and inserting the expansion of U (t1 − t0), we get ∞∑ n=0 cn(t−t0)n = 1− iV0 ℏ ∞∑ n=0 cn ∫ t t0 (t−t0)n dt = 1− iV0 ℏ ∞∑ n=0 cn(t − t0) n+1 n + 1 . Equating equal powers of t − t0 in the ﬁrst and last members of this equation, we ﬁnd c0 = 1, cn+1 = − iV0 ℏ cn (n + 1) , n = 0, 1, · · · . This recurrence formula can be solved: cn = 1 n! (− iV0 ℏ )n . These are the coeﬃcients in the expansion of exp [− i ℏ (t − t0)V0 ]. CHAPTER 3. EXERCISE SOLUTIONS 371 21.4 Hilbert-Schmidt Theory 21.4.1. Let ϕn(x) be an eigenfunction with eigenvalue λn. Multiply the Fredholm equation for ϕn(x) by ϕ∗ (x) and integrate: ∫ ϕ ∗ (x)ϕn(x) dx = λn ∫ b a dx ∫ b a dt ϕ∗ (x)K(x, t)ϕn(t) = λn λ∗ ∫ b a dt [ λ∗ ∫ b a K ∗(t, x)ϕ∗ (x) dx ] ϕn(t) = λn λ∗ ∫ b a dt ϕ∗ (t)ϕn(t) . We have used the self-adjoint property of K(x, t) to make the x integral correspond to the Fredholm equation for ϕ∗ (t). Using Dirac notation, the above equation can be written ⟨ϕm|ϕn⟩ = λn λ∗ ⟨ϕm|ϕn⟩, or (λ∗ − λn)⟨ϕm|ϕn⟩ = 0 . If m = n, the scalar product must be nonzero, so we must have λ∗ −λn = 0, showing that λn is real. If m ̸= n and λm ̸= λn, then the scalar product must vanish, indicating orthogonality. 21.4.2. (a) Referring to the answer to Exercise 21.2.12, we see that y1 is orthogonal to y2 and y3 by symmetry. To check the orthogonality of y2 and y3, form ⟨y2|y3⟩ = ⟨P0|P0⟩ + 16 9 λ2λ3⟨P2|P2⟩ , where we have omitted terms that vanish because the Legendre polyno-P0 is orthogonal to P2. Using ⟨P0|P0⟩ = 2 and ⟨P2|P2⟩ = 2/5 and substituting the values of λ2 and λ3, we obtain the desired zero result. (b) Referring to the answer to Exercise 21.2.14, we can check that ∫ 1 0 (1 + 0.5352x)(1 − 1.8685x) dx = 0 . 21.4.3. ϕ(x) = 3x + 1 2 . 21.4.4. λ1 = √ sin πa π , ϕ1(x) = √ Γ(a) x −a + √ Γ(1 − a) xa−1, 0 < a < 1 λ2 = − √ sin πa π , ϕ2(x) = √ Γ(a) x−a − √Γ(1 − a) x a−1, CHAPTER 3. EXERCISE SOLUTIONS 372 21.4.5. (a) y(x) = x ∞∑ s=0 ( λ 3 )s . (b) Convergent for |λ| < 3. Eq. (21.55) assures convergence for |λ| < 1. (c) λ = 3, y(x) = x. 21.4.6. The normalized eigenfunctions of this problem are ϕ1(x) = cos x/ √π and ϕ2(x) = sin x/ √π. Writing K(x, t) = cos(x − t) = πϕ1(x)ϕ1(t) + πϕ2(x)ϕ2(t)), and noting that π = 1/λ1 = 1/λ2, we recover the formula that is to be veriﬁed. 21.4.7. Solution is given in the text. 21.4.8. Expand ϕ(x) = ∑ i aiϕi(x), f (x) = ∑ i biϕi(x), and write K(x, t) = ∑ i ϕi(x)ϕi(t) λi . We get ∑ i aiϕi(x) = ∑ i biϕi(x) + ∑ i λ λi ϕ(x) ∫ b a ϕi(t) ∑ j ajϕj(t) dt = ∑ i bi ϕi(x) + ∑ i λ λi ai ϕi(x) . From the coeﬃcients of ϕi we have ai = bi + λ λi or ai = biλi λi − λ , corresponding to ϕ = ∑ i biλi λi − λ ϕi(x) . CHAPTER 3. EXERCISE SOLUTIONS 373 22. Calculus of Variations 22.1 Euler Equation 22.1.1. Expand the alternate expression for the Euler equation: ∂f ∂x − d dx [f −yx ∂f ∂yx ] = ∂f ∂x −[ ∂f ∂x + ∂f ∂yx yxx + ∂f ∂y yx ]+yxx ∂f ∂yx −yx d dx ∂f ∂yx = −yx [ ∂f ∂y − d dx ∂f ∂yx ] . If the Euler equation in its original form is satisﬁed, then the part of the alternate equation within square brackets vanishes, and the alternate form of the present exercise is also satisﬁed. 22.1.2. Letting y and yx stand respectively for y(x, 0) and yx(x, 0), we need for the ﬁrst two terms of the expansion J(0) = ∫ x2 x1 f (y, yx, x) dx , J ′(0) = ∫ x2 x1 [ ∂f ∂y ∂y ∂α + ∂f ∂yx ∂yx ∂α ] dx ∣α=0 . Now carry out an integration by parts on the second term of the integrandJ ′, using the fact that dyx/dα = d2y/dxdα: ∫ x2 x1 ( ∂f ∂yx ) d dx ( ∂y ∂α ) dx = ( ∂f ∂yx ) ( ∂y ∂α )∣ x2 x1−∫ x2 x1 ( ∂y ∂α ) d dx ( ∂f ∂yx ) dx . The integrated terms vanish because y is ﬁxed at the endpoints. When the transformed integral is inserted into the expression for J ′, we get J ′(0) = ∫ x2 x1 ( ∂y ∂α ) [ ∂f ∂y − d dx ∂f ∂yx ] dx = 0 . Our expansion is now J(α) = J(0) + J ′(0)α + O(α2), and J will be sta- tionary at α = 0 only if J ′(0) = 0. But since the dependence of y upon α is arbitrary and ∂y/∂α can be nonzero anywhere within the integration interval, J ′(0) can only be made to vanish if the quantity within square brackets in the above equation is zero. 22.1.3. Generalizing the procedure carried out in Eqs. (22.9) through (22.12), we ∂y(x, α) ∂α = η(x), ∂yx(x, α) ∂α = ηx(x), ∂yxx, α) ∂α = ηxx(x), CHAPTER 3. EXERCISE SOLUTIONS 374 then write dJ(α) dα = ∫ x2 x1 ( ∂f ∂y η(x) + ∂f ∂yx ηx(x) + ∂f ∂yxx ηxx(x) ) dx . We now integrate by parts the ηx term and (twice) the ηxx term of the integral. All the integrated terms vanish, and the new integrals can be collected into dJ(α) dα = ∫ x2 x1 [ ∂f ∂y − d dx ∂f ∂yx + d2 dx2 ∂f ∂yxx ] η(x) dx = 0 . 22.1.4. If f (y, yx, x) = f1(x, y) + f2(x, y)yx, then (a) ∂f ∂y = ∂f1 ∂y + ∂f2 ∂y yx = d dx ∂f ∂yx = d dx f2 = ∂f2 ∂x + yx ∂f2 ∂y implies ∂f1 ∂y = ∂f2 ∂x . (b) ∫ b a (f1 + f2yx)dx = ∫ b a (f1dx + f2dy) is independent of the choice of path, i.e. depends only on the endpoints because of (a). 22.1.5. If f = f (x, y) then (a) ∂f ∂y = d dx ∂f ∂yx = 0, so that f is independent of y. (b) There is no information on f (x). 22.1.6. (a) Diﬀerentiate the equation c1 cosh(x0/c1) as follows: dc1 cosh ( x0 c1 ) + c1 sinh ( x0 c1 ) [ dx0 c1 − x0 c2 dc1 ] = 0 . Substitute cosh(x0/c1) = 1/c1 and sinh(x0/c1) = 1/x0, reaching dc1 c1 + c1 x0 [ dx0 c1 − x0 c2 dc1 ] = 0 . Rearrange this expression to solve for dx0/dc1: dx0 dc1 = x0 ( 1 c1 − 1 c1 ) = 0. (b) Dividing the above expressions for cosh(x0/c1) and sinh(x0/c1), we ﬁnd that under the conditions of part (a) we have cosh(x0/c1) sinh(x0/c1) = x0 c1 = coth(x0/c1) . CHAPTER 3. EXERCISE SOLUTIONS 375 (c) Solve the equation of part (b) to obtain x0/c1 ≈ 1.199679; then obtain x0 from x0 = 1/ sinh(1.199679) = 0.662743 and c1 = x0/1.199679 = 0.5523434. 22.1.7. The condition that the shallow curve and Goldschmidt solution have equal area corresponds to the equation πc2 [sinh ( 2x0 c1 ) + 2x0 c1 ] = 2π . Using also the relation 1/c1 = cosh(x0/c1), the above equation can be brought to the form sinh(2w) + 2w = 2 cosh2 w, where w = x0 c1 . This is a transcendental equation in a single variable, with solution w = 0.63923. Then, c1 = 1/ cosh w = 0.82551, and x0 = wc1 = 0.5277. 22.1.8. Taking the second derivative of J, ∂2J ∂α2 = ∫ x2 x1 ∂ ∂α [ ∂f ∂yx η′(x)] dx = ∫ x2 x1 ∂2f ∂y2 x [η′(x)] 2 dx , where we have omitted terms that vanish because in this problem f does not depend on y. Here f = (1 + y2 x) 1/2 , ∂2f ∂y2 x = 1 (1 + y2 x)3/2 , and we see that the integrand in the integral for ∂2J/∂y2 x is everywhere nonnegative. Since the original formulation of this problem included the tacit assumption that x2 > x1, we see that our second derivative will be positive, indicating that the stationary J will be a minimum. 22.1.9. (a) Assuming that y(x1) and y(x2) are ﬁxed, one can choose a function y that assumes arbitrarily large positive values for a signiﬁcant portion of the range (x1, x2), thereby making J large and positive without limit. Alternatively, one can choose a y that assume arbitrarily large negative values, thereby making J be large and negative without limit. (b) With f = y2, a minimum in J can be achieved by setting f to zero, with discontinuities in f to reach the ﬁxed values at x1 and x2. 22.1.10. (a) Use the alternate form of the Euler equation f −yx(∂f /∂yx) = constant. We have J = ∫ (1,1) (−1,1) e y√1 + y2 x dx , f − yx ∂f ∂yx = e y√1 + y2 x − e yy2 x√1 + y2 x dx = C, or e y √2 + y2 x = C . CHAPTER 3. EXERCISE SOLUTIONS 376 Solve for yx and integrate: yx = ±√C 2e2y − 1, dx = ± dy √C 2e2y − 1 , x = ± tan −1 √C 2e2y − 1 + C ′ . The symmetry of the problem requires that C ′ = 0, and C must be set to make x = 1 when y = 1. This condition is equivalent to 1 = tan −1 √C 2e2 − 1, or C 2e 2 − 1 = π2/16. Substituting into the formula for x, we have x = tan −1 [ e 2(y−1) ( 1 + π2 16 ) − 1 ]1/2 . (b) This problem is not straightforward. If y0 is not suﬃciently less than 1, the optimum path will be discontinuous, consisting of a straight-line segment from (−1, 1) to (−1, y0) followed by a straight line (requiring zero travel time) from (−1, y0) to (1, y0) and then a straight line from there to (1, 1). The travel time for this path will be a(1 − y0) 2. This is clearly not a physically relevant situation. Looking now for continuous paths, we note that the travel time will be J = ∫ a(y − y0)√1 + y2 x dx , f − yx ∂f ∂yx = a(y − y0) √1 + y2 x = C −1 , where we have used the alternate form of the Euler equation. Solving forx and integrating, we get dx = ± dy √ C 2a2(y − y0)2 − 1 , x = ± 1 Ca cosh−1 [Ca(y − y0)] . We have not shown a constant of integration; the symmetry of the problem requires that it be zero. Rearranging the equation for x, we bring it to the form cosh Cax Ca = y − y0 . We now attempt to ﬁnd a solution that passes through the point (1, 1). Such a solution must have a value of Ca that satisﬁes (Ca) −1 cosh Ca = 1 − y0. However, for real Ca the left-hand side of this equation is always greater than approximately 1.5089, indicating that no optimum continuous path exists unless y0 is less than about −0.5089. Assuming a value of y0 permitting an optimum continuous path, the travel CHAPTER 3. EXERCISE SOLUTIONS 377 time on that path is given by t = ∫ 1 −1 a(y − y0) √ 1 + y2 x dx = 2a ∫ 1 0 Ca(y − y0)2 dx = 2a ∫ 1 ymin Ca(y − y0) 2 yx dy = 2a ∫ 1 ymin Ca(y − y0) 2 √C 2a2(y − y0)2 − 1 dy = 2a { 1 − y0 2Ca √ C 2a2(1 − y0)2 − 1 + 1 2 cosh−1[Ca(1 − y0)] } = a { 1 − y0 Ca √ C 2a2(1 − y0)2 − 1 + Ca } . where we have changed the integration variable from x to y and have introduced ymin, the value of y at x = 0. We will need to determine Ca and ymin from the boundary condition at (1, 1). Let’s ﬁrst make a computation for y0 = −0.5089, for which Ca = 1.1997 and ymin = y0 + 1/Ca is 0.3245. We get t = 3.098a, but the discontinuous solution is tdis = 2.28a, so the continuous solution does not yield a global minimum time. For y0 = −0.60, we ﬁnd t = 2.706a vs. tdis = 2.56a. At y0 = −0.70, t = 3.648a vs. tdis = 2.89a; the continuous solution now yields the global minimum time. Finally, at y0 = −1, t = 2.73a and tdis = 4.0a. 22.1.11. The solution is given in the text. 22.1.12. Assign the half-plane y > 0 index of refraction n1 and the half-plane y < 0 index of refraction n2. The velocity of light in a region of index of refraction n is c/n. Consider a light ray traveling from (0, 1) to (d, −1), in the upper half-plane at angle θ1 relative to the direction normal to the boundary between the half-planes, and in the lower half-plane at angle θ2 from that normal. The time of travel for the light ray is t = n1 c cos θ1 + n2 c cos θ2 where θ1 and θ2 are related by tan θ1 + tan θ2 = d. Fermat’s principle is that the path be such that t is a minimum. From the equation for t and the constraint equation, we have cdt = n1 sin θ1 cos2 θ1 dθ1 + n2 sin θ2 cos2 θ2 dθ2 = 0, dθ1 cos2 θ1 + dθ2 cos2 θ2 = 0 . Using the second of these equations to write dθ2 in terms of dθ1, we are left with (n1 sin θ1 − n2 sin θ2) dθ1 cos2 θ1 = 0 . This equation is satisﬁed only if n1 sin θ1 = n2 sin θ2 CHAPTER 3. EXERCISE SOLUTIONS 378 22.1.13. The solution is given in the text. 22.1.14. The solution is given in the text. 22.1.15. As in free fall y ∼ gt2, v ∼ gt ∼ √y in ∫ dt = ∫ ds v = ∫ √ 1 + y′2 √y dx = minimum. As there is no x-dependence, F − y′ ∂F ∂y′ = 1/c =const. using Eq. (22.19). This yields √ 1 + y′2 √y − y′2 √ y(1 + y′2) = 1 c , or c 2 = y(1 + y′2), or y′2 = c 2 − y y , with parametric solution y = c 2 2 (1 − cos u), x = ±c 2(u − sin u)/2. These parametric equations describe a cycloid. 22.2 More General Variations 22.2.1. (a) δ ∫ Ldt = 0, L = m( ˙x 2 + ˙y2)/2 lead to m¨x = 0 = ¨y. So x(t), y(t) are linear in the time.x =const. and y =const. give ∫ Ldt = 0, while a straight line (in t) gives ∫ Ldt =constant̸= 0. 22.2.2. Assuming T ( ˙x), V (x) a stable equilibrium with ˙xi =constant gives d dt ∂L ∂ ˙xi = 0 = ∂L ∂xi . Hence ∂V /∂xi = 0 from L = T − V . 22.2.3. (a) m¨r − mr ˙θ2 − mr sin 2 θ ˙ϕ2 = 0 (b) mr ¨θ + 2m ˙r ˙θ − mr sin θ cos θ ˙ϕ 2 = 0 (c) mr sin θ ¨ϕ + 2m ˙r sin θ ˙ϕ + 2mr cos θ ˙θ ˙ϕ = 0 The second and third terms of (a) correspond to centrifugal force. The second and third terms of (c) may be interpreted as Coriolis forces (with ˙ϕ the angular velocity of the rotating coordinate system). 22.2.4. l ¨θ − l sin θ cos θ ˙ϕ2 + g sin θ = 0 , d dt (ml2 sin 2 θ ˙ϕ) = 0 (conservation of angular momentum). 22.2.5. The independent variable is t; the dependent variables are the components of position xi; the Lagrangian depends also on the time derivatives of the xi, often written ˙xi. Write v2 = ˙x2 + ˙x 2 + ˙x 2 and V (r) = V (x1, x2, x3). CHAPTER 3. EXERCISE SOLUTIONS 379 The equations of motion can be derived from δ ∫ L dt = 0. The Euler equations for this relativistic Lagrangian are, for each component i, ∂L ∂xi − d dt ( ∂L ∂ ˙xi ) = 0 . We have ∂L/∂xi = −∂V /∂xi = Fi, and ∂L/∂ ˙xi = m0 ˙xi/ √ 1 − v2/c2. Thus, the Euler equations become Fi − d dt ( m0 ˙xi√1 − v2/c2 ) . 22.2.6. The solution is given in the text. 22.2.7. (a) From d dt ∂L ∂ ˙qi = ∂L ∂qi , dL dt = ∂L ∂qi ˙qi + ∂L ∂ ˙qi ¨qi, where sums over repeated indices are implied, we get d dt ( ˙qi ∂L ∂ ˙qi − L) = 0. (b) ˙qi ∂L ∂ ˙qi − L = ˙qipi − (T − V ) = 2T − T + V = T + V = H, H =const. follows from dH dt = 0, i.e. (a). 22.2.8. From the Lagrange density L = ρ 2 u2 − τ 2 u2 , the Euler equation yields ∂µ ∂L ∂(∂µu) = ∂L ∂u = 0 = ρ ∂ ∂t ∂u ∂t − τ ∂ ∂x ∂u ∂x . 22.2.10. We require δJ = δ ∫ L dx dy dz dt = 0. We need to write L in terms of the dependent variables and their derivatives; to keep the development more compact we adopt the following nonstandard notations: ϕx for ∂ϕ/∂x etc., (Ai)x for ∂Ai/∂x etc. Note that the index within the parentheses denotes the component of A while the outer index indicates a derivative. Using the equations E = −∇ϕ − ∂A/∂t and B = ∇ × A, we write L = ε0 2 [ ϕ2 +ϕ 2 +ϕ2 +(Ax) 2+(Ay) 2+(Az) 2+2ϕx(Ax)t+2ϕy(Ay)t+2ϕz(Az)t] − 1 2µ0 [ (Az) 2 + (Ay)2 − 2(Az)y(Ay)z + (Az) 2 + (Ax) 2 − 2(Az)x(Ax)z + (Ax) 2 + (Ay) 2 − 2(Ax)y(Ay)x] − ρϕ + JxAx + JyAy + JzAz . CHAPTER 3. EXERCISE SOLUTIONS 380 The Euler equation for ϕ is ∂L ∂ϕ − d dx ( ∂L ∂ϕx ) − d dy ( ∂L ∂ϕy ) − d dz ( ∂L ∂ϕz ) = −ρ − ε0 [ d dx (ϕx + (Ax)t) + d dy (ϕy + (Ay)t) + d dz (ϕz + (Az)t) ] = ρ − ε0∇ · E = 0 , equivalent to ∇ · E = ρ ε0 . The Euler equation for Ax is ∂L ∂Ax − d dy ( ∂L ∂(Ax)y ) − d dz ( ∂L ∂(Ax)z ) − d dt ( ∂L ∂(Ax)t ) = Jx − 1 µ0 [ d dy ( (Ax)y − (Ay)x) + d dz ( (Ax)z − (Az)x) ] − ε0 d dt ( (Ax)t + ϕx) = Jx − 1 µ0 [ ∂Bz ∂y − ∂By ∂z ] + ε0 d dt Ex = Jx − 1 µ0 [∇ × B]x + ε0 dEx dt = 0 . Multiplying this equation through by µ0 and combining it with similar equations for Ay and Az to make a vector equation, we get ∇ × B = µ0J + µ0ε0 dE dt . 22.3 Constrained Minima/Maxima 22.3.1. Diﬀerentiating 2mE ℏ2 − λπR2H with respect to R and H we obtain −2 2.048 2 R3 − 2πλRH = 0, − 2π2 H 3 − λπR2 = 0. Equating πλ from both equations yields R H = 2.048 π√2 . 22.3.2. Let the parallelepiped have dimensions a × a × c. The length plus girth is D = c + 4a; the volume is V = a2c. We carry out an unconstrained minimization of a 2c − λ(c + 4a): Diﬀerentiating with respect to a and c we obtain the equations 2ac − 4λ = 0, a 2 − λ = 0 , from which we ﬁnd λ = a2, c = 2a. From the constraint equation c + 4a = 36, we now ﬁnd a = 6′′, c = 12′′. The maximum volume is 432 in3. CHAPTER 3. EXERCISE SOLUTIONS 381 22.3.3. The volume V = abc is to be minimized subject to the constraint ϕ(a, b, c) = B. We now carry out an unconstrained minimization of V + λϕ, diﬀeren- tiating this quantity with respect to a, b, and c. The result is bc − 2π2λ a3 = 0, ac − 2π2λ b3 = 0, ab − 2π2λ c3 = 0. These equations can be rearranged into a 2 = b 2 = c 2 = 2π2λ/abc. We therefore get the unsurprising result a = b = c. 22.3.4. p = q, (p + q)min = 4f. 22.3.5. If c, d are half the rectangle sides, diﬀerentiating 4cd − λ ( c 2 a2 + d2 b2 − 1) with respect to c and d yields 4d − 2 λc a2 = 0, 4c − 2 λd b2 = 0, or d c = λ 2a2 , c d = λ 2b2 , c a = d b , from which the ellipse equation implies c a = 1 √2 = d b . Hence 4cd πab = 2 π . 22.3.6. If the parallelepiped coordinates are x = ±a′, y = ±b ′, z = ±c ′, diﬀer- entiate a′b′c ′ − λ ( a′2 a2 + b′2 b2 + c ′2 c2 ) with respect to a ′, b′, c′. This yields 8b′c ′ = 2 λa ′ a2 , 4a 2b′c ′ = λa ′ and by symmetry 4b 2a ′c ′ = λb′, 4c 2a ′b ′ = λc′. Taking ratios we ﬁnd a 2 b2 b′ a′ = a′ b′ , or a ′ b′ = a b , i.e., a′ a = b ′ b = c ′ c . Sub- stituting this into the ellipsoid equation yields 3 a ′2 a2 = 1, a ′ = a/ √3, etc. Hence 8a ′b′c ′ 4πabc/3 = 2 π√3 . 22.4 Variation with Constraints 22.4.1. The solution is given in the text. 22.4.2. (c) ω(t) = L m(ρ0 − kt)3 where L is the angular momentum. 22.4.3. The integrals H and K, that respectively describe the potential energy and the length of the cable in terms of the vertical position y(x) of the cable at points x, are proportional to H = ∫ x2 x1 y√1 + y2 x dx and K = ∫ x2 x1 √ 1 + y2 x dx . CHAPTER 3. EXERCISE SOLUTIONS 382 The quantity to be made stationary is J = H + λK = ∫ x2 x1 f (y, yx) dx, f (y, yx) = (y − λ) √1 + y2 x . The Euler equation for this problem is f − yx ∂f ∂yx = C1 or (y − λ) √ 1 + y2 x − y2 x(y − λ) √1 + y2 x = C1 , which simpliﬁes to y − λ = C1 √ 1 + y2 x . Solving for yx and integrating, yx = dy dx = [( y − λ C1 )2 − 1 ]1/2 , C1 cosh−1 ( y − λ C1 ) = x − C2 which rearranges to y − λ = C1 cosh ( x − C2 C1 ) . The constants λ, C1, and C2 must now be chosen so that y(x) passes through the points (x1, y1) and (x2, y2) and that the integral K evaluates to the cable length L. The conditions on the endpoints correspond to y1 − λ = C1 cosh ( x1 − C2 C1 ) , y2 − λ = C1 cosh ( x2 − C2 C1 ) . The cable length satisﬁes L = ∫ x2 x1 y − λ C1 dx = ∫ x2 x1 cosh ( x − C2 C1 ) dx = C1 [sinh ( x2 − C2 C1 ) − sinh ( x2 − C2 C1 )] . From the above we form L 2 − (y2 − y1) 2 = C 2 1 [ −2 + 2 cosh ( x2 − x1 C1 )] = 4C 2 1 sinh 2 ( x2 − x1 2C1 ) . This is a transcendental equation in the single unknown C1 and can easily be solved numerically for any given input. Using this value for C1, the equation for L then contains only the undetermined quantity C2, which can be obtained by numerical methods. Finally, the equation for y1 (or y2) can be solved for λ. The curve y(x) solving this problem is known as a catenary. CHAPTER 3. EXERCISE SOLUTIONS 383 22.4.4. The gravitational potential per unit volume of water at vertical positionrelative to a zero at y0 is ρg(y − y0), where ρ is the mass density and g is the acceleration of gravity. The total gravitational potential energy of a cylindrical shell of water of radius r, thickness dr, base at y = y0, and surface at y(r) is ρg[y(r) − y0] 2(2πr) dr/2. The centrifugal force per unit volume of water a distance r from the axis of rotation, under a ro- tational angular velocity ω, is ρω2r, and its rotational potential energy (relative to a position on the axis of rotation) is −ρω2r2/2. Therefore the total rotational potential energy of the cylindrical shell described above isρω2r2(y − y0)(2πr)/2. Based on the above analysis, the total potential energy E and volume V of a column of water of radius a, rotating at angular velocity ω, with a base at y0 and surface at y(r), are E = 2πρ ∫ a 0 dr [ gy(r) 2r 2 − ωy(r)r3 2 ] , V = 2π ∫ a 0 y(r)r dr . Discarding common factors, we want to minimize E for constant V , cor- responding to δJ = ∫ a 0 f (y, r) dr = 0 , f = gy2r − ω2yr3 − 2λyr . The Euler equation is ∂f ∂y = 0 , or 2gry − ω2r3 − 2λr = 0, and its solution is y = ω2r2 − 2λ 2g . If we set λ = 0 our water column will have its surface at y = 0 at the axis (r = 0) and for r = a the surface will be at y = ω2a2/2g. The surface will be a paraboloid of revolution. 22.4.5. Deﬁne a curve parametrically, as x(t), y(t). Then, for a closed curve, for which x(t2) = x(t1) and y(t2) = y(t1), the area A and the perimeter L are given by the following integrals: A = 1 2 ∫ t2 t1 (x ˙y − ˙xy) dt , L = ∫ t2 t1 √ ˙x2 + ˙y2 dt , where we have written the line integral for the area in a more or less symmetric form and have used the dot notation for derivatives with respectt, even though t is not really a time variable. (a) For maximum area at ﬁxed perimeter we therefore consider variation J = ∫ t2 t1 f (x, y, ˙x, ˙y) dt, with f = 1 2 (x ˙y − ˙xy) + λ√ ˙x2 + ˙y2 , CHAPTER 3. EXERCISE SOLUTIONS 384 leading to the two Euler equations ∂f ∂x − d dt ( ∂f ∂ ˙x ) = ˙y 2 − d dt ( − y 2 + λ ˙x √ ˙x2 + ˙y2 ) = 0 , ∂f ∂y − d dt ( ∂f ∂ ˙y ) = − ˙x 2 − d dt ( x 2 + λ ˙y √ ˙x2 + ˙y2 ) = 0 . Integrating these equations with respect to t, y − λ ˙x √ ˙x2 + ˙y2 = C1 , x + λ ˙y √ ˙x2 + ˙y2 = C2 . Moving the constants C1 and C2 to the left-hand sides of these equations, then squaring both equations and adding them together, we reach (x − C2) 2 + (y − C1)2 = λ2 ˙y2 ˙x2 + ˙y2 + λ2 ˙x 2 ˙x2 + ˙y2 = λ2. This is the equation of a circle. (b) If we divide the expression for J by λ, its variation can be interpreted as describing an extremum in the perimeter with a constraint of ﬁxed area. The solution will be the same as that already obtained, so the closed curve of minimum perimeter will be a circle. 22.4.6. Inserting ϕ = ϕ + δϕ, deﬁning S = ∫ b a ϕ 2(x) dx, and using the symmetry of K(x, t): δ(J − λS) = ∫ b a dxδϕ(x) [ 2 ∫ b a K(x, t)ϕ(t) dt − 2λϕ(x) ] , where we retain only terms that are ﬁrst-order in δϕ. Since the above equation must be satisﬁed for arbitrary δϕ, the integrand of the x integral must vanish, leading to the required integral equation. 22.4.7. (a) Here F [ ] refers to J as deﬁned in Eq. (22.100); in the notation most frequently used in quantum mechanics, F = ⟨y|H|y⟩ ⟨y|y⟩ , where here H = −(d2/dx2) and we can use the Rayleigh-Ritz method to ﬁnd an approximate function y. Noting that the trial function ytrial = 1 − x2 satisﬁes the boundary conditions, we insert it into F , obtaining F = − ∫ 1 0 (1 − x 2)(1 − x 2) ′′ dx ∫ 1 0 (1 − x2) 2 dx = 4/3 8/15 = 5 2 = 2.5 . CHAPTER 3. EXERCISE SOLUTIONS 385 (b) The exact value is (π/2) 2 = 2.467. 22.4.8. Using the notation of the solution to Exercise 22.4.7, we require F = − ∫ 1 0 (1 − x n)(1 − x n) ′′ dx ∫ 1 0 (1 − xn) 2 dx = n(n − 1) ∫ 1 0 (x n−2 − x 2n−2) dx n ∫ 1 0 (x 2n − 2x n + 1 ) dx = n2/(2n − 1) 2n2/(2n + 1)(n + 1) = (2n + 1)(n + 1) 2(2n − 1) . Setting dF/dn = 0, we ﬁnd n = (1±√6)/2 = 1.7247 or −0.7247. We reject the negative n value because it does not satisfy the boundary condition at x = 0. From n = 1.7247 we evaluate F = 2.4747, much closer to the exact value 2.467 than was the approximation of Exercise 22.4.7 (which was 2.50). 22.4.9. In the usual quantum-mechanics notation, in this problem H = − ∂2 ∂r2 − 2 r ∂ ∂r , ⟨H⟩ = ⟨ψ|H|ψ⟩ ⟨ψ|ψ⟩ , ψ = 1 − ( r a )2 . For spherically symmetric functions, the scalar product has deﬁnition ⟨χ|ϕ⟩ = 4π ∫ a 0 r2χ(r) ∗ϕ(r) dr . We have Hψ = 6/a2, so ⟨ψ|H|ψ⟩ = 24π a2 ∫ a 0 ( r2 − r4 a2 ) dr = 16πa 5 . Also, ⟨ψ|ψ⟩ = 4π ∫ a 0 ( r2 − 2r4 a2 + r6 a4 ) dr = 32πa3 105 . Therefore, ⟨H⟩ = 16πa/5 32πa3/105 = 21 2a2 = 10.5 a2 . The exact ψ is the spherical Bessel function j0(πr/a); note that −∇ 2j0(πr/a) = (π/a) 2j0(πr/a), showing that the exact eigenvalue is π2/a 2 = 9.87/a 2. 22.4.10. Normalizing, and changing the integration variable to u = x/a, N 2 ∫ a 0 ( 1 − x 2 a2 )2 dx = N 2a ∫ 1 0 (1 − u2)2 du = N 2a ( 8 15 ) = 1 CHAPTER 3. EXERCISE SOLUTIONS 386 gives N 2 = 15/8a. The expectation value of H is N 2 [− ∫ a 0 ( 1 − x 2 a2 ) d2 dx2 ( 1 − x 2 a2 ) dx + ∫ a 0 ( 1 − x 2 a2 ) x 2 ( 1 − x 2 a2 ) dx ] = 15 4a2 ∫ 1 0 ∗1 − u2) du + 15a 2 8 ∫ 1 0 u2(1 − u2) 2 du = 5 2a2 + a 2 7 . Diﬀerentiating with respect to a yields − 5 a3 + 2a 7 = 0, i.e., a = (35/2) 1/4. This value of a causes the energy to have expectation value 2 √10/7, which is quite far from the exact value λ = 1. The large error is indicative of the fact that we chose a trial function that cannot for any value of thea be a good approximation to the exact eigenfunction. 22.4.11. Let u1 be an eigenfunction of the entire Schr¨odinger equation for some nonzero l. Note that ⟨u1|L|u1⟩ must be at least as large as E0, and that the centrifugal operator will have a positive expectation value for any function. (To prove this, multiply the wave function in each half of the scalar product by the square root of the centrifugal term, giving us an expression of the form ⟨f |f ⟩.) The sum of these two terms will be larger than E0. CHAPTER 3. EXERCISE SOLUTIONS 387 23. Probability and Statistics 23.1 Probability: Deﬁnitions, Simple Properties 23.1.1. (a) 52/2 52 = 1 2 . (b) 2 52 = 1 26 . (c) 1 52 . 23.1.2. (a) ( 4 52 )2 = 1 132 . (b) 4 52 3 51 = 1 13 · 17 . 23.1.3. (a) 1 + 2 62 = 1 12 . (b) (1 + 2) + 2 + 2 62 = 7 62 . 23.1.4. There are three events: (2,2,2), (4,1,1), (1,2,3) whose probabilities sum up 1 + 3 + 3 · 2 63 = 5 3 · 62 . 23.1.5. P (A ∩ B ∩ C) = P (A)P (B|A)P (C|A ∩ B) = P (A)P (B ∩ C|A) = P (B)P (C|B)P (A|B ∩ C). 23.1.6. Maxwell-Boltzmann: kN1+···+Nk , Fermi-Dirac: ∏ i ( k + Ni − 1 Ni ), Bose-Einstein: ∏ i ( k Ni ) . 23.1.7. If A ∩ B = ∅, A ∩ C = ∅, B ∩ C = ∅ then P (A ∪ B ∪ C) = P (A) + P (B) + P (C). If A ∩ B ̸= ∅, B ∩ C ̸= ∅, A ∩ C ̸= ∅, but A ∩ B ∩ C = ∅, then P (A ∪ B ∪ C) = P (A) + P (B) − P (A ∩ B) + P (C) − P (A ∩ C) − P (B ∩ C). CHAPTER 3. EXERCISE SOLUTIONS 388 In general, P (A ∪ B ∪ C) = P (A) + P (B) + P (C) − P (B ∩ C) − P (A ∩ C) − P (A ∩ B) + P (A ∩ B ∩ C). 23.1.8. To a good approximation 1/p. For p = 3 compare 1/3 with 33/100; for p = 5 compare 1/5 with 20/100; for p = 7 compare 1/7 with 14/100; or [100/p ]/100 ≈ 1/p with [x] the largest integer below x. 23.1.9. Maxwell-Boltzmann: 32, Fermi-Dirac: ( 3 ) , Bose-Einstein: ( 4 ) . 23.2 Random Variables 23.2.1. The equally probable mutually exclusive two-card draws are: (1, 2), (1, 3), (1, 4), (2, 3), (2, 4), (3, 4) . Each of these pairs has an equal probability of being drawn in either order, so we can make computations based on the six listed possibilities. Adding the numbers on the cards, 3, 4, 6, and 7 each occur once, 5 occurs twice. A single occurrence corresponds to P = 1/6, two occurrences to P = 2/6 = 1/3. The mean computed directly from the six events is (3 + 4 + 5 + 5 + 6 + 7)/6 = 5 . To obtain the variance, we can compute (3 − 5)2 + (4 − 5)2 + 2(5 − 5)2 + (6 − 5)2 + (7 − 5) 2 6 = 10 6 = 5 3 . 23.2.2. ⟨X⟩ + c = ∫ ∞ −∞(x + c)f (x) dx, σ2(X) = ∫ ∞ −∞(x − ⟨X⟩) 2f (x) dx, ⟨cX⟩ = c ∫ ∞ −∞ xf (x) dx = c⟨X⟩, c 2σ2(X) = ∫ ∞ −∞(cx − ⟨cX⟩) 2f (x) dx. 23.2.3. Expanding the integral in Eq. (23.27) and identifying the three resultant integrals as respectively ⟨X 2⟩, ⟨X⟩, and unity, we get σ2 = ∫ ∞ −∞ x 2f (x) dx − 2⟨X⟩ ∫ ∞ −∞ xf (x) dx + ⟨X⟩ 2 ∫ ∞ −∞ f (x) dx = ⟨X 2⟩ − 2⟨X⟩ 2 + ⟨X⟩2 = ⟨X 2⟩ − ⟨X⟩ 2. CHAPTER 3. EXERCISE SOLUTIONS 389 23.2.4. 1 N N∑ j=1 vj = ¯v = 1 N N∑ j=1 xj tj = 1 N N∑ j=1 ¯x + ∆xj ¯t + ∆tj = ¯x ¯t 1 N N∑ j=1  1 + ∆xj ¯x 1 + ∆tj ¯t  . Hence ∣¯v − ¯x ¯t ∣ ≤ ∣ ¯x ¯t ∣ 1 N N∑ j=1 [ |∆xj| ¯x + |∆tj| ¯t ] ≪ ∣ ¯x ¯t ∣ . 23.2.5. Since X has the same deﬁnition as in the example, its expectation value ⟨X⟩ = 10/13 and variance σ2(X) = 80/132 are the same as found there. To compute the other quantities, we need to develop the probability dis- tribution. We have for f (x, y): f (0, 0) = ( 2 13 )2 = 4 132 f (1, 1) = 2 ( 5 13 ) ( 6 13 ) = 60 132 f (2, 0) = ( 5 13 )2 = 25 132 f (1, 0) = 2 ( 5 13 ) ( 2 13 ) = 20 132 f (0, 2) = ( 6 13 )2 = 36 132 f (0, 1) = 2 ( 6 13 ) ( 2 13 ) = 24 132 Then we can compute 2(Y ) = ( 12 13 )2 [ 4 + 25 + 20 132 ]+( 1 13 )2 [ 60 + 24 132 ]+( 14 13 )2 36 132 = 84 132 . Next we compute the covariance: cov(X, Y ) = ( − 10 13 ) (− 12 13 ) ( 4 132 ) + ( 16 13 ) (− 12 13 ) ( 25 132 ) + ( − 10 13 ) ( 14 13 ) ( 36 132 ) + ( 3 13 ) ( 1 13 ) ( 60 132 ) + ( 3 13 ) (− 12 13 ) ( 20 132 ) + (− 10 13 ) ( 1 13 ) ( 24 132 ) = − 10140 134 = − 60 132 . Finally, we obtain the correlation: cov(X, Y ) σ(X)σ(Y ) = − 60 √80 · 84 = −0.732. 23.2.6. The mean free path is ∫ ∞ 0 e −x/f dx = − f e −x/f ∣∞ = f , or normalizing the probability density as p(x) dx = (e −x/f /f ) dx, we have ∫ ∞ 0 xe −x/f dx f = ∫ ∞ 0 xe −xdx = f. CHAPTER 3. EXERCISE SOLUTIONS 390 For l > 3f, the probability is ∫ ∞ 3f e −x/f dx f = ∫ ∞ 3 e −xdx = e −3 = 5%. 23.2.7. x(t) = A cos ωt dx = −Aω sin ωt dt, dx v = dt = dx ω√A2 − x2 ; ∫ A −A dx √A2 − x2 = arcsin x A ∣AA = π. Hence the probability density is p(x) dx = dx π√A2 − x2 . 23.3 Binomial Distribution 23.3.1. The probability distribution is f (X = x) = ( n x ) 1 2n . The sample space corresponds to x = 0, 1, . . . , n. A typical event has x heads up and n − x down. Using the formulas from Example 23.3.2, ⟨X⟩ = n 2 , σ2(X) = n 4 . 23.3.2. Plot f (X = x) = (6 x ) ( 1 6 )x ( 5 6 )6−x, x = 0, 1 . . . , 6 as a function of x. 23.3.3. Compute this probability as unity minus the sum of the probabilities of exactly zero, one, and two defective nails, i.e., P = 1 − ( 100 0 ) (0.97) 100 − (100 1 ) (0.97) 99(0.03) − ( 100 2 ) (0.97) 98(0.03) 2 = 0.58 (58%). 23.3.4. When the cards are put back at random places the probabilities are All red: 1 24 . All hearts: 1 44 . All honors: ( 5 13 )4 . When the cards are not put back, these probabilities become Red: 1 2 25 51 24 50 23 49 . Hearts: 1 4 12 51 11 50 10 49 . Honors: 5 13 19 51 18 50 17 49 . 23.3.5. Form ⟨e tX ⟩ = (pe t + q)n, ∂ ∂t ⟨e tX ⟩ ∣t=0 = ⟨X⟩ = np. CHAPTER 3. EXERCISE SOLUTIONS 391 23.4 Poisson Distribution 23.4.1. From the data or the problem statement, we determine the average number of particles λ per time interval: n = ∑ i ni = 2608, λ = 1 n ∑ i ini = 203 + 2 · 383 + · · · + 10 · 16 2608 = 3.87, yielding e −λ = 0.0209. From the Poisson distribution, npi = λi i! e −λ. Evaluating npi and tabulating, i ni npi 0 57 55.7 1 203 210.8 2 383 407.8 3 525 525.7 4 532 508.4 5 408 393.3 6 273 253.5 7 139 140.1 8 45 67.7 9 27 29.1 10 16 11.3 23.4.2. σ2 = ⟨X 2⟩ − ⟨X⟩2 . From the mean value, ⟨X⟩ 2 = µ 2. If we write n2 n! = 1 (n − 2)! + 1 (n − 1)! , we can evaluate ⟨X 2⟩ as follows: ⟨X 2⟩ = e −µ ∞∑ n=1 n2µ n n! = e −µ ∞∑ n=2 µ n (n − 2)! + e −µ ∞∑ n=1 µ n (n − 1)! = µ2e −µ ∞∑ n=2 µn−2 (n − 2)! + µe −µ ∞∑ n=1 µn−1 (n − 1)! = µ 2 + µ . Therefore, σ2 = µ 2 + µ − µ 2 = µ. 23.4.3. The parameter µ of the Poisson distribution (based on 5000 counts in 2400 seconds) is µ = 5000/2400 = 2.083. The probability of n counts in a one-second interval is µ ne −µ/n!; for n = 2 and n = 5 we have P (2) = µ 2 2! e −µ = 0.270, P (5) = µ 5 5! e −µ = 0.041. CHAPTER 3. EXERCISE SOLUTIONS 392 23.4.4. Take the time unit to be 10 s, thereby making µ = 1. The probability of three counts in one time interval is (µ 3/3!)e −µ = 1/6 e = 0.061. 23.4.5. The solution is given in the text. 23.4.6. This is a binomial distribution problem. We compute the probability of one or more hits as unity minus the probability that all ﬁve shots miss the target. This is P = 1 − (0.80) 5 = 0.67. 23.5 Gauss’ Normal Distribution 23.5.1. Use Eq. (23.56) with µ = 0, which means that ⟨X⟩ = 0. We therefore need to show that ⟨X 2⟩ = σ2 when σ is the symbol occurring in Eq. (23.56). We start by verifying that the probability density is properly normalized.u = x/(σ√ 2), we recognize the u integration as an error function (Section 13.6), so ∫ ∞ −∞ f (x) dx = 1 σ√2π ∫ ∞ −∞ e −x2/2σ2 dx = 1 σ√2π ∫ ∞ −∞ e −u2 (σ√2 du) = 1 √π ∫ ∞ −∞ e −u2 du = 1 . In a similar way we now compute ⟨X 2⟩ = ∫ ∞ −∞ x 2f (x) dx = 2σ2 √π ∫ ∞ −∞ u2e −u2 du = 2σ2 √π ( √π 2 ) = σ2 , completing the proof. The value of the u integral can be obtained by integrating the error-function integral by parts, diﬀerentiating e −u2 and integrating du. 23.5.2. In Eq. (23.61), write (pn + v) s+1/2 = (pn)s+1/2(1 + v/pn) s+1/2, (qn − v) n−s+1/2 = (qn) n−s+1/2(1 − v/qn)n−s+1/2 , cancel the exponential (whose argument is zero), and combine the powersp, q, and n. We then get Eq. (23.62) when we replace s by pn + v and n − s by qn − v. 23.5.3. By taking the logarithm the quantity (1 + v/pn) −(pn+v+1/2) becomes − ( pn + v + 1 2 ) ln ( 1 + v pn ) = − ( pn + v + 1 2 ) ( v pn − v2 2p2n2 + · · · ) , and a similar treatment can be applied to (1−v/qn) −(qn−v+1/2). Equation (23.63) results when the terms linear and quadratic in v are collected. CHAPTER 3. EXERCISE SOLUTIONS 393 23.5.4. P (|X − ⟨X⟩| > 4σ) = 2 √π ∫ ∞ 4/√2 e −x 2 dx = 6.3 · 10 −5 ≈ 10−3 . This can be compared to PCheby(|X − ⟨X⟩| > 4σ) ≤ 1 16 = 0.0625, 23.5.5. This problem has been worded incorrectly. Reinterpret it to identify m as the mean of the student scores and M as an individual student score. Then an A grade corresponds to a score higher than m + 3σ/2, etc. The probabilities we need are the following: PA = PF = P ( M −m > 3σ 2 ) = 1 √π ∫ ∞ 3/2√2 e −x 2 dx = 1 2 erfc ( 3 2 √2 ) = 6.7% ; PB = PD = P ( σ 2 < M −m < 3σ 2 ) = 1 √π ∫ 3/2√2 1/2√2 e −x2dx = 1 2 erf ( 3 2 √2 ) − 1 2 erf ( 1 2√2 ) = 24.2% ; PC = P (|x − m| < σ 2 ) = erf ( 1 2√2 ) = 38.3% ; with percentages (reﬂecting round-oﬀ error) A: 6.7%, B: 24.2%, C: 38.3%, D: 24.2%, F: 6.7%. A redesign to bring the percentage of As to 5% would require us to ﬁnd a value of kAσ such that PA = erfc(kA/√2)/2 = 0.05; it is kA = 1.645. With this value of kA, a value of kB that makes PB = erf(kA/√2) − erf(kB/ √2) 2 = 0.25 is kB = 0.524. Then PC = erf(kB/ √2) = 0.40. 23.6 Transformations of Random Variables 23.6.1. The addition theorem states n∑ n=1 Xi has mean value n¯x, and 1 n n∑ n=1 Xi has mean value ¯x. Since σ2 n∑ n=1 Xi = nσ2, and translation does not change the variance, we obtain the σ2 claim. 23.6.2. ⟨2X − 1⟩ = 2⟨X⟩ − 1 = 2 · 29 − 1 = 57 , σ2(2X − 1) = σ2(2X) = 2σ2 = 2 · 9 = 18 , CHAPTER 3. EXERCISE SOLUTIONS 394 σ(2X − 1) = 3 √2 . ⟨3X + 2⟩ = ⟨3X⟩ + 2 = 3⟨X⟩ + 2 = 87 + 2 = 89 , σ(3X) = 3 √3. 23.6.3. Set I = 1 σ√2π ∫ m+r m−r e −(x−m)2/2σ2dx = 1 2 . Simplify this integral to I = 1 σ√2π ∫ r −r e −x2/2σ2 dx = 2 √π ∫ r/σ√2 0 e −x2dx = erf ( r σ√2 ) = 1 2 . The value of r that satisﬁes this equation is r = 0.477σ√2 = 0.674σ. 23.6.4. ⟨X Y ⟩ = ∫ ∫ f (x, y) dx dy = ∫ f (x) dx ∫ g(y) dy = ⟨X⟩ ⟨Y ⟩. 23.6.5. ⟨f (X, Y )⟩ = ∫ ∫ f (x, y)P (x)Q(y) .dx dy = ∫ ∫ [ f (0, 0) + x ∂f ∂x ∣(0,0) + y ∂f ∂y ∣(0,0) + · · · ] P (x)Q(y) dx dy = f (0, 0) + ⟨X⟩ ∂f ∂x ∣(0,0) + ⟨Y ⟩ ∂f ∂y ∣(0,0) + · · · . A corresponding expansion of the covariance takes the form cov f (X, Y ) = ∫ ∫ (x − ⟨X⟩)(y − ⟨Y ⟩)f (x, y)P (x)Q(y) dx dy = ∫ ∫ (x − ⟨X⟩)(y − ⟨Y ⟩) [ f (0, 0) + ∂f ∂x ∣(0,0) x + ∂f ∂y ∣(0,0) y + ∂2f ∂x2 ∣(0,0) x 2 2 + ∂2f ∂x∂y ∣(0,0) xy + ∂2f ∂y2 ∣(0,0) y2 2 + · · · ] P (x)Q(y) dx dy . Of the terms explicitly shown, all but the xy term vanish because the double integral can be separated to contain as a factor ∫ (x − ⟨X⟩)P (x) dx or ∫ (y − ⟨Y ⟩)Q(y) dy . CHAPTER 3. EXERCISE SOLUTIONS 395 Thus, the lowest-order contribution to the covariance is cov f (X, Y ) = ∂2f ∂x∂y ∣(0,0) ∫ ∫ (x − ⟨X⟩)(y − ⟨Y ⟩)xyP (x)Q(y) dx dy = ∂2f ∂x∂y ∣(0,0) ∫ (x 2 − x⟨X⟩)P (x) dx ∫ (y2 − y⟨Y ⟩)Q(y) dy = ∂2f ∂x∂y ∣(0,0) σ2(X)σ2(Y ) . Hence the correlation, to lowest order, is covf (X, Y ) σ2(X)σ2(Y ) ≈ ∂2f ∂x∂y ∣(0,0). 23.6.6. σ2(aX + bY ) = ∫ ∫ [ (ax + by) − ⟨aX + bY ⟩] 2f (x, y) dx dy = a2σ2(X) + b 2σ2(Y ) + 2ab [ ⟨XY ⟩ − ⟨X⟩⟨Y ⟩] . When X and Y are independent then σ2(aX + bY ) = a 2σ2(X) + b 2σ2(Y ). 23.6.7. A normally distributed Gaussian variable with mean µ and variance σ2 has Fourier transform, and equivalently ⟨e itX ⟩, given by f T (t) = 1 √2π e itµ e −t 2σ2/2, ⟨e itX ⟩ = e itµ e −t 2σ2/2 . If a random variable Y is the sum of two Gaussian variables X1 and X2 with respective means µ1, µ2 and variances σ2 1, σ2 2, it is useful to form ⟨e itY ⟩ = ⟨e it(X1+X2)⟩ = ⟨e itX1 ⟩⟨e itX2⟩ = e it(µ1+µ2)e −t 2(σ2 1 +σ2 2 ). This equation shows that Y is described by a Gauss normal distribution with mean µ1 + µ2 and variance σ2 1 + σ2 2. 23.6.8. The Fourier transform of g(p, σ; y) is [g(p, σ)] T (t) = 1 √2π (2σ2)pΓ(p) ∫ ∞ 0 yp−1e iyte −y/2σ2 dy . Noting now that e iyt e −y/2σ2 = e −y(1/2σ2−it), we change the variable of integration to u = (1 − 2itσ2)y/2σ2, converting the integral to ∫ ∞ 0 yp−1e iyte −y/2σ2 dy = ( 2σ2 1 − 2itσ2 )p ∫ ∞ 0 up−1e −udu The integration path (from zero to inﬁnity through complex values) can be (as indicated above) deformed to the real line without changing its value because σ2 is positive. CHAPTER 3. EXERCISE SOLUTIONS 396 Recognizing the u integral as Γ(p) and inserting the value of the y integral, we get [g(p, σ)] T (t) = 1 √2π (1 − 2itσ2) −p . 23.7 Statistics 23.7.1. If C = AB then σ2(AB) = A2σ2(B) + B2σ2(A), and σ2(C) C 2 = σ2(A) A2 + σ2(B) B2 . 23.7.2. ¯x = 1 4 (6.0 + 6.5 + 5.9 + 6.2) = 6.15, ¯x ′ = 1 5 (4¯x + 6.1) = 6.14; σ2 = 1 4 (0.152 + 0.352 + 0.252 + 0.05 2) = 0.0525, σ′2 = 1 5 (0.14 2 + 0.362 + 0.242 + 0.062 + 0.042) = 0.0424. Since x6 is close to ¯x, ¯x′ ≈ ¯x and σ2 decreases a bit. 23.7.3. The problem is to be solved using the data from Example 23.7.2, but with the uncertainties given in the example associated with the tj rather than with the yj. Reversing the roles of y and t, we ﬁrst compute the expectation value of dt/dy using N = 1 · 0.8 0.12 + 2 · 1.5 0.052 + 3 · 3 0.22 = 1505, D = 0.82 0.12 + 1.5 2 0.052 + 32 0.22 = 1189, from which we ﬁnd 〈 dt dy 〉 = N D = 1.266, σ2 b = 1 D = 0.000841 . From the square root of σ2 b we get σb = 0.029, so our chi-square ﬁt for dt/dy is 1.166 ± 0.029. We can compare the reciprocal of this result with that obtained for dy/dt in Example 23.7.2, where we found dy/dt = 0.782±0.023: 1/1.266 = 0.790, and the reciprocals of 1.266 ± 0.029 are 0.772 and 0.808, spanning an in- terval of width 0.036, not too diﬀerent from 2 × 0.023 = 0.046. To ﬁnd the 95% conﬁdence interval, we compute A = 4.3σb/ √3 (com- pare with Example 23.7.2). We obtain A = 0.072, meaning that at this conﬁdence level dt/dy = 1.266 ± 0.072. CHAPTER 3. EXERCISE SOLUTIONS 397 23.7.4. The sample mean is X = (6.0 + 6.5 + 5.9 + 6.1 + 6.2 + 6.1)/6 = 6.133. The sample standard deviation (based on ﬁve degrees of freedom) is √ (6.0 − 6.133)2 + (6.5 − 6.133)2 + · · · + (6.1 − 6.133)2 5 = 0.2066 . Then, using Table 23.3, with p = 0.95 for the 90% conﬁdence level and p = 0.975 for the 95% conﬁdence interval, we obtain (based on n = 5) C90 = 2.02 and C95 = 2.57. These translate into For 90% conﬁdence : 6.133 ± (2.02)(0.2066) √ 5 = 6.133 ± 0.187, For 95% conﬁdence : 6.133 ± (2.57)(0.2066) √ 5 = 6.133 ± 0.237. Chapter 4 Correlation of Sixth and Seventh Edition Exercises The following two tables indicate: (1) The source of the exercises in the Seventh Edition; “new” indicates that the exercise was not in the Sixth Edition; (2) The locations at which Sixth-Edition exercises can be found in the Seventh Edition; “unused” indicates that the exercise was not used in the Seventh 398 CHAPTER 4. CORRELATION, EXERCISE PLACEMENT 399 Source of Exercises in Seventh Edition 7th 6th 7th 6th 7th 6th 1.1.1 5.2.1 1.1.2 5.2.2 1.1.3 5.2.4 1.1.4 5.2.5 1.1.5 5.2.6 1.1.6 5.2.7 1.1.7 5.2.8 1.1.8 5.2.12 1.1.9 5.2.13 1.1.10 5.2.14 1.1.11 new 1.1.12 5.2.22 1.1.13 5.2.20 1.1.14 new 1.1.15 5.4.3 1.1.16 5.2.21 1.2.1 5.5.1 1.2.2 5.5.2 1.2.3 5.5.3 1.2.4 5.5.4 1.2.5 5.2.15 1.2.6 5.2.16 1.2.7 5.2.17 1.2.8 5.6.1 1.2.9 5.6.2 1.2.10 5.6.4 1.2.11 5.6.5 1.2.12 5.6.8 1.2.13 5.6.9 1.2.14 5.6.21 1.2.15 5.7.9 1.2.16 5.7.13 1.3.1 5.7.1 1.3.2 5.7.6 1.3.3 5.7.7 1.3.4 5.7.11 1.3.5 new 1.3.6 5.6.11 1.3.7 5.6.12 1.3.8 5.6.13 1.3.9 5.6.14 1.3.10 5.6.15 1.3.11 5.6.16 1.3.12 5.6.17 1.3.13 5.6.18 1.3.14 5.6.19 1.3.15 5.6.20 1.3.16 5.7.15 1.3.17 5.7.16 1.3.18 5.7.17 1.4.1 new 1.4.2 new 1.5.1 new 1.5.2 new 1.5.3 new 1.5.4 new 1.5.5 new 1.6.1 5.4.1 1.7.1 1.1.2 1.7.2 1.1.8 1.7.3 1.1.9 1.7.4 1.1.11 1.7.5 1.1.12 1.7.6 1.3.3 1.7.7 1.3.5 1.7.8 1.3.6 1.7.9 1.4.1 1.7.10 1.4.2 1.7.11 1.4.5 1.8.1 6.1.1 1.8.2 6.1.5 1.8.3 6.1.6 1.8.4 6.1.7 1.8.5 6.1.9 1.8.6 6.1.10 1.8.7 6.1.11 1.8.8 6.1.14 1.8.9 new 1.8.10 new 1.8.11 new 1.9.1 new 1.9.2 new 1.10.1 new 1.10.2 new 1.10.3 new 1.10.4 new 1.10.5 new 1.10.6 new 1.10.7 new 1.10.8 new 1.10.9 new 1.10.10 new 1.10.11 new 1.10.12 new 1.11.1 1.15.1 1.11.2 1.15.3 1.11.3 1.15.5 1.11.4 1.15.6 1.11.5 1.15.7 1.11.6 1.15.8 1.11.7 1.15.9 1.11.8 1.15.10 1.11.9 1.15.13 2.1.1 3.1.1 2.1.2 3.1.2 2.1.3 3.1.3 2.1.4 3.1.5 2.1.5 3.1.6 2.1.6 new 2.1.7 3.1.7 2.1.8 2.9.3 2.1.9 2.9.4 2.2.1 3.2.1 2.2.2 3.2.2 2.2.3 3.2.4 2.2.4 3.2.5 2.2.5 3.2.6 2.2.6 3.2.8 2.2.7 3.2.9 2.2.8 3.2.10 CHAPTER 4. CORRELATION, EXERCISE PLACEMENT 400 Source of Exercises in Seventh Edition (continued) 7th 6th 7th 6th 7th 6th 2.2.9 3.2.11 2.2.10 3.2.12 2.2.11 3.2.13 2.2.12 3.2.15 2.2.13 3.2.18 2.2.14 3.2.23 2.2.15 3.2.24 2.2.16 3.2.25 2.2.17 3.2.26 2.2.18 3.2.28 2.2.19 3.2.30 2.2.20 3.2.32 2.2.21 3.2.34 2.2.22 3.2.35 2.2.23 3.2.36 2.2.24 3.2.38 2.2.25 3.2.39 2.2.26 3.3.1 2.2.27 3.3.2 2.2.28 3.3.8 2.2.29 3.3.12 2.2.30 3.4.1 2.2.31 3.4.2 2.2.32 3.4.3 2.2.33 3.4.4 2.2.34 3.4.5 2.2.35 3.4.6 2.2.36 3.4.7 2.2.37 3.4.9 2.2.38 3.4.10 2.2.39 3.4.15 2.2.40 new 2.2.41 new 2.2.42 3.4.16 2.2.43 3.4.19 2.2.44 3.4.20 2.2.45 3.4.22 2.2.46 3.4.23 2.2.47 3.4.24 2.2.48 new 2.2.49 new 2.2.50 new 2.2.51 3.4.26 3.2.1 1.4.6 3.2.2 1.4.7 3.2.3 1.4.8 3.2.4 1.4.9 3.2.5 1.4.10 3.2.6 1.4.15 3.2.7 1.4.16 3.2.8 1.5.4 3.2.9 1.5.7 3.2.10 1.5.8 3.2.11 1.5.9 3.2.12 1.5.10 3.2.13 1.5.12 3.2.14 1.5.13 3.2.15 1.5.18 3.3.1 3.3.16 3.3.2 1.1.10 3.3.3 3.3.13 3.3.4 new 3.3.5 new 3.4.1 3.3.4 3.4.2 3.3.5 3.4.3 3.3.6 3.4.4 3.3.7 3.4.5 2.5.4 3.5.1 1.6.1 3.5.2 1.6.2 3.5.3 1.6.3 3.5.4 1.6.4 3.5.5 1.6.5 3.5.6 1.7.1 3.5.7 1.7.2 3.5.8 1.7.3 3.5.9 1.7.5 3.5.10 1.8.7 3.5.11 1.8.8 3.5.12 1.8.9 3.5.13 new 3.6.1 1.8.2 3.6.2 1.8.3 3.6.3 1.8.4 3.6.4 1.8.5 3.6.5 1.8.11 3.6.6 1.8.12 3.6.7 1.8.13 3.6.8 1.8.14 3.6.9 1.8.15 3.6.10 1.9.1 3.6.11 1.9.3 3.6.12 1.9.4 3.6.13 1.9.5 3.6.14 1.9.7 3.6.15 1.9.8 3.6.16 1.9.12 3.6.17 1.9.13 3.6.18 3.2.16 3.6.18 3.2.17 3.7.1 1.4.13 3.7.2 1.10.2 3.7.3 1.10.3 3.7.4 1.10.4 3.7.5 1.10.5 3.8.1 1.11.1 3.8.2 1.11.2 3.8.3 1.11.3 3.8.4 1.11.7 3.8.5 1.11.8 3.8.6 1.12.1 3.8.7 1.12.2 3.8.8 1.12.3 3.8.9 1.12.9 3.8.10 1.12.10 3.8.11 new 3.8.12 new 3.8.13 new 3.9.1 1.13.1 3.9.2 1.13.2 CHAPTER 4. CORRELATION, EXERCISE PLACEMENT 401 Source of Exercises in Seventh Edition (continued) 7th 6th 7th 6th 7th 6th 3.9.3 1.13.4 3.9.4 1.13.5 3.9.5 1.13.6 3.9.6 1.13.7 3.9.7 1.13.8 3.9.8 1.13.9 3.9.9 1.14.3 3.9.10 1.14.4 3.9.11 new 3.9.12 new 3.10.1 2.1.3 3.10.2 2.1.4 3.10.3 2.2.1 3.10.4 2.2.2 3.10.5 2.2.3 3.10.6 2.4.1 3.10.7 2.4.2 3.10.8 2.4.3 3.10.9 2.4.4 3.10.10 2.4.5 3.10.11 2.4.6 3.10.12 2.4.7 3.10.13 2.4.8 3.10.14 2.4.10 3.10.15 2.4.12 3.10.16 2.4.13 3.10.17 2.4.15 3.10.18 2.5.1 3.10.19 2.5.5 3.10.20 new 3.10.21 new 3.10.22 2.5.2 3.10.23 2.5.3 3.10.24 2.5.7 3.10.25 2.5.8 3.10.26 2.5.9 3.10.27 2.5.10 3.10.28 2.5.12 3.10.29 2.5.13 3.10.30 2.5.14 3.10.31 2.5.15 3.10.32 2.5.16 3.10.33 2.5.17 3.10.34 2.5.18 3.10.35 2.5.20 3.10.36 2.5.21 3.10.37 1.8.16 4.1.1 2.6.1 4.1.2 2.6.2 4.1.3 2.6.3 4.1.4 2.6.4 4.1.5 2.6.5 4.1.6 2.6.6 4.1.7 2.7.1 4.1.8 2.7.2 4.1.9 2.7.3 4.1.10 2.8.1 4.1.11 2.8.2 4.2.1 2.9.1 4.2.2 2.9.2 4.2.3 2.9.7 4.2.4 2.9.9 4.2.5 2.9.10 4.2.6 2.9.11 4.2.7 2.9.12 4.3.1 2.10.3 4.3.2 2.10.5 4.3.3 new 4.3.4 new 4.3.5 2.10.6 4.3.6 2.10.9 4.3.7 2.10.10 4.3.8 2.10.11 4.3.9 2.10.12 4.3.10 2.10.15 4.3.11 2.11.2 4.3.12 2.11.3 4.4.1 1.6.5 4.4.2 2.1.5 4.4.3 new 4.5.1 new 4.5.2 4.8.2 4.6.1 new 4.6.2 new 4.6.3 new 4.7.1 new 4.7.2 4.8.5 4.7.3 4.8.11 5.1.1 10.4.1 5.1.2 10.4.2 5.1.3 10.4.3 5.1.4 10.4.4 5.1.5 10.4.5 5.1.6 10.4.7 5.1.7 new 5.1.8 new 5.1.9 new 5.1.10 new 5.1.11 new 5.1.12 new 5.2.1 10.3.2 5.2.2 10.3.3 5.2.3 10.3.4 5.2.4 10.3.5 5.2.5 10.3.6 5.2.6 10.3.7 5.2.7 10.3.8 5.2.8 new 5.3.1 new 5.3.2 10.1.13 5.3.3 new 5.3.4 new 5.4.1 10.1.12 5.4.2 10.1.14 5.4.3 10.1.15 5.4.4 10.1.16 5.4.5 new 5.5.1 new 5.5.2 new 5.5.3 new CHAPTER 4. CORRELATION, EXERCISE PLACEMENT 402 Source of Exercises in Seventh Edition (continued) 7th 6th 7th 6th 7th 6th 5.5.4 new 5.5.5 new 5.6.1 new 5.6.2 new 5.6.3 new 5.7.1 new 5.7.2 new 5.7.3 new 6.2.1 3.5.16 6.2.2 3.5.17 6.2.3 3.5.18 6.2.4 3.5.19 6.2.5 3.5.20 6.2.6 3.5.21 6.2.7 3.5.22 6.2.8 3.5.23 6.2.9 3.5.24 6.2.10 3.5.25 6.2.11 3.5.26 6.2.12 3.5.27 6.2.13 3.5.28 6.2.14 3.5.29 6.2.15 3.5.33 6.4.1 3.5.2 6.4.2 3.5.3 6.4.3 3.5.4 6.4.4 3.5.5 6.4.5 3.5.6 6.4.6 3.5.7 6.4.7 3.5.9 6.4.8 3.5.10 6.4.9 new 6.5.1 3.6.2 6.5.2 3.6.3 6.5.3 3.6.4 6.5.4 3.6.5 6.5.5 3.6.6 6.5.6 3.6.7 6.5.7 3.6.8 6.5.8 3.6.9 6.5.9 3.6.10 6.5.10 3.6.11 6.5.11 3.6.12 6.5.12 3.6.13 6.5.13 3.6.14 6.5.14 3.6.15 6.5.15 3.4.12 6.5.15 3.6.16 6.5.16 3.6.17 6.5.17 3.6.18 6.5.18 3.6.19 6.5.19 3.6.20 6.5.20 3.6.21 6.5.21 new 7.2.1 9.2.1 7.2.2 9.2.2 7.2.3 9.2.3 7.2.4 9.2.4 7.2.5 9.2.5 7.2.6 9.2.6 7.2.7 9.2.7 7.2.8 9.2.8 7.2.9 9.2.9 7.2.10 9.2.10 7.2.11 9.2.11 7.2.12 9.2.12 7.2.13 9.2.13 7.2.14 9.2.14 7.2.15 9.2.15 7.2.16 9.2.18 7.2.17 new 7.2.18 new 7.3.1 new 7.3.2 new 7.3.3 new 7.3.4 new 7.4.1 9.4.1 7.4.2 9.4.2 7.4.3 new 7.4.4 new 7.4.5 9.4.3 7.5.1 9.5.1 7.5.2 9.5.2 7.5.3 9.5.3 7.5.4 9.5.4 7.5.5 9.5.10 7.5.6 9.5.11 7.5.7 9.5.12 7.5.8 9.5.13 7.5.9 9.5.14 7.5.10 9.5.16 7.5.11 9.5.17 7.5.12 9.5.18 7.5.13 9.5.19 7.6.1 9.6.1 7.6.2 9.6.2 7.6.3 9.6.3 7.6.4 9.6.4 7.6.5 9.6.5 7.6.6 9.6.6 7.6.7 9.6.7 7.6.8 9.6.8 7.6.9 9.6.9 7.6.10 9.6.10 7.6.11 10.1.4 7.6.12 9.6.11 7.6.13 9.6.12 7.6.14 9.6.13 7.6.15 9.6.14 7.6.16 9.6.15 7.6.17 9.6.16 7.6.18 9.6.17 7.6.19 9.6.18 7.6.20 9.6.19 7.6.21 9.6.20 7.6.22 9.6.21 7.6.23 9.6.22 7.6.24 9.6.23 7.6.25 9.6.24 7.6.26 9.6.26 CHAPTER 4. CORRELATION, EXERCISE PLACEMENT 403 Source of Exercises in Seventh Edition (continued) 7th 6th 7th 6th 7th 6th 7.7.1 9.6.25 7.7.2 new 7.7.3 new 7.7.4 new 7.7.5 new 7.8.1 new 7.8.2 new 7.8.3 new 7.8.4 new 8.2.1 10.1.1 8.2.2 10.1.2 8.2.3 10.1.3 8.2.4 10.1.10 8.2.5 10.2.1 8.2.6 10.2.3 8.2.7 10.2.4 8.2.8 10.2.6 8.2.9 10.2.7 8.2.10 10.2.9 8.3.1 9.5.5 8.3.2 new 8.3.3 9.5.6 8.3.4 9.5.7 8.3.5 9.5.8 8.3.6 9.5.9 8.4.1 new 9.2.1 new 9.2.2 new 9.2.3 new 9.2.4 new 9.2.5 new 9.2.6 new 9.3.1 new 9.4.1 9.3.1 9.4.2 9.3.2 9.4.3 9.3.3 9.4.4 9.3.4 9.4.5 9.3.5 9.4.6 9.3.8 9.4.7 9.3.9 9.5.1 9.3.10 9.5.2 9.3.11 9.5.3 new 9.6.1 new 9.6.2 new 9.6.3 new 9.6.4 new 9.7.1 9.3.6 9.7.2 9.3.7 9.7.3 new 9.7.4 new 10.1.1 10.5.1 10.1.2 10.5.2 10.1.3 new 10.1.4 new 10.1.5 10.5.8 10.1.6 10.5.9 10.1.7 new 10.1.8 10.5.10 10.1.9 10.5.11 10.1.10 10.5.12 10.1.11 16.1.2 10.1.12 16.1.4 10.1.13 9.7.7 10.2.1 new 10.2.2 new 10.2.3 9.7.2 10.2.4 9.7.3 10.2.5 9.7.4 10.2.6 new 10.2.7 9.7.6 11.2.1 6.2.2 11.2.2 6.2.3 11.2.3 6.2.5 11.2.4 6.2.6 11.2.5 new 11.2.6 new 11.2.7 6.2.8 11.2.8 6.2.9 11.2.9 new 11.2.10 new 11.2.11 6.2.10 11.2.12 6.2.12 11.3.1 6.3.1 11.3.2 6.3.2 11.3.3 new 11.3.4 new 11.3.5 new 11.3.6 6.3.3 11.3.7 6.3.4 11.4.1 6.4.2 11.4.2 6.4.4 11.4.3 6.4.5 11.4.4 6.4.6 11.4.5 6.4.7 11.4.6 new 11.4.7 new 11.4.8 new 11.4.9 new 11.5.1 6.5.1 11.5.2 6.5.2 11.5.3 6.5.3 11.5.4 6.5.4 11.5.5 6.5.9 11.5.6 new 11.5.7 new 11.5.8 new 11.6.1 6.6.5 11.6.2 6.7.4 11.6.3 6.6.2 11.6.4 new 11.6.5 new 11.6.6 new 11.6.7 6.7.5 11.6.8 6.7.7 11.6.9 6.7.8 11.6.10 6.5.10 11.6.11 6.5.11 11.7.1 7.1.1 11.7.2 new CHAPTER 4. CORRELATION, EXERCISE PLACEMENT 404 Source of Exercises in Seventh Edition (continued) 7th 6th 7th 6th 7th 6th 11.7.3 new 11.7.4 new 11.7.5 new 11.7.6 new 11.7.7 new 11.7.8 new 11.7.9 new 11.7.10 7.1.3 11.7.11 7.1.4 11.7.12 7.1.5 11.8.1 7.1.7 11.8.2 7.1.8 11.8.3 7.1.9 11.8.4 new 11.8.5 7.1.10 11.8.6 new 11.8.7 new 11.8.8 7.1.11 11.8.9 7.1.12 11.8.10 new 11.8.11 7.1.13 11.8.12 7.1.14 11.8.13 7.1.15 11.8.14 7.1.16 11.8.15 7.1.20 11.8.16 7.1.21 11.8.17 new 11.8.18 7.1.17 11.8.19 new 11.8.20 7.1.18 11.8.21 7.1.26 11.8.22 7.1.24 11.8.23 7.1.25 11.8.24 7.1.19 11.8.25 new 11.8.26 7.1.22 11.8.27 new 11.8.28 new 11.9.1 new 11.9.2 new 11.9.3 new 11.9.4 new 11.9.5 new 11.9.6 new 11.9.7 new 11.9.8 new 11.10.1 6.5.5 11.10.2 6.5.6 11.10.3 6.5.7 11.10.4 6.7.1 11.10.5 6.7.2 11.10.6 new 11.10.7 new 12.1.1 new 12.1.2 new 12.1.3 new 12.1.4 new 12.1.5 7.1.6 12.1.6 5.6.10 12.1.7 new 12.2.1 new 12.2.2 5.9.2 12.2.3 5.9.1 12.3.1 5.9.5 12.3.2 5.10.11 12.4.1 5.9.6 12.4.2 5.9.11 12.4.3 5.9.12 12.4.4 5.9.15 12.4.5 5.9.10 12.4.6 5.9.17 12.4.7 5.9.18 12.5.1 5.11.1 12.5.2 5.11.2 12.5.3 5.11.3 12.5.4 5.11.4 12.5.5 5.11.5 12.5.6 5.11.6 12.5.7 5.11.8 12.5.8 5.11.9 12.5.9 new 12.5.10 5.11.7 12.6.1 5.10.2 12.6.2 5.10.3 12.6.3 5.10.4 12.6.4 5.10.5 12.6.5 5.10.6 12.6.6 5.10.7 12.6.7 5.10.8 12.7.1 new 12.7.2 7.3.2 12.7.3 7.3.6 12.8.1 7.2.1 12.8.2 7.2.2 12.8.3 7.2.3 12.8.4 7.2.4 12.8.5 7.2.5 12.8.6 7.2.6 12.8.7 7.2.7 12.8.8 7.2.8 13.1.1 8.1.1 13.1.2 8.1.2 13.1.3 8.1.4 13.1.4 8.1.5 13.1.5 8.1.6 13.1.6 8.1.7 13.1.7 8.1.8 13.1.8 8.1.9 13.1.9 8.1.10 13.1.10 8.1.11 13.1.11 8.1.14 13.1.12 8.1.15 13.1.13 8.1.16 13.1.14 8.1.17 13.1.15 8.2.7 13.1.16 8.1.19 13.1.17 8.1.20 13.1.18 8.1.21 13.1.19 8.1.22 13.1.20 8.1.23 CHAPTER 4. CORRELATION, EXERCISE PLACEMENT 405 Source of Exercises in Seventh Edition (continued) 7th 6th 7th 6th 7th 6th 13.1.21 8.1.24 13.1.22 8.1.25 13.1.23 8.1.26 13.2.1 5.9.13 13.2.2 5.9.14 13.2.3 8.2.1 13.2.4 8.2.2 13.2.5 8.2.3 13.2.6 8.2.4 13.2.7 8.2.5 13.2.8 8.2.6 13.2.9 8.2.8 13.2.10 8.2.9 13.2.11 8.2.11 13.2.12 8.2.12 13.2.13 8.2.13 13.2.14 8.2.19 13.2.15 8.2.20 13.3.1 8.4.2 13.3.2 8.4.3 13.3.3 8.4.4 13.3.4 8.4.5 13.3.5 8.4.6 13.3.6 8.4.7 13.3.7 8.4.8 13.3.8 8.4.9 13.3.9 8.4.10 13.3.10 8.4.11 13.3.11 8.4.12 13.3.12 8.4.13 13.3.13 8.4.14 13.3.14 8.4.15 13.3.15 8.4.16 13.3.16 8.4.17 13.3.17 8.4.18 13.4.1 8.3.1 13.4.2 8.3.2 13.4.3 8.3.4 13.4.4 8.3.6 13.4.5 8.3.7 13.4.6 8.3.8 13.4.7 8.3.9 13.4.8 new 13.5.1 new 13.5.2 5.9.8 13.5.3 5.9.9 13.5.4 5.9.16 13.5.5 8.2.14 13.5.6 8.2.15 13.5.7 8.2.17 13.5.8 8.2.16 13.5.9 8.2.18 13.5.10 8.2.22 13.6.1 8.5.1 13.6.2 8.5.2 13.6.3 8.5.3 13.6.4 new 13.6.5 5.2.18 13.6.6 new 13.6.7 8.5.4 13.6.8 8.5.5 13.6.9 8.5.6 13.6.10 8.5.7 13.6.11 8.5.8 13.6.12 8.5.9 13.6.13 8.5.10 13.6.14 8.5.11 13.6.15 8.5.12 13.6.16 new 14.1.1 11.1.1 14.1.2 11.1.2 14.1.3 11.1.3 14.1.4 new 14.1.5 11.1.4 14.1.6 11.1.5 14.1.7 11.1.6 14.1.8 11.1.7 14.1.9 11.1.8 14.1.10 11.1.10 14.1.11 11.1.11 14.1.12 11.1.12 14.1.13 11.1.13 14.1.14 11.1.14 14.1.15 11.1.16 14.1.16 11.1.17 14.1.17 11.1.18 14.1.18 11.1.19 14.1.19 11.1.20 14.1.20 11.1.21 14.1.21 new 14.1.22 11.1.23 14.1.23 11.1.24 14.1.24 11.1.25 14.1.25 11.1.26 14.1.26 new 14.1.27 11.1.27 14.1.28 11.1.29 14.1.29 11.1.30 14.2.1 11.2.1 14.2.2 11.2.3 14.2.3 11.2.4 14.2.4 11.2.5 14.2.5 11.2.6 14.2.6 11.2.7 14.2.7 11.2.9 14.2.8 11.2.10 14.2.9 11.2.11 14.3.1 11.3.1 14.3.2 11.3.2 14.3.3 11.3.3 14.3.4 11.3.4 14.3.5 11.3.5 14.3.6 11.3.6 14.3.7 11.3.7 14.3.8 new 14.3.9 new 14.3.10 11.3.11 14.4.1 11.4.1 14.4.2 11.4.2 14.4.3 new CHAPTER 4. CORRELATION, EXERCISE PLACEMENT 406 Source of Exercises in Seventh Edition (continued) 7th 6th 7th 6th 7th 6th 14.4.4 11.4.3 14.4.5 11.4.4 14.4.6 11.4.5 14.4.7 11.4.6 14.4.8 11.4.7 14.5.1 11.5.1 14.5.2 11.5.2 14.5.3 11.5.3 14.5.4 11.5.4 14.5.5 11.5.5 14.5.6 11.5.6 14.5.7 11.5.7 14.5.8 11.5.8 14.5.9 new 14.5.10 11.5.9 14.5.11 11.5.10 14.5.12 new 14.5.13 11.5.11 14.5.14 11.5.14 14.5.15 11.5.15 14.5.16 11.5.18 14.6.1 7.3.4 14.6.2 7.3.5 14.6.3 11.5.13 14.6.4 new 14.6.5 new 14.6.6 11.6.2 14.6.7 11.6.3 14.6.8 new 14.6.9 11.6.4 14.6.10 11.6.5 14.6.11 7.3.1 14.6.12 7.3.3 14.6.13 11.6.6 14.7.1 new 14.7.2 11.7.1 14.7.3 11.7.2 14.7.4 11.7.3 14.7.5 11.7.4 14.7.6 11.7.5 14.7.7 11.7.6 14.7.8 11.7.7 14.7.9 11.7.8 14.7.10 new 14.7.11 11.7.9 14.7.12 11.7.10 14.7.13 11.7.11 14.7.14 11.7.13 14.7.15 11.7.14 14.7.16 11.7.16 14.7.17 11.7.20 15.1.1 new 15.1.2 new 15.1.3 12.1.8 15.1.4 new 15.1.5 12.2.1 15.1.6 12.2.2 15.1.7 12.2.3 15.1.8 12.2.7 15.1.9 12.2.8 15.1.10 12.2.9 15.1.11 12.3.7 15.1.12 12.3.8 15.1.13 12.4.1 15.1.14 12.4.3 15.1.15 12.4.4 15.1.16 12.4.5 15.1.17 12.4.6 15.1.18 12.4.13 15.2.1 12.4.2 15.2.2 12.3.1 15.2.3 12.3.2 15.2.4 12.3.3 15.2.5 12.3.4 15.2.6 12.3.5 15.2.7 12.3.6 15.2.8 12.3.9 15.2.9 12.3.10 15.2.10 12.3.12 15.2.11 12.3.13 15.2.12 12.3.15 15.2.13 12.3.16 15.2.14 12.3.17 15.2.15 12.3.19 15.2.16 12.3.20 15.2.17 12.3.21 15.2.18 12.3.22 15.2.19 12.3.23 15.2.20 12.3.24 15.2.21 12.3.25 15.2.22 12.3.26 15.2.23 12.3.27 15.2.24 12.4.7 15.2.25 12.4.8 15.2.26 12.4.9 15.2.27 12.4.10 15.3.1 12.1.1 15.3.2 12.1.2 15.3.3 12.1.3 15.3.4 12.1.4 15.3.5 12.2.5 15.3.6 12.1.5 15.3.7 12.2.4 15.3.8 12.1.6 15.4.1 new 15.4.2 new 15.4.3 12.5.1 15.4.4 12.5.2 15.4.5 12.5.3 15.4.6 new 15.4.7 12.5.4 15.4.8 12.5.5 15.4.9 12.5.6 15.4.10 12.5.7 15.4.11 12.5.8 15.4.12 12.5.9 15.4.13 12.5.10 15.4.14 12.5.11 15.4.15 12.5.12 15.4.16 12.5.13 CHAPTER 4. CORRELATION, EXERCISE PLACEMENT 407 Source of Exercises in Seventh Edition (continued) 7th 6th 7th 6th 7th 6th 15.4.17 1.8.17 15.4.18 12.5.14 15.4.19 12.5.15 15.4.20 12.5.16 15.5.1 12.6.1 15.5.2 12.6.2 15.5.3 12.6.3 15.5.4 12.6.5 15.5.5 12.6.6 15.5.6 12.6.9 15.5.7 12.6.10 15.6.1 12.10.1 15.6.2 12.10.3 15.6.3 12.10.4 15.6.4 12.10.6 16.1.1 12.6.7 16.1.2 12.6.8 16.1.3 12.7.1 16.1.4 new 16.1.5 12.7.2 16.1.6 12.7.3 16.1.7 12.7.4 16.1.8 12.7.5 16.2.1 4.4.1 16.2.2 4.4.2 16.2.3 new 16.2.4 new 16.2.5 new 16.3.1 4.4.4 16.3.2 12.8.1 16.3.3 12.8.2 16.3.4 12.8.3 16.3.5 12.8.4 16.3.6 12.8.5 16.3.7 12.8.6 16.3.8 12.8.7 16.3.9 12.8.9 16.3.10 12.9.1 16.3.11 12.9.2 16.3.12 12.9.3 16.4.1 12.11.1 16.4.2 12.11.2 16.4.3 12.11.3 16.4.4 12.11.4 16.4.5 12.11.5 16.4.6 12.11.6 17.1.1 new 17.1.2 new 17.1.3 4.7.4 17.1.4 4.7.8 17.1.5 4.7.9 17.1.6 4.7.21 17.1.7 4.7.20 17.2.1 new 17.2.2 new 17.2.3 new 17.2.4 4.7.10 17.2.5 4.7.17 17.2.6 4.7.18 17.3.1 new 17.4.1 new 17.4.2 4.7.13 17.4.3 new 17.4.4 new 17.4.5 new 17.4.6 new 17.5.1 new 17.6.1 4.7.15 17.6.2 4.7.14 17.6.3 new 17.7.1 4.2.3 17.7.2 new 17.7.3 new 17.7.4 new 17.8.1 new 17.8.2 new 17.8.3 new 17.9.1 new 17.9.2 new 18.1.1 13.1.1 18.1.2 13.1.2 18.1.3 13.1.4 18.1.4 13.1.5 18.1.5 13.1.6 18.1.6 13.1.7 18.1.7 13.1.13 18.2.1 13.1.3 18.2.2 13.1.8 18.2.3 13.1.9 18.2.4 13.1.10 18.2.5 13.1.11 18.2.6 13.1.12 18.2.7 13.1.14 18.2.8 13.1.15 18.3.1 13.2.1 18.3.2 13.2.2 18.3.3 13.2.4 18.3.4 13.2.5 18.3.5 13.2.6 18.3.6 13.2.7 18.3.7 13.2.8 18.3.8 13.2.9 18.3.9 13.2.10 18.3.10 13.2.21 18.4.1 new 18.4.2 new 18.4.3 13.3.1 18.4.4 13.3.2 18.4.5 13.3.3 18.4.6 13.3.4 18.4.7 13.3.5 18.4.8 13.3.6 18.4.9 13.3.7 18.4.10 13.3.8 18.4.11 13.3.9 18.4.12 13.3.10 18.4.13 13.3.12 18.4.14 new 18.4.15 13.3.13 18.4.16 13.3.14 CHAPTER 4. CORRELATION, EXERCISE PLACEMENT 408 Source of Exercises in Seventh Edition (continued) 7th 6th 7th 6th 7th 6th 18.4.17 13.3.15 18.4.18 13.3.16 18.4.19 13.3.17 18.4.20 13.3.18 18.4.21 13.3.19 18.4.22 13.3.20 18.4.23 13.3.21 18.4.24 13.3.22 18.4.25 13.3.27 18.4.26 13.3.28 18.4.27 13.3.29 18.4.28 13.3.30 18.5.1 13.4.1 18.5.2 13.4.2 18.5.3 13.4.3 18.5.4 13.4.4 18.5.5 13.4.5 18.5.6 13.4.6 18.5.7 13.4.7 18.5.8 13.4.8 18.5.9 13.4.9 18.5.10 13.3.11 18.5.11 new 18.5.12 13.4.10 18.6.1 13.5.1 18.6.2 13.5.2 18.6.3 13.5.3 18.6.4 13.5.4 18.6.5 13.5.5 18.6.6 13.5.6 18.6.7 13.5.7 18.6.8 13.5.8 18.6.9 13.5.9 18.6.10 13.5.10 18.6.11 13.5.11 18.6.12 13.5.12 18.6.13 13.5.13 18.6.14 13.5.14 18.6.15 13.5.15 18.6.16 13.5.16 18.6.17 13.5.17 18.7.1 new 18.7.2 new 18.7.3 new 18.7.4 new 18.7.5 new 18.7.6 new 18.8.1 5.8.1 18.8.2 5.8.2 18.8.3 5.8.3 18.8.4 5.8.4 18.8.5 5.8.5 18.8.6 5.8.6 19.1.1 14.1.1 19.1.2 14.1.2 19.1.3 14.1.3 19.1.4 14.1.4 19.1.5 14.1.5 19.1.6 14.1.6 19.1.7 14.1.7 19.1.8 14.1.9 19.1.9 14.2.2 19.1.10 14.2.3 19.1.11 14.3.12 19.1.12 14.4.1 19.1.13 14.4.2 19.1.14 14.4.13 19.1.15 14.4.14 19.1.16 14.4.15 19.2.1 14.3.8 19.2.2 14.3.10 19.2.3 14.3.1 19.2.4 14.4.3 19.2.5 new 19.2.6 14.3.1 19.2.7 14.3.2 19.2.8 14.3.3 19.2.9 14.3.4 19.2.10 14.3.5 19.2.11 14.3.6 19.2.12 14.3.7 19.2.13 14.3.14 19.2.14 14.4.4 19.2.15 14.4.5 19.2.16 14.4.6 19.2.17 14.4.7 19.2.18 14.4.8 19.2.19 14.4.9 19.2.20 14.4.10 19.2.21 14.4.11 19.3.1 14.5.1 19.3.2 14.5.2 19.3.3 14.5.4 20.2.1 15.3.1 20.2.2 15.3.3 20.2.3 15.3.4 20.2.4 15.3.5 20.2.5 15.3.6 20.2.6 15.3.7 20.2.7 15.3.8 20.2.8 15.3.9 20.2.9 15.3.10 20.2.10 15.3.11 20.2.11 15.3.18 20.2.12 15.3.19 20.2.13 15.3.21 20.2.14 new 20.2.15 15.1.1 20.2.16 15.3.20 20.3.1 new 20.3.2 new 20.3.3 new 20.3.4 new 20.3.5 new 20.3.6 15.4.3 20.4.1 15.5.1 20.4.2 15.5.3 20.4.3 15.5.5 20.4.4 15.5.6 20.4.5 15.5.7 CHAPTER 4. CORRELATION, EXERCISE PLACEMENT 409 Source of Exercises in Seventh Edition (continued) 7th 6th 7th 6th 7th 6th 20.4.6 15.5.8 20.4.7 15.5.9 20.4.8 15.6.8 20.4.9 new 20.4.10 15.6.10 20.4.11 15.6.11 20.5.1 new 20.5.2 new 20.5.3 new 20.5.4 new 20.6.1 14.6.1 20.6.2 14.6.3 20.6.3 14.6.4 20.7.1 15.8.1 20.7.2 15.8.2 20.7.3 15.8.3 20.7.4 15.8.4 20.7.5 15.8.5 20.7.6 15.8.7 20.7.7 15.8.8 20.7.8 15.8.9 20.8.1 15.9.1 20.8.2 15.9.2 20.8.3 15.9.3 20.8.4 15.9.4 20.8.5 15.9.5 20.8.6 15.10.1 20.8.7 15.10.2 20.8.8 15.10.3 20.8.9 15.10.4 20.8.10 15.10.5 20.8.11 15.10.6 20.8.12 15.10.7 20.8.13 15.10.9 20.8.14 15.10.10 20.8.15 15.10.11 20.8.16 15.10.12 20.8.17 15.10.13 20.8.18 15.10.14 20.8.19 15.10.15 20.8.20 15.10.16 20.8.21 15.10.17 20.8.22 15.10.18 20.8.23 15.10.19 20.8.24 15.10.20 20.9.1 15.11.1 20.9.2 15.11.2 20.9.3 15.11.3 20.9.4 15.11.4 20.10.1 15.12.1 20.10.2 15.12.2 20.10.3 15.12.3 20.10.4 15.12.4 20.10.5 15.12.5 20.10.6 15.12.6 20.10.7 15.12.7 20.10.8 15.12.8 20.10.9 15.12.9 20.10.10 15.12.10 20.10.11 15.12.11 20.10.12 15.12.12 20.10.13 15.12.13 21.1.1 16.1.1 21.1.2 16.1.3 21.1.3 16.1.6 21.1.4 16.1.7 21.2.1 16.2.1 21.2.2 16.2.2 21.2.2 16.2.3 21.2.3 16.2.4 21.2.4 16.2.5 21.2.5 16.2.6 21.2.6 16.2.7 21.2.7 16.2.8 21.2.8 16.2.9 21.2.9 16.2.10 21.2.10 16.3.3 21.2.11 16.3.4 21.2.12 16.3.5 21.2.13 16.3.8 21.2.14 16.3.11 21.2.15 16.3.12 21.2.16 16.3.15 21.2.17 16.2.11 21.3.1 16.3.1 21.3.2 16.3.7 21.3.3 16.3.9 21.3.4 16.3.10 21.4.1 16.4.1 21.4.2 16.4.8 21.4.3 16.4.2 21.4.4 16.4.3 21.4.5 16.4.4 21.4.6 16.4.5 21.4.7 16.4.6 21.4.8 16.4.7 22.1.1 17.1.1 22.1.2 17.1.2 22.1.3 17.1.3 22.1.4 17.1.4 22.1.5 17.1.5 22.1.6 new 22.1.7 17.2.1 22.1.8 17.2.2 22.1.9 17.2.3 22.1.10 17.2.4 22.1.11 17.2.5 22.1.12 17.2.6 22.1.13 17.2.7 22.1.14 17.2.8 22.1.15 17.2.12 22.2.1 17.3.1 22.2.2 17.3.2 22.2.3 17.3.3 22.2.4 17.3.4 22.2.5 17.3.5 22.2.6 17.3.6 22.2.7 17.3.7 22.2.8 17.4.1 22.2.9 17.4.2 CHAPTER 4. CORRELATION, EXERCISE PLACEMENT 410 Source of Exercises in Seventh Edition (continued) 7th 6th 7th 6th 7th 6th 22.2.10 17.5.1 22.3.1 17.6.1 22.3.2 17.6.3 22.3.3 17.6.4 22.3.4 17.6.5 22.3.5 17.6.6 22.3.6 17.6.7 22.3.7 17.6.9 22.4.1 17.7.1 22.4.2 17.7.2 22.4.3 17.7.3 22.4.4 17.7.4 22.4.5 17.7.5 22.4.6 17.7.7 22.4.7 17.8.2 22.4.8 17.8.3 22.4.9 17.8.4 22.4.10 17.8.5 22.4.11 17.8.6 23.1.1 19.1.1 23.1.2 19.1.2 23.1.3 19.1.3 23.1.4 19.1.4 23.1.5 19.1.5 23.1.6 19.1.6 23.1.7 19.1.7 23.1.8 19.1.8 23.1.9 19.1.9 23.2.1 new 23.2.2 19.2.1 23.2.3 new 23.2.4 19.2.3 23.2.5 19.2.4 23.2.6 19.2.7 23.2.7 19.2.8 23.3.1 19.3.1 23.3.2 19.3.2 23.3.3 19.3.3 23.3.4 19.3.4 23.3.5 19.3.5 23.4.1 19.4.1 23.4.2 19.4.2 23.4.3 19.4.3 23.4.4 19.4.4 23.4.5 19.4.5 23.4.6 19.4.6 23.5.1 new 23.5.2 new 23.5.3 new 23.5.4 19.5.1 23.5.5 19.5.3 23.6.1 19.5.2 23.6.2 19.5.4 23.6.3 19.5.5 23.6.4 19.2.2 23.6.5 19.2.5 23.6.6 19.2.6 23.6.7 new 23.6.8 new 23.7.1 19.6.1 23.7.2 19.6.2 23.7.3 19.6.3 23.7.4 new 31.1.1 new 31.1.2 new 31.1.3 new 31.2.1 new 31.2.2 new 31.2.3 new 31.3.1 new 31.3.2 new 31.3.3 new 32.1.1 new 32.2.1 new 32.2.2 new 32.2.3 new 32.2.4 new 32.2.5 new 32.2.6 new 33.1.1 18.2.1 33.1.2 18.2.2 33.1.3 18.2.3 33.1.4 18.2.4 33.1.5 18.2.5 33.1.6 18.2.6 33.1.7 18.2.7 33.1.8 18.2.9 33.1.9 18.2.10 33.1.10 18.3.2 33.2.1 new 33.2.2 18.4.1 33.3.1 new 33.3.2 new 33.3.3 new 33.4.1 new 33.4.2 new 33.4.3 18.4.2 33.5.1 18.4.3 33.5.2 new 33.5.3 new 33.5.4 new 33.5.5 new 33.5.6 18.4.2 CHAPTER 4. CORRELATION, EXERCISE PLACEMENT 411 New Locations of Sixth Edition Exercises 6th 7th 6th 7th 6th 7th 1.1.1 unused 1.1.2 1.7.1 1.1.3 unused 1.1.4 unused 1.1.5 unused 1.1.6 unused 1.1.7 unused 1.1.8 1.7.2 1.1.9 1.7.3 1.1.10 3.3.2 1.1.11 1.7.4 1.1.12 1.7.5 1.2.1 unused 1.2.2 unused 1.3.1 unused 1.3.2 unused 1.3.3 1.7.6 1.3.4 unused 1.3.5 1.7.7 1.3.6 1.7.8 1.3.7 unused 1.4.1 1.7.9 1.4.2 1.7.10 1.4.3 unused 1.4.4 unused 1.4.5 1.7.11 1.4.6 3.2.1 1.4.7 3.2.2 1.4.8 3.2.3 1.4.9 3.2.4 1.4.10 3.2.5 1.4.11 unused 1.4.12 unused 1.4.13 3.7.1 1.4.14 unused 1.4.15 3.2.6 1.4.16 3.2.7 1.4.17 unused 1.4.18 unused 1.5.1 unused 1.5.2 unused 1.5.3 unused 1.5.4 3.2.8 1.5.5 unused 1.5.6 unused 1.5.7 3.2.9 1.5.8 3.2.10 1.5.9 3.2.11 1.5.10 3.2.12 1.5.11 unused 1.5.12 3.2.13 1.5.13 3.2.14 1.5.14 unused 1.5.15 unused 1.5.16 unused 1.5.17 unused 1.5.18 3.2.15 1.6.1 3.5.1 1.6.2 3.5.2 1.6.3 3.5.3 1.6.4 3.5.4 1.6.5 3.5.5 1.6.5 4.4.1 1.7.1 3.5.6 1.7.2 3.5.7 1.7.3 3.5.8 1.7.4 unused 1.7.5 3.5.9 1.7.6 unused 1.8.1 unused 1.8.2 3.6.1 1.8.3 3.6.2 1.8.4 3.6.3 1.8.5 3.6.4 1.8.6 unused 1.8.7 3.5.10 1.8.8 3.5.11 1.8.9 3.5.12 1.8.10 unused 1.8.11 3.6.5 1.8.12 3.6.6 1.8.13 3.6.7 1.8.14 3.6.8 1.8.15 3.6.9 1.8.16 3.10.37 1.8.17 15.4.17 1.8.18 unused 1.8.19 unused 1.9.1 3.6.10 1.9.2 unused 1.9.3 3.6.11 1.9.4 3.6.12 1.9.5 3.6.13 1.9.6 unused 1.9.7 3.6.14 1.9.8 3.6.15 1.9.9 unused 1.9.10 unused 1.9.11 unused 1.9.12 3.6.16 1.9.13 3.6.17 1.10.1 unused 1.10.2 3.7.2 1.10.3 3.7.3 1.10.4 3.7.4 1.10.5 3.7.5 1.10.6 unused 1.11.1 3.8.1 1.11.2 3.8.2 1.11.3 3.8.3 1.11.4 unused 1.11.5 unused 1.11.6 unused 1.11.7 3.8.4 1.11.8 3.8.5 1.11.9 unused 1.11.10 unused 1.12.1 3.8.6 1.12.2 3.8.7 1.12.3 3.8.8 CHAPTER 4. CORRELATION, EXERCISE PLACEMENT 412 New Locations of Sixth Edition Exercises (continued) 6th 7th 6th 7th 6th 7th 1.12.4 unused 1.12.5 unused 1.12.6 unused 1.12.7 unused 1.12.8 unused 1.12.9 3.8.9 1.12.10 3.8.10 1.13.1 3.9.1 1.13.2 3.9.2 1.13.3 unused 1.13.4 3.9.3 1.13.5 3.9.4 1.13.6 3.9.5 1.13.7 3.9.6 1.13.8 3.9.7 1.13.9 3.9.8 1.13.11 unused 1.14.1 unused 1.14.2 unused 1.14.3 3.9.9 1.14.4 3.9.10 1.15.1 1.11.1 1.15.2 unused 1.15.3 1.11.2 1.15.4 unused 1.15.5 1.11.3 1.15.6 1.11.4 1.15.7 1.11.5 1.15.8 1.11.6 1.15.9 1.11.7 1.15.10 1.11.8 1.15.11 unused 1.15.12 unused 1.15.13 1.11.9 1.15.14 unused 1.15.15 unused 1.15.16 unused 1.15.17 unused 1.15.18 unused 1.15.19 unused 1.15.20 unused 1.15.21 unused 1.15.22 unused 1.15.23 unused 1.15.24 unused 1.16.1 unused 1.16.2 unused 2.1.1 unused 2.1.2 unused 2.1.3 3.10.1 2.1.4 3.10.2 2.1.5 4.4.2 2.1.6 unused 2.2.1 3.10.3 2.2.2 3.10.4 2.2.3 3.10.5 2.2.4 unused 2.4.1 3.10.6 2.4.2 3.10.7 2.4.3 3.10.8 2.4.4 3.10.9 2.4.5 3.10.10 2.4.6 3.10.11 2.4.7 3.10.12 2.4.8 3.10.13 2.4.9 unused 2.4.10 3.10.14 2.4.11 unused 2.4.12 3.10.15 2.4.13 3.10.16 2.4.14 unused 2.4.15 3.10.17 2.4.16 unused 2.4.17 unused 2.5.1 3.10.18 2.5.2 3.10.22 2.5.3 3.10.23 2.5.4 3.4.5 2.5.5 3.10.19 2.5.6 unused 2.5.7 3.10.24 2.5.8 3.10.25 2.5.9 3.10.26 2.5.10 3.10.27 2.5.11 unused 2.5.12 3.10.28 2.5.13 3.10.29 2.5.14 3.10.30 2.5.15 3.10.31 2.5.16 3.10.32 2.5.17 3.10.33 2.5.18 3.10.34 2.5.19 unused 2.5.20 3.10.35 2.5.21 3.10.36 2.5.22 unused 2.5.23 unused 2.5.24 unused 2.5.25 unused 2.6.1 4.1.1 2.6.2 4.1.2 2.6.3 4.1.3 2.6.4 4.1.4 2.6.5 4.1.5 2.6.6 4.1.6 2.7.1 4.1.7 2.7.2 4.1.8 2.7.3 4.1.9 2.8.1 4.1.10 2.8.2 4.1.11 2.8.3 unused 2.9.1 4.2.1 2.9.2 4.2.2 2.9.3 2.1.8 2.9.4 2.1.9 2.9.5 unused 2.9.6 unused 2.9.7 4.2.3 2.9.8 unused 2.9.9 4.2.4 CHAPTER 4. CORRELATION, EXERCISE PLACEMENT 413 New Locations of Sixth Edition Exercises (continued) 6th 7th 6th 7th 6th 7th 2.9.10 4.2.5 2.9.11 4.2.6 2.9.12 4.2.7 2.9.13 unused 2.9.14 unused 2.10.1 unused 2.10.2 unused 2.10.3 4.3.1 2.10.4 unused 2.10.5 4.3.2 2.10.6 4.3.5 2.10.7 unused 2.10.8 unused 2.10.9 4.3.6 2.10.10 4.3.7 2.10.11 4.3.8 2.10.12 4.3.9 2.10.13 unused 2.10.14 unused 2.10.15 4.3.10 2.10.16 unused 2.10.17 unused 2.11.1 unused 2.11.2 4.3.11 2.11.3 4.3.12 3.1.1 2.1.1 3.1.2 2.1.2 3.1.3 2.1.3 3.1.4 unused 3.1.5 2.1.4 3.1.6 2.1.5 3.1.7 2.1.7 3.1.8 unused 3.1.9 unused 3.1.10 unused 3.2.1 2.2.1 3.2.2 2.2.2 3.2.3 unused 3.2.4 2.2.3 3.2.5 2.2.4 3.2.6 2.2.5 3.2.7 unused 3.2.8 2.2.6 3.2.9 2.2.7 3.2.10 2.2.8 3.2.11 2.2.9 3.2.12 2.2.10 3.2.13 2.2.11 3.2.15 2.2.12 3.2.16 3.6.18 3.2.17 3.6.18 3.2.18 2.2.13 3.2.19 unused 3.2.20 unused 3.2.21 unused 3.2.22 unused 3.2.23 2.2.14 3.2.24 2.2.15 3.2.25 2.2.16 3.2.26 2.2.17 3.2.27 unused 3.2.28 2.2.18 3.2.29 unused 3.2.30 2.2.19 3.2.31 unused 3.2.32 2.2.20 3.2.33 unused 3.2.34 2.2.21 3.2.35 2.2.22 3.2.36 2.2.23 3.2.37 unused 3.2.38 2.2.24 3.2.39 2.2.25 3.2.40 unused 3.2.41 unused 3.2.42 unused 3.2.43 unused 3.2.44 unused 3.3.1 2.2.26 3.3.2 2.2.27 3.3.3 unused 3.3.4 3.4.1 3.3.5 3.4.2 3.3.6 3.4.3 3.3.7 3.4.4 3.3.8 2.2.28 3.3.9 unused 3.3.10 unused 3.3.11 unused 3.3.12 2.2.29 3.3.13 3.3.3 3.3.14 unused 3.3.15 unused 3.3.16 3.3.1 3.3.17 unused 3.3.18 unused 3.4.1 2.2.30 3.4.2 2.2.31 3.4.3 2.2.32 3.4.4 2.2.33 3.4.5 2.2.34 3.4.6 2.2.35 3.4.7 2.2.36 3.4.8 unused 3.4.9 2.2.37 3.4.10 2.2.38 3.4.12 6.5.15 3.4.13 unused 3.4.14 unused 3.4.15 2.2.39 3.4.16 2.2.42 3.4.17 unused 3.4.18 unused 3.4.19 2.2.43 3.4.20 2.2.44 3.4.21 unused 3.4.22 2.2.45 3.4.23 2.2.46 3.4.24 2.2.47 3.4.25 unused CHAPTER 4. CORRELATION, EXERCISE PLACEMENT 414 New Locations of Sixth Edition Exercises (continued) 6th 7th 6th 7th 6th 7th 3.4.26 2.2.51 3.4.27 unused 3.4.28 unused 3.4.29 unused 3.5.1 unused 3.5.2 6.4.1 3.5.3 6.4.2 3.5.4 6.4.3 3.5.5 6.4.4 3.5.6 6.4.5 3.5.7 6.4.6 3.5.9 6.4.7 3.5.10 6.4.8 3.5.11 unused 3.5.12 unused 3.5.13 unused 3.5.14 unused 3.5.15 unused 3.5.16 6.2.1 3.5.17 6.2.2 3.5.18 6.2.3 3.5.19 6.2.4 3.5.20 6.2.5 3.5.21 6.2.6 3.5.22 6.2.7 3.5.23 6.2.8 3.5.24 6.2.9 3.5.25 6.2.10 3.5.26 6.2.11 3.5.27 6.2.12 3.5.28 6.2.13 3.5.29 6.2.14 3.5.30 unused 3.5.31 unused 3.5.32 unused 3.5.33 6.2.15 3.6.1 unused 3.6.2 6.5.1 3.6.3 6.5.2 3.6.4 6.5.3 3.6.5 6.5.4 3.6.6 6.5.5 3.6.7 6.5.6 3.6.8 6.5.7 3.6.9 6.5.8 3.6.10 6.5.9 3.6.11 6.5.10 3.6.12 6.5.11 3.6.13 6.5.12 3.6.14 6.5.13 3.6.15 6.5.14 3.6.16 6.5.15 3.6.17 6.5.16 3.6.18 6.5.17 3.6.19 6.5.18 3.6.20 6.5.19 3.6.21 6.5.20 4.1.1 unused 4.1.2 unused 4.1.3 unused 4.1.4 unused 4.1.5 unused 4.2.1 unused 4.2.2 unused 4.2.3 17.7.1 4.2.4 unused 4.2.5 unused 4.2.6 unused 4.3.1 unused 4.3.2 unused 4.4.1 16.2.1 4.4.2 16.2.2 4.4.3 unused 4.4.4 16.3.1 4.4.5 unused 4.4.6 unused 4.4.7 unused 4.4.8 unused 4.4.9 unused 4.5.1 unused 4.5.2 unused 4.5.3 unused 4.6.1 unused 4.6.2 unused 4.6.3 unused 4.6.4 unused 4.6.5 unused 4.6.6 unused 4.6.7 unused 4.6.8 unused 4.6.9 unused 4.6.10 unused 4.6.11 unused 4.6.12 unused 4.6.13 unused 4.6.14 unused 4.7.1 unused 4.7.2 unused 4.7.3 unused 4.7.4 17.1.3 4.7.5 unused 4.7.6 unused 4.7.7 unused 4.7.8 17.1.4 4.7.9 17.1.5 4.7.10 17.2.4 4.7.11 unused 4.7.12 unused 4.7.13 17.4.2 4.7.14 17.6.2 4.7.15 17.6.1 4.7.16 unused 4.7.17 17.2.5 4.7.18 17.2.6 4.7.19 unused 4.7.20 17.1.7 4.7.21 17.1.6 4.7.22 unused 4.8.1 unused 4.8.2 4.5.2 CHAPTER 4. CORRELATION, EXERCISE PLACEMENT 415 New Locations of Sixth Edition Exercises (continued) 6th 7th 6th 7th 6th 7th 4.8.3 unused 4.8.4 unused 4.8.5 4.7.2 4.8.6 unused 4.8.7 unused 4.8.8 unused 4.8.9 unused 4.8.10 unused 4.8.11 4.7.3 4.8.12 unused 4.8.13 unused 4.8.14 unused 4.8.15 unused 5.1.1 unused 5.1.2 unused 5.2.1 1.1.1 5.2.2 1.1.2 5.2.3 unused 5.2.4 1.1.3 5.2.5 1.1.4 5.2.6 1.1.5 5.2.7 1.1.6 5.2.8 1.1.7 5.2.9 unused 5.2.10 unused 5.2.11 unused 5.2.12 1.1.8 5.2.13 1.1.9 5.2.14 1.1.10 5.2.15 1.2.5 5.2.16 1.2.6 5.2.17 1.2.7 5.2.18 13.6.5 5.2.19 unused 5.2.20 1.1.13 5.2.21 1.1.16 5.2.22 1.1.12 5.3.1 unused 5.3.2 unused 5.3.3 unused 5.4.1 1.6.1 5.4.2 unused 5.4.3 1.1.15 5.4.4 unused 5.5.1 1.2.1 5.5.2 1.2.2 5.5.3 1.2.3 5.5.4 1.2.4 5.6.1 1.2.8 5.6.2 1.2.9 5.6.2 unused 5.6.3 unused 5.6.4 1.2.10 5.6.5 1.2.11 5.6.6 unused 5.6.7 unused 5.6.8 1.2.12 5.6.9 1.2.13 5.6.10 12.1.6 5.6.10 unused 5.6.11 1.3.6 5.6.12 1.3.7 5.6.13 1.3.8 5.6.14 1.3.9 5.6.15 1.3.10 5.6.16 1.3.11 5.6.17 1.3.12 5.6.18 1.3.13 5.6.19 1.3.14 5.6.20 1.3.15 5.6.21 1.2.14 5.6.22 unused 5.6.23 unused 5.6.24 unused 5.7.1 1.3.1 5.7.2 unused 5.7.3 unused 5.7.4 unused 5.7.5 unused 5.7.6 1.3.2 5.7.7 1.3.3 5.7.8 unused 5.7.9 1.2.15 5.7.10 unused 5.7.11 1.3.4 5.7.12 unused 5.7.13 1.2.16 5.7.14 unused 5.7.15 1.3.16 5.7.16 1.3.17 5.7.17 1.3.18 5.7.18 unused 5.7.19 unused 5.8.1 18.8.1 5.8.2 18.8.2 5.8.3 18.8.3 5.8.4 18.8.4 5.8.5 18.8.5 5.8.6 18.8.6 5.8.7 unused 5.8.8 unused 5.8.9 unused 5.9.1 12.2.3 5.9.2 12.2.2 5.9.3 unused 5.9.4 unused 5.9.5 12.3.1 5.9.6 12.4.1 5.9.7 unused 5.9.8 13.5.2 5.9.9 13.5.3 5.9.10 12.4.5 5.9.11 12.4.2 5.9.12 12.4.3 5.9.13 13.2.1 5.9.14 13.2.2 5.9.15 12.4.4 5.9.16 13.5.4 5.9.17 12.4.6 5.9.18 12.4.7 CHAPTER 4. CORRELATION, EXERCISE PLACEMENT 416 New Locations of Sixth Edition Exercises (continued) 6th 7th 6th 7th 6th 7th 5.9.19 unused 5.9.20 unused 5.10.1 unused 5.10.2 12.6.1 5.10.3 12.6.2 5.10.4 12.6.3 5.10.5 12.6.4 5.10.6 12.6.5 5.10.7 12.6.6 5.10.8 12.6.7 5.10.9 unused 5.10.10 unused 5.10.11 12.3.2 5.11.1 12.5.1 5.11.2 12.5.2 5.11.3 12.5.3 5.11.4 12.5.4 5.11.5 12.5.5 5.11.6 12.5.6 5.11.6 unused 5.11.7 12.5.10 5.11.8 12.5.7 5.11.9 12.5.8 5.11.10 unused 6.1.1 1.8.1 6.1.2 unused 6.1.3 unused 6.1.4 unused 6.1.5 1.8.2 6.1.6 1.8.3 6.1.7 1.8.4 6.1.8 unused 6.1.9 1.8.5 6.1.9 unused 6.1.10 1.8.6 6.1.11 1.8.7 6.1.12 unused 6.1.13 unused 6.1.14 1.8.8 6.1.15 unused 6.1.16 unused 6.1.17 unused 6.1.18 unused 6.1.19 unused 6.1.20 unused 6.1.21 unused 6.1.22 unused 6.1.23 unused 6.1.24 unused 6.1.25 unused 6.1.26 unused 6.2.1 unused 6.2.2 11.2.1 6.2.3 11.2.2 6.2.5 11.2.3 6.2.6 11.2.4 6.2.7 unused 6.2.8 11.2.7 6.2.9 11.2.8 6.2.10 11.2.11 6.2.11 unused 6.2.12 11.2.12 6.3.1 11.3.1 6.3.2 11.3.2 6.3.3 11.3.6 6.3.4 11.3.7 6.4.2 11.4.1 6.4.4 11.4.2 6.4.5 11.4.3 6.4.6 11.4.4 6.4.7 11.4.5 6.4.8 unused 6.5.1 11.5.1 6.5.2 11.5.2 6.5.3 11.5.3 6.5.4 11.5.4 6.5.5 11.10.1 6.5.6 11.10.2 6.5.7 11.10.3 6.5.8 unused 6.5.9 11.5.5 6.5.10 11.6.10 6.5.11 11.6.11 6.6.1 unused 6.6.2 11.6.3 6.6.3 unused 6.6.4 unused 6.6.5 11.6.1 6.7.1 11.10.4 6.7.2 11.10.5 6.7.3 unused 6.7.4 11.6.2 6.7.5 11.6.7 6.7.6 unused 6.7.7 11.6.8 6.7.8 11.6.9 6.8.1 unused 6.8.2 unused 6.8.3 unused 7.1.1 11.7.1 7.1.2 unused 7.1.3 11.7.10 7.1.4 11.7.11 7.1.5 11.7.12 7.1.6 12.1.5 7.1.7 11.8.1 7.1.8 11.8.2 7.1.9 11.8.3 7.1.10 11.8.5 7.1.11 11.8.8 7.1.12 11.8.9 7.1.13 11.8.11 7.1.14 11.8.12 7.1.15 11.8.13 7.1.16 11.8.14 7.1.17 11.8.18 7.1.18 11.8.20 7.1.19 11.8.24 7.1.20 11.8.15 7.1.21 11.8.16 CHAPTER 4. CORRELATION, EXERCISE PLACEMENT 417 New Locations of Sixth Edition Exercises (continued) 6th 7th 6th 7th 6th 7th 7.1.22 11.8.26 7.1.23 unused 7.1.24 11.8.22 7.1.25 11.8.23 7.1.26 11.8.21 7.1.27 unused 7.1.28 unused 7.2.1 12.8.1 7.2.2 12.8.2 7.2.3 12.8.3 7.2.4 12.8.4 7.2.5 12.8.5 7.2.6 12.8.6 7.2.7 12.8.7 7.2.8 12.8.8 7.2.9 unused 7.3.1 14.6.11 7.3.2 12.7.2 7.3.3 14.6.12 7.3.4 14.6.1 7.3.5 14.6.2 7.3.6 12.7.3 7.3.7 unused 8.1.1 13.1.1 8.1.2 13.1.2 8.1.3 unused 8.1.4 13.1.3 8.1.5 13.1.4 8.1.6 13.1.5 8.1.7 13.1.6 8.1.8 13.1.7 8.1.9 13.1.8 8.1.10 13.1.9 8.1.11 13.1.10 8.1.12 unused 8.1.13 unused 8.1.14 13.1.11 8.1.15 13.1.12 8.1.16 13.1.13 8.1.17 13.1.14 8.1.19 13.1.16 8.1.20 13.1.17 8.1.21 13.1.18 8.1.22 13.1.19 8.1.23 13.1.20 8.1.24 13.1.21 8.1.25 13.1.22 8.1.26 13.1.23 8.1.27 unused 8.1.28 unused 8.1.29 unused 8.1.30 unused 8.2.1 13.2.3 8.2.2 13.2.4 8.2.3 13.2.5 8.2.4 13.2.6 8.2.5 13.2.7 8.2.6 13.2.8 8.2.7 13.1.15 8.2.8 13.2.9 8.2.9 13.2.10 8.2.10 unused 8.2.11 13.2.11 8.2.12 13.2.12 8.2.13 13.2.13 8.2.14 13.5.5 8.2.15 13.5.6 8.2.16 13.5.8 8.2.17 13.5.7 8.2.18 13.5.9 8.2.19 13.2.14 8.2.20 13.2.15 8.2.21 unused 8.2.22 13.5.10 8.2.23 unused 8.3.1 13.4.1 8.3.2 13.4.2 8.3.3 unused 8.3.4 13.4.3 8.3.5 unused 8.3.6 13.4.4 8.3.7 13.4.5 8.3.8 13.4.6 8.3.9 13.4.7 8.3.10 unused 8.3.11 unused 8.3.12 unused 8.4.1 unused 8.4.2 13.3.1 8.4.3 13.3.2 8.4.4 13.3.3 8.4.5 13.3.4 8.4.6 13.3.5 8.4.7 13.3.6 8.4.8 13.3.7 8.4.9 13.3.8 8.4.10 13.3.9 8.4.11 13.3.10 8.4.12 13.3.11 8.4.13 13.3.12 8.4.14 13.3.13 8.4.15 13.3.14 8.4.16 13.3.15 8.4.17 13.3.16 8.4.18 13.3.17 8.4.19 unused 8.4.20 unused 8.5.1 13.6.1 8.5.2 13.6.2 8.5.3 13.6.3 8.5.4 13.6.7 8.5.5 13.6.8 8.5.6 13.6.9 8.5.7 13.6.10 8.5.8 13.6.11 8.5.9 13.6.12 8.5.10 13.6.13 8.5.11 13.6.14 8.5.12 13.6.15 8.5.13 unused CHAPTER 4. CORRELATION, EXERCISE PLACEMENT 418 New Locations of Sixth Edition Exercises (continued) 6th 7th 6th 7th 6th 7th 8.5.14 unused 8.5.15 unused 8.5.16 unused 9.2.1 7.2.1 9.2.2 7.2.2 9.2.3 7.2.3 9.2.4 7.2.4 9.2.5 7.2.5 9.2.6 7.2.6 9.2.7 7.2.7 9.2.8 7.2.8 9.2.9 7.2.9 9.2.10 7.2.10 9.2.11 7.2.11 9.2.12 7.2.12 9.2.13 7.2.13 9.2.14 7.2.14 9.2.15 7.2.15 9.2.16 unused 9.2.17 unused 9.2.18 7.2.16 9.3.1 9.4.1 9.3.2 9.4.2 9.3.3 9.4.3 9.3.4 9.4.4 9.3.5 9.4.5 9.3.6 9.7.1 9.3.7 9.7.2 9.3.8 9.4.6 9.3.9 9.4.7 9.3.10 9.5.1 9.3.11 9.5.2 9.4.1 7.4.1 9.4.2 7.4.2 9.4.3 7.4.5 9.5.1 7.5.1 9.5.2 7.5.2 9.5.3 7.5.3 9.5.4 7.5.4 9.5.5 8.3.1 9.5.6 8.3.3 9.5.7 8.3.4 9.5.8 8.3.5 9.5.9 8.3.6 9.5.10 7.5.5 9.5.11 7.5.6 9.5.12 7.5.7 9.5.13 7.5.8 9.5.14 7.5.9 9.5.16 7.5.10 9.5.17 7.5.11 9.5.18 7.5.12 9.5.19 7.5.13 9.6.1 7.6.1 9.6.2 7.6.2 9.6.3 7.6.3 9.6.4 7.6.4 9.6.5 7.6.5 9.6.6 7.6.6 9.6.7 7.6.7 9.6.8 7.6.8 9.6.9 7.6.9 9.6.10 7.6.10 9.6.11 7.6.12 9.6.12 7.6.13 9.6.13 7.6.14 9.6.14 7.6.15 9.6.15 7.6.16 9.6.16 7.6.17 9.6.17 7.6.18 9.6.18 7.6.19 9.6.19 7.6.20 9.6.20 7.6.21 9.6.21 7.6.22 9.6.22 7.6.23 9.6.23 7.6.24 9.6.24 7.6.25 9.6.25 7.7.1 9.6.26 7.6.26 9.7.1 unused 9.7.2 10.2.3 9.7.3 10.2.4 9.7.4 10.2.5 9.7.5 unused 9.7.6 10.2.7 9.7.7 10.1.13 9.7.8 unused 9.7.9 unused 9.7.10 unused 9.7.11 unused 9.7.12 unused 9.7.13 unused 9.7.14 unused 9.7.15 unused 9.7.16 unused 9.7.17 unused 9.7.18 unused 9.7.19 unused 9.7.20 unused 10.1.1 8.2.1 10.1.2 8.2.2 10.1.3 8.2.3 10.1.4 7.6.11 10.1.5 unused 10.1.6 unused 10.1.7 unused 10.1.8 unused 10.1.9 unused 10.1.10 8.2.4 10.1.11 unused 10.1.12 5.4.1 10.1.13 5.3.2 10.1.14 5.4.2 10.1.15 5.4.3 10.1.16 5.4.4 10.1.17 unused 10.1.18 unused 10.1.19 unused 10.1.20 unused 10.1.21 unused CHAPTER 4. CORRELATION, EXERCISE PLACEMENT 419 New Locations of Sixth Edition Exercises (continued) 6th 7th 6th 7th 6th 7th 10.1.22 unused 10.2.1 8.2.5 10.2.3 8.2.6 10.2.4 8.2.7 10.2.5 unused 10.2.6 8.2.8 10.2.7 8.2.9 10.2.8 unused 10.2.9 8.2.10 10.2.10 unused 10.2.11 unused 10.2.12 unused 10.2.13 unused 10.2.14 unused 10.3.1 unused 10.3.2 5.2.1 10.3.3 5.2.2 10.3.4 5.2.3 10.3.5 5.2.4 10.3.6 5.2.5 10.3.7 5.2.6 10.3.8 5.2.7 10.3.9 unused 10.4.1 5.1.1 10.4.2 5.1.2 10.4.3 5.1.3 10.4.4 5.1.4 10.4.5 5.1.5 10.4.6 unused 10.4.7 5.1.6 10.4.8 unused 10.4.10 unused 10.4.11 unused 10.5.1 10.1.1 10.5.2 10.1.2 10.5.3 unused 10.5.4 unused 10.5.5 unused 10.5.6 unused 10.5.7 unused 10.5.8 10.1.5 10.5.9 10.1.6 10.5.10 10.1.8 10.5.11 10.1.9 10.5.12 10.1.10 10.5.13 unused 10.5.14 unused 10.5.15 unused 10.5.16 unused 10.5.17 unused 11.1.1 14.1.1 11.1.2 14.1.2 11.1.3 14.1.3 11.1.4 14.1.5 11.1.5 14.1.6 11.1.6 14.1.7 11.1.7 14.1.8 11.1.8 14.1.9 11.1.9 unused 11.1.10 14.1.10 11.1.11 14.1.11 11.1.12 14.1.12 11.1.13 14.1.13 11.1.14 14.1.14 11.1.15 unused 11.1.16 14.1.15 11.1.17 14.1.16 11.1.18 14.1.17 11.1.19 14.1.18 11.1.20 14.1.19 11.1.21 14.1.20 11.1.22 unused 11.1.23 14.1.22 11.1.24 14.1.23 11.1.25 14.1.24 11.1.26 14.1.25 11.1.27 14.1.27 11.1.28 unused 11.1.29 14.1.28 11.1.30 14.1.29 11.1.31 unused 11.1.32 unused 11.2.1 14.2.1 11.2.2 unused 11.2.3 14.2.2 11.2.4 14.2.3 11.2.5 14.2.4 11.2.6 14.2.5 11.2.7 14.2.6 11.2.8 unused 11.2.9 14.2.7 11.2.10 14.2.8 11.2.11 14.2.9 11.3.1 14.3.1 11.3.2 14.3.2 11.3.3 14.3.3 11.3.4 14.3.4 11.3.5 14.3.5 11.3.6 14.3.6 11.3.7 14.3.7 11.3.8 unused 11.3.9 unused 11.3.10 unused 11.3.11 14.3.10 11.4.1 14.4.1 11.4.2 14.4.2 11.4.3 14.4.4 11.4.4 14.4.5 11.4.5 14.4.6 11.4.6 14.4.7 11.4.7 14.4.8 11.5.1 14.5.1 11.5.2 14.5.2 11.5.3 14.5.3 11.5.4 14.5.4 11.5.5 14.5.5 11.5.6 14.5.6 11.5.7 14.5.7 11.5.8 14.5.8 11.5.9 14.5.10 CHAPTER 4. CORRELATION, EXERCISE PLACEMENT 420 New Locations of Sixth Edition Exercises (continued) 6th 7th 6th 7th 6th 7th 11.5.10 14.5.11 11.5.11 14.5.13 11.5.12 unused 11.5.13 14.6.3 11.5.14 14.5.14 11.5.15 14.5.15 11.5.16 unused 11.5.17 unused 11.5.18 14.5.16 11.6.1 unused 11.6.2 14.6.6 11.6.3 14.6.7 11.6.4 14.6.9 11.6.5 14.6.10 11.6.6 14.6.13 11.6.7 unused 11.7.1 14.7.2 11.7.2 14.7.3 11.7.3 14.7.4 11.7.4 14.7.5 11.7.5 14.7.6 11.7.6 14.7.7 11.7.7 14.7.8 11.7.8 14.7.9 11.7.9 14.7.11 11.7.10 14.7.12 11.7.11 14.7.13 11.7.12 unused 11.7.13 14.7.14 11.7.14 14.7.15 11.7.15 unused 11.7.16 14.7.16 11.7.17 unused 11.7.18 unused 11.7.19 unused 11.7.20 14.7.17 11.7.21 unused 11.7.22 unused 11.7.23 unused 11.7.24 unused 11.7.25 unused 11.7.26 unused 11.7.27 unused 12.1.1 15.3.1 12.1.2 15.3.2 12.1.3 15.3.3 12.1.4 15.3.4 12.1.5 15.3.6 12.1.6 15.3.8 12.1.7 unused 12.1.8 15.1.3 12.1.9 unused 12.2.1 15.1.5 12.2.2 15.1.6 12.2.3 15.1.7 12.2.4 15.3.7 12.2.5 15.3.5 12.2.6 unused 12.2.7 15.1.8 12.2.8 15.1.9 12.2.9 15.1.10 12.2.10 unused 12.2.11 unused 12.2.12 unused 12.2.13 unused 12.2.14 unused 12.3.1 15.2.2 12.3.2 15.2.3 12.3.3 15.2.4 12.3.4 15.2.5 12.3.5 15.2.6 12.3.6 15.2.7 12.3.7 15.1.11 12.3.8 15.1.12 12.3.9 15.2.8 12.3.10 15.2.9 12.3.11 unused 12.3.12 15.2.10 12.3.13 15.2.11 12.3.14 unused 12.3.15 15.2.12 12.3.16 15.2.13 12.3.17 15.2.14 12.3.18 unused 12.3.19 15.2.15 12.3.20 15.2.16 12.3.21 15.2.17 12.3.22 15.2.18 12.3.23 15.2.19 12.3.24 15.2.20 12.3.25 15.2.21 12.3.26 15.2.22 12.3.27 15.2.23 12.4.1 15.1.13 12.4.2 15.2.1 12.4.3 15.1.14 12.4.4 15.1.15 12.4.5 15.1.16 12.4.6 15.1.17 12.4.7 15.2.24 12.4.8 15.2.25 12.4.9 15.2.26 12.4.10 15.2.27 12.4.11 unused 12.4.12 unused 12.4.13 15.1.18 12.5.1 15.4.3 12.5.2 15.4.4 12.5.3 15.4.5 12.5.4 15.4.7 12.5.5 15.4.8 12.5.6 15.4.9 12.5.7 15.4.10 12.5.8 15.4.11 12.5.9 15.4.12 12.5.10 15.4.13 12.5.11 15.4.14 12.5.12 15.4.15 12.5.13 15.4.16 12.5.14 15.4.18 CHAPTER 4. CORRELATION, EXERCISE PLACEMENT 421 New Locations of Sixth Edition Exercises (continued) 6th 7th 6th 7th 6th 7th 12.5.15 15.4.19 12.5.16 15.4.20 12.5.17 unused 12.5.18 unused 12.5.19 unused 12.6.1 15.5.1 12.6.2 15.5.2 12.6.3 15.5.3 12.6.4 unused 12.6.5 15.5.4 12.6.6 15.5.5 12.6.7 16.1.1 12.6.8 16.1.2 12.6.9 15.5.6 12.6.10 15.5.7 12.7.1 16.1.3 12.7.2 16.1.5 12.7.3 16.1.6 12.7.4 16.1.7 12.7.5 16.1.8 12.8.1 16.3.2 12.8.2 16.3.3 12.8.3 16.3.4 12.8.4 16.3.5 12.8.5 16.3.6 12.8.6 16.3.7 12.8.7 16.3.8 12.8.8 unused 12.8.9 16.3.9 12.9.1 16.3.10 12.9.2 16.3.11 12.9.3 16.3.12 12.9.4 unused 12.10.1 15.6.1 12.10.2 unused 12.10.3 15.6.2 12.10.4 15.6.3 12.10.5 unused 12.10.6 15.6.4 12.11.1 16.4.1 12.11.2 16.4.2 12.11.3 16.4.3 12.11.4 16.4.4 12.11.5 16.4.5 12.11.6 16.4.6 13.1.1 18.1.1 13.1.2 18.1.2 13.1.3 18.2.1 13.1.4 18.1.3 13.1.5 18.1.4 13.1.6 18.1.5 13.1.7 18.1.6 13.1.8 18.2.2 13.1.9 18.2.3 13.1.10 18.2.4 13.1.11 18.2.5 13.1.12 18.2.6 13.1.13 18.1.7 13.1.14 18.2.7 13.1.15 18.2.8 13.1.16 unused 13.1.17 unused 13.1.18 unused 13.1.19 unused 13.1.20 unused 13.1.21 unused 13.1.22 unused 13.1.23 unused 13.2.1 18.3.1 13.2.2 18.3.2 13.2.3 unused 13.2.4 18.3.3 13.2.5 18.3.4 13.2.6 18.3.5 13.2.7 18.3.6 13.2.8 18.3.7 13.2.9 18.3.8 13.2.10 18.3.9 13.2.11 unused 13.2.12 unused 13.2.13 unused 13.2.14 unused 13.2.15 unused 13.2.16 unused 13.2.17 unused 13.2.18 unused 13.2.19 unused 13.2.20 unused 13.2.21 18.3.10 13.2.22 unused 13.3.1 18.4.3 13.3.2 18.4.4 13.3.3 18.4.5 13.3.4 18.4.6 13.3.5 18.4.7 13.3.6 18.4.8 13.3.7 18.4.9 13.3.8 18.4.10 13.3.9 18.4.11 13.3.10 18.4.12 13.3.11 18.5.10 13.3.12 18.4.13 13.3.13 18.4.15 13.3.14 18.4.16 13.3.15 18.4.17 13.3.16 18.4.18 13.3.17 18.4.19 13.3.18 18.4.20 13.3.19 18.4.21 13.3.20 18.4.22 13.3.21 18.4.23 13.3.22 18.4.24 13.3.23 unused 13.3.24 unused 13.3.25 unused 13.3.26 unused 13.3.27 18.4.25 13.3.28 18.4.26 13.3.29 18.4.27 13.3.30 18.4.28 CHAPTER 4. CORRELATION, EXERCISE PLACEMENT 422 New Locations of Sixth Edition Exercises (continued) 6th 7th 6th 7th 6th 7th 13.4.1 18.5.1 13.4.2 18.5.2 13.4.3 18.5.3 13.4.4 18.5.4 13.4.5 18.5.5 13.4.6 18.5.6 13.4.7 18.5.7 13.4.8 18.5.8 13.4.9 18.5.9 13.4.10 18.5.12 13.5.1 18.6.1 13.5.2 18.6.2 13.5.3 18.6.3 13.5.4 18.6.4 13.5.5 18.6.5 13.5.6 18.6.6 13.5.7 18.6.7 13.5.8 18.6.8 13.5.9 18.6.9 13.5.10 18.6.10 13.5.11 18.6.11 13.5.12 18.6.12 13.5.13 18.6.13 13.5.14 18.6.14 13.5.15 18.6.15 13.5.16 18.6.16 13.5.17 18.6.17 13.6.1 unused 13.6.2 unused 14.1.1 19.1.1 14.1.2 19.1.2 14.1.3 19.1.3 14.1.4 19.1.4 14.1.5 19.1.5 14.1.6 19.1.6 14.1.7 19.1.7 14.1.8 unused 14.1.9 19.1.8 14.2.1 unused 14.2.2 19.1.9 14.2.3 19.1.10 14.3.1 19.2.3 14.3.1 19.2.6 14.3.2 19.2.7 14.3.3 19.2.8 14.3.4 19.2.9 14.3.5 19.2.10 14.3.6 19.2.11 14.3.7 19.2.12 14.3.8 19.2.1 14.3.9 unused 14.3.10 19.2.2 14.3.12 19.1.11 14.3.13 unused 14.3.14 19.2.13 14.3.15 unused 14.3.16 unused 14.3.17 unused 14.4.1 19.1.12 14.4.2 19.1.13 14.4.3 19.2.4 14.4.4 19.2.14 14.4.5 19.2.15 14.4.6 19.2.16 14.4.7 19.2.17 14.4.8 19.2.18 14.4.9 19.2.19 14.4.10 19.2.20 14.4.11 19.2.21 14.4.12 unused 14.4.13 19.1.14 14.4.14 19.1.15 14.4.15 19.1.16 14.5.1 19.3.1 14.5.2 19.3.2 14.5.3 unused 14.5.4 19.3.3 14.6.1 20.6.1 14.6.2 unused 14.6.3 20.6.2 14.6.4 20.6.3 14.6.5 unused 14.6.6 unused 14.7.1 unused 14.7.2 unused 14.7.3 unused 15.1.1 20.2.15 15.1.2 unused 15.1.3 unused 15.1.4 unused 15.3.1 20.2.1 15.3.2 unused 15.3.3 20.2.2 15.3.4 20.2.3 15.3.5 20.2.4 15.3.6 20.2.5 15.3.7 20.2.6 15.3.8 20.2.7 15.3.9 20.2.8 15.3.10 20.2.9 15.3.11 20.2.10 15.3.12 unused 15.3.13 unused 15.3.14 unused 15.3.15 unused 15.3.16 unused 15.3.17 unused 15.3.18 20.2.11 15.3.19 20.2.12 15.3.20 20.2.16 15.3.21 20.2.13 15.4.1 unused 15.4.2 unused 15.4.3 20.3.6 15.4.4 unused 15.4.5 unused 15.5.1 20.4.1 15.5.3 20.4.2 15.5.4 unused 15.5.5 20.4.3 CHAPTER 4. CORRELATION, EXERCISE PLACEMENT 423 New Locations of Sixth Edition Exercises (continued) 6th 7th 6th 7th 6th 7th 15.5.6 20.4.4 15.5.7 20.4.5 15.5.8 20.4.6 15.5.9 20.4.7 15.6.1 unused 15.6.2 unused 15.6.3 unused 15.6.4 unused 15.6.5 unused 15.6.6 unused 15.6.7 unused 15.6.8 20.4.8 15.6.9 unused 15.6.10 20.4.10 15.6.11 20.4.11 15.6.12 unused 15.7.1 unused 15.8.1 20.7.1 15.8.2 20.7.2 15.8.3 20.7.3 15.8.4 20.7.4 15.8.5 20.7.5 15.8.6 unused 15.8.7 20.7.6 15.8.8 20.7.7 15.8.9 20.7.8 15.9.1 20.8.1 15.9.2 20.8.2 15.9.3 20.8.3 15.9.4 20.8.4 15.9.5 20.8.5 15.10.1 20.8.6 15.10.2 20.8.7 15.10.3 20.8.8 15.10.4 20.8.9 15.10.5 20.8.10 15.10.6 20.8.11 15.10.7 20.8.12 15.10.8 unused 15.10.9 20.8.13 15.10.10 20.8.14 15.10.11 20.8.15 15.10.12 20.8.16 15.10.13 20.8.17 15.10.14 20.8.18 15.10.15 20.8.19 15.10.16 20.8.20 15.10.17 20.8.21 15.10.18 20.8.22 15.10.19 20.8.23 15.10.20 20.8.24 15.10.21 unused 15.10.22 unused 15.11.1 20.9.1 15.11.2 20.9.2 15.11.3 20.9.3 15.11.4 20.9.4 15.12.1 20.10.1 15.12.2 20.10.2 15.12.3 20.10.3 15.12.4 20.10.4 15.12.5 20.10.5 15.12.6 20.10.6 15.12.7 20.10.7 15.12.8 20.10.8 15.12.9 20.10.9 15.12.10 20.10.10 15.12.11 20.10.11 15.12.12 20.10.12 15.12.13 20.10.13 16.1.1 21.1.1 16.1.2 10.1.11 16.1.3 21.1.2 16.1.4 10.1.12 16.1.5 unused 16.1.6 21.1.3 16.1.7 21.1.4 16.2.1 21.2.1 16.2.2 21.2.2 16.2.3 21.2.2 16.2.4 21.2.3 16.2.5 21.2.4 16.2.6 21.2.5 16.2.7 21.2.6 16.2.8 21.2.7 16.2.9 21.2.8 16.2.10 21.2.9 16.2.11 21.2.17 16.3.1 21.3.1 16.3.2 unused 16.3.3 21.2.10 16.3.4 21.2.11 16.3.5 21.2.12 16.3.6 unused 16.3.7 21.3.2 16.3.8 21.2.13 16.3.9 21.3.3 16.3.10 21.3.4 16.3.11 21.2.14 16.3.12 21.2.15 16.3.13 unused 16.3.14 unused 16.3.15 21.2.16 16.3.16 unused 16.3.17 unused 16.3.18 unused 16.3.19 unused 16.4.1 21.4.1 16.4.2 21.4.3 16.4.3 21.4.4 16.4.4 21.4.5 16.4.5 21.4.6 16.4.6 21.4.7 16.4.7 21.4.8 16.4.8 21.4.2 17.1.1 22.1.1 17.1.2 22.1.2 17.1.3 22.1.3 17.1.4 22.1.4 17.1.5 22.1.5 CHAPTER 4. CORRELATION, EXERCISE PLACEMENT 424 New Locations of Sixth Edition Exercises (continued) 6th 7th 6th 7th 6th 7th 17.2.1 22.1.7 17.2.2 22.1.8 17.2.3 22.1.9 17.2.4 22.1.10 17.2.5 22.1.11 17.2.6 22.1.12 17.2.7 22.1.13 17.2.8 22.1.14 17.2.9 unused 17.2.10 unused 17.2.11 unused 17.2.12 22.1.15 17.3.1 22.2.1 17.3.2 22.2.2 17.3.3 22.2.3 17.3.4 22.2.4 17.3.5 22.2.5 17.3.6 22.2.6 17.3.7 22.2.7 17.4.1 22.2.8 17.4.2 22.2.9 17.5.1 22.2.10 17.6.1 22.3.1 17.6.2 unused 17.6.3 22.3.2 17.6.4 22.3.3 17.6.5 22.3.4 17.6.6 22.3.5 17.6.7 22.3.6 17.6.8 unused 17.6.9 22.3.7 17.6.10 unused 17.6.11 unused 17.6.12 unused 17.7.1 22.4.1 17.7.2 22.4.2 17.7.3 22.4.3 17.7.4 22.4.4 17.7.5 22.4.5 17.7.6 unused 17.7.7 22.4.6 17.8.1 unused 17.8.2 22.4.7 17.8.3 22.4.8 17.8.4 22.4.9 17.8.5 22.4.10 17.8.6 22.4.11 17.8.7 unused 17.8.8 unused 18.2.1 33.1.1 18.2.2 33.1.2 18.2.3 33.1.3 18.2.4 33.1.4 18.2.5 33.1.5 18.2.6 33.1.6 18.2.7 33.1.7 18.2.8 unused 18.2.9 33.1.8 18.2.10 33.1.9 18.2.11 unused 18.3.1 unused 18.3.2 33.1.10 18.4.1 33.2.2 18.4.2 33.4.3 18.4.2 33.5.6 18.4.3 33.5.1 18.4.4 unused 19.1.1 23.1.1 19.1.2 23.1.2 19.1.3 23.1.3 19.1.4 23.1.4 19.1.5 23.1.5 19.1.6 23.1.6 19.1.7 23.1.7 19.1.8 23.1.8 19.1.9 23.1.9 19.2.1 23.2.2 19.2.2 23.6.4 19.2.3 23.2.4 19.2.4 23.2.5 19.2.5 23.6.5 19.2.6 23.6.6 19.2.7 23.2.6 19.2.8 23.2.7 19.3.1 23.3.1 19.3.2 23.3.2 19.3.3 23.3.3 19.3.4 23.3.4 19.3.5 23.3.5 19.4.1 23.4.1 19.4.2 23.4.2 19.4.3 23.4.3 19.4.4 23.4.4 19.4.5 23.4.5 19.4.6 23.4.6 19.4.7 unused 19.5.1 23.5.4 19.5.2 23.6.1 19.5.3 23.5.5 19.5.4 23.6.2 19.5.5 23.6.3 19.6.1 23.7.1 19.6.2 23.7.2 19.6.3 23.7.3 19.6.4 unused Chapter 5 Unused Sixth Edition Exercises These exercises from the Sixth Edition were not used in the Seventh, for any one of several reasons. A few were adjudged unclear or not suﬃciently relevant. Others were made unnecesssary because their subject matter was explicitly dis- cussed in the text, or became redundant because of the selection of similar problems. And some interesting and worthy problems had to be moved on-line due to space limitations of the book. There has been no attempt to edit these exercises. The exercise numbers, equations, sections, ﬁgures, and other exercises referred to are from the Sixth Edition. We supply this material because some instructors may ﬁnd it useful. 1.1.1 Show how to ﬁnd A and B, given A + B and A − B. 1.1.3 Calculate the components of a unit vector that lies in the xy-plane and makes equal angles with the positive directions of the x- and y-axes. 1.1.4 The velocity of sailboat A relative to sailboat B, vrel, is deﬁned by the equation vrel = vA − vB, where vA is the velocity of A and vB is the velocity of B. Determine the velocity of A relative to B if vA = 30 km/hr east vB = 40 km/hr north. ANS. vrel = 50 km/hr, 53.1◦ south of east. 1.1.5 A sailboat sails for 1 hr at 4 km/hr (relative to the water) on a steady compass heading of 40◦ east of north. The sailboat is simultaneously carried along by a current. At the end of the hour the boat is 6.12 km from its starting point. The line from its starting point to its location lies ◦ east of north. Find the x (easterly) and y (northerly) components of the water’s velocity. 425 CHAPTER 5. UNUSED SIXTH EDITION EXERCISES 426 ANS. veast = 2.73 km/hr, vnorth ≈ 0 km/hr. 1.1.6 A vector equation can be reduced to the form A = B. From this show that the one vector equation is equivalent to three scalar equations. Assuming the validity of Newton’s second law, F = ma, as a vector equation, this means that ax depends only on Fx and is independent of Fy and Fz. 1.1.7 The vertices A, B, and C of a triangle are given by the points (−1, 0, 2), (0, 1, 0), and (1, −1, 0), respectively. Find point D so that the ﬁgure ABCD forms a plane parallelogram. ANS. (0, −2, 2) or (2, 0, −2). 1.2.1 (a) Show that the magnitude of a vector A, A = (A2 + A 2) 1/2, is inde- pendent of the orientation of the rotated coordinate system, (A 2 + A2) 1/2 = (A ′2 x + A′2 y ) 1/2 independent of the rotation angle ϕ. This independence of angle is expressed by saying that A is invariant under rotations. (b) At a given point (x, y), A deﬁnes an angle α relative to the positive x-axis and α′ relative to the positive x ′-axis. The angle from x to x′ is ϕ. Show that A = A′ deﬁnes the same direction in space when expressed in terms of its primed components as in terms of its unprimed components; that is, α′ = α − ϕ. 1.2.2 Prove the orthogonality condition ∑ i ajiaki = δjk. As a special case of this, the direction cosines of Section 1.1 satisfy the relation cos2 α + cos2 β + cos2 γ = 1, a result that also follows from Eq. (1.6). 1.3.1 Two unit magnitude vectors ei and ej are required to be either parallel or perpendicular to each other. Show that ei · ej provides an interpretation of Eq. (1.18), the direction cosine orthogonality relation. 1.3.2 Given that (1) the dot product of a unit vector with itself is unity and (2) this relation is valid in all (rotated) coordinate systems, show that ˆx ′ · ˆx ′ = 1 (with the primed system rotated 45 ◦ about the z-axis relative to the unprimed) implies that ˆx · ˆy = 0. CHAPTER 5. UNUSED SIXTH EDITION EXERCISES 427 1.3.4 The interaction energy between two dipoles of moments µ1 and µ2 may be written in the vector form V = − µ1 · µ2 r3 + 3 (µ1 · r) (µ2 · r) r5 and in the scalar form V = µ1µ2 r3 (2 cos θ1 cos θ2 − sin θ1 sin θ2 cos ϕ) . Here θ1 and θ2 are the angles of µ1 and µ2 relative to r, while ϕ is the azimuth of µ2 relative to the µ1 − r plane (Fig. 1.11). Show that these two forms are equivalent.: Equation (12.178) will be helpful. 1.3.7 Prove the law of cosines from the triangle with corners at the point of C and A in Fig. 1.10 and the projection of vector B onto vector A. 1.4.3 Starting with C = A + B, show that C × C = 0 leads to A × B = −B × A. 1.4.4 Show that (a) (A − B) · (A + B) = A 2 − B2, (b) (A − B) × (A + B) = 2A × B. The distributive laws needed here, A · (B + C) = A · B + A · C, and A × (B + C) = A × B + A × C, may easily be veriﬁed (if desired) by expansion in Cartesian compo- nents. 1.4.11 The coordinates of the three vertices of a triangle are (2, 1, 5), (5, 2, 8), and (4, 8, 2). Compute its area by vector methods, its center and medians. Lengths are in centimeters.. See Exercise 1.4.1. 1.4.12 The vertices of parallelogram ABCD are (1, 0, 0), (2, −1, 0), (0, −1, 1), and (−1, 0, 1) in order. Calculate the vector areas of triangle ABD and of triangle BCD. Are the two vector areas equal? ANS. AreaABD = − 1 2 (ˆx + ˆy + 2ˆz). CHAPTER 5. UNUSED SIXTH EDITION EXERCISES 428 1.4.14 Find the sides and angles of the spherical triangle ABC deﬁned by the three vectors A = (1, 0, 0), B = ( 1 √2 , 0, 1 √2 ) , C = ( 0, 1 √2 , 1 √2 ) . Each vector starts from the origin (Fig. 1.14). 1.4.17 Deﬁne a cross product of two vectors in two-dimensional space and give a geometrical interpretation of your construction. 1.4.18 Find the shortest distance between the paths of two rockets in free ﬂight. Take the ﬁrst rocket path to be r = r1 + t1v1 with launch at r1 = (1, 1, 1), velocity v1 = (1, 2, 3) and time parameter t1 and the second rocket path as r = r2 + t2v2 with r2 = (5, 2, 1), v2 = (−1, −1, 1) and time parameter t2. Lengths are in kilometers, velocities in kilometers per hour. 1.5.1 One vertex of a glass parallelepiped is at the origin (Fig. 1.18). The three adjacent vertices are at (3, 0, 0), (0, 0, 2), and (0, 3, 1). All lengths are in centimeters. Calculate the number of cubic centimeters of glass in the parallelepiped using the triple scalar product. 1.5.2 Verify the expansion of the triple vector product A × (B × C) = B(A · C) − C(A · B) by direct expansion in Cartesian coordinates. 1.5.3 Show that the ﬁrst step in Eq. (1.43), which is (A × B) · (A × B) = A2B2 − (A · B)2, is consistent with the BAC-CAB rule for a triple vector product. 1.5.5 The orbital angular momentum L of a particle is given by L = r × p = mr×v, where p is the linear momentum. With linear and angular velocity related by v = ω × r, show that L = mr2 [ω − ˆr (ˆr · ω)] . Here ˆr is a unit vector in the r-direction. For r · ω = 0 this reduces to L = Iω, with the moment of inertia I given by mr2. In Section 3.5 this result is generalized to form an inertia tensor. CHAPTER 5. UNUSED SIXTH EDITION EXERCISES 429 1.5.6 The kinetic energy of a single particle is given by T = 1 2 mv2. For rotational motion this becomes 1 2 m(ω × r) 2. Show that T = 1 2 m [ r2ω2 − (r · ω)2] . For r · ω = 0 this reduces to T = 1 2 Iω2, with the moment of inertia I given by mr2. 1.5.11 Vector D is a linear combination of three noncoplanar (and nonorthogonal) vectors: D = aA + bB + cC. Show that the coeﬃcients are given by a ratio of triple scalar products, a = D · B × C A · B × C , and so on. 1.5.14 For a spherical triangle such as pictured in Fig. 1.14 show that sin A sin BC = sin B sin CA = sin C sin AB . Here sin A is the sine of the included angle at A, while BC is the side opposite (in radians). 1.5.15 Given a′ = b × c a · b × c , b ′ = c × a a · b × c , c′ = a × b a · b × c , and a · b × c ̸= 0, show that (a) x · y′ = δxy, (x, y = a, b, c), (b) a′ · b ′ × c′ = (a · b × c)−1, (c) a = b′ × c′ a′ · b′ × c′ . 1.5.16 If x · y′ = δxy, (x, y = a, b, c), prove that a ′ = b × c a · b × c . (This is the converse of Problem 1.5.15.) 1.5.17 Show that any vector V may be expressed in terms of the reciprocal vectors a′, b ′, c′ (of Problem 1.5.15) by V = (V · a) a′ + (V · b) b′ + (V · c) c′. CHAPTER 5. UNUSED SIXTH EDITION EXERCISES 430 1.7.4 In Chapter 2 it will be seen that the unit vectors in non-Cartesian co- ordinate systems are usually functions of the coordinate variables, ei = ei(q1, q2, q3) but |ei| = 1. Show that either ∂ei/∂qj = 0 or ∂ei/∂qj is orthogonal to ei. Hint. ∂ei2/∂qj = 0. 1.7.6 The electrostatic ﬁeld of a point charge q is E = q 4πε0 · ˆr r2 . Calculate the divergence of E. What happens at the origin? 1.8.1 Show, by rotating the coordinates, that the components of the curl of a vector transform as a vector.. The direction cosine identities of Eq. (1.46) are available as needed. 1.8.6 If (a) V = ˆxVx(x, y) + ˆyVy(x, y) and (b) ∇ × V ̸= 0, prove that ∇ × V is perpendicular to V. 1.8.10 For A = ˆxAx(x, y, z) and B = ˆxBx(x, y, z) evaluate each term in the vector identity ∇(A · B) = (B · ∇)A + (A · ∇)B + B × (∇ × A) + A × (∇ × B) and verify that the identity is satisﬁed. 1.8.18 The velocity of a two-dimensional ﬂow of liquid is given by V = ˆxu(x, y) − ˆyv(x, y). If the liquid is incompressible and the ﬂow is irrotational, show that ∂u ∂x = ∂v ∂y and ∂u ∂y = − ∂v ∂x . These are the Cauchy-Riemann conditions of Section 6.2. 1.8.19 The evaluation in this section of the four integrals for the circulation omit- ted Taylor series terms such as ∂Vx/∂x, ∂Vy/∂y and all second derivatives. Show that ∂Vx/∂x, ∂Vy/∂y cancel out when the four integrals are added and that the second-derivative terms drop out in the limit as dx → 0, dy → 0. Hint. Calculate the circulation per unit area and then take the limit dx → 0, dy → 0. 1.9.2 Show that the identity ∇ × (∇ × V) = ∇∇ · V − ∇ · ∇V follows from the BAC-CAB rule for a triple vector product. Justify any alteration of the order of factors in the BAC and CAB terms. CHAPTER 5. UNUSED SIXTH EDITION EXERCISES 431 1.9.6 From the Navier-Stokes equation for the steady ﬂow of an incompressible viscous ﬂuid we have the term ∇ × [v × (∇ × v)], where v is the ﬂuid velocity. Show that this term vanishes for the special case v = ˆxv(y, z). 1.9.9 With ψ a scalar (wave) function, show that (r × ∇) · (r × ∇)ψ = r2∇ 2ψ − r2 ∂2ψ ∂r2 − 2r ∂ψ ∂r . (This can actually be shown more easily in spherical polar coordinates, Section 2.5.) 1.9.10 In a (nonrotating) isolated mass such as a star, the condition for equilib- rium is ∇P + ρ∇ϕ = 0. Here P is the total pressure, ρ is the density, and ϕ is the gravitational potential. Show that at any given point the normals to the surfaces of constant pressure and constant gravitational potential are parallel. 1.9.11 In the Pauli theory of the electron, one encounters the expression (p − eA) × (p − eA)ψ, where ψ is a scalar (wave) function. A is the magnetic vector potential related to the magnetic induction B by B = ∇ × A. Given that p = −i∇, show that this expression reduces to ieBψ. Show that this leads to the orbital g-factor gL = 1 upon writing the magnetic moment as µ = gLL in units of Bohr magnetons and L = −ir × ∇. See also Exercise 1.13.7. 1.10.1 The force ﬁeld acting on a two-dimensional linear oscillator may be de- scribed by F = −ˆxkx − ˆyky. Compare the work done moving against this force ﬁeld when going from, 1) to (4, 4) by the following straight-line paths: (a) (1, 1) → (4, 1) → (4, 4) (b) (1, 1) → (1, 4) → (4, 4) (c) (1, 1) → (4, 4) along x = y. This means evaluating − ∫ (4,4) (1,1) F · dr along each path. CHAPTER 5. UNUSED SIXTH EDITION EXERCISES 432 1.10.6 Show, by expansion of the surface integral, that lim∫ dτ →0 ∫ s dσ × V ∫ dτ = ∇ × V. Hint. Choose the volume ∫ dτ to be a diﬀerential volume dx dy dz. 1.11.4 Over some volume V let ψ be a solution of Laplace’s equation (with the derivatives appearing there continuous). Prove that the integral over any closed surface in V of the normal derivative of ψ (∂ψ/∂n, or ∇ψ · n) will be zero. 1.11.5 In analogy to the integral deﬁnition of gradient, divergence, and curl of Section 1.10, show that ∇ 2ϕ = lim∫ dτ →0 ∫ ∇ϕ · dσ ∫ dτ . 1.11.6 The electric displacement vector D satisﬁes the Maxwell equation ∇ · D = ρ, where ρ is the charge density (per unit volume). At the boundary between two media there is a surface charge density σ (per unit area). Show that a boundary condition for D is (D2 − D1) · n = σ. n is a unit vector normal to the surface and out of medium 1. Hint. Consider a thin pillbox as shown in Fig. 1.29. 1.11.9 The creation of a localized system of steady electric currents (current density J) and magnetic ﬁelds may be shown to require an amount of work W = 1 2 ∫ H · B dτ. Transform this into W = 1 2 ∫ J · A dτ. Here A is the magnetic vector potential: ∇ × A = B. Hint. In Maxwell’s equations take the displacement current term ∂D/∂t = 0. If the ﬁelds and currents are localized, a bounding surface may be taken far enough out so that the integrals of the ﬁelds and currents over the surface yield zero. 1.11.10 Prove the generalization of Green’s theorem: ∫ ∫ ∫ V (vLu − uLv) dτ = ∮ ∂V p (v∇u − u∇v) · dσ. Here L is the self-adjoint operator (Section 10.1), L = ∇ · [p(r)∇] + q(r) CHAPTER 5. UNUSED SIXTH EDITION EXERCISES 433 and p, q, u, and v are functions of position, p and q having continuous ﬁrst derivatives and u and v having continuous second derivatives. Note. This generalized Green’s theorem appears in Section 9.7. 1.12.4 In steady state the magnetic ﬁeld H satisﬁes the Maxwell equation ∇ × H = J, where J is the current density (per square meter). At the boundary between two media there is a surface current density K. Show that a boundary condition on H is n × (H2 − H1) = K. n is a unit vector normal to the surface and out of medium 1. Hint. Consider a narrow loop perpendicular to the interface as shown in the Fig. 1.31 1.12.5 From Maxwell’s equations, ∇ × H = J, with J here the current density and E = 0. Show from this that ∮ H · dr = I, where I is the net electric current enclosed by the loop integral. These are the diﬀerential and integral forms of Amp`ere’s law of magnetism. 1.12.6 A magnetic induction B is generated by electric current in a ring of radius R. Show that the magnitude of the vector potential A (B = ∇ × A) at the ring can be |A| = ϕ 2πR , where ϕ is the total magnetic ﬂux passing through the ring. Note. A is tangential to the ring and may be changed by adding the gradient of a scalar function. 1.12.7 Prove that ∫ S ∇ × V · dσ = 0 if S is a closed surface. 1.12.8 Evaluate ∮ r · dr (Exercise 1.10.4) by Stokes’ theorem. 1.13.3 The usual problem in classical mechanics is to calculate the motion of a particle given the potential. For a uniform density (ρ0), nonrotating massive sphere, Gauss’ law of Section 1.14 leads to a gravitational force on a unit mass m0 at a point r0 produced by the attraction of the mass at r ≤ r0. The mass at r > r0 contributes nothing to the force. (a) Show that F/m0 = −(4πGρ0/3)r, 0 ≤ r ≤ a, where a is the radius of the sphere. (b) Find the corresponding gravitational potential, 0 ≤ r ≤ a. CHAPTER 5. UNUSED SIXTH EDITION EXERCISES 434 (c) Imagine a vertical hole running completely through the center of the Earth and out to the far side. Neglecting the rotation of the Earth and assuming a uniform density ρ0 = 5.5 gm/cm3, calculate the nature of the motion of a particle dropped into the hole. What is its period?. F ∝ r is actually a very poor approximation. Because of varying density, the approximation F = constant along the outer half of a radial line and F ∝ r along the inner half is a much closer approximation. 1.13.10 With E the electric ﬁeld and A the magnetic vector potential, show that [E + ∂A/∂t] is irrotational and that therefore we may write E = −∇ϕ − ∂A ∂t . 1.13.11 The total force on a charge q moving with velocity v is F = q(E + v × B). Using the scalar and vector potentials, show that F = q [ −∇ϕ − dA dt + ∇(A · v) ] . Note that we now have a total time derivative of A in place of the partial derivative of Exercise 1.13.10. 1.14.1 Develop Gauss’ law for the two-dimensional case in which ϕ = −q ln ρ 2πε0 , E = −∇ϕ = q ˆρ 2πε0ρ . Here q is the charge at the origin or the line charge per unit length if the two-dimensional system is a unit thickness slice of a three-dimensional (circular cylindrical) system. The variable ρ is measured radially outward from the line charge. ˆρ is the corresponding unit vector (see Section 2.4). 1.14.2 (a) Show that Gauss’ law follows from Maxwell’s equation ∇ · E = ρ ε0 . Here ρ is the usual charge density. (b) Assuming that the electric ﬁeld of a point charge q is spherically symmetric, show that Gauss’ law implies the Coulomb inverse square E = qˆr 4πε0r2 . CHAPTER 5. UNUSED SIXTH EDITION EXERCISES 435 1.15.2 Verify that the sequence δn(x), based on the function δn(x) = { 0, x < 0, ne−nx x > 0, is a delta sequence (satisfying Eq. (1.177)). Note that the singularity is at +0, the positive side of the origin.. Replace the upper limit (∞) by c/n, where c is large but ﬁnite, and use the mean value theorem of integral calculus. 1.15.4 Demonstrate that δn = sin nx/πx is a delta distribution by showing that lim n→∞ ∫ ∞ −∞ f (x) sin nx πx dx = f (0). Assume that f (x) is continuous at x = 0 and vanishes as x → ±∞. Hint. Replace x by y/n and take lim n → ∞ before integrating. 1.15.11 Show that in spherical polar coordinates (r, cos θ, ϕ) the delta function δ(r1 − r2) becomes 1 r2 1 δ(r1 − r2)δ(cos θ1 − cos θ2)δ(ϕ1 − ϕ2). Generalize this to the curvilinear coordinates (q1, q2, q3) of Section 2.1 with scale factors h1, h2, and h3. 1.15.12 A rigorous development of Fourier transforms 1 includes as a theorem the relations lim a→∞ 2 π ∫ x2 x1 f (u + x) sin ax x dx =  f (u + 0) + f (u − 0), x1 < 0 < x2 f (u + 0), x1 = 0 < x2 f (u − 0), x1 < 0 = x2 0 x1 < x2 < 0 or 0 < x1 < x2. Verify these results using the Dirac delta function. 1.15.14 Show that the unit step function u(x) may be represented by u(x) = 1 2 + 1 2πi P ∫ ∞ −∞ e ixt dt t , where P means Cauchy principal value (Section 7.1). 1I. N. Sneddon, Fourier Transforms. New York: McGraw-Hill (1951). CHAPTER 5. UNUSED SIXTH EDITION EXERCISES 436 1.15.15 As a variation of Eq. (1.174), take δn(x) = 1 2π ∫ ∞ −∞ e ixt−|t|/n dt. Show that this reduces to (n/π)1/(1 + n2x 2), Eq. (1.173), and that ∫ ∞ −∞ δn(x) dx = 1. Note. In terms of integral transforms, the initial equation here may be interpreted as either a Fourier exponential transform of e −|t|/n or a Laplace transform of e ixt. 1.15.16 (a) The Dirac delta function representation given by Eq. (1.189) δ(x − t) = ∞∑ n=0 ϕn(x)ϕn(t) is often called the closure relation. For an orthonormal set of real functions, ϕn, show that closure implies completeness, that is, Eq. (1.190) follows from Eq. (1.189). Hint. One can take F (x) = ∫ F (t)δ(x − t) dt. (b) Following the hint of part (a) you encounter the integral F (t)ϕn(t) dt. How do you know that this integral is ﬁnite? 1.15.17 For the ﬁnite interval (−π, π) write the Dirac delta function δ(x − t) as a series of sines and cosines: sin nx, cos nx, n = 0, 1, 2, . . .. Note that although these functions are orthogonal, they are not normalized to unity. 1.15.18 In the interval (−π, π), δn(x) = n√π exp(−n2x2). (a) Write δn(x) as a Fourier cosine series. (b) Show that your Fourier series agrees with a Fourier expansion of δ(x) in the limit as n → ∞. (c) Conﬁrm the delta function nature of your Fourier series by showing that for any f (x) that is ﬁnite in the interval [−π, π] and continuous at x = 0, ∫ π −π f (x)[Fourier expansion of δ∞(x)] dx = f (0). 1.15.19 (a) Write δn(x) = n√π exp(−n2x 2) in the interval (−∞, ∞) as a Fourier integral and compare the limit n → ∞ with Eq. (1.192c). CHAPTER 5. UNUSED SIXTH EDITION EXERCISES 437 (b) Write δn(x) = n exp(−nx) as a Laplace transform and compare the limit n → ∞ with Eq. (1.194). Hint. See Eqs. (15.22) and (15.23) for (a) and Eq. (15.212) for (b). 1.15.20 (a) Show that the Dirac delta function δ(x − a), expanded in a Fourier sine series in the half-interval (0, L), (0 < a < L), is given by δ(x − a) = 2 L ∞∑ n=1 sin ( nπa L ) sin ( nπx L ) . Note that this series actually describes −δ(x + a) + δ(x − a) in the interval (−L, L). (b) By integrating both sides of the preceding equation from 0 to x, show that the cosine expansion of the square wave f (x) = { 0, 0 ≤ x < a 1, a < x < L, is, for 0 ≤ x < L, f (x) = 2 π ∞∑ n=1 1 n sin ( nπa L ) − 2 π ∞∑ n=1 1 n sin ( nπa L ) cos ( nπx L ) . (c) Verify that the term 2 π ∞∑ n=1 1 n sin ( nπa L ) is ⟨f (x)⟩ ≡ 1 L ∫ L 0 f (x) dx. 1.15.21 Verify the Fourier cosine expansion of the square wave, Exercise 1.15.20(b), by direct calculation of the Fourier coeﬃcients. 1.15.22 We may deﬁne a sequence δn(x) = { n, |x| < 1/2n, 0, |x| > 1/2n. (This is Eq. (1.171).) Express δn(x) as a Fourier integral (via the Fourier integral theorem, inverse transform, etc.). Finally, show that we may write δ(x) = lim n→∞ δn(x) = 1 2π ∫ ∞ −∞ e −ikx dk. 1.15.23 Using the sequence δn(x) = n √π exp(−n2x 2), CHAPTER 5. UNUSED SIXTH EDITION EXERCISES 438 show that δ(x) = 1 2π ∫ ∞ −∞ e −ikx dk. Note. Remember that δ(x) is deﬁned in terms of its behavior as part of an integrand — especially Eqs. (1.177) and (1.188). 1.15.24 Derive sine and cosine representations of δ(t − x) that are comparable to the exponential representation, Eq. (1.192c). ANS. 2 π ∫ ∞ 0 sin ωt sin ωx dω, 2 π ∫ ∞ 0 cos ωt cos ωx dω. 1.16.1 Implicit in this section is a proof that a function ψ(r) is uniquely speciﬁed by requiring it to (1) satisfy Laplace’s equation and (2) satisfy a complete set of boundary conditions. Develop this proof explicitly. 1.16.2 (a) Assuming that P is a solution of the vector Poisson equation, ∇ 2P(r1) = −V(r1), develop an alternate proof of Helmholtz’s theorem, showing that V may be written as V = −∇ϕ + ∇ × A, where A = ∇ × P, and ϕ = ∇ · P. (b) Solving the vector Poisson equation, we ﬁnd P(r1) = 1 4π ∫ V V(r2) r12 dτ2. Show that this solution substituted into ϕ and A of part (a) leads to the expressions given for ϕ and A in Section 1.16. 2.1.1 Show that limiting our attention to orthogonal coordinate systems impliesgij = 0 for i ̸= j (Eq. (2.7)). Hint. Construct a triangle with sides ds1, ds2, and ds2. Equation (2.9) must hold regardless of whether gij = 0. Then compare ds 2 from Eq. (2.5) with a calculation using the law of cosines. Show thatθ12 = g12/√ g11g22. 2.1.2 In the spherical polar coordinate system, q1 = r, q2 = θ, q3 = ϕ. The transformation equations corresponding to Eq. (2.1) are x = r sin θ cos ϕ, y = r sin θ sin ϕ, z = r cos θ. CHAPTER 5. UNUSED SIXTH EDITION EXERCISES 439 (a) Calculate the spherical polar coordinate scale factors: hr, hθ, and hϕ. (b) Check your calculated scale factors by the relation dsi = hi dqi. 2.1.6 In Minkowski space we deﬁne x1 = x, x2 = y, x3 = z, and x0 = ct. This is done so that the metric interval becomes ds 2 = dx2 − dx2 − dx 2 − dx2 (with c = velocity of light). Show that the metric in Minkowski space is (gij) =  1 0 0 0−1 0 0 0 0 −1 0 0 0 0 −1  . We use Minkowski space in Sections 4.5 and 4.6 for describing Lorentz 2.2.4 Derive ∇ψ = ˆq1 1 h1 ∂ψ ∂q1 + ˆq2 1 h2 ∂ψ ∂q2 + ˆq3 1 h3 ∂ψ ∂q3 by direct application of Eq. (1.97), ∇ψ = lim∫ dτ →0 ∫ ψ dσ ∫ dτ . Hint. Evaluation of the surface integral will lead to terms like (h1h2h3)−1 (∂/∂q1)(ˆq1h2h3). The results listed in Exercise 2.2.3 will be helpful. Cancellation of unwanted terms occurs when the contributions of all three pairs of surfaces are added together. 2.4.9 Solve Laplace’s equation, ∇ 2ψ = 0, in cylindrical coordinates for ψ = ψ(ρ). AN S. ψ = k ln ρ ρ0 . 2.4.11 For the ﬂow of an incompressible viscous ﬂuid the Navier-Stokes equations lead to −∇ × (v × (∇ × v)) = η ρ0 ∇ 2(∇ × v). Here η is the viscosity and ρ0 is the density of the ﬂuid. For axial ﬂow in a cylindrical pipe we take the velocity v to be v = ˆzv(ρ). From Example 2.4.2, ∇ × (v × (∇ × v)) = 0 for this choice of v. CHAPTER 5. UNUSED SIXTH EDITION EXERCISES 440 Show that ∇ 2(∇ × v) = 0 leads to the diﬀerential equation 1 ρ d dρ ( ρ d2v dρ2 ) − 1 ρ2 dv dρ = 0 and that this is satisﬁed by v = v0 + a2ρ2. 2.4.14 A transverse electromagnetic wave (TEM) in a coaxial waveguide has an electric ﬁeld E = E(ρ, ϕ)e i(kz−ωt) and a magnetic induction ﬁeld of B = B(ρ, ϕ)e i(kz−ωt). Since the wave is transverse, neither E nor B has a z component. The two ﬁelds satisfy the vector Laplacian equation ∇ 2E(ρ, ϕ) = 0 ∇2B(ρ, ϕ) = 0. (a) Show that E = ˆρE0(a/ρ)e i(kz−ωt) and B = ˆϕB0(a/ρ)e i(kz−ωt) are solutions. Here a is the radius of the inner conductor and E0 and B0 are constant amplitudes. (b) Assuming a vacuum inside the waveguide, verify that Maxwell’s equa- tions are satisﬁed with B0/E0 = k/ω = µ0ε0(ω/k) = 1/c. 2.4.16 The linear velocity of particles in a rigid body rotating with angular ve- locity ω is given by v = ˆϕρω. Integrate ∮ v · dλ around a circle in the xy-plane and verify that ∮ v · dλ area = ∇ × v|z. 2.4.17 A proton of mass m, charge +e, and (asymptotic) momentum p = mv is incident on a nucleus of charge +Ze at an impact parameter b. Determine the proton’s distance of closest approach. 2.5.6 The direction of one vector is given by the angles θ1 and ϕ1. For a second vector the corresponding angles are θ2 and ϕ2. Show that the cosine of the included angle γ is given by cos γ = cos θ1 cos θ2 + sin θ1 sin θ2 cos(ϕ1 − ϕ2). See Fig. 12.15. CHAPTER 5. UNUSED SIXTH EDITION EXERCISES 441 2.5.11 A particle m moves in response to a central force according to Newton’s second law, m¨r = ˆrf (r). Show that r × ˙r = c, a constant, and that the geometric interpretation of this leads to Kepler’s second law. 2.5.19 One model of the solar corona assumes that the steady-state equation of heat ﬂow, ∇ · (k∇T ) = 0, is satisﬁed. Here, k, the thermal conductivity, is proportional to T 5/2. Assuming that the temperature T is proportional to rn, show that the heat ﬂow equation is satisﬁed by T = T0(r0/r) 2/7. 2.5.22 A magnetic vector potential is given by A = µ0 4π m × r r3 . Show that this leads to the magnetic induction B of a point magnetic dipole with dipole moment m. AN S. for m = ˆzm, ∇ × A = ˆr µ0 4π 2m cos θ r3 + ˆθ µ0 4π m sin θ r3 . Compare Eqs. (12.133) and (12.134) 2.5.23 At large distances from its source, electric dipole radiation has ﬁelds E = aE sin θ e i(kr−ωt) r ˆθ, B = aB sin θ e i(kr−ωt) r ˆϕ. Show that Maxwell’s equations ∇ × E = − ∂B ∂t and ∇ × B = ε0µ0 ∂E ∂t are satisﬁed, if we take aE aB = ω k = c = (ε0µ0) −1/2. Hint. Since r is large, terms of order r−2 may be dropped. 2.5.24 The magnetic vector potential for a uniformly charged rotating spherical shell is A =  ˆϕ µ0a 4σω 3 · sin θ r2 , r > a ˆϕ µ0aσω 3 · r cos θ, r < a. (a = radius of spherical shell, σ= surface charge density, and ω= angular velocity.) Find the magnetic induction B = ∇ × A. CHAPTER 5. UNUSED SIXTH EDITION EXERCISES 442 AN S. Br(r, θ) = 2µ0a 4σω 3 · cos θ r3 , r > a Bθ(r, θ) = µ0a 4σω 3 · sin θ r3 , r > a B = ˆz 2µ0aσω 3 , r < a. 2.5.25 (a) Explain why ∇ 2 in plane polar coordinates follows from ∇2 in cir- cular cylindrical coordinates with z = constant. (b) Explain why taking ∇2 in spherical polar coordinates and restricting θ to π/2 does not lead to the plane polar form of ∇. Note. ∇ 2(ρ, ϕ) = ∂2 ∂ρ2 + 1 ρ ∂ ∂ρ + 1 ρ2 ∂2 ∂ϕ2 . 2.8.3 The exponential in a plane wave is exp[i(k · r − ωt)]. We recognize xµ = (ct, x1, x2, x3) as a prototype vector in Minkowski space. If k · r − ωt is a scalar under Lorentz transformations (Section 4.5), show that kµ = (ω/c, k1, k2, k3) is a vector in Minkowski space. Note. Multiplication by ℏ yields (E/c, p) as a vector in Minkowski space. 2.9.5 (a) Express the components of a cross-product vector C, C = A × B, in terms of εijk and the components of A and B. (b) Use the antisymmetry of εijk to show that A · A × B = 0. AN S. (a) Ci = εijkAjBk. 2.9.6 (a) Show that the inertia tensor (matrix) may be written Iij = m(xixjδij − xixj) for a particle of mass m at (x1, x2, x3). (b) Show that Iij = −MilMlj = −mεilkxkεljmxm, where Mil = m 1/2εilkxk. This is the contraction of two second-rank tensors and is identical with the matrix product of Section 3.2. 2.9.8 Expressing cross products in terms of Levi-Civita symbols (εijk), derive the BAC-CAB rule, Eq. (1.55). Hint. The relation of Exercise 2.9.4 is helpful. 2.9.13 Show that the vector identity (A × B) · (C × D) = (A · C)(B · D) − (A · D)(B · C) (Exercise 1.5.12) follows directly from the description of a cross productεijk and the identity of Exercise 2.9.4. CHAPTER 5. UNUSED SIXTH EDITION EXERCISES 443 2.9.14 Generalize the cross product of two vectors to n-dimensional space for n = 4, 5, . . . . Check the consistency of your construction and discuss concrete examples. See Exercise 1.4.17 for the case n = 2. 2.10.1 Equations (2.115) and (2.116) use the scale factor hi, citing Exercise 2.2.3. In Section 2.2 we had restricted ourselves to orthogonal coordinate sys- tems, yet Eq. (2.115) holds for nonorthogonal systems. Justify the use of Eq. (2.115) for nonorthogonal systems. 2.10.2 (a) Show that ε i · εj = δi j. (b) From the result of part (a) show that F i = F · ε i and Fi = F · εi. 2.10.4 Prove that the contravariant metric tensor is given by gij = ε i · εj. 2.10.7 Transform the right-hand side of Eq. (2.129), ∇ψ = ∂ψ ∂qi εi, into the ei basis, and verify that this expression agrees with the gradient developed in Section 2.2 (for orthogonal coordinates). 2.10.8 Evaluate ∂εi/∂qj for spherical polar coordinates, and from these results calculate Γk for spherical polar coordinates. Note. Exercise 2.5.2 oﬀers a way of calculating the needed partial deriva- tives. Remember, ε1 = ˆr but ε2 = r ˆθ and ε3 = r sin θ ˆϕ. 2.10.13 A triclinic crystal is described using an oblique coordinate system. The three covariant base vectors are ε1 = 1.5ˆx, ε2 = 0.4ˆx + 1.6ˆy, ε3 = 0.2ˆx + 0.3ˆy + 1.0ˆz. (a) Calculate the elements of the covariant metric tensor gij. (b) Calculate the Christoﬀel three-index symbols, Γk . (This is a “by inspection” calculation.) (c) From the cross-product form of Exercise 2.10.3 calculate the con- travariant base vector ε 3. (d) Using the explicit forms ε3 and εi, verify that ε3 · εi = δ3i. CHAPTER 5. UNUSED SIXTH EDITION EXERCISES 444 Note. If it were needed, the contravariant metric tensor could be de- termined by ﬁnding the inverse of gij or by ﬁnding the ε i and using gij = εi · εj. 2.10.14 Verify that [ij, k] = 1 2 { ∂gik ∂qj + ∂gjk ∂qi − ∂gij ∂qk } . Hint. Substitute Eq. (2.135) into the right-hand side and show that an identity results. 2.10.16 Show that parallel displacement δdqi = d2qi along a geodesic. Construct a geodesic by parallel displacement of δdqi. 2.10.17 Construct the covariant derivative of a vector V i by parallel transport starting from the limiting procedure lim dqj →0 V i(qj + dqj) − V i(qj) dqj . 2.11.1 Verify Eq. (2.160), ∂g ∂qk = ggim ∂gim ∂qk , for the speciﬁc case of spherical polar coordinates. 3.1.4 Express the components of A × B as 2 × 2 determinants. Then show that the dot product A · (A × B) yields a Laplacian expansion of a 3 × 3 determinant. Finally, note that two rows of the 3 × 3 determinant are identical and hence that A · (A × B) = 0. 3.1.8 Solve the linear equations a · x = c, a × x + b = 0 for x = (x1, x2, x3) with constant vectors a ̸= 0, b and constant c. ANS. x = c a2 a + (a × b)/a 2. 3.1.9 Solve the linear equations a · x = d, b · x = e, c · x = f, for x = (x1, x2, x3) with constant vectors a, b, c and constants d, e, f such that (a × b) · c ̸= 0. ANS. [(a × b) · c]x = d(b × c) + e(c × a) + f (a × b). 3.1.10 Express in vector form the solution (x1, x2, x3) of ax1 + bx2 + cx3 + d = 0 with constant vectors a, b, c, d so that (a × b) · c ̸= 0. CHAPTER 5. UNUSED SIXTH EDITION EXERCISES 445 3.2.3 Show that matrix A is a linear operator by showing that A(c1r1 + c2r2) = c1Ar1 + c2Ar2. It can be shown that an n × n matrix is the most general linear operator in an n-dimensional vector space. This means that every linear operator in this n-dimensional vector space is equivalent to a matrix. 3.2.7 Given the three matrices A = ( −1 0−1 ) , B = ( 0 1 1 0 ) , C = ( 0 −1 −1 0 ) , ﬁnd all possible products of A, B, and C, two at a time, including squares. Express your answers in terms of A, B, and C, and 1, the unit matrix. These three matrices, together with the unit matrix, form a representation of a mathematical group, the vierergruppe (see Chapter 4). 3.2.19 An operator P commutes with Jx and Jy, the x and y components of an angular momentum operator. Show that P commutes with the third component of angular momentum, that is, that [P, Jz] = 0. Hint. The angular momentum components must satisfy the commutation relation of Exercise 3.2.15(a). 3.2.20 The L + and L − matrices of Exercise 3.2.15 are ladder operators (see Chapter 4): L+ operating on a system of spin projection m will raise the spin projection to m + 1 if m is below its maximum. L+ operating on mmax yields zero. L − reduces the spin projection in unit steps in a similar fashion. Dividing by √2, we have L+ =  0 1 0 0 0 1 0 0 0  , L− =  0 0 0 1 0 0 0 1 0  . Show that L+| − 1⟩ = |0⟩, L −| − 1⟩ = null column vector, L+|0⟩ = |1⟩, L −|0⟩ = | − 1⟩, L +|1⟩ = null column vector, L −|1⟩ = |0⟩, where | − 1⟩ =  0  , |0⟩ =  0  , and |1⟩ =  1  represent states of spin projection −1, 0, and 1, respectively. Note. Diﬀerential operator analogs of these ladder operators appear in Exercise 12.6.7. CHAPTER 5. UNUSED SIXTH EDITION EXERCISES 446 3.2.21 Vectors A and B are related by the tensor T, B = TA. Given A and B, show that there is no unique solution for the compo- nents of T. This is why vector division B/A is undeﬁned (apart from the special case of A and B parallel and T then a scalar). 3.2.22 We might ask for a vector A−1, an inverse of a given vector A in the sense that A · A−1 = A−1 · A = 1. Show that this relation does not suﬃce to deﬁne A−1 uniquely; A would then have an inﬁnite number of inverses. 3.2.27 (a) The operator trace replaces a matrix A by its trace; that is, trace(A) = ∑ i aii. Show that trace is a linear operator. (b) The operator det replaces a matrix A by its determinant; that is, det(A) = determinant of A. Show that det is not a linear operator. 3.2.29 With |x > an N -dimensional column vector and < y| an N -dimensional row vector, show that trace(|x⟩⟨y|) = ⟨y|x⟩. Note. |x⟩⟨y| means direct product of column vector |x⟩ with row vector ⟨y|. The result is a square N × N matrix. 3.2.31 If a matrix has an inverse, show that the inverse is unique. 3.2.33 Show that det A −1 = (det A) −1. Hint. Apply the product theorem of Section 3.2. Note. If det A is zero, then A has no inverse. A is singular. 3.2.37 (a) Rewrite Eq. (2.4) of Chapter 2 (and the corresponding equations forand dz) as a single matrix equation |dxk⟩ = J|dqj⟩. J is a matrix of derivatives, the Jacobian matrix. Show that ⟨dxk|dxk⟩ = ⟨dqi|G|dqj⟩, with the metric (matrix) G having elements gij given by Eq. (2.6). CHAPTER 5. UNUSED SIXTH EDITION EXERCISES 447 (b) Show that det(J)dq1dq2dq3 = dxdydz, with det(J) the usual Jacobian. 3.2.40 Exercise 3.1.7 may be written in matrix form AX = C. Find A −1 and calculate X as A −1C. 3.2.41 (a) Write a subroutine that will multiply complex matrices. Assume that the complex matrices are in a general rectangular form. (b) Test your subroutine by multiplying pairs of the Dirac 4×4 matrices, Section 3.4. 3.2.42 (a) Write a subroutine that will call the complex matrix multiplica- tion subroutine of Exercise 3.2.41 and will calculate the commutator bracket of two complex matrices. (b) Test your complex commutator bracket subroutine with the matrices of Exercise 3.2.16. 3.2.43 Interpolating polynomial is the name given to the (n − 1)-degree poly- nomial determined by (and passing through) n points, (xi, yi) with all the xi distinct. This interpolating polynomial forms a basis for numerical quadratures. (a) Show that the requirement that an (n − 1)-degree polynomial in x passes through each of the n points (xi, yi) with all xi distinct leads to n simultaneous equations of the form n−1∑ j=0 ajx j = yi, i = 1, 2, . . . , n. (b) Write a computer program that will read in n data points and return the n coeﬃcients aj. Use a subroutine to solve the simultaneous equations if such a subroutine is available. (c) Rewrite the set of simultaneous equations as a matrix equation XA = Y. (d) Repeat the computer calculation of part (b), but this time solve for vector A by inverting matrix X (again, using a subroutine). 3.2.44 A calculation of the values of electrostatic potential inside a cylinder leads V (0.0) = 52.640 V (0.6) = 25.844 V (0.2) = 48.292 V (0.8) = 12.648 V (0.4) = 38.270 V (1.0) = 0.0. CHAPTER 5. UNUSED SIXTH EDITION EXERCISES 448 The problem is to determine the values of the argument for which V = 10, 20, 30, 40, and 50. Express V (x) as a series 5∑ n=0 a2nx 2n. (Symmetry requirements in the original problem require that V (x) be an even function of x.) Determine the coeﬃcients a2n. With V (x) now a known function of x, ﬁnd the root of V (x) − 10 = 0, 0 ≤ x ≤ 1. Repeat for V (x) − 20, and so on. AN S. a0 = 52.640 a2 = − 117.676 V (0.6851) = 20. 3.3.3 If A is orthogonal and det A = +1, show that (det A)aij = Cij, where Cij is the cofactor of aij. This yields the identities of Eq. (1.46), used in Section 1.4 to show that a cross product of vectors (in three-space) is itself a vector.Note Exercise 3.2.32. 3.3.9 Show that the trace of a matrix remains invariant under similarity trans- 3.3.10 Show that the determinant of a matrix remains invariant under similarityExercises (3.3.9) and (3.3.10) show that the trace and the determi- nant are independent of the Cartesian coordinates. They are characteris- tics of the matrix (operator) itself. 3.3.11 Show that the property of antisymmetry is invariant under orthogonal similarity transformations. 3.3.14 Show that the sum of the squares of the elements of a matrix remains invariant under orthogonal similarity transformations. 3.3.15 As a generalization of Exercise 3.3.14, show that ∑ jk SjkTjk = ∑ l,m S′ lmT ′ lm, where the primed and unprimed elements are related by an orthogonal similarity transformation. This result is useful in deriving invariants in electromagnetic theory (compare Section 4.6).This product Mjk = ∑ SjkTjk is sometimes called a Hadamard product. In the framework of tensor analysis, Chapter 2, this exercise becomes a double contraction of two second-rank tensors and therefore is clearly a scalar (invariant). 3.3.17 A column vector V has components V1 and V2 in an initial (unprimed) system. Calculate V ′ 1 and V ′ 2 for a CHAPTER 5. UNUSED SIXTH EDITION EXERCISES 449 (a) rotation of the coordinates through an angle of θ counterclockwise, (b) rotation of the vector through an angle of θ clockwise. The results for parts (a) and (b) should be identical. 3.3.18 Write a subroutine that will test whether a real N ×N matrix is symmetric. Symmetry may be deﬁned as 0 ≤ |aij − aji| ≤ ε, where ε is some small tolerance (which allows for truncation error, and so on in the computer). 3.4.8 Show that a Hermitian matrix remains Hermitian under unitary similarity 3.4.11 A particular similarity transformation yields A ′ = UAU −1, A ′† = UA †U −1. If the adjoint relationship is preserved (A † ′ = A ′†) and det U = 1, show that U must be unitary. 3.4.13 An operator T (t + ε, t) describes the change in the wave function from t to t + ε. For ε real and small enough so that ε 2 may be neglected, T (t + ε, t) = 1 − i ℏ εH(t). (a) If T is unitary, show that H is Hermitian. (b) If H is Hermitian, show that T is unitary. Note. When H(t) is independent of time, this relation may be put in exponential form - Exercise 3.4.12. 3.4.14 Show that an alternate form, T (t + ε, t) = 1 − iεH(t)/2ℏ 1 + iεH(t)/2ℏ , agrees with the T of part (a) of Exercise 3.4.13, neglecting ε2, and is exactly unitary (for H Hermitian). 3.4.17 Use the four-dimensional Levi-Civita symbol ελµνρ with ε0123 = −1 (gen- eralizing Eqs. (2.93) in Section 2.9 to four dimensions) and show that (i)γ5σµν = −iεµναβσαβ using the summation convention of Section 2.6 and (ii) γλγµγν = gλµγν − gλνγµ + gµνγλ + iελµνργργ5. Deﬁne γµ = gµνγν using gµν = gµν to raise and lower indices. CHAPTER 5. UNUSED SIXTH EDITION EXERCISES 450 3.4.18 Evaluate the following traces: (see Eq. (3.123) for the notation) (i) trace(γ · aγ · b) = 4a · b, (ii) trace(γ · aγ · bγ · c) = 0, (iii) trace(γ · aγ · bγ · cγ · d) = 4(a · bc · d − a · cb · d + a · db · c), (iv) trace(γ5γ · aγ · bγ · cγ · d) = 4iεαβµνaαbβc µdν. 3.4.21 Show that α × α = 2iσ ⊗ 12, where α = γ0γ is a vector α = (α1, α2, α3). Note that if α is a polar vector (Section 2.4), then σ is an axial vector. 3.4.25 Let x ′ = Λν xν be a rotation by an angle θ about the 3-axis, x ′ = x0, x′ = x1 cos θ + x2 sin θ, x ′ = −x1 sin θ + x2 cos θ, x′ = x3. Use R = exp(iθσ12/2) = cos θ/2 + iσ12 sin θ/2 (see Eq. (3.170b)) and show that the γ’s transform just like the coordinates x µ, that is, Λ ν γν = R−1γµR. (Note that γµ = gµνγν and that the γµ are well deﬁned only up to a similarity transformation.) Similarly, if x′ = Λx is a boost (pure Lorentz transformation) along the 1-axis, that is, x ′ = x0 cosh ζ − x1 sinh ζ, x ′ = −x0 sinh ζ + x1 cosh ζ, x ′ = x2, x′ = x3, with tanh ζ = v/c and B = exp(−iζσ01/2) = cosh ζ/2 − iσ01 sinh ζ/2 (see Eq. (3.170b)), show that Λ ν γν = BγµB−1. 3.4.27 Write a subroutine that will test whether a complex n × n matrix is self- adjoint. In demanding equality of matrix elements aij = a † , allow some small tolerance ε to compensate for truncation error of the computer. 3.4.28 Write a subroutine that will form the adjoint of a complex M × N matrix. 3.4.29 (a) Write a subroutine that will take a complex M × N matrix A and yield the product A †A. Hint. This subroutine can call the subroutines of Exercises 3.2.41 and 3.4.28. (b) Test your subroutine by taking A to be one or more of the Dirac matrices, Eq. (3.124). 3.5.1 (a) Starting with the orbital angular momentum of the ith element of mass, Li = ri × pi = miri × (ω × ri), derive the inertia matrix such that L = Iω, |L⟩ = I|ω⟩. CHAPTER 5. UNUSED SIXTH EDITION EXERCISES 451 Figure 3.6. Mass sites for inertia tensor. (b) Repeat the derivation starting with kinetic energy Ti = 1 2 mi(ω × ri)2 (T = 1 2 ⟨ω|I|ω⟩ ) . 3.5.11 Show that the inertia matrix for a single particle of mass m at (x, y, z) has a zero determinant. Explain this result in terms of the invariance of the determinant of a matrix under similarity transformations (Exercise 3.3.10) and a possible rotation of the coordinate system. 3.5.12 A certain rigid body may be represented by three point masses: m1 = 1 at (1, 1, −2), m2 = 2 at (−1, −1, 0), and m3 = 1 at (1, 1, 2). (a) Find the inertia matrix. (b) Diagonalize the inertia matrix, obtaining the eigenvalues and the principal axes (as orthonormal eigenvectors). 3.5.13 Unit masses are placed as shown in Fig. 3.6 (6th edition). (a) Find the moment of inertia matrix. (b) Find the eigenvalues and a set of orthonormal eigenvectors. (c) Explain the degeneracy in terms of the symmetry of the system. AN S. I =  4 −1 −1 −1 4 −1 −1 −1 4  λ1 = 2 r1 = (1/√ 3, 1/ √3, 1/ √3) λ2 = λ3 = 5. CHAPTER 5. UNUSED SIXTH EDITION EXERCISES 452 3.5.14 A mass m1 = 1/2 kg is located at (1, 1, 1) (meters), a mass m2 = 1/2 kg is at (−1, −1, −1). The two masses are held together by an ideal (weightless, rigid) rod. (a) Find the inertia tensor of this pair of masses. (b) Find the eigenvalues and eigenvectors of this inertia matrix. (c) Explain the meaning, the physical signiﬁcance of the λ = 0 eigen- value. What is the signiﬁcance of the corresponding eigenvector? (d) Now that you have solved this problem by rather sophisticated matrix techniques, explain how you could obtain (1) λ = 0 and λ =? - by inspection (that is, using common sense). (2) rλ=0 =? - by inspection (that is, using freshman physics). 3.5.15 Unit masses are at the eight corners of a cube (±1, ±1, ±1). Find the moment of inertia matrix and show that there is a triple degeneracy. This means that so far as moments of inertia are concerned, the cubic structure exhibits spherical symmetry. 3.5.30 (a) Determine the eigenvalues and eigenvectors of ( 1 ε ε 1 ) . Note that the eigenvalues are degenerate for ε = 0 but that the eigenvectors are orthogonal for all ε ̸= 0 and ε → 0. (b) Determine the eigenvalues and eigenvectors of ( 1 1 2 1 ) . Note that the eigenvalues are degenerate for ε = 0 and that for this (nonsymmetric) matrix the eigenvectors (ε = 0) do not span the space. (c) Find the cosine of the angle between the two eigenvectors as a func- tion of ε for 0 ≤ ε ≤ 1. 3.5.31 (a) Take the coeﬃcients of the simultaneous linear equations of Exer- cise 3.1.7 to be the matrix elements aij of matrix A (symmetric). Calculate the eigenvalues and eigenvectors. (b) Form a matrix R whose columns are the eigenvectors of A, and cal- culate the triple matrix product ˜RAR. AN S. λ = 3.33163. 3.5.32 Repeat Exercise 3.5.31 by using the matrix of Exercise 3.2.39. CHAPTER 5. UNUSED SIXTH EDITION EXERCISES 453 3.6.1 Show that every 2 × 2 matrix has two eigenvectors and corresponding eigenvalues. The eigenvectors are not necessarily orthogonal and may be degenerate. The eigenvalues are not necessarily real. BAD PROBLEM! 4.1.1 Show that an n × n orthogonal matrix has n(n − 1)/2 independent param- eters.. The orthogonality condition, Eq. (3.71), provides constraints. 4.1.2 Show that an n × n unitary matrix has n2 − 1 independent parameters. Hint. Each element may be complex, doubling the number of possible parameters. Some of the constraint equations are likewise complex and count as two constraints. 4.1.3 The special linear group SL(2) consists of all 2 × 2 matrices (with complex elements) having a determinant of +1. Show that such matrices form a. The SL(2) group can be related to the full Lorentz group in Sec- tion 4.4, much as the SU(2) group is related to SO(3). 4.1.4 Show that the rotations about the z-axis form a subgroup of SO(3). Is it an invariant subgroup? 4.1.5 Show that if R, S, T are elements of a group G so that RS = T and R → (rik), S → (sik) is a representation according to Eq. (4.7), then (rik)(sik) = ( tik = ∑ n rinsnk ) , that is, group multiplication translates into matrix multiplication for any group representation. 4.2.1 (i) Show that the Pauli matrices are the generators of SU(2) without using the parameterization of the general unitary 2 × 2 matrix in Eq. (4.38). (ii) Derive the eight independent generators λi of SU(3) similarly. Normalize them so that tr(λiλj) = 2δij. Then determine the structure constants of SU(3). Hint. The λi are traceless and Hermitian 3 × 3 matrices. (iii) Construct the quadratic Casimir invariant of SU(3). Hint. Work by analogy with σ2 1 + σ2 2 + σ2 3 of SU(2) or L 2 of SO(3). 4.2.2 Prove that the general form of a 2 × 2 unitary, unimodular matrix is U = ( a bb ∗ a∗ ) with a ∗a + b ∗b = 1. CHAPTER 5. UNUSED SIXTH EDITION EXERCISES 454 4.2.4 A translation operator T (a) converts ψ(x) to ψ(x + a), T (a)ψ(x) = ψ(x + a). In terms of the (quantum mechanical) linear momentum operator px = −id/dx, show that T (a) = exp(iapx), that is, that px is the generator of translations.. Expand ψ(x + a) as a Taylor series. 4.2.5 Consider the general SU(2) element Eq. (4.38) to be built up of three Euler rotations: (i) a rotation of a/2 about the z-axis, (ii) a rotation of b/2 about the new x-axis, and (iii) a rotation of c/2 about the new z-axis. (All rotations are counterclockwise.) Using the Pauli σ generators, show that these rotation angles are determined by a = ξ − ζ + π 2 = α + π 2 b = 2η = β c = ξ + ζ − π 2 = γ − π 2 . Note. The angles a and b here are not the a and b of Eq. (4.38). 4.2.6 Rotate a nonrelativistic wave function ˜ψ = (ψ↑, ψ↓) of spin 1/2 about the z-axis by a small angle dθ. Find the corresponding generator. 4.3.1 Show that (a) [J+, J2] = 0, (b) [J−, J2] = 0. 4.3.2 Derive the root diagram of SU(3) in Fig. 4.6b from the generators λi in Eq. (4.61).. Work out ﬁrst the SU(2) case in Fig. 4.6a from the Pauli matrices. 4.4.3 When the spin of quarks is taken into account, the SU(3) ﬂavor symmetry is replaced by the SU(6) symmetry. Why? Obtain the Young tableau for the antiquark conﬁguration ¯q. Then decompose the product q ¯q. Which SU(3) representations are contained in the nontrivial SU(6) representation for mesons?. Determine the dimensions of all YT. 4.4.5 Assuming that Dj(α, β, γ) is unitary, show that l∑ m=−l Y m∗ l (θ1, ϕ1)Y m l (θ2, ϕ2) is a scalar quantity (invariant under rotations). This is a spherical tensor analog of a scalar product of vectors. 4.4.6 (a) Show that the α and γ dependence of D j(α, β, γ) may be factored out such that D j(α, β, γ) = A j(α)d j(β)C j(γ). CHAPTER 5. UNUSED SIXTH EDITION EXERCISES 455 (b) Show that A j(α) and Cj(γ) are diagonal. Find the explicit forms. (c) Show that d j(β) = Dj(0, β, 0). 4.4.7 The angular momentum-exponential form of the Euler angle rotation op- erators is R = Rz′′ (γ)Ry′(β)Rz(α) = exp(−iγJz′′ ) exp(−iβJy′) exp(−iαJz). Show that in terms of the original axes R = exp(iαJz) exp(−iβJy) exp(−iγJz). Hint. The R operators transform as matrices. The rotation about the y′-axis (second Euler rotation) may be referred to the original y-axis by exp(−iβJy′) = exp(−iαJz) exp(−iβJy) exp(iαJz). 4.4.8 Using the Wigner-Eckart theorem, prove the decomposition theorem for a spherical vector operator ⟨j′m′|T1m|jm⟩ = ⟨jm ′|J·T1|jm⟩ j(j+1) δjj′. 4.4.9 Using the Wigner-Eckart theorem, prove the factorizationj′m′|JM J · T1|jm⟩ = ⟨jm′|JM |jm⟩δj′j⟨jm|J · T1|jm⟩. 4.5.1 Two Lorentz transformations are carried out in succession: v1 along the x-axis, then v2 along the y-axis. Show that the resultant transformation (given by the product of these two successive transformations) cannot be put in the form of a single Lorentz transformation.. The discrepancy corresponds to a rotation. 4.5.2 Rederive the Lorentz transformation, working entirely in the real spacex0, x 1, x2, x3) with x 0 = x0 = ct. Show that the Lorentz transformation may be written L(v) = exp(ρσ), with σ =  0 −λ −µ −ν −λ 0 0 0 −µ 0 0 0 −ν 0 0 0  and λ, µ, ν the direction cosines of the velocity v. 4.5.3 Using the matrix relation, Eq. (4.136), let the rapidity ρ1 relate the Lorentz reference frames (x ′0, x ′1) and (x 0, x1). Let ρ2 relate (x ′′0, x ′′1) and (x ′0, x ′1). Finally, let ρ relate (x ′′0, x′′1) and (x 0, x1). From ρ = ρ1+ρ2 derive the Einstein velocity addition law v = v1 + v2 1 + v1v2/c2 . CHAPTER 5. UNUSED SIXTH EDITION EXERCISES 456 4.6.1 (a) Show that every four-vector in Minkowski space may be decomposed into an ordinary three-space vector and a three-space scalar. Exam- ples: (ct, r), (ρ, ρv/c), (ε0ϕ, cε0A), (E/c, p), (ω/c, k). Hint. Consider a rotation of the three-space coordinates with time ﬁxed. (b) Show that the converse of (a) is not true - every three-vector plus scalar does not form a Minkowski four-vector. 4.6.2 (a) Show that ∂µjµ = ∂ · j = ∂jµ ∂xµ = 0. (b) Show how the previous tensor equation may be interpreted as a statement of continuity of charge and current in ordinary three- dimensional space and time. (c) If this equation is known to hold in all Lorentz reference frames, why can we not conclude that jµ is a vector? 4.6.3 Write the Lorentz gauge condition (Eq. (4.143)) as a tensor equation in Minkowski space. 4.6.4 A gauge transformation consists of varying the scalar potential ϕ1 and the vector potential A1 according to the relation ϕ2 = ϕ1 + ∂χ ∂t , A2 = A1 − ∇χ. The new function χ is required to satisfy the homogeneous wave equation ∇ 2χ − 1 c2 ∂2χ ∂t2 = 0. Show the following: (a) The Lorentz gauge relation is unchanged. (b) The new potentials satisfy the same inhomogeneous wave equations as did the original potentials. (c) The ﬁelds E and B are unaltered. The invariance of our electromagnetic theory under this transforma- tion is called gauge invariance. 4.6.5 A charged particle, charge q, mass m, obeys the Lorentz covariant equation dpµ dτ = q ε0mc F µνpν, CHAPTER 5. UNUSED SIXTH EDITION EXERCISES 457 where pν is the four-momentum vector (E/c; p1, p2, p3). τ is the proper time; dτ = dt√ 1 − v2/c2, a Lorentz scalar. Show that the explicit space- time forms are dE dt = qv · E; dp dt = q(E + v × B). 4.6.6 From the Lorentz transformation matrix elements (Eq. (4.158)) derive the Einstein velocity addition law u′ = u − v 1 − (uv/c2) or u = u′ + v 1 + (u′v/c2) , where u = cdx3/dx 0 and u′ = cdx′3/dx ′0. Hint. If L12(v) is the matrix transforming system 1 into system 2, L23(u′) the matrix transforming system 2 into system 3, L13(u) the matrix trans- forming system 1 directly into system 3, then L13(u) = L23(u′)L12(v). From this matrix relation extract the Einstein velocity addition law. 4.6.7 The dual of a four-dimensional second-rank tensor B may be deﬁned by ˜B, where the elements of the dual tensor are given by ˜Bij = 1 2! εijklBkl. Show that ˜B transforms as (a) a second-rank tensor under rotations, (b) a pseudotensor under inversions. Note. The tilde here does not mean transpose. 4.6.8 Construct ˜F, the dual of F, where F is the electromagnetic tensor given by Eq. (4.153). AN S. ˜F µν = ε0  0 −cBx −cBy −cBz cBx 0 Ez −Ey cBy −Ez 0 Ex cBz Ey −Ex 0  . This corresponds to cB → −E, E → cB. This transformation, sometimes called a dual transformation, leaves Maxwell’s equations in vacuum (ρ = 0) invariant. CHAPTER 5. UNUSED SIXTH EDITION EXERCISES 458 4.6.9 Because the quadruple contraction of a fourth-rank pseudotensor and two second-rank tensors εµλνσF µλF νσ is clearly a pseudoscalar, evaluate it. AN S. − 8ε 2cB · E. 4.6.10 (a) If an electromagnetic ﬁeld is purely electric (or purely magnetic) in one particular Lorentz frame, show that E and B will be orthogonal in other Lorentz reference systems. (b) Conversely, if E and B are orthogonal in one particular Lorentz frame, there exists a Lorentz reference system in which E (or B) vanishes. Find that reference system. 4.6.11 Show that c 2B2 − E2 is a Lorentz scalar. 4.6.12 Since (dx0, dx1, dx2, dx3) is a four-vector, dxµdx µ is a scalar. Evaluate this scalar for a moving particle in two diﬀerent coordinate systems: (a) a coordinate system ﬁxed relative to you (lab system), and (b) a coordinate system moving with a moving particle (velocity v relative to you). With the time increment labeled dτ in the particle system and dt in the lab system, show that dτ = dt√ 1 − v2/c2. τ is the proper time of the particle, a Lorentz invariant quantity. 4.6.13 Expand the scalar expression − 1 4ε0 FµνF µν + 1 ε0 jµA µ in terms of the ﬁelds and potentials. The resulting expression is the La- grangian density used in Exercise 17.5.1. 4.6.14 Show that Eq. (4.157) may be written εαβγδ ∂F αβ ∂xγ = 0. 4.7.1 Show that the matrices 1, A, B, and C of Eq. (4.165) are reducible. Reduce them.. This means transforming A and C to diagonal form (by the same unitary transformation).. A and C are anti-Hermitian. Their eigenvectors will be orthogonal. 4.7.2 Possible operations on a crystal lattice include Aπ (rotation by π), m (reﬂection), and i (inversion). These three operations combine as A2 = m 2 = i 2 = 1, Aπ · m = i, m · i = Aπ, and i · Aπ = m. Show that the group (1, Aπ, m, i) is isomorphic with the vierergruppe. CHAPTER 5. UNUSED SIXTH EDITION EXERCISES 459 4.7.3 Four possible operations in the xy-plane are: 1. no change { x → x y → y 2. inversion { x → −x y → −y 3. reﬂection { x → −x y → y 4. reﬂection { x → x y → −y. (a) Show that these four operations form a group. (b) Show that this group is isomorphic with the vierergruppe. (c) Set up a 2 × 2 matrix representation. 4.7.5 Using the 2×2 matrix representation of Exercise 3.2.7 for the vierergruppe, (a) Show that there are four classes, each with one element. (b) Calculate the character (trace) of each class. Note that two diﬀerent classes may have the same character. (c) Show that there are three two-element subgroups. (The unit element by itself always forms a subgroup.) (d) For any one of the two-element subgroups show that the subgroup and a single coset reproduce the original vierergruppe. Note that subgroups, classes, and cosets are entirely diﬀerent. 4.7.6 Using the 2 × 2 matrix representation, Eq. (4.165), of C4, (a) Show that there are four classes, each with one element. (b) Calculate the character (trace) of each class. (c) Show that there is one two-element subgroup. (d) Show that the subgroup and a single coset reproduce the original 4.7.7 Prove that the number of distinct elements in a coset of a subgroup is the same as the number of elements in the subgroup. 4.7.11 Explain how the relation ∑ i n2 = h applies to the vierergruppe (h = 4) and to the dihedral group D3 with h = 6. CHAPTER 5. UNUSED SIXTH EDITION EXERCISES 460 4.7.12 Show that the subgroup (1, A, B) of D3 is an invariant subgroup. 4.7.16 The elements of the dihedral group Dn may be written in the form S λRµ(2π/n), λ = 0, 1 µ = 0, 1, . . . , , n − 1, where Rz(2π/n) represents a rotation of 2π/n about the n-fold symmetry axis, whereas S represents a rotation of π about an axis through the center of the regular polygon and one of its vertices. For S = E show that this form may describe the matrices A, B, C, and D of D3. Note. The elements Rz and S are called the generators of this ﬁnite group. Similarly, i is the generator of the group given by Eq. (4.164). 4.7.19 The permutation group of four objects contains 4! = 24 elements. From Exercise 4.7.18, D4, the symmetry group for a square, has far fewer than 24 elements. Explain the relation between D4 and the permutation group of four objects. 4.7.22 (a) From the D3 multiplication table of Fig. 4.18 construct a similarity transform table showing xyx−1, where x and y each range over all six elements of D3:. (b) Divide the elements of D3 into classes. Using the 2 × 2 matrix repre- sentation of Eqs. (4.169) - (4.172) note the trace (character) of each 4.8.1 Evaluate the 1-form adx + 2bdy + 4cdz on the line segment P Q with P = (3, 5, 7), Q = (7, 5, 3). 4.8.3 Evaluate the ﬂow described by the 2-form dxdy + 2dydz + 3dzdx across the oriented triangle P QR with corners at P = (3, 1, 4), Q = (−2, 1, 4), R = (1, 4, 1). 4.8.4 Are the points, in this order, (0, 1, 1), (3, −1, −2), (4, 2, −2), (−1, 0, 1) coplanar, or do they form an oriented volume (right-handed or left-handed)? 4.8.6 Describe the electric ﬁeld by the 1-form E1dx + E2dy + E3dz and the mag- netic induction by the 2-form B1dydz +B2dzdx+B3dxdy. Then formulate Faraday’s induction law in terms of these forms. 4.8.7 Evaluate the 1-form xdy x2 + y2 − ydx x2 + y2 on the unit circle about the origin oriented counterclockwise. CHAPTER 5. UNUSED SIXTH EDITION EXERCISES 461 4.8.8 Find the pullback of dxdz under x = u cos v, y = u − v, z = u sin v. 4.8.9 Find the pullback of the 2-form dydz + dzdx + dxdy under the map x = sin θ cos ϕ, y = sin θ sin ϕ, z = cos θ. 4.8.10 Parameterize the surface obtained by rotating the circle (x − 2)2 + z2 = 1, y = 0, about the z-axis in a counterclockwise orientation, as seen from outside. 4.8.12 Show that n∑ i=1 x 2 = a 2 deﬁnes a diﬀerentiable manifold of dimension D = n − 1 if a ̸= 0 and D = 0 if a = 0. 4.8.13 Show that the set of orthogonal 2 × 2 matrices form a diﬀerentiable man- ifold, and determine its dimension. 4.8.14 Determine the value of the 2-form Adydz + Bdzdx + Cdxdy on a parallel- ogram with sides a, b. 4.8.15 Prove Lorentz invariance of Maxwell’s equations in the language of diﬀer- ential forms. 5.1.1 Show that ∞∑ n=1 1 (2n − 1)(2n + 1) = 1 2 . Hint. Show (by mathematical induction) that sm = m/(2m + 1). 5.1.2 Show that ∞∑ n=1 1 n(n + 1) = 1. Find the partial sum sm and verify its correctness by mathematical in- duction.. The method of expansion in partial fractions, Section 15.8, oﬀers an alternative way of solving Exercises 5.1.1 and 5.1.2. 5.2.3 Show that the complete d’Alembert ratio test follows directly from Kum- mer’s test with ai = 1. 5.2.9 Determine the range of convergence for Gauss’s hypergeometric series F (α, β; γ; x) = 1 + αβ 1!γ x + α(α + 1)β(β + 1) 2!γ(γ + 1) x 2 + · · · . Hint. Gauss developed his test for the speciﬁc purpose of establishing the convergence of this series. AN S. Convergent for −1 < x < 1 and x = ±1 if γ > α + β. CHAPTER 5. UNUSED SIXTH EDITION EXERCISES 462 5.2.10 A pocket calculator yields 100∑ n=1 n−3 = 1.202 007. Show that 1.202056 ≤ ∞∑ n=1 n−3 ≤ 1.202 057. Hint. Use integrals to set upper and lower bounds on ∑∞=101 n−3. Note. A more exact value for summation of ζ(3) = ∞∑ n=1 n−3 is 1.202 056 903· · · ; ζ(3) is known to be an irrational number, but it is not linked to known constants such as e, π, γ, ln 2. 5.2.11 Set upper and lower bounds on ∑1,000,000 n=1 n−1, assuming that (a) the Euler-Mascheroni constant is known. AN S. 14.392726 < 1,000,000∑ n=1 n−1 < 14.392 727. (b) The Euler-Mascheroni constant is unknown. 5.2.19 Show that the following series is convergent. ∞∑ s=0 (2s − 1)!! (2s)!!(2s + 1) . Note. (2s − 1)!! = (2s − 1)(2s − 3) · · · 3 · 1 with (−1)!! = 1; (2s)!! = (2s)(2s − 2) · · · 4 · 2 with 0!! = 1. The series appears as a series expansion of sin −1(1) and equals π/2, and sin −1 x ≡ arcsin x ̸= (sin x)−1. 5.3.1 (a) From the electrostatic two-hemisphere problem (Exercise 12.3.20) we obtain the series ∞∑ s=0(−1) s(4s + 3) (2s − 1)!! (2s + 2)!! . Test it for convergence. (b) The corresponding series for the surface charge density is ∞∑ s=0(−1) s(4s + 3) (2s − 1)!! (2s)!! . Test it for convergence. The !! notation is explained in Section 8.1 and Exercise 5.2.19. CHAPTER 5. UNUSED SIXTH EDITION EXERCISES 463 5.3.2 Show by direct numerical computation that the sum of the ﬁrst 10 terms lim x→1 ln(1 + x) = ln 2 = ∞∑ n=1(−1) n−1n−1 diﬀers from ln 2 by less than the eleventh term: ln 2 = 0.69314 71806 · · · . 5.3.3 In Exercise 5.2.9 the hypergeometric series is shown convergent for x = ±1, if γ > α + β. Show that there is conditional convergence for x = −1 for γ down to γ > α + β − 1. Hint. The asymptotic behavior of the factorial function is given by Stir- ling’s series, Section 8.3. 5.4.2 Determine the values of the coeﬃcients a1, a2, and a3 that will make (1 + a1x + a2x 2 + a3x 3) ln(1 + x) converge as n−4 . Find the resulting series. 5.4.4 Write a program that will rearrange the terms of the alternating harmonic series to make the series converge to 1.5. Group your terms as indicated in Eq. (5.61). List the ﬁrst 100 successive partial sums that just climb above 1.5 or just drop below 1.5, and list the new terms included in each such partial sum. AN S. n 1 2 3 4 5 sn 1.5333 1.0333 1.5218 1.2718 1.5143 5.6.2 Derive a series expansion of cot x in increasing powers of x by dividing cos x by sin x. Note. The resultant series that starts with 1/x is actually a Laurent series (Section 6.5). Although the two series for sin x and cos x were valid for all x, the convergence of the series for cot x is limited by the zeros of the denominator, sin x (see Analytic Continuation in Section 6.5). 5.6.3 The Raabe test for ∑ n(n ln n)−1 leads to lim n→∞ n [ (n + 1) ln(n + 1) n ln n − 1 ] . Show that this limit is unity (which means that the Raabe test here is 5.6.6 Let x be an approximation for a zero of f (x) and ∆x be the correction. Show that by neglecting terms of order (∆x) 2, ∆x = − f (x) f ′(x) . This is Newton’s formula for ﬁnding a root. Newton’s method has the virtues of illustrating series expansions and elementary calculus but is very treacherous. CHAPTER 5. UNUSED SIXTH EDITION EXERCISES 464 5.6.7 Expand a function Φ(x, y, z) by Taylor’s expansion about (0,0,0) to O(a3). Evaluate ¯Φ, the average value of Φ, averaged over a small cube of side a centered on the origin and show that the Laplacian of Φ is a measure of deviation of Φ from Φ(0, 0, 0). 5.6.22 You have a function y(x) tabulated at equally spaced values of the argu- ment { yn = y(xn) xn = x + nh. Show that the linear combination 1 12h {−y2 + 8y1 − 8y−1 + y−2} yields y′ 0 − h4 30 y(5) 0 + · · · . Hence this linear combination yields y′ 0 if (h4/30)y(5) 0 and higher powers of h and higher derivatives of y(x) are negligible. 5.6.23 In a numerical integration of a partial diﬀerential equation, the three- dimensional Laplacian is replaced by ∇ 2ψ(x, y, z) → h−2 [ψ(x + h, y, z) + ψ(x − h, y, z) + ψ(x, y + h, z) + ψ(x, y − h, z) + ψ(x, y, z + h) + ψ(x, y, z − h) − 6ψ(x, y, z)]. Determine the error in this approximation. Here h is the step size, the distance between adjacent points in the x-, y-, or z-direction. 5.6.24 Using double precision, calculate e from its Maclaurin series. Note. This simple, direct approach is the best way of calculating e to high accuracy. Sixteen terms give e to 16 signiﬁcant ﬁgures. The reciprocal factorials give very rapid convergence. 5.7.2 The depolarizing factor L for an oblate ellipsoid in a uniform electric ﬁeld parallel to the axis of rotation is L = 1 ε0 (1 + ζ 2 0 )(1 − ζ0 cot−1 ζ0), where ζ0 deﬁnes an oblate ellipsoid in oblate spheroidal coordinates (ξ, ζ, ϕ). Show that lim ζ0→∞ L = 1 3ε0 (sphere), lim ζ0→0 L = 1 ε0 (thin sheet). CHAPTER 5. UNUSED SIXTH EDITION EXERCISES 465 5.7.3 The depolarizing factor (Exercise 5.7.2) for a prolate ellipsoid is L = 1 ε0 (η2 0 − 1) ( 1 2 η0 ln η0 + 1 η0 − 1 − 1) . Show that lim η0→∞ L = 1 3ε0 (sphere), lim η0→0 L = 0 (long needle). 5.7.4 The analysis of the diﬀraction pattern of a circular opening involves ∫ 2π 0 cos(c cos ϕ)dϕ. Expand the integrand in a series and integrate by using ∫ 2π 0 cos2n ϕdϕ = (2n)! 22n(n!)2 · 2π, ∫ 2π 0 cos2n+1 ϕdϕ = 0. The result is 2π times the Bessel function J0(c). 5.7.5 Neutrons are created (by a nuclear reaction) inside a hollow sphere ofR. The newly created neutrons are uniformly distributed over the spherical volume. Assuming that all directions are equally probable (isotropy), what is the average distance a neutron will travel before striking the surface of the sphere? Assume straight-line motion and no collisions. (a) Show that ¯r = 3 2 R ∫ 1 0 ∫ π 0 √ 1 − k2 sin 2 θk2 dk sin θ dθ. (b) Expand the integrand as a series and integrate to obtain ¯r = R [ 1 − 3 ∞∑ n=1 1 (2n − 1)(2n + 1)(2n + 3) ] . (c) Show that the sum of this inﬁnite series is 1/12, giving ¯r = 3 4 R. Hint. Show that sn = 1/12 − [4(2n + 1)(2n + 3)]−1 by mathematical induction. Then let n → ∞. 5.7.8 Derive the series expansion of the incomplete beta function Bx(p, q) = ∫ x 0 tp−1(1 − t) q−1dt = x p { 1 p + 1 − q p + 1 x + · · · + (1 − q) · · · (n − q) n!(p + n) x n + · · · } for 0 ≤ x ≤ 1, p > 0, and q > 0 (if x = 1). CHAPTER 5. UNUSED SIXTH EDITION EXERCISES 466 5.7.10 Neutron transport theory gives the following expression for the inverse neutron diﬀusion length of k: a − b k tanh −1 ( k a ) = 1. By series inversion or otherwise, determine k2 as a series of powers of b/a. Give the ﬁrst two terms of the series. AN S. k2 = 3ab ( 1 − 4 5 b a ) . 5.7.12 A function f (z) is represented by a descending power series f (z) = ∞∑ n=0 anz−n, R ≤ z < ∞. Show that this series expansion is unique; that is, if f (z) = ∞∑ n=0 bnz−n, R ≤ z < ∞, then an = bn for all n. 5.7.14 Assuming that f (x) may be expanded in a power series about the origin, f (x) = ∑∞=0 anxn, with some nonzero range of convergence. Use the techniques employed in proving uniqueness of series to show that your assumed series is a Maclaurin series: an = 1 n! f (n)(0). 5.7.18 Calculate π (double precision) by each of the following arc tangent expres- sions: π = 16 tan −1(1/5) − 4 tan −1(1/239) π = 24 tan −1(1/8) + 8 tan −1(1/57) + 4 tan −1(1/239) π = 48 tan −1(1/18) + 32 tan −1(1/57) − 20 tan−1(1/239). Obtain 16 signiﬁcant ﬁgures. Verify the formulas using Exercise 5.6.2.. These formulas have been used in some of the more accurate calcu- lations of π. 162 5.7.19 An analysis of the Gibbs phenomenon of Section 14.5 leads to the expres- 2 π ∫ π 0 sin ξ ξ dξ. (a) Expand the integrand in a series and integrate term by term. Find the numerical value of this expression to four signiﬁcant ﬁgures. 216D. Shanks and J. W. Wrench, Computation of π to 100 000 decimals. Math. Comput. 16: 76 (1962). CHAPTER 5. UNUSED SIXTH EDITION EXERCISES 467 (b) Evaluate this expression by the Gaussian quadrature if available. AN S. 1.178980. 5.8.7 (a) Write a function subroutine that will compute E(m) from the series expansion, Eq. (5.137). (b) Test your function subroutine by using it to calculate E(m) over the range m = 0.0(0.1)0.9 and comparing the result with the values given by AMS-55 (see footnote 4 for this reference). 5.8.8 Repeat Exercise 5.8.7 for K(m). Note. These series for E(m), Eq. (5.137), and K(m), Eq. (5.136), converge only very slowly for m near 1. More rapidly converging series for E(m) and K(m) exist. See Dwight’s Tables of Integrals: 183 No. 773.2 and 774.2. Your computer subroutine for computing E and K probably uses polynomial approximations: AMS-55, Chapter 17 (see footnote 4 for this 5.8.9 A simple pendulum is swinging with a maximum amplitude of θM . In the limit as θM → 0, the period is 1 s. Using the elliptic integral, K(k2), k = sin(θM /2), calculate the period T for θM = 0 (10◦) 90 ◦. Caution. Some elliptic integral subroutines require k = m1/2 as an input parameter, not m itself. Check values. θM 10 ◦ 50◦ 90◦ T (sec) 1.00193 1.05033 1.18258 5.8.10 Calculate the magnetic vector potential A(ρ, ϕ, z) = ˆϕAϕ(ρ, ϕ, z) of a circular current loop (Exercise 5.8.4) for the ranges ρ/a = 2, 3, 4, and z/a = 0, 1, 2, 3, 4. Note. This elliptic integral calculation of the magnetic vector potential may be checked by an associated Legendre function calculation, Exam- ple 12.5.1. Check value. For ρ/a = 3 and z/a = 0; Aϕ = 0.029023µ0I. 5.9.3 Show that B′ n(s) = nBn−1(s), n = 1, 2, 3, . . . Hint. Diﬀerentiate Eq. (5.158). 5.9.4 Show that Bn(1) = (−1) nBn(0). Hint. Go back to the generating function, Eq. (5.158), or Exercise 5.9.2. 318H. B. Dwight, Tables of Integrals and Other Mathematical Data. New York: Macmillan (1947). CHAPTER 5. UNUSED SIXTH EDITION EXERCISES 468 5.9.7 Planck’s blackbody radiation law involves the integral ∫ ∞ 0 x 3dx ex − 1 . Show that this equals 6ζ(4). From Exercise 5.9.6, ζ(4) = π4 90 . Hint. Make use of the gamma function, Chapter 8. 5.9.19 Write a function subprogram ZETA(N ) that will calculate the Riemann zeta function for integer argument. Tabulate ζ(s) for s = 2, 3, 4, . . . , 20. Check your values against Table 5.3 and AMS-55, Chapter 23 (see foot- note 4 for this reference).. If you supply the function subprogram with the known values of ζ(2), ζ(3), and ζ(4), you avoid the more slowly converging series. Calcu- lation time may be further shortened by using Eq. (5.170). 5.9.20 Calculate the logarithm (base 10) of |B2n|, n = 10, 20, . . . , 100. Hint. Program ζ(n) as a function subprogram, Exercise 5.9.19. Check values. log |B100| = 78.45 log |B200| = 215.56. 5.10.1 Stirling’s formula for the logarithm of the factorial function is ln(x!) = 1 2 ln 2π + ( x + 1 2 ) ln x − x − N∑ n=1 B2n 2n(2n − 1) x 1−2n. The B2n are the Bernoulli numbers (Section 5.9). Show that Stirling’s formula is an asymptotic expansion. 5.10.9 Calculate partial sums of e xE1(x) for x = 5, 10, and 15 to exhibit the behavior shown in Fig. 5.11. Determine the width of the throat for x = 10 and 15, analogous to Eq. (5.183). ANS. Throat width: n = 10, 0.000051 n = 15, 0.0000002. 5.10.10 The knife-edge diﬀraction pattern is described by I = 0.5I0 {[C(u0) + 0.5] 2 + [S(u0) + 0.5] 2} , where C(u0) and S(u0) are the Fresnel integrals of Exercise 5.10.2. Here I0 is the incident intensity and I is the diﬀracted intensity; u0 is proportional to the distance away from the knife edge (measured at right angles to the incident beam). Calculate I/I0 for u0 varying from −1.0 to +4.0 in steps of 0.1. Tabulate your results and, if a plotting routine is available, plot CHAPTER 5. UNUSED SIXTH EDITION EXERCISES 469 Check value. u0 = 1.0, I/I0 = 1.259226. 5.11.6 Prove that ∞∏ n=2 ( 1 − 1 n2 ) = 1 2 . 5.11.10 Calculate cos x from its inﬁnite product representation, Eq. (5.211), using (a) 10, (b) 100, and (c) 1000 factors in the product. Calculate the absolute error. Note how slowly the partial products converge - making the inﬁnite product quite unsuitable for precise numerical work. ANS. For 1000 factors, cos π = −1.00051. 6.1.2 The complex quantities a = u + iv and b = x + iy may also be represented as two-dimensional vectors, a = ˆxu + ˆyv, b = ˆxx + ˆyy. Show that a ∗b = a · b + iˆz · a × b. 6.1.3 Prove algebraically that for complex numbers, |z1| − |z2| ≤ |z1 + z2| ≤ |z1| + |z2|. Interpret this result in terms of two-dimensional vectors. Prove that |z − 1| < |√z2 − 1| < |z + 1|, for ℜ(z) > 0. 6.1.4 We may deﬁne a complex conjugation operator K such that Kz = z∗. Show that K is not a linear operator. 6.1.8 For −1 < p < 1 prove that (a) ∞∑ n=0 pn cos nx = 1 − p cos x 1 − 2p cos x + p2 , (b) ∞∑ n=0 pn sin nx = p sin x 1 − 2p cos x + p2 . These series occur in the theory of the Fabry-Perot interferometer. 6.1.9 Assume that the trigonometric functions and the hyperbolic functions are deﬁned for complex argument by the appropriate power series sin z = ∞∑ n=1,odd(−1)(n−1)/2 zn n! = ∞∑ s=0(−1) s z2s+1 (2s + 1)! , cos z = ∞∑ n=0,even (−1)n/2 zn n! = ∞∑ s=0(−1) s z2s (2s)! , sinh z = ∞∑ n=1,odd zn n! = ∞∑ s=0 z2s+1 (2s + 1)! , cosh z = ∞∑ n=0,even zn n! = ∞∑ s=0 z2s (2s)! . CHAPTER 5. UNUSED SIXTH EDITION EXERCISES 470 (a) Show that i sin z = sinh iz, sin iz = i sinh z, cos z = cosh iz, cos iz = cosh z. (b) Verify that familiar functional relations such as cosh z = e z + e −z 2 , sin(z1 + z2) = sin z1 cos z2 + sin z2 cos z1, still hold in the complex plane. 6.1.12 Prove that| sin z| ≥ | sin x| (b) | cos z| ≥ | cos x|. 6.1.13 Show that the exponential function e z is periodic with a pure imaginary period of 2πi. 6.1.15 Find all the zeros of (a) sin z, (b) cos z, (c) sinh z, (d) cosh z. 6.1.16 Show that (a) sin −1 z = −i ln(iz ± √1 − z2), (d) sinh −1 z = ln(z + √ z2 + 1), (b) cos−1 z = −i ln(z ± √z2 − 1), (e) cosh−1 z = ln(z + √ z2 − 1), (c) tan−1 z = i 2 ln ( i + z i − z ) , (f) tanh −1 z = 1 2 ln ( 1 + z 1 − z ) . Hint. 1. Express the trigonometric and hyperbolic functions in terms of exponentials. 2. Solve for the exponential and then for the exponent. 6.1.17 In the quantum theory of photoionization we encounter the identity ( ia − 1 ia + 1 )ib = exp(−2b cot−1 a), in which a and b are real. Verify this identity. 6.1.18 A plane wave of light of angular frequency ω is represented by e iω(t−nx/c). In a certain substance the simple real index of refraction n is replaced by the complex quantity n − ik. What is the eﬀect of k on the wave? What does k correspond to physically? The generalization of a quantity from real to complex form occurs frequently in physics. Examples range from the complex Young’s modulus of viscoelastic materials to the complex (optical) potential of the “cloudy crystal ball” model of the atomic nucleus. 6.1.19 We see that for the angular momentum components deﬁned in Exer- cise 2.5.14 Lx − iLy ̸= (Lx + iLy) ∗. Explain why this occurs. CHAPTER 5. UNUSED SIXTH EDITION EXERCISES 471 6.1.20 Show that the phase of f (z) = u + iv is equal to the imaginary part of the logarithm of f (z). Exercise 8.2.13 depends on this result. 6.1.21 (a) Show that e ln z always equals z. (b) Show that ln e z does not always equal z. 6.1.22 The inﬁnite product representations of Section 5.11 hold when the real variable x is replaced by the complex variable z. From this, develop inﬁnite product representations for (a) sinh z, (b) cosh z. 6.1.23 The equation of motion of a mass m relative to a rotating coordinate system is m d2r dt2 = F − mω × (ω × r) − 2m ( ω × dr dt ) − m ( dω dt × r ) . Consider the case F = 0, r = ˆxx + ˆyy, and ω = ωˆz, with ω constant. Show that the replacement of r = ˆxx + ˆyy by z = x + iy leads to d2z dt2 + i2ω dz dt − ω2z = 0. Note. This ODE may be solved by the substitution z = f e −iωt. 6.1.24 Using the complex arithmetic available in FORTRAN, write a program that will calculate the complex exponential e z from its series expansion (deﬁnition). Calculate e z for z = e inπ/6, n = 0, 1, 2, . . . , 12. Tabulate the phase angle (θ = nπ/6), ℜz, ℑz, ℜ(e z), ℑ(e z), |e z|, and the phase of e z. Check value. n = 5, θ = 2.61799, ℜ(z) = −0.86602, ℑz = 0.50000, ℜ(e z) = 0.36913, ℑ(e z) = 0.20166, |e z| = 0.42062, phase(e z) = 0.50000. 6.1.25 Using the complex arithmetic available in FORTRAN, calculate and tab-ℜ(sinh z), ℑ(sinh z), | sinh z|, and phase(sinh z) for x = 0.0(0.1)1.0 and y = 0.0(0.1)1.0. Hint. Beware of dividing by zero when calculating an angle as an arc tangent. Check value. z = 0.2 + 0.1i, ℜ(sinh z) = 0.20033, ℑ(sinh z) = 0.10184, | sinh z| = 0.22473, phase(sinh z) = 0.47030. 6.1.26 Repeat Exercise 6.1.25 for cosh z. 6.2.1 The functions u(x, y) and v(x, y) are the real and imaginary parts, respec- tively, of an analytic function w(z). CHAPTER 5. UNUSED SIXTH EDITION EXERCISES 472 (a) Assuming that the required derivatives exist, show that ∇ 2u = ∇ 2v = 0. Solutions of Laplace’s equation such as u(x, y) and v(x, y) are called harmonic functions. (b) Show that ∂u ∂x ∂u ∂y + ∂v ∂x ∂v ∂y = 0. and give a geometric interpretation.. The technique of Section 1.6 allows you to construct vectors normal to the curves u(x, y) = ci and v(x, y) = cj. 6.2.7 The function f (z) = u(x, y) + iv(x, y) is analytic. Show that f ∗(z∗) is also analytic. 6.2.11 A proof of the Schwarz inequality (Section 10.4) involves minimizing an f = ψaa + λψab + λ∗ψ∗ ab + λλ∗ψbb ≥ 0. The ψ are integrals of products of functions; ψaa and ψbb are real, ψab is complex and λ is a complex parameter. (a) Diﬀerentiate the preceding expression with respect to λ∗, treating λ as an independent parameter, independent of λ∗. Show that setting the derivative ∂f /∂λ ∗ equal to zero yields λ = − ψ∗ ab ψbb . (b) Show that ∂f /∂λ = 0 leads to the same result. (c) Let λ = x + iy, λ ∗ = x − iy. Set the x and y derivatives equal to zero and show that again λ = − ψ∗ ab ψbb . This independence of λ and λ∗ appears again in Section 17.7. 6.4.8 Using the Cauchy integral formula for the nth derivative, convert the following Rodrigues formulas into the corresponding so-called Schlaeﬂi in- (a) Legendre: Pn(x) = 1 2nn! dn dxn (x2 − 1) n. ANS. (−1)n 2n · 1 2πi ∮ (1 − z2)n (z − x)n+1 dz CHAPTER 5. UNUSED SIXTH EDITION EXERCISES 473 (b) Hermite: Hn(x) = (−1) ne x2 dn dxn e −x2. (c) Laguerre: Ln(x) = e x n! dn dxn (x ne −x). Note. From the Schlaeﬂi integral representations one can develop gen- erating functions for these special functions. Compare Sections 12.4, 13.1, and 13.2. 6.5.8 Develop the ﬁrst three nonzero terms of the Laurent expansion of f (z) = (e z − 1)−1 about the origin. Notice the resemblance to the Bernoulli number-generating function, Eq. (5.144) of Section 5.9. 6.6.1 The function f (z) expanded in a Laurent series exhibits a pole of order m at z = z0. Show that the coeﬃcient of (z − z0)−1, a−1, is given by a−1 = 1 (m − 1)! dm−1 dzm−1 [(z − z0) mf (z)]z=z0 , with a−1 = [(z − z0)f (z)]z=z0 , when the pole is a simple pole (m = 1). These equations for a−1 are extremely useful in determining the residue to be used in the residue the- orem of Section 7.1.. The technique that was so successful in proving the uniqueness of power series, Section 5.7, will work here also. 6.6.3 In analogy with Example 6.6.1, consider in detail the phase of each factor and the resultant overall phase of f (z) = (z2 + 1)1/2 following a contour similar to that of Fig. 6.16 but encircling the new branch points. 6.6.4 The Legendre function of the second kind, Qν(z), has branch points at z = ±1. The branch points are joined by a cut line along the real (x)-axis. (a) Show that Q0(z) = 1 2 ln((z + 1)/(z − 1)) is single-valued (with the real axis −1 ≤ x ≤ 1 taken as a cut line). (b) For real argument x and |x| < 1 it is convenient to take Q0(x) = 1 2 ln 1+x 1−x . Show that Q0(x) = 1 2 [Q0(x + i0) + Q0(x − i0)]. Here x + i0 indicates that z approaches the real axis from above, and x − i0 indicates an approach from below. CHAPTER 5. UNUSED SIXTH EDITION EXERCISES 474 6.7.3 Discuss the transformations (a) w(z) = sin z, (c) w(z) = sinh z, (b) w(z) = cos z, (d) w(z) = cosh z. Show how the lines x = c1, y = c2 map into the w-plane. Note that the last three transformations can be obtained from the ﬁrst one by appropriate translation and/or rotation. 6.7.6 An integral representation of the Bessel function follows the contour int-plane shown in Fig. 6.24. Map this contour into the θ-plane with t = e θ. Many additional examples of mapping are given in Chapters 11, 12, and 13. 6.8.1 Expand w(x) in a Taylor series about the point z = z0, where f ′(z0) = 0. (Angles are not preserved.) Show that if the ﬁrst n − 1 derivatives vanish but f (n)(z0) ̸= 0, then angles in the z-plane with vertices at z = z0 appear in the w-plane multiplied by n. 6.8.2 Develop the transformations that create each of the four cylindrical coor- dinate systems: (a) Circular cylindrical: x = ρ cos ϕ, y = ρ sin ϕ. (b) Elliptic cylindrical: x = a cosh u cos v, y = a sinh u sin v. (c) Parabolic cylindrical: x = ξη, y = 1 2 (η2 − ξ2). (d) Bipolar: x = a sinh η cosh η − cos ξ . y = a sin ξ cosh η − cos ξ . Note. These transformations are not necessarily analytic. 6.8.3 In the transformation e z = a − w a + w , how do the coordinate lines in the z-plane transform? What coordinate system have you constructed? 7.1.2 Locate the singularities and evaluate the residues of each of the following (a) z−n(e z − 1)−1, z ̸= 0, (b) z2e z 1 + e2z . (c) Find a closed-form expression (that is, not a sum) for the sum of the ﬁnite-plane singularities. (d) Using the result in part (c), what is the residue at |z| → ∞? CHAPTER 5. UNUSED SIXTH EDITION EXERCISES 475 Hint. See Section 5.9 for expressions involving Bernoulli numbers. Note that Eq. (5.144) cannot be used to investigate the singularity at z → ∞, since this series is only valid for |z| < 2π. 7.1.23 Several of the Bromwich integrals, Section 15.12, involve a portion that may be approximated by I(y) = ∫ a+iy a−iy e zt z1/2 dz. Here a and t are positive and ﬁnite. Show that lim y→∞ I(y) = 0. 7.1.27 Apply the techniques of Example 7.1.5 to the evaluation of the improper integral I = ∫ ∞ −∞ dx x2 − σ2 . (a) Let σ → σ + iγ. (b) Let σ → σ − iγ. (c) Take the Cauchy principal value. 7.1.28 The integral in Exercise 7.1.17 may be transformed into ∫ ∞ 0 e −y y2 1 + e−2y dy = π3 16 . Evaluate this integral by the Gauss-Laguerre quadrature and compare your result with π3/16. ANS. Integral = 1.93775 (10 points). 7.2.9 Show that δ(x) = 1 π2 ∫ ∞ −∞ dt t(t − x) is a valid representation of the delta function in the sense that ∫ ∞ −∞ f (x)δ(x)dx = f (0). Assume that f (x) satisﬁes the condition for the existence of a Hilbert transform.. Apply Eq. (7.84) twice. CHAPTER 5. UNUSED SIXTH EDITION EXERCISES 476 7.3.7 Assume H (1) ν (s) to have a negative power-series expansion of the form H (1) ν (s) = √ 2 πs e i(s−ν(π/2)−π/4) ∞∑ n=0 a−ns −n, with the coeﬃcient of the summation obtained by the method of steepest descent. Substitute into Bessel’s equation and show that you reproduce the asymptotic series for H (1) ν (s) given in Section 11.6. 8.1.3 Show that, as s − n → negative integer, (s − n)! (2s − 2n)! → (−1) n−s(2n − 2s)! (n − s)! . Here s and n are integers with s < n. This result can be used to avoid negative factorials, such as in the series representations of the spherical Neumann functions and the Legendre functions of the second kind. 8.1.12 (a) Develop recurrence relations for (2n)!! and for (2n + 1)!!. (b) Use these recurrence relations to calculate (or to deﬁne) 0!! and−1)!!. ANS. 0!! = 1, (−1)!! = 1. 8.1.13 For s a nonnegative integer, show that (−2s − 1)!! = (−1) s (2s − 1)!! = (−1)s2 ss! (2s)! . item[8.1.18] From one of the deﬁnitions of the factorial or gamma func- tion, show that |(ix)!|2 = πx sinh πx . 8.1.27 Write a function subprogram F ACT (N ) (ﬁxed-point independent vari- able) that will calculate N !. Include provision for rejection and appropri- ate error message if N is negative. Note. For small integer N, direct multiplication is simplest. For large N , Eq. (8.55), Stirling’s series would be appropriate. 8.1.28 (a) Write a function subprogram to calculate the double factorial ratioN − 1)!!/(2N )!!. Include provision for N = 0 and for rejection and an error message if N is negative. Calculate and tabulate this ratio for N = 1(1)100. (b) Check your function subprogram calculation of 199!!/200!! against the value obtained from Stirling’s series (Section 8.3). CHAPTER 5. UNUSED SIXTH EDITION EXERCISES 477 ANS. 199!! 200!! = 0.056348. 8.1.29 Using either the FORTRAN-supplied GAMMA or a library supplied sub- routine for x! or Γ(x), determine the value of x for which Γ(x) is a mini- mum (1 ≤ x ≤ 2) and this minimum value of Γ(x). Notice that although the minimum value of Γ(x) may be obtained to about six signiﬁcant ﬁg- ures (single precision), the corresponding value of x is much less accurate. Why this relatively low accuracy? 8.1.30 The factorial function expressed in integral form can be evaluated by the Gauss-Laguerre quadrature. For a 10-point formula the resultant x! is theoretically exact for x an integer, 0 up through 19. What happens if x is not an integer? Use the Gauss-Laguerre quadrature to evaluate x!, x = 0.0(0.1)2.0. Tabulate the absolute error as a function of x. Check value. x!exact − x!quadrature = 0.00034 for x = 1.3. 8.2.10 Derive the polygamma function recurrence relation ψ(m)(1 + z) = ψ(m)(z) + (−1) mm!/zm+1, m = 0, 1, 2, . . . . 8.2.21 Verify the contour integral representation of ζ(s), ζ(s) = − (−s)! 2πi ∫ C (−z)s−1 ez − 1 dz. The contour C is the same as that for Eq. (8.35). The points z = ±2nπi, n = 1, 2, 3, . . . , are all excluded. 8.2.23 Using the complex variable capability of FORTRAN calculate(1 + ib)!, ℑ(1 + ib)!, |(1 + ib)!| and phase (1 + ib)! for b = 0.0(0.1)1.0. Plot the phase of (1 + ib)! versus b. Hint. Exercise 8.2.3 oﬀers a convenient approach. You will need to calcu- late ζ(n). 8.3.3 By integrating Eq. (8.51) from z −1 to z and then letting z → ∞, evaluate the constant C1 in the asymptotic series for the digamma function ψ(z). 8.3.5 By direct expansion, verify the doubling formula for z = n + 1 2 ; n is an integer. 8.3.10 Calculate the binomial coeﬃcient ( 2n n ) to six signiﬁcant ﬁgures for n = 10, 20, and 30. Check your values by (a) a Stirling series approximation through terms in n−1, (b) a double precision calculation. ANS. ( 20 ) = 1.84756 × 10 5, ( 40 ) = 1.37846 × 10 11, ( 60 ) = 1.18264 × 1017. CHAPTER 5. UNUSED SIXTH EDITION EXERCISES 478 8.3.11 Write a program (or subprogram) that will calculate log10(x!) directly from Stirling’s series. Assume that x ≥ 10. (Smaller values could be calculated via the factorial recurrence relation.) Tabulate log10(x!) versus x for x = 10(10)300. Check your results against AMS-55 (see Additional Readings for this reference) or by direct multiplication (for n = 10, 20, and 30). Check value. log10(100!) = 157.97. 8.3.12 Using the complex arithmetic capability of FORTRAN, write a subroutine that will calculate ln(z!) for complex z based on Stirling’s series. Include a test and an appropriate error message if z is too close to a negative real integer. Check your subroutine against alternate calculations for z real, z pure imaginary, and z = 1 + ib (Exercise 8.2.23). Check values. |(i0.5)!| = 0.82618 phase (i0.5)! = −0.24406. 8.4.1 Derive the doubling formula for the factorial function by integrating (sin 2θ) 2n+1 = (2 sin θ cos θ)2n+1 (and using the beta function). 8.4.19 Tabulate the beta function B(p, q) for p and q = 1.0(0.1)2.0 independently. Check value. B(1.3, 1.7) = 0.40774. 8.4.20 (a) Write a subroutine that will calculate the incomplete beta functionx(p, q). For 0.5 < x ≤ 1 you will ﬁnd it convenient to use the relation Bx(p, q) = B(p, q) − B1−x(q, p). (b) Tabulate Bx( 3 2 , 3 2 ). Spot check your results by using the Gauss- Legendre quadrature. 8.5.13 (a) Write a subroutine that will calculate the incomplete gamma func-γ(n, x) and Γ(n, x) for n a positive integer. Spot check Γ(n, x) by Gauss-Laguerre quadratures. (b) Tabulate γ(n, x) and Γ(n, x) for x = 0.0(0.1)1.0 and n = 1, 2, 3. 8.5.14 Calculate the potential produced by a 1S hydrogen electron (Exercise 8.5.4) (Fig. 8.10). Tabulate V (r)/(q/4πε0a0) for x = 0.0(0.1)4.0. Check your calculations for r ≪ 1 and for r ≫ 1 by calculating the limiting forms given in Exercise 8.5.4. 8.5.15 Using Eqs. (5.182) and (8.75), calculate the exponential integral E1(x) for x = 0.2(0.2)1.0, (b) x = 6.0(2.0)10.0. Program your own calculation but check each value, using a library sub- routine if available. Also check your calculations at each point by a Gauss- Laguerre quadrature. CHAPTER 5. UNUSED SIXTH EDITION EXERCISES 479 You’ll ﬁnd that the power-series converges rapidly and yields high precision for small x. The asymptotic series, even for x = 10, yields relatively poor accuracy. Check values. E1(1.0) = 0.219384 E1(10.0) = 4.15697 × 10 −6. 8.5.16 The two expressions for E1(x), (1) Eq. (5.182), an asymptotic series and (2) Eq. (8.75), a convergent power series, provide a means of calculating the Euler-Mascheroni constant γ to high accuracy. Using double precision, calculate γ from Eq. (8.75), with E1(x) evaluated by Eq. (5.182). Hint. As a convenient choice take x in the range 10 to 20. (Your choice of x will set a limit on the accuracy of your result.) To minimize errors in the alternating series of Eq. (8.75), accumulate the positive and negative terms separately. ANS. For x = 10 and “double precision,” γ = 0.57721566. 9.2.16 Bernoulli’s equation, dy dx + f (x)y = g(x)yn, is nonlinear for n ̸= 0 or 1. Show that the substitution u = y1−n reduces Bernoulli’s equation to a linear equation. (See Section 18.4.) ANS. du dx + (1 − n)f (x)u = (1 − n)g(x). 9.2.17 Solve the linear, ﬁrst-order equation, Eq. (9.25), by assuming y(x) = u(x)v(x), where v(x) is a solution of the corresponding homogeneous equa- tion [q(x) = 0]. This is the method of variation of parameters due to Lagrange. We apply it to second-order equations in Exercise 9.6.25. 9.7.1 Verify Eq. (9.168), ∫ (vL2u − uL2v)dτ2 = ∫ p(v∇2u − u∇2v) · dσ2. 9.7.5 The homogeneous Helmholtz equation ∇2ϕ + λ2ϕ = 0 has eigenvalues λ2 and eigenfunctions ϕi. Show that the corresponding Green’s function that satisﬁes ∇2G(r1, r2) + λ2G(r1, r2) = −δ(r1 − r2) CHAPTER 5. UNUSED SIXTH EDITION EXERCISES 480 may be written as G(r1, r2) = ∞∑ i=1 ϕi(r1)ϕi(r2) λ2 − λ2 . An expansion of this form is called a bilinear expansion. If the Green’s function is available in closed form, this provides a means of generating functions. 9.7.8 A charged conducting ring of radius a (Example 12.3.3) may be described by ρ(r) = q 2πa2 δ(r − a)δ(cos θ). Using the known Green’s function for this system, Eq. (9.187), ﬁnd the electrostatic potential.. Exercise 12.6.3 will be helpful. 9.7.9 Changing a separation constant from k2 to −k2 and putting the disconti- nuity of the ﬁrst derivative into the z-dependence, show that 1 4π|r1 − r2| = 1 4π ∞∑ m=−∞ ∫ ∞ 0 e im(ϕ1−ϕ2)Jm(kρ1)Jm(kρ2)e −k|z1−z2|dk. Hint. The required δ(ρ1 − ρ2) may be obtained from Exercise 15.1.2. 9.7.10 Derive the expansion exp[ik|r1 − r2|] 4π|r1 − r2| = ik ∞∑ l=0  jl(kr1)h(1)(kr2), r1 < r2 jl(kr2)h(1)(kr1), r1 > r2  × l∑ m=−l Y m l (θ1, ϕ1)Y m∗ l (θ2, ϕ2). Hint. The left side is a known Green’s function. Assume a spherical harmonic expansion and work on the remaining radial dependence. The spherical harmonic closure relation, Exercise 12.6.6, covers the angular dependence. 9.7.11 Show that the modiﬁed Helmholtz operator Green’s function exp(−k|r1 − r2|) 4π|r1 − r2| has the spherical polar coordinate expansion exp(−k|r1 − r2|) 4π|r1 − r2| = k ∞∑ l=0 il(kr<)kl(kr>) l∑ m=−l Y m l (θ1, ϕ1)Y m∗ l (θ2, ϕ2). Note. The modiﬁed spherical Bessel functions il(kr) and kl(kr) are deﬁned in Exercise 11.7.15. CHAPTER 5. UNUSED SIXTH EDITION EXERCISES 481 9.7.12 From the spherical Green’s function of Exercise 9.7.10, derive the plane- wave expansion e ik·r = ∞∑ l=0 i l(2l + 1)jl(kr)Pl(cos γ), where γ is the angle included between k and r. This is the Rayleigh equation of Exercise 12.4.7.. Take r2 ≫ r1 so that |r1 − r2| → r2 − r20 · r1 = r2 − k · r1 k . Let r2 → ∞ and cancel a factor of e ikr2/r2. 9.7.13 From the results of Exercises 9.7.10 and 9.7.12, show that e ix = ∞∑ l=0 i l(2l + 1)jl(x). 9.7.14 (a) From the circular cylindrical coordinate expansion of the Laplace Green’s function (Eq. (9.197)), show that 1 (ρ2 + z2)1/2 = 2 π ∫ ∞ 0 K0(kρ) cos kzdk. This same result is obtained directly in Exercise 15.3.11. (b) As a special case of part (a) show that ∫ ∞ 0 K0(k)dk = π 2 . 9.7.15 Noting that ψk(r) = 1 (2π)3/2 e ik·r is an eigenfunction of (∇ 2 + k2)ψk(r) = 0 (Eq. (9.206)), show that the Green’s function of L = ∇ 2 may be expanded as 1 4π|r1 − r2| = 1 (2π)3 ∫ e ik·(r1−r2) d3k k2 . 9.7.16 Using Fourier transforms, show that the Green’s function satisfying the nonhomogeneous Helmholtz equation (∇ 2 + k2 0)G(r1, r2) = −δ(r1 − r2) is G(r1, r2) = 1 (2π)3 ∫ e ik·(r1−r2) k2 − k2 0 d3k, in agreement with Eq. (9.213). CHAPTER 5. UNUSED SIXTH EDITION EXERCISES 482 9.7.17 The basic equation of the scalar Kirchhoﬀ diﬀraction theory is ψ(r1) = 1 4π ∫ S2 [ e ikr r ∇ψ(r2) − ψ(r2)∇ ( e ikr r )] · dσ2, where ψ satisﬁes the homogeneous Helmholtz equation and r = |r1 − r2|. Derive this equation. Assume that r1 is interior to the closed surface S2. Hint. Use Green’s theorem. 9.7.18 The Born approximation for the scattered wave is given by Eq. (9.203b) (and Eq. (9.211)). From the asymptotic form, Eq. (9.199), fk(θ, ϕ) e ikr r = − 2m ℏ2 ∫ V (r2) e ik|r−r2| 4π|r − r2| e ik0·r2d3r2. For a scattering potential V (r2) that is independent of angles and for r ≫ r2, show that fk(θ, ϕ) = − 2m ℏ2 ∫ ∞ 0 r2V (r2) sin(|k0 − k|r2) |k0 − k| dr2. Here k0 is in the θ = 0 (original z-axis) direction, whereas k is in the (θ, ϕ) direction. The magnitudes are equal: |k0| = |k|; m is the reduced mass.. You have Exercise 9.7.12 to simplify the exponential and Exer- cise 15.3.20 to transform the three-dimensional Fourier exponential trans- form into a one-dimensional Fourier sine transform. 9.7.19 Calculate the scattering amplitude fk(θ, ϕ) for a mesonic potential V(r) = V0(e −αr/αr). Hint. This particular potential permits the Born integral, Exercise 9.7.18, to be evaluated as a Laplace transform. ANS. fk(θ, ϕ) = − 2mV0 ℏ2α 1 α2 + (k0 − k)2 . 9.7.20 The mesonic potential V (r) = V0(e −αr/αr) may be used to describe the Coulomb scattering of two charges q1 and q2. We let α → 0 and V0 → 0 but take the ratio V0/α to be q1q2/4πε0. (For Gaussian units omit the 4πε0.) Show that the diﬀerential scattering cross section dσ/dΩ = |fk(θ, ϕ)|2 is given by dσ dΩ = ( q1q2 4πε0 )2 1 16E2 sin 4(θ/2) , E = p2 2m = ℏ2k2 2m . It happens (coincidentally) that this Born approximation is in exact agree- ment with both the exact quantum mechanical calculations and the clas- sical Rutherford calculation. CHAPTER 5. UNUSED SIXTH EDITION EXERCISES 483 10.1.5 Un(x), the Chebyshev polynomial (type II) satisﬁes the ODE, Eq. (13.1), (1 − x 2)U ′′ n (x) − 3xU ′ n(x) + n(n + 2)Un(x) = 0. (a) Locate the singular points that appear in the ﬁnite plane, and show whether they are regular or irregular. (b) Put this equation in self-adjoint form. (c) Identify the complete eigenvalue. (d) Identify the weighting function. 10.1.6 For the very special case λ = 0 and q(x) = 0 the self-adjoint eigenvalue equation becomes d dx [p(x) du(x) dx ] = 0, satisﬁed by du dx = 1 p(x) . Use this to obtain a “second” solution of the following: (a) Legendre’s equation, (b) Laguerre’s equation, (c) Hermite’s equation. ANS (a) u2(x) = 1 2 ln 1 + x 1 − x , (b) u2(x) − u2(x0) = ∫ x x0 e t dt t , (c) u2(x) = ∫ x 0 e t 2dt. These second solutions illustrate the divergent behavior usually found in a second solution.. In all three cases u1(x) = 1. 10.1.7 Given that Lu = 0 and gLu is self-adjoint, show that for the adjoint operator ¯L, ¯L(gu) = 0. 10.1.8 For a second-order diﬀerential operator L that is self-adjoint show that ∫ b a [y2Ly1 − y1Ly2]dx = p(y′ 1y2 − y1y′ 2) |b . 10.1.9 Show that if a function ψ is required to satisfy Laplace’s equation in a ﬁnite region of space and to satisfy Dirichlet boundary conditions over the entire closed bounding surface, then ψ is unique. Hint. One of the forms of Green’s theorem, Section 1.11, will be helpful. CHAPTER 5. UNUSED SIXTH EDITION EXERCISES 484 10.1.11 Within the framework of quantum mechanics (Eqs. (10.26) and following), show that the following are Hermitian operators: (a) momentum p = −iℏ∇ ≡ −i h 2π ∇ (b) angular momentum L = −iℏr × ∇ ≡ −i h 2π r × ∇. Hint. In Cartesian form L is a linear combination of noncommuting Her- mitian operators. 10.1.17 A quantum mechanical expectation value is deﬁned by ⟨A⟩ = ∫ ψ∗(x)Aψ(x)dx, where A is a linear operator. Show that demanding that ⟨A⟩ be real means that A must be Hermitian - with respect to ψ(x). 10.1.18 From the deﬁnition of adjoint, Eq. (10.27), show that A†† = A in the sense that ∫ ψ∗ 1A††ψ2dτ = ∫ ψ∗ 1Aψ2dτ . The adjoint of the adjoint is the original operator.. The functions ψ1 and ψ2 of Eq. (10.27) represent a class of func- tions. The subscripts 1 and 2 may be interchanged or replaced by other 10.1.19 The Schr¨odinger wave equation for the deuteron (with a Woods-Saxon potential) is − ℏ2 2M ∇ 2ψ + V0 1 + exp[(r − r0)/a] ψ = Eψ. Here E = −2.224 MeV, a is a “thickness parameter,” 0.4 × 10−13 cm. Expressing lengths in fermis (10 −13 cm) and energies in million electron volts (MeV), we may rewrite the wave equation as d2 dr2 (rψ) + 1 41.47 [E − V0 1 + exp((r − r0)/a) ] (rψ) = 0. E is assumed known from experiment. The goal is to ﬁnd V0 for a speciﬁed value of r0 (say, r0 = 2.1). If we let y(r) = rψ(r), then y(0) = 0 and we take y′(0) = 1. Find V0 such that y(20.0) = 0. (This should be y(∞), but r = 20 is far enough beyond the range of nuclear forces to approximate inﬁnity.) ANS. For a = 0.4 and r0 = 2.1 fm, V0 = −34.159 MeV. 10.1.20 Determine the nuclear potential well parameter V0 of Exercise 10.1.19 as a function of r0 for r = 2.00(0.05)2.25 fermis. Express your results as a power law |V0|rν 0 = k. CHAPTER 5. UNUSED SIXTH EDITION EXERCISES 485 Determine the exponent ν and the constant k. This power-law formulation is useful for accurate interpolation. 10.1.21 In Exercise 10.1.19 it was assumed that 20 fermis was a good approxi- mation to inﬁnity. Check on this by calculating V0 for rψ(r) = 0 at (a) r = 15, (b) r = 20, (c) r = 25, and (d) r = 30. Sketch your results. Take r0 = 2.10 and a = 0.4 (fermis). 10.1.22 For a quantum particle moving in a potential well, V (x) = 1 2 mω2x 2, the Schr¨odinger wave equation is − ℏ2 2m d2ψ(x) dx2 + 1 2 mω2x 2ψ(x) = Eψ(x), or d2ψ(z) dz2 − z2ψ(z) = − 2E ℏω ψ(z), where z = (mω/ℏ)1/2x. Since this operator is even, we expect solutions of deﬁnite parity. For the initial conditions that follow, integrate out from the origin and determine the minimum constant 2E/ℏω that will lead to ψ(∞) = 0 in each case. (You may take z = 6 as an approximation of inﬁnity.) (a) For an even eigenfunction, ψ(0) = 1, ψ′(0) = 0. (b) For an odd eigenfunction, ψ(0) = 0, ψ′(0) = 1. Note. Analytical solutions appear in Section 13.1. 10.2.2 (a) The vectors en are orthogonal to each other: en · em = 0 for n ̸= m. Show that they are linearly independent. (b) The functions ψn(x) are orthogonal to each other over the interval [a, b] and with respect to the weighting function w(x). Show that the ψn(x) are linearly independent. 10.2.5 (a) Show that the ﬁrst derivatives of the Legendre polynomials satisfy a self-adjoint diﬀerential equation with eigenvalue λ = n(n + 1) − 2. (b) Show that these Legendre polynomial derivatives satisfy an orthogo- nality relation ∫ 1 −1 P ′ m(x)P ′ n(x)(1 − x 2)dx = 0, m ̸= n. Note. In Section 12.5, (1 − x 2) 1/2P ′ n(x) will be labeled an associated Legendre polynomial, P 1 n(x). CHAPTER 5. UNUSED SIXTH EDITION EXERCISES 486 10.2.8 (a) Show that the Liouville substitution u(x) = v(ξ)[p(x)w(x)] −1/4, ξ = ∫ x a [ w(t) p(t) ] 1/2dt transforms d dx [ p(x) d dx u] + [λw(x) − q(x)]u(x) = 0 into d2v dξ2 + [λ − Q(ξ)]v(ξ) = 0, where Q(ξ) = q(x(ξ)) w(x(ξ)) + [p(x(ξ))w(x(ξ))]−1/4 d2 dξ2 (pw) 1/4. (b) If v1(ξ) and v2(ξ) are obtained from u1(x) and u2(x), respectively, by a Liouville substitution, show that ∫ b a w(x)u1u2dx is transformed into ∫ c 0 v1(ξ)v2(ξ)dξ with c = ∫ b a [ w p ] 1/2dx. 10.2.10 With L not self-adjoint, Lui + λiwui = 0 and ¯Lvj + λjwvj = 0. (a) Show that ∫ b a vjLuidx = ∫ b a ui ¯Lvjdx, provided uip0v′ j ∣ b = vjp0u′ ∣ b and ui(p1 − p′ )vj ∣ b = 0. (b) Show that the orthogonality integral for the eigenfunctions ui and vj becomes ∫ b a uivjw dx = 0 (λi ̸= λj). 10.2.11 In Exercise 9.5.8 the series solution of the Chebyshev equation is found to be convergent for all eigenvalues n. Therefore n is not quantized by the argument used for Legendre’s (Exercise 9.5.5). Calculate the sum of the indicial equation k = 0 Chebyshev series for n = v = 0.8, 0.9, and 1.0 and for x = 0.0(0.1)0.9. Note. The Chebyshev series recurrence relation is given in Exercise 5.2.16. CHAPTER 5. UNUSED SIXTH EDITION EXERCISES 487 10.2.12 (a) Evaluate the n = ν = 0.9, indicial equation k = 0 Chebyshev series for x = 0.98, 0.99, and 1.00. The series converges very slowly at x = 1.00. You may wish to use double precision. Upper bounds to the error in your calculation can be set by comparison with the= 1.0 case, which corresponds to (1 − x 2) 1/2. (b) These series solutions for eigenvalue ν = 0.9 and for ν = 1.0 are obvi- ously not orthogonal, despite the fact that they satisfy a self-adjoint eigenvalue equation with diﬀerent eigenvalues. From the behavior of the solutions in the vicinity of x = 1.00 try to formulate a hypothesis as to why the proof of orthogonality does not apply. 10.2.13 The Fourier expansion of the (asymmetric) square wave is given by Eq. (10.38).h = 2, evaluate this series for x = 0(π/18)π/2, using the ﬁrst (a) 10 terms, (b) 100 terms of the series.. For 10 terms and x = π/18, or 10◦, your Fourier representation has a sharp hump. This is the Gibbs phenomenon of Section 14.5. For 100 terms this hump has been shifted over to about 1 ◦. 10.2.14 The symmetric square wave f (x) =  1, |x| < π 2 −1, π 2 < |x| < π has a Fourier expansion f (x) = 4 π ∞∑ n=0(−1) n cos(2n + 1)x 2n + 1 . Evaluate this series for x = 0(π/18)π/2 using the ﬁrst (a) 10 terms, (b) 100 terms of the series.. As in Exercise 10.2.13, the Gibbs phenomenon appears at the dis- continuity. This means that a Fourier series is not suitable for precise numerical work in the vicinity of a discontinuity. 10.3.1 Rework Example 10.3.1 by replacing ϕn(x) by the conventional Legendre polynomial, Pn(x). ∫ 1 −1[Pn(x)] 2dx = 2 2n + 1 . Using Eqs. (10.47a), and (10.49a), construct P0, P1(x), and P2(x). ANS. P0 = 1, P1 = x, P2 = 3 2 x 2 − 1 2 . 10.3.9 Form an orthogonal set over the interval 0 ≤ x < ∞, using un(x) = e −nx, n = 1, 2, 3, . . . . Take the weighting factor, w(x), to be unity. These functions are solutions of u′′ −n2un = 0, which is clearly already in Sturm- Liouville (self–adjoint) form. Why doesn’t the Sturm-Liouville theory guarantee the orthogonality of these functions? CHAPTER 5. UNUSED SIXTH EDITION EXERCISES 488 10.4.6 Diﬀerentiate Eq. (10.79), ⟨ψ|ψ⟩ = ⟨f |f ⟩ + λ⟨f |g⟩ + λ∗⟨g|f ⟩ + λλ∗⟨g|g⟩, with respect to λ∗ and show that you get the Schwarz inequality, Eq. (10.78). 10.4.8 If the functions f (x) and g(x) of the Schwarz inequality, Eq. (10.78), may be expanded in a series of eigenfunctions ϕi(x), show that Eq. (10.78) reduces to Eq. (10.76) (with n possibly inﬁnite). Note the description of f (x) as a vector in a function space in which ϕi(x) corresponds to the unit vector e1. 10.4.10 A normalized wave function ψ(x) = ∑∞=0 anϕn(x). The expansion coef- ﬁcients an are known as probability amplitudes. We may deﬁne a density matrix ρ with elements ρij = aia∗. Show that (ρ2)ij = ρij, or ρ2 = ρ. This result, by deﬁnition, makes ρ a projection operator. Hint: Use ∫ ψ∗ψdx = 1. 10.4.11 Show that (a) the operator |ϕi(x)⟩⟨ϕi(t)| operating on f (t) = ∑ j cj|ϕj(t)⟩ yields ci|ϕi(x)⟩. (b) ∑ i |ϕi(x)⟩⟨ϕi(x)| = 1. This operator is a projection operator projecting f (x) onto the ith coordinate, selectively picking out the ith component ci|ϕi(x)⟩ of f (x). Hint. The operator operates via the well-deﬁned inner product. 10.5.3 Find the Green’s function for the operators (a) Ly(x) = d dx ( x dy(x) dx ) . ANS. (a) G(x, t) = { − ln t, 0 ≤ x < t, − ln x, t < x ≤ 1. CHAPTER 5. UNUSED SIXTH EDITION EXERCISES 489 (b) Ly(x) = d dx ( x dy(x) dx ) − n 2 x y(x), with y(0) ﬁnite and y(1) = 0. ANS. (b) G(x, t) =  1 2n [( x t )n − (xt) n] , 0 ≤ x < t, 1 2n [( t x )n − (xt) n] , t < x ≤ 1. The combination of operator and interval speciﬁed in Exercise 10.5.3(a) is pathological, in that one of the endpoints of the interval (zero) is a singular point of the operator. As a consequence, the integrated part (the surface integral of Green’s theorem) does not vanish. The next four exercises explore this situation. 10.5.4 (a) Show that the particular solution of d dx [x d dx y(x) ] = −1 is yP (x) = −x. (b) Show that yP (x) = −x ̸= ∫ 1 0 G(x, t)(−1)dt, where G(x, t) is the Green’s function of Exercise 10.5.3(a). 10.5.5 Show that Green’s theorem, Eq. (1.104) in one dimension with a Sturm- Liouville type operator (d/dt)p(t)(d/dt) replacing ∇·∇, may be rewritten as ∫ b a [u(t) d dt ( p(t) dv(t) dt ) − v(t) d dt ( p(t) du(t) dt )] dt = [u(t)p(t) dv(t) dt − v(t)p(t) du(t) dt ] ∣ b . 10.5.6 Using the one-dimensional form of Green’s theorem of Exercise 10.5.5, let v(t) = y(t) and d dt ( p(t) dy(t) dt ) = −f (t) u(t) = G(x, t) and d dt ( p(t) ∂G(x, t) ∂t ) = −δ(x − t). Show that Green’s theorem yields y(x) = ∫ b a G(x, t)f (t)dt +[G(x, t)p(t) dy(t) dt − y(t)p(t) ∂ ∂t G(x, t)] ∣ t=b t=a. CHAPTER 5. UNUSED SIXTH EDITION EXERCISES 490 10.5.7 For p(t) = t, y(t) = −t, G(x, t) = { − ln t, 0 ≤ x < t − ln x, t < x ≤ 1, verify that the integrated part does not vanish. 10.5.13 In the Fredholm equation, f (x) = λ2 ∫ b a G(x, t)ϕ(t)dt, G(x, t) is a Green’s function given by G(x, t) = ∞∑ n=1 ϕn(x)ϕn(t) λ2 − λ2 . Show that the solution is ϕ(x) = ∞∑ n=1 λ2 − λ2 λ2 ϕn(x) ∫ b a f (t)ϕn(t)dt. 10.5.14 Show that the Green’s function integral transform operator ∫ b a G(x, t)[ ]dt is equal to −L −1, in the sense that (a) Lx ∫ b a G(x, t)y(t)dt = −y(x), (b) ∫ b a G(x, t)Lty(t)dt = −y(x). Note. Take Ly(x) + f (x) = 0, Eq. (10.92). 10.5.15 Substitute Eq. (10.87), the eigenfunction expansion of Green’s function, into Eq. (10.88) and then show that Eq. (10.88) is indeed a solution of the inhomogenous Helmholtz equation (10.82). 10.5.16 (a) Starting with a one-dimensional inhomogeneous diﬀerential equation, (Eq. (10.89)), assume that ψ(x) and ρ(x) may be represented by eigenfunction expansions. Without any use of the Dirac delta func- tion or its representations, show that ψ(x) = ∞∑ n=0 ∫ b a ρ(t)ϕn(t)dt λn − λ ϕn(x). Note that (1) if ρ = 0, no solution exists unless λ = λn and (2) if λ = λn, no solution exists unless ρ is orthogonal to ϕn. This same behavior will reappear with integral equations in Section 16.4. CHAPTER 5. UNUSED SIXTH EDITION EXERCISES 491 (b) Interchanging summation and integration, show that you have con- structed the Green’s function corresponding to Eq. (10.90). 10.5.17 The eigenfunctions of the Schr¨odinger equation are often complex. In this case the orthogonality integral, Eq. (10.40), is replaced by ∫ b a ϕ ∗(x)ϕj(x)w(x)dx = δij. Instead of Eq. (1.189), we have δ(r1 − r2) = ∞∑ n=0 ϕn(r1)ϕ ∗ (r2). Show that the Green’s function, Eq. (10.87), becomes G(r1, r2) = ∞∑ n=0 ϕn(r1)ϕ∗ (r2) k2 n − k2 = G∗(r2, r1). 11.1.9 Show that J0(x) = 2 π ∫ 1 0 cos xt √1 − t2 dt. This integral is a Fourier cosine transform (compare Section 15.3). The corresponding Fourier sine transform, J0(x) = 2 π ∫ ∞ 1 sin xt √t2 − 1 dt, is established in Section 11.4 (Exercise 11.4.6), using a Hankel function integral representation. 11.1.15 A particle (mass m) is contained in a right circular cylinder (pillbox) of radius R and height H. The particle is described by a wave function satisfying the Schr¨odinger wave equation − ℏ2 2m ∇2ψ(ρ, ϕ, z) = Eψ(ρ, ϕ, z) and the condition that the wave function go to zero over the surface of the pillbox. Find the lowest (zero point) permitted energy. ANS. E = ℏ2 2m [( zpq R )2 + ( nπ H )2] , Emin = ℏ2 2m [( 2.405 R )2 + ( π H )2] , CHAPTER 5. UNUSED SIXTH EDITION EXERCISES 492 where zpq is the qth zero of Jp and the index p is ﬁxed by the azimuthal dependence. 11.1.22 Using trigonometric forms, verify that J0(br) = 1 2π ∫ 2π 0 e ibr sin θdθ. 11.1.28 A thin conducting disk of radius a carries a charge q. Show that the potential is described by ϕ(r, z) = q 4πε0a ∫ ∞ 0 e −k|z|J0(kr) sin ka k dk, where J0 is the usual Bessel function and r and z are the familiar cylin- drical coordinates.. This is a diﬃcult problem. One approach is through Fourier trans- forms such as Exercise 15.3.11. For a discussion of the physical problem see Jackson (Classical Electrodynamics in Additional Readings). 11.1.31 The circular aperature diﬀraction amplitude Φ of Eq. (11.34) is propor- tional to f (z) = J1(z)/z. The corresponding single slit diﬀraction ampli- tude is proportional to g(z) = sin z/z. (a) Calculate and plot f (z) and g(z) for z = 0.0(0.2)12.0. (b) Locate the two lowest values of z(z > 0) for which f (z) takes on an extreme value. Calculate the corresponding values of f (z). (c) Locate the two lowest values of z(z > 0) for which g(z) takes on an extreme value. Calculate the corresponding values of g(z). 11.1.32 Calculate the electrostatic potential of a charged disk ϕ(r, z) from the inte- gral form of Exercise 11.1.28. Calculate the potential for r/a = 0.0(0.5)2.0 and z/a = 0.25(0.25)1.25. Why is z/a = 0 omitted? Exercise 12.3.17 is a spherical harmonic version of this same problem. 11.2.2 Show that ∫ a 0 [ Jν (ανm ρ a )]2 ρ dρ = a2 2 [Jν+1(ανm)] 2, ν > −1. Here ανm is the mth zero of Jν. Hint. With ανn = ανm + ε, expand Jν[(ανm + ε)ρ/a] about ανmρ/a by a Taylor expansion. 11.2.8 For the continuum case, show that Eqs. (11.51) and (11.52) are replaced by f (ρ) = ∫ ∞ 0 a(α)Jν(αρ) dα, a(α) = α ∫ ∞ 0 f (ρ)Jν(αρ)ρ dρ. CHAPTER 5. UNUSED SIXTH EDITION EXERCISES 493 Hint. The corresponding case for sines and cosines is worked out in Sec- tion 15.2. These are Hankel transforms. A derivation for the special case= 0 is the topic of Exercise 15.1.1. 11.3.8 A cylindrical wave guide has radius r0. Find the nonvanishing components of the electric and magnetic ﬁelds for (a) TM01, transverse magnetic wave (Hz = Hρ = Eϕ = 0) , (b) TE01, transverse electric wave (Ez = Eρ = Hϕ = 0). The subscripts 01 indicate that the longitudinal component (Ez or Hz) involves J0 and the boundary condition is satisﬁed by the ﬁrst zero of J0 or J ′ 0. Hint. All components of the wave have the same factor: exp i(kz − ωt). 11.3.9 For a given mode of oscillation the minimum frequency that will be passed by a circular cylindrical wave guide (radius r0) is νmin = c λc , in which λc is ﬁxed by the boundary condition Jn ( 2πr0 λc ) = 0 for TMnm mode, J ′ n ( 2πr0 λc ) = 0 for TEnm mode. The subscript n denotes the order of the Bessel function and m indicates the zero used. Find this cutoﬀ wavelength λc for the three TM and three TE modes with the longest cutoﬀ wavelengths. Explain your results in terms of the graph of J0, J1, and J2 (Fig. 11.1). 11.3.10 Write a program that will compute successive roots of the Neumann func-Nn(x), that is αns, where Nn(αns) = 0. Tabulate the ﬁrst ﬁve roots of N0, N1, and N2. Check your values for the roots against those listed in AMS-55 (see Additional Readings of Chapter 8 for the full ref.). Check value. α12 = 5.42968. 11.5.12 (a) Verify that I0(x) = 1 π ∫ π 0 cosh(x cos θ)dθ satisﬁes the modiﬁed Bessel equation, ν = 0. (b) Show that this integral contains no admixture of K0(x), the irregular second solution. (c) Verify the normalization factor 1/π. CHAPTER 5. UNUSED SIXTH EDITION EXERCISES 494 11.5.16 Show that e ax = I0(a)T0(x) + 2 ∞∑ n=1 In(a)Tn(x), −1 ≤ x ≤ 1. Tn(x) is the nth-order Chebyshev polynomial, Section 13.3. Hint. Assume a Chebyshev series expansion. Using the orthogonality and normalization of the Tn(x), solve for the coeﬃcients of the Chebyshev series. 11.5.17 (a) Write a double precision subroutine to calculate In(x) to 12-decimal- place accuracy for n = 0, 1, 2, 3, . . . and 0 ≤ x ≤ 1. Check your results against the 10-place values given in AMS-55, Table 9.11, see Additional Readings of Chapter 8 for the reference. (b) Referring to Exercise 11.5.16, calculate the coeﬃcients in the Cheby- shev expansions of cosh x and of sinh x. 11.6.1 In checking the normalization of the integral representation of Kν(z) (Eq. (11.122)), we assumed that Iν(z) was not present. How do we know that the integral representation (Eq. (11.122)) does not yield Kν(z) + εIν(z) with ε ̸= 0? 11.6.7 (a) Using the asymptotic series (partial sums) P0(x) and Q0(x) deter- mined in Exercise 11.6.6, write a function subprogram FCT(X) that will calculate J0(x), x real, for x ≥ xmin. (b) Test your function by comparing it with the J0(x) (tables or computer library subroutine) for x = xmin(10)xmin + 10. Note. A more accurate and perhaps simpler asymptotic form for J0(x) is given in AMS-55, Eq. (9.4.3), see Additional Readings of Chapter 8 for the reference. 11.7.12 Set up the orthogonality integral for jL(kr) in a sphere of radius R with the boundary condition jL(kR) = 0. The result is used in classifying electromagnetic radiation according to its angular momentum. 11.7.15 Deﬁning the spherical modiﬁed Bessel functions (Fig. 11.16) by in(x) = √ π 2x In+1/2(x), kn(x) = √ 2 πx Kn+1/2(x), show that i0(x) = sinh x x , k0(x) = e −x x . Note that the numerical factors in the deﬁnitions of in and kn are not identical. CHAPTER 5. UNUSED SIXTH EDITION EXERCISES 495 11.7.17 Show that the spherical modiﬁed Bessel functions satisfy the following (a) in(x) = i−njn(ix), kn(x) = −i nh(1)(ix), (b) in+1(x) = x n d dx (x −nin), kn+1(x) = −xn d dx (x −nkn), (c) in(x) = x n ( 1 x d dx )n sinh x x , kn(x) = (−1)nx n ( 1 x d dx )n e −x x . 11.7.18 Show that the recurrence relations for in(x) and kn(x) are (a) in−1(x) − in+1(x) = 2n + 1 x in(x), nin−1(x) + (n + 1)in+1(x) = (2n + 1)i ′ (x), (b) kn−1(x) − kn+1(x) = − 2n + 1 x kn(x), nkn−1(x) + (n + 1)kn+1(x) = −(2n + 1)k′ n(x). 11.7.19 Derive the limiting values for the spherical modiﬁed Bessel functions (a) in(x) ≈ x n (2n + 1)!! , kn(x) ≈ (2n − 1)!! xn+1 , x ≪ 1. (b) in(x) ∼ e x 2x , kn(x) ∼ e −x x , x ≫ 1 2 n(n + 1). 11.7.21 A quantum particle of mass M is trapped in a “square” well of radius a. The Schr¨odinger equation potential is V (r) = { −V0, 0 ≤ r < a 0, r > a. The particle’s energy E is negative (an eigenvalue). (a) Show that the radial part of the wave function is given by jl(k1r) for 0 ≤ r < a and kl(k2r) for r > a. (We require that ψ(0) be ﬁnite and ψ(∞) → 0.) Here k2 1 = 2M (E + V0)/ℏ2, k2 2 = −2M E/ℏ2, and l is the angular momentum (n in Eq. (11.139)). (b) The boundary condition at r = a is that the wave function ψ(r) and its ﬁrst derivative be continuous. Show that this means (d/dr)jl(k1r) jl(k1r) ∣r=a = (d/dr)kl(k2r) kl(k2r) ∣r=a. This equation determines the energy eigenvalues. CHAPTER 5. UNUSED SIXTH EDITION EXERCISES 496 Note. This is a generalization of Example 10.1.2. 11.7.22 The quantum mechanical radial wave function for a scattered wave is given by ψk = sin(kr + δ0) kr , where k is the wave number, k = √ 2mE/ℏ, and δ0 is the scattering phase shift. Show that the normalization integral is ∫ ∞ 0 ψk(r)ψk′(r)r2 dr = π 2k δ(k − k′). Hint. You can use a sine representation of the Dirac delta function. See Exercise 15.3.8. 11.7.23 Derive the spherical Bessel function closure relation 2a2 π ∫ ∞ 0 jn(ar)jn(br)r2 dr = δ(a − b). Note. An interesting derivation involving Fourier transforms, the Rayleigh plane-wave expansion, and spherical harmonics has been given by P. Ug-Am. J. Phys. 40: 1690 (1972). 11.7.24 (a) Write a subroutine that will generate the spherical Bessel functions,n(x), that is, will generate the numerical value of jn(x) given x and n. Note. One possibility is to use the explicit known forms of j0 and j1 and to develop the higher index jn, by repeated application of the recurrence relation. (b) Check your subroutine by an independent calculation, such as Eq. (11.154). If possible, compare the machine time needed for this check with the time required for your subroutine. 11.7.25 The wave function of a particle in a sphere (Example 11.7.1) with angular momentum l is ψ(r, θ, ϕ) = Ajl(( √2M E)r/ℏ)Y m l (θ, ϕ). The Y m l (θ, ϕ) is a spherical harmonic, described in Section 12.6. From the boundaryψ(a, θ, ϕ) = 0 or jl((√ 2M E)a/ℏ) = 0 calculate the 10 lowest- energy states. Disregard the m degeneracy (2l + 1 values of m for each choice of l). Check your results against AMS-55, Table 10.6, see Additional Readings of Chapter 8 for the reference.. You can use your spherical Bessel subroutine and a root-ﬁnding subroutine. Check values. jl(αls) = 0, α01 = 3.1416 α11 = 4.4934 α21 = 5.7635 α02 = 6.2832. CHAPTER 5. UNUSED SIXTH EDITION EXERCISES 497 11.7.26 Let Example 11.7.1 be modiﬁed so that the potential is a ﬁnite V0 outside (r > a). (a) For E < V0 show that ψout(r, θ, ϕ) ∼ kl ( r ℏ √2M (V0 − E) ) . (b) The new boundary conditions to be satisﬁed at r = a are ψin(a, θ, ϕ) = ψout(a, θ, ϕ), ∂ ∂r ψin(a, θ, ϕ) = ∂ ∂r ψout(a, θ, ϕ) or 1 ψin ∂ψin ∂r ∣r=a = 1 ψout ∂ψout ∂r ∣r=a. For l = 0 show that the boundary condition at r = a leads to f (E) = k { cot ka − 1 ka } + k′ {1 + 1 k′a } = 0, where k = √2M E/ℏ and k′ = √2M (V0 − E)/ℏ. (c) With a = 4πǫ0ℏ2/M e2 (Bohr radius) and V0 = 4M e4/2ℏ2, compute the possible bound states (0 < E < V0). Hint. Call a root-ﬁnding subroutine after you know the approximate location of the roots of f (E) = 0, (0 ≤ E ≤ V0). (d) Show that when a = 4πǫ0ℏ2/M e 2 the minimum value of V0 for which a bound state exists is V0 = 2.4674M e4/2ℏ2. 11.7.27 In some nuclear stripping reactions the diﬀerential cross section is propor- tional to jl(x)2, where l is the angular momentum. The location of the maximum on the curve of experimental data permits a determination of, if the location of the (ﬁrst) maximum of jl(x) is known. Compute the location of the ﬁrst maximum of j1(x), j2(x), and j3(x). Note. For better accuracy look for the ﬁrst zero of j′ l(x). Why is this more accurate than direct location of the maximum? 12.1.7 Prove that Pn(cos θ) = (−1)n rn+1 n! ∂n ∂zn ( 1 r ) . Hint. Compare the Legendre polynomial expansion of the generating func- tion (a → ∆z, Fig. 12.1) with a Taylor series expansion of 1/r, where z dependence of r changes from z to z − ∆z (Fig. 12.7). CHAPTER 5. UNUSED SIXTH EDITION EXERCISES 498 12.1.9 The Chebyshev polynomials (type II) are generated by (Eq. (13.93), Sec- tion 13.3) 1 1 − 2xt + t2 = ∞∑ n=0 Un(x)t n. Using the techniques of Section 5.4 for transforming series, develop a series representation of Un(x). ANS. Un(x) = [n/2]∑ k=0 (−1) k (n − k)! k!(n − 2k)! (2x) n−2k. 12.2.6 From PL(cos θ) = 1 L! ∂L ∂tL (1 − 2t cos θ + t 2) −1/2 |t=0 show that PL(1) = 1, PL(−1) = (−1) L. 12.2.10 Write a program that will generate the coeﬃcients as in the polynomial form of the Legendre polynomial Pn(x) = n∑ s=0 asx s. 12.2.11 (a) Calculate P10(x) over the range [0, 1] and plot your results. (b) Calculate precise (at least to ﬁve decimal places) values of the ﬁve positive roots of P10(x). Compare your values with the values listed in AMS-55, Table 25.4. (For the complete reference see Additional Readings of Chapter 8.) 12.2.12 (a) Calculate the largest root of Pn(x) for n = 2(1)50. (b) Develop an approximation for the largest root from the hypergeomet- ric representation of Pn(x) (Section 13.4) and compare your values from part (a) with your hypergeometric approximation. Compare also with the values listed in AMS-55, Table 25.4. (For the complete reference see Additional Readings of Chapter 8.) References). 12.2.13 (a) From Exercise 12.2.1 and AMS-55, Table 22.9 develop the 6×6 matrix B that will transform a series of even order Legendre polynomials through P10(x) into a power series ∑5 =0 α2nx 2n. (b) Calculate A as B −1. Check the elements of A against the values listed in AMS-55, Table 22.9. (For the complete reference see additional Readings of Chapter 8.) (c) By using matrix multiplication, transform some even power-series5 =0 α2nx2n into a Legendre series. CHAPTER 5. UNUSED SIXTH EDITION EXERCISES 499 12.2.14 Write a subroutine that will transform a ﬁnite power series ∑N=0 anxn into a Legendre series ∑N=0 bnPn(x). Use the recurrence relation, Eq. (12.17), and follow the technique outlined in Section 13.3 for a Chebyshev 12.3.11 The amplitude of a scattered wave is given by f (θ) = 1 k ∞∑ l=0(2l + 1) exp[iδl] sin δlPl(cos θ). Here θ is the angle of scattering, l is the angular momentum eigenvalue, ℏk is the incident momentum, and δl is the phase shift produced by the central potential that is doing the scattering. The total cross section istot = ∫ |f (θ)| 2dΩ. Show that σtot = 4π k2 ∞∑ l=0(2l + 1) sin2 δl. 12.3.14 A charge q is displaced a distance a along the z-axis from the center of a spherical cavity of radius R. (a) Show that the electric ﬁeld averaged over the volume a ≤ r ≤ R is zero. (b) Show that the electric ﬁeld averaged over the volume 0 ≤ r ≤ a is E = ˆzEz = −ˆz q 4πε0a2 (SI units) = −ˆz nqa 3ε0 , where n is the number of such displaced charges per unit volume. This is a basic calculation in the polarization of a dielectric.. E = −∇ϕ. 12.3.18 From the result of Exercise 12.3.17 calculate the potential of the disk. Since you are violating the condition r > a, justify your calculation. Hint. You may run into the series given in Exercise 5.2.9. 12.4.11 By direct evaluation of the Schlaeﬂi integral show that Pn(1) = 1. 12.4.12 Explain why the contour of the Schlaeﬂi integral, Eq. (12.69), is chosen to enclose the points t = z and t = 1 when n → ν, not an integer. 12.5.17 A nuclear particle is in a spherical square well potential V (r, θ, ϕ) = 0 for 0 ≤ r < a and ∞ for r > a. The particle is described by a wave function ψ(r, θ, ϕ) which satisﬁes the wave equation − ℏ2 2M ∇ 2ψ + V0ψ = Eψ, r < a, CHAPTER 5. UNUSED SIXTH EDITION EXERCISES 500 and the boundary condition ψ(r = a) = 0. Show that for the energy E to be a minimum there must be no angular dependence in the wave function; that is, ψ = ψ(r). Hint. The problem centers on the boundary condition on the radial func- tion. 12.5.18 (a) Write a subroutine to calculate the numerical value of the associated Legendre function P 1 N (x) for given values of N and x. Hint. With the known forms of P 1 1 and P 1 2 you can use the recurrence relation Eq. (12.92) to generate P 1 N , N > 2. (b) Check your subroutine by having it calculate P 1 N (x) for x = 0.0(0.5) 1.0 and N = 1(1)10. Check these numerical values against the known values of P 1 N (0) and P 1 N (1) and against the tabulated values of P 1 N (0.5). 12.5.19 Calculate the magnetic vector potential of a current loop, Example 12.5.1. Tabulate your results for r/a = 1.5(0.5)5.0 and θ = 0◦(15 ◦)90 ◦. Include terms in the series expansion, Eq. (12.137), until the absolute values of the terms drop below the leading term by a factor of 10 5 or more. Note. This associated Legendre expansion can be checked by comparison with the elliptic integral solution, Exercise 5.8.4. Check value. For r/a = 4.0 and θ = 20◦, Aϕ/µ0I = 4.9398 × 10−3. 12.6.4 (a) Express the elements of the quadrupole moment tensor xixj as a linear combination of the spherical harmonics Y m 2 (and Y 0 0 ). Note. The tensor xixj is reducible. The Y 0 0 indicates the presence of a scalar component. (b) The quadrupole moment tensor is usually deﬁned as Qij = ∫ (3xixj − r2δij)ρ(r)dτ, with ρ(r) the charge density. Express the components of (3xixj − r2δij) in terms of r2Y M 2 . (c) What is the signiﬁcance of the −r2δij term? Hint. Compare Sections 2.9 and 4.4. 12.8.8 The electric current density produced by a 2P electron in a hydrogen atom is J = ˆϕ qℏ 32ma5 e −r/a0 r sin θ. Using A(r1) = µ0 4π ∫ J(r2) |r1 − r2| d3r2, CHAPTER 5. UNUSED SIXTH EDITION EXERCISES 501 ﬁnd the magnetic vector potential produced by this hydrogen electron.. Resolve into Cartesian components. Use the addition theorem to eliminate γ, the angle included between r1 and r2. 12.9.4 Show that Eq. (12.199) is a special case of Eq. (12.190) and derive the reduced matrix element ⟨YL1∥Y1∥YL⟩. ANS. ⟨YL1 ∥Y1∥YL⟩ = (−1) L1+1−LC(1LL1|000) √3(2L + 1) 4π . 12.10.2 From Eqs. (12.212) and (12.213) show that (a) P2n(x) = (−1)n 22n−1 n∑ s=0(−1) s (2n + 2s − 1)! (2s)!(n + s − 1)!(n − s)! x 2s. (b) P2n+1(x) = (−1) n 22n n∑ s=0(−1)s (2n + 2s + 1)! (2s + 1)!(n + s)!(n − s)! x 2s+1. Check the normalization by showing that one term of each series agrees with the corresponding term of Eq. (12.8). 12.10.5 Verify that the Legendre functions of the second kind, Qn(x), satisfy the same recurrence relations as Pn(x), both for |x| < 1 and for |x| > 1: (2n + 1)xQn(x) = (n + 1)Qn+1(x) + nQn−1(x), (2n + 1)Qn(x) = Q′ +1(x) − Q′ −1(x). item[12.10.7] (a) Write a subroutine that will generate Qn(x) and Q0 through Qn−1 based on the recurrence relation for these Legendre functions of the second kind. Take x to be within (−1, 1) - excluding the endpoints. Hint. Take Q0(x) and Q1(x) to be known. b) Test your subroutine for accuracy by computing Q10(x) and compar- ing with the values tabulated in AMS-55 (for a complete reference, see Additional Readings of Chapter 8). 13.1.16 (a) Show that the simple oscillator Hamiltonian (from Eq. (13.38)) may be written as H = − 1 2 d2 dx2 + 1 2 x 2 = 1 2 (ˆaˆa † + ˆa†ˆa). Hint. Express E in units of ℏω. (b) Using the creation-annihilation operator formulation of part (a), show Hψ(x) = (n + 1 2 )ψ(x). This means the energy eigenvalues are E = (n+ 1 2 )(ℏω), in agreement with Eq. (13.40). CHAPTER 5. UNUSED SIXTH EDITION EXERCISES 502 13.1.17 Write a program that will generate the coeﬃcients as, in the polynomial form of the Hermite polynomial Hn(x) = ∑n=0 asx s. 13.1.18 A function f (x) is expanded in a Hermite series: f (x) = ∞∑ n=0 anHn(x). From the orthogonality and normalization of the Hermite polynomials the coeﬃcient an is given by an = 1 2nπ1/2n! ∫ ∞ −∞ f (x)Hn(x)e −x 2 dx. For f (x) = x 8 determine the Hermite coeﬃcients an by the Gauss-Hermite quadrature. Check your coeﬃcients against AMS-55, Table 22.12 (for the reference, see footnote 4 in Chapter 5 or the General References at book’s 13.1.19 (a) In analogy with Exercise 12.2.13, set up the matrix of even Hermite polynomial coeﬃcients that will transform an even Hermite series into an even power series: B =  1 −2 12 · · · 0 4 −48 · · · 0 0 16 · · · . . . . ..  . Extend B to handle an even polynomial series through H8(x). (b) Invert your matrix to obtain matrix A, which will transform an even power series (through x 8) into a series of even Hermite polynomials. Check the elements of A against those listed in AMS-55 (Table 22.12, in General References at book’s end). (c) Finally, using matrix multiplication, determine the Hermite series equivalent to f (x) = x 8. 13.1.20 Write a subroutine that will transform a ﬁnite power series, ∑N=0 anx n, into a Hermite series, ∑N=0 bnHn(x). Use the recurrence relation, Eq. (13.2).. Both Exercises 13.1.19 and 13.1.20 are faster and more accurate than the Gaussian quadrature, Exercise 13.1.18, if f (x) is available as a power series. 13.1.21 Write a subroutine for evaluating Hermite polynomial matrix elements of the form Mpqr = ∫ ∞ −∞ Hp(x)Hq(x)x re −x 2 dx, CHAPTER 5. UNUSED SIXTH EDITION EXERCISES 503 using the 10-point Gauss-Hermite quadrature (for p+q+r ≤ 19). Include a parity check and set equal to zero the integrals with odd-parity integrand. Also, check to see if r is in the range |p − q| ≤ r. Otherwise Mpqr = 0. Check your results against the speciﬁc cases listed in Exercises 13.1.9, 13.1.10, 13.1.11, and 13.1.12. 13.1.22 Calculate and tabulate the normalized linear oscillator wave functions ψn(x) = 2 −n/2π−1/4(n!) −1/2Hn(x) exp ( − x 2 2 ) for x = 0.0(0.1)5.0 and n = 0(1)5. If a plotting routine is available, plot your results. 13.1.23 Evaluate ∫ ∞ −∞ e −2x2HN1 (x) · · · HN4 (x)dx in closed form. Hint. ∫ ∞ −∞ e −2x 2 HN1(x)HN2(x)HN3 (x)dx = 1 π 2 (N1+N2+N3−1)/2 · Γ(s − N1)Γ(s − N2)Γ(s − N3), s = (N1 + N2 + N3 + 1)/2 or ∫ ∞ −∞ e −2x2HN1(x)HN2 (x)dx = (−1) (N1+N2−1)/22 (N1+N2−1)/2 ·Γ((N1 +N2 +1)/2) may be helpful. Prove these formulas (see Gradshteyn and Ryshik, no. 7.375 on p. 844, in the Additional Readings). 13.2.3 From the generating function derive the Rodrigues representation L k (x) = e xx −k n! dn dxn (e −xx n+k). 13.2.11 The hydrogen wave functions, Eq. (13.91), are mutually orthogonal as they should be, since they are eigenfunctions of the self-adjoint Schr¨odinger ∫ ψ∗ n1L1M1 ψn2L2M2 r2drdΩ = δn1n2δL1L2δM1M2. Yet the radial integral has the (misleading) form ∫ ∞ 0 e −αr/2(αr)LL 2L+1 n1−L−1(αr)e −αr/2(αr) LL 2L+1 n2−L−1(αr)r2dr, which appears to match Eq. (13.83) and not the associated Laguerre orthogonality relation, Eq. (13.79). How do you resolve this paradox? ANS. The parameter α is dependent on n. The ﬁrst three α, previously shown, are 2Z/n1a0. The last three are 2Z/n2a0. For n1 = n2 Eq. (13.83) applies. For n1 ̸= n2 neither Eq. (13.79) nor Eq. (13.83) is applicable. 13.2.12 A quantum mechanical analysis of the Stark eﬀect (parabolic coordinate) leads to the ODE d dξ ( ξ du dξ ) + ( 1 2 Eξ + L − m 2 4ξ − 1 4 F ξ2) u = 0. CHAPTER 5. UNUSED SIXTH EDITION EXERCISES 504 Here F is a measure of the perturbation energy introduced by an external electric ﬁeld. Find the unperturbed wave functions (F = 0) in terms of associated Laguerre polynomials. ANS. u(ξ) = e −εξ/2ξm/2L m(εξ), with ε = √−2E > 0, p = L/ε − (m + 1)/2, a nonnegative integer. 13.2.13 The wave equation for the three-dimensional harmonic oscillator is − ℏ2 2M ∇ 2ψ + 1 2 M ω2r2ψ = Eψ. Here ω is the angular frequency of the corresponding classical oscillator. Show that the radial part of ψ (in spherical polar coordinates ) may be written in terms of associated Laguerre functions of argument (βr2), where β = M ω/ℏ. Hint. As in Exercise 13.2.8, split oﬀ radial factors of rl and e −βr2/2. The associated Laguerre function will have the form L l+1/2 1/2(n−l−1)(βr2). 13.2.14 Write a computer program that will generate the coeﬃcients as in the polynomial form of the Laguerre polynomial Ln(x) = ∑n=0 asx s. 13.2.15 Write a computer program that will transform a ﬁnite power series ∑N=0 anx n into a Laguerre series ∑N=0 bnLn(x). Use the recurrence relation, Eq. (13.62). 13.2.16 Tabulate L10(x) for x = 0.0(0.1)30.0. This will include the 10 roots of L10. Beyond x = 30.0, L10(x) is monotonic increasing. If graphic software is available, plot your results. Check value. Eighth root = 16.279. 13.2.17 Determine the 10 roots of L10(x) using root-ﬁnding software. You may use your knowledge of the approximate location of the roots or develop a search routine to look for the roots. The 10 roots of L10(x) are the evaluation points for the 10-point Gauss-Laguerre quadrature. Check your values by comparing with AMS-55, Table 25.9. (For the reference, see footnote 4 in Chapter 5 or the General References at book’s end.) 13.2.18 Calculate the coeﬃcients of a Laguerre series expansion (Ln(x), k = 0) of the exponential e −x. Evaluate the coeﬃcients by the Gauss-Laguerre quadrature (compare Eq. (10.64)). Check your results against the values given in Exercise 13.2.6.. Direct application of the Gauss-Laguerre quadrature with f (x)Ln(x)e −x gives poor accuracy because of the extra e −x. Try a change of variable, y = 2x, so that the function appearing in the integrand will be simply Ln(y/2). CHAPTER 5. UNUSED SIXTH EDITION EXERCISES 505 13.2.19 (a) Write a subroutine to calculate the Laguerre matrix elements Mmnp = ∫ ∞ 0 Lm(x)Ln(x)x pe −x dx. Include a check of the condition |m − n| ≤ p ≤ m + n. (If p is outside this range, Mmnp = 0. Why?) Note. A 10-point Gauss-Laguerre quadrature will give accurate re- sults for m + n + p ≤ 19. (b) Call your subroutine to calculate a variety of Laguerre matrix ele- ments. Check Mmn1 against Exercise 13.2.7. 13.2.20 Write a subroutine to calculate the numerical value of L k (x) for speciﬁed values of n, k, and x. Require that n and k be nonnegative integers and x ≥ 0. Hint. Starting with known values of L k and L k(x), we may use the recur- rence relation, Eq. (13.75), to generate L k (x), n = 2, 3, 4, . . . . 13.2.22 Write a program to calculate the normalized hydrogen radial wave functionnL(r). This is ψnLM of Eq. (13.91), omitting the spherical harmonic Y M L (θ, ϕ). Take Z = 1 and a0 = 1 (which means that r is being expressed in units of Bohr radii). Accept n and L as input data. Tabulate ψnL(r) for r = 0.0(0.2)R with R taken large enough to exhibit the signiﬁcant features of ψ. This means roughly R = 5 for n = 1, R = 10 for n = 2, and R = 30 for n = 3. 13.3.23 (a) Calculate and tabulate the Chebyshev functions V1(x), V2(x), and V3(x) for x = −1.0(0.1)1.0. (b) A second solution of the Chebyshev diﬀerential equation, Eq. (13.100),n = 0 is y(x) = sin −1 x. Tabulate and plot this function over the same range: −1.0(0.1)1.0. 13.3.24 Write a computer program that will generate the coeﬃcients as in the polynomial form of the Chebyshev polynomial Tn(x) = ∑n=0 asx s. 13.3.25 Tabulate T10(x) for 0.00(0.01)1.00. This will include the ﬁve positive roots of T10. If graphics software is available, plot your results. 13.3.26 Determine the ﬁve positive roots of T10(x) by calling a root–ﬁnding sub- routine. Use your knowledge of the approximate location of these roots from Exercise 13.3.25 or write a search routine to look for the roots. These ﬁve positive roots (and their negatives) are the evaluation points of the 10-point Gauss-Chebyshev quadrature method. Check values xk = cos[(2k − 1)π/20], k = 1, 2, 3, 4, 5. 13.6.1 For the simple pendulum ODE of Section 5.8, apply Floquet’s method and derive the properties of its solutions similar to those marked by bullets before Eq. (13.186). CHAPTER 5. UNUSED SIXTH EDITION EXERCISES 506 13.6.2 Derive a Mathieu-function analog for the Rayleigh expansion of a plane wave for cos(k cos η cos θ) and sin(k cos η cos θ). 14.1.8 Calculate the sum of the ﬁnite Fourier sine series for the sawtooth wave,(x) = x, (−π, π), Eq. (14.21). Use 4-, 6-, 8-, and 10-term series and x/π = 0.00(0.02)1.00. If a plotting routine is available, plot your results and compare with Fig. (14.1). 14.2.1 The boundary conditions (such as ψ(0) = ψ(l) = 0) may suggest solutions of the form sin(nπx/l) and eliminate the corresponding cosines. (a) Verify that the boundary conditions used in the Sturm-Liouville the- ory are satisﬁed for the interval (0, l). Note that this is only half the usual Fourier interval. (b) Show that the set of functions ϕn(x) = sin(nπx/l), n = 1, 2, 3, . . ., satisﬁes an orthogonality relation ∫ l 0 ϕm(x)ϕn(x)dx = l 2 δmn, n > 0. 14.3.9 (a) Show that the Fourier expansion of cos ax is cos ax = 2a sin aπ π { 1 2a2 − cos x a2 − 12 + cos 2x a2 − 22 − · · · } , an = (−1)n 2a sin aπ π(a2 − n2) . (b) From the preceding result show that aπ cot aπ = 1 − 2 ∞∑ p=1 ζ(2p)a 2p. This provides an alternate derivation of the relation between the Riemann zeta function and the Bernoulli numbers, Eq. (5.151). 14.3.13 (a) Using f (x) = x 2, −π < x < π, show that ∞∑ n=1 (−1)n+1 n2 = π2 12 = η(2). (b) Using the Fourier series for a triangular wave developed in Exer- cise 14.3.4, show that ∞∑ n=1 1 (2n − 1)2 = π2 8 = λ(2). CHAPTER 5. UNUSED SIXTH EDITION EXERCISES 507 (c) Using f (x) = x 4, −π < x < π, show that ∞∑ n=1 1 n4 = π4 90 = ζ(4), ∞∑ n=1 (−1) n+1 n4 = 7π4 720 = η(4). (d) Using f (x) = { x(π − x), 0 < x < π, x(π + x), π < x < 0, derive f (x) = 8 π ∞∑ n=1,3,5,... sin nx n3 and show that ∞∑ n=1,3,5,...(−1) (n−1)/2 1 n3 = 1 − 1 33 + 1 53 − 1 73 + · · · = π3 32 = β(3). (e) Using the Fourier series for a square wave, show that ∞∑ n=1,3,5,...(−1) (n−1)/2 1 n = 1 − 1 3 + 1 5 − 1 7 + · · · = π 4 = β(1). This is Leibniz’ formula for π, obtained by a diﬀerent technique in Exercise 5.7.6.. The η(2), η(4), λ2), β(1), and β(3) functions are deﬁned by the indicated series. General deﬁnitions appear in Section 5.9. 14.3.15 A symmetric triangular pulse of adjustable height and width is described by f (x) = { a(1 − x/b), 0 ≤ |x| ≤ b 0, b ≤ |x| ≤ π. (a) Show that the Fourier coeﬃcients are a0 = ab π , an = 2ab π(nb)2 (1 − cos nb). Sum the ﬁnite Fourier series through n = 10 and through n = 100 for x/π = 0(1/9)1. Take a = 1 and b = π/2. (b) Call a Fourier analysis subroutine (if available) to calculate the Fourier coeﬃcients of f (x), a0 through a10. 14.3.16 (a) Using a Fourier analysis subroutine, calculate the Fourier cosine co- eﬃcients a0 through a10 of f (x) = [1 − ( x π )2]1/2, x ∈ [−π, π]. CHAPTER 5. UNUSED SIXTH EDITION EXERCISES 508 (b) Spot-check by calculating some of the preceding coeﬃcients by direct numerical quadrature. Check values. a0 = 0.785, a2 = 0.284. 14.3.17 Using a Fourier analysis subroutine, calculate the Fourier coeﬃcients through10 and b10 for (a) a full-wave rectiﬁer, Example 14.3.2, (b) a half-wave rectiﬁer, Exercise 14.3.1. Check your results against the analytic forms given (Eq. (14.41) and Exercise 14.3.1). 14.4.12 Find the charge distribution over the interior surfaces of the semicircles of Exercise 14.3.6.. You obtain a divergent series and this Fourier approach fails. Using conformal mapping techniques, we may show the charge density to be proportional to csc θ. Does csc θ have a Fourier expansion? 14.5.3 Evaluate the ﬁnite step function series, Eq. (14.73), h = 2, using 100, 200, 300, 400, and 500 terms for x = 0.0000(0.0005)0.0200. Sketch your results (ﬁve curves) or, if a plotting routine is available, plot your results. 14.6.2 Equation (14.84) exhibits orthogonality summing over time points. Show that we have the same orthogonality summing over frequency points 1 2N 2N −1∑ p=0 (e iωptm) ∗e iωptk = δmk. 14.6.5 Given N = 2, T = 2π, and f (tk) = sin tk, (a) ﬁnd F (ωp), p = 0, 1, 2, 3, and (b) reconstruct f (tk) from F (ωp) and exhibit the aliasing of ω1 = 1 and ω3 = 3. ANS. (a) F (ωp) = (0, i/2, 0, −i/2) (b) f (tk) = 1 2 sin tk − 1 2 sin 3tk. 14.6.6 Show that the Chebyshev polynomials Tm(x) satisfy a discrete orthogo- nality relation 1 2 Tm(−1)Tn(−1) + N −1∑ s=1 Tm(xs)Tn(xs) + 1 2 Tm(1)Tn(1) =  0, m ̸= n N/2, m = n ̸= 0 N, m = n = 0. Here, xs = cos θs, where the (N + 1)θs are equally spaced along the θ-axis: θs = sπ N , s = 0, 1, 2, . . . , N. CHAPTER 5. UNUSED SIXTH EDITION EXERCISES 509 14.7.1 Determine the nonleading coeﬃcients β(n) n+2 for se1. Derive a suitable re- cursion relation. 14.7.2 Determine the nonleading coeﬃcients β(n) n+4 for ce0. Derive the correspond- ing recursion relation. 14.7.3 Derive the formula for ce1, Eq. (14.155), and its eigenvalue, Eq.(14.156). 15.1.2 Assuming the validity of the Hankel transform-inverse transform pair of g(α) = ∫ ∞ 0 f (t)Jn(αt)t dt, f (t) = ∫ ∞ 0 g(α)Jn(αt)α dα, show that the Dirac delta function has a Bessel integral representation δ(t − t ′) = t ∫ ∞ 0 Jn(αt)Jn(αt′)α dα. This expression is useful in developing Green’s functions in cylindrical coordinates, where the eigenfunctions are Bessel functions. 15.1.3 From the Fourier transforms, Eqs. (15.22) and 15.23), show that the trans- t → ln x iω → α − γ leads to G(α) = ∫ ∞ 0 F (x)xα−1 dx and F (x) = 1 2πi ∫ γ+i∞ γ−i∞ G(α)x −α dα. These are the Mellin transforms. A similar change of variables is employed in Section 15.12 to derive the inverse Laplace transform. 15.1.4 Verify the following Mellin transforms: (a) ∫ ∞ 0 x α−1 sin(kx) dx = k−α(α − 1)! sin πα 2 , −1 < α < 1. (b) ∫ ∞ 0 x α−1 cos(kx) dx = k−α(α − 1)! cos πα 2 , 0 < α < 1. Hint. You can force the integrals into a tractable form by inserting a convergence factor e −bx and (after integrating) letting b → 0. Also, cos kx + i sin kx = exp ikx. CHAPTER 5. UNUSED SIXTH EDITION EXERCISES 510 15.3.2 Let F (ω) be the Fourier (exponential) transform of f (x) and G(ω) be the Fourier transform of g(x) = f (x + a). Show that G(ω) = e −iaωF (ω). 15.3.12 A calculation of the magnetic ﬁeld of a circular current loop in circular cylindrical coordinates leads to the integral ∫ ∞ 0 cos kz k K1(ka)dk. Show that this integral is equal to πa 2(z2 + a2)3/2 . Hint. Try diﬀerentiating Exercise 15.3.11(c). 15.3.13 As an extension of Exercise 15.3.11, show that ∫ ∞ 0 J0(y)dy = 1, (b) ∫ ∞ 0 N0(y)dy = 0, (c) ∫ ∞ 0 K0(y)dy = π 2 . 15.3.14 The Fourier integral, Eq. (15.18), has been held meaningless for f (t) = cos αt. Show that the Fourier integral can be extended to cover f (t) = cos αt by use of the Dirac delta function. 15.3.15 Show that ∫ ∞ 0 sin ka J0(kρ)dk = { (a 2 − ρ2) −1/2, ρ < a, 0, ρ > a. Here a and ρ are positive. The equation comes from the determination of the distribution of charge on an isolated conducting disk, radius a. Note that the function on the right has an inﬁnite discontinuity at ρ = a. Note. A Laplace transform approach appears in Exercise 15.10.8. 15.3.16 The function f (r) has a Fourier exponential transform g(k) = 1 (2π)3/2 ∫ f (r)e ik·r d3r = 1 (2π)3/2k2 . Determine f (r). Hint. Use spherical polar coordinates in k-space. ANS. f (r) = 1 4πr . 15.3.17 (a) Calculate the Fourier exponential transform of f (x) = e −a|x|. (b) Calculate the inverse transform by employing the calculus of residues (Section 7.1). CHAPTER 5. UNUSED SIXTH EDITION EXERCISES 511 15.4.1 The one-dimensional Fermi age equation for the diﬀusion of neutrons slow- ing down in some medium (such as graphite) is ∂2q(x, τ ) ∂x2 = ∂q(x, τ ) ∂τ . Here q is the number of neutrons that slow down, falling below some given energy per second per unit volume. The Fermi age, τ , is a measure of the energy loss.q(x, 0) = Sδ(x), corresponding to a plane source of neutrons at x = 0, emitting S neutrons per unit area per second, derive the solution q = S e −x2/4τ √4πτ . Hint. Replace q(x, τ ) with p(k, τ ) = 1 √2π ∫ ∞ −∞ q(x, τ )e ikx dx. This is analogous to the diﬀusion of heat in an inﬁnite medium. 15.4.2 Equation (15.41) yields g2(ω) = −ω2g(ω) for the Fourier transform of the second derivative of f (x). The condition f (x) → 0 for x → ±∞ may be relaxed slightly. Find the least restrictive condition for the preceding equation for g2(ω) to hold. ANS. [ df (x) dx − iωf (x) ] e iωx∣ ∞ = 0. 15.4.4 For a point source at the origin the three-dimensional neutron diﬀusion equation becomes −D ∇ 2ϕ(r) + K 2Dϕ(r) = Qδ(r). Apply a three-dimensional Fourier transform. Solve the transformed equa- tion. Transform the solution back into r-space. 15.4.5 (a) Given that F (k) is the three-dimensional Fourier transform of f (r) and F1(k) is the three-dimensional Fourier transform of ∇f (r), show that F1(k) = (−ik)F (k). This is a three-dimensional generalization of Eq. (15.40). CHAPTER 5. UNUSED SIXTH EDITION EXERCISES 512 (b) Show that the three-dimensional Fourier transform of ∇ · ∇f (r ¯ ) is F2(k) = (−ik) 2F (k). Note. Vector k is a vector in the transform space. In Section 15.6 we shall have ℏk = p, linear momentum. item[15.5.2] F (ρ) and G(ρ) are the Hankel transforms of f (r) and g(r), respectively (Exercise 15.1.1). Derive the Hankel transform Parseval rela-∫ ∞ 0 F ∗(ρ)G(ρ)ρ dρ = ∫ ∞ 0 f ∗(r)g(r)rdr. 15.5.4 Starting from Parseval’s relation (Eq. (15.54)), let g(y) = 1, 0 ≤ y ≤ α, and zero elsewhere. From this derive the Fourier inverse transform (Eq. (15.23)).. Diﬀerentiate with respect to α. 15.6.1 The function e ik·r describes a plane wave of momentum p = ℏk normalized to unit density. (Time dependence of e −iωt is assumed.) Show that these plane-wave functions satisfy an orthogonality relation ∫ (e ik·r)∗e ik ′·rdx dy dz = (2π) 3δ(k − k′). 15.6.2 An inﬁnite plane wave in quantum mechanics may be represented by the ψ(x) = e ip′x/ℏ. Find the corresponding momentum distribution function. Note that it has an inﬁnity and that ψ(x) is not normalized. 15.6.3 A linear quantum oscillator in its ground state has a wave function ψ(x) = a−1/2π−1/4e −x2/2a 2. Show that the corresponding momentum function is g(p) = a 1/2π−1/4ℏ−1/2e −a 2p 2/2ℏ 2 . 15.6.4 The nth excited state of the linear quantum oscillator is described by ψn(x) = a −1/22 −n/2π−1/4(n!) −1/2e −x2/2a 2 Hn(x/a), where Hn(x/a) is the nth Hermite polynomial, Section 13.1. As an ex- tension of Exercise 15.6.3, ﬁnd the momentum function corresponding ton(x). Hint. ψn(x) may be represented by (ˆa†) nψ0(x), where ˆa† is the raising operator, Exercise 13.1.14 to 13.1.16. CHAPTER 5. UNUSED SIXTH EDITION EXERCISES 513 15.6.5 A free particle in quantum mechanics is described by a plane wave ψk(x, t) = e i[kx−(ℏk2/2m)t]. Combining waves of adjacent momentum with an amplitude weightingϕ(k), we form a wave packet Ψ(x, t) = ∫ ∞ −∞ ϕ(k)e i[kx−(ℏk2/2m)t] dk. (a) Solve for ϕ(k) given that Ψ(x, 0) = e −x2/2a 2 . (b) Using the known value of ϕ(k), integrate to get the explicit form of Ψ(x, t). Note that this wave packet diﬀuses, or spreads out, with time. ANS. Ψ(x, t) = e −{x2/2[a 2+(iℏ/m)t]} [1 + (iℏt/ma2)]1/2 . Note. An interesting discussion of this problem from the evolution op- erator point of view is given by S. M. Blinder, Evolution of a Gaussian wavepacket, Am. J. Phys. 36: 525 (1968). 15.6.6 Find the time-dependent momentum wave function g(k, t) correspond- ing to Ψ(x, t) of Exercise 15.6.5. Show that the momentum wave packet g∗(k, t)g(k, t) is independent of time. 15.6.7 The deuteron, Example 10.1.2, may be described reasonably well with a Hulth´en wave function ψ(r) = A r [e −αr − e −βr], with A, α, and β constants. Find g(p), the corresponding momentum function.. The Fourier transform may be rewritten as Fourier sine and cosine transforms or as a Laplace transform, Section 15.8. 15.6.9 Check the normalization of the hydrogen momentum wave function g(p) = 23/2 π a3/2 0 ℏ5/2 (a2p2 + ℏ2)2 by direct evaluation of the integral ∫ g∗(p)g(p)d3p. CHAPTER 5. UNUSED SIXTH EDITION EXERCISES 514 15.6.12 The one-dimensional time-independent Schr¨odinger wave equation is − ℏ2 2m d2ψ(x) dx2 + V (x)ψ(x) = Eψ(x). For the special case of V (x) an analytic function of x, show that the corresponding momentum wave equation is V ( iℏ d dp ) g(p) + p2 2m g(p) = Eg(p). Derive this momentum wave equation from the Fourier transform, Eq. (15.62), and its inverse. Do not use the substitution x → iℏ(d/dp) directly. 15.7.1 Derive the convolution g(t) = ∫ ∞ −∞ f (τ )Φ(t − τ )dτ. 15.8.6 The electrostatic potential of a charged conducting disk is known to have the general form (circular cylindrical coordinates) Φ(ρ, z) = ∫ ∞ 0 e −k|z|J0(kρ)f (k)dk, with f (k) unknown. At large distances (z → ∞) the potential must approach the Coulomb potential Q/4πε0z. Show that lim k→0 f (k) = q 4πε0 . Hint. You may set ρ = 0 and assume a Maclaurin expansion of f (k) or, using e −kz, construct a delta sequence. 15.10.8 The electrostatic potential of a point charge q at the origin in circular cylindrical coordinates is q 4πε0 ∫ ∞ 0 e −kzJ0(kρ)dk = q 4πε0 · 1 (ρ2 + z2)1/2 , ℜ(z) ≥ 0. From this relation show that the Fourier cosine and sine transforms of0(kρ) are (a) √ π 2 Fc {J0(kρ)} = ∫ ∞ 0 J0(kρ) cos kζ dk = { (ρ2 − ζ 2) −1/2, ρ > ζ, 0, ρ < ζ. . (b) √ π 2 Fs {J0(kρ)} = ∫ ∞ 0 J0(kρ) sin kζ dk = { 0, ρ > ζ, (ρ2 − ζ 2) −1/2, ρ < ζ, . Hint. Replace z by z + iζ and take the limit as z → 0. CHAPTER 5. UNUSED SIXTH EDITION EXERCISES 515 15.10.21 The Laplace transform ∫ ∞ 0 e −xsxJ0(x)dx = s (s2 + 1)3/2 may be rewritten as 1 s2 ∫ ∞ 0 e −yyJ0( y s ) dy = s (s2 + 1)3/2 , which is in Gauss-Laguerre quadrature form. Evaluate this integral for s = 1.0, 0.9, 0.8, . . . , decreasing s in steps of 0.1 until the relative error rises to 10 percent. (The eﬀect of decreasing s is to make the integrand oscillate more rapidly per unit length of y, thus decreasing the accuracy of the numerical quadrature.) 15.10.22 (a) Evaluate ∫ ∞ 0 e −kzkJ1(ka)dk by the Gauss-Laguerre quadrature. Take a = 1 and z = 0.1(0.1)1.0. (b) From the analytic form, Exercise 15.10.7, calculate the absolute error and the relative error. 16.1.5 Verify that ∫ x a ∫ x a f (t)dt dx = ∫ x a (x − t)f (t)dt for all f (t) (for which the integrals exist). 16.3.2 Solve the equation ϕ(x) = x + 1 2 ∫ 1 −1(t + x)ϕ(t)dt by the separable kernel method. Compare with the Neumann method solution of Section 16.3. ANS. ϕ(x) = 1 2 (3x − 1). 16.3.6 If the separable kernel technique of this section is applied to a Fredholm equation of the ﬁrst kind (Eq. (16.1)), show that Eq. (16.76) is replaced by c = A −1b. In general the solution for the unknown ϕ(t) is not unique. 16.3.13 The integral equation ϕ(x) = λ ∫ 1 0 J0(αxt)ϕ(t)dt, J0(α) = 0, CHAPTER 5. UNUSED SIXTH EDITION EXERCISES 516 is approximated by ϕ(x) = λ ∫ 1 0 [1 − x 2t 2]ϕ(t)dt. Find the minimum eigenvalue λ and the corresponding eigenfunction ϕ(t) of the approximate equation. ANS. λmin = 1.112486, ϕ(x) = 1 − 0.303337x 2. 16.3.14 You are given the integral equation ϕ(x) = λ ∫ 1 0 sin πxtϕ(t)dt. Approximate the kernel by K(x, t) = 4xt(1 − xt) ≈ sin πxt. Find the positive eigenvalue and the corresponding eigenfunction for the approximate integral equation.For K(x, t) = sin πxt, λ = 1.6334. ANS. λ = 1.5678, ϕ(x) = x − 0.6955x 2 (λ+ = √ 31 − 4, λ− = − √31 − 4). 16.3.16 Using numerical quadrature, convert ϕ(x) = λ ∫ 1 0 J0(αxt)ϕ(t)dt, J0(α) = 0, to a set of simultaneous linear equations. (a) Find the minimum eigenvalue λ. (b) Determine ϕ(x) at discrete values of x and plot ϕ(x) versus x. Com- pare with the approximate eigenfunction of Exercise 16.3.13. ANS. (a) λmin = 1.14502. 16.3.17 Using numerical quadrature, convert ϕ(x) = λ ∫ 1 0 sin πxtϕ(t)dt to a set of simultaneous linear equations. (a) Find the minimum eigenvalue λ. (b) Determine ϕ(x) at discrete values of x and plot ϕ(x) versus x. Com- pare with the approximate eigenfunction of Exercise 16.3.14. CHAPTER 5. UNUSED SIXTH EDITION EXERCISES 517 ANS. (a) λmin = 1.6334. 16.3.18 Given a homogeneous Fredholm equation of the second kind λϕ(x) = ∫ 1 0 K(x, t)ϕ(t)dt. (a) Calculate the largest eigenvalue λ0. Use the 10-point Gauss-Legendre quadrature technique. For comparison the eigenvalues listed by Linz are given as λexact. (b) Tabulate ϕ(xk), where the xk are the 10 evaluation points in [0, 1]. (c) Tabulate the ratio 1 λ0ϕ(x) ∫ 1 0 K(x, t)ϕ(t)dt for x = xk. This is the test of whether or not you really have a solution. (a) K(x, t) = e xt. ANS. λexact = 1.35303. (b) K(x, t) = { 1 2 x(2 − t), x < t, 1 2 t(2 − x), x > t. ANS. λexact = 0.24296. (c) K(x, t) = |x − t|. ANS. λexact = 0.34741. (d) K(x, t) = { x, x < t, t, x > t. ANS. λexact = 0.40528. Note. (1) The evaluation points xi of Gauss-Legendre quadrature for [−1, 1] may be linearly transformed into [0, 1], xi[0, 1] = 1 2 (xi[−1, 1] + 1). Then the weighting factors Ai are reduced in proportion to the length of the interval: Ai[0, 1] = 1 2 Ai[−1, 1]. 16.3.19 Using the matrix variational technique of Exercise 17.8.7, reﬁne your cal- culation of the eigenvalue of Exercise 16.3.18(c) [K(x, t) = |x − t|]. Try a 40 × 40 matrix. Note. Your matrix should be symmetric so that the (unknown) eigenvec- tors will be orthogonal. CHAPTER 5. UNUSED SIXTH EDITION EXERCISES 518 ANS. (40-point Gauss-Legendre quadrature) 0.34727. 17.2.9 Find the root of px0 = coth px0 (Eq. (17.39)) and determine the corre- sponding values of p and x0 (Eqs. (17.41) and (17.42)). Calculate your values to ﬁve signiﬁcant ﬁgures. 17.2.10 For the two-ring soap ﬁlm problem of this section calculate and tabulate0, p, p−1, and A, the soap ﬁlm area for px0 = 0.00(0.02)1.30. 17.2.11 Find the value of x0 (to ﬁve signiﬁcant ﬁgures) that leads to a soap ﬁlm area, Eq. (17.43), equal to 2π, the Goldschmidt discontinuous solution. ANS. x0 = 0.52770. 17.6.2 Find the ratio of R (radius) to H(height) that will minimize the total surface area of a right-circular cylinder of ﬁxed volume. 17.6.8 A deformed sphere has a radius given by r = r0{α0 +α2P2(cos θ)}, where α0 ≈ 1 and |α2| ≪ |α0|. From Exercise 12.5.16 the area and volume are A = 4πr2 0α2 0 { 1 + 4 5 ( α2 α0 )2} , V = 4πr3 0 3 a 3 { 1 + 3 5 ( α2 α0 )2} . Terms of order α3 2 have been neglected. (a) With the constraint that the enclosed volume be held constant, thatV = 4πr3 0/3, show that the bounding surface of minimum area is a sphere (α0 = 1, α2 = 0). (b) With the constraint that the area of the bounding surface be held constant, that is, A = 4πr2 0, show that the enclosed volume is a maximum when the surface is a sphere. Note concerning the following exercises: In a quantum-mechanical system there are gi distinct quantum states between energies Ei and Ei + dEi. The problem is to describe how ni particles are distributed among these states subject to two constraints: (a) ﬁxed number of particles, ∑ i ni = n. (b) ﬁxed total energy, ∑ i niEi = E. CHAPTER 5. UNUSED SIXTH EDITION EXERCISES 519 17.6.10 For identical particles obeying the Pauli exclusion principle, the probabil- ity of a given arrangement is WF D = ∏ i gi! ni!(gi − ni)! . Show that maximizing WF D, subject to a ﬁxed number of particles and ﬁxed total energy, leads to ni = gi eλ1+λ2Ei + 1 . With λ1 = −E0/kT and λ2 = 1/kT , this yields Fermi-Dirac statistics. Hint. Try working with ln W and using Stirling’s formula, Section 8.3. The justiﬁcation for diﬀerentiation with respect to ni is that we are dealing here with a large number of particles, ∆ni/ni ≪ 1. 17.6.11 For identical particles but no restriction on the number in a given state, the probability of a given arrangement is WBE = ∏ i (ni + gi − 1)! ni!(gi − 1)! . Show that maximizing WBE, subject to a ﬁxed number of particles and ﬁxed total energy, leads to ni = gi eλ1+λ2Ei − 1 . With λ1 = −E0/kT and λ2 = 1/kT , this yields Bose–Einstein statistics. Note. Assume that gi ≫ 1. 17.6.12 Photons satisfy WBE and the constraint that total energy is constant. They clearly do not satisfy the ﬁxed-number constraint. Show that elim- inating the ﬁxed-number constraint leads to the foregoing result but with1 = 0. 17.7.6 Show that requiring J, given by J = ∫ b a [p(x)y2 x − q(x)y2] dx, to have a stationary value subject to the normalizing condition ∫ b a y2w(x) dx = 1 leads to the Sturm-Liouville equation of Chapter 10: d dx ( p dy dx ) + qy + λwy = 0. CHAPTER 5. UNUSED SIXTH EDITION EXERCISES 520 Note. The boundary condition pyxy | b = 0 is used in Section 10.1 in establishing the Hermitian property of the op- 17.8.1 From Eq. (17.128) develop in detail the argument when λ ≥ 0 or λ < 0. Explain the circumstances under which λ = 0, and illustrate with several examples. 17.8.7 In the matrix eigenvector, eigenvalue equation Ari = λiri, where λ is an n × n Hermitian matrix. For simplicity, assume that its n real eigenvalues (Section 3.5) are distinct, λ1 being the largest. If r is an approximation to r1, r = r1 + n∑ i=2 δi ri, show that r †Ar r†r ≤ λ1 and that the error in λ1 is of the order |δi|2. Take |δi| ≪ 1. Hint. The n ri form a complete orthogonal set spanning the n-dimensional (complex) space. 17.8.8 The variational solution of Example 17.8.1 may be reﬁned by taking y = x(1−x)+a2x2(1−x) 2. Using the numerical quadrature, calculate λapprox = F [y(x)], Eq. (17.128), for a ﬁxed value of a2. Vary a2 to minimize λ. Calculate the value of a2 that minimizes λ and calculate λ itself, both to ﬁve signiﬁcant ﬁgures. Compare your eigenvalue λ with π2. 18.2.8 Repeat Exercise 18.2.7 for Feigenbaum’s α instead of δ. 18.2.11 Repeat Exercise 18.2.9 for Feigenbaum’s α. 18.3.1 Use a programmable pocket calculator (or a personal computer with BA- SIC or FORTRAN or symbolic software such as Mathematica or Maple) to obtain the iterates xi of an initial 0 < x0 < 1 and f ′ µ(xi) for the logistic map. Then calculate the Lyapunov exponent for cycles of period 2, 3,... of the logistic map for 2 < µ < 3.7. Show that for µ < µ∞ the Lyapunov exponent λ is 0 at bifurcation points and negative elsewhere, while for µ > µ∞ it is positive except in periodic windows. Hint. See Fig. 9.3 of Hilborn (1994) in the Additional Readings. 18.4.4 Plot the intermittency region of the logistic map at µ = 3.8319. What is the period of the cycles? What happens at µ = 1 + 2√2? CHAPTER 5. UNUSED SIXTH EDITION EXERCISES 521 ANS. There is a tangent bifurcation to period 3 cycles. 19.4.7 A piece of uranium is known to contain the isotopes 235 92 U and 238 92 U as well as from 0.80 g of 206 82 Pb per gram of uranium. Estimate the age of the piece (and thus Earth) in years.Assume the lead comes only from the 238 92 U. Use the decay constant from Exercise 19.4.5. 19.6.4 If x1, x2, · · · , xn are a sample of measurements with mean value given by the arithmetic mean ¯x and the corresponding random variables Xj that take the values xj with the same probability are independent and have mean value µ and variance σ2, then show that ⟨¯x⟩ = µ and σ2(¯x) = σ2/n. If ¯σ2 = 1 n ∑ j(xj − ¯x) 2 is the sample variance, show that ⟨¯σ2⟩ = n−1 n σ2.","libVersion":"0.3.2","langs":""}