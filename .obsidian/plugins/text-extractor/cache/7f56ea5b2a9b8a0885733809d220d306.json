{"path":"Books and Papers/General Relativity/Maximally_Symmetric_Spaces.pdf","text":"Typeset in JHEP style Updated: 5/2018 Maximally Symmetric Spaces Douglas H. Laurence Department of Physical Sciences, Broward College, Davie, FL 33314 Abstract: These notes follow Weinberg’s derivation of the Riemann Curvature tensor for a maximally symmetric space presented in \"Gravitation and Cosmology,\" with some details ﬁlled in. Weinberg is particularly diﬃcult to read, so writing down these notes and ﬁlling in the gap really helped me understand his derivation, which is the most rigorous and thorough derivation in any of the popular general relativity or cosmology textbooks. These notes start by presenting Killing vectors from scratch, and then apply the most restrictions on can on the form of the Riemann curvature tensor for a maximally symmetric space. Speciﬁcally, the maximally symmetric space considered is a homogeneous and isotropic space, which is obviously important when studying cosmology. Contents 1 Isometries of the Metric 1 2 Killing Vectors 3 3 Maximally Symmetric Spaces 5 1 Isometries of the Metric A metric gµν(x) is form-invariant under some coordinate transformation x ↦→ x′ when the transformed metric g′ µν(x′) is the same function of its argument x′ as the original metric gµν was of its argument x. The metric transformation is deﬁned by: gµν(x) = ∂x′ρ ∂xµ ∂x′σ ∂xν g′ ρσ(x ′) (1.1) The above deﬁnition of a form-invariant metric is equivalent to the statement: g′ ρσ(x′) = gρσ(x′) (1.2) i.e. that the form of the metric is invariant under the transformation; the function itself remains the same. So, equation (1.1) becomes: gµν(x) = ∂x′ρ ∂xµ ∂x′σ ∂xν gρσ(x ′) (1.3) What we want to consider are isometries, which are the coordinate transformations x ↦→ x′ that leave a metric form-invariant. We’ll restrict ourselves to inﬁnitesimal isometries, as all the interesting physics is going to be related to inﬁnitesimal transformations. An inﬁnitesimal coordinate transformation can be written as: x µ ↦→ x ′µ = xµ + ϵξµ (ϵ ≪ 1) (1.4) We can plug this transformation into equation (1.3) and keep terms up to order ϵ. First, the partial derivatives will be: ∂x′ρ ∂xµ ∂x′σ ∂xν = ( ∂xρ ∂xµ + ϵ ∂ξρ ∂xµ ) ( ∂xσ ∂xν + ϵ ∂ξσ ∂xν ) = δρ µδσ ν + ϵδρ µ ∂ξσ ∂xν + ϵδσ ν ∂ξρ ∂xµ + O(ϵ 2) Next, taking the Taylor expansion of gρσ(x′) to order ϵ: – 1 – gρσ(x′) = gρσ(x) + ϵξα ∂gρσ(x) ∂xα + O(ϵ 2) Plugging these two results into equation (1.3), we see that: gµν(x) = ( δρ µδσ ν + ϵδρ µ ∂ξσ ∂xν + ϵδσ ν ∂ξρ ∂xµ ) ( gρσ(x) + ϵξα ∂gρσ(x) ∂xα ) = δρ µδσ ν gρσ(x) + ϵδρ µ ∂ξσ ∂xν gρσ(x) + ϵδσ ν ∂ξρ ∂xµ gρσ(x) + δρ µδσ ν ϵξα ∂gρσ(x) ∂xα = gµν(x) + ϵ ∂ξσ ∂xν gµσ(x) + ϵ ∂ξρ ∂xµ gρν(x) + ϵξα ∂gµν(x) ∂xα Thus, to order ϵ, the condition for form-invariance of the metric for an inﬁnitesimal isometry is equivalent to the following condition on the metric: ∂ξσ ∂xν gµσ(x) + ∂ξρ ∂xµ gρν(x) + ξα ∂gµν(x) ∂xα = 0 (1.5) From now on, I’m going to drop the explicit dependence on x, since all of the metrics are being evaluated at the same position, so there is no longer a need to be explicit. The next step is to notice that: ∂ ∂xν (ξσgµσ) = ∂ξσ ∂xν gµσ + ξσ ∂gµσ ∂xν So equation (1.5) becomes: ∂ ∂xν (ξσgµσ) − ξσ ∂gµσ ∂xν + ∂ ∂xµ (ξρgρν) − ξρ ∂gρν ∂xµ + ξα ∂gµν ∂xα = 0 (1.6) There are a couple of things to note about the above equation. There are two non-dummy indices: µ and ν. Besides those, all indices are dummy indices. In the second term, I want to replace σ with α, and in the fourth term, ρ with α. Another thing to notice is that: ξσgµσ = ξµ So, equation (1.6) becomes: ∂ξµ ∂xν + ∂ξν ∂xµ + ξα ( ∂gµν ∂xα − ∂gµα ∂xν − ∂gαν ∂xµ ) = 0 (1.7) Recalling the deﬁnition of the Christoﬀel symbols of the ﬁrst kind: Γαµν = 1 2 ( ∂gµα ∂xν + ∂gαν ∂xµ − ∂gµν ∂xα ) equation (1.7) becomes: – 2 – ∂ξµ ∂xν + ∂ξν ∂xµ − 2ξαΓαµν = 0 (1.8) Noting that ξµ = xλgµλ and that the Christoﬀel symbol of the second kind is deﬁned as: Γλ µν = gλαΓαµν equation (1.8) becomes: ∂ξµ ∂xν + ∂ξν ∂xµ − 2ξλΓλ µν = 0 (1.9) The factor of 2 in front of the Christoﬀel term allows that term to be split, one for each derivative of ξ, which turns those ordinary derivatives into covariant derivatives. Thus, we arrive at the equation: ∇νξµ + ∇µξν = 0 (1.10) 2 Killing Vectors The equation derived at the end of the last section is known as the Killing equation, and the vector ﬁelds ξ that satisfy it are known as Killing vector ﬁelds; they deﬁne the particular isometries of the metric that one might be interested in. For instance, we could construct a killing vector to describe a translational isometry or a rotational isometry. What Killing vectors allow us to do is reduce the problem of ﬁnding all symmetries of a particular metric down to simply ﬁnding the corresponding Killing vectors. Sometimes this problem is very easy, for instance if a metric has an explicit independence of a coordinate. For example, the Minkowski metric is invariant under a translation of any of its four coordinates, so there would be one Killing vector per coordinate (at least). Note that a linear combination of Killing vectors is also a Killing vector, since it will solve the Killing equation like any linear combination of solutions to any diﬀerential equation. So, technically, it’s the spanning set of Killing vectors is actually what describes the isometries of a particular metric. The Killing equation is actually more useful than it appear at ﬁrst sight; it will allow us to deﬁne a Killing vector at any point x if we only know the Killing vector at a speciﬁc point X and its covariant derivative at that point X. It turns out that we can show that second-order covariant derivatives of Killing vectors are not unique, but are proportional to the Killing vector itself, so all second- and higher-order covariant derivatives of the Killing vector can be expressed in terms of just the Killing vector itself and its ﬁrst-order covariant derivative. Thus a Taylor expansion for a Killing vector at x can be expressed entirely in terms of the Killing vector at X and its ﬁrst-order covariant derivative at X. To show this, we need to begin with an identity for second-order covariant derivatives (a la Weinberg, \"Gravitation and Cosmology,\" (13.1.6) or Dirac, \"The General Theory of – 3 – Relativity,\" (11.2)). From now on, I will use the notation that a covariant derivative is given by a subscript with a semi-colon preceding it. The relevant identity is: ξµ;ν;ρ − ξµ;ρ;ν = −Rλ µνρξλ (2.1) Combining this with the ﬁrst Bianchi identity of the Riemann curvature tensor: Rλ µνρ + Rλ νρµ + Rλ ρµν = 0 ⇒ Rλ µνρξλ + Rλ νρµξλ + Rλ ρµνξλ = 0 ⇒ ξµ;ν;ρ − ξµ;ρ;ν + ξν;ρ;µ − ξν;µ;ρ + ξρ;µ;ν − ξρ;ν;µ = 0 Now we want to group the above Killing vector derivatives by the second-derivative, i.e. ξµ;ν;ρ and −ξν;µ;ρ are to be grouped: (ξµ;ν;ρ − ξν;µ;ρ) + (ξν;ρ;µ − ξρ;ν;µ) + (ξρ;µ;ν − ξµ;ρ;ν) = 0 (2.2) If we take the Killing equation and take a second covariant derivative: ξµ;ν + ξν;µ = 0 ⇒ ξµ;ν;ρ + ξν;µ;ρ = 0 we can substitute these modiﬁed Killing equations into equaton (2.2), yielding: 2ξµ;ν;ρ − 2ξρ;ν;µ − 2ξµ;ρ;ν = 0 or: ξµ;ν;ρ − ξµ;ρ;ν = ξρ;ν;µ (2.3) Notice above that I chose a very particular set of signs (ﬁrst term positive, second and third terms negative). This is because, as you can see in the equation immediately above, this gives the term ξµ;ν;ρ − ξµ;ρ;ν, which we have our general second-order covariant derivative identity for. The sign of the third Killing vector derivative isn’t important, but the signs of the ﬁrst two are. Plugging this result into equation (2.1), we arrive at: ξρ;ν;µ = −Rλ µνρξλ (2.4) Thus, the second-order covariant derivative of a Killing vector depends on the Killing vector itself! This is a direct consequence of the Killing equation, because aside from that, we used an identity that is satisﬁed by any vector. Using the above equation, we can construct higher- order covariant derivatives in terms of the Killing vector itself and its ﬁrst-order covariant derivative, allowing us to construct the Taylor expansion for a Killing vector at any point x knowing only the Killing vector at some point X and its ﬁrst-order covariant derivative at that same point X. – 4 – So, any Killing vector can be written as the Taylor expansion: ξµ(x) = A λ µ(x; X)ξλ(X) + Bλν µ (x; X)ξλ;ν(X) (2.5) where the functions A and B contain all the higher-order terms in the Taylor expansion that, through the relationship between the second-order derivative and the Killing vector itself, reduce to either the Killing vector or the ﬁrst-order covariant derivative of the Killing vector. The functions A and B should, in general, depend on the metric and on the choice of point X, but should not depend on the initial value of the Killing vector ξλ(X) or its derivative ξλ;ν(X), so are the same functions for any Killing vector. We could broaden the above equation to allow for a set of Killing vectors {ξ(n)}, in which case equation (2.5) be: ξ(n) µ (x) = Aλ µ(x; X)ξ(n) λ (X) + Bλν µ (x; X)ξ(n) λ;ν (X) (2.6) While the initial values of the Killing vector an its derivative will change with each individual Killing vector considered, the functions A and B will not, because they are independent of these initial values. Note that to avoid confusion, I indexed each individual Killing vector with (n) instead of a bare n, to avoid assuming that n is an index and the assumption that ξn µ is a tensor quantity. Now that we can describe all Killing vectors ξ(n) µ (x) based on their individual initial conditions, we need to consider only the linearly-independent Killing vectors so we can form the spanning set of Killing vectors which, as mentioned, actually describes the isometries of the metric. As always, a set of vectors {ξ(n) µ } is linearly-inependent if ∑ n cnξ(n) µ (x) = 0 if and only if the constant coeﬃcients cn are each independently 0. 3 Maximally Symmetric Spaces The question is now: \"What is the maximum number of linearly-independent Killing vectors one can have in an N -dimensional space?\" Looking back at the Taylor expansion for ξ(n) µ (x), any Killing vector is deﬁned by its initial conditions ξ(n) λ (X) and ξ(n) λ;ν (X). In an N -dimensional space, the Killing vector ξ(n) λ (X) has N independent components. Because of the Killing equation, the ﬁrst-order covariant derivative of a Killing vector ξ(n) λ;ν (X) is anti-symmetric about its indices λ and ν, meaning that in N -dimensions it has N (N − 1)/2 independent components. So a Killing vector ξ(n) µ (x) is deﬁned by N + N (N − 1) 2 = N (N + 1) 2 independent components. – 5 – So, if we take a set of Killing vectors {ξ(n) µ }, the initial values ξ(n) λ (X) and ξ(n) λ;ν (X) should be thought of as the components of vectors in an N (N + 1)/2-dimensional vector space. By deﬁnition, a vector space in d-dimensional because it has, at most, d linearly-independent vectors, so the maximum number of linearly-independent Killing vectors is N (N + 1)/2. A space that has N (N +1)/2 Killing vectors for its metric is known as a maximally symmetric space. The study of maximally symmetric spaces is particularly important in cosmology, speciﬁ- cally in the study of homogeneous and isotropic spaces. A space is homogeneous if for any two points p, q in the space, there exists an isometry of the metric that takes p to q, i.e. the Killing vector ξλ must be an arbitrary value. If at every point p in a space, we deﬁne u to be a time-like tangent vector, and s1 and s2 to be orthogonal space-like tangent vectors, and there exists an isometry of the metric such that p and u are unchanged, but s1 is rotated into s2, then the space is isotropic at every point. This requires that ξλ = 0, so as not to translate the point, but the derivative ξλ;ν must be an arbitrary matrix (which is anti-symmetric, due to the Killing equation). A space which is homogeneous and isotropic at one point is isotropic at every point, so these spaces are typically referred to simply as homogeneous and isotropic spaces. For an N -dimensional space, it is clear that the homogeneity requirement deﬁnes N translational isometries. Further, there will be N diﬀerent time-like vectors about which to rotate in an isotropic space, so that leaves N − 1 space-like vectors to physically rotate (e.g. rotating s1). To avoid double counting, there are N (N − 1)/2 independent isometric rotations in an isotropic space. So, a space which is both homogeneous and isotropic must have N (N + 1)/2 isometries, and is therefore maximally symmetric. In order for a metric to admit the maximal number of Killing vectors depends on how many Killing vectors can be constructed out of their initial data points using a Taylor expan- sion, which we should recall is only possible in the form we’ve considered if equation (2.4) is integrable. We can borrow another covariant derivative identity (a la Dirac (13.1)): ξρ;ν;µ;σ − ξρ;ν;σ;µ = −Rλ ρµσξλ;ν − Rλ νµσξρ;λ (3.1) Taking the covariant derivative of (2.4), we see that: ξρ;ν;µ;σ = −Rλ µνρ;σξλ − Rλ µνρξλ;σ Likewise, by swapping indices in equation (2.4) and taking a covariant derivative, as we did above, we have: ξρ;ν;σ;µ = −Rλ σνρ;µξλ − Rλ σνρξλ;µ – 6 – Plugging these into equation (3.1): ξρ;ν;µ;σ − ξρ;ν;σ;µ = −Rλ ρµσξλ;ν − Rλ νµσξρ;λ ⇒ (−Rλ µνρ;σξλ − Rλ µνρξλ;σ) − (−Rλ σνρ;µξλ − Rλ σνρξλ;µ) = −Rλ ρµσξλ;ν − Rλ νµσξρ;λ ⇒ − Rλ µνρξλ;σ + Rλ σνρξλ;µ + (Rλ σνρ;µ − Rλ µνρ;σ)ξλ = −Rλ ρµσξλ;ν − Rλ νµσξρ;λ In the above equation, we can group by the Killing vector ξλ and by it derivative. Of the four terms that are derivatives, three of them are of the form ξλ;j, where j is an arbitrary index. The one outlier is the term ξρ;λ, but due to the Killing equation, this is equal to −ξλ;ρ. So the above equation becomes: Rλ µνρξλ;σ − Rλ σνρξλ;µ − Rλ ρµσξλ;ν + Rλ νµσξλ;ρ = (Rλ σνρ;µ − Rλ µνρ;σ)ξλ A ξλ;κ can be factored from each term on the left-hand-side by inserting an appropriate Kronecker-delta in each term, causing us to arrive at: (Rλ µνρδκ σ − Rλ σνρδκ µ − Rλ ρµσδκ ν + Rλ νµσδκ ρ )ξλ;κ = (Rλ σνρ;µ − Rλ µνρ;σ)ξλ (3.2) This is yet another requirement for Killing vectors, but we have yet to tie it into maximally symmetric spaces. We know that in a maximally symmetric space, we can ﬁnd Killing vectors for which ξλ(x) = 0 and ξλ;κ(x) is an arbitrary, anti-symmetric matrix (from the condition of isotropy). This means that the left-hand-side of the above equation must be identically equal to zero. A sure-ﬁre way to ensure this is to require that the entire coeﬃcient of ξλ;κ remain unchanged under an exchange of λ and κ. Since the derivative of the Killing vector is antisymmetric, if the coeﬃcient remains the same under a symmetry operation, it must be zero, satisfying the right-hand-side of the above equation when ξλ(x) = 0. Thus: Rλ µνρδκ σ − Rλ σνρδκ µ − Rλ ρµσδκ ν + Rλ νµσδκ ρ = Rκ µνρδλ σ − Rκ σνρδλ µ − Rκ ρµσδλ ν + Rκ νµσδλ ρ (3.3) The above only considers Killing vectors for an isotropic space. For a homogeneous space, we know there must also be Killing vectors which are arbitrary. Keeping the above requirement for the isotropic Killing vectors means that the right-hand-side of equation (3.2) identically equal to zero as well, so it must be true that: Rλ σνρ;µ = Rλ µνρ;σ (3.4) With the previous two conditions satisﬁed, one for isotropy and one for homogeneity, we guaranteed that our space is homogeneous and isotropic, and therefore admits N (N + 1)/2 Killing vectors and is thus maximally symmetric. What we want to do now is use the above results to determine what the Riemann curvature tensor should be for a maximally symmetric space. Taking equation (3.3), we want to contract the κ and σ indices: – 7 – Rλ µνρδσ σ − Rλ σνρδσ µ − Rλ ρµσδσ ν + Rλ νµσδσ ρ = Rσ µνρδλ σ − Rσ σνρδλ µ − Rσ ρµσδλ ν + Rσ νµσδλ ρ The sum of δσ σ is just the dimensionality of the space, which we will assume is N . Note that because of the anti-symmetry conditions of the Riemann curvature tensor, the sum Rσ σνρ equals 0, and that the sum Rσ ρµσ is, by deﬁnition, the Ricci tensor Rρµ. So, the above equation reduces to: N Rλ µνρ − Rλ µνρ − Rλ ρµν + Rλ νµρ = Rλ µνρ − Rρµδλ ν + Rνµδλ ρ (3.5) Now we want to apply the ﬁrst Bianchi identity to the second, third, and fourth terms on the left-hand-side, which states that: Rλ µνρ + Rλ ρµν + Rλ νρµ = 0 Due to the antisymmetry of the Riemann curvature tensor, the third term is equal to Rλ νρµ = −Rλ νµρ, and thus we see that the above Bianchi identity means that the three terms identiﬁed previously in equation (3.5) sum to zero. So, we have, after grouping the factors of Rλ µνρ on the left-hand-side of the equation: (N − 1)Rλ µνρ = −Rρµδλ ν + Rνµδλ ρ And, if we multiply both sides by gκλ and sum, we can lower the indices of all the tensors: (N − 1)Rκµνρ = −Rρµgκν + Rνµgκρ (3.6) Since the Riemann curvature tensor on the left-hand-side must by anti-symmetric about κ and µ, if we were to swap those indices on the right-hand-side of the equation, we’d pick up a negative sign due to this antisymmetry, so: −Rρµgκν + Rνµgκρ = +Rρκgµν − Rνκgµρ Multiplying by gκρ and summing yields: − Rρµ gκνgκρ ︸ ︷︷ ︸ δρ ν +Rνµ gκρgκρ ︸ ︷︷ ︸ N = Rρκgκρ ︸ ︷︷ ︸ Rρ ρ gµν − Rνκ gµρgκρ ︸ ︷︷ ︸ δκ µ ⇒ − Rνµ + N Rνµ = Rgµν − Rνµ where the Ricci scalar is deﬁned as R = Rρ ρ. Since the Ricci curvature tensor is symmetric, we can also say Rνµ = Rµν for cohesiveness. Thus, our result is: Rµν = R N gµν (3.7) Plugging this result back into equation (3.6), we get: – 8 – (N − 1)Rκµνρ = −Rρµgκν + Rνµgκρ = − R N gρµgκν + R N gµνgκρ = R N (gµνgκρ − gρµgκν) Thus, we arrive at the Riemann curvature tensor that describes a maximally symmetric space: Rκµνρ = R N (N − 1) (gµνgκρ − gρµgκν) (3.8) We set out to apply as many restrictions on the form of the Riemann curvature tensor as we could for a maximally symmetric space, and we’ve done just that; there’s nothing else we can do to the above equation given the Killing vectors. However, there is more to learn about the Ricci curvature tensor and the Ricci scalar. Using a well-known identity (a la Weinberg (6.8.4) or Dirac (14.3)): ( Rµν − 1 2 gµνR) ;µ = 0 we can multiply a factor of gνρ into the covariant derivative, resulting in: (Rµ ρ − 1 2 δµ ρ R) ;µ = 0 Using equation (3.7), this means that: Rµ ρ = R N δµ ρ and so the above equation becomes: ( 1 N δµ ρ R − 1 2 gµ ρ R) ;µ = 0 or: ( 1 N − 1 2 ) R;µ = 0 Since R is a scalar, the covariant derivative is equal to the typical gradient, so the above equation is equivalent to: ( 1 N − 1 2 ) ∂R ∂xµ = 0 (3.9) The result of this is that, for a space with dimension N > 2, the Ricci scalar R is a constant; that is, maximally symmetric spaces (with dimension greater than 2) have a constant Ricci curvature. In equation (3.8), we had a term R/N (N −1). Because this is cumbersome, it is convenient to introduce a diﬀerent curvature scalar K such that: – 9 – K = R N (N − 1) This means that equation (3.8) can be re-written as: Rκµνρ = K(gµνgκρ − gρµgκν) (3.10) where K is a constant since R is a constant. There is a very important theorem that Weinberg proves, but I won’t prove here, which I will call the theorem of metric uniqueness. From Weinberg, Given two maximally symmetric metrics with the same K and the same signature, it will always be possible to ﬁnd a coordinate transformation that carries one metric into another. i.e. that a metric is uniquely deﬁned, up to a coordinate transformation, for a given curvature K and signature. The last thing to do now is to take all that we have gathered about maximally symmetric spaces, which bear in mind came entirely from the Killing equation and from the requirements on the Killing vectors that homogeneity and isotropy demand, we can construct the metrics for any maximally symmetric space. It turns out that it won’t be necessary to consider any arbitrary curvature K, because the curvature can easily be rescaled in the metric; it will only be necessary to consider spaces of constant positive curvature, zero curvature, and constant negative curvature. Spaces of constant positive curvature are spherical, spaces of zero curvature are ﬂat, and spaces of constant negative curvature are hyperbolic, so these are the only three spaces (with a regular topology; nothing strange has been considered here) that are maximally symmetric. The end result of this last derivation will be the Robertson-Walker metric, which is the metric used in cosmology. Note that all of the work up to this point has, essentially, been to rigorously derive the single equation for the Riemann curvature tensor for a maximally symmetric space. This is not the most common way, by any means; in fact, it is incredibly uncommon, and Weinberg is the only (popular) reference that I found with such a detailed derivation. Carroll has a much more popular derivation for the same equation, which uses a less rigorous approach to exploiting the symmetry, but arrives at the same result in almost no time at all. The basic argument is this: if space is homogeneous and isotropic, then your Riemann curvature tensor should be invariant under any (local) Lorentz transformation (i.e. a local change of basis should leave the Riemann curvature tensor invariant). There are only three unique tensors that have this property, though: the metric tensor, the Kronecker-delta, and the Levi-Civita tensor. This means that the Riemann curvature tensor must be constructed out of some linear combination of these three tensors, while still maintaining the appropriate anti-symmetry relations. By brute force, it is possible to show that there is only one such combination: – 10 – Rκµνρ ∝ gµνgκρ − gρµgκν Setting the proportionality constant equal to some c and contracting over all indices, the left- hand-side becomes R, the Ricci curvature, and the right-hand-side becomes cN (N − 1), so we would arrive at the same equation for the Riemann curvature tensor: Rκµνρ = R N (N − 1) (gµνgκρ − gρµgκν) = K(gµνgκρ − gρµgκν) – 11 –","libVersion":"0.3.2","langs":""}