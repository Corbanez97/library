{"path":"Books and Papers/Quantum Mechanics & Information/Jakob Schwichtenberg - Physics from Symmetry-Springer (2018).pdf","text":"Undergraduate Lecture Notes in Physics Jakob Schwichtenberg Physics from Symmetry Second Edition Undergraduate Lecture Notes in Physics Undergraduate Lecture Notes in Physics (ULNP) publishes authoritative texts covering topics throughout pure and applied physics. Each title in the series is suitable as a basis for undergraduate instruction, typically containing practice problems, worked examples, chapter summaries, and suggestions for further reading. ULNP titles must provide at least one of the following: • An exceptionally clear and concise treatment of a standard undergraduate subject. • A solid undergraduate-level introduction to a graduate, advanced, or non-standard subject. • A novel perspective or an unusual approach to teaching a subject. ULNP especially encourages new, original, and idiosyncratic approaches to physics teaching at the undergraduate level. The purpose of ULNP is to provide intriguing, absorbing books that will continue to be the reader’s preferred reference throughout their academic career. Series editors Neil Ashby University of Colorado, Boulder, CO, USA William Brantley Department of Physics, Furman University, Greenville, SC, USA Matthew Deady Physics Program, Bard College, Annandale-on-Hudson, NY, USA Michael Fowler Department of Physics, University of Virginia, Charlottesville, VA, USA Morten Hjorth-Jensen Department of Physics, University of Oslo, Oslo, Norway Michael Inglis SUNY Suffolk County Community College, Long Island, NY, USA More information about this series at http://www.springer.com/series/8917 Jakob Schwichtenberg Physics from Symmetry Second Edition 123 Jakob Schwichtenberg Karlsruhe Germany ISSN 2192-4791 ISSN 2192-4805 (electronic) Undergraduate Lecture Notes in Physics ISBN 978-3-319-66630-3 ISBN 978-3-319-66631-0 (eBook) https://doi.org/10.1007/978-3-319-66631-0 Library of Congress Control Number: 2017959156 1st edition: © Springer International Publishing Switzerland 2015 2nd edition: © Springer International Publishing AG 2018 This work is subject to copyright. All rights are reserved by the Publisher, whether the whole or part of the material is concerned, speciﬁcally the rights of translation, reprinting, reuse of illustrations, recitation, broadcasting, reproduction on microﬁlms or in any other physical way, and transmission or information storage and retrieval, electronic adaptation, computer software, or by similar or dissimilar methodology now known or hereafter developed. The use of general descriptive names, registered names, trademarks, service marks, etc. in this publication does not imply, even in the absence of a speciﬁc statement, that such names are exempt from the relevant protective laws and regulations and therefore free for general use. The publisher, the authors and the editors are safe to assume that the advice and information in this book are believed to be true and accurate at the date of publication. Neither the publisher nor the authors or the editors give a warranty, express or implied, with respect to the material contained herein or for any errors or omissions that may have been made. The publisher remains neutral with regard to jurisdictional claims in published maps and institutional afﬁliations. Printed on acid-free paper This Springer imprint is published by Springer Nature The registered company is Springer International Publishing AG The registered company address is: Gewerbestrasse 11, 6330 Cham, Switzerland NATURE AL W A YS CREATES THE BEST OF ALL OPTIONS ARIST O TLE AS F AR AS I SEE, ALL A PRIORI STATEMENTS IN PHYSICS HA VE THEIR ORIGIN IN SYMMETR Y. HERMANN WEYL THE IMPOR TANT THING IN SCIENCE IS NO T SO MUCH T O OBTAIN NEW F A CTS AS T O DISCO VER NEW W A YS OF THINKING ABOUT THEM. WILLIAM LA WRENCE BRA GG Dedicated to my parents Preface to the Second Edition In the two years since the ﬁrst edition of this book was published I’ve received numerous messages from readers all around the world. I was surprised by this large number of responses and how positive most of them were. Of course, I was cautiously conﬁdent that read- ers would like the book. Otherwise I wouldn’t have spent so many months writing it. However, there is certainly no shortage of books on group theory or on the role of symmetries in physics. To quote Predrag Cvitanovic1 1 Predrag Cvitanovi´c. Group Theory: Birdtracks, Lie’s, and Exceptional Groups. Princeton University Press, 7 2008. ISBN 9780691118369 Almost anybody whose research requires sustained use of group theory (and it is hard to think of a physical or mathematical problem that is wholly devoid of symmetry) writes a book about it. Moreover, I’m not a world renowned expert. Therefore, I knew no one would buy the book because my name is written on the cover. So the chances were high that \"Physics from Symmetry\" would simply drown in the ﬂood of new textbooks that are published every year. Therefore, it’s reasonable to wonder: Why and how did \"Physics from Symmetry\" avoid this fate? I think the main reason for the success of the ﬁrst edition is what I framed as something negative above: it wasn’t written by a world renowned expert. I wrote the book while I was still a student and, as I remarked in the preface to the ﬁrst edition, \"I wrote the book I wished had existed when I started my journey in physics\". So my motivation for writing the book wasn’t to create an authoritative ref- erence or a concise text that experts would love. Instead, my only fo- cus was to write a book that helps students understand. As a student myself I always had still fresh in memory what I found confusing and what ﬁnally helped me understand. This point of view is nicely summarized in the following quote by C.S. Lewis2 2 C. S. Lewis. Reﬂections on the Psalms. HarperOne, reprint edition, 2 2017. ISBN 9780062565488It often happens that two schoolboys can solve difﬁculties in their work for one another better than the master can. When you took the problem to a master, as we all remember, he was very likely to explain what you understood already, to add a great deal of information which you didn’t want, and say nothing at all about the thing that was puzzling you. [...] The fellow-pupil can help more than the master because he knows less. The difﬁculty we want him to explain is one he has recently met. The expert met it so long ago he has forgotten. He sees the whole subject, by now, in a different light that he cannot conceive what is really troubling the pupil; he sees a dozen other difﬁculties which ought to be troubling him but aren’t. While most readers liked the student-friendly spirit of the ﬁrst edi- tion, it was, of course, not perfect. Several readers pointed out typos and paragraphs with confusing notation or explanations. This feed- back guided me during the preparation of this second edition. I focused on correcting typos, improving the notation and I rewrote entire sections that were causing confusion. I hope these changes make \"Physics from Symmetry\" even more student-friendly and useful3. 3 No book is ever perfect and I’m al- ways happy to receive feedback. So if you ﬁnd an error, have an idea for im- provement or simply want to comment on something, always feel free to write me at mail@jakobschwichtenberg.com Karlsruhe, September 2017 Jakob Schwichtenberg X Preface to the First Edition The most incomprehensible thing about the world is that it is at all comprehensible. - Albert Einstein4 4 As quoted in Jon Fripp, Deborah Fripp, and Michael Fripp. Speaking of Science. Newnes, 1st edition, 4 2000. ISBN 9781878707512In the course of studying physics I became, like any student of physics, familiar with many fundamental equations and their solu- tions, but I wasn’t really able to see their connection. I was thrilled when I understood that most of them have a com- mon origin: symmetry. To me, the most beautiful thing in physics is when something incomprehensible, suddenly becomes comprehen- sible, because of a deep explanation. That’s why I fell in love with symmetries. For example, for quite some time I couldn’t really understand spin, which is some kind of curious internal angular momentum that almost all fundamental particles carry. Then I learned that spin is a direct consequence of a symmetry, called Lorentz symmetry, and everything started to make sense. Experiences like this were the motivation for this book and in some sense, I wrote the book I wished had existed when I started my journey in physics. Symmetries are beautiful explanations for many otherwise incomprehensible physical phenomena and this book is based on the idea that we can derive the fundamental theories of physics from symmetry. One could say that this book’s approach to physics starts at the end: Before we even talk about classical mechanics or non-relativistic quantum mechanics, we will use the (as far as we know) exact sym- metries of nature to derive the fundamental equations of quantum ﬁeld theory. Despite its unconventional approach, this book is about standard physics. We will not talk about speculative, experimentally unveriﬁed theories. We are going to use standard assumptions and develop standard theories. XII Depending on the reader’s experience in physics, the book can be used in two different ways: • It can be used as a quick primer for those who are relatively new to physics. The starting points for classical mechanics, electro- dynamics, quantum mechanics, special relativity and quantum ﬁeld theory are explained and after reading, the reader can decide which topics are worth studying in more detail. There are many good books that cover every topic mentioned here in greater depth and at the end of each chapter some further reading recommen- dations are listed. If you feel you ﬁt into this category, you are encouraged to start with the mathematical appendices at the end of the book5 before going any further. 5 Starting with Chapter A. In addition, the corresponding appendix chapters are mentioned when a new mathemati- cal concept is used in the text. • Alternatively, this book can be used to connect loose ends for more experienced students. Many things that may seem arbitrary or a little wild when learnt for the ﬁrst time using the usual historical approach, can be seen as being inevitable and straightforward when studied from the symmetry point of view. In any case, you are encouraged to read this book from cover to cover, because the chapters build on one another. We start with a short chapter about special relativity, which is the foundation for everything that follows. We will see that one of the most powerful constraints is that our theories must respect special relativity. The second part develops the mathematics required to utilize symmetry ideas in a physical context. Most of these mathe- matical tools come from a branch of mathematics called group theory. Afterwards, the Lagrangian formalism is introduced, which makes working with symmetries in a physical context straightforward. In the ﬁfth and sixth chapters the basic equations of modern physics are derived using the two tools introduced earlier: The Lagrangian formalism and group theory. In the ﬁnal part of this book these equa- tions are put into action. Considering a particle theory we end up with quantum mechanics, considering a ﬁeld theory we end up with quantum ﬁeld theory. Then we look at the non-relativistic and classi- cal limits of these theories, which leads us to classical mechanics and electrodynamics. Every chapter begins with a brief summary of the chapter. If you catch yourself thinking: \"Why exactly are we doing this?\", return to the summary at the beginning of the chapter and take a look at how this speciﬁc step ﬁts into the bigger picture of the chapter. Every page has a big margin, so you can scribble down your own notes and ideas while reading6. 6 On many pages I included in the margin some further information or pictures. XIII I hope you enjoy reading this book as much as I have enjoyed writing it. Karlsruhe, January 2015 Jakob Schwichtenberg Acknowledgments I want to thank everyone who helped me create this book. I am espe- cially grateful to Fritz Waitz, whose comments, ideas and corrections have made this book so much better. I am also very indebted to Arne Becker and Daniel Hilpert for their invaluable suggestions, comments and careful proofreading. I thank Robert Sadlier for his proofreading, Jakob Karalus for his comments and Marcel Köpke and Paul Tremper for many insightful discussions. I also want to thank Silvia Schwichtenberg, Christian Nawroth, Ulrich Nierste and my editor at Springer, Angela Lahee, for their support. Many thanks are due to all readers of the ﬁrst edition who sug- gested improvements and pointed out mistakes, especially Meir Krukowsky, Jonathan Jones, Li Zeyang, Rob Casey, Ethan C. Jahns, Bart Pastoor, Zheru Qiu, Rudy Blyweert, Bruno Jacobs, Joey Ooi, Henry Carnes, Jandro Kirkish, Vicente Iranzo, Rohit Chaki, Jonathan Wermelinger, Achim Schmetz, RubingBai, Markus Pernow, Gleb Klimovitch, Enric Arcadia, Cassiano Cattan, Martin Wong, Marco Smolla, Alexander Zeng, Mohammad Mahdi AlTakach, Jonathan Hobson, Peter Freed, Daniel Ciobotu, Telmo Cunha, Jia-Ji Zhu, An- drew J. Sutter, Rutwig Campoamor-Stursberg and Andreas Wipf. Finally, my greatest debt is to my parents who always supported me and taught me to value education above all else. If you ﬁnd an error in the text I would appreciate a short email to errors@jakobschwichtenberg.com. All known errors are listed at http://physicsfromsymmetry.com/errata . Contents Part I Foundations 1 Introduction 3 1.1 What we Cannot Derive ................... 3 1.2 Book Overview ........................ 5 1.3 Elementary Particles and Fundamental Forces ...... 7 2 Special Relativity 11 2.1 The Invariant of Special Relativity ............. 12 2.2 Proper Time .......................... 14 2.3 Upper Speed Limit ...................... 16 2.4 The Minkowski Notation .................. 17 2.5 Lorentz Transformations ................... 19 2.6 Invariance, Symmetry and Covariance ........... 21 Part II Symmetry Tools 3 Lie Group Theory 25 3.1 Groups ............................. 26 3.2 Rotations in two Dimensions ................ 29 3.2.1 Rotations with Unit Complex Numbers ...... 31 3.3 Rotations in three Dimensions ............... 33 3.3.1 Quaternions ...................... 34 3.4 Lie Algebras .......................... 38 3.4.1 The Generators and Lie Algebra of SO(3) .... 42 3.4.2 The Abstract Deﬁnition of a Lie Algebra ..... 45 3.4.3 The Generators and Lie Algebra of SU(2) .... 46 3.4.4 The Abstract Deﬁnition of a Lie Group ...... 47 3.5 Representation Theory .................... 50 3.6 SU(2) ............................. 54 3.6.1 The Finite-dimensional Irreducible Representations of SU(2) ........................ 54 XVIII 3.6.2 The Representation of SU(2) in one Dimension . 61 3.6.3 The Representation of SU(2) in two Dimensions 61 3.6.4 The Representation of SU(2) in three Dimensions 62 3.7 The Lorentz Group O(1, 3) .................. 62 3.7.1 One Representation of the Lorentz Group .... 66 3.7.2 Generators of the Other Components of the Lorentz Group .................... 69 3.7.3 The Lie Algebra of the Proper Orthochronous Lorentz Group .................... 70 3.7.4 The (0, 0) Representation .............. 72 3.7.5 The ( 1 2 ,0) Representation .............. 72 3.7.6 The (0, 1 2 ) Representation .............. 74 3.7.7 Van der Waerden Notation ............. 75 3.7.8 The ( 1 2 , 1 2 ) Representation .............. 80 3.7.9 Spinors and Parity .................. 84 3.7.10 Spinors and Charge Conjugation .......... 86 3.7.11 Inﬁnite-Dimensional Representations ....... 87 3.8 The Poincaré Group ..................... 89 3.9 Elementary Particles ..................... 91 3.10 Appendix: Rotations in a Complex Vector Space ..... 92 3.11 Appendix: Manifolds ..................... 93 4 The Framework 95 4.1 Lagrangian Formalism .................... 95 4.1.1 Fermat’s Principle .................. 96 4.1.2 Variational Calculus - the Basic Idea ........ 96 4.2 Restrictions ........................... 97 4.3 Particle Theories vs. Field Theories ............. 98 4.4 Euler-Lagrange Equation ................... 99 4.5 Noether’s Theorem ...................... 101 4.5.1 Noether’s Theorem for Particle Theories ..... 101 4.5.2 Noether’s Theorem for Field Theories - Spacetime Symmetries ...................... 105 4.5.3 Rotations and Boosts ................. 108 4.5.4 Spin ........................... 110 4.5.5 Noether’s Theorem for Field Theories - Internal Symmetries ...................... 110 4.6 Appendix: Conserved Quantity from Boost Invariance for Particle Theories ..................... 113 4.7 Appendix: Conserved Quantity from Boost Invariance for Field Theories ....................... 114 XIX Part III The Equations of Nature 5 Measuring Nature 117 5.1 The Operators of Quantum Mechanics ........... 117 5.1.1 Spin and Angular Momentum ........... 118 5.2 The Operators of Quantum Field Theory ......... 119 6 Free Theory 121 6.1 Lorentz Covariance and Invariance ............. 121 6.2 Klein-Gordon Equation .................... 122 6.2.1 Complex Klein-Gordon Field ............ 124 6.3 Dirac Equation ........................ 124 6.4 Proca Equation ........................ 127 7 Interaction Theory 131 7.1 U(1) Interactions ....................... 133 7.1.1 Internal Symmetry of Free Spin 1 2 Fields ..... 134 7.1.2 Internal Symmetry of Free Spin 1 Fields ..... 135 7.1.3 Putting the Puzzle Pieces Together ......... 136 7.1.4 Inhomogeneous Maxwell Equations and Minimal Coupling ........................ 139 7.1.5 Charge Conjugation, Again ............. 140 7.1.6 Noether’s Theorem for Internal U(1) Symmetry . 141 7.1.7 Interaction of Massive Spin 0 Fields ........ 142 7.1.8 Interaction of Massive Spin 1 Fields ........ 143 7.2 SU(2) Interactions ...................... 143 7.3 Mass Terms and \"Uniﬁcation\" of SU(2) and U(1) .... 150 7.4 Parity Violation ........................ 158 7.5 Lepton Mass Terms ...................... 162 7.6 Quark Mass Terms ...................... 165 7.7 Isospin ............................. 166 7.7.1 Labelling States .................... 168 7.8 SU(3) Interactions ...................... 170 7.8.1 Color .......................... 172 7.8.2 Quark Description .................. 173 7.9 The Interplay Between Fermions and Bosons ....... 174 Part IV Applications 8 Quantum Mechanics 177 8.1 Particle Theory Identiﬁcations ................ 178 8.2 Relativistic Energy-Momentum Relation .......... 178 8.3 The Quantum Formalism .................. 179 8.3.1 Expectation Value .................. 181 XX 8.4 The Schrödinger Equation .................. 182 8.4.1 Schrödinger Equation with an External Field . . . 185 8.5 From Wave Equations to Particle Motion ......... 185 8.5.1 Example: Free Particle ................ 185 8.5.2 Example: Particle in a Box .............. 186 8.5.3 Dirac Notation .................... 189 8.5.4 Example: Particle in a Box, Again ......... 191 8.5.5 Spin ........................... 192 8.6 Heisenberg’s Uncertainty Principle ............. 196 8.7 Comments on Interpretations ................ 197 8.8 Appendix: Interpretation of the Dirac Spinor Components .......................... 198 8.9 Appendix: Solving the Dirac Equation ........... 203 8.10 Appendix: Dirac Spinors in Different Bases ........ 205 8.10.1 Solutions of the Dirac Equation in the Mass Basis 207 9 Quantum Field Theory 209 9.1 Field Theory Identiﬁcations ................. 210 9.2 Free Spin 0 Field Theory ................... 211 9.3 Free Spin 1 2 Field Theory ................... 216 9.4 Free Spin 1 Field Theory ................... 219 9.5 Interacting Field Theory ................... 219 9.5.1 Scatter Amplitudes .................. 220 9.5.2 Time Evolution of States ............... 220 9.5.3 Dyson Series ..................... 224 9.5.4 Evaluating the Series ................. 225 9.6 Appendix: Most General Solution of the Klein-Gordon Equation ............................ 229 10 Classical Mechanics 233 10.1 Relativistic Mechanics .................... 235 10.2 The Lagrangian of Non-Relativistic Mechanics ...... 236 11 Electrodynamics 239 11.1 The Homogeneous Maxwell Equations .......... 240 11.2 The Lorentz Force ....................... 241 11.3 Coulomb Potential ...................... 243 12 Gravity 245 13 Closing Words 251 Part V Appendices A Vector calculus 255 XXI A.1 Basis Vectors .......................... 256 A.2 Change of Coordinate Systems ............... 257 A.3 Matrix Multiplication ..................... 259 A.4 Scalars ............................. 260 A.5 Right-handed and Left-handed Coordinate Systems . . . 260 B Calculus 263 B.1 Product Rule .......................... 263 B.2 Integration by Parts ...................... 263 B.3 The Taylor Series ....................... 264 B.4 Series .............................. 266 B.4.1 Important Series ................... 266 B.4.2 Splitting Sums .................... 268 B.4.3 Einstein’s Sum Convention ............. 269 B.5 Index Notation ........................ 269 B.5.1 Dummy Indices .................... 269 B.5.2 Objects with more than One Index ......... 270 B.5.3 Symmetric and Antisymmetric Indices ...... 270 B.5.4 Antisymmetric × Symmetric Sums ........ 271 B.5.5 Two Important Symbols ............... 272 C Linear Algebra 273 C.1 Basic Transformations .................... 273 C.2 Matrix Exponential Function ................ 274 C.3 Determinants ......................... 274 C.4 Eigenvalues and Eigenvectors ................ 275 C.5 Diagonalization ........................ 275 D Additional Mathematical Notions 277 D.1 Fourier Transform ....................... 277 D.2 Delta Distribution ....................... 278 Bibliography 281 Index 285 Part I Foundations \"The truth always turns out to be simpler than you thought.\" Richard P. Feynman as quoted by K. C. Cole. Sympathetic Vibrations. Bantam, reprint edition, 10 1985. ISBN 9780553342345 1 Introduction 1.1 What we Cannot Derive Before we talk about what we can derive from symmetry, let’s clarify what we need to put into the theories by hand. First of all, there is presently no theory that is able to derive the constants of nature. These constants need to be extracted from experiments. Examples are the coupling constants of the various interactions and the masses of the elementary particles. Besides that, there is something else we cannot explain: The num- ber three. This should not be some kind of number mysticism, but we cannot explain all sorts of restrictions that are directly connected with the number three. For instance, • there are three gauge theories1, corresponding to the three fun- 1 Don’t worry if you don’t understand some terms, like gauge theory or double cover, in this introduction. All these terms will be explained in great detail later in this book and they are included here only for completeness. damental forces described by the standard model: The electro- magnetic, the weak and the strong force. These forces are de- scribed by gauge theories that correspond to the symmetry groups U(1), SU(2) and SU(3). Why is there no fundamental force follow- ing from SU(4)? Nobody knows! • There are three lepton generations and three quark generations. Why isn’t there a fourth? We only know from experiments with high accuracy that there is no fourth generation2. 2 For example, the element abundance in the present universe depends on the number of generations. In addition, there are strong evidence from collider experiments. (See e.g. Phys. Rev. Lett. 109, 241802). • We only include the three lowest orders in Φ in the Lagrangian (Φ0, Φ1, Φ2), where Φ denotes here something generic that de- scribes our physical system and the Lagrangian is the object we use to derive our theory from, in order to get a sensible theory describing free (=non-interacting) ﬁelds/particles. • We only use the three lowest-dimensional representations of the double cover of the Poincaré group, which correspond to spin 0, 1 2 © Springer International Publishing AG 2018 J. Schwichtenberg, Physics from Symmetry, Undergraduate Lecture Notes in Physics, https://doi.org/10.1007/978-3-319-66631-0_1 4 physics from symmetry and 1, respectively, to describe fundamental particles. There is no fundamental particle with spin 3 2 . In the present theory, these things are assumptions we have to put in by hand. We know that they are correct from experiments, but there is presently no deeper principle why we have to stop after three. In addition, there is one thing that can’t be derived from symme- try, but which must be taken into account in order to get a sensible theory: We are only allowed to include the lowest-possible, non-trivial order in the differential operator ∂μ in the Lagrangian. For some theories these are ﬁrst order derivatives ∂μ, for other theories Lorentz in- variance forbids ﬁrst order derivatives and therefore second order derivatives ∂μ∂μ are the lowest-possible, non-trivial order. Otherwise, we don’t get a sensible theory. Theories with higher order derivatives are unbounded from below, which means that the energy in such the- ories can be arbitrarily negative. Therefore states in such theories can always transition into lower energy states and are never stable. Finally, there is another thing we cannot derive in the way we de- rive the other theories in this book: gravity. Of course there is a beau- tiful and correct theory of gravity, called general relativity. But this theory works quite differently than the other theories and a complete derivation lies beyond the scope of this book. Quantum gravity, as an attempt to ﬁt gravity into the same scheme as the other theories, is still a theory under construction that no one has successfully derived. Nevertheless, some comments regarding gravity will be made in the last chapter. introduction 5 1.2 Book Overview Double Cover of the Poincaré Group Irreducible Representations \u0002\u0002 \u0003\u0003 \u0002\u0002 \u0004\u0004 (0, 0) : Spin 0 Rep acts on \u0002\u0002 ( 1 2 ,0) ⊕ (0, 1 2 ) : Spin 1 2 Rep acts on \u0002\u0002 ( 1 2 , 1 2 ) : Spin 1 Rep acts on \u0002\u0002 Scalars Constraint that Lagrangian is invariant \u0002\u0002 Spinors Constraint that Lagrangian is invariant \u0002\u0002 Vectors Constraint that Lagrangian is invariant \u0002\u0002 Free Spin 0 Lagrangian Euler-Lagrange equations \u0002\u0002 Free Spin 1 2 Lagrangian Euler-Lagrange equations \u0002\u0002 Free Spin 1 Lagrangian Euler-Lagrange equations \u0002\u0002 Klein-Gordon equation Dirac equation Proka equation This book uses natural units, which means we set the Planck constant to ¯h = 1 and the speed of light to c = 1. This is helpful for theoretical considerations, because it avoids a lot of unnecessary writing. For applications the constants need to be added again to return to standard SI units. Our starting point will be the basic assumptions of special relativ- ity. These are: The velocity of light has the same value c in all inertial frames of reference, which are frames moving with constant velocity relative to each other and physics is the same in all inertial frames of reference. The set of all transformations permitted by these symmetry con- straints is called the Poincaré group. To be able to utilize them, we discuss the mathematical theory that enables us to work with sym- metries. This branch of mathematics is called group theory. We will derive the irreducible representations of the Poincaré group3, which 3 To be technically correct: We will derive the representations of the double-cover of the Poincaré group instead of the Poincaré group itself. The term \"double-cover\" comes from the observation that the map between the double-cover of a group and the group itself maps two elements of the double cover to one element of the group. This is explained in Section 3.3.1 in detail. you can think of as basic building blocks of all other representations. These representations are what we use later in this text to describe particles and ﬁelds of different spin. On the one hand, spin is an ab- stract label for different kinds of particles/ﬁelds and on the other hand can be seen as something like internal angular momentum. We will discuss in detail how this comes about. Afterwards, the Lagrangian formalism is introduced, which makes working with symmetries in a physical context very conve- 6 physics from symmetry nient. The central object is the Lagrangian. Different Lagrangians describe different physical systems and we will derive several La- grangians using symmetry considerations. In addition, the Euler- Lagrange equations are derived. These enable us to derive the equa- tions of motion from a given Lagrangian. Using the irreducible rep- resentations of the Poincaré group, the fundamental equations of motion for ﬁelds and particles with different spin can be derived. The central idea here is that the Lagrangian must be invariant (=does not change) under any transformation of the Poincaré group. This makes sure the equations of motion take the same form in all frames of reference, which we stated above as \"physics is the same in all inertial frames\". Then, we will discover another symmetry of the Lagrangian for free spin 1 2 ﬁelds: Invariance under U(1) transformations. Similarly an internal symmetry for spin 1 ﬁelds can be found. Demanding local U(1) symmetry will lead us to coupling terms between spin 1 2 and spin 1 ﬁelds. The Lagrangian with this coupling term is the cor- rect Lagrangian for quantum electrodynamics. A similar procedure for local SU(2) and SU(3) transformations will lead us to the correct Lagrangian for weak and strong interactions. In addition, we discuss symmetry breaking and a special way to break symmetries called the Higgs mechanism. The Higgs mecha- nism enables us to describe particles with mass4. 4 Without the Higgs mechanism, terms describing mass in the Lagrangian spoil the symmetry and are therefore forbidden. Afterwards, Noether’s theorem is derived, which reveals a deep connection between symmetries and conserved quantities. We will utilize this connection by identifying each physical quantity with the corresponding symmetry generator. This leads us to the most important equation of quantum mechanics [ ˆxi, ˆpj]= iδij (1.1) and quantum ﬁeld theory [ ˆΦ(x), ˆπ(y)] = iδ(x − y).(1.2) We continue by taking the non-relativistic5 limit of the equation 5 Non-relativistic means that everything moves slowly compared to the speed of light and therefore especially curious features of special relativity are too small to be measurable. of motion for spin 0 particles, called Klein-Gordon equation, which result in the famous Schrödinger equation. This, together with the identiﬁcations we made between physical quantities and the genera- tors of the corresponding symmetries, is the foundation of quantum mechanics. Then we take a look at free quantum ﬁeld theory, by starting introduction 7 with the solutions of the different equations of motion6 and Eq. 1.2. 6 The Klein-Gordon, Dirac, Proka and Maxwell equations.Afterwards, we take interactions into account, by taking a closer look at the Lagrangians with coupling terms between ﬁelds of different spin. This enables us to discuss how the probability amplitude for scattering processes can be derived. By deriving the Ehrenfest theorem the connection between quan- tum and classical mechanics is revealed. Furthermore, the fun- damental equations of classical electrodynamics, including the Maxwell equations and the Lorentz force law, are derived. Finally, the basic structure of the modern theory of gravity, called general relativity, is brieﬂy introduced and some remarks regarding the difﬁculties in the derivation of a quantum theory of gravity are made. The major part of this book is about the tools we need to work with symmetries mathematically and about the derivation of what is commonly known as the standard model. The standard model uses quantum ﬁeld theory to describe the behavior of all known elemen- tary particles. Until the present day, all experimental predictions of the standard model have been correct. Every other theory introduced here can then be seen to follow from the standard model as a special case. For example in the limit of macroscopic objects we get classical mechanics or in the limit of elementary particles with low energy, we get quantum mechanics. For those readers who have never heard about the presently-known elementary particles and their interac- tions, a really quick overview is included in the next section. 1.3 Elementary Particles and Fundamental Forces There are two major categories for elementary particles: bosons and fermions. There can be never two fermions in exactly the same state, which is known as Pauli’s exclusion principle, but inﬁnitely many bosons. This curious fact of nature leads to the completely different behavior of these particles: • fermions are responsible for matter • bosons for the forces of nature. This means, for example, that atoms consist of fermions7, but the 7 Atoms consist of electrons, protons and neutrons, which are all fermions. But take note that protons and neutrons are not fundamental and consist of quarks, which are fermions, too. electromagnetic-force is mediated by bosons. The bosons that are responsible for electromagnetic interactions are called photons. One of the most dramatic consequences of thie exclusion principle is that there is stable matter at all. If there could be inﬁnitely many fermions in the same state, there would be no stable matter8. 8 We will discuss this in Chapter 6 8 physics from symmetry There are four presently known fundamental forces • The electromagnetic force, which is mediated by massless photons. • The weak force, which is mediated by massive W+, W− and Z- bosons. • The strong force, which is mediated by massless gluons. • Gravity, which is (maybe) mediated by gravitons. Some of the these bosons are massless and some are not and this tells us something deep about nature. We will fully understand this after setting up the appropriate framework. For the moment, just take note that each force is closely related to a symmetry. The fact that the bosons mediating the weak force are massive means the related symmetry is broken. This process of spontaneous symmetry breaking is responsible for the masses of all elementary particles. We will see later that this is possible through the coupling to another fundamental boson, the Higgs boson. Fundamental particles interact via some force if they carry the corresponding charge9. 9 All charges have a beautiful common origin that will be discussed in Chapter 7. • For the electromagnetic force this is the electric charge and conse- quently only electrically charged particles take part in electromag- netic interactions. • For the weak force, the charge is called isospin10. All known 10 Often the charge of the weak force carries the extra preﬁx \"weak\", i.e. is called weak isospin, because there is another concept called isospin for composite objects that interact via the strong force. Nevertheless, this is not a fundamental charge and in this book the preﬁx \"weak\" is omitted. fermions carry isospin and therefore interact via the weak force. • The charge of the strong force is called color, because of some curious features it shares with the humanly visible colors. Don’t let this name confuse you, because this charge has nothing to do with the colors you see in everyday life. The fundamental fermions are divided into two subcategories: quarks, which are the building blocks of protons and neutrons, and leptons. Famous leptons are, for example, electrons and neutrinos. The difference is that quarks carry color charge and therefore take part in strong interactions, whereas leptons do not. There are three quark and lepton generations, which consist each of two particles: Generation 1 Generation 2 Generation 3 Electric charge Isospin Color Up Charm Top +2 3 e 1 2 ✓ Quarks: Down Strange Bottom −1 3 e −1 2 ✓ Electron-Neutrino Muon-Neutrino Tauon-Neutrino 0 +1 2 - Leptons: Electron Muon Tauon −e −1 2 - introduction 9 Different particles can be identiﬁed through labels. In addition to the charges and the mass there is another incredibly important label called spin, which can be seen as some kind of internal angular momentum. Bosons carry integer spin, whereas fermions carry half- integer spin. The fundamental fermions we listed above have spin 1 2 and almost all fundamental bosons have spin 1. There is only one known fundamental particle with spin 0: the Higgs boson. There is an anti-particle for each particle, which carries exactly the same labels with opposite sign11. For the electron the anti-particle 11 Maybe except for the mass label. This is currently under experimental investigation, for example at the AEGIS, the ATRAP and the ALPHA exper- iment, located at CERN in Geneva, Switzerland. is called positron, but in general there is no extra name and only a preﬁx \"anti\". For example, the antiparticle corresponding to an up- quark is called anti-up-quark. Some particles, like the photon12 are 12 And maybe the neutrinos, which is currently under experimental investi- gation in many experiments that search for a neutrinoless double-beta decay. their own anti-particle. All these notions will be explained in more detail later in this text. Now it’s time to start with the derivation of the theory that describes correctly the interplay of the different characters in this particle zoo. The ﬁrst cornerstone towards this goal is Einstein’s famous theory of special relativity, which is the topic of the next chapter. 2 Special Relativity The famous Michelson-Morley experiment discovered that the speed of light has the same value in all reference frames1. Albert Einstein 1 The speed of objects we observe in everyday life depend on the frame of reference. For example, when an observer standing at a train station measures that a train moves with 50 km h , another observer running with 15 km h next to the same train, measures that the train moves with 35 km h .In contrast, light always moves with 1, 08 · 109 km h , no matter how you move relative to it. recognized the far reaching consequences of this observation and around this curious fact of nature he built the theory of special rela- tivity. Starting from the constant speed of light, Einstein was able to predict many interesting and strange consequences that all proved to be true. We will see how powerful this idea is, but ﬁrst let’s clarify what special relativity is all about. The two basic postulates are • The principle of relativity: Physics is the same in all inertial frames of reference, i.e. frames moving with constant velocity relative to each other. • The invariance of the speed of light: The velocity of light has the same value c in all inertial frames of reference. In addition, we will assume that the stage our physical laws act on is homogeneous and isotropic. This means it does not matter where (=homogeneity) we perform an experiment and how it is oriented (=isotropy), the laws of physics stay the same. For example, if two physicists, one in New-York and the other one in Tokyo, perform ex- actly the same experiment, they would ﬁnd the same2 physical laws. 2 Besides from changing constants, as, for example, the gravitational acceleration Equally a physicist on planet Mars would ﬁnd the same physical laws. The laws of physics, formulated correctly, shouldn’t change if you look at the experiment from a different perspective or repeat it tomorrow. In addition, the ﬁrst postulate tells us that a physical experiment should come up with the same result regardless of if you perform it on a wagon moving with constant speed or at rest in a laboratory. These things coincide with everyday experience. For example, if you close your eyes in a car moving with constant speed, there is no way to tell if you are really moving or if you’re at rest. © Springer International Publishing AG 2018 J. Schwichtenberg, Physics from Symmetry, Undergraduate Lecture Notes in Physics, https://doi.org/10.1007/978-3-319-66631-0_2 12 physics from symmetry Without homogeneity and isotropy physics would be in deep trouble: If the laws of nature we deduce from experiment would hold only at one point in space, for a speciﬁc orientation of the experiment such laws would be rather useless. The only unintuitive thing is the second postulate, which is con- trary to all everyday experience. Nevertheless, all experiments until the present day show that it is correct. 2.1 The Invariant of Special Relativity Before we dive into the details, here’s a short summary of what we want to do in the following sections. We use the postulates of special relativity to derive the Minkowski metric, which tells us how to com- pute the \"distance\" between two physical events. Another name for physical events in this context is points in Minkowski space, which is how the stage the laws of special relativity act on is called. It then follows that all transformations connecting different inertial frames of reference must leave the Minkowski metric unchanged. This is how we are able to ﬁnd all transformations that connect allowed frames of reference, i.e. frames with a constant speed of light. In the rest of the book we will use the knowledge of these transformations, to ﬁnd equations that are unchanged by these transformations. Let’s start with a thought experiment that enables us to derive one of the most fundamental consequences of the postulates of special relativity. Fig. 2.1: Illustration of the thought experiment Imagine, we have a spectator, standing at the origin of his co- ordinate system and sending a light pulse straight up, where it is reﬂected by a mirror and ﬁnally reaches again the point from where it was sent. An illustration of this can be seen in Fig. 2.1 We have three important events: • A : the light leaves the starting point • B : the light is reﬂected at a mirror • C : the light returns to the starting point. The time-interval between A and C is33 For constant speed v we have v = Δs Δt , with the distance covered Δs and the time needed Δt, and therefore Δt = Δs v Δt = tC − tA = 2L c ,(2.1) where L denotes the distance between the starting point and the mirror. Next imagine a second spectator, standing at tA at the origin of his coordinate system and moving with constant velocity u to the left, special relativity 13 relative to the ﬁrst spectator4. For simplicity let’s assume that the 4 Transformations that allow us to trans- form the description of one observer into the description of a second ob- server, moving with constant speed relative to ﬁrst observer, are called boosts. We derive later a formal de- scription of such transformations. origin of this second spectators’ coordinate system coincides at tA with the coordinate origin of the ﬁrst spectator. The second spectator sees things a little differently. In his frame of reference the point where the light ends up will not have the same coordinates as the starting point (see Fig. 2.2). We can express this mathematically x′ A = 0 ̸= x′ C = uΔt′ → Δx′ = uΔt′,(2.2) where the primed coordinates denote the moving spectator. For the ﬁrst spectator in the rest-frame we have of course xA = xC → Δx = 0. (2.3) We assume movement along the x-axis, therefore y′ A = y′ C and z′ A = z′ C → Δy′ = 0 and Δz′ = 0 (2.4) and equally of course yA = yC and zA = zC → Δy = 0 and Δz = 0. (2.5) Fig. 2.2: Illustration of the thought experiment for a moving spectator. The second spectator moves to the left and therefore the ﬁrst spectator (and the experiment) moves relative to him to the right. The next question is: What about the time interval the second spectator measures? Because we postulate a constant velocity of light, the second spectator measures a different time interval between A and C! The time interval Δt′ = t′ C − t′ A is equal to the distance l the light travels, as the second spectator observes it, divided by the speed of light c. Δt′ = l c (2.6) We can compute the distance traveled l using the good old Pythagorean theorem (see Fig. 2.2) l = 2 √( 1 2 uΔt′)2 + L2.(2.7) Using Eq. 2.6, we therefore conclude cΔt′ = 2 √( 1 2 uΔt′)2 + L2 .(2.8) If we now use Δx′ = uΔt′ from Eq. 2.2, we can write cΔt′ = 2 √( 1 2 Δx′)2 + L2 14 physics from symmetry → (cΔt′)2 = 4 (( 1 2 Δx′)2 + L2) → (cΔt′)2 − (Δx′)2 = 4 (( 1 2 Δx′)2 + L2) − (Δx′)2 = 4L2 (2.9) and now recalling from Eq. 2.1 that Δt = 2L c , we can write (cΔt′)2 − (Δx′)2 = 4L2 =(cΔt)2 =(Δtc)2 − (Δx)2 ︸ ︷︷ ︸ =0 see Eq. 2.3 .(2.10) So ﬁnally, we arrive5 at 5 Take note that what we are doing here is just the shortest path to the result, because we chose the origins of the two coordinate systems to coincide at tA. Nevertheless, the same can be done, with more effort, for arbitrary choices, because physics is the same in all inertial frames. We used this freedom to choose two inertial frames where the computation is easy. In an arbitrarily moving second inertial system we do not have Δy′ = 0 and Δz′ = 0. Nevertheless, the equation holds, because physics is the same in all inertial frames. (cΔt′)2 − (Δx′)2 − (Δy′)2 ︸ ︷︷ ︸ =0 − (Δz′)2 ︸ ︷︷ ︸ =0 =(cΔt)2 − (Δx)2 ︸ ︷︷ ︸ =0 − (Δy)2 ︸ ︷︷ ︸ =0 − (Δz)2 ︸ ︷︷ ︸ =0 . (2.11) Considering a third observer, moving with a different velocity rela- tive to the ﬁrst observer, we can use the same reasoning to arrive at (cΔt′′)2 − (Δx′′)2 − (Δy′′)2 − (Δz′′)2 =(cΔt)2 − (Δx)2 − (Δy)2 − (Δz)2 (2.12) Therefore, we have found something which is the same for all observers: the quadratic form (Δs)2 ≡ (cΔt)2 − (Δx)2 − (Δy)2 − (Δz)2.(2.13) In addition, we learned in this section that (Δx)2 +(Δy)2 +(Δz)2 or (cΔt)2 aren’t the same for different observers. We will talk about the implications of this curious property in the next section. 2.2 Proper Time Fig. 2.3: World line of an object at rest. The position of the object stays the same as time goes on. Fig. 2.4: World line of a moving object with two events A and B. The distance travelled between A and B is Δx and the time that passed the events is Δt. We derived in the last section the invariant of special relativity Δs2, i.e. a quantity that has the same value for all observers. Now, we want to think about the physical meaning of this quantity. For brevity, let’s restrict ourselves to one spatial dimension. An object at rest, relative to some observer, has a spacetime diagram as drawn in Fig. 2.3. In contrast, an object moving with constant velocity, relative to the same observer, has a spacetime diagram as drawn in Fig. 2.4. The lines we draw to specify the position of objects in spacetime are called world lines. World lines are always observer dependent. Two different observers may draw completely different world lines for the same object. The moving object with world line drawn in special relativity 15 Fig. 2.4, looks for a second observer who moves with the same con- stant speed as the object, as drawn in Fig. 2.5. For this second ob- server the object is at rest. Take note, to account for the two different descriptions we introduce primed coordinates for the second ob- server: x′ and t′. We can see that both observers do not agree on the distance the object travels between some events A and B in spacetime. For the ﬁrst observer we have Δx ̸= 0, but for the second observer Δx′ = 0. For both observers the time interval between A and B is non-zero: Δt ̸= 0 and Δt′ ̸= 0. Both observers agree on the value of the quantity (Δs)2, because as we derived in the last section, this invariant of special relativity has the same value for all observers. A surprising consequence is that both observers do not agree on the time elapsed between the events A and B Fig. 2.5: World line of the same moving object, as observed from someone moving with the same constant speed as the object. The distance travelled between A and B is for this observer Δx′ = 0. (Δs)2 =(cΔt)2 − (Δx)2 (2.14) (Δs′)2 =(cΔt′)2 − (Δx′)2 ︸ ︷︷ ︸ =0 =(cΔt′)2 (2.15) (Δs)2 =(Δs′)2 → (Δt′)2 ̸=(Δt)2 because (Δx)2 ̸= 0. (2.16) This is one of the most famous phenomena of special relativity and commonly called time-dilation. Time-intervals and spatial dis- tances are observer dependent. The clocks tick differently for differ- ent observers and therefore they observe a different number of ticks between two events. Now that the concept of time has become relative, a new notion of time that all observers agree on may be useful. In the example above we can see that for the second observer, moving with the same speed as the object, we have (Δs)2 =(cΔt′)2 .(2.17) This means the invariant of special relativity is equivalent, up to a constant c, to the time interval measured by this observer. With this in mind, we can interpret (Δs)2 and deﬁne a notion of time that all observers agree on. We deﬁne (Δs)2 =(cΔτ)2,(2.18) where τ is called the proper time. The proper time is the time mea- sured by an observer in the special frame of reference where the object in question is at rest. 16 physics from symmetry Of course objects in the real world aren’t restricted to motion with constant speed, but if the time interval is short enough, in the extremal case inﬁnitesimal, any motion is linear and the notion of proper time is sensible. In mathematical terms this requires we make the transition to inﬁnitesimal intervals Δ → d: (ds)2 =(cdτ)2 =(cdt)2 − (dx)2 − (dy)2 − (dz)2.(2.19) Therefore, even if an object moves wildly, we can still imagine some observer with a clock travelling with the object and therefore observing the object at rest. The time interval this special observer measures is the proper time and all observers agree on its value, be- cause (ds)2 =(cdτ)2 has the same value for all observers. Again, this does not mean that all observers measure the same time inter- val! They just agree on the value of the time interval measured by someone who travels with the object in question. 2.3 Upper Speed Limit Now that we have an interpretation for the invariant of special rela- tivity, we can go a step further and explore one of the most stunning consequences of the postulates of special relativity. It follows from the minus sign in the deﬁnition of Δs2that it can be zero for two events that are separated in space and time. It even can be negative, but then we would get a complex value for the proper time6, which is commonly discarded as unphysical. We conclude, we 6 Recall (ds)2 =(cdτ)2 and therefore if (ds)2 < 0 → dτ is complex. have a minimal proper time τ = 0 for two events if Δs2 = 0. Then we can write Δs2 min = 0 =(cΔt)2 − (Δx)2 − (Δy)2 − (Δz)2 → (cΔt)2 =(Δx)2 +(Δy)2 +(Δz)2 → c2 = (Δx)2 +(Δy)2 +(Δz)2 (Δt)2 .(2.20) On the right-hand side we have a squared velocity v2, i.e. distance divided by time. We can rewrite this in the inﬁnitesimal limit → c2 = (dx)2 +(dy)2 +(dz)2 (dt)2 .(2.21) The functions x(t), y(t), z(t) describe the path between the two events. Therefore, we have on the right-hand side the velocity be- tween the events. special relativity 17 We conclude the lowest value for the proper time is measured by someone travelling with speed → c2 = v2.(2.22) This means nothing can move with a velocity larger than c! We have an upper speed limit for everything in physics. Two events in spacetime can’t be connected by anything faster than c. From this observation follows the principle of locality, which means that everything in physics can only be inﬂuenced by its imme- diate surroundings. Every interaction must be local and there can be no action at a distance, because everything in physics needs time to travel from some point to another. 2.4 The Minkowski Notation Henceforth space by itself, and time by itself, are doomed to fade away into mere shadows, and only a kind of union of the two will preserve an independent reality. - Hermann Minkowski7 7 In a speech at the 80th Assembly of German Natural Scientists and Physicians (21 September 1908)We can rewrite the invariant of special relativity ds2 =(cdt)2 − (dx)2 − (dy)2 − (dz)2 (2.23) by using a new notation, which looks quite complicated at ﬁrst sight, but will prove to be invaluable: ds2 = ημνdxμdxν = η00(dx0)2 + η11(dx1)2 + η22(dx2)2 + η33(dx3)2 =(dx0)2 − (dx1)2 − (dx2)2 − (dx3)2 =(cdt)2 − (dx)2 − (dy)2 − (dz)2. (2.24) Here we use several new notations and conventions one needs to become familiar with, because they are used everywhere in modern physics: • Einsteins summation convention: If an index occurs twice, a sum is implicitly assumed : ∑3 i=1 aibi = aibi = a1b1 + a2b2 + a3b3, but ∑3 i=1 aibj = a1bj + a2bj + a3bj ̸= aibj • Greek indices8, like μ, ν or σ, are always summed from 0 to 3: 8 In contrast, Roman indices like i, j, k are always summed: xi xi ≡ ∑3 i xi xi from 1 to 3. Much later in the book we will use capital Roman letters like A, B, C that are summed from 1 to 8. xμyμ = ∑3 μ=0 xμyμ. • Renaming of the variables x0 ≡ ct, x1 ≡ x, x2 ≡ y and x3 ≡ z,to make it obvious that time and space are now treated equally and to be able to use the rules introduced above 18 physics from symmetry • Introduction of the Minkowski metric η00 = 1, η11 = −1, η22 = −1, η33 = −1 and ημν = 0 for μ ̸= ν ( an equal way of writing this is9 9 η = ⎛ ⎜ ⎜ ⎝ 1 000 0 −10 0 00 −10 00 0 −1 ⎞ ⎟ ⎟ ⎠ η = diag(1, −1, −1, −1) ) In addition, it’s conventional to introduce the notion of a four- vector dxμ = ⎛ ⎜ ⎜ ⎜ ⎝ dx0 dx1 dx2 dx3 ⎞ ⎟ ⎟ ⎟ ⎠ ,(2.25) because the equation above can be written equally using four-vectors and the Minkowski metric in matrix form (ds)2 = dxμημνdxν = (dx0 dx1 dx2 dx3) ⎛ ⎜ ⎜ ⎜ ⎝ 1 000 0 −10 0 00 −10 00 0 −1 ⎞ ⎟ ⎟ ⎟ ⎠ ⎛ ⎜ ⎜ ⎜ ⎝ dx0 dx1 dx2 dx3 ⎞ ⎟ ⎟ ⎟ ⎠ = dx2 0 − dx2 1 − dx2 2 − dx2 3 (2.26) This is really just a clever way of writing things. A physical in- terpretation of ds is that it is the \"distance\" between two events in spacetime. Take note that we don’t mean here only the spatial dis- tance, but also have to consider a separation in time. If we consider 3-dimensional Euclidean10 space the squared (shortest) distance be- 10 3-dimensional Euclidean space is just the space of classical physics, where time was treated differently from space and therefore it was not included into the geometric considerations. The notion of spacetime, with time as a fourth coordinate was introduced with special relativity, which enables mixing of time and space coordinates as we will see. tween two points is given by11 11 The Kronecker delta δij, which is the identity matrix in index notation, is deﬁned in Appendix B.5.5. (ds)2 = dxiδijdxj = (dx1 dx2 dx3) ⎛ ⎜ ⎝100 010 001 ⎞ ⎟ ⎠ ⎛ ⎜ ⎝dx1 dx2 dx3 ⎞ ⎟ ⎠ =(ds)2 =(dx1)2 +(dx2)2 +(dx3)2 (2.27) The mathematical tool that tells us the distance between two in- ﬁnitesimal separated points is called metric. In boring Euclidean space the metric is just the identity matrix δ. In the curved space- time of general relativity much more complicated metrics can occur. The geometry of the spacetime of special relativity is encoded in the relatively simple Minkowski metric η. Because the metric is the tool to compute length, we need it to deﬁne the length of a four-vector, which is given by the scalar product of the vector with itself1212 The same is true in Euclidean space: length 2(v)= ⃗v · ⃗v = v2 1 + v2 2 + v2 3, because the metric is here simply δ = ⎛ ⎝100 010 001 ⎞ ⎠. x2 = x · x ≡ xμxνημν . Analogously, the scalar product of two arbitrary four-vectors is special relativity 19 deﬁned by x · y ≡ xμyνημν.(2.28) There is another, notational convention to make computations more streamlined. We deﬁne a four-vector with upper index as13 13 Four-vectors with a lower index are often called covariant and four-vectors with an upper index contravariant. xμ ≡ ημνxν (2.29) or equally yν ≡ ημνyμ =︸︷︷︸ The Minkowski metric is symmetric ημν=ηνμ ηνμyμ .(2.30) Therefore, we can write the scalar product of two four-vectors as14 14 The name of the index makes no difference. For more information about this have a look at Appendix B.5.1. x · y ≡ xμyνημν = xμyμ = xνyν.(2.31) It doesn’t matter which index we transform to an upper index. This is just a way of avoiding writing the Minkowski metric all the time, just as Einstein’s summation convention is introduced to avoid writ- ing the summation sign. 2.5 Lorentz Transformations Next, we try to ﬁgure out in what ways we can transform our de- scription in a given frame of reference without violating the postu- lates of special-relativity. We learned above that it follows directly from the two postulates that ds2 = ημνdxμdxν is the same in all iner- tial frames of reference: ds′2 = dx′ μdx′ νημν = ds2 = dxμdxνημν.(2.32) Therefore, allowed transformations are those which leave this quadratic form or equally the scalar product of Minkowski spacetime invariant. Denoting a generic transformation that transforms the description in one frame of reference into the description in another frame with Λ, the transformed coordinates dx′ μ can be written as: dxμ → dx′ μ = Λ σ μ dxσ.(2.33) Then we can write the invariance condition as 20 physics from symmetry (ds)2 =(ds′)2 → dx · dx ! = dx′ · dx′ → dxμdxνημν ! = dx′ μdx′ νημν =︸︷︷︸ Eq. 2.33 Λ σ μ dxσΛ γ ν dxγημν →︸︷︷︸ Renaming dummy indices dxμdxνημν ! = Λ μ σ dxμΛ ν γ dxνησγ →︸︷︷︸ Because the equation holds for arbitrary dxμ ημν ! = Λ μ σ ησγΛ ν γ .(2.34) Or written in matrix notation1515 If you wonder about the transpose here have a look at Appendix C.1. η = ΛTηΛ (2.35) This is the condition that transformations Λ between allowed frames of reference must fulﬁl. If this seems strange at this point don’t worry, because we will see that such a condition is a quite natural thing. In the next chapter we will learn that, for example, rotations in ordinary Euclidean space are deﬁned as those transformations O that leave the scalar product of Euclidean space invariant1616 The · is used for the scalar product of vectors, which corresponds to ⃗a ·⃗b = ⃗aT⃗b for ordinary matrix multiplication, where a vector is an 1 × 3 matrix. The fact (Oa)T = aTOT is explained in Appendix C.1, speciﬁcally Eq. C.3. ⃗a ·⃗b ! = ⃗a′ ·⃗b′ =︸︷︷︸ Take note that (Oa)T =aTOT ⃗aTOTO⃗b.(2.36) Therefore17 OT1O ! = 1 and we can see that the metric of Euclidean 17 This condition is often called orthog- onality, hence the symbol O. A matrix satisfying OTO = 1 is called orthogonal, because its columns are orthogonal to each other. In other words: Each column of a matrix can be thought of as a vector and the orthogonality condi- tion for matrices means that each such vector is orthogonal to all other column vectors. space, which is just the unit matrix 1, plays the same role as the Minkowski metric in Eq. 2.35. This is one part of the deﬁnition for rotations, because the deﬁning feature of rotations is that they leave the length of a vector unchanged, which corresponds mathematically to the invariance of the scalar product18. Additionally we must in- 18 Recall that the length of a vector is given by the scalar product of a vector with itself. clude that rotations do not change the orientation19 of our coordinate 19 This is explained in Appendix A.5. system, which means mathematically det O ! = 1, because there are other transformations which leave the length of any vector invariant: spatial inversions20 20 A spatial inversion is simply a map ⃗x →−⃗x. Mathematically such trans- formations are characterized by the conditions det O ! = −1 and OTO = 1. Therefore, if we only want to talk about rotations we have the extra condition det O ! = 1. Another name for spatial inversions are parity transformations. We deﬁne the Lorentz transformations as those transformations that leave the scalar product of Minkowski spacetime invariant. In physical terms this means that Lorentz transformations describe changes between frames of references that respect the postulates of special relativity. In turn this does mean, of course, that every- time we want to get a term that does not change under Lorentz transformations, we must combine an upper with a lower index: special relativity 21 xμyμ = xμyνημν. We will construct explicit matrices for the allowed transformations in the next chapter, after we have learned some very elegant techniques for dealing with conditions like this. 2.6 Invariance, Symmetry and Covariance Before we move on, we have to talk about some very important no- tions. Firstly, we call something invariant, if it does not change under transformations. For instance, let’s consider something arbitrary like F = F(A, B, C, ...) that depends on different quantities A, B, C, .... If we transform A, B, C, ... → A′, B′, C′, ... and we have F(A′, B′, C′, ...)= F(A, B, C, ...) (2.37) F is called invariant under this transformation. We can express this differently using the word symmetry. Symmetry is deﬁned as in- variance under a transformation or class of transformations. For example, some physical system is symmetric under rotations if we can rotate it arbitrarily and it always stays exactly the same. Another example would be a room with constant temperature. The quantity temperature does not depend on the position of measurement. In other words, the quantity temperature is invariant under translations. A translation means that we move every point a given distance in a speciﬁed direction. Therefore, we have translational symmetry within this room. Covariance means something similar, but may not be confused with invariance. An equation is called covariant, if it takes the same form when the objects in it are transformed. For instance, if we have an equation E1 = aA2 + bBA + cC4 and after the transformation this equation reads E′ 1 = aA′2 + bB′ A′ + cC′4 the equation is called covariant, because the form stayed the same. Another equation E2 = x2 + 4axy + z that after a transformation looks like E′ 2 = y′3 + 4az′y′ + y′2 + 8z′x′ is not covariant, because it changed its form completely. 22 physics from symmetry All physical laws must be covariant under Lorentz transformations, because only such laws are valid in all reference frames. Formulat- ing the laws of physics in a non-covariant way would be a very bad idea, because such laws would only hold in one frame of reference. The laws of physics would look differently in Tokyo and New York. There is no preferred frame of reference and we therefore want our laws to hold in all reference frames. We will learn later how we can formulate the laws of physics in a covariant manner. special relativity 23 Further Reading Tips • E. Taylor and J. Wheeler - Spacetime Physics: Introduction to Special Relativity21 is a very good book to start with. 21 Edwin F. Taylor and John Archibald Wheeler. Spacetime Physics.W. H. Freeman, 2nd edition, 3 1992. ISBN 9780716723271 • D. Fleisch - A Student’s Guide to Vectors and Tensors22 has very 22 Daniel Fleisch. A Student’s Guide to Vectors and Tensors. Cambridge University Press, 1st edition, 11 2011. ISBN 9780521171908 creative explanations for the tensor formalism used in special relativity, for example, for the differences between covariant and contravariant components. • N. Jeevanjee - An Introduction to Tensors and Group Theory for Physicists23 is another good source for the mathematics needed in 23 Nadir Jeevanjee. An Introduction to Tensors and Group Theory for Physicists. Birkhaeuser, 1st edition, August 2011. ISBN 978-0817647148 special relativity. • A. Zee - Einstein Gravity in a nutshell24 is a book about gen- 24 Anthony Zee. Einstein Gravity in a Nutshell. Princeton University Press, 1st edition, 5 2013. ISBN 9780691145587 eral relativity, but has many great explanations regarding special relativity, too. Part II Symmetry Tools \"Numbers measure size, groups measure symmetry.\" Mark A. Armstrong in Groups and Symmetry. Springer, 2nd edition, 2 1997. ISBN 9780387966755 3 Lie Group Theory Chapter Overview This diagram explains the structure of this chapter. You should come back here whenever you feel lost. There is no need to spend much time here at a ﬁrst encounter. 2D Rotations U(1) \u0005\u0005 SO(2) \u0006\u0006 3D Rotations SU(2) \u0007\u0007 SO(3) \u0006\u0006 Lorentz Transformations \u0002\u0002 Lie algebra ˆ=su(2) ⊕ su(2) \u0002\u0002 Representations of the Double Cover Lorentz Transformations + Translations \u0002\u0002 Poincaré Group The ﬁnal goal of this chapter is the derivation of the fundamental representations of the double cover of the Poincaré group, which we assume is the fundamental symmetry group of spacetime. These fundamental representations are the tools needed to describe all elementary particles, each representation for a different kind of el- ementary particle. The representations will tell us what types of elementary particles exist in nature. We start with the deﬁnition of a group, which is motivated by two easy examples. Then, as a ﬁrst step towards Lie theory we introduce two ways for describing rotations in two dimensions: •2 × 2 rotation matrix and • unit complex numbers. Then we will try to ﬁnd a similar second description of rotations in three dimensions. This leads us to an extremely important group, called1 SU(2). After that, we will learn about Lie algebras, which en- 1 The S stands for special, which means det(M)= 1. U stands for unitary: M† M = 1 and the number 2 is used because the group is deﬁned in the ﬁrst place by 2 × 2 matrices. able us to learn a lot about something difﬁcult (a Lie group) by using something simpler (the corresponding Lie algebra). There are in gen- eral many groups with the same Lie algebra, but only one of them is truly fundamental. We will use this knowledge to reveal the true fundamental symmetry group of nature, which doubly covers the Poincaré group. We usually start with some known transformations, derive the Lie algebra and use this Lie algebra to get different repre- sentations of the symmetry transformations. This will enable us to see that the representation we started with is just one special case out of many. This knowledge can then be used to learn something fun- damental about the Lorentz group, which is an important part of the © Springer International Publishing AG 2018 J. Schwichtenberg, Physics from Symmetry, Undergraduate Lecture Notes in Physics, https://doi.org/10.1007/978-3-319-66631-0_3 26 physics from symmetry Poincaré group. We will see that the Lie algebra of the double cover of the Lorentz group consists of two copies of the SU(2) Lie algebra. Therefore, we can directly use everything we learned about SU(2). Finally, we include translations into the considerations, which leads us to the Poincaré group. The Poincaré group is the Lorentz group plus translations. At this point, we will have everything at hand to classify the fundamental representations of the double cover of the Poincaré group. We use these fundamental representations in later chapters to derive the fundamental laws of physics. 3.1 Groups If we want to utilize the power of symmetry, we need a framework to deal with symmetries mathematically. The branch of mathematics that deals with symmetries is called group theory. A special branch of group theory that deals with continuous symmetries is Lie The- ory. Symmetry is deﬁned as invariance under a set of of transforma- tions and therefore, one deﬁnes a group as a collection of transforma- tions. Let us get started with two easy examples to get a feel for what we want to do: 1. A square is mathematically a set of points (for example, the four corner points are part of this set) and a symmetry of the square is a transformation that maps this set of points into itself. Fig. 3.1: Illustration of a square Examples of symmetries of the square are rotations about the origin by 90◦, 180◦, 270◦ or 0◦. These rotations map the square into itself. This means they map every point of the set to a point that lies again in the set and one says the set is invariant under such transformations. Fig. 3.2: Illustration of a square, rotated by 5◦ Take note that not every rotation is a symmetry of the square. This becomes obvious when we focus on the corner points of the square. Transforming the set by a clockwise rotation by, say 5◦, maps these points into points outside the original set that deﬁnes the square. For example, as shown in Figure 3.2, the corner point A is mapped to the point A′, which is not found inside the set that deﬁned the square in the ﬁrst place. Therefore a rotation by 5◦ is not a symmetry of the square. Of course the rotated object is still a square, but a different square (=different set of points). Never- theless, a rotation by 90◦ is a symmetry of the square because the point A is mapped to the point B, which lies again in the original set. This is shown in Fig. 3.3. lie group theory 27 Fig. 3.3: Illustration of the square rotated by 90◦ Here’s another helpful perspective: Imagine you close your eyes for a moment, and someone transforms a square in front of you. If you can’t tell after opening your eyes whether the person changed anything at all, then the transformation was a symmetry transfor- mation. The set of transformations that leave the square invariant is called a group. The transformation parameter, here the rotation angle, can’t take on arbitrary values and the group is called a discrete group. 2. Another example is the set of transformations that leave the unit circle invariant. Again, the unit circle is deﬁned as a set of points and a symmetry transformation is a map that maps this set into itself. Fig. 3.4: Illustration of the rotation of the unit circle. For arbitrary rotations about the origin, all rotated points lie again in the initial set. The unit circle is invariant under all rotations about the origin, not just a few. In other words: the transformation parameter (the rotation angle) can take on arbitrary values, and the group is said to be a continuous group. We are, of course, not only interested in symmetries of geomet- ric shapes. For examples, considering vectors, we can look at the set of transformations that leave the length of any vector unchanged. For this reason, the deﬁnition of symmetry at the beginning of this chapter was very general: Symmetry means invariance under a trans- formation. Luckily, there is one mathematical theory, called group theory, that lets us work with all kinds of symmetries2 2 As a side-note: Group theory was invented historically to describe sym- metries of equationsTo make the idea of a mathematical theory that lets us deal with symmetries precise, we need to distill the deﬁning features of sym- metries into mathematical terms: • Leaving the object in question unchanged (\"doing nothing\") is always a symmetry and therefore, every group needs to contain an identity element. In the examples above, the identity element is the rotation by 0◦. 28 physics from symmetry • Transforming something and afterwards doing the inverse trans- formation must be equivalent to doing nothing. Therefore, there must be, for every element in the set, an inverse element. A trans- formation followed by its inverse transformation is, by deﬁnition of the inverse transformation, the same as the identity transforma- tion. In the above examples this means that the inverse transfor- mation of a rotation by 90◦ is a rotation by -90◦. A rotation by 90◦ followed by a rotation by -90◦ is the same as a rotation by 0◦. • Performing a symmetry transformation followed by a second symmetry transformation is again a symmetry transformation. A rotation by 90◦ followed by a rotation by 180◦ is a rotation by 270◦, which is a symmetry transformation, too. This property of the set of transformations is called closure. • The combination of transformations must be associative3. A rota- 3 But not commutative! For example rotations around different axes do not commute. This means in general: Rx(θ)Rz(Φ) ̸= Rz(Φ)Rx(θ) tion by 90◦ followed by a rotation by 40◦, followed by a rotation by 110◦ is the same as a rotation by 130◦ followed by a rotation by 110◦, which is the same as a rotation by 90◦ followed by a rotation by 150◦. In a symbolic form: R(110◦)R(40◦)R(90◦)= R(110◦)(R(40◦)R(90◦)) = R(110◦)R(130◦) (3.1) and R(110◦)R(40◦)R(90◦)= (R(110◦)R(40◦))R(90◦)= R(150◦)R(90◦) (3.2) This property is called associativity. • To be able to talk about the things above, one needs a rule, to be precise: a binary operation, for the combination of group ele- ments. In the above examples, the standard approach would be to use rotation matrices4 and the rule for combining the group 4 If you want to know more about the derivation of rotation matrices have a look at Appendix A.2. elements (the corresponding rotation matrices) would be ordi- nary matrix multiplication. Nevertheless, there are often different ways to describe the same thing5 and group theory enables us to 5 For example, rotations in the plane can be described alternatively by multiplication with unit complex numbers. The rule for combining group elements is then complex number multiplication. This will be discussed later in this chapter. study this systematically. The branch of group theory that deals with different descriptions of the same transformations is called representation theory6. 6 Representation theory is the topic of Section 3.5. To work with ideas like these in a rigorous, mathematical way, one distils the deﬁning features of such transformations and promotes them to axioms. All structures satisfying these axioms are then called groups. This paves the way for a whole new branch of mathematics, called group theory. It is possible to ﬁnd very abstract structures lie group theory 29 satisfying the group axioms, but we will stick with groups that are very similar to the rotations we explored above. After the discussion above, we can see that the abstract deﬁnition of a group simply states (obvious) properties of symmetry transfor- mations: A group (G, ◦) is a set G, together with a binary operation ◦ deﬁned on G, that satisﬁes the following axioms7 7 Do not worry too much about this. In practice one checks for some kind of transformation if they obey these axioms. If they do, the transformations form a group and one can use the results of group theory to learn more about the transformations in question. • Closure: For all g1, g2 ∈ G, g1 ◦ g2 ∈ G • Identity element: There exists an identity element e ∈ G such that for all g ∈ G, g ◦ e = g = e ◦ g • Inverse element: For each g ∈ G, there exists an inverse element g−1 ∈ G such that g ◦ g−1 = e = g−1 ◦ g. • Associativity: For all g1, g2, g3 ∈ G, g1 ◦ (g2 ◦ g3)=(g1 ◦ g2) ◦ g3. To summarize: The set of all transformations that leave a given object invariant is called a symmetry group. For Minkowski space- time, the object that is left invariant is the Minkowski metric8 and the 8 Recall, this is the tool which we use to compute distances and lengths in Minkowski space. corresponding symmetry group is called the Poincaré group. Take note that the characteristic properties of a group are deﬁned completely independent of the object the transformations act on. We can therefore study such symmetry transformations without making references to any object we extracted them from. This is very useful, because there can be many objects with the same symmetry or at least the same kind of symmetry. Using group theory we no longer have to inspect each object on its own, but are now able to study general properties of symmetry transformations. 3.2 Rotations in two Dimensions As a ﬁrst step, we start with an easy, but important, example. What transformations in two dimensions leave the length of any vector unchanged? After thinking about it for a while, we come up with9 9 Another kind of transformation that leaves the length of a vector unchanged are translations, which means we move every point a constant distance in a speciﬁed direction. These are described mathematically a bit different and we are going to talk about them later. rotations and reﬂections. These transformations are of course the same ones that map the unit circle into the unit circle. This is an ex- ample of how one group may act on different kinds of objects: On the circle, which is a geometric shape, and on a vector. Considering vec- tors, one can represent these transformations by rotation matrices10, 10 For an explicit derivation of these matrices have a look a look at Ap- pendix A.2. 30 physics from symmetry which are of the form Rθ = (cos(θ) − sin(θ) sin(θ) cos(θ) ) (3.3) and describe two-dimensional rotations about the origin by angle θ. Reﬂections at the axes can be performed using the matrices: Px = (−10 01 ) Py = (10 0 −1 ) .(3.4) You can check that these matrices, together with the ordinary matrix multiplication as binary operation ◦, satisfy the group axioms and therefore these transformations form a group. We can formulate the task of ﬁnding \"all transformations in two dimensions that leave the length of any vector unchanged\" in a more abstract way. The length of a vector is given by the scalar product of the vector with itself. If the length of the vector is the same after the transformation a → a′, the equation a′ · a′ ! = a · a (3.5) must hold. We denote the transformation with O and write the trans- formed vector as a → a′ = Oa. Thus a · a = aT a → a′T a′ =(Oa)TOa = aTOTOa ! = aT a = a · a,(3.6) where we can see the condition a transformation must fulﬁl to leave the length of a vector unchanged is OTO = I,(3.7) where I denotes the unit matrix11. You can check that the well-11 I = (10 01 ) known rotation and reﬂection matrices we cited above fulﬁl exactly this condition12. This condition for two dimensional matrices deﬁnes12 With the matrix from Eq. 3.3 we have RT θ R = (cos(θ) − sin(θ) sin(θ) cos(θ) )( cos(θ) sin(θ) − sin(θ) cos(θ) ) = (cos2(θ)+ sin 2(θ) 0 0 sin 2(θ)+ cos2(θ) ) = (10 01 ) ✓ the group O(2), which is the group of all13 orthogonal 2 × 2 matrices. 13 Every orthogonal 2 × 2 matrix can be written either in the form of Eq. 3.3, as in Eq. 3.4, or as a product of these matrices. We can ﬁnd a subgroup of this group that includes only rotations, by observing that it follows from the condition in Eq. 3.7 that det(OTO) ! = det(I)= 1 → det(OTO)= det(OT) det(O) ! = det(I)= 1 → (det(O))2 ! = 1 → det(O) ! = ±1. (3.8) The transformations of the group with det(O)= 1 are rotations14 and 14 As can be easily seen by looking at the matrices in Eq. 3.3 and Eq. 3.4. The matrices with det O = −1are reﬂections. the two conditions OTO = I (3.9) lie group theory 31 det O = 1(3.10) deﬁne the SO(2) group, where the \"S\" denotes special and the \"O\" orthogonal. The special thing about SO(2) is that we now restrict it to transformations that keep the system orientation, i.e., a right- handed15 coordinate system stays right-handed. In the language of 15 If you don’t know the difference between a right-handed and a left- handed coordinate system have a look at the Appendix A.5. linear algebra this means that the determinant of our matrices must be +1. 3.2.1 Rotations with Unit Complex Numbers There is a different way to describe rotations in two dimensions that makes use of complex numbers: rotations about the origin by angle θ can be described by multiplication with a unit complex number ( z = a + ib which fulﬁls the condition16 |z|2 = z⋆z = 1). 16 The ⋆ symbol denotes complex conjugation: z = a + ib → z⋆ = a − ib The unit complex numbers together with ordinary complex num- ber multiplication are a group, called17 U(1), as you can check by 17 The U stands for unitary, which means the condition U†U = 1, where the symbol \"†\", called \"dagger\", denotes transposition plus complex conjugation: U† = UT⋆. For numbers, the dagger operation † is the same as taking only the complex conjugate, because every number satisﬁes trivially zT = z. Hence the condition reduces here simply to U⋆ = U. looking at the group axioms. To establish the connection with the group deﬁnitions for O(2) and SO(2) introduced above, we write the deﬁning condition for unit numbers as18 18 For more general information about the deﬁnition of groups involving a complex product, have a look at the appendix in Section 3.10. U⋆U = 1. (3.11) Another way to write a unit complex number is19 19 This is known as Euler’s formula, which is derived in Appendix B.4.2. For a complex number z = a + ib, a is called the real part of z: Re(z)= a and b the imaginary part: Im(z)= b.In Euler’s formula cos(θ) is the real part, and sin(θ) the imaginary part of Rθ. Fig. 3.5: The unit complex numbers lie on the unit circle in the complex plane. Rθ = eiθ = cos(θ)+ i sin(θ),(3.12) because then R⋆ θ Rθ = e−iθeiθ = ( cos(θ) − i sin(θ))( cos(θ)+ i sin(θ)) = 1(3.13) Let’s have a look at an example: we rotate the complex number z = 3 + 5i,by90◦: z → z′ = ei90◦ z =(cos(90◦) ︸ ︷︷ ︸ =0 +i sin(90◦) ︸ ︷︷ ︸ =1 )(3 + 5i)= i(3 + 5i)= 3i − 5. (3.14) The two complex numbers are plotted in Fig. 3.6 and we see the multiplication with ei90◦ does indeed rotate the complex number by 90◦. In this description, the rotation operator ei90◦ acts on complex numbers instead of on vectors. To describe a rotation in two dimen- sions, one parameter is necessary: the angle of rotation θ. A complex number has two degrees of freedom and with the constraint to unit complex numbers |z| = 1, one degree of freedom is left as needed. 32 physics from symmetry We can connect this description to the previous one, where we used rotation matrices, by representing complex numbers by real 2 × 2 matrices. We deﬁne 1 = (10 01 ) , i = (0 −1 10 ) .(3.15) You can check that these matrices fulﬁl 1 2 = 1, i2 = −1, 1i = i1 = i.(3.16) Fig. 3.6: Rotation of a complex number, by multiplication with a unit complex number So now, the complex representation of rotations of the plane reads Rθ = cos(θ)+ i sin(θ)= cos(θ) (10 01 ) + sin(θ) (0 −1 10 ) = (cos(θ) − sin(θ) sin(θ) cos(θ) ) .(3.17) By making the map i → real matrix, we go back to the familiar representation of rotations of the plane. Maybe you have noticed a subtle point: The familiar rotation matrix in 2-dimensions acts on vectors, but here we identiﬁed the complex unit i with a real matrix (Eq. 3.15). Therefore, the rotation matrix will act on a 2 × 2 matrix, because the complex number we act on becomes a matrix, too. A generic complex number in this description reads z = a + ib = a (10 01 ) + b (0 −1 10 ) = (a −b ba ) .(3.18) Let us take a look at how rotations act on such a matrix that repre- sents a complex number: z′ = (a′ −b′ b′ a′ ) = Rθz = (cos(θ) − sin(θ) sin(θ) cos(θ) )(a −b ba ) = (cos(θ)a − sin(θ)b − cos(θ)b − sin(θ)a sin(θ)a + cos(θ)b − sin(θ)b + cos(θ)a ) .(3.19) By comparing the left-hand side with the right-hand side, we get → a′ = cos(θ)a − sin(θ)b → b′ = sin(θ)a + cos(θ)b ,(3.20) lie group theory 33 which is the same result that we get when we act with Rθ on a col- umn vector (cos(θ) − sin(θ) sin(θ) cos(θ) )(a b ) = (cos(θ)a − sin(θ)b sin(θ)a + cos(θ)b ) = (a′ b′ ) .(3.21) We see that both representations do exactly the same thing and math- ematically speaking we have an isomorphism20 between SO(2) and 20 An isomorphism is a one-to-one map Π that preserves the product structure Π(g1)Π(g2)= Π(g1g2) ∀g1, g2 ∈ G. U(1). This is a very important discovery and we will elaborate on such lines of thought in the following chapters. Next we want to describe rotations in three dimensions and ﬁnd similarly two descriptions for rotations in three dimensions21. 21 Things are about to get really interest- ing! Analogous to the two-dimensional case we discussed in the preceding sec- tion, we will ﬁnd a second description of rotations in three dimensions and this alternative description will reveal something fundamental about nature. 3.3 Rotations in three Dimensions The standard method to rotate vectors in three dimensions is to use 3 × 3 rotation matrices. The \"basis rotations\" around the three axes can be described by the following matrices: Rx = ⎛ ⎜ ⎝10 0 0 cos(θ) − sin(θ) 0 sin(θ) cos(θ) ⎞ ⎟ ⎠ Ry = ⎛ ⎜ ⎝ cos(θ) 0sin(θ) 01 0 − sin(θ) 0 cos(θ) ⎞ ⎟ ⎠ Rz = ⎛ ⎜ ⎝cos(θ) − sin(θ) 0 sin(θ) cos(θ) 0 00 1 ⎞ ⎟ ⎠ .(3.22) If we want to rotate the vector ⃗v = ⎛ ⎜ ⎝1 0 0 ⎞ ⎟ ⎠ around the z-axis22, we multiply it with the corresponding rotation 22 A general, rotated vector is derived explicitly in Appendix A.2.matrix Rz(θ)⃗v = ⎛ ⎜ ⎝cos(θ) − sin(θ) 0 sin(θ) cos(θ) 0 00 1 ⎞ ⎟ ⎠ ⎛ ⎜ ⎝1 0 0 ⎞ ⎟ ⎠ = ⎛ ⎜ ⎝cos(θ) sin(θ) 0 ⎞ ⎟ ⎠ .(3.23) To get a second description for rotations in three dimensions, the ﬁrst thing we have to do is ﬁnd a generalisation of complex numbers in higher dimensions. A ﬁrst guess may be to go from 2-dimensional complex numbers to 3-dimensional complex numbers, but it turns out that there are no 3-dimensional complex numbers. Instead, we can ﬁnd 4-dimensional complex numbers, called quaternions. The 34 physics from symmetry quaternions will prove to be the correct second tool to describe rota- tions in 3-dimensions and the fact that this tool is 4-dimensional re- veals something deep about the universe. We could have anticipated this result, because to describe an arbitrary rotation in 3-dimensions, 3 parameters are needed. Four dimensional complex numbers, with the constraint to unit quaternions23, have exactly 3 degrees of free- 23 Remember that we used the con- straint to unit complex numbers in the two dimensional case, too. dom. 3.3.1 Quaternions The 4-dimensional complex numbers can be constructed analogous to the 2-dimensional complex numbers. Instead of just one complex \"unit\" we introduce three, named i, j, k. These fulﬁl i 2 = j2 = k 2 = −1. (3.24) Then a 4-dimensional complex number, called a quaternion, can be written as q = a1 + bi + cj + dk.(3.25) We now need multiplication rules for ij =? etc., because products like this will occur when one multiplies two quaternions. The extra condition ijk = −1(3.26) sufﬁces to compute all needed relations, for example ij=k follows from multiplying Eq. 3.26 with k: ij kk︸︷︷︸ =−1 = −k → ij=k.(3.27) The set of unit quaternions q = a1 + bi + cj + dk satisfy the condition2424 The symbol †, here is called \"dagger\" and denotes transposition plus complex conjugation: a† =(a⋆)T. The ordinary scalar product always includes a trans- position a · b = aT b, because matrix multiplication requires that we multiply a row with a column. In addition, for complex entities we include complex conjugation that makes sure we get something real, which is important if we want to interpret things in terms of length. q†q ! = 1 → (a1 − bi − cj − dk)(a1 + bi + cj + dk)= a2 + b2 + c2 + d2 ! = 1. (3.28) Exactly as the unit complex numbers formed a group under complex number multiplication, the unit quaternions form a group under quaternion multiplication. Analogous to what we did for two-dimensional complex numbers, we now represent each of the three complex units with a matrix. There are different ways of doing this, but one choice that does the job is as complex 2 × 2 matrices: lie group theory 35 1 = (10 01 ) , i = ( 01 −10 ) j = (0 i i 0 ) , k = ( i 0 0 −i ) .(3.29) You can check that these matrices fulﬁl the deﬁning conditions in Eq. 3.24 and Eq. 3.26. Using these matrices a generic quaternion can then be written q = a1 + bi + cj + dk = ( a + di b + ci −b + ci a − di ) .(3.30) Furthermore, we have det(q)= a2 + b2 + c2 + d2.(3.31) Comparing this with Eq. 3.28 tells us that the set of unit quaternions is given by matrices of the above form with unit determinant. The unit quaternions, written as complex 2 × 2 matrices therefore fulﬁl the conditions U†U = 1 and det(U)= 1. (3.32) Take note that the way we deﬁne SU(2) here, is analogously to how we deﬁned SO(2). The S denotes special, which means det(U)= 1 and U stands for unitary, which means the property25 U†U = 1. 25 For some more information about this, have a look at the Appendix 3.10 at the end of this chapter. Through the map in Eq. 3.29, every unit quaternion can be identiﬁed with an element of SU(2). Now, how is SU(2) and with it the unit quaternions related to rotations? Unfortunately, the map between SU(2) and26 SO(3) is not 26 Recall that SO(3) is the set of the usual rotation matrices acting on 3 dimensional vectors. as simple as the one between U(1) and SO(2). In 2-dimensions the 2 parameters of a complex number z = a + ib could be easily identiﬁed with the two spatial axes, i.e. v = x + iy. The restriction to unit complex numbers automatically makes sure that the resulting matrix preserves the length of any vector27 27 Recall that here R is a unit complex number, because complex numbers can be rotated by multiplication with unit complex numbers. Therefore we have U⋆U = 1, which is the deﬁning condition for unit complex numbers. (Uz)⋆Uz = z⋆U⋆Uz = z⋆z. The quaternions have 4 parameters, so the identiﬁcation with the 3 coordinates of a three-dimensional vector is not obvious. When we deﬁne v ≡ xi + yj + zk (3.33) and use the matrix representation of the quaternions (Eq. 3.29), we can compute det(v)= x2 + y2 + z2.(3.34) 36 physics from symmetry Therefore, if we want to consider transformations that preserve the length of the vector (x, y, z), we must use matrix transformations that preserve determinants. Therefore the restriction to unit quaternions means that we must restrict to matrices with unit determinant28. 28 This follows from the general rule det(BA)= det(B)det(A). Therefore, if B has determinant 1, the product matrix BA has the same determinant as A. Everything may now seem straight forward, but there is a subtle point. A ﬁrst guess would be that a unit quaternion u induces a rotation on v simply by multiplication. This is not the case, because the product of u and v may not belong to Ri + Rj + Rk. Therefore, the transformed vector can have a component we are not able to interpret29. Instead the transformation that does the job is given by 29 We identify our spatial components x, y, z as components in the subspace Ri + Rj + Rk. If, as a result of a transformation, we end up with a coefﬁcient that does not belong to this subspace, i.e. does not appear together with i, j or k, we can’t interpret it. v′ = qvq−1.(3.35) It turns out that by making this identiﬁcation unit quaternions can describe rotations in 3-dimensions. Let’s take a look at an explicit example: To make the connection to our example in two dimensions, we deﬁne u as a unit quaternion that only takes values in Ri + Rj + Rk and denote a general unit quaternion with t = cos(θ)+ sin(θ)u.(3.36) Using Eq. 3.33 a generic vector can be written ⃗v =(vx, vy, vz)T = vxi + vyj + vzk =︸︷︷︸ Eq. 3.30 ( ivz vx + ivy −vx + ivy −ivz ) . (3.37) With the identiﬁcations made above, we want to rotate, as an ex- ample, a vector ⃗v =(1, 0, 0)T around the z-axis. We will make a particular choice for the vector and for the quaternion representing the rotation and show that it works. We write, using quaternions in their matrix representation (Eq. 3.29) ⃗v =(1, 0, 0)T → v = 1i + 0j + 0k = ( 01 −10 ) .(3.38) In addition, we use the following quaternion Rz(θ)= cos(θ)1 + sin(θ)k = (cos(θ)+ i sin(θ) 0 0 cos(θ) − i sin(θ) ) , (3.39) and then calculate that it is the correct quaternion that describes a rotation around the z-axis. We can rewrite Rz using Euler’s formula3030 For a derivation have a look at Ap- pendix B.4.2. eix = cos(x)+ i sin(x): ⇒ Rz(θ)= (eiθ 0 0e−iθ ) .(3.40) lie group theory 37 Inverting the quaternion rotation matrix yields Rz(θ)−1 = (cos(θ) − i sin(θ) 0 0 cos(θ)+ i sin(θ) ) = (e−iθ 0 0eiθ ) . (3.41) Using Eq. 3.35 the rotated vector reads v′ = Rz(θ)vR−1 z (θ)= (eiθ 0 0e−iθ )( 01 −10 )(e−iθ 0 0eiθ ) = ( 0ei2θ −e−2iθ 0 ) = ( 0 cos(2θ)+ i sin(2θ) − cos(2θ)+ i sin(2θ) 0 ) . (3.42) On the other hand, an arbitrary vector can be written in our quaternion notation (Eq. 3.37) v′ = ( iv′ z v′ x + iv′ y −v′ x + iv′ y −iv′ z ) ,(3.43) which we now compare with Eq. 3.42. This yields v′ x = cos(2θ) , v′ y = sin(2θ) , v′ z = 0. (3.44) Therefore, written again in the conventional vector notation → ⃗v′ =(cos(2θ), sin(2θ),0)T.(3.45) Our identiﬁcations do indeed induce rotations31, but something 31 See the example in Eq. 3.23 where we rotated the vector, using the conven- tional rotation matrix needs our attention. We haven’t rotated ⃗v by θ, but by 2θ. Therefore, we deﬁne φ ≡ 2θ, because then φ really represents the angle we rotate. Using this deﬁnition we rewrite Eq. 3.36, which yields t = cos( φ 2 )+ sin( φ 2 )u .(3.46) We can now see that the identiﬁcations we made are not one-to- one, but rather we have two unit-quaternions describing the same rotation. For example32 32 A rotation by π is the same as a rotation by 3π = 2π + π for ordinary vectors, because 2π = 360◦ is a full rotation. In other words: We can see that two quaternions u and −u can be used to rotate a vector by π. tφ=π = u \b\b tφ=3π = −u \t\t Vector Rotation by π This is the reason SU(2) is called the double-cover of SO(3).It is always possible to go unambiguously from SU(2) to SO(3) but not 38 physics from symmetry vice versa. One may think this is just a mathematical side-note, but we will understand later that groups which cover other groups are indeed more fundamental33. 33 To spoil the surprise: We will use the double cover of the Lorentz group, instead of the Lorentz group itself, because otherwise we miss something important: Spin. Spin is some kind of internal momentum and one of the most important particle labels. This is discussed in detail in Section 4.5.4 and Section 8.5.5. To be able to discover the group that covers a given group, we need to introduce the most important tool of Lie theory: Lie algebras. This is the topic of the next section. Take note that the fact we had one quaternion parameter too many, may be interpreted as a hint towards relativity. One may ar- gue that a more natural identiﬁcation would have been, as in the two-dimensional case, v = t1 + xi + yj + zk. We see that pure math- ematics pushes us towards the idea of using a 4th component and what could it be, if not time? If we now want to describe rotations in 4-dimensions, because we know that the universe we live in is 4-dimensional, we have two choices: • We could search for even higher dimensional complex numbers or • we could again try to work with quaternions. From the last paragraph it may seem that quaternions have some- thing to say about rotations in 4 dimensions, too. An arbitrary ro- tation in 4 dimensions is described by34 6 parameters. There is no 34 Using ordinary matrices, we need in four dimensions 4 × 4 matrices. The two conditions OTO = 1 and det(O)= 1 reduce the 16 components of an arbitrary 4 × 4 matrix to six independent components. 7-dimensional generalisation of complex numbers, which together with the constraint to unit objects would have 6 free parameters. However, two unit quaternions have exactly 6 free parameters. There- fore, maybe it’s possible to describe a rotation in 4-dimensions by two quaternions? We will learn later that there is indeed a close connec- tion between two copies of SU(2) and rotations in four dimensions. 3.4 Lie Algebras Lie theory is all about continuous symmetries. An example is the continuous symmetry of the unit circle we discussed at the beginning of this chapter. Continuous here means that there are inﬁnitely many symmetry transformations, that can be parametrized continuously by one or several parameters. For example, the rotation angle φ in the circle example can be any value: 0.1◦, 0.11◦, 0.11991◦, . . ... In contrast, for discrete symmetries like a reﬂection symmetry there is no continuous transformation parameter. An important observation in Lie theory is that for continuous sym- metries there are elements of the group which are arbitrarily close to the identity transformation35. In contrast, for a discrete group there 35 The identity transformation is the transformation that changes nothing at all. For example, a rotation by 0◦ is an identity transformation. is no continuous transformation parameter and therefore no element arbitrarily close to the identity. Consider again the symmetries of a lie group theory 39 square. A rotation by 0,000001◦, which is very close to the identity transformation (= a rotation by 0◦), is not in the set of symmetry transformations of the square. In contrast, a rotation by 0,000001◦ is a symmetry of the circle. The symmetry group of a circle is continuous, because the rotation parameter (the rotation angle) can take on arbi- trary (continuous) values. Mathematically, with the identity denoted I, an element g close to the identity is denoted g(ϵ)= I + ϵX ,(3.47) where ϵ is, as always in mathematics, a really, really small number and X is an object, called generator, we will talk about in a moment. Such small transformations, when acting on some object change barely anything. In the smallest possible case such transformations are called inﬁnitesimal transformation. Nevertheless, repeating such an inﬁnitesimal transformation often, results in a ﬁnite transforma- tion. Think about rotations: many small rotations in one direction are equivalent to one big rotation in the same direction. Mathematically, we can write the idea of repeating a small transformation many times h(θ)=(I + ϵX)(I + ϵX)(I + ϵX)... =(I + ϵX)k,(3.48) where k denotes how often we repeat the small transformation. If θ denotes some ﬁnite transformation parameter, e.g. 50◦ or so, and N is some really big number which makes sure we are close to the identity, we can write the element close to the identity as g(θ)= I + θ N X.(3.49) The transformations we want to consider are the smallest possible, which means N must be the biggest possible number, i.e. N → ∞.To get a ﬁnite transformation from such a inﬁnitesimal transformation, one has to repeat the inﬁnitesimal transformation inﬁnitely. Mathe- matically h(θ)= lim N→∞(I + θ N X)N,(3.50) which is in the limit just the exponential function36 36 This is often used as a deﬁnition of the exponential function. A proof, showing the equivalence of this limit and the exponential series we derive in Appendix B.4.1, can be found in most books about analysis. h(θ)= lim N→∞(I + θ N X)N = eθX .(3.51) In some sense the object X generates the ﬁnite transformation h, which is why it’s called the generator. If we want to calculate the generator X of a given transformation, we can differentiate the above formula 40 physics from symmetry d dθ h(θ)= d dθ eθX = XeθX .(3.52) Thus, if we evaluate this formula at θ = 0, we get X = dh(θ) dθ ∣ ∣ ∣θ=0.(3.53) The idea behind such lines of thought is that one can learn a lot about a group by looking at the important part of the inﬁnitesimal elements (denoted X above): the generators. This will be made more precise in a moment, but ﬁrst let’s look at this from another perspec- tive that makes it even clearer in what sense the generators generate a ﬁnite transformation: If we consider a continuous group of transformations that are given by matrices, we can make a Taylor expansion37 of an element 37 If you’ve never heard of the Taylor expansion, or Taylor series before, you are encouraged to have a look at Appendix B.3. of the group about the identity. The Taylor series is given by h(θ)= I + dh dθ .|θ=0θ + 1 2 d2h dθ2 .|θ=0θ2 + ... = ∑ n 1 n! dnh dθn ∣ ∣θ=0θn.(3.54) This shows nicely how the generators generate transformations. For matrix Lie groups one deﬁnes the corresponding Lie algebra as the collection of objects that give an element of the group when exponentiated. This is an easy deﬁnition one can use when restrict- ing to matrix Lie groups. Later we will introduce a more general deﬁnition. In mathematical terms3838 The Lie algebra which belongs to a group G is conventionally denoted by the corresponding \"Fraktur\" letter g For a Lie Group G (given by n × n matrices), the Lie algebra g of G is given by those n × n matrices X such that etX ∈ G for t ∈ R, together with an operation, called the Lie bracket [, ] that tells us how we can combine these matrices. The last part of this deﬁnition can be a bit confusing and thus we now spent some time discussing it. We know from the deﬁnition of a group, that a group is more than just a collection of transformations. The deﬁnition of a group includes a binary operation ◦ that tells us how to combine group elements. For matrix Lie groups this is just ordinary matrix multi- plication. Naively one may think that the same combination rule ◦ is valid for elements of the Lie algebra, but this is not the case! The elements of the Lie algebra are given by matrices39, but the multipli- 39 A famous theorem of Lie group theory, called Ado’s Theorem, states that every Lie algebra is isomorphic to a matrix Lie algebra. cation of two Lie algebra elements doesn’t need to be an element of the Lie algebra. Instead there is another combination rule for the Lie lie group theory 41 algebra, already mentioned in the deﬁnition above, that is directly connected to the combination rule of the corresponding Lie group. The connection between the combination rule of the Lie group and the combination rule of the Lie algebra is given by the famous Baker-Campbell-Hausdorff formula40 40 We will not talk about the proof of this formula in this book. Proofs can be found in most books about Lie theory, for example in William Fulton and Joe Harris. Representation Theory: A First Course. Springer, 1st corrected edition, 8 1999. ISBN 9780387974958 eX ◦ e Y = eX+Y+ 1 2 [X,Y]+ 1 12 [X,[X,Y]]− 1 12 [Y,[X,Y]]+... (3.55) On the left hand side, we have the multiplication of two elements of the Lie group, let’s name them g and h, which we can write in terms of the corresponding generators (=elements of the Lie algebra) g ︸︷︷︸ ∈G ◦ h︸︷︷︸ ∈G = eX ◦ e Y = eX+Y+ 1 2 [X,Y]+ 1 12 [X,[X,Y]]− 1 12 [Y,[X,Y]]+... ︸ ︷︷ ︸ ∈G (3.56) with the generators41 X, Y ∈ g. On the right-hand side we have a sin- 41 The Lie algebra which belongs to a group G is conventionally denoted by the corresponding \"Fraktur\" letter g. gle object of the group and the multiplication of the group elements have been translated to a sum of Lie algebra elements. The new sym- bol in this sum [ , ] is called Lie bracket and for matrix Lie groups it is given by [X, Y]= XY − YX, which is called the commutator of X and Y. The elements XY and YX need not to be part of the Lie algebra, but their difference always is42! 42 A very illuminating proof of this fact can be found in John Stillwell. Naive Lie Theory. Springer, 1st edition, August 2008. ISBN 978-0387782140 We learn from the Baker-Campbell-Hausdorff-Formula that the natural product of the Lie algebra is, not as one would naively think, ordinary matrix multiplication, but the Lie bracket [, ]. One says, the Lie algebra is closed under the Lie bracket, just as the group is closed under the corresponding composition rule ◦, e.g. matrix multiplication. Closure means that the composition of two elements lies again in the same set43. 43 For group elements g, h ∈ G we have g ◦ h ∈ G. For elements of the Lie algebra X, Y ∈ g we have [X, Y] ∈ g and in general X ◦ Y ̸∈ g After looking at an example to illustrate these new notions, we will have a look at the modern deﬁnition of a Lie algebra. The main component of this deﬁnition is how the generators of a group behave when put into the Lie bracket. By using this general deﬁnition we will see that it is possible to say that different groups have the same Lie algebra. With the deﬁnition above saying something like this would make little sense. Nevertheless, this new way of thinking about Lie algebras will enable us to reveal the most fundamental description corresponding to a given transformation. This is possible because there is a theorem in Lie theory that tells us that there is exactly one distinguished Lie group for each Lie algebra. The Lie algebra however, according to the abstract deﬁnition, corresponds to many Lie groups. We will make this more concrete after introducing the modern deﬁnition of a Lie group. 42 physics from symmetry Now we want to take a look at an explicit example of how we can derive the Lie algebra of a given group. 3.4.1 The Generators and Lie Algebra of SO(3) The deﬁning conditions of the group SO(3) are (Eq. 3.10) OTO ! = I and det(O) ! = 1. (3.57) We can write every group element O in terms of a generator J: O = eθ J.(3.58) Putting this into the ﬁrst deﬁning condition yields OTO = eθ JT eθ J ! = 1 → JT + J ! = 0. (3.59) Using the second condition in Eq. 3.57 and the identity44 det(eA)= etr(A)44 tr(A) denotes the trace of the ma- trix A, which means the sum of all elements on the main diagonal. For example for A = (A11 A12 A21 A22 ),wehave tr(A)= A11 + A22. for the matrix exponential, we see (O) ! = 1 → det(eθ J)= eθtr(J) ! = 1 → tr(J) ! = 0. (3.60) Three linearly independent45 matrices fulﬁlling both conditions 45 This is explained in Appendix A.1. (Eq. 3.59, Eq. 3.60)are J1 = ⎛ ⎜ ⎝00 0 00 −1 01 0 ⎞ ⎟ ⎠ J2 = ⎛ ⎜ ⎝ 00 1 00 0 −100 ⎞ ⎟ ⎠ J3 = ⎛ ⎜ ⎝0 −10 100 000 ⎞ ⎟ ⎠ . (3.61) These matrices form a basis for the generators of the group SO(3). This means any generator of the group can be written as a linear combination of these basis generators: J = aJ1 + bJ2 + cJ3, where a, b, c denote real constants. These generators can be written more compactly by using the Levi-Civita symbol4646 The Levi-Civita symbol is explained in Appendix B.5.5. (Ji)jk = −ϵijk,(3.62) where j, k denote the components of the generator Ji. For example, (J1)jk = −ϵ1jk ↔ ⎛ ⎜ ⎝(J1)11 (J1)12 (J1)13 (J1)21 (J1)22 (J1)23 (J1)31 (J1)32 (J1)33 ⎞ ⎟ ⎠ = − ⎛ ⎜ ⎝ϵ111 ϵ112 ϵ113 ϵ121 ϵ122 ϵ123 ϵ131 ϵ132 ϵ133 ⎞ ⎟ ⎠ = ⎛ ⎜ ⎝00 0 00 −1 01 0 ⎞ ⎟ ⎠ .(3.63) lie group theory 43 Let’s see what ﬁnite transformation matrix we get from the ﬁrst of these basis generators. The connection between the generators and the ﬁnite transformations is given by the exponential function: R1ﬁn = eθ J1. To calculate this, we can focus on the lower right 2 × 2 matrix47 j1 in J1 and ignore the zeroes for a moment: 47 This is exactly minus the two- dimensional Levi-Civita symbol (j1)ij = −ϵij in matrix form (see Appendix B.5.5), which is the genera- tor of rotations in two dimensions (of SO(2)). J1 = ⎛ ⎜ ⎜ ⎜ ⎜ ⎝ 0 (0 −1 10 ) ︸ ︷︷ ︸ ≡j1 ⎞ ⎟ ⎟ ⎟ ⎟ ⎠ .(3.64) We can immediately compute (j1)2 = −1, (3.65) therefore (j1)3 =(j1)2 ︸︷︷︸ =−1 j1 = −j1 , (j1)4 =+1, (j1)5 =+j1 .(3.66) In general, we have (j1)2n =(−1)n I and (j1)2n+1 =(−1)n j1 ,(3.67) which we can use if we evaluate the exponential function as series expansion48 48 This is derived in Appendix B.4.1. The trick used here is explained in more detail in Appendix B.4.2 and the series expansions of sine and cosine are derived in Appendix B.4.1, too.˜R1ﬁn = eθj1 = ∞ ∑ n=0 θn jn 1 n! = ∞ ∑ n=0 θ2n (2n)! (j1)2n ︸ ︷︷ ︸ (−1)n I + ∞ ∑ n=0 θ2n+1 (2n + 1)! (j1)2n+1 ︸ ︷︷ ︸ (−1)n j1 = ( ∞ ∑ n=0 θ2n (2n)! (−1)n) ︸ ︷︷ ︸ =cos(θ) I + ( ∞ ∑ n=0 θ2n+1 (2n + 1)! (−1)n) ︸ ︷︷ ︸ =sin(θ) j1 = cos(θ) (10 01 ) + sin(θ) (0 −1 10 ) = (cos(θ) − sin(θ) sin(θ) cos(θ) ) . (3.68) Using e0 = 1 for the upper-left component, the complete, ﬁnite transformation matrix therefore reads R1 = ⎛ ⎜ ⎝10 0 0 cos(θ) − sin(θ) 0 sin(θ) cos(θ) ⎞ ⎟ ⎠ ,(3.69) which we can recognize as one of the well-known rotation matrices in 3-dimensions that were quoted at the beginning of this chapter 44 physics from symmetry (Eq. 3.22). Following the same steps, we can derive the matrices for rotations around the other axes, too. We now have the generators of the group in explicit matrix form (Eq. 3.61) and this allows us to compute the Lie bracket relations between the basis generators by brute force49. The result is5049 As explained above, the natural product of the Lie algebra is the Lie bracket. Here we compute how the basis generators behave, when put into the Lie bracket. All other generators can be constructed by linear combination of these basis generators. Therefore, if we know the result of the Lie bracket of the basis generators, we know automatically the result for all other generators. This behavior of the basis generators in the Lie bracket, will become incredibly important in the next section. Everything that is important about a Lie algebra, is encoded in the Lie bracket relation of the basis generators. 50 For example, we have [J1, J2]= J1 J2 − J2 J1 = ⎛ ⎝00 0 00 −1 01 0 ⎞ ⎠ ⎛ ⎝ 00 1 00 0 −100 ⎞ ⎠ − ⎛ ⎝ 00 1 00 0 −100 ⎞ ⎠ ⎛ ⎝00 0 00 −1 01 0 ⎞ ⎠ = ⎛ ⎝000 100 000 ⎞ ⎠ − ⎛ ⎝010 000 000 ⎞ ⎠ = ⎛ ⎝0 −10 100 000 ⎞ ⎠ = ϵ12k︸︷︷︸ =0 except for k=3 Jk = ϵ123 J3 = J3 [Ji, Jj]= ϵijk Jk,(3.70) where ϵijk is again the Levi-Civita symbol. In physics it’s conven- tional to deﬁne the generators of SO(3) with an extra \"i\". Concretely this means that instead of e ˜φJ, we write eiφJ with φ = − ˜φ. Our gener- ators are then J1 = ⎛ ⎜ ⎝00 0 00 −i 0 i 0 ⎞ ⎟ ⎠ J2 = ⎛ ⎜ ⎝ 00 i 00 0 −i 00 ⎞ ⎟ ⎠ J3 = ⎛ ⎜ ⎝0 −i 0 i 00 000 ⎞ ⎟ ⎠ (3.71) and the Lie algebra51 reads 51 We will call the Lie bracket relation of the basis generators the Lie algebra, be- cause everything important is encoded here. [Ji, Jj]= iϵijk Jk.(3.72) We introduce the additional \"i\" in physics to get Hermitian gen- erators, which means generators that satisfy52 J† =(J⋆)T = J. This 52 For example now we have J⋆ 1 = ⎛ ⎝000 00 i 0 −i 0 ⎞ ⎠ and therefore J† 1 =(J⋆ 1 )T = ⎛ ⎝00 0 00 −i 0 i 0 ⎞ ⎠ = J1 is a nice property, because Hermitian matrices have real eigenval- ues and this becomes important in quantum mechanics where the eigenvalues of the generators are the values we expect to measure in experiments53. Without the \"i\", the generators are anti-Hermitian 53 This will be discussed in Section 8.3. J† =(J⋆)T = −J and the corresponding eigenvalues are imagi- nary. This would make it less intuitive to interpret the eigenvalues as something that we can observe in experiments. We can derive the basis generators in another way, by starting with the well known rotation matrices and use Eq. 3.53: X = dh dθ |θ=0. For the ﬁrst rotation matrix, as quoted in Eq. 3.22 and derived in Eq. 3.69, this yields J1 = dR1 dθ |θ=0 = d dθ ⎛ ⎜ ⎝10 0 0 cos(θ) − sin(θ) 0 sin(θ) cos(θ) ⎞ ⎟ ⎠ ∣ ∣ ∣θ=0 = ⎛ ⎜ ⎝00 0 0 − sin(θ) − cos(θ) 0 cos(θ) − sin(θ) ⎞ ⎟ ⎠ ∣ ∣ ∣θ=0 = ⎛ ⎜ ⎝00 0 00 −1 01 0 ⎞ ⎟ ⎠ ,(3.73) which is exactly the ﬁrst generator in Eq. 3.61. Nevertheless, the ﬁrst method is more general, because we will not always start with lie group theory 45 given ﬁnite transformation matrices. For the Lorentz group we will start with the deﬁnition of the group, derive the basis generators and only afterwards compute an explicit matrix form of the Lorentz transformations. If you already have explicit transformation matrices, you can always use Eq. 3.53 to derive the corresponding generators. Before we discuss the Lorentz group in more detail, we take a small detour and have a look at the modern deﬁnition of a Lie alge- bra. This modern deﬁnition is essential to get a deep understanding of the symmetries of nature. 3.4.2 The Abstract Deﬁnition of a Lie Algebra Up to this point we used a simpliﬁed deﬁnition: The Lie algebra con- sists of all elements X that result in an element of the corresponding group G, when put into the exponential function eX ∈ G, and an op- eration, called Lie bracket [, ], that we use to combine the Lie algebra elements. We already discussed that the last part of this deﬁnition is cru- cial. As for the group, we also need a rule to combine Lie algebra elements. By looking at the Baker-Campbell-Hausdorff-Formula, we learned how the rule for the combination of group elements, is connected to the rule for the combination of Lie algebra elements. An important observation was that the rule for the combination of Lie algebra elements is not simply matrix multiplication, but a more complicated rule called Lie bracket. While this operation already appears in our simpliﬁed deﬁnition, we now introduce a more abstract deﬁnition where the Lie bracket is even more central54 54 This deﬁnition will prove to be invaluable for the following sections and it will become clear in a moment in what sense the Lie bracket is \"more central\". A Lie algebra is a vector space g equipped with a binary operation [, ]: g × g → g. The binary operation satisﬁes the following axioms: • Bilinearity: [aX + bY, Z]= a[X, Z]+ b[Y, Z] and [Z, aX + bY]= a[Z, X]+ b[Z, Y] , for arbitrary number a, b and ∀X, Y, Z ∈ g • Anticommutativity: [X, Y]= −[Y, X] ∀ X, Y ∈ g • The Jacobi Identity: [X, [Y, Z]]+[Z, [X, Y]]+[Y, [Z, X]] = 0 ∀X, Y, Z ∈ g You can check that the commutator of two matrices fulﬁlls all these conditions and of course this standard commutator was used to motivate these axioms. Nevertheless, there are quite different binary operations that fulﬁll these axioms, for example, the famous Poisson bracket of classical mechanics. 46 physics from symmetry The important point is that this deﬁnition makes no reference to any Lie group. The deﬁnition of a Lie algebra stands on its own and we will see that this makes a lot of sense. In the next section we will have a look at the generators of SU(2) and ﬁnd that the basis gener- ators, which is the set of generators we can use to construct all other generators by linear combinations, fulﬁll the same Lie bracket rela- tion as the basis generators of SO(3) (Eq. 3.72). This is interpreted as SU(2) and SO(3) having the same Lie algebra. This is an incredibly important result and it will tell us a lot about SU(2) and SO(3). 3.4.3 The Generators and Lie Algebra of SU(2) We stumbled upon SU(2) while trying to describe rotations in three dimensions and discovered that SU(2) is the double cover5555 Recall that this means that the map from SU(2) to SO(3) identiﬁes two elements of SU(2) with the same element of SO(3). of SO(3). Remember that SU(2) is the group of unitary 2 × 2 matrices with unit determinant56 :56 This is what the \"S\" stands for: Special = unit determinant. U†U = UU† = 1(3.74) det(U)= 1. (3.75) The ﬁrst thing we now want to take a look at is the Lie algebra of this group. Writing the deﬁning conditions of the group in terms of the generators J1, J2, . . . yields5757 As discussed above, we now work with an extra \"i\" in the exponent, in order to get Hermitian matrices, which guarantees that we get real numbers as predictions for experiments in quantum mechanics. U†U =(eiJi )†eiJi ! = 1(3.76) det(U)= det(eiJi ) ! = 1(3.77) The ﬁrst condition tells us, using the Baker-Campbell-Hausdorff theorem (Eq. 3.55) and [Ji, Ji]= 0 (eiJi )†eiJi = e−iJ† i eiJi ! = 1 → e−iJ† i +iJi+ 1 2 [J† i ,Ji]+... ! = 1 →︸︷︷︸ e0=1 J† i ! = Ji.(3.78) A matrix fulﬁlling the condition J† i = Ji is called Hermitian and we therefore learn here that the generators of SU(2) must be Hermitian. Using the identity det(eA)= etr(A), we see that the second condition yields det(eiJi )= eitr(Ji) = 1 →︸︷︷︸ e0=1 tr(Ji) ! = 0. (3.79) lie group theory 47 We conclude that the generators of SU(2) must be Hermitian traceless matrices. A basis for Hermitian traceless 2 × 2 matrices is given by the following 3 matrices58: 58 A complex 2 × 2 matrix has 4 complex entries and therefore 8 degrees of freedom. Because of the two conditions the degrees of freedom are reduced to 3.σ1 = (01 10 ) , σ2 = (0 −i i 0 ) , σ3 = (10 0 −1 ) .(3.80) This means every Hermitian traceless 2 × 2 matrix can be written as a linear combination of these matrices that are called Pauli matrices. We can put these explicit matrices for the basis generators into the Lie bracket and this yields [σi, σj]= 2iϵijkσk,(3.81) where ϵijk is again the Levi-Civita symbol. To get rid of the nasty 2 it is conventional to deﬁne the generators of SU(2) as Ji ≡ 1 2 σi. The Lie algebra then reads [Ji, Jj]= iϵijk Jk .(3.82) Take note that this is exactly the same Lie bracket relation we de- rived for SO(3) (Eq. 3.72)! Therefore one says that SU(2) and SO(3) have the same Lie algebra, because we deﬁne Lie algebras by their Lie bracket. We will use the abstract deﬁnition of this Lie algebra, to get different descriptions for the transformations described by SU(2). We will learn that an SU(2) transformation doesn’t need to be described by 2 × 2 matrices. To make sense of things like this, we need a more abstract deﬁnition of a Lie group. At this point SU(2) is deﬁned as a set of 2 × 2 matrices, and a description of SU(2) by, for example, 3 × 3 matrices, makes little sense. The abstract deﬁnition of a Lie group will enable us to see the connection between different de- scriptions of the same transformation. We will identify with each Lie group a geometrical object (a manifold) and use this abstract object to deﬁne a group. This may seem like a strange thought, but will make a lot of sense after taking a second look at two examples we already encountered in earlier sections. 3.4.4 The Abstract Deﬁnition of a Lie Group One of the ﬁrst Lie groups we discussed was U(1), the unit complex numbers. These are deﬁned as complex numbers that satisfy z⋆z = 1. If we write z = a + ib this condition reads z⋆z =(a + ib)⋆(a + ib)=(a − ib)(a + ib)= a2 + b2 = 1. (3.83) This is exactly the deﬁning condition of the unit circle59. The set 59 The unit circle S1 is the set of all points in two dimensions with distance 1 from the origin. In mathematical terms this means all points (x1, x2) fulﬁlling x2 1 + x2 2 = 1. 48 physics from symmetry of unit-complex numbers is the unit circle in the complex plane. Furthermore, we found that there is a one-to-one map60 between 60 To be precise: an isomorphism. To say two things are isomorphic is the mathematical way of saying that they are \"the same thing\". Two things are called isomorphic if there exists an isomorphism between them. elements of U(1) and SO(2). Therefore, for these groups it is easy to identify them with a geometric object: the unit circle. Instead of talking about different descriptions for SO(2) or U(1), which are deﬁned by objects of given dimension, it can help to think about this group as the unit-circle. Rotations in two-dimensions are, as a Lie group, the unit-circle and we can represent these transformations by elements of SO(2), i.e. 2 × 2 matrices or elements of U(1), i.e. unit-complex numbers. The next groups we discussed were SO(3) and SU(2). Remem- ber that we found a one-to-one map between SU(2) and the unit quaternions. The unit quaternions are deﬁned as those quaternions q = a1 + bi + cj + dk that satisfy the condition (Eq. 3.28) a2 + b2 + c2 + d2 ! = 1, (3.84) which is the same condition that deﬁnes61 the three sphere S3! There- 61 Recall that the unit circle S1 is deﬁned as the set of points that satisfy the condition x2 1 + x2 2 = 1. Equally, the two- sphere S2 is deﬁned by the condition x2 1 + x2 2 + x2 3 = 1 and analogously the three sphere S3 by x2 1 + x2 2 + x2 3 + x2 4 = 1. The number that follows the S denotes the dimension. In two dimensions, with one condition we get a one- dimensional object: S1. Equally we get in four dimensions, with one condition x2 1 + x2 2 + x2 3 + x2 4 = 1 a three dimensional object S3. S3 is the surface of the four-dimensional ball. fore the quaternions provide us with a map between SU(2) and the three sphere S3. This map is an isomorphism (1-1 and onto) and therefore we can really think of SU(2) as the three sphere S3. These observations motivate the modern deﬁnition of a Lie group62: 62 The technical details that follow aren’t important for what we want to do in this book. Especially, don’t worry if the exact meaning of notions like \"induces\" or \"differentiable\" is not clear. The important message to take away is: Lie group = manifold. A Lie group is a group, which is also a differentiable manifold63. Further- 63 A manifold is a set of points, for ex- ample a sphere that looks locally like ﬂat Euclidean space Rn. Another way of thinking about a n-dimensional mani- fold is that it’s a set which can be given n independent coordinates in some neighborhood of any point. For some more information about manifolds, see the appendix in Section 3.11 at the end of this chapter. more, the group operation ◦ must induce a differentiable map of the manifold into itself. This is a compatibility requirement that ensures that the group property is compatible with the manifold property. Concretely this means that every group element, say A induces a map that takes any element of the group B to another element of the group C = AB and this map must be differentiable. Using coordinates this means that the coordinates of AB must be differentiable functions of the coordinates of B. We can now understand the remark at the end of Section 3.4: \"... there is precisely one distinguished Lie group for each Lie alge- bra.\" a bit better64. From the geometric perspective, the distinguished 64 Recall that we already discovered that different groups can have the same Lie algebra. For example, using the abstract deﬁnition of a Lie algebra, we say that SO(3) and SU(2) have the same Lie algebra (Eq. 3.82). group has the property of being simply connected. This means that, if we use the modern deﬁnition of a Lie group as a manifold, any closed curve on this manifold can be shrunk smoothly to a point65. 65 We will not discuss this any further, but you are encouraged to read about it, for example in the books recom- mended at the end of this chapter. For the purpose of this book it suf- ﬁces to know that there is always one distinguished group. To emphasize this important point:66 66 A proof can be found, for example, in Michael Spivak. A Comprehensive Introduction to Differential Geometry, Vol. 1, 3rd Edition. Publish or Perish, 3rd edition, 1 1999. ISBN 9780914098706 There is precisely one simply-connected Lie group corresponding to each Lie algebra. lie group theory 49 This simply-connected group can be thought of as the \"mother\" of all those groups having the same Lie algebra, because there are maps to all other groups with the same Lie algebra from the simply connected group, but not vice versa. We could call it the mother group of this particular Lie algebra, but mathematicians tend to be less dramatic and call it the covering group. All other groups having the same Lie algebra are said to be covered by the simply connected one. We already stumbled upon an example of this: SU(2) is the double cover of SO(3). This means there is a two-to-one map from SU(2) to SO(3). Furthermore, SU(2) is the three sphere, which is a simply con- nected manifold. Therefore, we have already found the \"most impor- tant\" group belonging to the Lie algebra in Eq. 3.82. We can get all other groups belonging to this Lie algebra through maps from SU(2). We can now understand what manifold SO(3) is. The map from SU(2) to SO(3) identiﬁes with two points of SU(2), one point of SO(3). Therefore, we can think of SO(3) as the top half67 of S3. 67 This picture is a bit oversimpliﬁed. Strictly speaking SO(3) as a manifold is still a sphere, but with antipodal points identiﬁed. Fig. 3.7: Two-dimensional slice of the three Sphere S3 (which is a three dimensional surface and therefore not drawable itself). We can see that the top half of the sphere is SO(3), because to get from SU(2) to SO(3) we identify two points, for example, p and p + 2π, with each other. We can see, from the point of view that Lie groups are manifolds that SU(2) is a more complete object than SO(3). SO(3) is just \"part\" of the complete object. In this book we take the view that to describe nature at the most fundamental level, we need to use the most fundamental groups. For rotations in three dimensions this group is SU(2) and not SO(3). We will discover something similar when considering the symmetry group of special relativity. We will see that Nature agrees with such lines of thought! To describe elementary particles one uses the representations of the covering group of the Poincaré group, instead of just the usual repre- sentation one uses to transform four-vectors. To describe nature at the most fundamental level, we must use the covering group, instead of any of the other groups that one can map to from the covering group. We are able to derive the representations68 of the most fundamen- 68 This notion will be made precise in the next section.tal group, belonging to a given Lie algebra, by deriving representa- tions of the Lie algebra. We can then put the matrices representing the Lie algebra elements (the generators) into the exponential func- tion to get matrices representing group elements. Herein lies the strength of Lie theory. By using pure mathemat- ics we are able to reveal something fundamental about nature. The standard symmetry group of special relativity hides something from 50 physics from symmetry us, because it is not the most fundamental group belonging to this symmetry69. The covering group of the Poincaré group is the funda- 69 For those who already know some quantum mechanics: the standard symmetry group hides spin from us! mental group and therefore we will use it to describe nature70. 70 In the following, we will use one representation of the Poincaré group to derive the corresponding Lie algebra. Then we will use this Lie algebra to derive the representations of the one distinguished group that belongs to this Lie algebra, which doubly covers the Poincaré group. To summarize71 71 Maybe you wonder why S2, the sur- face of the sphere in three dimensions, is missing. S2 is not a Lie group and this is closely related to the fact that there are no three-dimensional complex numbers. Recall that we had to move from two-dimensional complex num- bers with just i to the four-dimensional quaternions with i,j,k. • S1 ˆ=U(1) ↔︸︷︷︸ one-to-one SO(2) • S3 ˆ=SU(2) →︸︷︷︸ two-to-one SO(3) ˆ= \"half\" of S3 ⇒ SU(2) is the distinguished group belonging to the Lie algebra [Ji, Jj]= iϵijk Jk (Eq. 3.82), because S3 is simply connected. Next, we will introduce another important branch of Lie theory, called representation theory. It is representation theory that enables us to derive from a given Lie group the tools that we need to describe nature at the most fundamental level. 3.5 Representation Theory The important thing about group theory is that it is able to describe transformations without referring to any objects in the real world. For theoretical considerations it is often useful to regard any group as an abstract group. This means deﬁning the group by its manifold structure and the group operation. For example SU(2) is the three sphere S3, the elements of the group are points of the manifold and the rule associating a product point ab with any two points b and a satisﬁes the usual group axioms. In physical applications one is more interested in what the group actually does, i.e. the group action. An important idea is that one group can act on many different kinds of objects72. This idea motivates the deﬁnition of a representa- 72 This will make much more sense in a moment. tion: A representation is a map73 between any group element g of a 73 The mathematical term for a map with these special properties is ho- momorphism. The deﬁnition of an isomorphism is then a homomorphism, which is in addition one-to-one. group G and a linear transformation74 R(g) of some vector-space V 74 In the context of this book this will always mean that we map each group element to a matrix. Each group ele- ment is then given by a matrix that acts by usual matrix multiplication on the elements of some vector space. g →︸︷︷︸ R R(g) (3.85) in such a way that the group properties are preserved: • R(e)= I (The identity element of the group transforms nothing at all) • R(g−1)= (R(g))−1 (Every inverse element is mapped to the corresponding inverse transformation) lie group theory 51 • R(g) ◦ R(h)= R(gh) (The combination of transformations corre- sponding to g and h is the same as the transformation correspond- ing to the point gh) A representation75 identiﬁes with each point (abstract group el- 75 This concept can be formulated more generally if one accepts arbitrary (not necessarily linear) transformations of an arbitrary (not necessarily a vector) space. Such a map is called a realiza- tion. In physics one is concerned most of the time with linear transformations of objects living in some vector space (for example Hilbert space in quantum mechanics or Minkowski space for special relativity), therefore the concept of a representation is more relevant to physics than the general concept called realization. ement) of the group manifold (the abstract group) a linear transfor- mation of a vector space. Although we deﬁne a representation as a map, most of the time we will call a set of matrices a representation. For example, the usual rotation matrices are a representation of the group SO(3) on the vector space76 R3. The rotation matrices are lin- 76 R3 denotes three dimensional Eu- clidean space, where elements are ordinary 3 component vectors, as we use them for example in Appendix A.1. ear transformations on R3. However, the important thing here is that we can examine the group action on other vector spaces, too! Using representation theory, we are able to investigate systemati- cally how a given group acts on very different vector spaces and that is where things start to get really interesting. One of the most important examples in physics is SU(2). For ex- ample, we can examine how SU(2) acts on the complex vector space of dimension one C1, which is especially easy, as we will see later. We can also investigate how SU(2) acts on C2. The objects living in C2 are complex vectors of dimension two and therefore SU(2) acts on them as 2 × 2 matrices. The matrices (=linear transformations) act- ing on C2 are just the \"usual\" SU(2) matrices that we already know. In addition, we can examine how SU(2) acts on C3 or even higher dimensional vector spaces. There is a well deﬁned framework for constructing such representations and as a result, SU(2) acts, for ex- ample, on complex vectors of dimension three as 3 × 3 matrices. A basis for the SU(2) generators when they act on C3 is given by77 77 We will learn later in this chapter how to derive these. At this point just take notice that it is possible. J1 = 1 √2 ⎛ ⎜ ⎝010 101 010 ⎞ ⎟ ⎠ , J2 = 1 √2 ⎛ ⎜ ⎝0 −i 0 i 0 −i 0 i 0 ⎞ ⎟ ⎠ , J3 = ⎛ ⎜ ⎝10 0 00 0 00 −1 ⎞ ⎟ ⎠ . (3.86) As usual, we can compute matrices that represent elements of the group SU(2) by putting linear combinations of these generators into the exponential function. One can go on and inspect how SU(2) acts on higher dimensional vectors. This can be quite confusing and it would be better to call78 78 In an early draft version of this book the group was consequently called S3. Unfortunately, such a non-standard name makes it hard for beginners to dive deeper into the subject using the standard textbooks. this group S3 instead of SU(2), because usually SU(2) is deﬁned as the set of complex 2 × 2 (!) matrices satisfying (Eq. 3.32) U†U = 1 and det(U)= 1(3.87) and now we write SU(2) transformations as 3 × 3 matrices. Therefore 52 physics from symmetry one must always keep in mind that we mean the abstract group, in- stead of the 2 × 2 deﬁnition, when we talk about higher dimensional representation of SU(2) or any other group. Typically a group is deﬁned in the ﬁrst place with the help of an explicit representation. For example, we began our discussion of SU(2) with explicit 2 × 2 matrices. This approach enables us to study the group properties concretely, as we did in the preceding sections. After this initial study it’s often more helpful to regard the group as an abstract group79, because it’s possible to ﬁnd other, useful 79 For SU(2) this means using S3. representations of the group. Before we move on to examples we need to deﬁne some abstract, but useful, notions. These notions will clarify the hierarchy of rep- resentations, because not every possible representation is equally fundamental. The ﬁrst notion we want to talk about is called similarity trans- formation. Given a matrix R and an invertible80 matrix S then a 80 A matrix S is called invertible, if there exists a matrix T, such that ST = TS = 1. The inverse matrix is usually denoted S−1. transformation of the form R → R′ = S−1RS (3.88) is called a similarity transformation. The usefulness of this kind of transformation in this context lies in the fact that if we have a rep- resentation R(G) of a group G, then S−1RS is also a representation. This follows directly from the deﬁnition of a representation: Suppose we have two group elements g1, g2 and a map R: G ⇒ GL(V), i.e. R(g1) and R(g2). This is a representation if R(g1)R(g2)= R(g1g2) (3.89) If we now look at the similarity transformation of the representa- tion S−1R(g1) SS−1 ︸ ︷︷ ︸ =1 R(g2)S = S−1R(g1)R(g2)S = S−1R(g1g2)S ,(3.90) we see that this is a representation, too. Speaking colloquially, this means that if we have a representation, we can transform its elements wildly with literally any non-singular matrix S to get nicer matri- ces81. 81 The freedom to perform similarity transformations correspond to our freedom to choose a basis for the vector space our group acts on. The next notion we want to introduce is called invariant subspace. When we have a representation R of a group G on a vector space V, we call V′ ⊆ V an invariant subspace if for82 v ∈ V′ we have82 Of course v ∈ V, too. The vector space V′ must be part of the vector space V, which is mathematically denoted by V′ ⊆ V. In other words this means that every element of V′ is at the same time an element of V. R(g)v ∈ V′ for all g ∈ G. This means, if we have a vector in the subspace V′ and we act on it with arbitrary group elements, the lie group theory 53 transformed vector will always be again part of the subspace V′.If we ﬁnd such an invariant subspace we can deﬁne a representation R′ of G on V′, called a subrepresentation of R,by R′(g)v = R(g)v (3.91) for all v ∈ V′. Therefore, one is led to the thought that the represen- tation R, we talked about in the ﬁrst place, is not fundamental, but a composite of smaller building blocks, called subrepresentations. This leads us to the very important notion irreducible represen- tation. An irreducible representation is a representation of a group G on a vector space V that has no invariant subspaces besides the zero space {0} and V itself83. Such representations can be thought 83 The subspace consisting solely of the identity element is always, trivially an invariant subspace. of as truly fundamental, because they are not made up by smaller representations. The irreducible representations of a group are the building blocks from which we can build up all other representa- tions. There is another way to think about irreducible representation: An irreducible representation cannot be rewritten, using a similarity transformation, in block diagonal form84. In contrast, a reducible 84 An example for a matrix in block- diagonal form is ⎛ ⎝ab 0 cd 0 00 e ⎞ ⎠. representation can be rewritten in block-diagonal form through sim- ilarity transformations. These notions are important because we use irreducible representations to describe elementary particles85. We will 85 What else?see later that the behavior of elementary particles under transforma- tions is described by irreducible representations of the corresponding symmetry group. There are many possible representations for each group86,howdo 86 For example we already know two different representations for rotations in two-dimensions. One using complex numbers and one using 2 × 2 matrices. Both are representations of S1 as a group. we know which one to choose to describe nature? There is an idea that is based on the Casimir elements. A Casimir element C is built from generators of the Lie algebra and its deﬁning feature is that it commutes with every generator X of the group [C, X]= 0. (3.92) What does this mean? A famous Lemma, called Schur’s Lemma87, 87 A basic result of group theory, which you can look up in any book about group theory. For example, Schur’s lemma is proven at page 239 in Nadir Jeevanjee. An Introduction to Tensors and Group Theory for Physicists. Birkhaeuser, 1st edition, August 2011. ISBN 978- 0817647148. tells us that if we have an irreducible representation R : g → GL(V), any linear operator T : V → V that commutes with all operators R(X) must be a scalar multiple of the identity operator. Therefore, the Casimir elements give us linear operators with constant values for each representation. As we will see, these values provide us with a way of labelling representations naturally.88 We can therefore start 88 This will become much clearer as soon as we look at an example.to investigate the irreducible representations, by starting with the representation with the lowest possible scalar value for the Casimir element. Is there anything we can say about the vector space V mentioned 54 physics from symmetry in the deﬁnition of a representation above? An important observation that helps us to make sense of the vector space, is that for any Lie group, one or several of the corresponding generators can be diag- onalized using similarity transformations. In physics we use these diagonal generators to get labels for the basis vectors that span our vector space. We use the eigenvectors of these diagonal generators as basis for our vector space and the corresponding eigenvalues as labels. This idea is incredibly important to actually understand the physical implications of a given group. If there is just one gener- ator that can be diagonalized simultaneously, each basis vector is labelled by just one number: the corresponding eigenvalue. If there are several generators that can be diagonalized simultaneously, we get several numbers as labels for each basic vector. Each such number is simply the eigenvalue of a given diagonal generator that belongs to this basic vector (=eigenvector). In particular this is where the \"charge labels\" for elementary particles: electric charge, weak charge, color charge, come from. This idea will make a lot more sense, once we are ready to look at some explicit examples89. 89 A bit more background information: The set of diagonal generators is called Cartan subalgebra, and the correspond- ing generators Cartan generators. As already mentioned, these generators play a big role in elementary particle physics, because the eigenvalues of the Cartan generators are used to give charge labels to elementary particles. For example, to derive quantum chro- modynamics, we use the group SU(3), as we will see later, and there are two SU(3) Cartan generators. Therefore, each particle that interacts via chromo- dynamics, carries two charge labels. Conventionally instead of writing two numbers, one uses the words red, blue, green, and calls the corresponding charge colour. Analogous, the theory of weak interactions uses the group SU(2), which has only one Cartan generator. Therefore, each particle is labelled by the corresponding eigenvalue of this Cartan generator. In the next sections, we will derive the irreducible representations of the Lie algebra of SU(2), because, as we will see, the Lie algebra of the Lorentz group can be thought of as two copies of the algebra su(2)90. The Lorentz group is part of the Poincaré group and there- 90 Technically it’s the complexiﬁcation of the Lie algebra of the Lorentz group that can be understood as two copies of the complexiﬁcation of the Lie algebra su(2). fore we will talk about these groups in this order. 3.6 SU(2) We used in Section 3.4.3 speciﬁc matrices (=a speciﬁc representation) to identify how the generators of SU(2) behave, when put into the Lie bracket91. We can use this knowledge to ﬁnd further represen- 91 Recall that this is what we use to deﬁne the Lie algebra of a group in abstract terms. The ﬁnal result was Eq. 3.82. tations. Unsurprisingly, we will derive again the representation that we started with, i.e. the set of unitary 2 × 2 matrices with unit deter- minant. However, we are then able to see that this is just one special case. Before we tackle this task, we want to take a moment to think about what representations we can expect. 3.6.1 The Finite-dimensional Irreducible Representations of SU(2) As noted earlier, there are special operators that we can build from a given set of generators that are useful to understand the repre- sentations of the Lie algebra in question. These operators are called Casimir operators and have the special property that they commute with all generators of the given Lie algebra. For the Lie algebra su(2) there is one such operator9292 We restrict ourselves here to quadratic Casimir operators, which means opera- tors that are quadratic in the generators. There are also higher order Casimir operators, but here we always mean quadratic Casimir operators. lie group theory 55 J2 = J2 1 + J2 2 + J3 3 .(3.93) To illustrate this, let’s consider again the 3-dimensional represen- tation93, as shown in Eq. 3.86. For, this representation the Casimir 93 So far, we have not discussed where this representation comes from. We will understand this in a moment. Here we only use the ﬁnal result to explain the basic idea behind the use of the Casimir operator J2. operator is J2 3-dim = ⎛ ⎜ ⎝ 200 020 002 ⎞ ⎟ ⎠ .(3.94) In other words, the Casimir operator is simply two times the 3 × 3 identity matrix. In contrast, for the 2-dimensional representation, as given by Ji = 1 2 σi, where σi are the Pauli matrices (Eq. 3.80), we get J2 2-dim = ( 3 4 0 0 3 4 ) .(3.95) This illustrates that if the generators J1, J2, J3 are given in some rep- resentation, we can calculate the corresponding Casimir operator explicitly. If we act with this Casimir operator on any element of the vector space that our generators act on94, we get a number. This 94 Recall that a representation is a map of the abstract group or Lie algebra elements to the linear operators that act on some vector space. number is what we use to label different representations. In addition to this label for different representations, we use addi- tional special operators to label the different elements of the vector space that our groups acts on. The operators we use for this purpose are known as Cartan elements of the Lie algebra. In other words, while Casimir elements operators provide labels for different repre- sentations, the Cartan element provide labels within a given repre- sentation. The Cartan elements are all those generators that can be diagonalized simultaneously. For su(2) there is only one such ele- ment and it is conventional to choose J3 as diagonal generator95.In 95 As noted above, for other algebras like su(3), there is more than one Cartan element and therefore we get multiple labels for each vector. the 3-dimensional representation (Eq. 3.86)itisgivenby J3 = ⎛ ⎜ ⎝10 0 00 0 00 −1 ⎞ ⎟ ⎠ (3.96) and in the 2-dimensional representation it is given by J3 = ( 1 2 0 0 − 1 2 ) .(3.97) We use for each representation the eigenvectors of the diagonal gen- erator J3 as basis vectors for the vector space that our representation acts on. This means that every such basis vector is labeled by two numbers96 96 We use here an abstract notation for the elements of the vector space that our generators act on. This notations emphasizes the labels that we use to distinguish different elements and is extremely popular in quantum mechanics, as will be discussed in Section 8.5.3. J2 |b, m⟩ = b |b, m⟩ J3 |b, m⟩ = m |b, m⟩ .(3.98) 56 physics from symmetry The ﬁrst label is the value of the quadratic Casimir operator J2 for the representation in question and the second label corresponds to the value that we get when we act with the Cartan element J3 on the vector. By looking at Eq. 3.95 and Eq. 3.97, we can see that the basis vectors for the 2-dimensional representation in this notation are9797 Take note that in the usual, non- abstract vector notation, we can use as basis vectors for the 2-dimensional representation (1 0 ) and (0 1 ). | 3 4 , 1 2 ⟩ , | 3 4 , − 1 2 ⟩. Analogously, by looking at Eq. 3.94 and Eq. 3.96,we can see that the basis vectors for the 3-dimensional representation are98 |2, 1⟩ , |2, 0⟩ , |2, −1⟩. 98 Equally, in the usual, non-abstract vector notation we can use as our basis vectors for the 3-dimensional representation ⎛ ⎝1 0 0 ⎞ ⎠, ⎛ ⎝0 1 0 ⎞ ⎠ and ⎛ ⎝0 0 1 ⎞ ⎠. After this preliminary discussion we are ﬁnally ready to under- stand the representations of SU(2). To learn something about what ﬁnite-dimensional, irreducible representations of SU(2) are possible, we deﬁne new operators from the ones we used in Section 3.4.3:99 99 Take note that we use a complex lin- ear combination here. This process of considering a complex linear combina- tion, instead of the original generators is called a complexiﬁcation, because usually we only allow real linear combi- nations of the generators. So from here on, we consider the complexiﬁcation of the Lie algebra su(2), which is also called sl(2, C). J+ = J1 + iJ2 (3.99) J− = J1 − iJ2 .(3.100) These new operators obey the following commutation relations, as you can check by using the commutator relations in Eq. 3.82100 100 We can always diagonalize one of the generators. As mentioned above, we choose J3 as diagonal and therefore yielding the basis vectors for our vector space. [J3, J±]= ±J± (3.101) [J+, J−]= 2J3.(3.102) If we now investigate how these operators act on an eigenvector |b, m⟩ of J3 with eigenvalue101 m, we discover something remarkable: 101 This means J3 |b, m⟩ = m |b, m⟩ as explained in Appendix C.4. J3(J± |b, m⟩)= J3(J± |b, m⟩)+ J± J3 |b, m⟩− J± J3 |b, m⟩ ︸ ︷︷ ︸ =0 = J± J3 |b, m⟩ ︸ ︷︷ ︸ =J±m|b,m⟩ + J3 J± |b, m⟩− J± J3 |b, m⟩ ︸ ︷︷ ︸ =[J3,J±]|b,m⟩ =︸︷︷︸ Eq. 3.101 (m ± 1)J± |b, m⟩ .(3.103) We conclude that J± |b, m⟩ is again an eigenvector of J3, but with eigenvalue (m ± 1) and thus we write102 J± |b, m⟩≡ C |b, m ± 1⟩: 102 To be general, we include here a constant C. This constant will be discussed in a moment. J3 |b, m ± 1⟩ =(m ± 1) |b, m ± 1⟩ .(3.104) The operators J− and J+ are called raising and lowering opera- tors or ladder operators. Starting from one J3 eigenvector, we can construct more and more J3 eigenvectors using the ladder operators J± repeatedly. This process must come to an end, because eigenvec- tors with different eigenvalues are linearly independent and we are dealing with ﬁnite-dimensional representations. This means that the corresponding vector space is ﬁnite-dimensional and therefore we can only ﬁnd a ﬁnite number of linearly independent vectors. lie group theory 57 We conclude that there must be an eigenvector with a maximum eigenvalue that we call j. For this maximum eigenvector, we must have J+ |b, j⟩ = 0, (3.105) because the only other possibility would be that, according to Eq. 3.103, we produce a new eigenvector with eigenvalue j + 1 and thus j wouldn’t be the maximum eigenvalue. We can calculate a relation- ship between this maximum J3 eigenvalue j and the label b for the whole representation by using103 103 This follows from J2 = J2 1 + J2 2 + J3 3 → J2 1 + J2 2 = J2 − J2 3 . J− J+ =(J1 − iJ2)(J1 + iJ2) == J2 1 + J2 2︸ ︷︷ ︸ =J2−J2 3 +i (J1 J2 − J2 J1) ︸ ︷︷ ︸ =[J1,J2]=iJ3 (Eq. 3.82) = J2 − J2 3 − J3 .(3.106) Using this expression, we can write 0 =︸︷︷︸ Eq 3.105 J− J+ |b, j⟩ =︸︷︷︸ Eq 3.106 and Eq 3.98(b − j2 − j) |b, j⟩ .(3.107) Therefore, we can conclude b − j2 − j = 0 and thus b = j(j + 1) .(3.108) Completely analogous to how we concluded that there is an eigen- vector of J3 with maximum eigenvalue j, we can conclude that there is an eigenvector with minimal eigenvalue. We call this minimal eigenvalue k and we must have J− |b, k⟩ = 0, because otherwise k would not be the minimal eigenvalue. Analogous to the calculation in Eq. 3.107, we can calculate 0 = J+ J− |b, k⟩ =(b − k2 + k) |b, k⟩ .(3.109) Therefore, we have (b − k2 + k)= 0 and can conclude b = −k(−k + 1) .(3.110) By comparing Eq. 3.108 with Eq. 3.110, we can conclude k = −j .(3.111) Now it’s time to recall our discussion from the beginning of this section. We have one label b coming from the quadratic Casimir op- erator J2, which we use to distinguish different representations. In addition, we have another label m coming from the diagonal gener- ator J3, which we use to label different elements of the vector space our representation acts on. We have derived above that for ﬁnite di- mensional representations, there is a maximal value for m, which 58 physics from symmetry we called j. We introduced ladder operators J± that act on a given |b, m⟩ and yield a new eigenvector of J3 with eigenvalue m ± 1. In practice, this means we can start with the eigenvector with maxi- mum J3 eigenvalue |b, j⟩ for a given representation and then \"move down the ladder\" using J−. The repeated application of J− yields new eigenvectors of J3. However, this process must come to an end at some eigenvector |b, k⟩ with lowest J3 eigenvalue k, because we are dealing with a ﬁnite dimensional representation and there can not be inﬁnitely many eigenvectors. Acting with J− on this eigenvector with minimal eigenvalue |b, k⟩ yields simply zero. We calculated that this minimal eigenvalue is k = −j. In summary, for each SU(2) representation, labeled by b = j(j + 1) (Eq. 3.108), we get a set of J3 eigenvectors with integer spaced eigenvalues in the range −j ≤ m ≤ j. As mentioned above, we can start climbing down the ladder at the vector |b, j⟩ with maximum J3 eigenvalue and get to the vector with minimum eigenvalue |b, −j⟩ by repeated application of the operator J−. After each application the eigenvalue is lowered by one. Therefore, the difference between the maximum J3 eigenvalue j and the minimal value −j is an integer: j − (−j)= integer. From this we can conclude immediately 2j = integer → j = integer 2 .(3.112) This is an incredibly important insight, because it allows us to under- stand the possible ﬁnite-dimensional representations of su(2).If we simply start plugging in the allowed values of j = 0, 1/2, 1, 3/2, . . ., we get all possible su(2) representations. In addition, we can use what learned above to understand and construct these representa- tions explicitly. This explicit construction will be the topic of the next sections. It is particular instructive to have a look at the possible J3 eigenvalues m for the different allowed values of j and the value of the quadratic Casimir operator J2 for these representations104104 In Eq. 3.98 we called the eigenvalue that belongs to J2 simply b. However in Eq. 3.108, we calculated that we express b through the maximum J3 eigenvalue that we called j: b = j(j + 1). j = 0, m = 0, j(j + 1)= 0 j = 1/2 , m = 1/2, −1/2 , j(j + 1)= 3/4 j = 1, m = 1, 0, 1 , j(j + 1)= 2 j = 3/2 , m = 3/2, 1/2, −1/2, −3/2 , j(j + 1)= 15/4 ... (3.113) We learn here that the j = 0 representation is one-dimensional, the j = 1/2 representation is two-dimensional, the j = 1 representa- tion is three-dimensional and the j = 3/2 representation is four- dimensional105. Take note that the values for the quadratic Casimir 105 We use the eigenvectors of the Cartan generator, here J3, as basis vectors for the vector space that our representation acts on. For example, if there are two possible eigenvalues of J3, i.e. m values, we have two basis vectors and thus the corresponding representation is two-dimensional. lie group theory 59 operator J2 for the two-dimensional and the three-dimensional repre- sentation are exactly those that we calculated at the beginning of this section. There is one more thing we need to discuss, before we can move on to the actual explicit construction of these various representations. We calculated in Eq. 3.103 that if we act with J+ on a given J3 eigen- vector |b, m⟩,wegetanew J3 eigenvector with a higher eigenvalue: J3 J+ |b, m⟩ =(m + 1)J+ |b, m⟩. However, we can not simply conclude that J+ |b, m⟩ = |b, m + 1⟩. Instead, we only know that J+ |b, m⟩ is proportional to |b, m + 1⟩ and therefore we write J+ |b, m⟩ = C |b, m + 1⟩ ,(3.114) where C is some constant. We now want to calculate this constant, because only then we have fully understood the action of the ladder operators and can actually use them to construct the representations explicitly. The thing is that we want to work with normalized basis vectors and hence want that |b, m⟩ and |b, m + 1⟩ are normalized: |b, m⟩† |b, m⟩ = 1 |b, m + 1⟩† |b, m + 1⟩ = 1. (3.115) If we act with J+ or equally with J− on a normalized basis vector like |b, m⟩ the result will be, in general, not normalized. If we wouldn’t care about normalization, we could write J+ |b, m⟩ = |b, m + 1⟩.How- ever, for us a basis vector like |b, m + 1⟩ means always a normalized basis vector and hence we need to include the additional constant C. From the deﬁnition106 of J− and J+ it follows that J† − = J+ and 106 Eq. 3.99 and Eq. 3.100: J+ = 1√2 (J1 + iJ2) and J− = 1√2 (J1 − iJ2) J† + = J−. Thus if we calculate the norm107 of Eq. 3.114,weget 107 It will become clear in a second why this is a clever thing to do.(J+ |b, m⟩)† J+ |b, m⟩ = |C|2 |b, m + 1⟩† |b, m + 1⟩ ︸ ︷︷ ︸ =1 (Eq. 3.115) |b, m⟩† J† + J+ |b, m⟩ = |C|2 |b, m⟩† J− J+︸ ︷︷ ︸ =J2−J2 3 −J3 (Eq. 3.106) |b, m⟩ = |C|2 |b, m⟩† (J2 − J2 3 − J3) |b, m⟩ ︸ ︷︷ ︸ =(b−m2−m)|b,m⟩ (Eq. 3.98) = |C|2 |b, m⟩† ( b︸︷︷︸ =j(j+1) (Eq. 3.108) −m2 − m) |b, m⟩ = |C|2 60 physics from symmetry |b, m⟩† |b, m⟩ ︸ ︷︷ ︸ =1 (Eq. 3.115) (j(j + 1) − m2 − m)= |C|2 (j(j + 1) − m2 − m)= |C|2 .(3.116) The ﬁnal result of this calculation expresses the norm of the previ- ously unknown constant C in terms of the labels j and m that we use to characterize our representation and the vectors within a represen- tation. We can conclude108 from Eq. 3.116: 108 A possible complex phase of the constant C is irrelevant and we chose it to be real and positive. √(j(j + 1) − m2 − m)= C .(3.117) Thus, for a given representation, which means a given j and a given basis vector, which means given m, we can use Eq. 3.117 to calculate the full result of what happens if we act with J+ on a given eigenvec- tor: J+ |j(j + 1), m⟩ = C |j(j + 1), m + 1⟩ =︸︷︷︸ Eq. 3.117 √(j(j + 1) − m2 − m) |j(j + 1), m + 1⟩ .(3.118) We already argued above that if we act with J+ on the eigenvector with maximum J3 eigenvalue |j(j + 1), j⟩, we must get zero. If we now plug in m = j in Eq. 3.117 we can see that this indeed happens: √(j(j + 1) − j2 − j)= C √j2 + j − j2 − j = C 0 = C .(3.119) In addition, following exactly the same steps as above, we can calcu- late the constant ˜C that we get if we act with J− on a given eigenvec- tor. The result is J− |j(j + 1), m⟩ = ˜C |j(j + 1), m + 1⟩ = √(j(j + 1) − m2 + m) |j(j + 1), m + 1⟩ .(3.120) We have now everything we need to calculate explicit matrix ex- pressions for the various SU(2) representations. In fact, it’s possi- ble to show that every irreducible representation of SU(2) must be equivalent to one of these that we can construct by using the tools de- scribed above109. There is one small thing we need to discuss before 109 See, for example, page 190 in: Nadir Jeevanjee. An Introduction to Tensors and Group Theory for Physicists. Birkhaeuser, 1st edition, August 2011. ISBN 978- 0817647148 we move on. The label j(j + 1) takes a lot of space and is somewhat redundant. It is therefore conventional to use simply j as a label in- stead. This means, we use |j, m⟩ instead of |j(j + 1), m⟩. Now we look at speciﬁc examples for the representations. We start, of course, with the lowest dimensional representation. lie group theory 61 3.6.2 The Representation of SU(2) in one Dimension The lowest possible value for j is zero. As already mentioned above, this representation acts on a one-dimensional vector space. We can see that this representation is trivial, because the only 1 × 1 \"ma- trix\" that fulﬁlls the commutation relations of the SU(2) Lie algebra [Jl, Jm]= iϵlmn Jn, are the number 0. If we exponentiate the generator 0, we always get the transformation U = e0 = 1, which changes nothing at all. 3.6.3 The Representation of SU(2) in two Dimensions We now take a look at the next possible value j = 1 2 . This representa- tion is 2 1 2 + 1 = 2 dimensional110. The generator J3 has eigenvalues 1 2 110 See Eq. 3.113. and 1 2 − 1 = − 1 2 , as can be seen from Eq. 3.113 and is therefore given by J3 = 1 2 (10 0 −1 ) ,(3.121) because we choose J3 to be the diagonal generator111. The eigenvec- 111 For SU(2) only one generator is diagonal, because of the commutation relations. Furthermore, remember that we are able to transform the generators using similarity transformations and could therefore easily make another generator diagonal. tors corresponding to the eigenvalues + 1 2 and − 1 2 are112 112 As mentioned above, we use, for brevity, |j, m⟩ instead of |j(j + 1), m⟩. Here j = 1/2. |1/2, 1/2⟩ = (1 0 ) and |1/2, −1/2⟩ = (0 1 ) .(3.122) We can ﬁnd the explicit matrix form of the other two SU(2) gen- erators J1 and J2 in this basis by rewriting them using the ladder operators J1 = 1 2 (J− + J+) (3.123) J2 = i 2 (J− − J+),(3.124) which we get directly from inverting the deﬁnitions of J± in Eq. 3.100 and Eq. 3.99. Recall that a basis for the vector space of this represen- tation is given by the eigenvectors of J3 and we therefore express the generators J1 and J2 in this basis. In other words, in this basis J1 and J2 are deﬁned by their action on the eigenvectors of J3. We compute J1 |1/2, 1/2⟩ = 1 2 (J− + J+) |1/2, 1/2⟩ = 1 2 (J− |1/2, 1/2⟩ + J+ |1/2, 1/2⟩ ︸ ︷︷ ︸ =0 ) = 1 2 J− |1/2, 1/2⟩ =︸︷︷︸ Eq. 3.120 with ˜C=1 1 2 |1/2, −1/2⟩ ,(3.125) 62 physics from symmetry where we used that 1/2 is already the maximum J3 eigenvalue and we cannot go higher. Similarly we get J1 |1/2, −1/2⟩ = 1 2 (J− + J+) |1/2, −1/2⟩ = 1 2 |1/2, 1/2⟩ .(3.126) Using Eq. 3.125 and Eq. 3.126, we can write J1 in matrix form: J1 = 1 2 (01 10 ) .(3.127) You can check that this matrix has the correct action on the basis vectors that we derived above113. In the same way, we ﬁnd 113 We derived in Eq. 3.125: J1 |1/2, 1/2⟩ = 1 2 |1/2, −1/2⟩. Using the explicit matrix form of J1 we get J1 |1/2, 1/2⟩ = 1 2 (01 10 )(1 0 ) = 1 2 (0 1 ) = 1 2 |1/2, −1/2⟩ ✓. J2 = 1 2 (0 −i i 0 ) .(3.128) These are the same generators Ji = 1 2 σi, with the Pauli matrices σi,we found while investigating the Lie algebra of SU(2) at the beginning of this chapter (Eq. 3.80). We can now see that the representation we used there was exactly this two dimensional representation. Never- theless, there are many more, for example, in three-dimensions as we will see in the next section114. 114 Again, don’t get confused by the name SU(2), which we originally de- ﬁned as the set of unitary 2 × 2 matrices with unit determinant. Here we mean the abstract group, deﬁned by the cor- responding manifold S3 and we are going to talk about higher dimensional representations of this group, which result in, for example, a representation with 3 × 3 matrices. It would help if we could give this structure a different name (For example, using the name of the corresponding manifold S3), but unfortunately SU(2) is the conventional name. 3.6.4 The Representation of SU(2) in three Dimensions Following the same procedure115 as in two-dimensions, we ﬁnd: 115 Again we start with the diagonal generator J3, which we can write down immediately because we know its eigenvalues (1, 0, −1) from Eq. 3.113. Afterwards, the other two generators J1, J2 can be derived by looking at how they act on the basis vectors, i.e. the eigenvectors of J3. To calculate this, we use again that we can write J1 and J2 in terms of J±. J1 = 1 √2 ⎛ ⎜ ⎝010 101 010 ⎞ ⎟ ⎠ , J2 = 1 √2 ⎛ ⎜ ⎝0 −i 0 i 0 −i 0 i 0 ⎞ ⎟ ⎠ , J3 = ⎛ ⎜ ⎝10 0 00 0 00 −1 ⎞ ⎟ ⎠ (3.129) This is the representation of the generators of SU(2) in three di- mensions. If you’re interested, you can derive the corresponding representation for the group elements of SU(2) in three dimensions, by putting these generators into the exponential function. We will not go any further and derive even higher dimensional representa- tions, because at this point we already have everything we need to understand the most important representations of the Lorentz group. 3.7 The Lorentz Group O(1, 3) \"To arrive at abstraction, it is always necessary to begin with a concrete reality . . . You must always start with something. Afterward you can remove all traces of reality.\" - Pablo Picasso116116 As quoted in Robert S. Root- Bernstein and Michele M. Root- Bernstein. Sparks of Genius. Mariner Books, 1st edition, 8 2001. ISBN 9780618127450 lie group theory 63 In this section we will derive one well-known representation of the Lorentz group. Then we will use this familiar representation to derive the Lie algebra of the Lorentz group. This is exactly the same route we followed for SU(2). There we started with explicit 2 × 2 ma- trices to derive the corresponding Lie algebra. We will ﬁnd that the complexiﬁed Lie algebra of the Lorentz group consists of two copies of the Lie algebra su(2). This fact can be used to discover further representations of the Lorentz group, whereas the well-known vec- tor representation, which is the representation of the Lorentz group by 4 × 4 matrices acting on four-vectors, will prove to be one of the representations. The new representations will provide us with tools to describe physical systems that cannot be described by the vector representation. This shows the power of Lie theory. Using Lie theory we are able to identify the hidden abstract structure of a symmetry and by using this knowledge, we are able to describe nature at the most fundamental level with the required tools. We start with a characterisation of the Lorentz group and its sub- groups. The Lorentz group is the set of all transformations that pre- serve the inner product of Minkowski space117 117 This was derived in Chapter 2. Recall that this deﬁnition is analogous to our deﬁnition of rotations and spatial reﬂections in Euclidean space, which preserve the inner product of Euclidean space. xμxμ = xμημνxν =(x0)2 − (x1)2 − (x2)2 − (x3)2 (3.130) where ημν denotes the metric of Minkowski space ημν = ⎛ ⎜ ⎜ ⎜ ⎝ 10 0 0 0 −10 0 00 −10 00 0 −1 ⎞ ⎟ ⎟ ⎟ ⎠ .(3.131) This is the reason why we call the Lorentz group O(1, 3). The group O(4) preserves (x0)2 +(x1)2 +(x2)2 +(x3)2. Let’s see what restriction this imposes. The conventional name for a Lorentz transformation is Λ (\"lambda\"). For the moment, Λ is just a name and we will derive now how these transformations look like explicitly. If we transform xμ → x′μ = Λμ ν xν, we get the product xμημνxν → x′σησρx′ρ =(xμΛσ μ)ησρ(Λρ νxν) ! = xμημνxν (3.132) and because this must hold for arbitrary xμ we conclude Λσ μησρΛρ ν ! = ημν (3.133) or written in matrix form118 118 Recall that in order to write the prod- uct of two vectors in matrix notation, the left vector is transposed. Therefore we get here ΛT. ΛTηΛ ! = η.(3.134) 64 physics from symmetry This is how the Lorentz transformations Λ are deﬁned! Starting from this deﬁnition, we will now derive a useful classiﬁca- tion for all Lorentz transformations. If we take the determinant of Eq. 3.133 and use det(AB)= det(A) det(B), we get the condition det(Λ) det(η) ︸ ︷︷ ︸ =−1 det(Λ) ! = det(η) ︸ ︷︷ ︸ =−1 → det(Λ)2 ! = 1(3.135) → det(Λ) ! = ±1. (3.136) Furthermore, if we look at the μ = ν = 0 component in Eq. 3.133119, 119 We will see in a minute why this is useful. we get Λσ 0 ησρΛρ 0 ! = η00 ︸︷︷︸ =1 → Λσ 0 ησρΛρ 0 =(Λ0 0)2 − ∑ i (Λi 0)2 ! = 1(3.137) and thus conclude Λ0 0 ! = ±√1 + ∑ i (Λi 0)2.(3.138) We now divide the Lorentz transformations into four \"sub-categories\", depending on the signs in Eq. 3.136 and Eq. 3.138: L↑ + : det(Λ)=+1; Λ0 0 ≥ 1 L↑ − : det(Λ)= −1; Λ0 0 ≥ 1 L↓ + : det(Λ)=+1; Λ0 0 ≤−1 L↓ − : det(Λ)= −1; Λ0 0 ≤−1. (3.139) This classiﬁcation is useful, because, as we will see in a moment, only the transformations in one of these categories120, L↑ +, can be gen- 120 The technical term for this most important category L↑ + is proper, orthochronous Lorentz group. \"Proper\" refers to the property det (Λ)=+1, which in physical terms means that transformations in this category do not change the spatial orientation. For example, a right-handed coordinate system stays right-handed and does not become a left-handed one. The word \"orthochronous\" refers to the property Λ0 0 ≥ 1 and means in physical terms that transformations with this property do not change the direction of time. erated through inﬁnitesimal transformations. We, want to use the power of Lie theory and in particular learn as much as possible from the Lie algebra that belongs to a given group. Thus we focus on this sub-category L↑ + and try to learn as much as possible using the cor- responding generators. The transformations in the other categories are a combination of the transformations in this special category and one or both of two special transformations known as time-reversal ΛT and space-inversion ΛP, where121 121 At least for one representation, these operators look like this. We will see later that for different representations, these operators look quite different. The subscript P here denotes \"parity\" which is another name for space- inversion. In physical terms a parity transformation is a reﬂection at the spatial axes, whereas a time-reversal transformation is a reﬂection at the time axis. ΛP = ⎛ ⎜ ⎜ ⎜ ⎝ 1 000 0 −10 0 00 −10 00 0 −1 ⎞ ⎟ ⎟ ⎟ ⎠ (3.140) lie group theory 65 ΛT = ⎛ ⎜ ⎜ ⎜ ⎝ −1000 0 100 0 010 0 001 ⎞ ⎟ ⎟ ⎟ ⎠ .(3.141) This is illustrated in ﬁgure 3.8. In this sense, we can understand the complete Lorentz group as the set O(1, 3)= {L↑ +, ΛP L↑ +, ΛT L↑ +, ΛPΛT L↑ +}.(3.142) Fig. 3.8: The four components of the Lorentz group are connected through the two discrete transformations known as time-reversal ΛT and space-inversion ΛP. So, why can only transformations in the L↑ + category be built up by inﬁnitesimal transformations? The transformations that can be built up by inﬁnitesimal transformations are smoothly connected to the identity transformation, because the inﬁnitesimal transformations are inﬁnitesimally close to the identity element. Therefore, the iden- tity element is in the same category as all the transformations that can be built up by repeating inﬁnitesimal ones. We have det(Id)=+1; Id 0 0 = 1 and therefore the identity transformation and with it all transforma- tions that can be generated through inﬁnitesimal transformations, belong to the L↑ + category. An important related observation is that the four categories that we deﬁned above: L↑ +, L↑ −, L↓ +, L↓ −, are not smoothly connected to each other. For example, there is a \"gap\" between the transforma- tions with det(Λ)=+1 and those with det(Λ)= −1. There are no transformations in between. Equally, there is a \"gap\" between Λ0 0 ≥ 1 and Λ0 0 ≤−1 and also no transformations in between. The jump across this gap can only be achieved by making use of the discrete transformations ΛP and ΛT. Therefore, the transformations in the other categories are not smoothly connected to the identity element, which is part of the L↑ + category. For this reason, we can not get the transformations in these other categories, by solely using inﬁnitesi- mal transformations. Instead, we always need the discrete \"jumps\" provided by ΛP and ΛT. To summarize: We concentrate in the following on the transforma- tions in the L↑ + subcategory, because it contains all transformations that can be built up by repeating inﬁnitesimal ones. Such transforma- tions are especially nice, because we can understand them through the corresponding Lie algebra. In practice this means that in the next step, we investigate the generators122 that generate all transforma- 122 Recall: Generators are the elements of the Lie algebra.tions in the L↑ + category. The transformations in the other categories are simply a combination of the transformations that we derive this way, and the discrete operations ΛP and ΛT. 66 physics from symmetry 3.7.1 One Representation of the Lorentz Group Let’s see how we can use the deﬁning condition of the Lorentz group (Eq. 3.133) to construct an explicit matrix representation of the al- lowed transformations. First let’s think a moment about what we are trying to ﬁnd. The Lorentz group, when acting on 4-vectors123,is 123 The usual vector space of special relativity is the real, four-dimensional Minkowski space R(1,3). We will look at the representation on this vector space ﬁrst, because the Lorentz group is deﬁned there in the ﬁrst place, i.e. as the set of transformations that preserve the 4 × 4 metric. Equivalently SU(2) was deﬁned as complex 2 × 2 matrices in the ﬁrst place and we tried to learn as much as possible about SU(2) from these matrices, in order to derive other representations later . given by real 4 × 4 matrices. The matrices must be real, because we want to know how they act on elements of the real Minkowski space R(1,3). A generic, real 4 × 4 matrix has 16 parameters. The deﬁning condition of the Lorentz group, which is in fact 10 conditions124,re- 124 You can see this, by putting a generic 4 × 4 matrix Λ,in ΛT ηΛ = η. stricts this to 6 parameters. In other words, to describe a most general Lorentz transformation, 6 parameters are needed. Therefore, if we ﬁnd 6 linearly independent generators, we have found a complete basis for the Lie algebra of this group. This means every other gener- ator can be written as a linear combination of these basis generators. In addition, we are then able to compute how these basis genera- tors behave when put into the Lie bracket and therefore to derive the abstract deﬁnition of this Lie algebra. First note that the rotation matrices of 3-dimensional Euclidean space, which involve only space and leave the time unchanged, fulﬁl the condition in Eq. 3.133125. This follows because the spatial part126125 Λσ μησρΛρ ν ! = ημν 126 The spatial part are the components μ = 1, 2, 3. Commonly this is denoted by ηij, because Latin indices, like i, j always run from 1 to 3 and Greek indices, like μ and ν, run from 0 to 3. of the Minkowski metric is proportional to the 3 × 3 identity ma- trix127 and therefore for transformations involving only space, we 127 Recall η11 = η22 = η33 = −1 and ηij = 0 for i ̸= j. have from Eq. 3.133 the condition −RT I3×3R = −RT R ! = −I3×3 → RT I3×3R = RT R ! = I3×3. This is exactly the deﬁning condition of O(3). Together with the condition (Eq. 3.139) det(Λ) ! = 1 these are the deﬁning conditions of SO(3). We conclude that the corresponding Lorentz transformations are given by Λrot = (1 R3×3 ) with the rotation matrices R3×3 shown in Eq. 3.22 and derived in Section 3.4.1. The corresponding generators are therefore analogous to those we derived for three spatial dimensions in Section 3.4.1: Ji = (0 J3dim i ) .(3.143) lie group theory 67 For example, using Eq. 3.71 we now have J1 = (0 J3dim 1 ) = ⎛ ⎜ ⎜ ⎜ ⎝ 000 0 000 0 000 −i 00 i 0 ⎞ ⎟ ⎟ ⎟ ⎠ .(3.144) To investigate transformations involving time and space we will start, as always in Lie theory, with an inﬁnitesimal transformation128 128 With the Kronecker delta deﬁned by δμ ρ = 1 for μ = ρ and δμ ρ = 0 for μ ̸= ρ. This means writing the Kronecker delta in matrix form is just the identity matrix. Λμ ρ ≈ δμ ρ + ϵKμ ρ .(3.145) We put this into the deﬁning condition (Eq. 3.133) Λμ ρ ημνΛν σ ! = ηρσ → (δμ ρ + ϵKμ ρ )ημν(δν σ + ϵKν σ) ! = ηρσ → \u0002\u0002ηρσ + ϵKμ ρ ημσ + ϵKν σηρν + ϵ2Kμ ρ ημνKν σ ︸ ︷︷ ︸ ≈0 because ϵ is inﬁnitesimal →ϵ2≈0 = \u0002\u0002ηρσ → Kμ ρ ημσ + Kν σηρν = 0(3.146) which reads in matrix form129 129 Recall that the ﬁrst index denotes the row and the second the column. So far we have been a little sloppy with ﬁrst and second index, by writ- ing them above each other. In fact, we have Kμ ρ ≡ Kμ ρ → (KT)μ ρ = K μ ρ . Matrix multiplication always works by multiplying rows with columns. Therefore Kν σηρν = ηρνKν σ, where the ρ-row of η is multiplied with the σ-column of K. This term then is in matrix notation ηK. Furthermore, Kμ ρ ημσ = Kμ ρημσ =(KT) μ ρ ημσ. In order to write this index term in matrix nota- tion we need to use the transpose of K, because only then we get a product of the form row times column. The ρ-row of KT is multiplied with the σ-column of η. Therefore, this term is KT η in ma- trix notation. In index notation we are free to move objects around, because for example Kμ ρ is just one element of K, i.e. a number. KTη = −ηK.(3.147) Now we have the condition for the generators of transformations involving time and space. A transformation generated by these gen- erators is called a boost. A boost means a change into a coordinate system that moves with a different constant velocity compared with the original coordinate system. We can boost the description that we have, for example in a frame of reference where the object in ques- tion is at rest, into a frame of reference where it moves relative to the observer. Let’s go back to the example used in Chapter 2.1:A boost along the x-axis. Because we know that y′ = y and z′ = z the generator is of the form K1 = ⎛ ⎜ ⎜ ⎜ ⎜ ⎜ ⎜ ⎝ (ab cd ) ︸ ︷︷ ︸ ≡k1 (00 00 ) ⎞ ⎟ ⎟ ⎟ ⎟ ⎟ ⎟ ⎠ (3.148) and we only need to solve a 2 × 2 matrix equation. Equation 3.147 reduces to (ac bd )(−10 01 ) = − (−10 01 )(ab cd ) , 68 physics from symmetry which is solved by130 130 (0 i i 0 )(−10 01 ) = ( 0 i −i 0 ) and − (−10 01 )(0 i i 0 ) = − (0 −i i 0 ). k1 = (ab cd ) = (0 i i 0 ) . The complete generator for boosts along the x-axis is therefore K1 = ⎛ ⎜ ⎜ ⎜ ⎝ 0 i 00 i 000 0000 0000 ⎞ ⎟ ⎟ ⎟ ⎠ (3.149) and equally we can ﬁnd the generators for boosts along the y- and z-axis K2 = ⎛ ⎜ ⎜ ⎜ ⎝ 00 i 0 0000 i 000 0000 ⎞ ⎟ ⎟ ⎟ ⎠ K3 = ⎛ ⎜ ⎜ ⎜ ⎝ 000 i 0000 0000 i 000 ⎞ ⎟ ⎟ ⎟ ⎠ .(3.150) Now, we already know from Lie theory how we get from the gen- erators to ﬁnite transformations Λ1(φ)= eiφK1 . For brevity let’s focus again on the exciting part of the generator K1, i.e. the upper left 2 × 2 matrix k1, which is deﬁned in Eq. 3.148.We can then evaluate the exponential function using its series expansion and that131 (ik1)2 = 1 131 As you can easily check: (ik1)2 = i2 (0 i i 0 )(0 i i 0 ) = (10 01 ), equally k4 1 = 1 etc. for all even exponents and of course (ik1)3 = ik1, k5 1 = ik1 etc. for all uneven exponents. Λ1(φ)= eiφk1 = ∞ ∑ n=0 inφnkn 1 n! = ∞ ∑ n=0 φ2n (2n)! (ik1)2n ︸ ︷︷ ︸ =1 + ∞ ∑ n=0 φ2n+1 (2n + 1)! (ik2n+1 1 ) ︸ ︷︷ ︸ =ik1 = ( ∞ ∑ n=0 φ2n (2n)! ) I + i ( ∞ ∑ n=0 φ2n+1 (2n + 1)! ) k1 = cosh(φ)I + i sinh(φ)k1 = (cosh(φ) 0 0 cosh(φ) ) + ( 0 − sinh(φ) − sinh(φ) 0 ) = ( cosh(φ) − sinh(φ) − sinh(φ) cosh(φ) ) (3.151) This computation is analogous to the computation in Section 3.4.1, but observe that the sums here have no factor (−1)n and therefore these sums are not sin(φ) and cos(φ), but different functions called hyperbolic sine sinh(φ) and hyperbolic cosine cosh(φ). The complete 4 × 4 transformation matrix for a boost along the x-axis is therefore Λ1 = ⎛ ⎜ ⎜ ⎜ ⎝ cosh(φ) − sinh(φ) 00 − sinh(φ) cosh(φ) 00 00 1 0 00 0 1 ⎞ ⎟ ⎟ ⎟ ⎠ .(3.152) lie group theory 69 Analogously, we can derive the transformation matrices for boosts along the other axes: Λ2 = ⎛ ⎜ ⎜ ⎜ ⎝ cosh(φ) 0 − sinh(φ) 0 0100 − sinh(φ) 0 cosh(φ) 0 0001 ⎞ ⎟ ⎟ ⎟ ⎠ (3.153) Λ3 = ⎛ ⎜ ⎜ ⎜ ⎝ cosh(φ) 00 − sinh(φ) 01 00 00 10 − sinh(φ) 0 0 cosh(φ) ⎞ ⎟ ⎟ ⎟ ⎠ .(3.154) An arbitrary boost can be composed by multiplication of these 3 transformation matrices. 3.7.2 Generators of the Other Components of the Lorentz Group To understand how the generators for the transformations of the other components132 of the Lorentz Group look like, we simply have 132 Recall that the Lorentz group is in fact O(1, 3)= {L↑ +, ΛP L↑ +, ΛT L↑ +, ΛPΛT L↑ +} and we derived in the last section the generators of L↑ +. to act with the parity operation ΛP and the time reversal operator ΛT on the matrices Ji, Ki we just derived. In index notation we have133 133 We need two matrices ΛP, one for each index. This is just the ordinary transformation behavior of opera- tors under changes of the coordinate system. (ΛP)α α′ (ΛP)β β′ (Ji)α′ β′ ˆ=︸︷︷︸ switching to matrix notation ΛP Ji(ΛP)T = Ji ˆ=(Ji)αβ (3.155) (ΛP)α α′ (ΛP)β β′ (Ki)α′ β′ ˆ=︸︷︷︸ switching to matrix notation ΛPKi(ΛP)T = −Ki ˆ= − (Ki)αβ,(3.156) as we can check by a brute force computation, using the explicit matrices derived in the last section. For example, J1 = ⎛ ⎜ ⎜ ⎜ ⎝ 000 0 000 0 000 −i 00 i 0 ⎞ ⎟ ⎟ ⎟ ⎠ → J′ 1 = ΛP J1(ΛP)T = J1,(3.157) because ΛP J1(ΛP)T = ⎛ ⎜ ⎜ ⎜ ⎝ 1 000 0 −10 0 00 −10 00 0 −1 ⎞ ⎟ ⎟ ⎟ ⎠ ⎛ ⎜ ⎜ ⎜ ⎝ 000 0 000 0 000 −i 00 i 0 ⎞ ⎟ ⎟ ⎟ ⎠ ⎛ ⎜ ⎜ ⎜ ⎝ 1 000 0 −10 0 00 −10 00 0 −1 ⎞ ⎟ ⎟ ⎟ ⎠ T = ⎛ ⎜ ⎜ ⎜ ⎝ 000 0 000 0 000 −i 00 i 0 ⎞ ⎟ ⎟ ⎟ ⎠ (3.158) 70 physics from symmetry In contrast, K1 = ⎛ ⎜ ⎜ ⎜ ⎝ 0 i 00 i 000 0000 0000 ⎞ ⎟ ⎟ ⎟ ⎠ → K′ 1 = ΛPK1(ΛP)T = −K1,(3.159) because ΛPK1(ΛP)T = ⎛ ⎜ ⎜ ⎜ ⎝ 1 000 0 −10 0 00 −10 00 0 −1 ⎞ ⎟ ⎟ ⎟ ⎠ ⎛ ⎜ ⎜ ⎜ ⎝ 0 i 00 i 000 0000 0000 ⎞ ⎟ ⎟ ⎟ ⎠ ⎛ ⎜ ⎜ ⎜ ⎝ 1 000 0 −10 0 00 −10 00 0 −1 ⎞ ⎟ ⎟ ⎟ ⎠ T = − ⎛ ⎜ ⎜ ⎜ ⎝ 0 i 00 i 000 0000 0000 ⎞ ⎟ ⎟ ⎟ ⎠ .(3.160) In conclusion, we have under parity transformations Ji →︸︷︷︸ P Ji Ki →︸︷︷︸ P −Ki .(3.161) This will become useful later, because for different representations the parity transformations will not be as obvious as in the vector rep- resentation. Equally we can investigate the time-reversed generators and the result will be the same, because time-reversal involves only the ﬁrst component, which only changes something for the boost generators Ki (ΛT)α α′ (ΛT)β β′ (Ji)α′ β′ ˆ=︸︷︷︸ switching to matrix notation ΛT Ji(ΛT)T = Ji ˆ=(Ji)αβ (3.162) (ΛT)α α′ (ΛT)β β′ (Ki)α′ β′ ˆ=︸︷︷︸ switching to matrix notation ΛTKi(ΛT)T = −(Ki)αβ,(3.163) Or shorter: Ji →︸︷︷︸ T Ji Ki →︸︷︷︸ T −Ki.(3.164) 3.7.3 The Lie Algebra of the Proper Orthochronous Lorentz Group Now using the explicit matrix form of the generators134 for L↑ + we 134 See Eq. 3.149 for the boost generators and Eq. 3.61 for the rotation generators can derive the corresponding Lie algebra by brute force computa- tion135 135 The Levi-Civita symbol ϵijk,is deﬁned in Appendix B.5.5. lie group theory 71 [Ji, Jj]= iϵijk Jk (3.165) [Ji, Kj]= iϵijkKk (3.166) [Ki, Kj]= −iϵijk Jk ,(3.167) where again Ji denotes the generators of rotations and Ki are the generators of boosts. A general Lorentz transformation is of the form Λ = ei⃗J·⃗θ+i⃗K·⃗Φ (3.168) Equation 3.166 tells us that the two types of generator (Ji and Ki) do not commute with each other. While the rotation generators are closed under commutation136, the boost generators are not137.We 136 Closed under commutation means that the commutator [Ji, Jj]= Ji Jj − Jj Ji, is again a rotation generator. From Eq. 3.165 we can see that this is the case. 137 Eq. 3.167 tells us that the commutator of two boost generators Ki and Kj isn’t another boost generator, but a generator of rotations. can now deﬁne two new operator types from the old ones that are closed under commutation and commute with each other138 138 Again, take note that we use a complex linear combination here and recall that this process of considering a complex linear combination, instead of the original generators is called a complexiﬁcation. Usually we only allow real linear combinations of the generators. So from here on, we consider the complexiﬁcation of the Lie algebra of the Lorentz group. N± i = 1 2 (Ji ± iKi).(3.169) Working out the commutation relations yields [N+ i , N+ j ]= iϵijk N+ k (3.170) [N− i , N− j ]= iϵijk N− k (3.171) [N+ i , N− j ]= 0. (3.172) These are precisely the commutation relations for the Lie algebra of SU(2) and we have therefore discovered that the complexiﬁed Lie algebra of L↑ + consists of two copies of the Lie algebra su(2)139. 139 Recall that when we discussed the representations of the Lie al- gebra su(2), we also used the cor- responding complexiﬁcation. The complexiﬁcation of su(2) is sl(2, C) and therefore technically we have so(1, 3)C ∼= sl(2, C) ⊕ sl(2, C), where so(1, 3)C denotes the complexiﬁcation of the Lorentz group Lie algebra. This is great news, because we already know how to construct all irreducible representations of the Lie algebra of su(2).However we must be careful. The Lorentz group is, like SO(3), not simply- connected140 and Lie theory tells us that, for groups that aren’t sim- 140 We will use this simply as a fact here, because a proof would lead us too far apart. ply connected, there is no one-to-one correspondence between the irreducible representations of the Lie algebra and representations of the corresponding group141. Instead, by deriving the irreducible 141 This can be quite confusing, but remember that there is always one distinguished group that belongs to a Lie algebra. This group is distinguished because it is simply connected. If we derive the irreducible representation of a Lie algebra, we get, by putting those Lie algebra elements (= the generators) in the exponential function, representations of the simply connected (= covering) group. Only for the simply connected group there is a one-to-one correspondence. representations of the complexiﬁed Lie algebra of the Lorentz group, we ﬁnd the irreducible representations of the covering group of the Lorentz group, if we put the corresponding genera- tors into the exponential function. Some of these representations will be representations of the Lorentz group, but we will ﬁnd more than that. This is good, because we need these additional representations to describe certain elementary particles. 72 physics from symmetry For brevity, we will continue to call the representations we will derive, representations of the Lorentz group instead of representations of the Lie algebra of the Lorentz group or representations of the double cover of the Lorentz group. Each irreducible representation of the Lie algebra su(2) can be labeled by the scalar value j of the su(2) Casimir operator142. There- 142 To be precise: the scalar value that we get from the quadratic Casimir operator is j(j + 1). However, for brevity, we simply use j instead. fore, we now know that we can label the irreducible representations of the covering group143 of the Lorentz group by two integer or half 143 The covering group of the proper orthochronous Lorentz group L↑ + is SL(2, C), which is deﬁned as the set of 2 × 2 matrices with unit determinant and complex entries. The relationship SL(2, C) → L↑ + ≡ SO(1, 3)↑ + is similar to the relationship SU(2) → SO(3) we discovered earlier in this text. integer numbers: j1 and j2. This means we will look at the (j1, j2) rep- resentations and use the j1, j2 = 0, 1 2 , 1 . . . representations for the two su(2) copies, which we derived earlier. It is conventional to write the Lorentz algebra in a more compact way by introducing a new symbol Mμν, which is deﬁned through the equations Ji = 1 2 ϵijk Mjk.(3.173) Ki = M0i .(3.174) With this new deﬁnition the Lorentz algebra reads [Mμν, Mρσ]= i(ημρ Mνσ − ημσ Mνρ − ηνρ Mμσ + ηνσ Mμρ).(3.175) Next, we investigate different representations of the complexiﬁed Lie algebra of the Lorentz group and hence of the double cover of the Lorentz group in detail. 3.7.4 The (0, 0) Representation The lowest dimensional representation is, as it is for SU(2), trivial, because the vector space is one-dimensional for both copies of su(2). Our generators must therefore be 1 × 1 matrices and the only 1 × 1 \"matrix\" that fulﬁlls the commutation relations is the number 0: N+ i = N− i = 0 → eiN+ i = eiN− i = e 0 = 1(3.176) Therefore we conclude that the (0, 0) representation of the Lorentz group acts on objects that do not change under Lorentz transforma- tions. This representation is called the scalar representation. 3.7.5 The ( 1 2,0) Representation In this representation we use the144 2 dimensional representation 144 Recall that the dimension of our vec- tor space is given by 2j + 1. Therefore we have here 2 1 2 + 1 = 2 dimensions. for one copy of the SU(2) Lie algebra N+ i , i.e. N+ i = σi 2 and the 1 lie group theory 73 dimensional representation for the other N− i , i.e. N− i = 0. From the deﬁnition of N− in Eq. 3.169 we conclude N− i = 1 2 (Ji − iKi)= 0(3.177) → Ji = iKi.(3.178) Furthermore, we can use that we already derived in Section 3.6.3 the two dimensional representation of SU(2): N+ i = σi 2 ,(3.179) where σi denotes once more the Pauli matrices, which were deﬁned in Eq. 3.80. On the other hand, we have N+ i =︸︷︷︸ Eq. 3.169 1 2 (Ji + iKi)=︸︷︷︸ Eq. 3.178 1 2 (iKi + iKi)= iKi (3.180) Comparing Eq. 3.179 with Eq. 3.180 tells us that iKi = σi 2 → Ki = σi 2i = iσi 2i2 = −i 2 σi (3.181) Eq. 3.178 → Ji = iKi = −i2 2 σi = 1 2 σi.(3.182) We conclude that a Lorentz rotation in this representation is given by Rθ = ei⃗θ·⃗J = ei⃗θ·⃗σ 2 (3.183) and a Lorentz boost by Bφ = ei⃗φ·⃗K = e ⃗φ·⃗σ 2 .(3.184) By writing out the exponential function as series expansion we can easily get the representation of the double cover of the Lorentz group from the representation of the generators. For example, rotations about the x-axis e.g. are given by Rx(θ)= eiθ J1 = eiθ 1 2 σ1 = 1 + i 2 θσ1 + 1 2 ( i 2 θσ1 )2 + ... (3.185) And if we use the explicit matrix form of σ1 (Eq. 3.80), together with the fact that σ2 1 = 1, we get145 145 The steps are completely analogous to what we did in Section 3.4.1 Rx(θ)= (10 01 ) + i 2 θ (01 10 ) − 1 2 ( θ 2 )2 (10 01 ) + ... = ( cos( θ 2 ) i sin( θ 2 ) i sin( θ 2 ) cos( θ 2 ) ) .(3.186) 74 physics from symmetry Analogously, we can compute the transformation matrix for rota- tions around other axes or boosts. One important thing to notice is that we have here complex 2 × 2 matrices, representing the Lorentz transformations. These transformations certainly do not act on the four-vectors of Minkowski space, because these have 4 components. The two-component146 objects this representation acts on are called 146 We will learn later that these two components correspond to spin-up and spin-down states. left-chiral spinors147: 147 This name will make more sense after the deﬁnition of right-chiral spinors. Then we can see that parity transformations transform a left-chiral spinor transformation into a right- chiral spinor transformation and vice versa. These spinors are often called left-handed and right-handed, but this can be confusing, because these terms correspond originally to a concept called helicity, which is not the same as chirality. Recall what the parity operator does: changing a left-handed coordinate system into a right-handed coordinate system and vice versa. Hence the name. χL = ( (χL)1 (χL)2 . ) (3.187) Spinors in this context are two component objects. A possible deﬁnition for left-chiral spinors is that they are objects that transform under Lorentz transformations according to the ( 1 2 ,0) representation of the Lorentz group. Take note that this is not just another way to describe the same thing, because spinors have properties that usual vectors do not have. For instance, the factor 1 2 in the exponent. This factor shows us that a spinor is after a rotation by 2π not the same, but gets a minus sign148. This is a pretty crazy property, because we 148 There is much more one can say about spinors. See, for example, chapter 3.2 in J. J. Sakurai. Modern Quantum Mechanics. Addison Wesley, 1st edition, 9 1993. ISBN 9780201539295 usually expect that objects are exactly the same after a rotation by 360◦ = 2π. In the last section, we saw that the lowest-dimensional representa- tion is trivial. The next representation in the \"hierarchy\" of represen- tations is the spinor representation that we discovered in this section. In this sense, we can say that \". . . a spinor is the most basic sort of mathematical object that can be Lorentz-transformed.\" - A. M. Steane149149 Andrew M. Steane. An introduction to spinors. ArXiv e-prints, December 2013 3.7.6 The (0, 1 2 ) Representation This representation can be constructed analogous to the ( 1 2 ,0) repre- sentation but this time we use the 1 dimensional representation for N+ i , i.e. N+ i = 0 and the two dimensional representation for N− i , i.e. N− i = 1 2 σi . A ﬁrst guess could be that this representation looks ex- actly like the ( 1 2 ,0) representation, but this is not the case! This time we get from the deﬁnition of N+ in Eq. 3.169 N+ i = 1 2 (Ji + iKi)= 0(3.188) → Ji = −iKi.(3.189) Take notice of the minus sign. Using the two-dimensional represen- tation of su(2) for N+, which was derived in Section 3.6.3, yields lie group theory 75 N− i = 1 2 σi = 1 2 (Ji − iKi)=︸︷︷︸ Eq. 3.189 1 2 (−iKi − iKi)= −iKi .(3.190) Using this we can deduce the (0, 1 2 ) representation of the boost gener- ators −iKi = 1 2 σi → Ki = −1 2i σi = −i 2i2 σi = i 2 σi.(3.191) In addition, from Eq. 3.189 we get Ji = −iKi = 1 2 σi .(3.192) We conclude that in this representation a Lorentz rotation is given by Rθ = ei⃗θ·⃗J = ei⃗θ·⃗σ 2 (3.193) and a Lorentz boost by Bφ = ei⃗φ·⃗K = e−⃗φ·⃗σ 2 .(3.194) Therefore, rotations are the same as in the ( 1 2 ,0) representation, but boosts differ by a minus sign in the exponent. We conclude both representations act on objects that are similar but not the same.We call the objects the (0, 1 2 ) representation of the Lorentz group acts on right-chiral spinors: χR = ((χR)1 (χR)2 ) (3.195) The generic name for left- and right-chiral spinors is Weyl spinors. 3.7.7 Van der Waerden Notation Now we introduce a notation that makes working with spinors very convenient. We know that we have two kinds of objects that trans- form differently and therefore must be distinguished. In the last section we learned that they are different, but not too different. In a moment we will learn that there is a connection between the ob- jects transforming according to the ( 1 2 ,0) representation (left-chiral spinors) and the objects transforming according to the (0, 1 2 ) repre- sentation (right-chiral spinors). To be able to describe these different objects using one notation we introduce the notions of dotted and undotted indices, sometimes called Van der Waerden notation, after their inventor. This will help us to keep track of which object trans- forms in what way. This will become much clearer in a minute, as soon as we have set up the full formalism. 76 physics from symmetry Let’s deﬁne that a left-chiral spinor χL has a lower, undotted index χL = χa (3.196) and a right-chiral spinor χR has an upper, dotted index χR = χ ˙a.(3.197) Next, we introduce the \"spinor metric\". The spinor metric enables us to transform a right-chiral spinor into a left-chiral and vice versa, but not alone as we will see. We deﬁne the spinor metric150 as 150 Take note that this is the Levi-Civita symbol in two dimensions as deﬁned in Appendix B.5.5. ϵab = ( 01 −10 ) (3.198) and show that it has the desired properties. Furthermore, we de- ﬁne151151 Maybe a short comment on the strange notation χC L is in order. The su- perscript C denotes charge conjugation, as will be explained in Section 3.7.10 in more detail. Here we see that this op- eration ﬂips one label, i.e. a left-chiral spinor becomes right-chiral. Later we will see this operation ﬂips all labels, including, for example, the electric charge. χC L ≡ ϵχ⋆ L (3.199) where the ⋆ denotes complex conjugation. We will now inspect how χC L transforms under Lorentz transformations and see that it trans- forms precisely as a right-chiral spinor. The deﬁning feature of a right-chiral spinor is its transformation behavior and therefore we will conclude that χC L is a right-chiral spinor. Let us have a look at how χC L transforms under boosts, where we use (−ϵ)(ϵ)= 1(3.200) and (ϵ)σ⋆ i (−ϵ)= −σi (3.201) for each Pauli matrix σi, as you can check by using Eq. 3.198. Trans- forming χC L yields152152 We use the notation ⃗φ⃗σ = ∑i φiσi =︸︷︷︸ summation convention φiσi. The \"vector\" ⃗σ shouldn’t be taken too seriously, be- cause it’s just a shorthand, conventional notation. χC L → χ′C L = ϵ(χ′)⋆ L = ϵ ((e ⃗φ 2⃗σχL )⋆ = ϵ(e ⃗φ 2⃗σ (−ϵ)(ϵ) ︸ ︷︷ ︸ =1 (Eq. 3.200) χL )⋆ = ϵe ⃗φ 2⃗σ⋆ (−ϵ) ︸ ︷︷ ︸ =e− ⃗φ 2 ⃗σ (Eq. 3.201) (ϵ)χ⋆ L = e− ⃗φ 2⃗σ ϵχ⋆ L︸︷︷︸ =χC L = e− ⃗φ 2⃗σχC L ,(3.202) lie group theory 77 which is exactly the transformation behavior of a right-chiral spinor153. 153 The transformation behavior of right-chiral spinors under boosts was derived in Eq. 3.194: Bθ = ei⃗φ⃗K = e−⃗φ⃗σ 2 . Compare this to how left-chiral spinors transform under boosts, as derived in Eq. 3.184: Bθ = ei⃗φ⃗K = e ⃗φ⃗σ 2 To get to the ﬁfth line, we use the series expansion of e ⃗φ 2⃗σ and Eq. 3.201 on every term. You can check in the same way that the behavior un- der rotations is not changed by complex conjugation and multiplica- tion with ϵ, as it should be, because χL and χR transform in the same way under rotations: χC L → χ′C L = ϵ(χ′)⋆ L = ϵ(e i⃗θ 2 ⃗σχ)⋆ L = e i⃗θ 2 ⃗σϵ(χL)⋆ = e i⃗θ 2 ⃗σχC L .(3.203) Furthermore, you can check that ϵ is invariant under all transforma- tions and that if we want to go the other way round, i.e. transform a right-chiral spinor into a left-chiral spinor, we have to use (-ϵ). Therefore, we deﬁne in analogy with the tensor notation of special relativity that our \"metric\" raises and lowers indices ϵχL =︸︷︷︸ written in index notation ϵacχc = χa ,(3.204) where summation over identical indices is implicitly assumed (Ein- stein summation convention). Furthermore, we know that if we want to get χR from χL we need to use complex conjugation as well χR = ϵχL⋆ .(3.205) This means that complex conjugation transforms an undotted index into a dotted index: χR = ϵχL⋆ = χ ˙a.(3.206) Therefore, we can get a lower, dotted index by complex conjugating χL: χL⋆ = χa⋆ = χ ˙a (3.207) and an upper, undotted index, by complex conjugating χR χR⋆ =(χ ˙a)⋆ = χa .(3.208) It is instructive to investigate how χ ˙a and χa transform, because these objects are needed to construct terms from spinors, which do not change under Lorentz transformations. Terms like this are incred- ibly important, because we need them to derive physical laws that are the same in all frames of reference. This will be made explicit in a moment. From the transformation behavior of a left-chiral spinor χL = χa → χ′ a = (ei⃗θ⃗σ 2 +⃗φ⃗σ 2 )b a χb ,(3.209) we can derive how a spinor with lower, dotted index transforms: 78 physics from symmetry χ⋆ L = χ⋆ a = χ ˙a → χ′ ˙a =(χ′ a)⋆ = ((ei⃗θ⃗σ 2 +⃗φ⃗σ 2 )b a )⋆ χ⋆ b = (e−i⃗θ ⃗σ⋆ 2 +⃗φ ⃗σ⋆ 2 ) ˙b ˙a χ ˙b (3.210) Analogously, we use that we know how a right-chiral spinor trans- forms: χR → χ′ R = χ′ ˙a = (ei⃗θ⃗σ 2 −⃗φ⃗σ 2 ) ˙a ˙b χ ˙b (3.211) to derive how a spinor with upper, undotted index transforms: χ⋆ R =(χ ˙a)⋆ = χa → χ′a =(χ′ ˙a)⋆ = ((ei⃗θ⃗σ 2 −⃗φ⃗σ 2 ) ˙a ˙b )⋆ (χ ˙b)⋆ = (e−i⃗θ ⃗σ⋆ 2 −⃗φ ⃗σ⋆ 2 )a b χb .(3.212) To be able to write products of spinors that do not change under Lorentz transformations, we need one more ingredient. Recall how the scalar product of two vectors is deﬁned: ⃗a ·⃗b = ⃗aT⃗b. In the same spirit we should transpose one of the spinors in a spinor product. We can see this, because at the moment we have the complex con- jugate of the Pauli matrices σ⋆ i in the exponent, for example, e−i⃗θ ⃗σ⋆ 2 . Together with transposing this becomes the Hermitian conjugate: σ† i =(σ⋆ i )T, where the symbol † is called \"dagger\". The Hermitian conjugate of every Pauli matrix, is again the same Pauli matrix σ† i =(σ⋆ i )T = σi,(3.213) as you can easily check by looking at the explicit form of the Pauli matrices (Eq. 3.80). By comparing Eq. 3.209 with Eq. 3.212 and using Eq. 3.213,we see that the transformation behavior of a transposed spinor with lower, undotted index is exactly the opposite of a spinor with upper, undotted index. This means a term of the form (χa)Tχa is invariant (=does not change) under Lorentz transformations, because154154 As explained in Appendix B.5.5, the symbol δc b is called Kronecker symbol and denotes the unit matrix in index notation. This means δc b = 1 for b = c and δc b = 0 for b ̸= c. lie group theory 79 (χa)Tχa → (χ′a)Tχ′ a = ((e−i⃗θ ⃗σ⋆ 2 −⃗φ⃗σ⋆ 2 )a b χb)T (ei⃗θ ⃗σ 2 +⃗φ⃗σ 2 )c a χc =(χb)T (e−i⃗θ ⃗σ⋆T 2 −⃗φ⃗σ⋆T 2 )a b (ei⃗θ⃗σ 2 +⃗φ⃗σ 2 )c a χc =︸︷︷︸ Eq. 3.213 (χb)T (e−i⃗θ⃗σ 2 −⃗φ⃗σ 2 )a b (ei⃗θ⃗σ 2 +⃗φ⃗σ 2 )c a︸ ︷︷ ︸ =δc b χc =(χc)Tχc .(3.214) In the same way we can combine an upper, dotted index with a lower, dotted index as you can verify by comparing Eq. 3.210 with Eq. 3.211. In contrast, a term of the form (χ ˙a)Tχa ˆ=χT RχL isn’t invari- ant under Lorentz transformations, because χT RχL =(χ ˙a)Tχa → (χ′ ˙a)Tχ′ a = χ ˙b (ei⃗θ ⃗σT 2 −⃗φ ⃗σT 2 ) ˙a ˙b (ei⃗θ⃗σ 2 +⃗φ⃗σ 2 )c a ︸ ︷︷ ︸ ̸=δc b χc (3.215) Therefore a term combining a left-chiral with a right-chiral spinor is not Lorentz invariant. We conclude, we must always combine an upper with a lower index of the same type155 in order to get Lorentz 155 In this context dotted ˙a ˙a or undotted a a .invariant terms. Or formulated differently, we must combine the Hermitian conjugate of a right-chiral spinor with a left-chiral spinor χ† RχL =(χ⋆ R)TχL ˆ=(χa)Tχa, or the Hermitian conjugate of a left-chiral spinor with a right-chiral spinor χ† LχR =(χ⋆ L)TχR =(χ ˙a)Tχ ˙a to get Lorentz invariant terms. We will use this later, when need invariant terms that we can use to formulate our laws of nature. In addition, we have now another justiﬁcation for calling ϵab the spinor metric, because the invariant spinor product in Eq. 3.214, can be written as χT a χa =︸︷︷︸ Eq. 3.204 χT a ϵabχb.(3.216) Compare this to how we deﬁned in Eq. 2.31 the invariant product of Minkowsi space by using the Minkowski metric ημν: xμyμ = xμημνyν.(3.217) The spinor metric is for spinors indeed what the Minkowski metric is for four-vectors156. 156 Don’t get confused why we have no transposition for the four-vectors here. These equations can be read in two ways. On the one hand as vector equations and on the other hand as component equations. It’s conventional and sometimes confusing to use the same symbol xμ for a four-vector and its components. If we read the equation as a component equation we need no transposition. The same is of course true for our spinor products. Nevertheless, we have seen above that we mustn’t forget to transpose and in order to avoid errors we included the explicit superscript T, although the spinor equation here can be read as component equation that do not need it. In contrast, for three component vectors there is a clear distinction using the little arrow: ⃗a has components ai. After setting up this notation, we can now write the spinor \"met- 80 physics from symmetry ric\" with lowered indices ϵab = (0 −1 10 ) ,(3.218) because we need157 (−ϵ) to get from χR to χL. In addition, we can 157 You can check this yourself, but it’s not very important for what follows. now write the two transformation operators as one object Λ. For example, when it has dotted indices we know it multiplies with a right-chiral spinor and we know which transformation operator to choose: χR → χ′ R = χ′ ˙a = Λ ˙a˙bχ ˙b = (ei⃗θ⃗σ 2 −⃗φ⃗σ 2 ) ˙a ˙b χ ˙b (3.219) and analogously for left-chiral spinors χL → χ′ L = χ′ a = Λ b a χb = (ei⃗θ⃗σ 2 +⃗φ⃗σ 2 ) b a χb .(3.220) Therefore: Λ( 1 2 ,0) = (ei⃗θ⃗σ 2 +⃗φ⃗σ 2 ) ˆ=Λ b a (3.221) and Λ(0, 1 2 ) = (ei⃗θ⃗σ 2 −⃗φ⃗σ 2 ) ˆ=Λ ˙a˙b (3.222) This notation is useful, because, as we have seen, the two different objects χL and χR aren’t so different after all. In fact we can trans- form them into each other and a uniﬁed notation is the logical result. Now we move on to the next irreducible representation, which will turn out to be an old acquaintance. 3.7.8 The ( 1 2, 1 2 ) Representation For this representation we use the 2-dimensional representation for both copies of the SU(2) Lie algebra158 N+ i and N− i . This time let’s 158 Mathematically we have ( 1 2 , 1 2 )=( 1 2 ,0) ⊗ (0, 1 2 ). have a look at what kind of object our representation is going to act on ﬁrst. The copies will not interfere with each other, because N+ i and N− i commute, i.e. [N+ i , N− j ]= 0 (Eq. 3.172). Therefore, our objects will transform separately under both copies. Let’s name the object we want to examine v. This object will have 2 indices v ˙b a, each transforming under a separate two-dimensional copy of su(2). Here the notation we introduced in the last section comes in handy. We know that our object v will have 4 components, because each representation is 2 dimensional and this means that both indices can take on two values ( 1 2 and − 1 2 ). Therefore, the objects can be 2 × 2 matrices, but it’s also possible to enforce a four component vector form, as we will see159. 159 Remember that when we talked about rotations of the plane we were in the same situation. The rotation could be described by complex numbers acting on complex numbers. Doing the map to real matrices we had real matrices acting on real matrices, but the same action could be described by a real matrix acting on a column vector. lie group theory 81 First, let’s look at the complex matrix choice. A general 2 × 2 matrix has 4 complex entries and therefore 8 free parameters. As noted above, we only need 4. We can write every complex matrix M as a sum of a Hermitian (H† = H) and an anti-Hermitian (A† = −A) matrix: M = H + A. Both Hermitian and anti-Hermitian matrices have 4 free parameters. In addition, we will see in a moment that our transformations in this representation always transform a Hermitian 2 × 2 matrix into another Hermitian 2 × 2 matrix and equivalently an anti-Hermitian matrix into another anti-Hermitian matrix. This means Hermitian and anti-Hermitian matrices are invariant subsets. As explained in Section 3.5 this means that working with a general matrix here, corresponds to having a reducible representation. Putting these observations together, we conclude that we can assume that our irreducible representation acts on Hermitian 2 × 2 matrices. A basis160 for Hermitian 2 × 2 matrices is given by the Pauli matrices 160 This means that an arbitrary Her- mitian 2 × 2 matrix can be written as a linear combination of the form: a01 + aiσi together with the identity matrix. Instead of examining v ˙b a, we will have a look at va ˙b, because then we can use the Pauli matrices as deﬁned in Eq. 3.80. Take note that v ˙b a and va ˙b can be transformed into each other by multiplication with ϵ ˙b ˙c and therefore if you want to work with v ˙b a, you simply have to use the Pauli matrices that have been multiplied with ϵ. If we deﬁne σ0 = I2×2 = (10 01 ) , we can write va ˙b = vνσν a ˙b = v0 (10 01 ) + v1 (01 10 ) + v2 (0 −i i 0 ) + v3 (10 0 −1 ) . (3.223) As explained above, we could use161 v ˙b a = vμσμ a ˙cϵ ˙b ˙c instead, which 161 This is really just a basis choice and here we choose the basis that gives us with our deﬁnition of the Pauli matrices, the transformation behavior we derived earlier for vectors. means we would use the basis ( ˜σ ˙b a )μ = σμ a ˙cϵ ˙b ˙c. We therefore write a general Hermitian matrix as va ˙b = ( v0 + v3 v1 − iv2 v1 + iv2 v0 − v3 ) .(3.224) Remember that we have learned in the last section that different indices transform differently. For example, a lower dotted index transforms differently than a lower undotted index. Now we have a look at how va ˙b transforms and use the transforma- 82 physics from symmetry tion operators that we derived in the last sections v → v′ = v′ a ˙b = (ei⃗θ⃗σ 2 +⃗φ⃗σ 2 ) c a vc ˙d ((e−i⃗θ ⃗σ⋆ 2 +⃗φ ⃗σ⋆ 2 ) ˙d ˙b )T = (ei⃗θ⃗σ 2 +⃗φ⃗σ 2 ) c a vc ˙d (e−i⃗θ ⃗σ† 2 +⃗φ ⃗σ† 2 ) ˙d ˙b =︸︷︷︸ σ† i =σi (ei⃗θ⃗σ 2 +⃗φ⃗σ 2 ) c a vc ˙d (e−i⃗θ⃗σ 2 +⃗φ⃗σ 2 ) ˙d ˙b .(3.225) We can now see that a Hermitian matrix is after such a transforma- tion still Hermitian, as promised above162 162 Exactly the same computation shows that an anti-Hermitian matrix is still anti-Hermitian after such a transformation. To see this, use in the last step instead of v† c ˙d = vc ˙d that v† c ˙d = −vc ˙d. (ei⃗θ⃗σ 2 +⃗φ⃗σ 2 ) c a vc ˙d (e−i⃗θ⃗σ 2 +⃗φ⃗σ 2 ) ˙d ˙b → ((ei⃗θ⃗σ 2 +⃗φ⃗σ 2 ) c a vc ˙d (e−i⃗θ⃗σ 2 +⃗φ⃗σ 2 ) ˙d ˙b )† =︸︷︷︸ (ABC)†=C† B† A† ((e−i⃗θ⃗σ 2 +⃗φ⃗σ 2 ) ˙d ˙b )† v† c ˙d ((ei⃗θ⃗σ 2 +⃗φ⃗σ 2 ) c a )† = (ei⃗θ ⃗σ† 2 +⃗φ ⃗σ† 2 ) ˙d ˙b v† c ˙d (e−i⃗θ ⃗σ† 2 +⃗φ ⃗σ† 2 ) c a =︸︷︷︸ if v† c ˙d=vc ˙d (ei⃗θ⃗σ 2 +⃗φ⃗σ 2 ) c a vc ˙d (e−i⃗θ⃗σ 2 +⃗φ⃗σ 2 ) ˙d ˙b ✓ (3.226) The explicit computation for an arbitrary transformation is long and tedious163 so instead, we will look at one speciﬁc example. Let’s 163 See, for example, page 128 in Matthew Robinson. Symmetry and the Standard Model. Springer, 1st edition, August 2011. ISBN 978-1-4419-8267-4 boost v along the z-axis164 164 This means ⃗φ =(0, 0, φ)T. Such a boost is the easiest because σ3 is diag- onal. For boosts along other axes the exponential series must be evaluated in detail. va ˙b → v′ a ˙b = (eφ σ3 2 )c a vc ˙d (eφ σ3 2 ) ˙d ˙b = (e φ 2 0 0e− φ 2 )( v0 + v3 v1 − iv2 v1 + iv2 v0 − v3 )(e φ 2 0 0e− φ 2 ) = (eφ(v0 + v3) v1 − iv2 v1 + iv2 e−φ(v0 − v3) ) ,(3.227) where we have used the fact that σ3 is diagonal165 and that eA = (eA11 0 0eA22 ) 165 σ3 = (10 0 −1 ) holds for every diagonal matrix. We now compare the transformed object that we calculated in Eq. 3.227 with a generic object v′: v′ a ˙b = ( v′ 0 + v′ 3 v′ 1 − iv′ 2 v′ 1 + iv′ 2 v′ 0 − v′ 3 ) = (eφ(v0 + v3) v1 − iv2 v1 + iv2 e−φ(v0 − v3) ) . This tells us how the components of the transformed object are re- lated to the untransformed components166 166 We rewrite the equations using the connection between the hyper- bolic sine, the hyperbolic cosine function and the exponential func- tion e−φ = (cosh (φ) − sinh (φ)) and eφ = (cosh (φ) + sinh (φ)), which is conventional in this context. If you are unfamiliar with these functions you can either take notice of their deﬁni- tions: cosh (φ) ≡ 1 2 (eφ + e−φ) and sinh (φ) ≡ 1 2 (eφ − e−φ) or rewrite the few equations here in terms of eφ and e−φ, which is equally good. lie group theory 83 → v′ 0 + v′ 3 = eφ(v0 + v3)= (cosh (φ) + sinh (φ)) (v0 + v3) → v′ 0 − v′ 3 = e−φ(v0 − v3)= (cosh (φ) − sinh (φ)) (v0 − v3). The addition and subtraction of both equations yields → v′ 0 = cosh(φ)v0 + sinh(φ)v3 → v′ 3 = sinh(φ)v0 + cosh(φ)v3 .(3.228) This is exactly what we get using the 4-vector formalism167 167 See 3.154 for the explicit form of the matrix for a boost along the z-axis. ⎛ ⎜ ⎜ ⎜ ⎝ v′ 0 v′ 1 v′ 2 v′ 3 ⎞ ⎟ ⎟ ⎟ ⎠ = ⎛ ⎜ ⎜ ⎜ ⎝ cosh(φ) 0 0 sinh(φ) 01 00 00 10 sinh(φ) 0 0 cosh(φ) ⎞ ⎟ ⎟ ⎟ ⎠ ⎛ ⎜ ⎜ ⎜ ⎝ v0 v1 v2 v3 ⎞ ⎟ ⎟ ⎟ ⎠ = ⎛ ⎜ ⎜ ⎜ ⎝ cosh(φ)v0 + sinh(φ)v3 v1 v2 sinh(φ)v0 + cosh(φ)v3 ⎞ ⎟ ⎟ ⎟ ⎠ .(3.229) This is true for arbitrary Lorentz transformations, as you can check by computing the other possibilities. What we have shown here is that the ( 1 2 , 1 2 ) representation is the vector representation. We can simplify our transformation laws by using the enforced vector form, because multiplying a matrix with a vector is simpler than the multi- plication of three matrices. Nevertheless, we have seen how the famil- iar 4-vector is related to the more fundamental spinors. A 4-vector is a rank-2 spinor, which means a spinor with 2 indices that transforms according to the ( 1 2 , 1 2 ) representation of the Lorentz group. Further- more, we can now see that 4-vectors aren’t appropriate to describe every physical system on a fundamental level, because they aren’t fundamental. There are physical systems they cannot describe. We can now understand why some people say that \"spinors are the square root of vectors\". This is meant in the same way as vectors are the square root of rank-2 tensors168. A rank-2 tensor has two 168 A rank-2 tensor is simply a matrix Mμν.vector indices and a vector has two spinor indices. Therefore, the most basic object that can be Lorentz transformed is indeed a spinor. When we started our studies of the Lorentz group, we noted that it consists of four components169. These components are connected by 169 Eq. 3.142: O(1, 3)= {L↑ +, ΛP L↑ +, ΛT L↑ +, ΛPΛT L↑ +}.the parity and the time-reversal operator170. Therefore, to be able to 170 See Eq. 3.142 describe all transformations that preserve the speed of light, we need to ﬁnd the parity and time-reversal transformation for each repre- sentation. In this text we restrict ourselves to parity transformations, 84 physics from symmetry because the discussion for the time-reversal transformation is very similar. We will discuss in in a later section that nature isn’t always symmetric under parity transformations171. 171 Nature isn’t invariant under time- reversal transformations either, but a satisfying discussion of this curious fact lies beyond the scope of this book. 3.7.9 Spinors and Parity Up to this point, there is no justiﬁcation why we call the objects transforming according to the ( 1 2 ,0) representation left-chiral and the objects transforming according to the (0, 1 2 ) representation right- chiral. After talking a bit about parity transformation, this will make sense. Recall that we already know the behavior of the generators of the Lorentz group under parity transformations. The result was Eq. 3.161, which we recite here for convenience Ji →︸︷︷︸ P Ji Ki →︸︷︷︸ P −Ki .(3.230) By looking at the deﬁnition of the generators N± in Eq. 3.169, which we also recite here N± i = 1 2 (Ji ± iKi) .(3.231) we can see that under parity transformations N+ ↔ N−. There- fore, the (0, 1 2 ) representation of a transformation, becomes the ( 1 2 ,0) representation of this transformation and vice versa under parity transformations. This is the reason for talking about left- and right- chiral spinors172. Just as a right-handed coordinate system changes 172 The conventional name is left- and right-handed spinors, but this can be quite confusing, because the no- tions left-handed and right-handed are directly related to a concept called helicity, which is different from chi- rality. Anyway the name should make some sense, because something left is changed into something right under parity transformations. into a left-handed coordinate system under parity transformations, these two representations change into each other. Rotations are the same for both representations, but boost trans- formations differ by a sign and it is easy to make the above statement explicit: (Λ⃗K)( 1 2 ,0) = e ⃗φ⃗K →︸︷︷︸ P e−⃗φ⃗K =(Λ⃗K)(0, 1 2 ) (3.232) (Λ⃗K)(0, 1 2 ) = e−⃗φ⃗K →︸︷︷︸ P e ⃗φ⃗K =(Λ⃗K)( 1 2 ,0).(3.233) We learn here that if we want to describe a physical system that is invariant under parity transformations, we will always need right- chiral and left-chiral spinors. The easiest thing to do is to write them below each other into a single object called Dirac spinor Ψ = (χL ξR ) = (χa ξ ˙a ) .(3.234) lie group theory 85 Recalling that the generic name for left- and right-chiral spinors is Weyl spinors, we can say that a Dirac spinor Ψ consists of two Weyl spinors χL and ξR. Note that we want to stay general here and don’t assume any a priori connection between χ and ξ. A Dirac spinor of the form ΨM = (χL χR ) (3.235) is a special case, called Majorana spinor. A Dirac is not a four-vector, because it transforms completely different173. A Dirac spinor trans- 173 Equally, a Majorana spinor is not a vector.forms according to the ( 1 2 ,0) ⊕ (0, 1 2 ) representation174 of the Lorentz 174 This a reducible representation, which is obvious because of the block-diagonal form of the trans- formation matrix. In contrast, four- vectors transform according to the ( 1 2 , 1 2 )=( 1 2 ,0) ⊗ (0, 1 2 ) representation. group, which means nothing more than writing the corresponding transformations in block-diagonal form into one big matrix: Ψ → Ψ′ = Λ( 1 2 ,0)⊕(0, 1 2 )Ψ = (Λ( 1 2 ,0) 0 0 Λ(0, 1 2 ) )(χL ξR ) .(3.236) For example, a boost transformation is in this representation Ψ → Ψ′ = ⎛ ⎝e ⃗φ 2⃗σ 0 0e −⃗φ 2 ⃗σ ⎞ ⎠ (χL ξR ) .(3.237) It is instructive to investigate how Dirac spinors behave under parity transformations, because once we know how Dirac spinors transform under parity transformations, we can check if a given theory is invariant under such transformations. We can’t expect that a Dirac spinor is after a parity transformation still a Dirac spinor (an object transforming according to the ( 1 2 ,0) ⊕ (0, 1 2 ) representation), because we know that under parity transformations N+ ↔ N− and therefore (0, 1 2 ) ↔︸︷︷︸ P ( 1 2 ,0) .(3.238) We conclude that if a Dirac spinor transforms according to the ( 1 2 ,0) ⊕ (0, 1 2 ) representation, the parity transformed object trans- forms according to the (0, 1 2 ) ⊕ ( 1 2 ,0) representation. ΨP → (ΨP)′ = Λ(0, 1 2 )⊕( 1 2 ,0)ΨP = (Λ(0, 1 2 ) 0 0 Λ( 1 2 ,0) )(ξR χL ) .(3.239) Therefore Ψ = (χL ξR ) → ΨP = (ξR χL ) .(3.240) 86 physics from symmetry A parity transformed Dirac spinor contains the same objects ξR, χL as the untransformed Dirac spinor, only written differently. A parity transformation does nothing like ξ L → ξR, which is a different kind of transformation we will talk about in the next section. 3.7.10 Spinors and Charge Conjugation In Section 3.7.7 we stumbled upon a transformation, which yields χL → χR and ξR → ξ L. The transformation is achieved by χL → χC L = ϵχ⋆ L = χR and analogously for a right-chiral spinor ξR → ξC R = (−ϵ)ξ⋆ R = ξ L. We are now able to understand it from a quite different perspective. Up to this point, we used this transformation merely as a compu- tational trick in order to raise and lower indices. Now, how does a Dirac spinor transform under such a transformation? Naively we get: Ψ = (χL ξR ) → ˜Ψ = (χC L ξC R ) = (χR ξ L ) .(3.241) Unfortunately, this object does not transform like a Dirac spinor175, 175 Unlike for parity transformations, we have a choice here and we prefer to keep working with the same kind of object. The object ˜Ψ can then be seen as a Dirac spinor that has been parity transformed and charge conjugated. which transform under boosts as follows Ψ → Ψ′ = ⎛ ⎝e ⃗θ 2⃗σ 0 0e −⃗θ 2 ⃗σ ⎞ ⎠ (χL ξR ) .(3.242) In contrast, the object ˜Ψ we get from the naive operation, transforms as ˜Ψ → ˜Ψ′ = ⎛ ⎝e− ⃗θ 2⃗σ 0 0e ⃗θ 2⃗σ ⎞ ⎠ (χL ξR ) .(3.243) This is a different kind of object, because it transforms according to a different representation of the Lorentz group. Therefore we write Ψ = (χL ξR ) → ΨC = (ξC R χC L ) = ( ξ L χR ) ,(3.244) which incorporates the transformation behavior we observed ear- lier and transforms like a Dirac spinor. This operation is commonly called charge conjugation, which can be a little misleading. We know that this transformation transforms a left-chiral spinor into a right- chiral, i.e. ﬂips one label we use to describe our elementary parti- cles176. Later we will learn that this operator ﬂips not only one, but 176 For the more advanced reader: Recall that each Weyl spinor we are talking about here, is in fact a two component object. Later we will deﬁne a physical measurable quantity, called spin, that is described by 1 2 σ3. The matrix ϵ, ﬂips an object with eigenvalue + 1 2 for the spin operator 1 2 σ3 into an object with eigenvalue − 1 2 . This is commonly interpreted as spin ﬂip, which means an object with spin 1 2 , becomes an object with spin − 1 2 . all labels we use to describe fundamental particles. One such label is electric charge, hence the name charge conjugation, but before we are able to show this, we need of course to understand ﬁrst what electric lie group theory 87 charge is. Nevertheless, it’s always important to remember that all labels get ﬂipped, not only electric charge. We could now go on and derive higher-dimensional representa- tions of the Lorentz group, but at this point we already have every ﬁnite-dimensional irreducible representation we need for the purpose of this text. Nevertheless, there is another representation, the inﬁnite- dimensional representation, that is especially interesting, because we need it to transform ﬁelds, like, for example, the electromagnetic ﬁeld. 3.7.11 Inﬁnite-Dimensional Representations In the last sections, we talked about ﬁnite-dimensional representa- tions of the Lorentz group and learned how we can classify them. These ﬁnite-dimensional representations acted on constant one-, two- or four-component objects. In physics the objects we are deal- ing with are dynamically changing in space and time, so we need to understand how such objects transform. So far, we have dealt with transformations of the form Φa → Φ′ a = Mab(Λ)Φb ,(3.245) where Mab(Λ) denotes the matrix of the particular ﬁnite-dimensional representation of the Lorentz transformation Λ. This means Mab(Λ) is a matrix that acts, for example, on a two-component object like a Weyl spinor. The result of the multiplication with this matrix is sim- ply that the components of the object in question get mixed and are multiplied with constant factors. If our object Φ changes in space and time, it is a function of coordinates177 Φ = Φ(x) and these coordi- 177 Here x is a shorthand notation for all spacetime coordinates t, x, y, znates are affected by the Lorentz transformations, too. In general we have xμ → Λμ ν xν,(3.246) where Λμ ν denotes the vector representation (= ( 1 2 , 1 2 ) representation) of the Lorentz transformation in question. We have in this case178 178 Most books use the Wigner con- vention for symmetry operators: Φa(x) → Mab(Λ)Φb(Λ−1x), but unfortunately there is at this point no way to motivate this convention. Φa(x) → Mab(Λ)Φb(Λx).(3.247) Our transformation will therefore consist of two parts. One part, rep- resented by a ﬁnite-dimensional representation, acting on Φa and a second part that transforms the spacetime coordinates x. This sec- ond part will act on an inﬁnite-dimensional179 vector space and we 179 Each component of Φ is now a function of x. The corresponding operators act on Φa(x), i.e. functions of the coordinates and the space of functions is in this context inﬁnite- dimensional. The reason that the space of functions is inﬁnite-dimensional is that we need an inﬁnite number of basis functions. The expansion of an arbitrary function in terms of such an inﬁnite number of basis functions is the idea behind the Fourier transform as explained in Appendix D.1. therefore need an inﬁnite-dimensional representation. The inﬁnite- dimensional representation of the Lorentz group is given by differen- tial operators180 180 The symbols ∂ν are a shorthand notation for the partial derivative ∂ ∂ν . Minf μν = i(xμ∂ν − xν∂μ) .(3.248) 88 physics from symmetry You can check by a straightforward computation that Minf μν satisﬁes the Lorentz algebra (Eq. 3.175) and transforms the coordinates as desired. The transformation of the coordinates is now given by181181 Recall the deﬁnition of Mμν in Eq. 3.173. The components of ωμν can then be directly related to the usual rotation angles θi = 1 2 ϵijkωjk and the boost parameters φi = ω0i. Φ′(Λx)= e−i ωμν 2 Minf μν Φ(x),(3.249) where the exponential function is, as usual, understood in terms of its series expansion. The complete transformation is then a com- bination of a transformation generated by the ﬁnite-dimensional representation Mﬁn μν and a transformation generated by the inﬁnite- dimensional representation Minf μν of the generators: Φa(x) → (e−i ωμν 2 Mﬁn μν )b a e−i ωμν 2 Minf μν Φb(x).(3.250) Because our matrices Mﬁn μν are ﬁnite-dimensional and constant we can put the two exponents together Φa(x) → (e−i ωμν 2 Mμν )b a Φb(x) (3.251) with Mμν = Mﬁn μν + Minf μν . This representation of the generators of the Lorentz group is called ﬁeld representation. We can now talk about a different kind of transformation: transla- tions, which means transformations to another location in spacetime. Translations do not mix the components and therefore, we need no ﬁnite-dimensional representation. However, it’s quite easy to ﬁnd the inﬁnite-dimensional representation for translations. These are not part of the Lorentz group, but the laws of nature should be lo- cation independent. The Lorentz group (boosts and rotations) plus translations is called the Poincaré group, which is the topic of the next section. Nevertheless, we will introduce the inﬁnite-dimensional representation of translations already here. For simplicity, we restrict ourselves to one dimension. In this case an inﬁnitesimal translation of a function, along the x-axis is given by182182 For a non-inﬁnitesimal ϵ, we would get here inﬁnitely many terms. But for an inﬁnitesimal ϵ,weuse ϵ2 ≈ 0 and therefore neglect all higher order terms. Φ(x) → Φ(x + ϵ)= Φ(x)+ ∂xΦ(x) ︸ ︷︷ ︸ \"rate of change\" along the x-axis ϵ, which is, of course, the ﬁrst term of the Taylor series expansion. It is conventional in physics to add an extra −i to the generator and we therefore deﬁne Pi ≡−i∂i.(3.252) With this deﬁnition an arbitrary, ﬁnite translation is183183 Using i2 = −1. lie group theory 89 Φ(x) → Φ(x + a)= e−iai Pi Φ(x)= e−ai∂i Φ(x) , where ai denotes the amount we want to translate in each direction. If we write the exponential function as Taylor series184, this equation 184 This is derived in Appendix B.4.1. can simply be seen as the Taylor expansion185 for Φ(x + a).If we 185 This is derived in Appendix B.3. want to transform to another point in time we use P0 = i∂0, for a different location we use Pi = −i∂i. Now, let’s move on to the full spacetime symmetry group of na- ture: the Poincaré group. 3.8 The Poincaré Group The Lorentz group includes rotations and boosts. Further transforma- tions that leave the speed of light invariant are translations in space and time, because measuring the speed of light at a different point in spacetime does not change its value. If we add these symmetries to the Lorentz group we get the Poincaré group186 186 The Poincaré group is not the direct, but the semi-direct, sum of the Lorentz group and translations, but for the purpose of this text we can neglect this technical detail.Poincaré group = Lorentz group plus translations = Rotations plus boosts plus translations (3.253) The generators of the Poincaré group are the generators of the Lorentz group Ji, Ki plus the generators of translations Pμ. In terms of Ji, Ki and Pμ the Lie algebra reads187 187 This is not very enlightening, but included for completeness. [Ji, Jj]= iϵijk Jk (3.254) [Ji, Kj]= iϵijkKk (3.255) [Ki, Kj]= −iϵijk Jk (3.256) [Ji, Pj]= iϵijkPk (3.257) [Ji, P0]= 0(3.258) [Ki, Pj]= iδijP0 (3.259) [Ki, P0]= −iPi .(3.260) 90 physics from symmetry Because this looks like a huge mess it is conventional to write this in terms of Mμν, which was deﬁned by Ji = 1 2 ϵijk Mjk (3.261) Ki = M0i.(3.262) With Mμν the Poincaré algebra reads [Pμ, Pν]= 0(3.263) [Mμν, Pρ]= i(ημρPν − ηνρPμ) (3.264) and of course still have [Mμν, Mρσ]= i(ημρ Mνσ − ημσ Mνρ − ηνρ Mμσ + ηνσ Mμρ) .(3.265) For this quite complicated group it is very useful to label the rep- resentations by using the ﬁxed scalar values of the Casimir operators. The Poincaré group has two Casimir operators188 . The ﬁrst one is: 188 Recall that a Casimir operator is deﬁned as an operator, constructed from the generators, that commutes with all other generators. PμPμ =: m2.(3.266) We give the scalar value the suggestive name m2, because we will learn later that it coincides with the mass of particles189. 189 Don’t worry, this will make much more sense later. The second Casimir operator is WμWμ, where190 190 ϵμνρσ is the four-dimensional Levi- Civita symbol, which is deﬁned in Appendix B.5.5. Wμ = 1 2 ϵμνρσPν Mρσ (3.267) which is called the Pauli-Lubanski four-vector. In a lengthy com- putation it can be justiﬁed, that in addition to m, we use the number j ≡ j1 + j2 as a label. This label is commonly called spin. For the moment this is just a name. Later we will understand why the name spin is appropriate. Exactly as for the Lorentz group, we have one ji for each of the two191 representations of the SU(2) algebra. 191 Recall that the complexiﬁed Lie al- gebra of the Lorentz group could be seen to consist of two copies of the Lie algebra of SU(2). The representations of SU(2) could be labelled by a number j and consequently we used for repre- sentations of the double cover of the Lorentz group two numbers (j1, j2). For example, the (j1, j2)=(0, 0) representation is called spin 0 representation192. The (j1, j2)=( 1 2 ,0) and (j1, j2)=(0, 1 2 ) are both 192 j1 + j2 = 0 + 0 = 0 called spin 1 2 representations193 and analogously the (j1, j2)=( 1 2 , 1 2 ) 193 j1 + j2 = 1 2 + 0 = 0 + 1 2 = 1 2 representation is called spin 1 representation194. 194 j1 + j2 = 1 2 + 1 2 = 1 The message to take away is that each representation is labelled by two scalar values: m and j. While m can take on arbitrary values, j is restricted to half-integer or integer values. lie group theory 91 3.9 Elementary Particles The labels for the irreducible representations of double cover of the Poincaré group, mass m and by their spin (= j here), are how ele- mentary particles are labeled in physics195. An elementary particle 195 Some physicists go even farther and say that elementary particles are the irreducible representations of the Poincaré group. with given labels m and spin, say j = 1 2 , is described by an object, which transforms according to the m, spin 1 2 representation of the Poincaré group. More labels, called charges, will follow later from internal sym- metries. These labels are used to deﬁne an elementary particle. For example, an electron is deﬁned by the following labels • mass: 9, 109 · 10−31 kg, • spin: 1 2 , • electric charge: 1, 602 · 10−19 C, • weak charge, called weak isospin: − 1 2 , • strong charge, called color charge: 0. These labels determine how a given elementary particle behaves in experiments. The representations we derived in this chapter deﬁne how we can describe them mathematically. An elementary particle with196 196 Remember that in the introductory remarks about what we can’t derive, it was said there is no real reason to stop here after three representations. We could go on to higher dimensional representations, but there are no ele- mentary particles, for example, with spin 3 2 . Nevertheless, such representa- tions can be used to describe composite objects. In addition, there are many physicists that believe the fundamen- tal particle mediating gravity, called graviton, has spin 2 and therefore a corresponding higher dimensional representation must be used to describe it. • spin 0 is described by an object Φ, called scalar, that transforms according to the (0, 0), called spin 0 representation or scalar repre- sentation. For example, the Higgs particle is described by a scalar ﬁeld. • spin 1 2 is described by an object Ψ, called spinor, that transforms according to the ( 1 2 ,0) ⊕ (0, 1 2 ) representation, called spin 1 2 rep- resentation or spinor representation. For example, electrons and quarks are described by spinors. • spin 1 is described by an object A, called vector, that transforms according to the ( 1 2 , 1 2 ), called spin 1 representation or vector representation. For example photons are described by vectors. This is an incredibly important, deep and beautiful insight, so again: What we get from deriving the irreducible representations of the Poincaré group are the mathematical tools we need to describe all elementary particles. To describe spin 0 particles, like the Higgs Boson, we use mathematical objects, called scalars, that transform 92 physics from symmetry according to the spin 0 representation. To describe spin 1 2 particles like electrons, neutrinos, quarks etc. we use mathematical objects, called spinors, that transform according to the spin 1 2 representation. To describe photons or other particles with spin 1 we use objects, called vectors, transforming according to the spin 1 representation. An explanation for the very suggestive name spin, will be given in Section 8.5.5, after we talked about how and what we measure in experiments. We ﬁrst have to know how we are able to ﬁnd out if something is spinning, before we can justify the name spin. At this point, spin is merely a label. Further Reading Tips • John Stillwell - Naive Lie Theory197 is a very readable, math 197 John Stillwell. Naive Lie Theory. Springer, 1st edition, August 2008. ISBN 978-0387782140 orientated introduction to Lie Theory. • Nadir Jeevanjee - An Introduction to Tensors and Group Theory for Physicists198 is a very good introduction, with strong focus on 198 Nadir Jeevanjee. An Introduction to Tensors and Group Theory for Physicists. Birkhaeuser, 1st edition, August 2011. ISBN 978-0817647148 the usage of group theory in physics. • Howard Georgi - Lie Algebras In Particle Physics199 is a great 199 Howard Georgi. Lie Algebras In Particle Physics: from Isospin To Uniﬁed Theories (Frontiers in Physics). West- view Press, 2 edition, 10 1999. ISBN 9780738202334 book to learn more about the parts of Lie group theory that are relevant for particle physics. 3.10 Appendix: Rotations in a Complex Vector Space The concept of transformations that preserve the inner product can also be used in complex vector spaces. We want the inner product of a vector with itself to be a real number, because by deﬁnition this should result in the squared length of the vector. A complex number would make little sense as the length of the vector. Therefore, the inner product of complex vector spaces is deﬁned with additional complex conjugation200200 Because for z = a + ib we have z⋆ = a − ib and therefore z⋆z =(a + ib)(a − ib)= a2 + b2, which is real. a · a =(aT)⋆a = a†a.(3.268) The symbol †, called dagger, denotes Hermitian conjugation, which means complex conjugation and transposing. We see that a trans- formation that preserves this inner product must fulﬁl the condition U†U = 1: (Ua) · (Ua)= a†U†Ua = a†a .(3.269) Transformations like these form groups that are called U(n), where n denotes the dimensions of the complex vector space and \"U\" stands lie group theory 93 for unitary. Again the groups SU(n) are called \"special\", because their elements fulﬁl the additional condition det(U)= 1. 3.11 Appendix: Manifolds A manifold M is a set of points with a continuous 1-1 map from each open neighborhood onto an open set of Rn. In easy words this means that a manifold M looks locally like the standard Rn. This map from each open neighborhood of M onto Rn associates with each point P of M an n-tupel (x1(P), ...xn(P)) where the numbers x1(P), ...xn(P) are called the coordinates of the point P. Therefore another way of thinking about a n-dimensional manifold is that it’s a set, which can be given n independent coordinates ins some neighborhood of any point. An example for a manifold is the surface of a ball. The surface of the three-dimensional ball is called two-sphere S2 and is deﬁned as the set of points in R3 for which x2 + y2 + z2 = r holds, where r is the radius of the sphere. Take note that the surface of the three- dimensional ball is two-dimensional, because the deﬁnition involves 3 coordinates and one condition, which eliminates one degree of freedom. That is why it’s called mathematically two-sphere. To see that the sphere is a manifold we need a map onto R2. This map is given by the usual spherical coordinates. Fig. 3.9: Illustration of the map from one neighborhood of the sphere on to Rn. Almost all points on the surface of the sphere can be identiﬁed unambiguously with a coordinate combination of the form (ϕ, θ). Al- most all! Where is the pole ϕ = 0 mapped to? There is no one-to-one identiﬁcation possible, because the pole is mapped to a whole line, 94 physics from symmetry as indicated in the image. Therefore this map does not work for the complete sphere and we need another map in the neighborhood of the pole to describe things there. A similar problem occurs for the map on the semicircle θ = 0. Each point can be mapped in the R2 to θ = 0 and θ = 2π, which is again not a one-to-one map. This illustrates the fact that for manifolds there is in general not one coor- dinate system for all points of the manifold, only local coordinates, which are valid in some neighborhood. This is no problem because the deﬁning feature of a manifold is that it looks locally like Rn. The spherical coordinate map is only valid in the open neighbor- hood 0 < ϕ < π,0 < θ < 2π and we need a second map to cover the whole sphere. We can use, for example, a second spherical coor- dinate system with different orientation, such that the problematic poles lie at different points for this map and no longer at ϕ = 0. With this second map every point of the sphere has a map onto R2 and the two-sphere can be seen to be a manifold. A trivial example for a manifold is of course Rn. 4 The Framework The basic idea of this chapter is that we get the correct equations of nature, by minimizing something. What could this something be? One thing is for sure: the object shouldn’t change under Lorentz transformations, because otherwise we get different laws of nature for different frames of reference. In mathematical terms this means the object we are searching for must be a scalar, which is an object transforming according to the (0, 0) representation of the Lorentz group. Together with the restriction to the simplest possible choice this will be enough to derive the correct equations of nature. Nature likes it simple. Starting with this idea, we will introduce a framework called the Lagrangian formalism. By minimizing the central object of the the- ory we get the equations of motion that describe the physical system in question. The result of this minimization procedure is called the Euler-Lagrange equations. The Lagrangian formalism enables us to derive one of the most- important theorems of modern physics: Noether’s Theorem. This theorem reveals the deep connection between symmetries and con- served quantities1. We will use this connection in the next chapter to 1 A conserved quantity is a quantity that does not change in time. Famous examples are the energy or the momen- tum of a given system. In mathematical terms this means ∂tQ = 0 → Q =const. understand how the quantities that we measure in experiments can be described by the theory. 4.1 Lagrangian Formalism The Lagrangian formalism is an incredibly powerful framework2 that 2 There are of course other frameworks, e.g. the Hamiltonian formalism, which has the Hamiltonian as its central object. The problem with the Hamilto- nian is that it is not Lorentz invariant, because the energy, it represents, is just one component of the covariant energy-impulse vector. is used in most parts of fundamental physics. It is relatively simple, because the fundamental object, the Lagrangian, is a scalar3. The 3 A scalar is an object transforming according to the (0, 0) representation of the Lorentz group. This means that it does not change at all under Lorentz transformations. formalism is extremely useful if we want to use symmetry consider- ations. If we demand the action, the integral over the Lagrangian, to © Springer International Publishing AG 2018 J. Schwichtenberg, Physics from Symmetry, Undergraduate Lecture Notes in Physics, https://doi.org/10.1007/978-3-319-66631-0_4 96 physics from symmetry be invariant under some symmetry transformation, we ensure that the dynamics of the system in question respect this symmetry. 4.1.1 Fermat’s Principle \"Whenever any action occurs in nature, the quantity of action em- ployed by this change is the least possible.\" - Pierre de Maupertius44 \"Recherche des loix du mouvement\" (1746) The basic idea of the Lagrangian formalism emerged from Fer- mat’s principle, which states that light always chooses the path q(t) between two points in space that minimizes the time it takes to travel between the points. To put this into mathematical terms, we deﬁne the action of a given path q(t) as Slight[q(t)] = ∫ dt and our task is then to ﬁnd the speciﬁc path q(t) that minimizes the action5. To ﬁnd the minimum6 of a given function f (x), we take the 5 The action is here simply the integral over the time for a speciﬁc path, i.e. the total time. However, in general the action will be a bit more complicated, as we will see in a moment. 6 In general, we want to ﬁnd extrema, which means minimums and maxi- mums. The idea outlined in the next section is capable of ﬁnding both. Nev- ertheless, we will continue to talk about minimums. derivative and set it to zero: f ′(x) ! = 0. The solutions of this equation are the extrema of the functions. Here we want to ﬁnd the minimum of a functional S[q(t)], which is a function S of a function q(t).To ﬁnd the minimum of a functional, we need a new mathematical idea, called variational calculus. Fig. 4.1: Variations of a path with ﬁxed starting- and end-point. 4.1.2 Variational Calculus - the Basic Idea If we want to develop a new theory capable of ﬁnding the minima of functionals, we need to take a step back and think about what charac- terises a mathematical minimum. The answer of variational calculus is that a minimum is characterised by its immediate neighbourhood. For example, let’s ﬁnd the minimum xmin of an ordinary function f (x)= 3x2 + x. We start by looking at one speciﬁc x = a and take a close look at its neighborhood. Mathematically this means a + ϵ, where ϵ denotes an inﬁnitesimal (positive or negative) variation. We put this variation around a into our function f (x): f (a + ϵ)= 3(a + ϵ)2 +(a + ϵ)= 3(a2 + 2aϵ + ϵ2)+ a + ϵ. Now the crucial observation is that if a is a minimum, ﬁrst order variations in ϵ must vanish. Otherwise we can choose ϵ to be neg- ative ϵ < 0 and then f (a + ϵ) is smaller than f (a). Therefore, we collect all terms linear in ϵ and demand that they vanish: 3 · 2aϵ + ϵ ! = 0 → 6a + 1 ! = 0. the framework 97 This equation is solved by xmin = a = −1 6 . This is, of course, exactly the same result that we get if we take the derivative f (x)= 3x2 + x → f ′(x)= 6x + 1 and demand this to be zero. In terms of ordinary functions this is just another way of doing the same thing. However, variational calculus is additionally able to ﬁnd the extrema of functionals. We will see in a moment how this works for a general action functional. The idea of the Lagrangian formalism is that a principle like the Fermat principle for light exists for massive objects, too. Unfortu- nately, massive objects do not simply obey Fermat’s principle. Yet, we can try a more general ansatz S[q(t)] = ∫ L dt, where L is, in general, a non-constant function called the Lagrangian. This function happens to be constant for light, but a general La- grangian is a function of the position q(t) of the object in question. In addition, the Lagrangian can depend on the velocity of the object: L = L(q(t), ∂ ∂t q(t)). This will be discussed in more detail in the next section7. Before we take a closer look at the usage of the variational 7 Our task will be to ﬁnd the path q(t) with lowest possible action for a given Lagrangian and given initial conditions. Before we are able to do that, we need to ﬁnd the correct Lagrangian, describing the physical system in question. Here is where the symmetries we talked about in the last chapters come in handy. Demanding that the Lagrangian is invariant under all transformations of the Lorentz group, will lead us to the correct Lagrangians. calculus idea for a functional like this, we need to talk about two small things. 4.2 Restrictions As already noted in Chapter 1.1 there are restrictions to our present theories, that, so far, we can’t motivate from ﬁrst principles. We only know that we must respect them to get a sensible theory. One important restriction is that we are only allowed to use the lowest, non-trivial derivatives in the Lagrangian. Trivial in this con- text means with no inﬂuence of the dynamics of the system, i.e. on the equations of motion. For some theories this will be ﬁrst order and for others second order derivatives. The lowest order of a given theory is determined by the condition that the Lagrangian must be Lorentz invariant8, because otherwise we would get different equa- 8 In fact, the action must be Lorentz invariant, but if the Lagrangian is Lorentz invariant, the action certainly is, too. tions of motions for different frames of reference. For some theories we can’t get an invariant term with ﬁrst order derivatives and there- fore second order derivatives are the lowest possible order. We simply do not know how to work with theories including higher order derivatives and there are deep systematic problems 98 physics from symmetry with such theories9. In addition, higher order derivatives in the La- 9 These problems are known as Os- trogradski instabilities. The energy in theories with higher order deriva- tives can be arbitrarily negative, which would mean that every state in such theory would always decay into lower energy states. There are no stable states in such theories. grangian lead to higher order derivatives in the equations of motion and therefore more initial conditions would be required. It is sometimes claimed that the constraint to ﬁrst order derivatives is a consequence of our demand to get a local10 theory, but this only 10 Locality is a consequence of the basis postulates of special relativity, as shown in Section 2.4. rules out an inﬁnite number of derivatives. A non-local interaction is of the form11 11 We will discuss Lagrangians for particle theories, where we search for particle paths and Lagrangians for ﬁeld theories, where we search for ﬁeld conﬁgurations Φ(x). This is the topic of the next section. Φ(x − h)Φ(x),(4.1) that is, two ﬁelds interacting with each other at two different points in spacetime with arbitrary distance h. Using the Taylor expansion we can write Φ(x − h)= ∞ ∑ k=0 (( ∂ ∂x )k Φ(x)∣ ∣ ∣x=h ) (h)k k! ,(4.2) which shows that allowing an inﬁnite number of derivatives would result in a non-local interaction theory. Another restriction is that in order to get a theory describing free (=non-interacting) ﬁelds/particles we must stop at second order in the ﬁeld Φ(x). This means we only include the terms1212 From another perspective, this means again that we only include the lowest possible, non-trivial terms. Terms with Φ0 and Φ1 do not lead to terms proportional to Φ in the Lagrangian, as we will see later and therefore we use once more only the lowest possible, non-trivial order, now in Φ. Φ0, Φ1, Φ2 into our considerations. For example, a term of the form Φ2∂μΦ is of third order in Φ and therefore not included in the Lagrangian for our free theory. 4.3 Particle Theories vs. Field Theories Currently we have two frameworks to describe nature. On the one hand, we have particle theories that describe physical systems in terms of positions of particles depending on time, i.e. ⃗q = ⃗q(t).We use the symbol q instead of x, because there is no need to describe nature in terms of Cartesian coordinates13. For such theories the 13 Another possibility are, for example, spherical coordinates. Lagrangian depends on the position ⃗q, the velocity ∂t⃗q and the time t: L = L(⃗q, ∂t⃗q, t).(4.3) A famous example is the Lagrangian L = 1 2 m ˙⃗q2, from which we can derive Newton’s equation of motion for classical mechanics. This will be discussed later in great detail. On the other hand, we have ﬁeld theories that do not use the location ⃗q(t) of individual particles to describe nature, but ﬁelds14.In 14 An especially beautiful feature of quantum ﬁeld theory is how particles emerge. In Chapter 6 we will see that ﬁelds are able to create and destroy particles. the framework 99 such theories space and time form the stage the ﬁelds Φ(⃗x, t) act on. Using the restrictions we get15 15 The usage of a different symbol L here is intentional, because in ﬁeld theories we will work most of the time with the Lagrangian density L . The Lagrangian density is related to the Lagrangian via L = ∫ d3xL . L = L (Φ(⃗x, t), ∂μΦ(⃗x, t),⃗x, t) (4.4) A famous example is the Lagrangian L = 1 2 (∂μΦ∂μΦ − m2Φ2), from which we will derive the Klein-Gordon equation. The big advantage of ﬁeld theories is that they treat space and time on an equal footing. In a particle theory we use the space coor- dinates ⃗q(t) to describe our particle as a function of time. Notably, there is no term like ∂⃗qt in the Lagrangian and if it would be there, how should we interpret it? It is clear what we mean when we talk about the location of a particle, but there is no obvious way to make sense of a similar sentence for time. Having discussed all this, we are able to return to the original minimizing problem, proposed at the beginning of this chapter. We want to ﬁnd the minimum of some functional S[q(t)] = ∫ Ldt, which will give us the correct equations of motion. The solutions of these equations are for particles the correct paths that minimize the functional. For a ﬁeld theory the solutions are the correct ﬁeld conﬁgurations. For the moment, do not worry about the object L, because we will describe in the following chapters in great detail how we can derive the correct Lagrangian L for the systems in question. Here, we work with a general L and use the machinery of variational calculus, introduced above, to derive the minimum of the functional S[q(t)]. This minimization procedure will give us the equations of motion for the system. 4.4 Euler-Lagrange Equation We start with particle theory and this means, we want to ﬁnd out how a particle moves between two ﬁxed points. The mathematical problem we have to solve is to ﬁnd the function q(t) for which the action S = ∫ t2 t1 L (q(t), dq(t) dt , t) dt is an extremum (maximum or minimum). We use the notation ˙q(t) ≡ dq(t) dt . 100 physics from symmetry Analogous to the example above, we ﬁx q(t)= a(t) and vary this particle path a little bit a(t)+ ϵ(t) where ϵ is again inﬁnitesimal. Considering a particle, we are not only able to vary the path, but in the same way we can vary the velocity ˙a(t)+ ˙ϵ(t) with ˙ϵ(t)= dϵ(t) dt . At the boundary, the transformed path must be equivalent to the untransformed path: 0 = ϵ(t1)= ϵ(t2),(4.5) because we are searching for the path between two ﬁxed points that extremizes the action integral. This variation of the ﬁxed function results in the functional S = ∫ t2 t1 dtL(q + ϵ, ˙q + ˙ϵ, t). Analogous to the example above, where we searched for the mini- mum of a function, we will demand here that the terms linear in the variation ϵ vanish. Because we work with a general L, we expand it as Taylor series16 and demand that the ﬁrst order terms vanish 16 We are using a generalization of the formula, derived in Appendix B.3 for functions with more than one variable: L(q + ϵ, ˙q + ˙ϵ, t)= L(q)+(q + ϵ − q) ∂L ∂q +( ˙q + ˙ϵ − ˙q) ∂L ∂ ˙q + ... = L(q)+ ϵ ∂L ∂q + ˙ϵ ∂L ∂ ˙q + ... ∫ t2 t1 dt [ϵ(t) ∂L ∂q + ( d dt ϵ(t)) ∂L ∂ ˙q ] ! = 0. (4.6) To proceed further, we need to ﬁnd a way to bracket ϵ(t) out. This is necessary, because ϵ(t) is an arbitrary variation and when we bracket it out, we know that everything inside the brackets has to vanish if the total result is zero. So far we have one term that gets multiplied with ϵ(t) and a second term that gets multiplied with d dt ϵ(t).To bracket ϵ(t) out, we need get rid of the derivative. To achieve this, we integrate the last term by parts17, which yields 17 Integration by parts is a direct conse- quence of the product rule and derived in Appendix B.2. ∫ t2 t1 dt ( d dt ϵ(t)) ∂L(q, ˙q, t) ∂ ˙q = ϵ(t) ∂L(q, ˙q, t) ∂ ˙q ∣ ∣ ∣ ∣ t2 t1 − ∫ t2 t1 dtϵ(t) d dt ( ∂L(q, ˙q, t) ∂ ˙q ) . Using Eq. 4.5 we have ϵ(t) ∂L(q, ˙q, t) ∂ ˙q ∣ ∣ ∣ ∣ t2 t1 = 0. So, we can rewrite Eq. 4.6 as ∫ t2 t1 dtϵ(t) [ ∂L(q, ˙q, t) ∂q − d dt ( ∂L(q, ˙q, t) ∂ ˙q )] ! = 0 the framework 101 and we can see that this only vanishes for arbitrary variations ϵ(t) if the expression in the square bracket[]is identically zero. This yields18 18 Maybe you wonder about the two different symbols for derivatives. d dt is called the total derivative with respect to t, whereas ∂ ∂t is called the partial derivative. The total derivative gives us the total change, which is for a function f given by sum of the change rates, also known as partial derivatives, times the change of the quantity itself. For example, the total change of a function f (x(t), y(t), z(t)) in three dimensional space is given by df dt = ∂ f ∂x ∂x ∂t + ∂ f ∂y ∂y ∂t + ∂ f ∂z ∂z ∂t + ∂ f ∂t ∂t ∂t . The change rate times the distance it is changed. In contrast the partial derivative is just one part of this total change. For a function that does not explicitly depend on t the partial derivative is zero. For example, for f (x(t), y(t)) = x2y + y3, we have ∂ f ∂t = 0, but ∂ f ∂x = 2xy ̸= 0 and ∂ f ∂y = x2 + 3y2 ̸= 0. Therefore, df dt = 2xy ∂x ∂t +(x2 + 3y2) ∂y ∂t . In contrast for another function g(x(t), y(t), t)= x2t + y we have ∂g ∂t = x2. ∂L(q, ˙q, t) ∂q − d dt ( ∂L(q, ˙q, t) ∂ ˙q ) = 0, (4.7) which is the famous Euler-Lagrange equation. For a ﬁeld theory we can follow a similar route. First notice that in this case we treat time and space equally. Therefore, we introduce the Lagrangian density L : L = ∫ d3xL (Φi, ∂μΦi) (4.8) and we can write the action in terms of this Lagrangian density S = ∫ dtL = ∫ d4xL (Φi, ∂μΦi) .(4.9) Following the same steps as above, we get the equations19 of motion 19 Plural because we get one equa- tion for each ﬁeld component, i.e. Φ1, Φ2,. . .. for a ﬁeld theory: ∂L ∂Φi − ∂μ ( ∂L ∂(∂μΦi) ) = 0. (4.10) In the next section we will derive, using the Lagrangian formalism, one of the most important theorems of modern physics. We need this theorem to see the deep connection between symmetries and conserved quantities. The conserved quantities are the appropriate quantities20 to describe nature and from this theorem we learn how 20 We can see them as anchors in an otherwise extremely complicated world. While everything changes, the conserved quantities stay the same. we can work with them in a theoretical context. 4.5 Noether’s Theorem Noether’s theorem shows that each symmetry of the Lagrangian is directly related to one conserved quantity. Or formulated slightly different: The notions physicists commonly use to describe nature (the conserved quantities) are directly connected to symmetries. This is one of the most beautiful insights in the history of science. 4.5.1 Noether’s Theorem for Particle Theories Let’s have a look at what we can say about conserved quantities in particle theories. We will restrict to continuous symmetries, because then we can look at inﬁnitesimal changes. As we have seen in earlier chapters, we can build up ﬁnite changes by repetition of inﬁnitesimal 102 physics from symmetry changes. The invariance of the Lagrangian under an inﬁnitesimal transformation21 q → q′ = q + δq can be expressed mathematically 21 The symbol for a small variation δ may not be confused with the symbol for partial derivatives ∂. δL = L (q, dq dt , t) −L (q + δq, d(q + δq) dt , t) = L (q, dq dt , t) −L (q + δq, dq dt + dδq dt , t) ! = 0. (4.11) Demanding that the Lagrangian is invariant can be too restrictive. What really needs to be invariant for the dynamics to stay the same is the action and not the Lagrangian. Of course, if the Lagrangian is invariant, the action is automatically invariant: δS = ∫ dtL (q, dq dt , t) − ∫ dtL (q + δq, dq dt + dδq dt , t) = ∫ dtδL =︸︷︷︸ if δL=0 0. (4.12) How can the Lagrangian change, while the action stays the same? It turns out we can always add the total time derivative of a function G to the Lagrangian L→L + dG dt without changing the action, because2222 Using δG = ∂G ∂q δq, because G = G(q) and we vary q. Therefore the variation of G is given by the rate of change ∂G ∂q times the variation of q. δS → δS′ = δS + ∫ t2 t1 dt d dt δG = δS + ∂G ∂q δq∣ ∣t2 t1 ︸ ︷︷ ︸ =0 because δq(t1)=δq(t2)=0 . In the last step, we use that the variation δq vanishes at the initial and ﬁnal times (t1, t2). We conclude, there is no need for us to demand that the variation of the Lagrangian δL vanishes, rather we have the less restrictive condition δL ! = dG dt .(4.13) This means the Lagrangian can change in this way without chang- ing the action. Therefore the equation of motion stay the same even though the Lagrangian changes, as long as the change can be written as total derivative of some function: dG dt . Rewriting Eq. 4.11, now with dG dt instead of 0 on the right hand side yields δL = L (q, dq dt , t) −L (q + δq, dq dt + dδq dt , t) ! = dG dt (4.14) We expand the second term as Taylor series and keep only terms that are ﬁrst order in δq, because δq is inﬁnitesimal, and use the notation dq dt = ˙q: → δL = L−L− ∂L ∂q δq − ∂L ∂ ˙q δ ˙q ! = dG dt the framework 103 → δL = − ∂L ∂q δq − ∂L ∂ ˙q δ ˙q ! = dG dt .(4.15) We can rewrite Eq. 4.15 by using the Euler-Lagrange equation23. This 23 Eq. 4.7: ∂L ∂q = d dt ( ∂L ∂ ˙q ) yields → δL = − d dt ( ∂L ∂ ˙q ) δq − ∂L ∂ ˙q δ ˙q = dG dt . This can be rewritten, using the product rule24 24 If you’re unsure about the product rule, have a look at Appendix B.1. → δL = − d dt ( ∂L ∂ ˙q δq) = dG dt → d dt ( ∂L ∂ ˙q δq + G) ︸ ︷︷ ︸ ≡J = 0. (4.16) Therefore, we have found a quantity J that is conserved in time: J = ∂L ∂ ˙q δq + G,(4.17) because we have d dt J = 0 → J = const. To illustrate this, we will use one later result from Section 10.2: Newton’s second law for a free particle with constant mass25 25 If q denotes the position of some ob- ject, dq dt = ˙q is the velocity of the object and d dt dq dt = d2q dt2 = ¨q the acceleration.m ¨⃗q = 0. (4.18) The Lagrangian that reproduces this famous equation of motion is26 26 We work now with more than one spatial dimension, which means instead of q and a, we use vectors ⃗q and ⃗a. L = 1 2 m ˙⃗q2 (4.19) as you can check, by putting it into the Euler-Lagrange equation (Eq. 4.7). Let us compute for different symmetries of this Lagrangian the corresponding conserved quantities. Our Lagrangian is invariant (δL = 0) under spatial translations ⃗q → ⃗q′ = ⃗q +⃗a, where ⃗a denotes some constant vector, because L = 1 2 m ˙⃗q2 does not depend on ⃗q. The corresponding conserved quantity reads27 27 Here G = 0, which certainly fulﬁls the condition in Eq. 4.13. Jtrans = ∂L ∂ ˙⃗q ⃗a = m ˙⃗q⃗a = ⃗p⃗a,(4.20) where ⃗p = m ˙⃗q is what we usually call momentum in classical me- chanics. The equation d dt J = 0 holds for arbitrary ⃗a and therefore momentum is conserved, because the Lagrangian is invariant under spatial translations. 104 physics from symmetry We now want to look at rotations and therefore need more than one dimension, because a rotation in one dimension makes no sense. It is useful to use an index notation instead of the usual vector no- tation here, because then we can simply rewrite all equations with q → qi to be able to incorporate changes in more than one dimension. Let’s have a look at an inﬁnitesimal rotation28 qi → q′ i = qi + ϵijkqjak 28 Here we write the generator of rotations by using the Levi-Civita symbol. This was explained in the text below Eq. 3.62. and therefore δqi = ϵijkqjak. Our Lagrangian is invariant under such transformations, because again, L = 1 2 m ˙⃗q2 does not depend on q, and the corresponding conserved quantity is29 29 This was derived in Eq. 4.16, again we work here with G = 0. Jrot = ∂L(qi, ˙qi, t) ∂ ˙qi δqi = ∂L(qi, ˙qi, t) ∂ ˙qi ϵijkqjak = m ˙qiϵijkqjak = piϵijkqjak → Jrot =(⃗p × ⃗q) ·⃗a ≡ ⃗L ·⃗a .(4.21) In the last step we rewrite our term in vector notation, where × is called the cross product and ⃗L is what we usually call angular mo- mentum in classical mechanics. Therefore, invariance under rota- tions leads us to conservation of angular momentum. Next let’s have a look at invariance under time translations30.An 30 This means that physics doesn’t care about if we perform an experiment yesterday, today or in 50 years, given the same initial conditions, the physical laws stay the same. inﬁnitesimal time displacement t → t′ = t + ϵ has the effect δL = L (q(t), dq(t) dt , t) −L (q(t + ϵ), dq(t + ϵ) dt , t + ϵ) = − ∂L ∂q ∂q ∂t ϵ − ∂L ∂ ˙q ∂ ˙q ∂t ϵ − ∂L ∂t ϵ =︸︷︷︸ this is exactly the total derivative − dL dt ϵ,(4.22) which tells us that in general δL ̸= 0, but the condition in Eq. 4.13 is fulﬁlled anyway with G = −L. We can put this into Eq. 4.16, which yields d dt ( ∂L ∂ ˙q ˙q −L) ︸ ︷︷ ︸ ≡H = 0. (4.23) The conserved quantity H is called the Hamiltonian and represents the total energy of the system. For our example Lagrangian, we have H = ∂L ∂ ˙q ˙q −L = ( ∂ ∂ ˙q 1 2 m ˙q2) ︸ ︷︷ ︸ =m ˙q ˙q − 1 2 m ˙q2 = m ˙q2 − 1 2 m ˙q2 = 1 2 m ˙q2,(4.24) which is exactly the kinetic energy of our system. The kinetic energy is the total energy, because we worked without a potential/external the framework 105 force. The Lagrangian that leads to Newton’s second law for a parti- cle in an external potential: m ¨q = dV dq is L = 1 2 m ˙q2 − V(q). The Hamiltonian is then H = 1 2 m ˙q2 + V which is the correct total energy=kinetic energy+potential energy. The conserved quantity that follows from boost invariance is rather strange and the corresponding computation can be found in the appendix Section 4.6. The resulting conserved quantity is ˜Jboost = pt − 1 2 mvt ︸ ︷︷ ︸ ≡ ˜pt −mq = ˜pt − mq.(4.25) We can see that this quantity depends on the starting time and by choosing the starting time appropriately we can make it zero. Be- cause this quantity is conserved, this conservation law tells us that zero stays zero for all times. To summarize for particle theories we have the following connec- tions: • translational invariance in space ⇒ conservation of momentum, • boost invariance31 ⇒ conservation of ˜pt − mq, 31 Another name for a boost is transla- tion in momentum space, because the transformation q → q + vt, changes the momentum to m ˙q → m( ˙q + v). • rotational invariance ⇒ conservation of angular momentum, • translational invariance in time ⇒ conservation of energy. Noether’s theorem shows us why these notions32 are used in every 32 Except for the conserved quantity following from boost invariance.physical theory of nature in one or another form. As long as we have the usual spacetime symmetries of our physical laws, we have momentum, energy and angular momentum as conserved quantities. It is instructive to repeat the above discussion for ﬁeld theories. In ﬁeld theories we have two kinds of symmetries. On the one hand, our Lagrangian can be invariant under spacetime transformations, which means a transformation like a rotation. On the other hand, we can have invariance under transformations of the ﬁeld itself, which are called internal symmetries. 4.5.2 Noether’s Theorem for Field Theories - Spacetime Symmetries For ﬁelds one has to distinguish between different kinds of changes that can happen under spacetime transformations. Observer S′ sees 106 physics from symmetry the ﬁeld Ψ′(x′) whereas observer S sees the ﬁeld Ψ(x). This is the same ﬁeld, just from another perspective and the two observers do not see the same numerical ﬁeld components. The two different descriptions are related by the appropriate transformations of the Lorentz group. We introduced in Section 3.7.11 the ﬁeld representa- tion, which we will be using now. The (inﬁnite-dimensional) differ- ential operator representation changes x → x′. This means by using this representation we can compute the ﬁeld components at a differ- ent point in spacetime or in a rotated frame. The ﬁnite-dimensional representation of the Lorentz group changes Ψ → Ψ′, i.e. mixes the ﬁeld components33. 33 Remember for example, that a Weyl spinor has two- and a vector ﬁeld has four-components. If we look at the vector ﬁeld Aμ = ⎛ ⎜ ⎜ ⎝ A0 A1 A2 A3 ⎞ ⎟ ⎟ ⎠ from a different perspective, i.e. describe it in a rotated coordinate system it can look like A′ μ = ⎛ ⎜ ⎜ ⎝ A′ 0 A′ 1 A′ 2 A′ 3 ⎞ ⎟ ⎟ ⎠ = ⎛ ⎜ ⎜ ⎝ A0 −A2 A1 A3 ⎞ ⎟ ⎟ ⎠. A′ μ and Aμ describe the same ﬁeld in coordinate systems that are rotated by 90◦ around the z-axis relative to each other. A complete transformation, for a ﬁeld that depends on spacetime, needs to consist of both parts. We will look at these parts separately, starting with the change x → x′. For rotations the conserved quantity that follows is not really conserved, because we neglected the second part of the transformation, i.e. the mixing of the ﬁeld components. Only the sum of the two conserved quantities that follow from x → x′ and Ψ → Ψ′ is conserved. To make this more concrete consider a general Lagrangian density L ((Φ(xμ), ∂μΦ(xμ), xμ). Symmetry means we have L ((Φ(xμ), ∂μΦ(xμ), xμ)= L ((Φ′(x′ μ), ∂μΦ′(x′ μ), x′ μ).(4.26) In general, the total change of a function-of-a-function, when the independent functions are changed and the point at which they are evaluated is also changed, is given by3434 If this is new to you: This is often called the total derivative. The total change is given by the sum of the change rates, also known as derivatives, times the change of the quantity itself. For example, the total change of a function f (x, y, z) in three dimensional space is given by ∂ f ∂x δx + ∂ f ∂y δy + ∂ f ∂z δz. The change rate times the distance it is changed. We consider inﬁnitesimal changes and therefore this can be seen as the ﬁrst terms in the Taylor expansion, where we can neglect higher order terms. df (g(x), h(x), ...)= ∂ f ∂g δg + ∂ f ∂h δh + ... + ∂ f ∂x δx.(4.27) Applying this to the Lagrangian yields δL = ∂L ∂Φ δΦ + ∂L ∂(∂μΦ) δ(∂μΦ)+ ∂L ∂xμ δxμ,(4.28) which we can rewrite using the Euler-Lagrange equations35 35 See Eq. 4.10: ∂L ∂Φ = ∂μ( ∂L ∂(∂μ Φ) ) δL = ∂μ ( ∂L ∂(∂μΦ) ) δΦ + ∂L ∂(∂μΦ) δ(∂μΦ) ︸ ︷︷ ︸ =∂μδΦ + ∂L ∂xμ δxμ =︸︷︷︸ Product rule ∂μ ( ∂L ∂(∂μΦ) δΦ) + ∂L ∂xμ δxμ .(4.29) The variation δΦ has now two parts δΦ = ϵμνSμνΦ(x) − ∂Φ(x) ∂xμ δxμ,(4.30) the framework 107 with the transformation parameters ϵμν, the transformation operator Sμν in the corresponding ﬁnite-dimensional representation and a conventional minus sign. Sμν is related to the generators of rotations by Ji = 1 2 ϵijkSjk and to the generators of boosts by Ki = S0i, analogous to the deﬁnition of Mμν in Eq. 3.173. This deﬁnition of the quantity Sμν enables us to work with the generators of rotations and boosts at the same time. The ﬁrst part is only important for rotations and boosts, because translations do not mix the ﬁeld components. For boosts the con- served quantity will not be very enlightening, just as in the particle case, so in fact this term will become only relevant for rotational symmetry. Let’s start with the simplest ﬁeld transformation: a translation in spacetime xμ → x′ μ = xμ + δxμ = xμ + aμ.(4.31) For translations we have ϵμν = 0, because ﬁeld components do not mix under translations and therefore Eq. 4.30 reads δΦ = − ∂Φ ∂xμ δxμ . Thus if we want to investigate the consequences of invariance (δL = 0), we get from Eq. 4.29 −∂ν ( ∂L ∂(∂νΦ) ∂Φ ∂xμ δxμ ) + ∂L ∂xμ δxμ = 0(4.32) →−∂ν ( ∂L ∂(∂νΦ) ∂Φ ∂xμ − δν μL ) δxμ = 0. (4.33) From Eq. 4.31 we have δxμ = aμ, which we now put into Eq. 4.33. This yields −∂ν ( ∂L ∂(∂νΦ) ∂(Φ) ∂xμ − δν μL ) aμ = 0, (4.34) and this motivates us to deﬁne the energy-momentum tensor Tν μ := ∂L ∂(∂νΦ) ∂(Φ) ∂xμ − δν μL .(4.35) Equation 4.34 tells us that each component μ of Tν μ fulﬁls a continuity equation, because aμ is arbitrary36 36 Take note that we have here a plus sign ∂νTν μ = ∂0T0 μ + ∂i Ti μ, although we have Aμ Bμ = Aμημν Bν = A0B0 − Ai Bi. We deﬁned a four-vector with a lower index without minus signs Aμ =(A0, A1, A2, A3)T and a four-vector with an upper index as Bμ ≡ ημν Bν =(B0, −B1, −B2, −B3)T. The minus signs here are a result of the minus signs in the Minkowski metric ημν = diag(1, −1, −1, −1). The reason for the plus sign in Eq. 4.37 is that ∂μ is deﬁned as ∂μ ≡ ∂ ∂xμ =( ∂ ∂x0 , − ∂ ∂x1 , − ∂ ∂x2 , − ∂ ∂x3 )T. The minus signs here cancel with the minus signs that appear through the upper index of Tν μ and we get an overall plus sign. ∂νTν μ = 0(4.36) → ∂νTν μ = ∂0T0 μ + ∂iTi μ = 0. (4.37) 108 physics from symmetry This tells us directly that we have conserved quantities, because, for example, for μ = 0weget3737 Using ∂0 = ∂t and ∂i T0 i = ∇⃗T and the famous divergence theorem∫ V d3x∇A = ∫ δV d2xA, which enables us to rewrite the integral over some volume V, as an integral over the cor- responding surface δV. A very illumi- nating proof of the divergence theorem, there called Gauss’ theorem, can be found at http://www.feynmanlectures. caltech.edu/II_03.html which is Chapter 3 of the freely online avail- able Richard P. Feynman, Robert B. Leighton, and Matthew Sands. The Feynman Lectures on Physics: Volume 2. Addison-Wesley, 1st edition, 2 1977. ISBN 9780201021172 ∂0T0 0 + ∂iTi 0 = 0 → ∂0T0 0 = −∂iTi 0 ∂tT0 0 = −∇⃗T →︸︷︷︸ Integrating over some inﬁnite volume V ∫ V d3x∂tT0 0 = − ∫ V d3x∇⃗T → ∂t ∫ V d3xT0 0 = − ∫ V d3x∇⃗T Divergence theorem; δV denotes the surface of the volume V ︷︸︸︷ = − ∫ δV d2x⃗T =︸︷︷︸ Because ﬁelds vanish at inﬁnity 0(4.38) → ∂t ∫ V d3xT0 0 = 0. (4.39) In the last step we use that if we have an inﬁnite volume V, like a sphere with inﬁnite radius r, and we have to integrate over the surface of this volume δV, we need to evaluate our ﬁelds at r = ∞. Fields must vanish at inﬁnity, because otherwise the total ﬁeld energy would be inﬁnite and ﬁeld conﬁgurations with inﬁnite energy are non-physical38. 38 Take note that strictly speaking this is only true for spin 0 and spin 1/2 ﬁelds. For spin 1 ﬁelds, only the ﬁeld-strength tensor Fμν must vanish to guarantee ﬁnite energy, while the \"basic ﬁelds\" Aμ (with Fμν := ∂μ Aν − ∂ν Aμ) can be non- zero \"at inﬁnity\". (The ﬁeld strength tensor will be deﬁned in Eq. 6.23). This observation leads to the non- trivial vacuum picture in non-abelian gauge theories. Unfortunately, a proper discussion lies far beyond the scope of this book. We conclude: the invariance under translations in spacetime leads us to 4 conserved quantities39, one for each component μ . Equation 39 Because ∂0T0 μ aμ = ∂0T0 0 a0 − ∂0T0 i ai = 0, with arbitrary aμ we get a separate continuity equation for each compo- nent. 4.39 tells us these are E = ∫ d3xT0 0 (4.40) Pi = ∫ d3xT0 i ,(4.41) where as always i = 1, 2, 3. These quantities are called the total en- ergy E of the system, which is conserved because we have invariance under time-translations x0 → x0 + a0 and the total momentum of the ﬁeld conﬁguration Pi, which is conserved because we have invariance under spatial-translations xi → xi + ai. 4.5.3 Rotations and Boosts Next, we take a look at invariance under rotations and boosts. We will start with the second part of Eq. 4.30 and then look afterwards at the implications of the ﬁrst part. We will get a quantity from the ﬁrst part and a quantity from the second part, which are together conserved. A scalar ﬁeld has no components that could mix, hence for a scalar ﬁeld the ﬁrst part is zero. In other words, for scalars we use the 1-dimensional representation of the generators of the Lorentz group Sμν = 0, which was derived in Section 3.7.4. Therefore what we derive in this section is the complete conserved quantity for a scalar ﬁeld. the framework 109 The second part of the transformation is given by xμ → x′ μ = xμ + δxμ = xμ + Mσ μxσ (4.42) where Mσ μ are the generators of rotations and boost in their inﬁnite- dimensional representation. This means they are represented by differential operators, as deﬁned in Eq. 3.248. From Eq. 4.42, we see that the change of the coordinates is given by δxμ = Mσ μxσ. Putting this into Eq. 4.33 yields ∂ν ( ∂L ∂(∂νΦ) ∂(Φ) ∂xμ − δν μL ) Mμσxσ = 0(4.43) →︸︷︷︸ Eq. 4.35 ∂νTν μ Mμσxσ = 0. We can write this a little differently to bring it into the conventional form = 1 2 (∂νTμ ν Mμσxσ + ∂νTμ ν Mμσ ︸︷︷︸ =−Mσμ xσ)= 1 2 (∂νTμ ν Mμσxσ − ∂νTμ ν Mσμxσ) =︸︷︷︸ Renaming dummy indices 1 2 (∂νTμ ν Mμσxσ − ∂νTσ ν Mμσxμ)= 1 2 (∂νTμ ν xσ − ∂νTσ ν xμ)Mμσ = 1 2 ∂ν(Tμνxσ − Tσνxμ)Mμσ = 0 → with (Jν)σμ ≡ Tμνxσ − Tσνxμ → ∂ν(Jν)σμ = 0. (4.44) The quantity Jν we introduced in the last step is called Noether current. Note that, because of the anti-symmetry of Mμσ = −Mσμ, which follows from the deﬁnition in Eq. 3.173,wehave Mμμ = 0. Therefore, we found 6 different continuity equations ∂ν(Jν)= 0, one for each non-vanishing Mμσ. With the same arguments from Eq. 4.39 we conclude that the quantities conserved in time are Qμσ = ∫ d3x(Tμ0xσ − Tσ0xμ) .(4.45) For rotational invariance40, we therefore have the conserved quanti- 40 Recall the connection between the generator of rotations Ji and Mμν from Eq. 3.173: Ji = 1 2 ϵijk Mjk, which means we now restrict to the spatial components i = j = {1, 2, 3} here and write i, j instead of μ = ν = {0, 1, 2, 3}. ties Li orbit = 1 2 ϵijkQjk = 1 2 ϵijk ∫ d3x(Tj0xk − Tk0xj),(4.46) which we call the orbital angular momentum of our ﬁeld41. 41 The preﬁx \"orbital\" will make sense in a moment, because actually this is just one part of the complete angular momentum. We will have a look at the missing part in a moment. Equivalently, we have the conserved quantity for boosts42 42 Recall the connection between the boost generators Ki and Mμν: Ki = M0i. Q0i = ∫ d3x(T00xi − Ti0x0),(4.47) which is discussed a bit more in the appendix Section 4.7. 110 physics from symmetry 4.5.4 Spin Next, we want to take a look at the implications of the ﬁrst part of Eq. 4.30, which is what we missed in our previous derivation of the conserved quantity that follows from rotations. We now consider δΦ = ϵμνSμνΦ(x),(4.48) where Sμν is the appropriate ﬁnite-dimensional representation of the transformation in question43. This gives us in Eq. 4.29 the extra term 43 The ﬁnite-dimensional representa- tions are responsible for the mixing of the ﬁeld components. For example, the two dimensional representation of the rotation generators: Ji = 1 2 σi, mix the components of Weyl spinors. ∂ρ ( ∂L ∂(∂ρΦ) ϵμνSμνΦ(x)) ,(4.49) which leads to an additional term in Eq. 4.46. The complete con- served quantity then reads Li = 1 2 ϵijkQjk = 1 2 ϵijk ∫ d3x ( ∂L ∂(∂0Φ) SjkΦ(x)+(Tj0xk − Tk0xj)) (4.50) and therefore we write Li = Li spin + Li orbit .(4.51) The ﬁrst part is something new, but needs to be similar to the usual orbital angular momentum we previously considered, because the two terms are added and appear when considering the same invariance. The standard point of view is that the ﬁrst part of this conserved quantity is some-kind of internal angular momentum44. 44 We will see later that ﬁelds create and destroy particles. A spin 1 2 ﬁeld creates spin 1 2 particles, which is an un- changeable property of an elementary particle. Hence the usage of the word \"internal\". Orbital angular momentum is a quantity that describes how two or more particles revolve around each other. Recall that we label the representations of the Poincaré group by something we call spin, too. Now this notion appears again. We will learn in the next chapter and in great detail in Section 8.5.5,howwe are able to measure this new kind of angular momentum, called spin and see later that it indeed coincides with the label we use for the representations of the Poincaré group. 4.5.5 Noether’s Theorem for Field Theories - Internal Symmetries We now take a look at internal symmetries45. The invariance of a 45 Internal symmetries will be incredibly important for interacting ﬁeld theories. In addition, one conserved quantity, following from one of the easiest internal symmetries will provide us with the starting point for quantum ﬁeld theory. Lagrangian (δL = 0) under some inﬁnitesimal transformation of the ﬁeld itself Φi → Φ′ i = Φi + δΦi (4.52) can be written mathematically δL = L (Φi, ∂μΦi) − L (Φi + δΦi, ∂μ(Φi + δΦi)) the framework 111 = − ∂L (Φi, ∂μΦi) ∂Φi δΦi − ∂L (Φi, ∂μΦi) ∂(∂μΦi) ∂μδΦi ! = 0, (4.53) where we used the Taylor expansion to get to the second line and only keep terms of ﬁrst order in δΦi, because the transformation is inﬁnitesimal. From the Euler-Lagrange equation (Eq. 4.10) for ﬁelds we know ∂L ∂Φi = ∂μ ( ∂L ∂(∂μΦi) ) . Putting this into Eq. 4.53,weget δL = −∂μ ( ∂L ∂(∂μΦi) ) δΦi − ∂L ∂(∂μΦi) ∂μδΦi = 0 which is, using the product rule, the same as ∂μ ( ∂L ∂(∂μΦi) δΦi) = 0. (4.54) This means, if the Lagrangian is invariant under the transforma- tion Φi → Φ′i = Φi + δΦi, we get again a quantity, called Noether current Jμ ≡ ∂L ∂(∂μΦi) δΦi,(4.55) which fulﬁls the continuity equation Eq. 4.54 → ∂μ Jμ = 0. (4.56) Furthermore, following the same steps as in Eq. 4.39, we are able to derive a quantity that is conserved in time ∂t ∫ d3xJ0 = 0. (4.57) Let’s have a look at one very important example: invariance under displacements of the ﬁeld itself46, which means δΦ = −iϵ in Eq. 4.52: 46 Take note that at this point we made no assumptions about the ﬁeld being complex or real. The constant ϵ is arbi- trary and could be entirely imaginary if we want to move our ﬁeld by a real value. The i is included at this point to make the generator Hermitian (which is by no means obvious at this point) and therefore the eigenvalues real, as will be shown later. Don’t get confused at this point. You could simply see this extra i as a convention, because we could just as well absorb it into the constant by deﬁning ϵ′ := iϵ. Φ → Φ′ = Φ − iϵ (4.58) or for more than one ﬁeld component Φi → Φ′ i = Φi − iϵi.(4.59) The generator of this transformation is −i ∂ ∂Φ , because Φ′ = e−iϵ ∂ ∂Φ Φ = (1 − iϵ ∂ ∂Φ + ... )Φ ≈ Φ − iϵ (4.60) The corresponding conserved quantity is called conjugate momen- tum Π. With Eq. 4.54 and Eq. 4.57 we get47 47 The δΦ in Eq. 4.55 becomes a constant ϵ and because the quantity is conserved for arbitrary ϵ we deﬁne our conserved quantity without it. 112 physics from symmetry ∂tΠ = 0 → ∂tΠ = ∂t ∫ d3xJ0 = ∂t ∫ d3xπ = 0 with J0 = π = ∂L ∂(∂0Φ) (4.61) The quantity π here is called the conjugate momentum density48. 48 This rather abstract quantity is one of the most important notions in quantum ﬁeld theory, as we will see in Chapter 6. Take note that this is different from the physical momentum density of the ﬁeld, which arises from the invariance under spatial transla- tions Φ(x) → Φ(x′)= Φ(x + ϵ) and is given by pi = T0i = ∂L ∂(∂0Φ) ∂Φ ∂xi , which we derived in Eq. 4.41. In later chapters we will look at many more internal symmetries, which will prove to be invaluable when we develop a theory that describes interactions. Now let’s summarize what we learned about symmetries and conserved quantities in ﬁeld theories: • translational invariance in space ⇒ conservation of physical mo- mentum Pi = ∫ d3xT0i = ∫ d3x ∂L ∂(∂0Φ) ∂Φ ∂xi , • boost invariance49 ⇒ constant velocity of the center of energy, 49 Another name for a boost is a transla- tion in momentum space. • rotational invariance ⇒ conservation of the total angular mo- mentum Li = 1 2 ϵijk ∫ d3x ( ∂L ∂(∂0Φ) SjkΦ(x)+(Tk0xj − Tj0xk)) = Li spin + Li orbit consisting of spin and orbital angular momentum, • translational invariance in time ⇒ conservation of energy E = ∫ d3xT00 = ∫ d3x ( ∂L ∂(∂0Φ) ∂Φ ∂x0 − L ), • displacement invariance of the ﬁeld itself ⇒ conservation of the conjugate momentum Π = ∫ d3x ∂L ∂(∂0Φ) = ∫ d3xπ. Further Reading Tips • Cornelius Lanczos - The Variational Principles of Mechanics5050 Cornelius Lanczos. The Variational Principles of Mechanics. Dover Pub- lications, 4th edition, 3 1986. ISBN 9780486650678 is a brilliant book about the usage of the Lagrangian formalism in classical mechanics. • David Morin - Introduction to Classical Mechanics51 is an ex- 51 David Morin. Introduction to Classical Mechanics: With Problems and Solutions. Cambridge University Press, 1 edition, 2 2008. ISBN 9780521876223 tremely student friendly book that carefully explains how the Lagrangian framework is used in classical mechanics. • Herbert Goldstein - Classical Mechanics52 is the standard book 52 Herbert Goldstein, Charles P. Poole Jr., and John L. Safko. Classical Mechan- ics. Addison-Wesley, 3rd edition, 6 2001. ISBN 9780201657029 about classical mechanics with many great explanations regarding the Lagrangian formalism. the framework 113 4.6 Appendix: Conserved Quantity from Boost Invariance for Particle Theories In this appendix we want to ﬁnd the conserved quantity that follows for our example Lagrangian L = 1 2 m ˙⃗q2 from boost invariance. A boost transformation is q → q′ = q + δq = q + vt, where v denotes a constant velocity. Our Lagrangian is not invariant under boosts, but this is no problem at all, as we have seen above: For our equations of motion to be unchanged under transformations the Lagrangian is allowed to change up to the total derivative of an arbitrary function. This condition is clearly fulﬁlled for our boost transformation q → q′ = q + vt ⇒︸︷︷︸ v=const! ˙q′ = ˙q + v and therefore our Lagrangian L = 1 2 m ˙q2 is changed by δL = L(q, ˙q, t) −L(q′, ˙q′, t)= 1 2 m ˙q2 − 1 2 m ˙q′2 = 1 2 m ˙q2 − 1 2 m( ˙q + v)2 = −m ˙qv − 1 2 mv2, which is the total derivative of the function53 53 dG dt = d dt (−mqv − 1 2 mv2t)= −m ˙qv − 1 2 mv2, because v and m are constant. −G ≡−mqv − 1 2 mv2t. We conclude that our equations of motion stay unchanged and we can ﬁnd a conserved quantity54. 54 Another way to see this is by looking directly at the equation of motion: m ¨q = 0. We have the transformation q → q′ = q + vt, with v =const and therefore ˙q → ˙q′ = ˙q + v and ¨q → ¨q′ = ¨q. For boosts, the conserved quantity is (Eq. 4.16) Jboost = ∂L ∂ ˙q ︸︷︷︸ ≡p δq ︸︷︷︸ =vt −G = pvt − mvq − 1 2 mv2t, where we can cancel one v from every term, because in Eq. 4.16 we have a zero on the right hand side. This gives us ˜Jboost = pt − 1 2 mvt ︸ ︷︷ ︸ ≡ ˜pt −mq = ˜pt − mq .(4.62) This is a rather strange conserved quantity because its value de- pends on the starting time. We can choose a suitable zero time, which makes this quantity zero. Because it is conserved, this zero stays zero for all times. 114 physics from symmetry 4.7 Appendix: Conserved Quantity from Boost Invariance for Field Theories For invariance under boosts in a ﬁeld theory we have the conserved quantities Q0i = ∫ d3x(T00xi − Ti0x0),(4.63) which we derived in Eq. 4.47, using Ki = M0i. How can we interpret this quantity? Q0i is conserved, which means 0 = ∂Q0i ∂t = ∫ d3x ∂Ti0 ∂t x0 ︸ ︷︷ ︸ =x0 ∂ ∂t ∫ d3xTi0 + ∫ d3xTi0 ∂x0 ∂t︸︷︷︸ =1 because x0=t − ∂ ∂t ∫ d3x ∂T00 ∂t xi = t ∂Pi ∂t + Pi − ∂ ∂t ∫ d3xT00xi. From Eq. 4.20 we know that Pi is conserved ∂Pi ∂t = 0 → Pi = const. and we can conclude ∂ ∂t ∫ d3xT00xi = Pi = const. (4.64) Therefore this conservation law tells us55 that the center of energy 55 Don’t worry about the meaning of this term too much, because this isn’t really a useful conserved quantity like the others we derived so far. travels with constant velocity. Or from a different perspective: The momentum equals the total energy times the velocity of the centre-of- mass energy. Nevertheless, the conserved quantity derived in Eq. 4.47 remains strange. By a suitable choice of the starting time the quantity can be chosen to be zero. Because it is conserved, this zero stays zero in all instances. Part III The Equations of Nature \"If one is working from the point of view of getting beauty into one’s equation, ...one is on a sure line of progress.\" Paul A. M. Dirac in The evolution of the physicist’s picture of nature. Scientiﬁc American, vol. 208 Issue 5, pp. 45-53. Publication Date: 05/1963 5 Measuring Nature Now that we have discovered the connection between symmetries and conserved quantities, we can utilize this connection. In more technical terms, Noether’s Theorem establishes a connection between the generator of a symmetry transformation and a conserved quan- tity. In this chapter we will utilize this connection. Conserved quantities are what physicists commonly use to de- scribe physical systems, because no matter how complicated the system changes, the conserved quantities stay the same. For exam- ple, to describe what is happening in an experiment physicists use the momentum, energy and angular momentum. Noether’s theorem hints us towards an incredibly important idea: We identify the quantities that we use to describe nature with the corresponding generators: physical quantity ⇒ generator of the corresponding symmetry. (5.1) As we will see, this identiﬁcation naturally guide us towards quan- tum theory. Let’s make this concrete by considering a particle theory. 5.1 The Operators of Quantum Mechanics The invariance of the Lagrangian under the action of the generator of spatial-translations leads us to the conservation of momentum. Therefore, we make the identiﬁcation momentum ˆpi → generator of spatial-translations − i∂i It is conventional to use a hat: ˆO to denote an operator. Analogously, the invariance under the action of the generator of time-translations leads us to the conservation of energy. Conse- © Springer International Publishing AG 2018 J. Schwichtenberg, Physics from Symmetry, Undergraduate Lecture Notes in Physics, https://doi.org/10.1007/978-3-319-66631-0_5 118 physics from symmetry quently energy ˆE → generator of time-translations i∂o. There is no symmetry corresponding to the \"conservation of loca- tion\" and therefore the location is not identiﬁed with a generator. We simply have1 1 Alternatively, we can see this by looking at the conserved quantity corresponding to invariance under boosts. Take note that we derived in Section 4.6 the conserved quantity corresponding to a non-relativistic Galilei boost, because we started with a non-relativistic Lagrangian. Nev- ertheless, we can do the same for the relativistic Lagrangian and end up with the conserved quantity t⃗p − ⃗xE. The relativistic energy is given by E = √m2 + p2. In the non-relativistic limit c → ∞ we get E ≈ m and therefore recover the formula we derived for a Galilei boost from the Lorentz boost conserved quantity. The conserved quantity for a particle theory is then Mi = (tpi − xi E) . The generator of boosts is (see Eq. 3.248 with Ki = M0i) Ki = i(x0∂i − xi∂0). Comparing the two equations, with of course x0 = t, yields Mi = (tpi − xi E) ↔ Ki = i(t∂i − xi∂0) The identiﬁcation is now, with the identiﬁcations we made earlier, straight- forward. Location ˆxi → xi. location ˆxi → xi. The physical quantities we want to use in our theory to describe nature are now given by (differential) operators. The logical next thing to ask is: What do they act on and where is the connection to things we can measure in experiments? We will discuss this in a later chapter in detail. At this point it is sufﬁcient to note that our physical quantities, now operators, need to act on something. Here we want to move on with an abstract thing that the operators act on. Let’s name it Ψ. We will explore later what this something is. At this point, we are able to derive one of the most important2 2 If you don’t know anything about quantum mechanics, it may seem strange to you why this little equation is so important, but maybe you have heard of the Heisenberg uncertainty principle. In Section 8.3 we will take a closer look at the formalism of quantum mechanics. Then we will be able to see that this equation tells us that we aren’t able to measure the momentum and the location of a particle with arbitrary precision. Our physical quantities are interpreted as measurement opera- tors and this equation tells us that a measurement of location followed by a measurement of momentum is not the same as a measurement of momentum followed by a measurement of location. equations of quantum mechanics. As explained above, we assume that our operators act on something abstract Ψ. Then we have [ ˆpi, ˆxj]Ψ =( ˆpi ˆxj − ˆxj ˆpi)Ψ =(−i∂i ˆxj + ˆxji∂i)Ψ =︸︷︷︸ product rule −(i∂i ˆxj)Ψ − \u0003\u0003\u0003\u0003ˆxj(i∂iΨ)+ \u0002\u0002\u0002ˆxji∂iΨ =︸︷︷︸ because ∂i ˆxj= ∂xj ∂xi −iδijΨ.(5.2) This equation holds for arbitrary Ψ, because we made no assump- tions about it and therefore we can write the equation without Ψ3: 3 If this is a new idea to you, take note that we could rewrite every vector equation as an equation that involves only numbers. For example Newton’s second law: ⃗F = m ¨⃗x, could be written as ⃗F⃗C = m ¨⃗x⃗C, which is certainly true for any vector ⃗C. Nevertheless, if the equation is true for any ⃗C, writing it all the time makes little sense. [ ˆpi, ˆxj]= −iδij.(5.3) 5.1.1 Spin and Angular Momentum In the last chapter (Section 4.5.4) we saw that the conserved quan- tity that resulted from rotational invariance has two parts. The sec- ond part was identiﬁed with the orbital angular momentum and we therefore make the identiﬁcation with the inﬁnite dimensional representation of the generator orb. angular mom. ˆLi → gen. of rot. (inf. dim. rep. ) i 1 2 ϵijk(xj∂k − xk∂j) Analogously we identify the ﬁrst part, called spin, with the corre- sponding ﬁnite dimensional representation of the generators4 4 Recall that this was the part of the conserved quantity that resulted from the invariance under mixing of the ﬁeld components. Hence the ﬁnite- dimensional representation. spin ˆSi → generators of rotations (ﬁn. dim. rep.) Si. measuring nature 119 As explained in the text below Eq. 4.30 the relation between Sμν and the generator of rotations Si is Si = 1 2 ϵijkSjk. For example, when we consider a spin 1 2 ﬁeld, we have to use the two-dimensional representation which we derived in Section 3.7.5: ˆSi = i σi 2 ,(5.4) where once more σi denotes the Pauli matrices. We will return to this very interesting and very strange type of angular momentum in Section 8.5.5, after we learned how to work with the operators that we derive in this chapter. It is important to keep in mind that only the sum of spin and orbital angular momentum is conserved. 5.2 The Operators of Quantum Field Theory The central objects in a ﬁeld theory are, of course, ﬁelds. A ﬁeld is a function of the location in space and time5 Φ = Φ(x). Later we 5 Here x = x0, x1, x2, x3 includes time x0 = t.want to describe interactions at points in spacetime and therefore work with the densities of our dynamical variables π = π(x) and not the total quantities that we get by integrating the densities over all space Π = ∫ dx3π(x) ̸= Π(x). We discovered in the last chapter for invariance under displace- ments of the ﬁeld itself Φ → Φ − iϵ a new conserved quantity, called conjugate momentum Π. Analogous to the identiﬁcations we made in the last section, we identify the conjugate momentum density with the corresponding generator (Eq. 4.60) conj. mom. density π(x) → gen. of displ. of the ﬁeld itself : − i ∂ ∂Φ(x) . We could now go on, like we did for a particle theory, and identify momentum, angular momentum and energy with the corresponding generators. However, we will see later that quantum ﬁeld theory works a little differently and the identiﬁcation we make here will prove to be sufﬁcient. For the same reasons discussed in the last section, we need some- thing our operators act on. Thus again, we work again with an ab- stract Ψ, that we will specify in a later chapter. We are then again able to derive an incredibly important equation, this time of quantum ﬁeld theory6 6 For the last step we use the analogue to ∂xi ∂xj = δij for the delta distribution ∂ f (xi ) ∂ f (xj ) = δ(xi − xj), which can be shown in a rigorous way. For some more infor- mation have a look at Appendix D.2. [Φ(x), π(y)]Ψ = [Φ(x), −i ∂ ∂Φ(y) ] Ψ 120 physics from symmetry =︸︷︷︸ product rule \u0003\u0003\u0003\u0003\u0003\u0003\u0003 −iΦ(x) ∂Ψ ∂Φ(y) + \u0003\u0003\u0003\u0003\u0003\u0003\u0003\u0003 iΦ(x) ( ∂Ψ ∂Φ(y) ) + i ( ∂Φ(x) ∂Φ(y) ) Ψ = iδ(x − y)Ψ . (5.5) Again, the equations hold for arbitrary Ψ and we can therefore write [Φ(x), π(y)] = iδ(x − y) .(5.6) Analogously we have for more than one ﬁeld component [Φi(x), πj(y)] = iδ(x − y)δij.(5.7) As we will see later, almost everything in quantum ﬁeld theory follows from this little equation. 6 Free Theory In this chapter we will derive the basic equations for a physical the- ory of free (=non-interacting) ﬁelds1 from symmetry. We will 1 Although we specify here for ﬁelds we will see in a later chapter how the equations we derive here can be used to describe particles, too. • derive the Klein-Gordon equation using the (0, 0) representation of the Lorentz group, • derive the Dirac equation using the ( 1 2 ,0) ⊕ (0, 1 2 ) representation of the Lorentz group, • derive the Proca equations from the vector ( 1 2 , 1 2 ) representation of the Lorentz group which in the massless limit become the famous Maxwell equations. 6.1 Lorentz Covariance and Invariance In the following sections, we will derive the fundamental equations of motion of the standard model of particle physics, which is the best physical theory that we have. We want that these equations are the same in all inertial frames, because otherwise would have a different equation for each possible frame of reference. This would be useless because there is no preferred frame of reference in special relativity. The technical term for an equation that looks the same in all iner- tial frames of reference is Lorentz covariant equation. An object is Lorentz covariant if it transforms under a given representation of the Lorentz group. For example, a vector Aμ, transforms according to the ( 1 2 , 1 2 ) representation and is therefore Lorentz covariant. This means Aμ → A′ μ, but not something completely different. On the other hand, for example, a term of the form A1 + A3 is not Lorentz covariant, because it does not transform according to a representation of the Lorentz group. This does not mean that we do not know how it transforms. The transformation properties can be easily derived from the transformation laws for Aμ, but nevertheless this term looks © Springer International Publishing AG 2018 J. Schwichtenberg, Physics from Symmetry, Undergraduate Lecture Notes in Physics, https://doi.org/10.1007/978-3-319-66631-0_6 122 physics from symmetry completely different in different inertial frames. In a boosted frame, it may look like A2 + A4. An equation that involves only Lorentz covariant objects is called a Lorentz covariant equation. For example, Aμ + 7Bμ + Cν AνDμ = 0 is a Lorentz covariant equation, because in another coordinate system it reads Λν μ Aν + 7Λν μBν + Λρ νCρΛν η AηΛσ μDσ = A′ μ + 7B′ μ + C′ ν A′νD′ μ = 0. We see that it looks the same. An equation containing only some components of such objects is, in general, not Lorentz covariant and therefore looks completely different in each inertial frame. To make sure we only end up with Lorentz covariant equations, we require the action S to be Lorentz invariant. This means it should only contain terms that stay exactly the same when changing the frame of reference. In other words: The action is only allowed to con- tain terms that do not change under Lorentz transformations. We get the equations of motion from the action2 S.Now if S depends on the 2 Recall that we minimize the action and the result of this minimization proce- dure is the Euler-Lagrange equation, which yields the equation of motion for our system. frame of reference, so would the terms in the equations that follow from it and therefore these equations can not be Lorentz covariant. As already discussed in the last chapter, we can use the more restrictive requirement that the Lagrangian should be invariant, be- cause if the Lagrangian is invariant the action is, too. 6.2 Klein-Gordon Equation We now start with the simplest possible case: scalars, which trans- form according to the (0, 0) representation of the Lorentz group. To specify the equation of motion for scalars we need to ﬁnd the corre- sponding Lagrangian. A general Lagrangian that is compatible with our restrictions3 is 3 Discussed in Section 4.2: We only con- sider terms of order 0, 1 and 2 in Φ. The term with the lowest possible derivative will become clear in a moment. L = AΦ0 + BΦ + CΦ2 + D∂μΦ + E∂μΦ∂μΦ + FΦ∂μΦ .(6.1) Firstly, take note that we are considering the Lagrangian density L and not L itself and we get our physical theory from the action S = ∫ dxL ,(6.2) where dx is to be understood as the integral over space and time. Therefore a term like Φ∂μ∂μΦ would be redundant, because it is equivalent to the term ∂μΦ∂μΦ, as we can see if we integrate by parts4. 4 The boundary terms, as usual, vanish, because ﬁelds vanish at inﬁnity. Recall that this follows, because ﬁeld conﬁg- urations that do not vanish at inﬁnity correspond to inﬁnite ﬁeld energy, which is non-physical (Section 2.3). free theory 123 In addition, Lorentz invariance restricts the Lagrangian to be a scalar. Therefore, all odd powers in ∂μ, like in ∂μΦ are forbidden. What about the constants i.e. a and c etc. having a Lorentz index? This would mean that a, c are four-vectors, specifying a direction in spacetime and therefore violating the assumption of isotropy of space. We can neglect the constant term, i.e. A = 0, because we get our physical theory from the Euler-Lagrange equation and a constant in the Lagrangian has no inﬂuence on the equation of motion5.In 5 See Eq. 4.10: ∂L ∂Φ − ∂μ ( ∂L ∂(∂μ Φ) ) = 0 and therefore L → L + A with some constant A does not change anything: ∂(L +A) ∂Φ − ∂μ ( ∂(L +A) ∂(∂μ Φ) ) = ∂L ∂Φ − ∂μ ( ∂L ∂(∂μ Φ) ) addition, we ignore the term linear in Φ, i.e. B = 0, because it leads, using the Euler-Lagrange equation, to a constant in our equations of motion6. At least in a free theory, the absolute value of the ﬁeld 6 L → L + BΦ yields ∂(L +BΦ) ∂Φ − ∂μ ( ∂(L +BΦ) ∂(∂μ Φ) ) = ∂L ∂Φ − ∂μ ( ∂L ∂(∂μ Φ) ) + B = 0, which is just an additional constant in the equation of motion. has no relevance and thus we can always perform a redeﬁnition Φ → Φ′ = Φ + const. such that the constant term vanishes from the equation of motion7. What remains is 7 However take note that if the ﬁeld interacts with other ﬁelds, this is no longer true, because such a ﬁeld shift then also affects the terms that de- scribe the coupling between the ﬁelds. This will be discussed in detail in Sec- tion. 7.3 in the context of spontaneous symmetry breaking. L = CΦ2 + E∂μΦ∂μΦ .(6.3) As the heading of this chapter indicates we want to develop a free theory, which means there is just one Φ and no terms of the form Φ1Φ2. Terms like this will be investigated in the next chapter, when we develop a theory describing interactions. There is one last thing to note: we are left with only two constants C and E. By using variational calculus we are able to combine these into just one constant, because an overall constant in the Lagrangian has no inﬂuence on the physics8. Nevertheless, it is conventional to 8 L → CL yields ∂(CL ) ∂Φ − ∂μ ( ∂(CL ) ∂(∂μ Φ) ) = 0 ↕ ∂(L ) ∂Φ − ∂μ ( ∂(L ) ∂(∂μ Φ) ) = 0 include an overall factor 1 2 into the Lagrangian and call the remaining constant9 −m2. Therefore, we are ﬁnally left with 9 The suggestive name of this constant will become clear later, because we will see that it coincides with the mass of particles described by this Lagrangian. L = 1 2 (∂μΦ∂μΦ − m2Φ2) .(6.4) If we now use the variational calculus machinery, which means putting this Lagrangian into the Euler-Lagrange equation (Eq. 4.10), we get the equation of motion 0 = ∂L ∂Φ − ∂μ ( ∂L ∂(∂μΦ) ) → 0 = ∂ ∂Φ ( 1 2 (∂μΦ∂μΦ − m2Φ2)) − ∂μ ( ∂ ∂(∂μΦ) ( 1 2 (∂μΦ∂μΦ − m2Φ2))) → 0 =(∂μ∂μ + m2)Φ .(6.5) This is the famous Klein-Gordon equation, which is the correct equation of motion to describe free spin 0 ﬁelds and particles. 124 physics from symmetry 6.2.1 Complex Klein-Gordon Field For spin 0 ﬁelds, we are able to construct a Lorentz invariant La- grangian without using the complex conjugate of the scalar ﬁeld. This will not be the case for spin 1 2 ﬁelds Ψ and this curious fact will have very interesting consequences10. Nevertheless, nothing prevents 10 To spoil the surprise: there is an an- tiparticle for each spin 1 2 particle. Using complex ﬁelds is the same as consid- ering two ﬁelds at the same time as explained in the text below. Therefore we are forced by Lorentz invariance to use two (closely connected) ﬁelds at the same time, which are commonly interpreted as particle and antiparticle ﬁelds. us from investigating the equally Lorentz invariant Lagrangian L = ∂μφ†∂μφ − m2φ†φ as many textbooks do. This is simply the same as investigating two scalar ﬁelds of equal mass at the same time L = 1 2 ∂μφ1∂μφ1 − 1 2 m2φ2 1 + 1 2 ∂μφ2∂μφ2 − 1 2 m2φ2 2 , because we have φ ≡ 1 √2 (φ1 + iφ2) . Again Lorentz symmetry dictates the form of the Lagrangian. Ele- mentary scalar (=spin 0) particles are very rare. In fact, only one is experimentally veriﬁed: the Higgs boson. However this Lagrangian can also be used to describe composite systems like mesons. We will not investigate this Lagrangian any further and most textbooks use it only for \"training purposes\". 6.3 Dirac Equation Another story told of Dirac is that when he ﬁrst met Richard Feynman, he said after a long silence \"I have an equation. Do you have one too?\" - Anthony Zee1111 Anthony Zee. Quantum Field Theory in a Nutshell. Princeton University Press, 1st edition, 3 2003. ISBN 9780691010199 In this section we want to ﬁnd the equation of motion for free spin 1 2 ﬁelds/particles. We will use the ( 1 2 ,0) ⊕ (0, 1 2 ) representation of the Lorentz group, because a theory that respects symmetry under parity transformations must include the ( 1 2 ,0) and (0, 1 2 ) representations at the same time12. The objects transforming under this representation 12 We showed in Section 3.7.9 that a parity transformation transforms the ( 1 2 ,0) representation, into the (0, 1 2 ) representation. are called Dirac spinors and combine right-chiral and left-chiral Weyl spinors into one object13: 13 This was discussion in Section 3.7.9. Ψ ≡ (χL ξR ) = (χa ξ ˙a ) .(6.6) Now, we need to search for Lorentz invariant objects constructed from Dirac spinors, which we can then put into the Lagrangian. The ﬁrst step is to search for invariants constructed from our left-chiral and right-chiral Weyl spinors. free theory 125 We will use the Van-der-Waerden notation, which was introduced in Section 3.7.7. Two possibly invariants are14 14 There are two other possibilities, which go by the name Majorana mass terms. We already know how we can move spinor indices up and down by using the spinor \"metric\" ϵ.We can write down a Lorentz invariant term of the form ϵ(χL)†χL, because ϵ(χL)† = χa has an upper-undotted index. ϵ(χL)† transforms like a right- chiral spinor, but by writing a term like this we have less degrees of freedom. ξR and χL both have two components, and therefore we have four degrees of freedom in a term like (ξR)†χL. In the term ϵ(χL)†χL = χaχa, the object that transforms like a right-chiral spinor is not independent of χL and we therefore only have two degrees of freedom here. There is a lot more one can say about Majorana spinors and it is currently under (experimental) investigation which type of term is the correct one for neutrinos. One more thing is worth noting: a Majorana spinor is a \"real\" Dirac spinor. I put real into quotation marks, because usually real means Ψ⋆ ! = Ψ. For spinors this condition is not Lorentz invariant (because the Lorentz transformations are complex in this representation). If we impose the standard condition (Ψ⋆ ! = Ψ) in one frame, it will, in general, not hold in another frame. Instead, it is possible to derive a Lorentz invariant \"reality\" condition for Dirac spinors:( 0 ϵ −ϵ 0 ) Ψ⋆ ! = Ψ, which is commonly interpreted as charge conjugation. This interpretation will be explained in Section 7.1.5. Therefore, a Majorana spinor describes a particle which is equivalent to its charge conjugated particle, commonly called anti-particle. Majorana particles are their own anti- particles and a Majorana spinor is a Dirac spinor with an extra-condition: ΨM ≡ ( χL ϵχ⋆ L ) or ΨM ≡ (−ϵξ⋆ R ξR ) I1 := χT ˙a ξ ˙a =(χ⋆ a )Tξ ˙a =(χa)†ξ ˙a =(χL)†ξR (6.7) and I2 :=(ξ a)Tχa =((ξ ˙a)⋆)Tχa =(ξR)†χL,(6.8) because we always need to combine a lower dotted with an upper dotted and a lower undotted with an upper undotted index, in order to get a Lorentz invariant term. This was shown explicitly in Sec- tion 3.7.7. Here we see again that right-chiral and left-chiral spinors are needed in pairs. Furthermore, we can construct two Lorentz-invariant combinations involving ﬁrst order derivatives, as we will see in a moment. But ﬁrst we need to understand how we can write the derivative of a spinor. We learned in Section 3.7.8 how we can construct four-vectors from spinors va ˙b = vνσν a ˙b , where vν transforms like a four-vector. The differentiation operator is therefore in the spinor formalism ∂a ˙b = ∂νσν a ˙b .(6.9) It is conventional to deﬁne ¯σ0 = I2×2, ¯σi = −σi and using this we can construct the following Lorentz invariant terms I3 :=(χ ˙a)T∂μ(σμ) ˙abχb =(χL)†∂μ ¯σμχL (6.10) and I4 :=(ξ a)T∂μ(σμ)a ˙bξ ˙b =(ξR)†∂μσμξR .(6.11) In addition to (σμ)a ˙b, we need here also (σμ) ˙ab. The ﬁrst index must be dotted and the second index undotted to combine properly with the other spinor indices. We get (σμ) ˙ab by using the spinor metric twice: (σμ) ˙ab =((σμ)T)b ˙a = ϵbc((σμ)T)c ˙d(ϵ ˙a ˙d)T = ( 01 −10 ) (σμ)T ( 01 −10 )T = ( 01 −10 ) (σμ)T (0 −1 10 ) = ¯σμ .(6.12) 126 physics from symmetry For example, for σ3,wehave ( 01 −10 )(10 0 −1 ) ︸ ︷︷ ︸ =σT 3 (0 −1 10 ) = (−10 01 ) ︸ ︷︷ ︸ = ¯σ3=−σ3 . Don’t let yourself get confused why ∂μ acts only on one spinor. We are going to use these invariants in Lagrangians, which we always evaluate inside of integrals15 and therefore, we can always integrate 15 Remember that we get the equations of motion from the action, which is the integral over the Lagrangian. by parts to get the other possibility. Therefore, our choice here is no restriction16. 16 We will see this more clearly when we derive the corresponding equations of motion. We get the same equations regardless of where we put ∂μ and we could put both possibilities into the Lagrangian. This would be longer, but doesn’t gives us anything new. When we introduce the matrices17 17 We get the matrix with lowered index by using the metric: γμ = ημνγν = ημν ( 0 σν ¯σν 0 ) = ( 0 ημνσν ημν ¯σν 0 ) = ( 0 ¯σμ σμ 0 ), because ημνσν = ⎛ ⎜ ⎜ ⎝ 1 000 0 −10 0 00 −10 00 0 −1 ⎞ ⎟ ⎟ ⎠ ⎛ ⎜ ⎜ ⎝ σ0 σ1 σ2 σ3 ⎞ ⎟ ⎟ ⎠ = ⎛ ⎜ ⎜ ⎝ σ0 −σ1 −σ2 −σ3 ⎞ ⎟ ⎟ ⎠ = ¯σμ. γμ = ( 0 σμ ¯σμ 0 ) → γμ = ( 0 ¯σμ σμ 0 ) ,(6.13) we can write the invariants we just found using the Dirac spinor formalism. Using the matrices γμ and Dirac spinors our invariants can be written as Ψ†γ0Ψ and Ψ†γ0γμ∂μΨ,(6.14) because Ψ†γ0Ψ = ((χL)† (ξR)†) ( 0 ¯σ0 σ0 0 )(χL ξR ) =(χL)† ¯σ0ξR︸ ︷︷ ︸ =I1 +(ξR)†σ0χL︸ ︷︷ ︸ =I2 . These are exactly the ﬁrst two invariants we found earlier and18 18 Remember that σ0 is just the unit matrix and we have ¯σ0 = σ0. Ψ†γ0γμ∂μΨ = ((χL)† (ξR)†) ( 0 ¯σ0 σ0 0 )( 0 σμ∂μ ¯σμ∂μ 0 )(χL ξR ) =(χL)† ¯σ0 ¯σμ∂μχL ︸ ︷︷ ︸ =I3 +(ξR)†σ0σμ∂μξR ︸ ︷︷ ︸ =I4 gives the other two invariants19, as promised. To avoid writing γ0 all 19 Take note that σμ∂μ = ∂μσμ, because σμ are constant matrices. the time it is conventional to introduce the notation ¯Ψ :=(Ψ)†γ0.(6.15) Now we have everything we need to construct a Lorentz-invariant Lagrangian using Dirac spinors that is in agreement with the restric- tions20 discussed in Section 4.2: 20 Recall that these were: maximum order two in Ψ and only the lowest, non-trivial order in ∂μ, which is here order 1. L = AΨ†γ0Ψ + BΨ†γ0γμ∂μΨ = A ¯ΨΨ + B ¯Ψγμ∂μΨ. free theory 127 Putting in the constants (A = −m, B = i) gives us the ﬁnal Dirac- Lagrangian LDirac = −m ¯ΨΨ + i ¯Ψγμ∂μΨ = ¯Ψ(iγμ∂μ − m)Ψ.(6.16) Take note that what appears here in our Lagrangian are two distinct ﬁelds, because Ψ is complex21. This is a requirement, because other- 21 Therefore the left-chiral and right- chiral spinors inside each Dirac spinor, are complex, too. wise we can’t get something Lorentz invariant. More explicitly, we have Ψ = Ψ1 + iΨ2 with two real ﬁelds Ψ1 and Ψ2. Instead of working with two real ﬁelds it is conventional to work with two complex ﬁelds Ψ and ¯Ψ,as two distinct ﬁelds. Now, if we put this Lagrangian into the Euler-Lagrange equation, which we recite here for convenience ∂L ∂Ψ − ∂μ ( ∂L ∂(∂μΨ) ) = 0 we get −m ¯Ψ − i∂μ ¯Ψγμ = 0 → (i∂μ ¯Ψγμ + m ¯Ψ)= 0. (6.17) With the Euler-Lagrange equation for the ﬁeld ¯Ψ ∂L ∂ ¯Ψ − ∂μ ( ∂L ∂(∂μ ¯Ψ) ) = 0 we get the equation of motion for Ψ (iγμ∂μ − m)Ψ = 0. (6.18) This is the famous Dirac equation, which is the equation of motion for spin 1 2 particles and ﬁelds. Take note that this is exactly what we get if we integrate the Lagrangian by parts −m ¯ΨΨ + i ¯Ψγμ∂μΨ =︸︷︷︸ Integrate by parts. Just imagine here the action integral. −m ¯ΨΨ − (i∂μ ¯Ψ)γμΨ and then use the Euler-Lagrange equation, →−mΨ + i∂μγμΨ = 0. So it really makes no difference and the way we wrote the Lagrangian is no restriction, despite its asymmetry22. 22 You are free to use the longer La- grangian that includes both possibili- ties, but the results are the same. 6.4 Proca Equation Now, we want to ﬁnd the equation of motion for an object transform- ing according to the ( 1 2 , 1 2 ) representation of the Lorentz group. We 128 physics from symmetry already saw that this representation is the vector representation and therefore this task is easy. We simply take an arbitrary vector ﬁeld Aμ and construct all possible Lorentz-invariants from it that are in agreement with the restrictions from Section 4.2. We must combine an upper with a lower index, because we deﬁned the scalar product of Minkowski space in Section 2.4 this way and scalars are what we need in the Lagrangian. The possible invariants are2323 Again, a term of the form ∂μ∂μ Aν Aν is redundant, because we can integrate by parts and get ∂μ Aν∂μ Aν. I1 = ∂μ Aν∂μ Aν , I2 = ∂μ Aν∂ν Aμ I3 = Aμ Aμ , I4 = ∂μ Aμ and the Lagrangian reads LProka = C1∂μ Aν∂μ Aν + C2∂μ Aν∂ν Aμ + C3 Aμ Aμ + C4∂μ Aμ.(6.19) We can neglect the term ∂μ Aμ, because has no inﬂuence on the equa- tions of motion, as can be seen by looking at the Euler-Lagrange equation24. Therefore order 1 in ∂μ is trivial. 24 ∂σ ( ∂(C4∂μ Aμ ) ∂(∂σ Aρ ) ) = 0. If we now want to compute the equations of motion using the Euler-Lagrange equation for each ﬁeld component independently ∂L ∂Aρ = ∂σ ( ∂L ∂(∂σ Aρ) ) , we need to be very careful about the indices. Let us take a look at the right-hand side of the Euler-Lagrange equation and pick the term involving C1: ∂σ ( ∂ ∂(∂σ Aρ) (C1∂μ Aν∂μ Aν)) =︸︷︷︸ product rule C1∂σ ((∂μ Aν) ∂(∂μ Aν) ∂(∂σ Aρ) +(∂μ Aν) ∂(∂μ Aν) ∂(∂σ Aρ) ) =︸︷︷︸ lowering indices with the metric C1∂σ ((∂μ Aν)gμκ gνλ ∂(∂κ Aλ) ∂(∂σ Aρ) +(∂μ Aν) ∂(∂μ Aν) ∂(∂σ Aρ) ) = C1∂σ ((∂μ Aν)gμκ gνλδσ κ δρ λ +(∂μ Aν)δσ μδρ ν ) = C1∂σ (∂σ Aρ + ∂σ Aρ) = 2C1∂σ∂σ Aρ .(6.20) Following similar steps we can compute ∂σ ( ∂ ∂(∂σ Aρ) (C2∂μ Aν∂ν Aμ)) = 2C2∂ρ(∂σ Aσ) . Therefore the equation of motion, following from the Lagrangian in Eq. 6.19 reads 2C3 Aρ = 2C1∂σ∂σ Aρ + 2C2∂ρ(∂σ Aσ) , free theory 129 which gives us, when we put in the conventional constants25 25 Maybe you wonder why we use C1 = −C2. The reason for this it that with C1 = −C2 the Lagrangian in Eq. 6.19 has a special internal symme- try. This symmetry will be crucial in our discussion of how different ﬁelds or particles interact with each other. This will be discussed in Section 7.1.2 ff. → m2 Aρ = ∂σ(∂σ Aρ − ∂ρ Aσ).(6.21) This is called the Proca equation, which is the equation of motion for massive spin 1 particles and ﬁelds. For massless (m = 0) spin 1 particles, e.g. photons, the equation reads → 0 = ∂σ(∂σ Aρ − ∂ρ Aσ).(6.22) This is the inhomogeneous Maxwell equation in absence of electric currents. To unclutter the notation it is conventional to deﬁne the electromagnetic tensor Fσρ := ∂σ Aρ − ∂ρ Aσ.(6.23) Then the inhomogeneous Maxwell-equations read ∂σ Fσρ = 0(6.24) and we can rewrite the Lagrangian for massless spin 1 ﬁelds LMaxwell = 1 2 (∂μ Aν∂μ Aν − ∂μ Aν∂ν Aμ) as LMaxwell = 1 4 FμνFμν = 1 4 (∂μ Aν − ∂ν Aμ)(∂μ Aν − ∂ν Aμ) = 1 4 (∂μ Aν∂μ Aν − ∂μ Aν∂ν Aμ − ∂ν Aμ∂μ Aν + ∂ν Aμ∂ν Aμ) =︸︷︷︸ renaming dummy indices 1 4 (∂μ Aν∂μ Aν − ∂μ Aν∂ν Aμ − ∂μ Aν∂ν Aμ + ∂μ Aν∂μ Aν) = 1 4 (2∂μ Aν∂μ Aν − 2∂μ Aν∂ν Aμ) = 1 2 (∂μ Aν∂μ Aν − ∂μ Aν∂ν Aμ) ✓.(6.25) LMaxwell = 1 4 FμνFμν is the conventional way to write the Lagrangian. Equivalently, the Lagrangian for a massive spin 1 ﬁeld can be written as LProca = 1 4 FμνFμν + m2 Aμ Aμ = 1 2 (∂μ Aν∂μ Aν − ∂μ Aν∂ν Aμ)+ m2 Aμ Aμ. (6.26) In this chapter we derived the equations of motion that describe free ﬁelds and particles. We want to understand what we can do with these equations in order to get predictions for experiments. However 130 physics from symmetry ﬁrst, we need to derive some more equations, because experiments always work through interactions. For example, we are only able to detect an electron if we use another particle, like a photon. Therefore, in the next chapter we will derive Lagrangians that describe the interaction between different ﬁelds and particles.7 Interaction Theory Summary In this chapter we will derive how different ﬁelds and particles inter- act with each other. This will enable us, for example, to describe how electrons, interact with photons1. 1 From a different point of view: how the electron ﬁeld (= a massive spin 1 2 ﬁeld) interacts with the photon ﬁeld (= a massless spin 1 ﬁeld). We will be guided to the correct form of the Lagrangians by inter- nal symmetries, which are in this context often called gauge symme- tries2. The starting point will be local U(1) symmetry3 and we end up 2 This name will be explained in a moment. 3 This means we multiply the ﬁeld at each point in spacetime with a different factor: eiα(x), instead of using the same transformation everywhere: eiα. In other words: the transformation parameter α = α(x) is now a function of x and has therefore a different value for different points in spacetime. with the Lagrangian L = −m ¯ΨΨ + i ¯Ψγμ∂μΨ + Aμ ¯ΨγμΨ + 1 2 (∂μ Aν∂μ Aν − ∂μ Aν∂ν Aμ) . This is the Lagrangian of quantum electrodynamics. This Lagrangian describes the interaction between charged, massive spin 1 2 ﬁelds and a massless spin 1 ﬁeld (the photon ﬁeld). The Lagrangian is only then locally U(1) invariant, if we avoid \"mass terms\" of the form mAμ Aμ in the Lagrangian. This coincides with the experimental fact that photons, described by Aμ, are massless. Using Noether’s theorem, we can derive a new conserved quantity from U(1) symmetry, which is commonly interpreted as electric charge. Then we move on to local SU(2) symmetry. For this purpose a two component object ¯Ψ := ( ¯ψ1 ¯ψ2) , called doublet, is introduced. Such a doublet contains two spin 1 2 ﬁelds, for example, the electron and the electron neutrino ﬁeld that are \"rotated\" by SU(2) transformations into each other. Using this doublet notation we are able to write down a locally SU(2) invariant Lagrangian4 4 The object Wμν j is for the three ﬁelds Wμ j what Fμν is for the U(1) gauge ﬁeld Aμ. © Springer International Publishing AG 2018 J. Schwichtenberg, Physics from Symmetry, Undergraduate Lecture Notes in Physics, https://doi.org/10.1007/978-3-319-66631-0_7 132 physics from symmetry L = i ¯Ψγμ (∂μ − igW μ) Ψ − 1 4 Tr(WμνW μν), which contains three spin 1 ﬁelds W μ ≡ (Wμ)i σi 2 , with i = 1, 2, 3. We need three ﬁelds to make the Lagrangian locally SU(2) invariant, because we have three SU(2) basis generators: Ji = σi 2 . We will see that local SU(2) symmetry can only be achieved without \"mass terms\" of the form m ¯ΨΨ, mW μWμ, with some arbitrary mass matrix m, because Ψ is now a two-component object. So this time not only are the spin 1 ﬁelds (Wμ)i required to be massless, but the spin 1 2 ﬁelds, too. Also allowed are equal masses for the two spin 1 2 ﬁelds, but from experiments we know that this is not the case: The electron mass is much bigger than the electron-neutrino mass. In addition, we know from experiments that the three spin 1 ﬁelds (Wμ)i are not massless. This is commonly interpreted as the SU(2) symmetry being broken. This idea is the starting point for the Higgs formalism, which is introduced afterwards. This formalism enables us to get a locally SU(2) invariant Lagrangian that includes mass terms. This works by adding the interaction with a spin 0 ﬁeld, called Higgs ﬁeld, into our considerations. The ﬁnal locally SU(2) × U(1) invariant interaction Lagrangian describes the so called electroweak interactions. The no- tion electroweak interactions contains the electromagnetic interaction and a new type of interaction called the weak interaction. Through the Higgs formalism the SU(2) × U(1) is broken to a remnant U(1) symmetry. The weak interaction is mediated by three massive spin 1 ﬁelds, called W+,W− and Z and the remnant U(1) symmetry by one massless spin 1 ﬁeld γ. Using Noether’s theorem we will be able to derive from SU(2) symmetry a new conserved quantity, called isospin, which is the charge of weak interactions analogous to elec- tric charge for electromagnetic interactions. Lastly, we will consider internal local SU(3) symmetry, which will lead us to a Lagrangian describing another new interaction, called the strong interaction. For this purpose, we will introduce triplet objects Q = ⎛ ⎜ ⎝q1 q2 q3 ⎞ ⎟ ⎠ , that are transformed by SU(3) transformations and which contain three spin 1 2 ﬁelds. These three spin 1 2 ﬁelds are interpreted as quarks carrying different color, which is the strong interaction analogue to the electrical charge of the electromagnetic interaction or isospin of the weak interaction. Again, mass terms are forbidden, but this time this coincides with the experimental fact that the 8 corresponding interaction theory 133 bosons5, called gluons, are massless. In addition, we know from ex- 5 8 because SU(3) has 8 basis genera- tors.periments that the ﬁelds inside a SU(3) triplet have the same mass, This is a good thing, because local SU(3) symmetry forbids a term with arbitrary mass matrix m for terms like m ¯QQ, but allows a term of the form ¯Q (m 0 0 m ) Q, which means that the terms in the triplet have the same mass. Therefore local SU(3) invariance provides no new obstacles regarding mass terms in the Lagrangian and we there- fore say the SU(3) symmetry is unbroken. From experiments we know that only quarks (spin 1 2 ) and gluons (spin 1) carry color. The resulting Lagrangian L = − 1 4 GαβG αβ + Q(i(∂μ − igGμ)γμ − m)Q will only be cited, because the derivation is completely analogous to what we did before. To summarize the summary: U(1) 1 gauge ﬁeld massless photons electric charge SU(2) 3 gauge ﬁelds massive W- and Z-bosons (Higgs needed) isospin SU(3) 8 gauge ﬁelds massless gluons color charge 7.1 U(1) Interactions To derive the correct interaction terms in the Lagrangian, we are going to use internal symmetrie that are usually called gauge sym- metries. The notion gauge symmetry, is used for historic reasons and doesn’t make much sense for the type of symmetry we are consider- ing here. Weyl tried to derive electromagnetism6 6 Frank Wilczek. Riemann-einstein structure from volume and gauge sym- metry. Phys. Rev. Lett., 80:4851–4854, Jun 1998. doi: 10.1103/PhysRevLett.80.4851 \"as a consequence of spacetime symmetry, speciﬁcally symmetry under local changes of length scale.\" Naming this kind of symmetry gauge symmetry makes sense, be- cause this means, for example, that we can change the platinum bar that deﬁnes a standard meter (and which was used to gauge objects that measure length in experiments), arbitrarily without changing physics. This attempt was unsuccessful, but some time later, Weyl found the correct symmetry to derive electromagnetism and the name was kept. 134 physics from symmetry 7.1.1 Internal Symmetry of Free Spin 1 2 Fields Let’s have a look again at the Lagrangian that we derived for a free spin 1 2 theory (Eq. 6.16) LDirac = −m ¯ΨΨ + i ¯Ψγμ∂μΨ = ¯Ψ(iγμ∂μ − m)Ψ.(7.1) We derived it by demanding Lorentz symmetry, but if we take a sharp look we can discover another symmetry of this Lagrangian. The Lagrangian does not change if we transform the ﬁeld Ψ as fol- lows Ψ → Ψ′ = eiaΨ if we take into account that this implies that ¯Ψ also gets transformed ⇒ ¯Ψ → ¯Ψ′ = Ψ′†γ0 =(eiaΨ)†γ0 = ¯Ψe−ia .(7.2) The minus sign comes from the complex conjugation7 and a is an 7 Remember: ¯Ψ = Ψ†γ0. arbitrary real number. To see that the Lagrangian is invariant under this transformation, we transform the Lagrangian explicitly: L ′ Dirac = −m ¯Ψ′Ψ′ + i ¯Ψ′γμ∂μΨ′ = −m( ¯Ψe−ia)(eiaΨ)+ i( ¯Ψe−ia)γμ∂μ(eiaΨ) = −m ¯ΨΨ e−iaeia ︸ ︷︷ ︸ =1 +i ¯Ψγμ∂μΨ e−iaeia ︸ ︷︷ ︸ =1 = −m ¯ΨΨ + i ¯Ψγμ∂μΨ = LDirac,(7.3) where we used that eia is just a complex number, which we can move around freely8. Remembering that we learned in Chapter 3 that all 8 Speaking more technically: A complex number commutes with every matrix, like, for example, γμ. unit complex numbers can be written as eia and form a group called U(1), we can put what we just discovered into mathematical terms, by saying that the Lagrangian is U(1) invariant. This symmetry is an internal symmetry, because it is clearly no spacetime transformation and therefore transforms the ﬁeld internally. This internal symmetry does not look like a big thing. At a ﬁrst glance it may seem like a nice, but rather useless, mathematical side note. However, quite sur- prisingly we will see in a moment that this observation is incredibly important! Now let’s have a deeper look at what we just discovered. We showed that we are free to multiply our ﬁeld with an arbitrary unit complex number without changing anything. The symmetry transfor- mation Ψ → Ψ′ = eiaΨ is called a global transformation, because we multiply the ﬁeld Ψ = Ψ(x) at every point x with the same factor eia. Now, why should this factor at one point in spacetime be cor- related to the factor at another point in spacetime? The choice at interaction theory 135 one point in spacetime shouldn’t ﬁx this immediately in the whole universe. This would be strange, because special relativity tells us that no information can spread faster than light, as was shown in Section 2.4. For a global symmetry the choice would be ﬁxed imme- diately for any point in the whole universe. Let’s check if our Lagrangian is invariant if we transform each point in spacetime with a different factor a = a(x). This is called a local transformation. If we transform Ψ → Ψ′ = eia(x)Ψ ⇒ ¯Ψ → ¯Ψ′ = e−ia(x) ¯Ψ,(7.4) where the factor a = a(x) now depends on the position, we get the transformed Lagrangian9 9 Maybe you wonder if the Lagrangian that includes both possible derivatives, which we neglected for brevity, is locally U(1) invariant: L = −m ¯ΨΨ + i ¯Ψγμ∂μΨ + i(∂μ ¯Ψ)γμΨ. This Lagrangian is indeed locally U(1) invariant, as you can check, but take note that the addition of the second and the third term yields zero: i ¯Ψγμ∂μΨ + i(∂μ ¯Ψ)γμΨ =︸︷︷︸ integration by parts i(∂μ ¯Ψ)γμΨ − i(∂μ ¯Ψ)γμΨ = 0. The correct Lagrangian that includes both possible derivatives has a minus sign between those terms:LDirac = −m ¯ΨΨ + i ¯Ψγμ∂μΨ − i(∂μ ¯Ψ)γμΨ and is therefore not locally U(1) invariant. L ′ Dirac = −m ¯Ψ′Ψ′ + i ¯Ψ′γμ∂μΨ′ = −m( ¯Ψ e−ia(x))(eia(x) ︸ ︷︷ ︸ =1 Ψ)+ i( ¯Ψe−ia(x))γμ∂μ(eia(x)Ψ) =︸︷︷︸ Product rule −m ¯ΨΨ + i ¯Ψγμ(∂μΨ) e−ia(x)eia(x) ︸ ︷︷ ︸ =1 +i(e−ia(x) ¯Ψ)γμΨ(∂μeia(x)) = −m ¯ΨΨ + i ¯Ψγμ∂μΨ + i2(∂μa(x)) ¯ΨγμΨ ̸= LDirac (7.5) Therefore, our Lagrangian is not invariant under local U(1) symme- try, because the product rule produces an extra term. As discussed above, our Lagrangian should be locally invariant, but we just found out that it isn’t. There is something we can do about it, but ﬁrst we must investigate another symmetry. 7.1.2 Internal Symmetry of Free Spin 1 Fields Next, let’s take a look at the Lagrangian we derived for free spin 1 particles10 10 See Eq. 6.26 and take note that we neglect, for brevity, a conventional factor 1 2 here.LProca = ∂μ Aν∂μ Aν − ∂μ Aν∂ν Aμ + m2 Aμ Aμ.(7.6) We can discover a global internal symmetry here, too. If we trans- form Aμ → A′ μ = Aμ + aμ (7.7) with some arbitrary constants aμ11, the Lagrangian reads12 11 Remember, as always, μ = 0, 1, 2, 3. 12 The aμ are constants and therefore ∂μaν = 0 etc.L ′Proca =(∂μ A′ν∂μ A′ ν − ∂μ A′ν∂ν A′ μ)+ m2 A′μ A′ μ = ∂μ(Aν + aν)∂μ(Aν + aν) − ∂μ(Aν + aν)∂ν(Aμ + aμ)) + m2(Aμ + aμ)(Aμ + aμ) = ∂μ Aν∂μ Aν − ∂μ Aν∂ν Aμ + m2(Aμ + aμ)(Aμ + aμ).(7.8) 136 physics from symmetry We conclude this transformation is a global symmetry transforma- tion of this Lagrangian, if we restrict ourselves to massless ﬁelds, i.e. m = 0. What about local symmetry here? We transform Aμ → A′ μ = Aμ + aμ(x) (7.9) and the transformed massless Lagrangian reads L ′Maxwell =(∂μ A′ν∂μ A′ ν − ∂μ A′ν∂ν A′ μ) = ∂μ(Aν + aν(x))∂μ(Aν + aν(x)) − ∂μ(Aν + aν(x))∂ν(Aμ + aμ(x)) = ∂μ Aν∂μ Aν + ∂μaν∂μ Aν + ∂μ Aν∂μaν(x)+ ∂μaν(x)∂μaν(x) − ∂μ Aν∂ν Aμ − ∂μ Aν∂νaμ(x) − ∂μaν(x)∂ν Aμ − ∂μaν(x)∂νaμ(x) , (7.10) which shows that Aμ → A′ μ = Aμ + aμ(x) is not a local internal sym- metry . Nevertheless, we can ﬁnd a local internal symmetry by considering the transformation Aμ → A′ μ = Aμ + ∂μa(x) instead. This means we add the derivative of some arbitrary function ∂μa(x) instead of an arbitrary function. This transformation has the following effect on the Lagrangian1313 The symmetry of partial deriva- tives ∂ν∂μ = ∂μ∂ν is also known as \"Schwarz’s theorem\". ∂ν∂μ=∂μ∂ν and renaming dummy indices We see this is indeed an internal local symmetry transformation. Again this may look like a technical side note. Okay, we found some internal, local symmetry; so what? 7.1.3 Putting the Puzzle Pieces Together Let’s summarize what we found out so far: • We discovered the Lagrangian for free spin 1 2 ﬁelds has an internal global symmetry Ψ → Ψ′ = eiaΨ. Formulated differently: the Lagrangian for free spin 1 2 ﬁelds is invariant under global U(1) transformations. L ′Maxwell = ∂μ A′ν∂μ A′ ν − ∂μ A′ν∂ν A′ μ = ∂μ(Aν + ∂νa(x))∂μ(Aν + ∂νa(x)) − ∂μ(Aν + ∂νa(x))∂ν(Aμ + ∂μa(x)) = ∂μ Aν∂μ Aν + ∂μ(∂νa(x))∂μ Aν + ∂μ Aν∂μ(∂νa(x)) + ∂μ(∂νa(x))∂μ(∂νa(x)) − ∂μ Aν∂ν Aμ − ∂μ Aν∂ν(∂μa(x)) − ∂μ(∂νa(x))∂ν Aμ − ∂μ(∂νa(x))∂ν(∂μa(x)) =︸︷︷︸ ∂μ Aν∂μ Aν − ∂μ Aν∂ν Aμ = LMaxwell .(7.11) interaction theory 137 • We saw that this symmetry is not local (although it should be), because for a = a(x), we get an extra term in the Lagrangian of the form (Eq. 7.5). −(∂μa(x)) ¯ΨγμΨ.(7.12) In other words: The Lagrangian isn’t locally U(1) invariant. • In the last section we found an internal local symmetry for mass- less spin 1 ﬁelds Aμ → A′ μ = Aμ + ∂μa(x),(7.13) which is only a local symmetry if we add the derivative of an arbitrary function ∂μa(x), instead of an arbitrary function aμ(x). This really looks like two pieces of a puzzle we should put to- gether. When we transform Ψ, ¯Ψ and Aμ simultaneously, an addi- tional term Aμ ¯ΨγμΨ in the Lagrangian becomes Aμ ¯ΨγμΨ → (Aμ + ∂μa(x)) ¯ΨγμΨ = Aμ ¯ΨγμΨ + ∂μa(x) ¯ΨγμΨ .(7.14) Compare the second term here to Eq. 7.12. The new term in the La- grangian, coupling Ψ, ¯Ψ and Aμ together, therefore cancels exactly the term which stopped the Lagrangian for free spin 1 2 from being locally U(1) invariant. In other words: By adding this new term we can make the Lagrangian locally U(1) invariant. Let’s study this in more detail. First take note that it’s conventional to factor out a constant g in the exponent of the local U(1) transfor- mation: eiga(x). Then the extra term becomes −(∂μa(x)) ¯ΨγμΨ →−g(∂μa(x)) ¯ΨγμΨ.(7.15) This extra factor g accounts for an arbitrary coupling constant14,as 14 A coupling constant always tells us how strong a given interaction is. Here we are talking about electromagnetic interactions and g determines its strength. we will see now. We then add to the Lagrangian for free spin 1 2 ﬁelds the new term gAμ ¯ΨγμΨ, where we included γμ to make the term Lorentz invariant15 and 15 Otherwise Aμ has an unmatched index μ and therefore wouldn’t be Lorentz invariant. inserted the coupling constant16 g. This yields the Lagrangian 16 We can see here that g determines how strong Ψ, ¯Ψ and Aμ couple to- gether. LDirac+Extra-Term = −m ¯ΨΨ + i ¯Ψγμ∂μΨ + gAμ ¯ΨγμΨ. Transforming this Lagrangian according to the rules for local trans- formations of Ψ, ¯Ψ and Aμ yields17 17 The combined transformation of Ψ, ¯Ψ and Aμ is called U(1) gauge transformation. 138 physics from symmetry L ′ Dirac+Extra-Term = −m ¯Ψ′Ψ′ + i ¯Ψ′γμ∂μΨ′ + gA′ μ ¯Ψ′γμΨ′ =︸︷︷︸ See Eq. 7.5 −m ¯ΨΨ + i ¯Ψγμ∂μΨ − g(∂μa(x)) ¯ΨγμΨ + gA′ μ ¯Ψ′γμΨ′ = −m ¯ΨΨ + i ¯Ψγμ∂μΨ − g(∂μa(x)) ¯ΨγμΨ + g(Aμ + ∂μa(x))(e−iga(x) ¯Ψ)γμ(eiga(x)Ψ) = −m ¯ΨΨ + i ¯Ψγμ∂μΨ − \u0004\u0004\u0004\u0004\u0004\u0004\u0004\u0004 g(∂μa(x)) ¯ΨγμΨ + gAμ ¯ΨγμΨ + g\u0004\u0004\u0004\u0004\u0004\u0004\u0004 (∂μa(x)) ¯ΨγμΨ ︸ ︷︷ ︸ =(∂μ a(x)) ¯ΨγμΨ = −m ¯ΨΨ + i ¯Ψγμ∂μΨ + gAμ ¯ΨγμΨ = LDirac+Extra-Term. (7.16) Therefore, by adding an extra term we get a locally U(1) invariant Lagrangian. To describe a system consisting of massive spin 1 2 and massless spin 1 ﬁelds we must add the Lagrangian for free massless spin 1 ﬁelds to the Lagrangian as well. This gives us the complete Lagrangian1818 We use here the conventional \"nor- malization\" with an additional factor 1 2 in front of the last terms. LDirac+Extra-Term+Maxwell = − m ¯ΨΨ + i ¯Ψγμ∂μΨ + gAμ ¯ΨγμΨ − 1 2 (∂μ Aν∂μ Aν − ∂μ Aν∂ν Aμ).(7.17) To unclutter the notation it is conventional to introduce a new symbol Dμ ≡ i∂μ − igAμ,(7.18) called covariant derivative. The Lagrangian then reads LDirac+Extra-Term+Maxwell = −m ¯ΨΨ + i ¯Ψγμ (∂μ − igAμ) ︸ ︷︷ ︸ ≡Dμ Ψ − 1 2 (∂μ Aν∂μ Aν − ∂μ Aν∂ν Aμ) = −m ¯ΨΨ + i ¯ΨγμDμΨ − 1 2 (∂μ Aν∂μ Aν − ∂μ Aν∂ν Aμ).(7.19) This is the correct Lagrangian for the quantum ﬁeld theory of elec- trodynamics, commonly called quantum electrodynamics.We are able to derive this Lagrangian simply by making use of internal sym- metries of the Lagrangians describing free spin 1 2 ﬁelds and free spin 1 ﬁelds. The next question we have to answer is: What equations of motion follow from this Lagrangian? interaction theory 139 7.1.4 Inhomogeneous Maxwell Equations and Minimal Coupling To spoil the surprise: This Lagrangian gives us the inhomogeneous Maxwell equations in the presence of currents. The process is again straightforward: we simply put the La- grangian (Eq. 7.17) LDirac+Extra-Term+Maxwell = − m ¯ΨΨ + i ¯Ψγμ∂μΨ + gAμ ¯ΨγμΨ − 1 2 (∂μ Aν∂μ Aν − ∂μ Aν∂ν Aμ). into the Euler-Lagrange equation for each ﬁeld ∂L ∂Ψ − ∂μ ( ∂L ∂(∂μΨ) ) = 0 ∂L ∂ ¯Ψ − ∂μ ( ∂L ∂(∂μ ¯Ψ) ) = 0 ∂L ∂Aρ − ∂σ ( ∂L ∂(∂σ Aρ) ) = 0. This yields ¯Ψ(iγμ∂μ + m)+ gAμ ¯Ψγμ = 0(7.20) (iγμ∂μ − m)Ψ + gAμγμΨ = 0(7.21) ∂ν(∂ν Aμ − ∂μ Aν)+ g ¯ΨγμΨ = 0. (7.22) The ﬁrst two equations describe the behavior of spin 1 2 particles/ﬁelds in an external electromagnetic ﬁeld. In many books the derivation of these equations uses the notion minimal coupling, by which is meant that in the presence of an external ﬁeld the derivative ∂μ has to be changed into the covariant derivative ∂μ → Dμ = ∂μ − igAμ (7.23) to yield the correct equations. The word \"minimal\" is used, because only one gauge ﬁeld Aμ, with four components μ = 0, 1, 2, 3, is used. Now that we have the equation that describes how Dirac spinors behave in the presence of an external electromagnetic ﬁeld (Eq. 7.21), we can show something that we promised in Section 3.7.10. There we claimed that a transformation, which we called very sugges- tively charge conjugation, changes the electric charge of the object it describes. In other words, if Ψ describes something of charge +e, the charge conjugate spinor ΨC describes something of charge −e. 140 physics from symmetry Electrical charge determines the coupling strength of spin 1 2 parti- cles/ﬁelds to an external spin 1 ﬁeld and we therefore investigate now, which equation of motion holds for ΨC. Afterwards we will talk about the third equation, i.e. Eq. 7.22. 7.1.5 Charge Conjugation, Again Before we can derive the corresponding equation, we need to ﬁnd an explicit form of the charge conjugation operator for Dirac spinors. We derived in Section 3.7.10 the transformation (Eq. 3.244) Ψ = (χL ξR ) → ΨC = ( ξ L χR ) .(7.24) This transformation can now be described easily with the help of one of the γμ matrices. Using the deﬁnition of γ2 in Eq. 6.13,wehave ΨC = iγ2Ψ⋆ = i ( 0 σ2 −σ2 0 )(χ⋆ L ξ⋆ R ) ,(7.25) because we can rewrite this, using that iσ2 = ϵ is exactly the spinor metric = ( 0 ϵ −ϵ 0 )(χ⋆ L ξ⋆ R ) = ( ϵξ⋆ R −ϵχ⋆ L ) .(7.26) This is equivalent to = ( ξ L χR ) ,(7.27) as was shown in Section 3.7.7, speciﬁcally Eq. 3.202. Therefore we start with Eq. 7.21: (iγμ∂μ − m)Ψ + gAμγμΨ = (γμ(i∂μ + gAμ) − m)Ψ = 0, (7.28) and complex conjugate this equation, as a ﬁrst step towards an equa- tion for ΨC: → (γ⋆ μ(−i∂μ + gAμ) − m)Ψ⋆ = 0. (7.29) Now, we multiply this equation from the left-hand side with γ2 and adda1 = γ−1 2 γ2 in front of Ψ⋆: → γ2(γ⋆ μ(−i∂μ + gAμ) − m) γ−1 2 γ2 ︸ ︷︷ ︸ =1 Ψ⋆ = 0(7.30) → ( γ2γ⋆ μγ−1 2 ︸ ︷︷ ︸ =−γμ (−i∂μ + gAμ) − mγ2γ−1 2 )γ2Ψ⋆ = 0(7.31) interaction theory 141 →︸︷︷︸ Multiplying the equation with i ( − γμ(−i∂μ + gAμ) − m) iγ2Ψ⋆ ︸ ︷︷ ︸ =ΨC see Eq. 7.25 = 0(7.32) → ((γμ(i∂μ − gAμ) − m)ΨC = 0. (7.33) This is exactly the same equation of motion as for Ψ, but with op- posite coupling strength g →−g. This justiﬁes the name charge conjugation19. 19 It is important to note that Ψc ̸= ¯Ψ. Ψc = iγ2Ψ⋆ and ¯Ψ = Ψ†γ0 = (Ψ⋆)T γ0. Charge conjugation is the correct transformation that enables us to interpret things in terms of antiparticles, as we will discuss later in detail. Next, we turn to the third equation of motion derived in the last section (Eq. 7.22) which is called inhomogeneous Maxwell equation in the presence of an electric current. To make the notion \"electric current\" precise we need again Noether’s theorem. 7.1.6 Noether’s Theorem for Internal U(1) Symmetry In Section 4.5.5 we learned that Noether’s theorem connects each internal symmetry with a conserved quantity. What conserved quan- tity follows from the U(1) symmetry we just discovered? Noether’s theorem for internal symmetries tells us that a transformation of the form Ψ → Ψ′ = Ψ + δΨ leads to a Noether current Jμ = ∂L ∂(∂μΨ) δΨ which fulﬁls a continuity equation ∂μ Jμ = 0. (7.34) A global20 U(1) transformation is 20 Recall that the Lagrangian for free spin 1 2 ﬁelds was only globally U(1) invariant. The ﬁnal Lagrangian of the last section was locally U(1) invariant. Global symmetry is a special case of local symmetry with a =const. There- fore, if we have a locally U(1) invariant Lagrangian, it is automatically globally U(1) invariant, too. Considering global U(1) symmetry here will give us a quantity that is conserved for free and interacting ﬁelds. Ψ → Ψ′ = eigaΨ =(1 + iga + ...)Ψ. We stop the series expansion of the exponential function, as usual, after the ﬁrst term, because U(1) is a Lie group and arbitrary trans- formations can be built of inﬁnitesimal ones. An inﬁnitesimal trans- formation reads Ψ → Ψ′ = Ψ + igaΨ. Therefore we have δΨ = igaΨ and as we derived in Section 4.5.5 the corresponding Noether current is Jμ = ∂L ∂(∂μΨ) δΨ = ∂(−m ¯ΨΨ + i ¯Ψγμ∂μΨ) ∂(∂μΨ) igaΨ = − ¯ΨγμgaΨ = −ga ¯ΨγμΨ.(7.35) 142 physics from symmetry We can ignore21 the arbitrary constant a, because the continuity equa- 21 We keep the conventional constant g, which is not arbitrary but has one ﬁxed value that is determined in experiments. tion holds for arbitrary a and therefore, we deﬁne Jμ ≡−g ¯ΨγμΨ .(7.36) This is usually called the electric four-current. The zeroth component is the electric charge density, which gives us if we integrate it, a quantity that is conserved in time2222 This can be seen by following the same steps as in Eq. 4.39. Q = ∫ d3x ρ ︸︷︷︸ Charge density = ∫ d3xJ0 = −g ∫ d3x ¯Ψγ0Ψ.(7.37) In the quantum framework the objects Ψ will be related to probability amplitudes and this interpretation requires that ∫ d3x ¯Ψγ0Ψ = 1, because the overall probability must be 100% = 1. Therefore, the conserved quantity is in fact the coupling strength g, which is for electromagnetism the electric charge. Therefore, global U(1) symme- try leads to the conservation of electric charge. If we now take a look again at Eq. 7.22, we can write it, using the deﬁnition in Eq. 7.36,as ∂ν(∂ν Aμ − ∂μ Aν)+ g ¯ΨγμΨ ︸ ︷︷ ︸ =−Jμ = 0 → ∂ν(∂ν Aμ − ∂μ Aν)= Jμ.(7.38) Using the electromagnetic tensor as deﬁned in Eq. 6.23 this equation reads ∂νFνμ = Jμ.(7.39) These are the inhomogeneous Maxwell equations in the presence of an external electromagnetic current. These equations23, together 23 Plural, because we have an equation for each component μ. with the homogeneous Maxwell equations, which follow immediately from the deﬁnition of Fνμ, are the basis for the classical theory of electrodynamics24. 24 We will see this explicitly in Chap- ter 11. Next we take a quick look at interactions of massive spin 1 and spin 0 ﬁelds. 7.1.7 Interaction of Massive Spin 0 Fields Take note that the Lagrangian we derived for spin 0 ﬁelds L = 1 2 (∂μΦ∂μΦ − m2Φ2) is not U(1) invariant, as we can see by transforming Φ → Φ′ = eiaΦ. Nevertheless, the complex scalar theory L = 1 2 (∂μΦ⋆∂μΦ − m2Φ⋆Φ).(7.40) interaction theory 143 has U(1) symmetry, because then we have Φ → Φ′ = eiaΦ and Φ⋆ → (Φ⋆)′ = e−iaΦ⋆. Therefore it is possible to derive, analogous to what we did in Section 7.1 for spin 1 2 ﬁelds, an interaction theory for this Lagrangian. The derivation is completely analogous25 and one 25 The correct Lagrangian can be computed by substituting ∂μ → Dμ = ∂μ − igAμ as introduced in Eq. 7.23. gets L = 1 2 (((∂μ + iqAμ)Φ⋆) ((∂μ − iqAμ)Φ) − m2Φ⋆Φ) .(7.41) Using the Euler-Lagrange equation ∂L ∂Φ⋆ − ∂μ ( ∂L ∂(∂μΦ⋆) ) = 0, we ﬁnd the corresponding equation of motion (∂μ − iqAμ)(∂μ − iqAμ)Φ − m2Φ = 0, (7.42) which describes a charged spin 0 ﬁeld coupled to a massless spin 1 ﬁeld. 7.1.8 Interaction of Massive Spin 1 Fields The interaction of a massive spin 1 ﬁeld with a massless spin 1 ﬁeld is dictated by symmetry, too. The Lagrangian for massless spin 1 ﬁelds is given by (Eq. 6.25) LMaxwell = − 1 4 FμνFμν. To distinguish between a massless and a massive spin 1 ﬁeld, we name the massive ﬁeld Bμ and deﬁne Gμν := ∂μBν − ∂νBμ. The Lagrangian for this massive spin 1 ﬁeld reads (Eq. 6.19) LProca = − 1 4 GμνGμν + m2BμBμ. Lorentz symmetry dictates the interaction term in the Lagrangian to be of the form LProca-interaction = CGμνFμν, with a coupling constant C that we need to measure in experiments. If you’re interested you can derive yourself the corresponding equa- tions of motion, by using the Euler-Lagrange equations. 7.2 SU(2) Interactions Motivated by the success with U(1) symmetry we want to answer the question: Is U(1) the only internal symmetry of our Lagrangians? 144 physics from symmetry It turns out that we can ﬁnd an internal symmetry for two mass- less spin 1 2 ﬁelds. We get the Lagrangian for two spin 1 2 ﬁelds by adding two copies of the Lagrangian that we derived in Section 6.3. The ﬁnal Lagrangian can be found in Eq. 6.16 and we recite it here for convenience: LDirac = ¯ψ(iγμ∂μ − m)ψ. Here we neglect mass terms, which means m = 0, because other- wise the Lagrangian isn’t invariant as we will see in a moment. We will see later how we can include mass terms, without spoiling the symmetry. The addition yields LD1+D2 = i ¯ψ1γμ∂μψ1 + i ¯ψ2γμ∂μψ2 .(7.43) This can be rewritten, if we deﬁne Ψ := (ψ1 ψ2 ) → ¯Ψ := ( ¯ψ1 ¯ψ2) , where the newly deﬁned object Ψ is called a doublet: LD1+D2 = i ¯Ψγμ∂μΨ.(7.44) This Lagrangian is invariant under global SU(2) transformations2626 To calculate the transformation behavior of ¯Ψ,weuse σ† i = σi, which we already noted in Eq. 3.213. Ψ → Ψ′ = eiai σi 2 Ψ (7.45) ⇒ ¯Ψ → ¯Ψ′ = ¯Ψe−iai σi 2 ,(7.46) where a sum over the index \"i\" is implicitly assumed, ai denotes arbitrary real constants and σi 2 are the usual generators of SU(2), with the Pauli matrices σi. To see the invariance we take a look at the transformed Lagrangian27 27 We neglect mass terms here, because they are, in general, not invariant under SU(2) transformations. The mass terms would be −m1 ¯Ψ1Ψ1 and −m2 ¯Ψ2Ψ2 and we could write them, using the two component deﬁnition for Ψ and by deﬁning m := (m1 0 0 m2 ) as LD1+D2 = − ¯ΨmΨ. Such a term is not invariant under SU(2) transformations, because, in general, LD1+D2 = − ¯Ψ′mΨ′ = ¯Ψ e−iai σi 2 meiai σi 2 ︸ ︷︷ ︸ ̸=m Ψ. For equal masses m1 = m2 it would be invariant, but we are going to see how we can include arbitrary mass terms without violating this symmetry. We know from experiments that the two ﬁelds in the doublet do not create particles of equal mass, i.e. m1 ̸= m2. This will be discussed later in detail. L ′ D1+D2 = i ¯Ψ′γμ∂μΨ′ = i ¯Ψe−iai σi 2 γμ∂μeiai σi 2 Ψ = i ¯Ψγμ∂μΨ = LD1+D2, ✓ (7.47) where we got to the last line because our transformation eiai σi 2 acts on our newly deﬁned two-component object Ψ, whereas γμ acts on the objects in our doublet, i.e. the Dirac spinors. We can express this using indices [(e−iai σi 2 ) abδαβ][δbcγβδ μ ][(eiai σi 2 ) cdδδϵ] = [δadγαϵ μ ] . interaction theory 145 This symmetry should be a local symmetry, too. The SU(2) trans- formations mix the two components of the doublet. Later we will give these two ﬁelds names like electron and electron-neutrino ﬁeld. Our symmetry here tells us that it does not matter what we call electron and what electron-neutrino ﬁeld, because by using SU(2) transformations we can mix them as we like. If this is only a global symmetry, as soon as we ﬁx one choice28, which means we decide 28 This is known as choosing a gauge. what we call electron and what electron-neutrino ﬁeld, this choice would be ﬁxed immediately for the complete universe. Therefore we investigate if this is a local symmetry. Again we ﬁnd that it isn’t, but as for local U(1) symmetry, we will do everything we can to make the Lagrangian locally SU(2) invariant. The problem here is again the derivative, which produces an extra term. To unclutter the notation, we deﬁne U(x) ≡ e−iai(x) σi 2 : Ψ → Ψ′ = U(x)Ψ (7.48) ⇒ ¯Ψ → ¯Ψ′ = ¯ΨU†(x).(7.49) Our transformed Lagrangian then reads L ′ D1+D2 = i ¯Ψ′γμ∂μΨ′ = i ¯ΨU†(x)γμ∂μ(U(x)Ψ) =︸︷︷︸ product rule i ¯Ψγμ∂μΨ + i ¯ΨγμU†(x)(∂μU(x))Ψ ̸= LD1+D2.(7.50) We can see that the Lagrangian is not invariant because we get an additional term, i ¯ΨγμU†(x)(∂μU(x))Ψ, after the transformation. So how can we modify our Lagrangian LD1+D2 such that is in- variant under local SU(2) transformations? In principle the same method that we discovered in the last sections to ensure local U(1) works again. However, some details are a bit more complicated. We already noted in Eq. 7.23 that the essence of how we need to change our Lagrangian can be summarized through the replacement of the ordinary derivative ∂μ, with a \"covariant derivative\" Dμ = ∂μ − igAμ. With this in mind, we replace the derivative ∂μ in our Lagrangian LD1+D2 with a new object Dμ and then try to derive how Dμ looks like in order to ensure local SU(2) invariance. Concretely, we now write ̃LD1+D2 = i ¯ΨγμDμΨ (7.51) and under a local SU(2) transformation this Lagrangian becomes 146 physics from symmetry ̃L ′ D1+D2 = i ¯Ψ′γμ(DμΨ)′ = i ¯ΨU†(x)γμ(DμΨ)′ ! = ̃LD1+D2.(7.52) We can see here that this new Lagrangian is invariant under the local SU(2) transformation U(x)= e−iai(x) σi 2 if (DμΨ)′ = U(x)DμΨ, because then2929 The reason that we can change the positions of U†(x) and γμ, as already discussed in the text below Eq. 7.47, is that γμ is a matrix that acts on the components of the Dirac spinors, whereas the SU(2) transformation mixes the two Dirac spinors ψ1 and ψ2 inside the doublet Ψ. ̃L ′ D1+D2 = i ¯Ψ′γμ(DμΨ)′ = i ¯ΨU†(x)γμ(DμΨ)′ = i ¯Ψγμ U†(x)U(x) ︸ ︷︷ ︸ =1 DμΨ = ̃LD1+D2 ✓.(7.53) So our goal is to ﬁnd an object Dμ that has exactly this transforma- tion behavior (DμΨ)′ = U(x)DμΨ. Take note that this property is the reason why we call Dμ the \"covariant derivative\"30. The covariant 30 The notion \"covariance\" was dis- cussed in Section 2.6 and means roughly that the form of an equa- tion or an object is not changed under a given transformation. derivative of Ψ, which we denote by DμΨ, transforms exactly like Ψ, i.e. Ψ′ = U(x)Ψ. Thus the form stays the same and we don’t get additional terms, like we do if we use the ordinary derivative ∂μ31. 31 This was demonstrated in Eq. 7.50. From our experience with local U(1) symmetry, we already know that the crucial trick is to make use of spin 1 ﬁelds. However, there is one crucial difference. We saw in Eq. 7.50 that again the reason for the non-invariance is that the derivative ∂μ produces an ex- tra term i ¯ΨγμU†(x)(∂μU(x))Ψ. Our local SU(2) transformations U(x) ≡ e−iai(x) σi 2 are a bit more complicated than local U(1) trans- formations U(x) ≡ e−iα(x), because of the generators σi/2 in the exponent. For local SU(2) transformations, we have ∂μU(x)= ∂μe−iai(x) σi 2 = −i(∂μai(x)) σi 2 e−iai(x) σi 2 .(7.54) We can see here that we actually get three extra terms32, one for 32 We have here an implicit sum, in the sense of Einstein’s summation convention, over the index i. each Pauli matrix σi. Thus in contrast to the U(1) case, to make the Lagrangian locally SU(2) invariant we don’t need one additional spin 1 ﬁeld, but three! In addition, we can see that the troublesome terms, that are produced through the derivative in the Lagrangian ∂μ,are proportional to the generators σi 2 . To summarize: we need three spin 1 ﬁelds to cancel the terms that make our Lagrangian non-invariant under local SU(2) transforma- tions and must introduce these new ﬁelds in such a way that they are able to cancel terms that involve the generators σi 2 . interaction theory 147 We therefore try Dμ = ∂μ − ig σa 2 Wμ a ,(7.55) where σa are the Pauli matrices and a = 1, 2, 3. With this ansatz, the requirement (DμΨ)′ ! = U(x)DμΨ, can now be translated into a transformation law for the spin 1 ﬁelds Wμ a : (DμΨ)′ ! = U(x)DμΨ →︸︷︷︸ Eq. 7.55 ((∂μ − ig σa 2 Wμ a )Ψ)′ ! = U(x)(∂μ − ig σa 2 Wμ a )Ψ → ∂μΨ′ − ig σa 2 W′μ a Ψ′ ! = U(x)(∂μ − ig σa 2 Wμ a )Ψ →︸︷︷︸ Eq. 7.48 ∂μ(U(x)Ψ) − ig σa 2 W′μ a U(x)Ψ ! = U(x)(∂μ − ig σa 2 Wμ a )Ψ →︸︷︷︸ product rule (∂μU(x))Ψ + \u0003\u0003\u0003\u0003\u0003\u0003 U(x)(∂μΨ) − ig σa 2 W′μ a U(x)Ψ ! = \u0003\u0003\u0003\u0003\u0003 U(x)∂μΨ − igU(x) σa 2 Wμ a Ψ → (∂μU(x))Ψ − ig σa 2 W′μ a U(x)Ψ ! = −igU(x) σa 2 Wμ a Ψ . (7.56) The Lagrangian should be invariant for arbitrary Ψ and therefore, we write the last line in Eq. 7.56 without it (∂μU(x)) − ig σa 2 W′μ a U(x) ! = −igU(x) σa 2 Wμ a .(7.57) We can now calculate the correct transformation behavior of the spin 1 ﬁelds W′μ a by \"solving\" this equation for W′μ a . To achieve this we multiply Eq. 7.57 from the right with U−1(x), which yields (∂μU(x))U−1(x) − ig σa 2 W′μ a U(x)U−1(x) ︸ ︷︷ ︸ =1 ! = −igU(x) σa 2 Wμ a U(x)−1 → σa 2 W′μ a ! = U(x) σa 2 Wμ a U−1(x) − 1 ig ︸︷︷︸ = i i2 g =− i g (∂μU(x))U−1(x) → σa 2 W′μ a ! = U(x) σa 2 Wμ a U−1(x)+ i g (∂μU(x))U−1(x) (7.58) This is how our gauge ﬁelds W′μ a , that we introduced in Eq. 7.55 as part of the covariant derivative Dμ = ∂μ − ig σa 2 Wμ a , need to trans- form such that (DμΨ)′ = U(x)DμΨ. We saw in Eq. 7.53 that this transformation behavior is needed to get a locally SU(2) invariant Lagrangian. 148 physics from symmetry There is one last thing, we need to take care of. We introduced three new spin 1 ﬁelds Wμ a and we saw that they need to have very speciﬁc transformation properties when we want a locally SU(2) invariant Lagrangian. However, the \"naive\" Lagrangian for these spin 1 ﬁelds (Eq. 6.25) L3xMaxwell = 1 4 (Wμν)1(Wμν)1 + 1 4 (Wμν)2(Wμν)2 + 1 4 (Wμν)3(Wμν)3 = 1 4 (Wμν)i(Wμν)i (7.59) with (Wμν)i = ∂μ(Wν)i − ∂ν(Wμ)i is not invariant under such transformations33. 33 This can be seen by using the ex- plicit transformation behavior that we derived in Eq. 7.58. We saw above that the demand for local U(1) symmetry was pow- erful and yielded the correct Lagrangian that describes electromag- netic interactions. Thus instead of discarding the transformation behavior that successfully makes the spin 1 2 part of of the Lagrangian invariant under local SU(2) transformations, because it is not a sym- metry of the free spin 1 ﬁeld Lagrangian, we try to ﬁnd a better La- grangian for these spin 1 ﬁelds which has the desired symmetry. In other words, our ﬁnal task is to derive a Lagrangian that describes how these new spin 1 ﬁelds behave when they are on their own that is invariant under the transformation in Eq. 7.58. To ﬁnd this Lagrangian, we need to note several things: 1. The new spin 1 ﬁelds (Wμ)i always appeared in the previous Lagrangians34 in combination with the generators σi 2 . It is thus 34 See, e.g. Eq. 7.58. useful to introduce a new object Wμ ≡ (Wμ)i σi 2 . Next, we might try to use this new object Wμ instead of (Wμ)i in the Lagrangian Eq. 7.5935. The important difference is that Wμ is a matrix, because 35 It will become clear in a moment, why this is useful, although at a ﬁrst glance it seems to make things much more complicated. the generators are matrices. Therefore, when we deﬁne our ﬁeld strength tensor in terms of the new object Wμ: Wμν = ∂μWν − ∂νWμ ,(7.60) it becomes a matrix, too. 2. We want a Lagrangian that is invariant under local SU(2) trans- formations, and therefore need to combine our ﬁelds in such a way that their transformation behavior cancels exactly. Now that we have new objects (Wμ, Wμν) that are matrices, we can try to make use of the following nice property of the trace of matrices3636 This property is known as \"cyclic property\" of the trace. In words it means that the trace stays the same when we perform cyclic permutations among the matrices A, B, C, D that appear here. We always take the last element that appears in the product and put it at the beginning. However, take note that arbitrary permutations do not lead to the same trace. For example, Tr(ACBD) ̸= Tr(ABCD). Tr(ABCD)= Tr(DABC)= Tr(CDAB)= Tr(BCDA) .(7.61) interaction theory 149 If we somehow manage that our ﬁeld strength tensor transforms as Wμν → U(x)WμνU−1(x), the term Tr(WμνWμν) would be invariant, because37 37 To get to the second line, we use the cyclic property of the trace. Tr(WμνWμν) →Tr(U(x)WμνU−1(x)U(x)WμνU−1(x)) =︸︷︷︸ Eq. 7.61 Tr( U−1(x)U(x) ︸ ︷︷ ︸ =1 Wμν U−1(x)U(x) ︸ ︷︷ ︸ =1 Wμν) = Tr(WμνWμν) ✓ .(7.62) 3. Unfortunately, the naive ﬁeld strength tensor that we wrote down in Eq. 7.60 does not transform so nicely. However, we can construct a different ﬁeld strength tensor that has exactly the needed transformation behavior. Above, we derived the co- variant derivative Dμ that transforms exactly in the way we need it to get a locally SU(2) invariant Lagrangian for the spin 1 2 ﬁelds: (DμΨ)′ = U(x)DμΨ. The spin 1 2 doublet Ψ transforms as38 Ψ → U(x)Ψ. Therefore, we can conclude that the covariant 38 See Eq. 7.48. derivative transforms as Dμ → U(x)DμU−1(x), because (DμΨ)′ = D′μΨ′ = U(x)Dμ U−1(x)U(x) ︸ ︷︷ ︸ =1 Ψ = U(x)DμΨ ✓ (7.63) Now the ﬁnal crucial trick to get a locally SU(2) invariant La- grangian for the spin 1 ﬁelds is the observation that the object39 39 At this point the way we introduce this correct ﬁeld strength tensor may seem a bit like magic. However, of course, there is a deep reason why the correct ﬁeld strength tensor must be the commutator of the covariant derivative. Unfortunately, a proper discussion lies beyond the scope of this text. It will become clear in the a moment, why we included the additional factor i g here. Wμν ≡ i g [Dμ, Dν]= i g (DμDν − DνDμ) (7.64) has exactly the correct transformation behavior40 Wμν → U(x)WμνU−1(x): 40 Maybe you wonder why we use Dμ Dν − Dν Dμ and not just Dμ Dν.In short: we need to include all terms that are allowed by our restrictions in the Lagrangian. For the spin 1 ﬁelds this means that we not only need ∂μWν but also ∂νWμ. To correctly account for both these possibilities, we need to use not only Dμ Dν, but also Dν Dμ. This will be made explicit below. g i Wμν = DμDν − DνDμ → U(x)Dμ U−1(x)U(x) ︸ ︷︷ ︸ =1 DνU−1 − U(x)Dν U−1(x)U(x) ︸ ︷︷ ︸ =1 DμU−1 = U(x)DμDνU−1 − U(x)DνDμU−1 = U(x)(DμDν − DνDμ)U−1 = U(x)WμνU−1 ✓ (7.65) 4. When we now calculate explicitly how our ﬁeld strength tensor looks like in terms of the ﬁelds Wμ, we can see what we missed in our naive deﬁnition in Eq. 7.6041 41 We include here an arbitrary test function f (x), because our derivatives must act on something. 150 physics from symmetry Wμν f (x)= i g (DμDν − DνDμ) f (x) = ( i g (∂μ − igW μ)(∂ν − igW ν) − i g (∂ν − igW ν)(∂μ − igW μ)) f (x) = ( \u0005\u0005 \u0005i g ∂μ∂ν + ∂μW ν + W μ∂ν − igW μW ν − ( \u0005\u0005 \u0005i g ∂ν∂μ + ∂νW μ + W ν∂μ − igW νW μ)) f (x) =︸︷︷︸ product rule (∂μW ν + \u0003\u0003\u0003W ν∂μ + \u0003\u0003\u0003W μ∂ν − igW μW ν − (∂νW μ + \u0003\u0003\u0003W μ∂ν + \u0003\u0003\u0003W ν∂μ − igW νW μ)) f (x) = (∂μW ν − ∂νW μ − igW μW ν + igW νW μ)) f (x) = (∂μW ν − ∂νW μ − ig[W μ, W ν]) f (x) .(7.66) The last term here is what we missed previously42. It is important 42 In addition, we can see here, why we included the factor i g in the deﬁnition of Wμν. this factor is exactly what we need to cancel the factors that come from the deﬁnition of Dμ. for local SU(2) symmetry, because the W μ are now matrices and therefore W μW ν ̸= W νW μ. In contrast, in order to ensure local U(1) symmetry there was no need for such a term. There was just one spin 1 ﬁeld, hence no matrix and therefore this last term vanishes. This was quite a long journey, but now we have everything we need to write down a Lagrangian that is invariant under local SU(2) transformations: Llocally SU(2) invariant = i ¯ΨγμDμΨ − 1 4 Tr(WμνW μν) ,(7.67) where Dμ ≡ ∂μ − igW μ W μν ≡ ∂μW ν − ∂νW μ − ig[W μ, W ν] W μ ≡ (Wμ)i σi 2 .(7.68) 7.3 Mass Terms and \"Uniﬁcation\" of SU(2) and U(1) In the last section we couldn’t add mass terms like m1 ¯ΨΨ and m2(Wμ)i(Wμ)i to the Lagrangian without destroying the SU(2) symmetry. From ex- periments we know that the corresponding particles43 have mass 43 For example, the electron e− and the electron-neutrino νe, described by Ψ and the three bosons, described by (Wμ)i. and this is conventionally interpreted as the SU(2) symmetry being interaction theory 151 broken. This means the symmetry exists at high energy and sponta- neously breaks at lower energies. So far we derived a locally U(1) invariant Lagrangian and in this context it’s conventional to name the corresponding spin 1 ﬁeld Bμ: Llocally U(1) invariant = −m ¯ψψ + i ¯ψγμ(∂μ − igBμ)ψ − 1 4 BμνBμν (7.69) with Bμν := ∂μBν − ∂νBμ The spin 1 ﬁeld Bμ is often called U(1) gauge ﬁeld, because it makes the Lagrangian U(1) invariant. The locally SU(2) invariant Lagrangian is (Eq. 7.67) Llocally SU(2) invariant = i ¯ΨγμDμΨ − 1 4 Tr(WμνW μν) .(7.70) As above, the three spin 1 ﬁelds (Wν)i are called the SU(2) gauge ﬁelds, because they make the Lagrangian locally SU(2) invariant. We can combine them into one locally U(1) and locally SU(2) invariant Lagrangian44 44 We use here again the notation W μ = σj 2 Wμ j . LSU(2) and U(1) = i ¯Ψγμ(∂μ − igBμ − ig′W μ)Ψ − 1 4 Tr(WμνW μν) − 1 4 BμνBμν. (7.71) Now, how can we add mass terms to this Lagrangian without spoiling the SU(2) symmetry? The only ingredient we haven’t used so far is a spin 0 ﬁeld; so let’s see. The globally U(1) invariant La- grangian for a complex spin 0 ﬁeld is given by (Eq. 7.40) Lspin0 = 1 2 (∂μφ†∂μφ − m2φ†φ).(7.72) We can add to this Lagrangian the next higher power in φ without violating any symmetry constraints45. Thus we write, renaming the 45 Recall that only higher order deriva- tives were really forbidden in order to get a sensible theory. Higher powers of φ describe the self-interaction of the ﬁeld φ and were omitted in order to get a \"free\" theory. constants to their conventional names Lspin0+extraTerm = ∂μφ†∂μφ + ρ2φ†φ − λ(φ†φ)2.(7.73) We already know from Eq. 7.41 how we can add a coupling term between this spin 0 ﬁeld and a U(1) gauge ﬁeld Bμ, which makes the Lagrangian locally U(1) invariant: Lspin0+extraTerm+spin1Coupling = ((∂μ + igBμ)φ†)((∂μ − igBμ)φ) + ρ2φ†φ − λ(φ†φ)2 (7.74) with the symmetries46 46 See Eq. 7.13 and recall that an overall constant in the Lagrangian has no inﬂuence. 152 physics from symmetry Bμ → B′ μ = Bμ + ∂μa(x) (7.75) φ(x) → φ′(x)= eia(x)φ(x).(7.76) In the same way how we derived in the last chapter the locally SU(2) invariant Lagrangian for spin 1 2 ﬁelds, we can write a locally SU(2) invariant Lagrangian for doublets of spin 0 ﬁelds47 as47 Φ = (φ1 φ2 ) LSU(2) and U(1) = ((∂μ + ig′W μ + igBμ)Φ†)((∂μ − ig′W μ − igBμ)Φ) + ρ2Φ†Φ − λ(Φ†Φ)2 ︸ ︷︷ ︸ ≡−V(Φ) (7.77) with the doublet Φ := (φ1 φ2 ) and the symmetries48 (Eq. 7.58) 48 We use again the abbreviation U(x)= eibi (x) σi 2 for our local SU(2) transformations. W μ →W μ = U(x)W μU−1(x)+ i g (∂μU(x))U−1(x) (7.78) and Φ → Φ′ = U(x)Φ , Φ → Φ′ = ΦU†(x) .(7.79) We start with this locally SU(2) invariant Lagrangian and investigate in the following how this Lagrangian gives us mass terms for the ﬁelds W μ = Wμ i σi 2 and Bμ. Adding mass terms \"by hand\" to the Lagrangian does not work, because these terms spoil the symmetry and this leads to an insensible theory49. 49 The reason is quite complicated and will not be discussed in this book. In technical terms: We need a locally SU(2) symmetric Lagrangian to get a renormalizable theory. You are encouraged to read about this in the books mentioned at the end of this chapter. The term we deﬁned above V(Φ)= −ρ2Φ†Φ + λ(Φ†Φ)2 = −ρ2φ† 1 φ1 + λ(φ† 1 φ1)2 − ρ2φ† 2 φ2 + λ(φ† 2 φ2)2 = V1(φ1)+ V2(φ2) (7.80) is often called Higgs potential. A two-dimensional plot for different values of ρ, with λ > 0 can be seen in Fig. 7.1. The idea is that at very high temperatures, e.g. in the early uni- verse, the potential looks like in the image to the left. The minimum, in this context called the vacuum expectation value, is without am- biguity at φ = 0. With sinking temperature the parameters λ and ρ change, and with them the shape of the potential. After the temper- ature dropped below some critical value the potential no longer has its minimum at φ = 0, as indicated in the pictures to the right. Now there is not only one location with the minimum value, but many. Fig. 7.1: Two-dimensional illustration of the Higgs potential for different values of ρ, which is believed to have changed as the universe cooled down as a result of the expansion of the universe. Figure adapted from \"Spontaneous symmetry breaking\" by FT2 (Wikimedia Commons) released under a CC BY-SA 3.0 licence: http://creativecommons. org/licenses/by-sa/3.0/deed.en. URL: http://commons.wikimedia.org/ wiki/File:Spontaneous_symmetry_ breaking_(explanatory_diagram).png , Accessed: 8.12.2014 In fact, the potential has an inﬁnite number of possible minima. The minima of the potential can be computed in the usual way V(φ)= −ρ2φ†φ + λ(φ†φ)(φ†φ) (7.81) interaction theory 153 ∂V(φ) ∂φ = −2ρ2φ† + 2λ|φ|2φ† ! = 0(7.82) → φ†(−2ρ2 + 4λ|φ|2) ! = 0(7.83) →|φ|2 ! = ρ2 2λ (7.84) →|φ| ! = √ ρ2 2λ (7.85) φmin = √ ρ2 2λ eiϕ.(7.86) This is a minimum for every value of ϕ and we therefore have an inﬁnite number of minima. All these minima lie on a circle with radius √ ρ2 2λ . This can be seen in the three dimensional plot of the Higgs potential in Fig. 7.2. Like a marble that rolls down from the top of a sombrero, spontaneously one new vacuum value is chosen out of the inﬁnite possibilities. Fig. 7.2: 3-dimensional plot of the Higgs potential. Figure adapted from \"Mexican hat potential polar\" by Rupert Millard (Wikimedia Commons) released under a public domain licence. URL: http://commons.wikimedia.org/wiki/ File:Mexican_hat_potential_polar. svg , Accessed: 7.5.2014 From Eq. 7.80 we see that for the doublet, both components have this choice to make. We therefore have for the doublet the minimum Φmin = (φ1min φ2min ) .(7.87) An economical choice50 for the minimum is 50 Recall that symmetry breaking means that one minimum is chosen out of the inﬁnite possibilities. Φmin = ( 0√ ρ2 2λ ) ≡ ( 0 v√2 ) ,(7.88) where the factor 1 2 is just a convention to make computations easier and we deﬁne for brevity v ≡ √ ρ2 λ . We will learn later that in quan- tum ﬁeld theory computations are always done as a series expansion around the minimum, because no exact solutions are available. In order to get sensible results, we must therefore shift the ﬁeld Φ to the new minimum. We therefore consider the ﬁeld Φ = ( φ1r + iφ1c v√2 + φ2r + iφ2c ) .(7.89) This can be rewritten as51 51 This form is very useful as we will see in a moment. Φ = eiθi σi 2 ( 0 v+h√2 ) ,(7.90) 154 physics from symmetry because if we consider the series expansion of the exponential func- tion and the explicit form of the Pauli matrices σi (Eq. 3.80), we can see that in ﬁrst order eiθi σi 2 ( 0 v+h√2 ) ≈ (1 + i 1 2 θiσi) ( 0 v+h√2 ) =(1 + i 1 2 θ1σ1 + i 1 2 θ2σ2 + i 1 2 θ3σ3) ( 0 v+h√2 ) = ( 1 + i 1 2 θ3 i 1 2 θ1 + 1 2 θ2 i 1 2 θ1 − 1 2 θ2 1 − i 1 2 θ3 )( 0 v+h√2 ) = ((i 1 2 θ1 + 1 2 θ2) v+h√2 (1 − i 1 2 θ3) v+h√2 ) redeﬁnitions →≡ ( φ1r + iφ1c v√2 + φ2r + iφ2c ) . (7.91) Writing the complex spin 0 doublet in this form is useful, because we can now use the local SU(2) (gauge) symmetry to make com- putations simpler. In order to get physical results one gauge must be chosen and we prefer to work with a gauge that makes life the easiest52. 52 For different computations, different gauges can be useful. Here we will work with what is called the unitary gauge, that is particularly useful to understand the physical particle content of a theory. A general local SU(2) transformation is Φ → Φ′ = eibi(x) σi 2 Φ,(7.92) which enables us to eliminate the exponential factor in Eq. 7.90,by choosing appropriate bi(x). The complex scalar doublet is then, in this unitary gauge Φun = ( 0 v+h√2 ) .(7.93) Another possible way to understand this is that of the original four components that appeared in our complex scalar doublet, three are equivalent to our SU(2) gauge freedom53. Therefore, these three 53 Take note that this is only possible, because we have a local SU(2) theory, because our ﬁelds θ = θ(x), of course depend on the location in spacetime. For a global symmetry, these compo- nents can’t be gauged away, and are commonly interpreted as massless bosons, called Goldstone bosons. ﬁelds aren’t physical54 and can’t be measured in experiments. What 54 The local SU(2) symmetry is nothing that can be measured in experiments. This is merely a symmetry of our equa- tions and the gauge freedom disappears from everything that is measurable in experiments. Otherwise there would be no possible way to make predictions from our theory, because we would have an inﬁnite number of equivalently possible predictions (that are connected by SU(2) transformations). Neverthe- less, this symmetry is far from being useless, because it guides us to the correct form of the Lagrangian. remains is one physical ﬁeld h, which is called the Higgs ﬁeld. Next, we want to take a look at the implications of this symmetry breaking on the Lagrangian. We recite here the Lagrangian in ques- tion for convenience, which was derived in Eq. 7.74 and include an additional factor 1 2 in front of the ﬁeld Bμ to unclutter the notation in the calculations that follow55 55 Such a factor changes nothing, be- cause it corresponds simply to a redeﬁ- nition of the coupling constant 1 2 ˜g ≡ g. Thus, strictly speaking, we should use ˜g here instead of g. However, the name of the constant doesn’t matter and we continue to call the coupling constant simply g. interaction theory 155 L = ((∂μ + ig′ σi 2 (Wμ)i + i 1 2 gBμ)Φ†)((∂μ − ig′ σi 2 (Wμ)i − i 1 2 gBμ)Φ) − V(Φ) .(7.94) We now substitute the ﬁeld Φ with the shifted ﬁeld in the unitary gauge, which was deﬁned in Eq. 7.93. Of particular interest for us will be the newly appearing terms that include the constant vacuum value v. The other terms describe the self-interaction of the Higgs- ﬁeld and the interaction of the Higgs ﬁeld with the other ﬁelds, which we will not examine any further. If we put in the minimum value Φ → Φmin = ( 0 v√2 ) , which means we ignore h,weget ((∂μ + i σi 2 g′(Wμ)i + i 1 2 gBμ)Φ† min)((∂μ − ig′ σi 2 (Wμ)i − i 1 2 gBμ)Φmin) = ∣ ∣ ∣((∂μ + ig′ σi 2 (Wμ)i + i 1 2 gBμ)Φmin)∣ ∣ ∣2 = ∣ ∣ ∣((∂μ + ig′ σi 2 (Wμ)i + i 1 2 gBμ) √ 1 2 (0 v ) )∣ ∣ ∣2 = v2 8 ∣ ∣ ∣((g′σi(Wμ)i + gBμ) (0 1 ) )∣ ∣ ∣2. Now using that we have behind Bμ an implicit 2 × 2 identity matrix and the explicit form of the Pauli matrices56 σi yields 56 σiWi = ( W3 W1 − iW2 W1 + iW2 −W3 ) = v2 8 ∣ ∣ ∣ ( g′Wμ 3 + gBμ g′Wμ 1 − ig′Wμ 2 g′Wμ 1 + ig′Wμ 2 −g′Wμ 3 + gBμ )(0 1 ) ∣ ∣ ∣2 = v2 8 ∣ ∣ ∣( (g′Wμ 1 − ig′Wμ 2 −g′Wμ 3 + gBμ ) )∣ ∣ ∣2 = v2 8 ((g′)2((Wμ 1 )2 +(Wμ 2 )2) +(g′Wμ 3 − gBμ)2) (7.95) Next we deﬁne two new spin 1 ﬁelds from the old ones we have been using so far Wμ + ≡ 1 √2 (Wμ 1 − iWμ 2 ) (7.96) Wμ − ≡ 1 √2 (Wμ 1 + iWμ 2 ),(7.97) where Wμ + is the complex conjugate of Wμ −. The ﬁrst term in Eq. 7.95 is then (Wμ 1 )2 +(Wμ 2 )2 = 2(W+)μ(W−)μ (7.98) 156 physics from symmetry and thus we have, including the constants, ⎛ ⎜ ⎜ ⎝ g′v 2︸︷︷︸ ≡mW ⎞ ⎟ ⎟ ⎠ 2 (W+)μ(W−)μ (7.99) which then looks like a typical \"mass\" term. The second term in Eq. 7.95 can be written in matrix form (g′Wμ 3 − gBμ)2 = (Wμ 3 , Bμ) ( g′2 −gg′ −gg′ g2 ) ︸ ︷︷ ︸ ≡G (Wμ 3 Bμ ) .(7.100) In order to be able to interpret this as mass-terms, we need to diag- onalize57 the matrix G. The standard linear-algebra way to do this 57 We will see in a moment that a diagonalized matrix gives us terms that look exactly like the other mass terms. This enables us to interpret the corresponding ﬁelds as physical ﬁelds that can be observed in experiments. We could work with ﬁelds Wμ 3 and Bμ, but the physical interpretation would be much harder. needs the eigenvalues λ1, λ2 and normalized58 eigenvectors ⃗v1,⃗v2 of 58 Which means length 1, i.e. ⃗v · ⃗v = 1. the matrix G, which are λ1 = 0 → ⃗v1 = 1 √g2 + g′2 ( g g′ ) λ2 =(g2 + g′2) → ⃗v2 = 1 √g2 + g′2 ( g′ −g ) . The matrix G is then diagonalized by the matrix M build from the eigenvectors as its columns, i.e. Gdiag = M−1GM, with M = 1 √g2 + g′2 ( gg′ g′ −g ) (7.101) and Gdiag = (λ1 0 0 λ2 ) = (00 0 (g2 + g′2) ) .(7.102) The matrix M is orthogonal (MT = M−1), because we work with normalized eigenvectors: MT M = 1 √g2 + g′2 ( gg′ g′ −g ) 1 √g2 + g′2 ( gg′ g′ −g ) = 1 (g2 + g′2) ( g2 + g′2 gg′ − gg′ gg′ − gg′ g2 + g′2 ) = (10 01 ) .(7.103) We therefore add two unit matrices 1 = MT M, into Eq. 7.100: (Wμ 3 , Bμ) MMT ︸ ︷︷ ︸ =1 GMMT ︸ ︷︷ ︸ =1 (Wμ 3 Bμ ) = (Wμ 3 , Bμ) MMT GM︸ ︷︷ ︸ =Gdiag MT (Wμ 3 Bμ ) . (7.104) interaction theory 157 The remaining task is then to evaluate MT (Wμ 3 Bμ ) , in order to get the deﬁnition of two new ﬁelds, which have easily interpretable mass terms in the Lagrangian: MT (Wμ 3 Bμ ) = 1 √g2 + g′2 ( gg′ g′ −g )(Wμ 3 Bμ ) = 1 √g2 + g′2 ((gWμ 3 + g′Bμ) (g′Wμ 3 − gBμ) ) ≡ (Aμ Zμ ) .(7.105) We can therefore write the second term as (Aμ Zμ) Gdiag (Aμ Zμ ) = (Aμ Zμ) (00 0 (g2 + g′2) )(Aμ Zμ ) =(g2 + g′2)(Zμ)2 + 0 · (Aμ)2.(7.106) To summarize: We started with a Lagrangian, without mass terms for the spin 1 ﬁelds Wμ i and Bμ (Eq. 7.71) LSU(2) and U(1) = i ¯Ψγμ(∂μ − igBμ − ig′W μ)Ψ − 1 4 Tr(WμνW μν) − 1 4 BμνBμν. (7.107) Then we included interactions with a doublet of spin 0 ﬁelds (Eq. 7.77) and after the process of spontaneous symmetry breaking, we have new terms in the Lagrangian that are interpreted as mass terms59 59 For the ﬁrst term here, we combine Eq. 7.95 with Eq. 7.98. 1 4 v2g′2 ︸ ︷︷ ︸ =M2 W (W+)μ(W−)μ + 1 8 v2(g2 + g′2) ︸ ︷︷ ︸ = 1 2 M2 Z Z2 μ + 1 8 v20 ︸ ︷︷ ︸ photon mass =0 ·A2 μ .(7.108) We can see that one of the spin 1 ﬁelds Aμ remains massless after spontaneous symmetry breaking. This is the photon ﬁeld of electro- magnetism and all experiments up to now verify that the photon is massless 60. An important observation is that the ﬁeld responsible for 60 Take note that I omitted some very important notions in this section: Hypercharge and the Weinberg angle. The Weinberg angle θW is simply deﬁned as cos(θW )= g√g2+g′2 or sin(θW )= g′ √g2+g′2 . This can be used to simplify some of the deﬁnitions mentioned in this section. Hypercharge is a bit more complicated to explain and those who want to dig deeper are referred to the standard texts about quantum ﬁeld theory, some of which are recommended at the end of Chapter 9. Z-bosons Zμ and the ﬁeld responsible for photons Aμ are orthogonal linear combinations of the ﬁelds Bμ and W3 μ. Therefore we can see that both have a common origin! The same formalism can be used to get mass terms for spin 1 2 ﬁelds without spoiling the local SU(2) symmetry, but before we discuss this, we need to talk about one very curious fact of nature: parity violation. 158 physics from symmetry 7.4 Parity Violation One of the biggest discoveries in the history of science was that na- ture is not invariant under parity transformations. In layman’s terms this means that some experiments behave differently than their mir- rored analogue. The experiment that discovered the violation of parity symmetry was the Wu experiment. A full description of this experiment, although fascinating, strays from our current subject, so let’s just discuss the ﬁnal result. The Wu experiment discovered that the particles mediating the weak force (the W+, W−, Z bosons) only couple to left-chiral parti- cles. In other words: only left-chiral particles interact via the weak force61. All particles produced in weak interactions are left-chiral. 61 We will discuss at the end of this section why this means that parity is violated Neutrinos interact exclusively via the weak force and therefore it is possible that there are no right-chiral neutrinos62. All other particles 62 We will see in a moment that massive, left-chiral particles always get a right- chiral component during propagation. It is known from experiments that neutrinos have mass and therefore we would expect a right-chiral neutrino component. Nevertheless, this right- chiral component does not participate in any known interaction. can be produced via other interactions and therefore can be right- chiral, too. Up to this point, we used left-chiral and right-chiral as labels for objects transforming according to different representations of the Lorentz group. Although this seems like something very abstract, we can measure the chirality of particles, because there is a correlation to a more intuitive concept called helicity63. 63 We will not discuss this here, because the details make no difference for the purpose of the text. The message to take away is that it can be done. A very nice discussion of these matters can be found in Alessandro Bettini. Intro- duction to Elementary Particle Physics. Cambridge University Press, 2nd edi- tion, 4 2014. ISBN 9781107050402 In fact, most of the time particles do not have a speciﬁed chirality, which means they aren’t deﬁnitely left-chiral or right-chiral and the corresponding Dirac spinor Ψ has both components. Parity viola- tion was no prediction of the theory and a total surprise for every physicist. Until the present day, no one knows why nature behaves so strangely. Nevertheless, it’s easy to accommodate this discovery into our framework. We only need something that makes sure we always deal with left-chiral spinors when we describe weak interactions. Recall that the symbols χ and ξ denote Weyl spinors (two compo- nent objects), ψ Dirac spinors (four component objects, consisting of two Weyl spinors) ψ = (χL ξR ) (7.109) and Ψ doublets of Dirac spinors Ψ = (ψ1 ψ2 ) .(7.110) Then the \"something\" we need is the projection operator PL: PLψ = PL (χL ξR ) = (χL 0 ) ≡ ψL.(7.111) interaction theory 159 Such a projection operator can be constructed using the matrix64 64 Recall the deﬁnition of the γμ matri- ces in Eq. 6.13 and don’t let yourself get confused about the missing γ4 matrix. There is an alternative convention that uses γ4 instead of γ0 and to avoid inter- ference between those conventions, the matrix here is commonly called γ5. γ5 = iγ0γ1γ2γ3 = (−10 01 ) .(7.112) The matrix γ5 is called the chirality operator, because states of pure chirality (χL 0 ) or ( 0 ξR ) are eigenstates of γ5 with eigenvalue −1 and +1 respectively. The projection operator PL can then be written65 65 Maybe you wonder why we deﬁne PL as so complicated and do not start with the explicit matrix form right away. We do this, because it’s possible to work in a different basis where the matrices γμ look completely different. (For more information about this have a look at Section 8.10). Take note that in the Lagrangian the Dirac spinors appear al- ways in combination with the matrices γμ. We can always add a 1 = U−1U, with some arbitrary invertible ma- trix U, between them. For example, ∂μ ¯ΨγμΨ = ∂μ ¯Ψ U−1U︸ ︷︷ ︸ =1 γμ U−1U︸ ︷︷ ︸ =1 Ψ = ∂μ ¯ΨU−1 ︸ ︷︷ ︸ = ¯Ψ′ UγμU−1 ︸ ︷︷ ︸ γ′ μ UΨ︸︷︷︸ Ψ′ . Physics is of course completely independent of such transformations, but we can use this to simplify computations. The basis we prefer to work with in this text is called Weyl Basis. In other bases the two com- ponents of a Dirac spinor are mixtures of χL and ξR. Nevertheless, the projec- tion operator deﬁned as PL = 1−γ5 2 , always projects out the left-chiral component, because PWeyl L ΨWeyl = ΨWeyl L ⇒ P′ LΨ′ = 1−γ′ 5 2 Ψ′ ︸︷︷︸ UΨWeyl = 1−Uiγ0U−1Uγ1U−1Uγ2U−1Uγ3U−1 2 UΨWeyl = U−Uiγ0γ1γ2γ3 2 ΨWeyl = U ( 1−γ5 2 ) ΨWeyl = UΨWeyl L = Ψ′ L ✓ PL = 1 − γ5 2 = (10 00 ) (7.113) and we can deﬁne analogously PR = 1 + γ5 2 = (00 01 ) .(7.114) Now, in order to accommodate for the fact that only left-chiral particles interact via the weak force, we must simply include PL into all terms of the Lagrangian that describe the interaction of W± μ and Zμ with different ﬁelds. The corresponding terms were derived in Section 7.2, and the ﬁnal result was Eq. 7.67, which we recite here for convenience: Llocally SU(2) invariant = i ¯ΨγμDμΨ − 1 4 Tr(WμνW μν) = i ¯Ψγμ(∂μ − igW μ)Ψ − 1 4 Tr(WμνW μν).(7.115) The relevant term that describes the interaction is g ¯ΨγμW μΨ and we simply add PL: → L = i ¯Ψγμ(∂μ − igW μPL)Ψ − 1 4 Tr(WμνW μν).(7.116) Here PL acts on a doublet and is therefore PLΨ = (PL 0 0 PL )(ψ1 ψ2 ) = ((ψ1)L (ψ2)L ) .(7.117) One PL is enough to project the left-chiral component out of both doublets ¯Ψ and Ψ. To see this we need three identities: • (PL)2 = PL, which is obvious from the explicit matrix form and because every projection operator must have this property66.Pro- 66 Another deﬁning condition of any projection operator is PL PR = PR PL = 0, which is here fulﬁlled as you can check by using the explicit form of PL,PR and γ5. jecting twice must be the same as projecting one time. 160 physics from symmetry • {γ5, γμ} = γ5γμ + γμγ5 = 0, which you can check by brute force computation67. 67 Or using another identity {γμ, γν} = γμγν + γνγμ = 1 2 ημν, where ημν is the Minkowski metric and the deﬁnition γ5 = iγ0γ1γ2γ3. • (PL)† = PL, because γ5 is real, as can be seen from the explicit matrix form: γ5 = (−10 01 ) The second identity simply tells us that γ5γμ = −γμγ5, i.e. that we can switch the position of γ5 and any γμ matrix, as long as we include a minus sign. This tells us γμPL = γμ 1 − γ5 2 = 1 + γ5 2 γμ = PRγμ.(7.118) We can now rewrite the relevant term of Eq. 7.116: g ¯ΨγμW μPLΨ = g ¯ΨγμW μ P2 L︸︷︷︸ =PL Ψ = g ¯Ψ︸︷︷︸ Ψ†γ0 γμPL ︸ ︷︷ ︸ PRγμ W μ PLΨ ︸︷︷︸ ΨL = gΨ† γ0PR︸ ︷︷ ︸ PLγ0 γμW μΨL =︸︷︷︸ Using P† L =PL and (AB)†=((AB)T )⋆=(BT AT )⋆=B† A† (PLΨ)†γ0γμW μΨL = g(PLΨ ︸︷︷︸ =ΨL )†γ0γμW μΨL = g ¯ΨLγμW μΨL ✓ (7.119) We can see here that one projection operator is really enough to guarantee that both Ψ and ¯Ψ are left-chiral. Now we know how we can describe mathematically that only left- chiral ﬁelds interact via the weak force, but why does this mean that parity is violated? To understand this we need to parity transform this term, because if it isn’t invariant, the physical system in question is different from its mirror image68. Here we need the parity operator 68 This means an experiment, whose outcome depends on this term of the Lagrangian, will ﬁnd a different outcome if everything in the experiment is arranged mirrored. for spinors69 Pspinor and vectors70 Pvector. The transformation yields 69 The parity operator for spinors was derived in Section 3.7.9. Using the γμ matrices, we can write the parity operator derived there as P = γ0 =( 0 σ0 σ0 0 ) = (01 10 ) 70 The parity operator for vectors is simply Pvector = ⎛ ⎜ ⎜ ⎝ 1 000 0 −10 0 00 −10 00 0 −1 ⎞ ⎟ ⎟ ⎠ as already mentioned in Eq. 3.140. ¯Ψ︸︷︷︸ =Ψ†γ0 γμW μPLΨ → (PspinorΨ)†γ0γμ(PvectorW μ)PL(PspinorΨ) =(Ψ)†γ0γ0γμ(PvectorW μ)PLγ0Ψ =︸︷︷︸ using {γ5, γ0} = 0 and PL = 1−γ5 2 (Ψ)†γ0γ0γμγ0(PvectorW μ)PRΨ.(7.120) interaction theory 161 Then we can use γ0γ0γ0 = γ0 and γ0γiγ0 = −γi, as you can check by looking at the explicit form of the matrices. Furthermore, we have PvectorW0 = W0 and PvectorWi = −Wi, which follows from the explicit form of Pvector. We conclude these two minus signs cancel each other and the parity transformed term of the Lagrangian reads: (PspinorΨ)†γ0γμ(PvectorW μ)PL(PspinorΨ)= ¯ΨγμW μPRΨ ̸= ¯ΨγμW μPLΨ (7.121) Therefore this term is not invariant and parity is violated. Parity violation has another important implication. Recall that we always write things below each other between two big brackets if they can transform into each other71. For example, we use four- 71 This is explained in Appendix A. vectors, because their components can transform into each other through rotations or boosts. In this section we learned that only left- chiral particles interact via the weak force and the correct term in the Lagrangian is ¯ΨγμW μPLΨ = ¯ΨLγμW μΨL. In physical terms this term means that the components of the left-chiral doublets, which means the two spin 1 2 ﬁelds (ψ1)L and (ψ2)L can transform into each other through weak-interactions. Right-chiral ﬁelds do not interact via the weak force and therefore (ψ1)R, (ψ2)R aren’t transformed into each other. Therefore writing them below each other between two big brackets makes no sense. In mathematical terms this means that right-chiral ﬁelds form SU(2) singlets, i.e. are objects transforming according to the 1 dimensional representation of SU(2), which do not change at all72. So let’s summarize: 72 This was explained in Section 3.6.2. • Left-chiral ﬁelds are written as SU(2) doublets: ΨL = ((ψ1)L (ψ2)L ) , because they interact via the weak force and therefore can trans- form into each other. They transform under the two-dimensional representation of SU(2): ΨL → Ψ′ L = ei⃗a⃗σ 2 ΨL .(7.122) • Right-chiral ﬁelds are described by SU(2) singlets: (ψ1)R, (ψ2)R, because they do not interact via the weak force and therefore can’t transform into each other. Therefore they transform under the one-dimensional representation of SU(2): (ψ1)R → (ψ1)′ R = e 0(ψ1)R =(ψ1)R (ψ2)R → (ψ2)′ R = e 0(ψ2)R =(ψ2)R .(7.123) Now we move on and try to understand how mass terms for spin 1 2 particles can be added in the Lagrangian without spoiling any crucial symmetry. 162 physics from symmetry 7.5 Lepton Mass Terms At the beginning of Section 7.2, we discovered that we can’t include arbitrary mass terms ¯ΨmΨ without spoiling the SU(2) symmetry. Now we will see that parity violation makes this problem even big- ger. After discussing the problem, we will see that again the Higgs mechanism is a solution. In the last section we talked a bit about the chirality of the cou- pling term: ¯ΨγμσjWμ j PLΨ. What about the chirality of a mass term? Take a look again at the invariants without derivatives for spinors, which we derived in Eq. 6.7 and Eq. 6.8: I1 :=(χ ˙a)Tξ ˙a =(χL)†ξR and I2 :=(ξ a)Tχa =(ξR)†χL (7.124) We can write these invariants using Dirac spinors as7373 The Dirac spinors ψL and ψR are deﬁned using the chiral-projection operators introduced in the last section: ψL = PLψ and ψR = PRψ. And we have as always ¯ψ = ψ†γ0. ¯ψψ = ¯ψLψR + ¯ψRψL = (χ† L 0) ( 0 σ0 σ0 0 )( 0 ξR ) + (0 ξ† R) ( 0 σ0 σ0 0 )(χL 0 ) = χ† LξR + ξ† RχL ✓ (7.125) We can see that Lorentz invariant mass terms always combine left- chiral with right-chiral ﬁelds. This is a problem, because left-chiral and right-chiral ﬁelds transform differently under SU(2) transfor- mations, as explained at the end of the last section. The left-chiral ﬁelds are doublets, whereas the right-chiral ﬁelds are singlets. The multiplication of a doublet and singlet is not SU(2) invariant. For example ¯ΨL︸︷︷︸ doublet ψR ︸︷︷︸ singlet → ¯Ψ′ Lψ′ R = ¯ΨLe−ibi σi 2 ψR ̸= ¯ΨLψR (7.126) From the experience with mass terms for spin 1 ﬁelds, we know what to do: Instead of considering terms as above, we add SU(2) invariant coupling terms with 0 ﬁelds to the Lagrangian. Then, by choosing the vacuum value for the spin 0 ﬁeld we break the symme- try and generate mass terms. A SU(2), U(1) and Lorentz invariant term, coupling a spin 0 dou- blet and our spin 1 2 ﬁelds together, is given by ¯ΨLΦψR.(7.127) To see the invariance we transform this term with a SU(2) trans- formation7474 Remember ΦL → Φ′ L = eibi (x)σi ΦL and σ† i = σi interaction theory 163 ¯ΨLΦψR → ¯Ψ′ LΦ′ψR = ¯ΨLe−ibi(x)σi eibi(x)σi ΦψR = ¯ΨLΦψR ✓ and equally for a U(1) transformation: ¯ΨLΦψR → ¯Ψ′ LΦψ′ R = ¯ΨLe−ia(x)Φeia(x)ψR = ¯ΨLΦψR ✓ The spin 0 ﬁeld does not transform at all under Lorentz transfor- mations75 and therefore the term is Lorentz invariant, because we 75 By deﬁnition a spin 0 ﬁeld transforms according to the (0, 0) representation of the Lorentz group. In this represen- tation all Lorentz transformations are trivially the identity transformation. This was derived in Section 3.7.4. have the same Lorentz invariant terms as in Eq. 7.125. This kind of term is called Yukawa term and we add it, with the equally allowed Hermitian conjugate to the Lagrangian76 −λ2 76 The strange name −λ2 and why only add ψ2R here will become clear in a moment, because terms including ψ1R and −λ1 will be discussed afterwards. L = −λ2( ¯ΨLΦψ2R + ¯ψ2R ¯ΦΨL).(7.128) The coupling constant λ2 is called a Yukawa coupling. This extra term does not only describe the interaction between the fermions and the Higgs ﬁeld, but also leads to mass terms for the spin 1 2 ﬁelds after the symmetry breaking. We put the expansion around the vacuum expectation value (Eq. 7.88) Φ = √ 1 2 ( 0 v + h ) into the Lagrangian, which yields L = − λ2√2 (( ¯Ψ1L, ¯Ψ2L) ( 0 v + h ) ψ2R + ¯ψ2R (0, v + h) (Ψ1L Ψ2L )) = − λ2(v + h) √2 ( ¯Ψ2Lψ2R + ¯ψ2RΨ2L) .(7.129) Equation 7.125 tells us this is equivalent to = − λ2(v + h) √2 ¯ψ2ψ2 (7.130) = − λ2v √2 ( ¯ψ2ψ2) ︸ ︷︷ ︸ Fermion mass term − λ f h √2 ( ¯ψ2ψ2) ︸ ︷︷ ︸ Fermion-Higgs interaction .(7.131) We see that through the Higgs mechanism we get indeed the re- quired mass terms. Again, we used symmetry constraints to add a term to the Lagrangian and this yields after spontaneous symmetry breaking mass terms for the spin 1 2 ﬁelds. Take note that we only generated mass terms for the second ﬁeld inside the doublet ψ2. What about mass terms for the ﬁrst ﬁeld ψ1? To get mass terms for the ﬁrst ﬁeld ψ1 we need to consider cou- pling terms to the charge-conjugated77 Higgs ﬁeld ˜Φ = ϵΦ⋆, because 77 Charge conjugation is explained in Section 3.7.10. 164 physics from symmetry Φ = ( 0 v+h√2 ) → ˜Φ = ϵΦ⋆ = ( 01 −10 )( 0 v+h√2 ) = ( v+h√2 0 ) .(7.132) Following the same steps as above with the charge conjugated Higgs ﬁeld leads to mass terms for ψ1: L = −λ f ( ¯ΨL ˜Φψ1R + ¯ψ1R ˜¯ΦΨL) = − λ1√2 (( ¯Ψ1L, ¯Ψ2L) ( v+h√2 0 ) Ψ1R + ¯Ψ1R ( v+h√2 0 )(Ψ1L Ψ2L )) = − λ1(v + h) √2 ( ¯Ψ1LΨ1R + ¯Ψ1RΨ1L) .(7.133) To understand the rather abstract spin 1 2 doublets better, we rewrite them more suggestively7878 A neutrino is always denoted by a ν. In this step we simply give the two ﬁelds in the doublet ψ1 and ψ2 their conventional names: electron ﬁeld e and electron-neutrino ﬁeld νe. Ψ = (νe e ) (7.134) and equivalently for the other leptons μ, νμ and τ, ντ. This form of the doublets is suggested by experiments, because an electron e is always transformed by weak interactions into another electron e, with possibly different momentum, or an electron-neutrino ve plus other particles. In weak interactions e and νe (equivalently μ and νμ or τ and ντ) always appear in pairs. This can be understood by looking at the coupling term ¯ΨγμW μPLΨ = ¯Ψγμ(Wμ)i σi 2 PLΨ. As discussed in the last section this can be rewritten using the explicit matrix form of the Pauli matrices79 σi, which then gives us terms coupling the 79 This gives us once more σiWμ i = ( Wμ 3 Wμ 1 − iWμ 2 Wμ 1 + iWμ 2 −Wμ 3 ) which we can rewrite using W± = 1√2 (W1 ∓ W2): ⇒ σiWμ i = ( Wμ 3 √2W+√2W− −Wμ 3 ) components of the doublets together: ¯ΨγμσjWμ j PLΨ = ( ¯νe ¯e) γμ ( Wμ 3 √2W+√2W− −Wμ 3 ) PL (νe e ) =︸︷︷︸ using Eq. 7.116 (( ¯νe)L ( ¯e)L) γμ ( Wμ 3 √2W+√2W− −Wμ 3 )((νe)L (e)L ) =( ¯νe)LγμWμ 3 (νe)L +( ¯νe)Lγμ√2W+(e)L +( ¯e)Lγμ√2W−(νe)L − ( ¯e)LγμWμ 3 (e)L.(7.135) If we want to consider all lepton generations at once, i.e. e, μ and τ, we need to write down three terms like this into the Lagrangian: ¯ΨeγμσjWμ j PLΨe + ¯ΨμγμσjWμ j PLΨμ + ¯ΨτγμσjWμ j PLΨτ,(7.136) interaction theory 165 which can be written more compactly by introducing Ψl = (νl l ) , where l = e, μ, τ: ¯ΨlγμσjWμ j PLΨl. Using the notation l = (lL lR ) the coupling term between the spin 0 and the electrically charged spin 1 2 ﬁelds after spontaneous symmetry breaking reads − λlv √2 ︸︷︷︸ Fermion mass mL (¯ll) − λlh √2 ︸︷︷︸ Fermion-Higgs interaction strength cL (¯ll) . The terms for the corresponding neutrinos follow analogously80. 80 As already mentioned above, we can only write down such mass terms if there are right-chiral neutrinos. However, so far right-chiral neutrinos were never observed in experiments, although we know that neutrinos have mass. This is one of the open problems of the standard model. This Lagrangian enables us to predict something about the Higgs ﬁeld h that can be tested in experiments. For a given lepton l, the mass is given by ml = λlv √2 → λl = ml√2 v (7.137) and the coupling strength of this lepton to the Higgs is given by cl = λlh √2 =︸︷︷︸ Eq. 7.137 mlh v .(7.138) The last equation means that the coupling strength of the Higgs to a lepton is proportional to the mass of the lepton. The heavier the lepton the stronger the coupling. The same is true for all particles and the derivation is completely analogous. There are other spin 1 2 particles, called quarks, that interact via the weak force. In addition, quarks interact via a third force, called the strong force and this will be the topic of Section 7.8, but ﬁrst we want to talk about mass terms for quarks. Luckily, these can be incorporated analogous to the lepton mass terms. 7.6 Quark Mass Terms We learned in the last section that an SU(2) doublet contains the particles that are transformed into each other via the weak force. For quarks81 these are the up- and down quark: 81 If you’ve never heard of quarks before, have a look at Section 1.3. q = (u d ) (7.139) 166 physics from symmetry and equally for the strange and charm or top and bottom quarks. Again, we must incorporate the experimental fact that only left- chiral particles interact via the weak force. Therefore, we have left- chiral doublets and right-chiral singlets: qL ︸︷︷︸ doublet = (uL dL ) → eiai σi 2 qL (7.140) uR︸︷︷︸ singlet → uR dR︸︷︷︸ singlet → dR.(7.141) Again, right-chiral particles do not interact via the weak force and therefore they aren’t transformed into anything and form a SU(2) singlet (=one component object). The problem is the same as for leptons: To get something Lorentz invariant, we need to combine left-chiral with right-chiral spinors. Such a combination is not SU(2) invariant and we use again the Higgs mechanism. This means, instead of terms like ¯qLuR + ¯qLdR + ¯uRqL + ¯dRqL,(7.142) which aren’t SU(2) invariant, we consider the coupling of the quarks to a spin 0 ﬁeld doublet Φ: λu ¯qL ˜ΦuR + λd ¯qLΦdR + λu ¯uR ˜ΦqL + λd ¯dRΦqL,(7.143) with coupling constants λu, λd and the charge conjugated Higgs doublet82 which is needed in order to get mass terms for the up 82 This is deﬁned in Eq. 7.132: ˜Φ = ϵΦ⋆ =︸︷︷︸ ( v+h√2 0 ) . quarks83.83 We deﬁned the doublets as (u d ). Multiplication of this doublet with Φ = ( 0 v+h√2 ) always results in terms proportional to d. Then, everything is analogous to the lepton case: We put the expansion of the Higgs ﬁeld around its minimum84 into the La- 84 Φ = ( 0 v+h√2 ) and equivalently for the charge-conjugated Higgs ﬁeld. grangian, which gives us mass terms plus quark-Higgs coupling terms. 7.7 Isospin Now it’s time we talk about the conserved quantity that follows from SU(2) symmetry. The free Lagrangians are only globally invari- ant and we need interaction terms to make them locally symmet- ric. Recall that global symmetry is a special case of local symmetry. Therefore we have global symmetry in every locally invariant La- grangian and the corresponding conserved quantity is conserved for interaction theory 167 both cases. The result will be that global SU(2) invariance gives us through Noether’s theorem, a new conserved quantity called isospin. This is similar to electric charge, which is the conserved quantity that follows from global U(1) invariance. Noether’s theorem for internal symmetry (Section 4.5.5, especially Eq. 4.57) tells us that ∂0 ∫ d3x ∂L ∂(∂0Ψ) δΨ ︸ ︷︷ ︸ =Q = 0(7.144) The Lagrangian is invariant under transformations of the form Ψ → eiai σi 2 Ψ =(1 + iai σi 2 + ...)Ψ (7.145) Therefore our inﬁnitesimal variation is δΨ = iai σi 2 Ψ, with arbitrary ai. This tells us we get one conserved quantity for each generator, because the Lagrangian is invariant regardless of if two of the three ai are zero and one isn’t. For example, a2 = a3 = 0 and a1 ̸= 0or a1 = a2 = 0 and a3 ̸= 0. Of course we get another conserved quantity for a1 ̸= 0, a2 ̸= 0 and a3 ̸= 0, which is just the sum of the conserved quantities we get from the individual generators. In other words: we get three independently conserved quantities, one for each generator of SU(2). The globally invariant, free Lagrangian (Eq. 7.44)is LD1+D2 = i ¯Ψγμ∂μΨ. The corresponding conserved quantities Qi, for example for the electron-neutrino doublet, are85 85 See Eq. 7.144 and as always deﬁned without the arbitrary constants ai. Qi = i ¯Ψγ0 σi 2 Ψ = (ve e )† γ0γ0︸ ︷︷ ︸ =1 σi 2 (ve e ) .(7.146) Recall that only σ3 is diagonal. This means we are only able to assign a deﬁnite value to the two components of the doublet (ve, e) for the conserved quantity i = 3. For the other generators, σ1 and σ2, our two components ve and e aren’t eigenstates. We are of course free to choose a different basis, where for example σ2 is diagonal. Then we can simply redeﬁne what we call ve and e and get the same result. The thing to take away is that although we have three conserved quantities, one for each generator, we can only use one at a time to label our particles/states. 168 physics from symmetry For i = 3wehave Q3 = (ve e )† σ3 2 (ve e ) = 1 2 (ve e )† (10 0 −1 )(ve e ) = 1 2 v† e ve − 1 2 e†e (7.147) This means we can assign Q3(ve)= 1 2 and Q3(e)= − 1 2 as new particle labels. In contrast for i = 1, we have Q1 = (ve e )† σ1 2 (ve e ) = 1 2 (ve e )† (01 10 )(ve e ) = 1 2 v† e e + 1 2 e†ve (7.148) and we can’t assign any particle labels here, because the matrix σ1 isn’t diagonal. 7.7.1 Labelling States Recall that in Section 3.5, we introduced the notion of Cartan genera- tors, which is the set of diagonal generators of a given group. In the last section we learned that these generators become especially use- ful if we want to give new labels to our particles inside a doublet8686 In a later section we will learn that the same can be done for triplets and the conserved quantities following from SU(3) invariance. object. A typical SU(2) doublet is of the form (ve e ) .(7.149) We can’t diagonalize two or more elements of the Lie algebra su(2) at the same time and thus the \"Cartan subalgebra\" consists of only only one element87. It is conventional to choose J3 = 1 2 σ3 as diagonal. 87 This can be seen by noting that there are no commuting generators in su(2). Only commuting generators can be diagonalized at the same time. The corresponding eigenvalues are + 1 2 and − 1 2 . A left-chiral neutrino(ve 0 ) is an eigenstate of this generator, with eigenvalue + 1 2 and a left-chiral electron (0 e ) an eigenstate of this generator, with eigen- value − 1 2 . These are new particle labels, which are called the isospin of the neutrino and the electron. interaction theory 169 Following the same line of thoughts we can assign an isospin value to the right-chiral singlets. These transform according to the one-dimensional representation of SU(2), and the generators are in this representation simply zero88: Ji = 0. Therefore, in this one- 88 The right-chiral singlets do not trans- form at all as explained in Section 3.7.4.dimensional representation, the singlets are eigenstates of the Cartan generator J3 with eigenvalue zero. The right-chiral singlets, like eR carry isospin zero. This coincides with the remarks above that right- chiral ﬁelds do not interact via the weak force. Just as electrically uncharged objects do not interact via electromagnetic interactions, ﬁelds without isospin do not take part in weak interactions. Finally, we can assign isospin values to the three gauge ﬁelds Wμ +, Wμ −, Wμ 3 . The three gauge ﬁelds form a SU(2) triplet Wμ = ⎛ ⎜ ⎝Wμ + Wμ − Wμ 3 ⎞ ⎟ ⎠ ,(7.150) which transforms according to the three dimensional representation of SU(2). In this representation the Cartan generator J3 has eigenval- ues89 +1, −1, 0 and therefore we assign Q3(Wμ +)= 1, Q3(Wμ −)= −1, 89 This can be seen directly from the explicit matrix form of J3 in Eq. 3.129: J3 = ⎛ ⎝10 0 00 0 00 −1 ⎞ ⎠. Q3(Wμ 3 )= 0. This is the isospin of the W+ and the W− bosons. Take note that the triplet (Wμ 1 Wμ 2 Wμ 3 ) simply belongs to a differ- ent basis, where J3 isn’t diagonal. This can be seen as another reason for our introduction of Wμ ±. If this is unclear, have a look at how we introduced the three gauge ﬁelds Wμ i . They were included into the Lagrangian in combination with the generators σiWμ i . This can be seen as a basis expansion of some objects Wμ in terms of the basis σi: W μ = σiWμ i = σ1Wμ 1 + σ2Wμ 2 + σ3Wμ 3 , analogous to how we can write a vector in terms of basis vectors: ⃗v = v1⃗e1 + v2⃗e2 + v3⃗e3. The generators σi live in the Lie algebra90 of SU(2) and consequently 90 The Lie algebra is a vector space! our object W μ lives there, too. Therefore, if we want to know how Wμ transforms, we need to know the representation of SU(2) on this vector space, i.e. on its own Lie algebra. In other words: We need to know how the group elements of SU(2) act on their own Lie algebra elements, i.e. its generators. This may seem like a strange idea at ﬁrst, but actually is a quite natural idea. Recall how we deﬁned a representation: a representation is a map91 from the group to the 91 To be precise: A homomorphism, which is a map that satisﬁes some special conditions. space of linear operators over a vector space. So far we only looked 170 physics from symmetry at \"external\" vector spaces like Minkowski space. The only intrinsic vector space that comes with a group is its Lie algebra92 ! Therefore 92 A group itself is in general no vector space. Although we can take a look at how the group acts on itself, this is not a representation, but a realization of the group. it isn’t that strange to ask what a group representation on this vector space looks like. This very important representation is called the adjoint representation. Gauge ﬁelds (like W+, W−, W3) are said to live in the adjoint rep- resentation of the corresponding group. For SU(2) the Lie algebra is three dimensional, because we have three basis generators and there- fore the adjoint representation is three dimensional. Exactly how we are able to write the components of a vector between two brackets93, 93 ⃗v = ⎛ ⎝v1 v2 v3 ⎞ ⎠ we can write the component of Wμ between two brackets94, which is 94 Wμ = ⎛ ⎝Wμ 1 Wμ 2 Wμ 3 ⎞ ⎠ what we call a triplet . The generators in the adjoint representation are connected to the three dimensional generator we derived earlier through a basis transformation. In the following section we move on to the \"next higher\" internal symmetry group SU(3). Demanding local SU(3) invariance of the Lagrangian gives us the correct Lagrangian which describes strong interactions. 7.8 SU(3) Interactions For three fermion ﬁelds we can ﬁnd a locally SU(3) invariant La- grangian in exactly the same way we did in the last chapter for two ﬁelds and SU(2). This symmetry is not broken and the correspond- ing spin 1 ﬁelds, called gluon ﬁelds, are massless. SU(3) is the group of all unitary 3 × 3 matrices with unit determinant, i.e. U†U = UU† = 1 det U = 1. (7.151) As usual for Lie groups we can write this as an exponential func- tion9595 As already noted in Section 2.4, Capital Roman letters A, B, ... are always summed from 1 to 8. U = eiTAθA .(7.152) The deﬁning equations (Eq. 7.151) of the group require, as for96 96 See Eq. 3.79 and the following text plus equations, where the basis was given by the 2 × 2 Pauli matrices. SU(2), the generators to be Hermitian and traceless T† A = TA (7.153) tr(TA)= 0. (7.154) A basis for those traceless, Hermitian generators is, at least in one representation, given by eight97 3 × 3 matrices, called Gell-Mann 97 It can be shown that in general for SU(N) the Lie-Algebra is N2 − 1 dimensional. matrices: interaction theory 171 λ1 = ⎛ ⎜ ⎝ 010 100 000 ⎞ ⎟ ⎠ λ2 = ⎛ ⎜ ⎝ 0 −i 0 i 00 000 ⎞ ⎟ ⎠ λ3 = ⎛ ⎜ ⎝ 100 0 −10 000 ⎞ ⎟ ⎠ λ4 = ⎛ ⎜ ⎝ 001 000 100 ⎞ ⎟ ⎠ λ5 = ⎛ ⎜ ⎝ 00 i 00 0 −i 00 ⎞ ⎟ ⎠ λ6 = ⎛ ⎜ ⎝ 000 001 010 ⎞ ⎟ ⎠ λ7 = ⎛ ⎜ ⎝ 00 0 00 −i 0 i 0 ⎞ ⎟ ⎠ λ8 = 1 √3 ⎛ ⎜ ⎝ 10 0 01 0 00 −2 ⎞ ⎟ ⎠ .(7.155) The generators of the group are connected to these Gell-Mann ma- trices, just as the Pauli matrices were connected to the generators98 98 Ji = σi 2 , see Eq. 3.81 and the explana- tions there.of the SU(2) group via TA = 1 2 λA. The Lie algebra for this group is given by [TA, TB]= if ABCTC,(7.156) where we adopted the standard convention that capital letters like A, B, C can take on every value from 1 to 8. f ABC are called the struc- ture constants of SU(3), which for SU(2) were given by the Levi- Civita symbol ϵijk. They can be computed by brute-force computa- tion, which yields99 99 This is not very enlightening, but we list it here for completeness.f 123 = 1(7.157) f 147 = − f 156 = f 246 = f 257 = f 345 = − f 367 = 1 2 (7.158) f 458 = f 678 = √3 2 ,(7.159) where all others can be computed from the fact that the structure constants f ABC are antisymmetric under permutation of any two indices. For example f ABC = − f BAC = − f CBA.(7.160) All other possibilities, which cannot be computed by permutation, vanish. Analogous to what we did for SU(2) in Section 7.2, we introduce a triplet of spin 1 2 ﬁelds Q = ⎛ ⎜ ⎝q1 q2 q3 ⎞ ⎟ ⎠ (7.161) and exactly as for SU(2) we get new labels for the objects inside this triplet. We will discuss these new labels in the next section. 172 physics from symmetry To make the Lagrangian L = iQ∂μγμQ − QmQ (7.162) locally SU(3) invariant, one again adds coupling terms between the spin 1 2 ﬁelds and new spin 1 ﬁelds. The derivation is analogous as for SU(2), but the computations are quite cumbersome, so we just quote the ﬁnal Lagrangian100100 Remember: the sum over capital letters (A, B, C, ...) runs from 1 to 8 L = − 1 4 GαβG αβ + Q(iDμγμ − m)Q,(7.163) and the ﬁeld strength tensor Gαβ for the spin 1 gluon ﬁelds Gα ≡ TCGC α is deﬁned as Gαβ = ∂αGβ − ∂βGα − g[Gα, Gβ] .(7.164) Here TC denotes the generators of SU(3) that were deﬁned at the beginning of this section. Furthermore, Dα is deﬁned as Dα = ∂α − igTCGC α = ∂α − igGα .(7.165) As you can check every term here is completely analogous to the SU(2) case, except we now have different generators with different commutation properties. 7.8.1 Color From global SU(3) symmetry we get through Noether’s theorem new conserved quantities. This is analogous to what we discussed for SU(2) in Section 7.7. Following the same lines of thought as for SU(2) tells us that we have 8 conserved quantities, one for each gen- erator. Again, we can only use the conserved quantities that belong to the diagonal generators as particle labels. SU(3) has two Cartan101101 Recall, Cartan generators = diagonal generators. generators 1 2 λ3 and 1 2 λ8. Therefore, every particle that interacts via the strong force carries two additional labels, corresponding to the eigenvalues of the Cartan generators. The eigenvalues102 of 1 2 λ3 = 1 2 ⎛ ⎜ ⎝ 100 0 −10 000 ⎞ ⎟ ⎠ are + 1 2 , − 1 2 , 0. For 102 The eigenvectors are of course ⎛ ⎝1 0 0 ⎞ ⎠, ⎛ ⎝0 1 0 ⎞ ⎠ and ⎛ ⎝0 0 1 ⎞ ⎠. λ8 = 1 2√3 ⎛ ⎜ ⎝ 10 0 01 0 00 −2 ⎞ ⎟ ⎠ the eigenvalues103 are 1 2√3 , 1 2√3 , −1√3 . There- 103 Corresponding to the same eigenvec- tors ⎛ ⎝1 0 0 ⎞ ⎠, ⎛ ⎝0 1 0 ⎞ ⎠ and ⎛ ⎝0 0 1 ⎞ ⎠. fore if we arrange the strong interacting fermions into triplets (in the basis spanned by the eigenvectors of the Cartan generators), we can assign them the following labels, with some arbitrary spinor ψ: (+ 1 2 , 1 2√3 ) for ⎛ ⎜ ⎝1 0 0 ⎞ ⎟ ⎠ ψ, interaction theory 173 where one usually deﬁnes red:= ( 1 2 , 1 2√3 ). This means something of the form ⎛ ⎜ ⎝Ψ 0 0 ⎞ ⎟ ⎠ is called red104. Analogously 104 Although we use here the famil- iar sounding labels \"red\", blue\" and \"green\", there is absolutely no connec- tion with the usual meaning of these words. In the context of SU(3) inter- actions, we use these words simply as convenient labels. For a nice discussion on why we use color labels, see Chapter 1 in Francis Halzen and Alan D. Martin. Quarks and Leptons: An Introductory Course in Modern Particle Physics. Wiley, 1st edition, 1 1984. ISBN 9780471887416. (− 1 2 , 1 2√3 ) for ⎛ ⎜ ⎝0 1 0 ⎞ ⎟ ⎠ ψ with blue:= ( −1 2 , 1 2√3 ) and for the third possibility we deﬁne green:= (0, −1√3 ). Completely analogous to what we did for SU(2) we assign the color-charge zero to all SU(3) singlets, which are then particles that do not interact via the strong force. Formulated differently: they are colorless. In addition, one can use the (8-dimensional105) adjoint 105 The adjoint representation of SU(3) is 8 dimensional, because we have 8 generators. representation of SU(3) to assign color to the gauge ﬁelds Gμ A, i.e. the gluons, completely analogous to how we assigned isospin to the W-Bosons in Section 7.7. 7.8.2 Quark Description Recall that spin 1 2 particles106, which interact via the strong force are 106 Spin 1 2 are created by spin 1 2 ﬁelds, as we will learn in Chapter 6.called quarks. If we want to talk about quarks we have to consider quite a lot of things: • Quarks are SU(3) triplets, denoted by Q. Inside a triplet we have the same quark, say an up-quark, in different colors: U = ⎛ ⎜ ⎝ur ub ug ⎞ ⎟ ⎠. The triplets always appear in pairs ¯QQ in order to get something SU(3) invariant, exactly as we always need doublet pairs in order to get something SU(2) invariant. Instead of writing ¯QQ,wecan use an index notation: ¯QQ = ¯qcqc, where the index c stands for color c = r, g, b. • In addition, left-chiral quarks are SU(2) doublets, because they interact via the weak force, too. Each object in this doublet107 107 Each quark doublet consists of two different quarks, for example an up- and a down-quark or a top- and a bottom-quark. (=each quark) is a triplet: q = (uc dc ) . This can become very confus- ing, very fast and therefore the color index c is suppressed unless strong interactions are considered. • As if this weren’t enough, we need to remember that each quark is described by a Dirac spinor, which consits of two Weyl spinors 174 physics from symmetry uc = ((χL u)c (ξ R u )c ) . The upper Weyl-Spinor describes a left-chiral and the lower component the same quark with right-chirality. Having talked about this, let’s return to SU(3) interactions. Hap- pily, there is no experimental need for mass terms for the gauge bosons in the Lagrangian, because all experiments indicate that the gauge bosons of SU(3), called gluons, are massless. Therefore SU(3) is not broken. Furthermore, the SU(3) symmetry poses no new problems regard- ing mass terms for the fermions in the triplet, because a term of the form ¯QmQ (7.166) is SU(3) invariant, as long as all particles in the triplet have equal mass. This means m is proportional to the unit matrix108. The objects 108 m = m ⎛ ⎝100 010 001 ⎞ ⎠, instead of m = m ⎛ ⎝m1 00 0 m2 0 00 m3 ⎞ ⎠ inside a triplet describe the same quark in different colors, which indeed have equal mass. For example, for an up-quark the triplet is U = ⎛ ⎜ ⎝ur ub ug ⎞ ⎟ ⎠ ,(7.167) where ur denotes a red, ub a blue and ug green up-quark, which all have the same mass. The other spin 1 2 particles, like electrons or neutrinos, do not carry color and therefore do not couple to gluons. The interactions fol- lowing from local SU(3) invariance are called strong interactions, because the coupling constant is much bigger than for electromag- netic (U(1))orweak(SU(2)) interactions. 7.9 The Interplay Between Fermions and Bosons This section summarizes what we discovered in this chapter and puts it in a more physical context. We will learn later that spin 1 2 ﬁelds create and destroy spin 1 2 particles. Analogously, spin 1 ﬁelds create and destroy spin 1 particles. In this chapter we derived the Lagrangians that describe how different ﬁelds and therefore particles interact with each other. As already mentioned in Section 1.3 we call spin 1 2 particles fermions and spin 1 particles bosons. The standard interpretation is that fermions make up matter and bosons mediate the forces be- tween matter. We can now understand how this comes about. interaction theory 175 We started the chapter with Lagrangians describing free ﬁelds, which we derived in Chapter 6. Then we discovered internal sym- metries for the Lagrangian describing one, two or three free spin 1 2 ﬁelds. These internal symmetries are only global symmetries, which is quite unconvincing because of special relativity. More natural would be local symmetries. We then discovered that we could make the Lagrangians locally invariant by introducing additional coupling terms. These coupling terms describe the interaction of our spin 1 2 ﬁelds with new spin 1 ﬁelds. For historic reasons the internal symmetries here are called gauge symmetries and we therefore call these new spin 1 ﬁelds, gauge ﬁelds. Through Noether’s theorem we get for each inter- nal symmetry new conserved quantities. These are interpreted as charges, analogous to electric charge that follows for U(1) symmetry. • To get a locally U(1) invariant Lagrangian, we need one gauge ﬁeld Aμ. The ﬁnal Lagrangian describes correctly electromagnetic interactions. U(1) symmetry tells us that electric charge is con- served. • To get a locally SU(2) invariant Lagrangian, we need three gauge ﬁelds Wμ 1 , Wμ 2 , Wμ 3 . The ﬁnal Lagrangian describes correctly weak interactions. SU(2) symmetry tells us that isospin is conserved. • To get a locally SU(3) invariant Lagrangian, we need eight such ﬁelds Gμ 1 , Gμ 2 , . . .. The ﬁnal Lagrangian describes correctly strong interactions. SU(3) symmetry tells us that color is conserved. Different gauge bosons (spin 1 particles) are responsible for a different kind of force. The electromagnetic force is mediated by photons, which is created by the U(1) gauge ﬁeld Aμ. The weak force is mediated by W+, W− and Z bosons and the strong force by 8 different gluons, which are created by the corresponding SU(2) and SU(3) gauge ﬁelds. In addition, we discovered that SU(2) symmetry forbids mass terms in the Lagrangian. From experiments we know this is incorrect. The solution that enables us to include mass terms without spoiling any symmetry is the Higgs mechanism. It works by including addi- tional terms, describing coupling of our spin 1 and spin 1 2 ﬁelds to a new spin 0 ﬁeld, called the Higgs ﬁeld. By breaking SU(2) symme- try spontaneously and expanding the Higgs ﬁeld around a new, no longer symmetric minimum, we get the required mass terms in the Lagrangian. Part IV Applications \"There is nothing truly beautiful but that which can never be of any use whatsoever; everything useful is ugly.\" Theophile Gautier in Mademoiselle de Maupin. Wildside Press, 11 2007 . ISBN 9781434495556 8 Quantum Mechanics Summary In this chapter we will talk about quantum mechanics. The founda- tion for everything here are the identiﬁcations we discussed in Chap- ter 5. As a ﬁrst result, we derive the relativistic energy-momentum relation. After a discussion of how the quantum formalism works, we take the non-relativistic limit of the Klein-Gordon equation, because this is the equation of motion for the simplest type of particles: scalars. This results in the famous Schrödinger equation. The solution of this equation is interpreted as a probability amplitude and two simple examples are analysed using this wave-mechanic approach. Afterwards, the Dirac notation is introduced, which is useful to understand the general structure of quantum mechanics. In this no- tation, the initial state of a system is denoted by an abstract state vector |i⟩, called ket. The probability amplitude for measuring this initial state in a speciﬁc ﬁnal state can then be computed formally by multiplying it with a bra, denoted ⟨ f |. The combination of a bra with a ket results in a complex number that is interpreted as prob- ability amplitude A for the process i → f . The probability for this process is |A|2. Then we talk about projection operators. We will see how they can be used, together with the completeness relation, to expand an arbitrary state in the eigenstate basis of an arbitrary operator. The previously used wave-mechanics can then be seen as a special case, where we expand the states in the location basis. In the Dirac notation the Schrödinger equation is used to compute the time-evolution of states. To make the connection explicit, we use the Dirac notation to reanalyze an example which we already solved using wave-mechanics. © Springer International Publishing AG 2018 J. Schwichtenberg, Physics from Symmetry, Undergraduate Lecture Notes in Physics, https://doi.org/10.1007/978-3-319-66631-0_8 178 physics from symmetry 8.1 Particle Theory Identiﬁcations The equations we derived so far1 can be used in particle- and ﬁeld- 1 The Klein-Gordon, Dirac, Proka and Maxwell equations theories. In this chapter we want to investigate how they can be used in a particle-theory. Our dynamic variables are then the location, the angular momentum, the energy and the momentum of the particle in question. As explained in Chapter 5, we identify these with the generators of the corresponding symmetry2: 2 See Eq. 3.248, Eq. 3.252 and Chapter 5 • momentum ˆpi = −i∂i, • location ˆxi = xi, • energy ˆE = i∂0, • angular momentum ˆLi = i 1 2 ϵijk(xj∂k − xk∂j). Before we discuss how these operators are used in quantum me- chanics, we use them to derive one of the most important equations of modern physics. 8.2 Relativistic Energy-Momentum Relation In Section 6.2 we derived the equation of motion for a free spin 0 particle, the Klein-Gordon equation: (∂μ∂μ + m2)Φ = 0. With the identiﬁcations reiterated above this equation reads3 3 Using pμ = ⎛ ⎜ ⎜ ⎝ p0 p1 p2 p3 ⎞ ⎟ ⎟ ⎠ = (p0 ⃗p ) = (E ⃗p ) (∂μ∂μ + m2)Φ =(∂0∂0 − ∂i∂i + m2)Φ = (( 1 i E)( 1 i E) − (− 1 i pi )(− 1 i pi ) + m2) Φ =(−E2 + ⃗p2 + m2)Φ = 0. (8.1) Therefore → E2 = ⃗p2 + m2 or using four-vectors pμ pμ = m2 ,(8.2) which is the famous energy-momentum relation of special-relativity. For a particle at rest (⃗p = 0) this gives us Einstein’s famous equation E2 = m2 ↔ E = mc2 where we restored c2 for clarity. We can now understand why we gave the scalar value of the ﬁrst Casimir operator of the Poincaré group pμ pμ the suggestive name m2 (Eq. 3.266). The combination pμ pμ is indeed the squared mass of the particle in question, which can be measured in experiments, for example, by measuring the energy and momentum of the particle: m = √E2 − ⃗p2. For the same reason, we understand now why the constant in the Lagrangian we derived in Section 6.2 is also called m2. quantum mechanics 179 8.3 The Quantum Formalism Now that our physical quantities are given by operators, we need something they can act on. First take note that we have for each operator a set of eigenfunctions, which is completely analogous to the eigenvectors of matrices. Matrices are ﬁnite-dimensional and therefore we get ﬁnite dimensional eigenvectors. Here our operators act on an inﬁnite-dimensional vector space and we therefore have eigenfunctions. For example, the equation we must solve to get the eigenfunctions of the momentum operator is −i∂i︸︷︷︸ operator Ψ = pi︸︷︷︸ eigenvalue eigenfunction ︷︸︸︷ Ψ ,(8.3) with some number pi. A solution is Ψ = C︸︷︷︸ =const eipi xi because →−i∂iCeipi xi = piCeipi xi ✓ (8.4) but take note that this a solution for arbitrary pi. Therefore we have found an inﬁnite number of eigenfunctions for the momentum opera- tor ˆpi = −i∂i. Equivalently, we can search for energy eigenfunctions i∂0Φ = EΦ (8.5) or angular momentum eigenfunctions4. Analogous to eigenvectors 4 The discussion for angular momentum eigenfunctions is a bit more compli- cated, because the operator is more complicated than the others. We can’t ﬁnd a set of eigenfunctions for all three components at the same time, because [ ˆLi, ˆLj] ̸= 0. This will be discussed in a moment. The ﬁnal result of a lengthy discussion is that the corresponding eigenfunctions of the third component of the angular momentum operator ˆL3 (and of the squared angular momentum operator ˆL2, which commutes with all components [ ˆL2, ˆLj]= 0) are the famous spherical harmonics. These form an orthonormal basis. for matrices, these eigenfunctions are bases for the corresponding ab- stract vector space5. This means we can expand an arbitrary function 5 Recall that for matrices the eigenvec- tors are a basis for the corresponding vector space. Ψ in terms of eigenfunctions. For example, we can expand Ψ in terms of momentum eigenfunctions6 (for brevity in one dimension) 6 Take note that this is exactly the Fourier transform of a function Ψ, which is introduced in Appendix D.1 and the factor 1√2π is a matter of convention. Ψ = 1 √2π ∫ ∞ −∞ dpΨpe−ipx,(8.6) where Ψp are the coefﬁcients in this expansion analogous to v1, v2, v3 in ⃗v = v1⃗e1 + v2⃗e2 + v3⃗e3. For some systems we have boundary conditions such that we have a discrete instead of a continuous basis. Then we can expand an arbitrary state, for example, in terms of discrete set of energy eigenfunctions ΦEn : Ψ = ∑ n cnΦEn .(8.7) An important observation is that, in general, a set of eigenfunctions for one operator is not a set of eigenfunctions for another operator. 180 physics from symmetry Only for operators that commute [A, B]= AB − BA = 0, we can ﬁnd a simultaneous set of eigenfunctions for both operators. We don’t prove this here, but to see the connection between a common set of eigenfunctions and the commutator property, let’s assume we have two commutating operators [A, B]= 0 → AB = BA. For the set of eigenfunctions Ψi that belong to A,wehave AΨi = aiΨi, where ai denotes the corresponding eigenvalues. Now, we can calculate77 The brackets () are used here solely for illustrative purposes. A(BΨi)=︸︷︷︸ AB=BA BAΨi =︸︷︷︸ AΨi=aiΨi BaiΨi ai is just a number ︷︸︸︷ = ai(BΨi) .(8.8) This shows that (BΨi) is also an eigenfunction of A for all Ψi, with exactly the same eigenvalues ai. Therefore the only difference be- tween (BΨi) and Ψi can be a constant: BΨi = biΨi. We conclude that the A eigenfunctions Ψi are also eigenfunctions of B if AB = BA holds. In general our operators act on something we call8 Ψ, which de- 8 The usage of Ψ is conventional in quantum mechanics and we use it here, although we used it so far exclusively for spinors, to describe spin 0 particles, too. notes the state of the physical system in question. We get this Ψ,by solving the corresponding equation of motion. Usually, such a solution will have more than one term if we expand it in some basis. For example, consider a state that can be written in terms of two energy eigenstates9 Ψ = c1ΦE1 + c2ΦE2. Acting with the 9 This means all other coefﬁcients in the expansion Ψ = ∑n cnΦEn are zero. energy operator on this state yields ˆEΨ = ˆE(c1ΦE1 + c2ΦE2 )= c1E1ΦE1 + c2E2ΦE2 ̸= E(c1ΦE1 + c2ΦE2 ). (8.9) A superposition of states with different energy is therefore, in gen- eral, no eigenstate of the energy operator, because for an eigenstate we have by deﬁnition ˆEΨ = EΨ for some number E. But what is then the energy of the system described by Ψ? What does it mean that a state is a superposition of two energy eigenstates? How can we interpret all this in physical terms? A ﬁrst hint towards an interpretation is the U(1) symmetry of our Lagrangians, which shows us that the solution of an equation of motion Ψ cannot be directly physically relevant10. Secondly, we 10 If we assume that Ψ describes our particle directly in some way, what would the U(1) transformed solution Ψ′ = eiαΨ, which is equally allowed, describe? observe that a solution to any equation of motion we derived so far is a function of11 ⃗x and t, i.e. Ψ = Ψ(⃗x, t). 11 This will be made explicit in the next sections. The standard interpretation is that the absolute value squared |Ψ(⃗x, t)|2 of the wave function Ψ(⃗x, t) gives the probability density of its location. Observe that the U(1) symmetry has no inﬂuence on this quantity |Ψ|2 = Ψ†Ψ → (Ψ′)†(Ψ)′ = Ψ†e−iαeiαΨ = Ψ†Ψ.In quantum mechanics 181 other words: Ψ(x, t) is the probability amplitude that a measurement of the location gives a value in the interval [x, x + dx]. Consequently we have, if we integrate over all space ∫ dxΨ⋆(x, t)Ψ(x, t) ! = 1, (8.10) which is called the normalization prescription, because the probabil- ity for ﬁnding the particle anywhere in space must be 100% = 1. If we want to make predictions about any other physical quantity, we must expand the wave-function in terms of the corresponding basis. For example, we can expand it in terms of energy eigenfunc- tions: Ψ = c1ΦE1 + c2ΦE2 + . . .. Then, the standard interpretation of quantum mechanics is: the probability for measuring a given energy value E1 for the system described by Ψ is given by the absolute value squared of the overlap between Ψ and ΦE1 P(E1)= ∣ ∣ ∣ ∫ dxΦ⋆ E1 (x, t)Ψ(x, t)∣ ∣ ∣2 . In the example above this means P(E1)= ∣ ∣ ∣ ∫ dxΦ⋆ E1 (x, t)Ψ(x, t)∣ ∣ ∣2 = ∣ ∣ ∣ ∫ dxΦ⋆ E1 (x, t) (c1ΦE1 + c2ΦE2 ) ∣ ∣ ∣2 = ∣ ∣ ∣c1 ∫ dxΦ⋆ E1 (x, t)ΦE1 ︸ ︷︷ ︸ =1 as explained above + c2 ∫ dxΦ⋆ E1 (x, t)ΦE2 ︸ ︷︷ ︸ =0 because eigenstates are orthogonal ∣ ∣ ∣2 = |c1|2 .(8.11) Analogously, when we expand some other Ψ(⃗x, t) in terms of mo- mentum eigenfunctions Ψ(⃗x, t)= 1 √2π ∫ ∞ −∞ dp ˜Ψ(⃗p, t)e−i⃗p⃗x, we have ˜Ψ(⃗p, t) as the probability amplitude for ﬁnding the system with momentum in the interval [p, p + dp]. This interpretation can be used to make probabilistic predictions about the system, for example using the statistical expectation value, which is the topic of the next section. Afterwards we will derive the equation of motion for non-relativistic quantum mechanics and look at two examples. 8.3.1 Expectation Value In statistics the expectation value is deﬁned in analogy to the weighted average. For example, if tossing a dice ten times results in 2, 4, 1, 3, 3, 182 physics from symmetry 6, 3, 1, 4, 5, the average value is ⟨x⟩ =(2 + 4 + 1 + 3 + 3 + 6 + 3 + 1 + 4 + 5) · 1 10 = 3.2. An alternative way of computing this is to collect equal results and weighing them by their empirical probability: ⟨x⟩ = 2 10 · 1 + 1 10 · 2 + 3 10 · 3 + 2 10 · 4 + 1 10 · 5 + 1 10 · 6 = 3.2. We can write this in general as ⟨x⟩ = ∑ i ρixi (8.12) where ρi denotes the probability. Equally for a continuous distribu- tion we have ⟨x⟩ = ∫ dxρ(x)x (8.13) In quantum mechanics the expectation value for a physical quan- tity ˆO is deﬁned analogously ⟨ ˆO⟩ = ∫ d3xΨ⋆ ˆOΨ.(8.14) In general, we must expand Ψ in terms of eigenfunctions of ˆO, for example momentum eigenfunctions. Then, acting with the operator ˆO on these states yields the corresponding eigenvalues and we get a weighted sum. For example, the expectation value for the location of some parti- cle is ⟨ ˆx⟩ = ∫ d3xΨ⋆ ˆxΨ = ∫ d3xΨ⋆xΨ = ∫ d3xx Ψ⋆Ψ︸︷︷︸ probability density of its location .(8.15) In the next section, we consider the non-relativistic limit of the Klein-Gordon equation and will derive this way the equation of mo- tion of non-relativistic quantum mechanics12. 12 It is also possible to consider the non- relativistic limit of the other equations that we have derived so far. For exam- ple, the Dirac equation becomes in the non-relativistic limit the Pauli equation. However, these additional equations are less important for the goals of this book. 8.4 The Schrödinger Equation The Klein-Gordon equation is solved by plane waves Φ = e±ipμ xμ ≡ e±ip·x , where pμ =(E, ⃗p)T is the conserved four-momentum of the particle. We check 0 =(∂μ∂μ + m2)Φ =(∂μ∂μ + m2)e±ipμ xμ =(i2 pμ pμ + m2)e±ipμ xμ = 0 =(−m2 + m2)e±ipμ xμ = 0 ✓ (8.16) quantum mechanics 183 We now write the solution with a minus sign a little differently Φ = e−ipμ xμ = Φ = ei(−Et+⃗p·⃗x) and then we see that the time dependence is given by e−iEt, i.e. Φ∝ e−iEt. From Eq. 8.2 we know the energy is E = √ ⃗p2 + m2 = √ m2( ⃗p2 m2 + 1)= m √ ⃗p2 m2 + 1. In the non-relativistic limit |⃗p|≪ m, i.e. for an object that moves much slower than the speed of light, which implies that its momen- tum is much smaller than its mass, we can approximate the energy using the Taylor-series as E = m √ ⃗p2 m2 + 1 = m(1 + 1 2 ⃗p2 m2 + ...) ≈ m︸︷︷︸ rest-mass + ⃗p2 2m︸︷︷︸ kinetic energy .(8.17) We can therefore write Φ = ei(−Et+⃗p·⃗x) ≈ e−imt ei⃗p·⃗x−i(⃗p2/2m)t ︸ ︷︷ ︸ ≡φ(⃗x,t) = e−imtφ(⃗x, t).(8.18) From |⃗p|≪ m it follows that the rest-mass is much bigger than the kinetic energy and therefore the remaining time dependence in φ(⃗x, t) oscillates more slowly than e−imt. If we put our ansatz into the Klein-Gordon equation we get (∂μ∂μ + m2)e−imtφ(⃗x, t)=(∂t∂t − ∂i∂i + m2)e−imtφ(⃗x, t)= 0. Then we use ∂te−imt(...)= e−imt(−im + ∂t)(...), which is just the product rule, twice. This yields e−imt((−im + ∂t)2 − ∂i∂i + m2)φ(⃗x, t)= 0, which we can divide by e−imt, because this never becomes zero. Therefore → ((−im + ∂t)2 −∇2 + m2)φ(⃗x, t)= 0 → (−m2 − 2im∂t +(∂t)2 −∇2 + m2)φ(⃗x, t)= 0. Comparing now the third term (∂t)2φ(⃗x, t)=(∂t)2 exp[i⃗p · ⃗x − i(⃗p2/2m)t] =(⃗p2/2m)2 exp[i⃗p · ⃗x − i(⃗p2/2m)t] ∝ p4 m2 (8.19) 184 physics from symmetry with the second term im∂tφ(⃗x, t)= im∂t exp[i⃗p · ⃗x − i(⃗p2/2m)t] = m(⃗p2/2m) exp[i⃗p · ⃗x − i(⃗p2/2m)t] ∝ p2 (8.20) shows us that, because of |⃗p|≪ m, we can neglect the third term in this limit. Therefore (−2im∂t −∇2)φ(⃗x, t)= 0 →︸︷︷︸ dividing by (-2m) (i∂t + 1 2m ∇2)φ(⃗x, t)= 0 → (i∂t + ∇2 2m )φ(⃗x, t)= 0, (8.21) which is the famous Schrödinger equation. When we now make the identiﬁcations we recited at the beginning of this chapter, the equation reads → (E − ⃗p2 2m︸︷︷︸ =kinetic energy )φ(⃗x, t)= 0 → E = ⃗p2 2m ,(8.22) which is the usual non-relativistic energy-momentum relation. From this point-of-view, it is easy to see how we can include an exter- nal potential, because movement in an external potential simply adds a term describing the potential energy to the energy equation: → E = ⃗p2 2m + V A famous example is the potential of a harmonic oscillator V = −kx2. It is conventional to rewrite the Schrödinger equation, using the Hamiltonian operator ˆH, which collects all contributing energy op- erators, for example, the operator for the kinetic energy ∇2 2m and the operator for the potential energy ˆV. Then we have i∂tφ(⃗x, t)= ( ∇2 2m + ˆV) ︸ ︷︷ ︸ ≡ ˆH φ(⃗x, t) → i∂tφ(⃗x, t)= ˆHφ(⃗x, t).(8.23) This is the standard way to write the Schrödinger equation. quantum mechanics 185 8.4.1 Schrödinger Equation with an External Field We can also follow the same procedure as in the last section and derive the non-relativistic limit of the interacting Klein-Gordon equa- tion (Eq. 7.42), i.e. the equation that describes the interaction between a massive spin 0 ﬁeld φ and a massless spin 1 ﬁeld Aμ (the photon ﬁeld). The resulting equation is (i∂t − 1 2m (∇− iq ⃗A)2 − qA0 ) φ(⃗x, t)= 0. (8.24) 8.5 From Wave Equations to Particle Motion Now, let’s look at two examples of how the standard interpretation of quantum mechanics works in practice. 8.5.1 Example: Free Particle A solution for the free (without external potential) Schrödinger equa- tion (Eq. 8.21) is given by Ψ = e−i(Et−⃗p⃗x) (8.25) because i∂te−i(Et−⃗p⃗x) ! = − ∇2 2m e−i(Et−⃗p⃗x) → Ee−i(Et−⃗p⃗x) ! = ⃗p2 2m e−i(Et−⃗p⃗x) ✓ ,(8.26) where E is just the numerical value for the total energy of the free particle, which was derived in Eq. 8.22 as E = ⃗p2 2m . A more general solution is a linear combination Ψ = Ae−i(Et−⃗p⃗x) + Be−i(E′t−⃗p′⃗x) + ... . Fig. 8.1: Free wave-packet with Gaus- sian envelope. Figure by Inductiveload (Wikimedia Commons) released under a public domain licence. URL: http: //commons.wikimedia.org/wiki/File: Travelling_Particle_Wavepacket.svg , Accessed: 4.5.2014 We interpret the wave-function as a probability amplitude and therefore it must be normalized, because the total probability for ﬁnding the particle must be 100% = 1. This is not possible for the wave-function above which spreads out over all of space. To describe an individual free particle we have to use a suited linear combination, called a wave-packet: ΨWP(⃗x, t)= ∫ dp3 A(⃗p)ei(⃗p⃗x−Et),(8.27) where the complex numbers A(⃗p) have to be chosen in a way that makes the wave packet normalizable. One possibility is a Gaussian 186 physics from symmetry wave-packet, where A(⃗p) is a Gauss distribution. ΨGWP(⃗x, t)= ∫ dp3 A(⃗p)ei(⃗p⃗x−Et) = ∫ dp3ψ0ei(⃗p−⃗˜p)2/4σ2ei(⃗p⃗x−Et) . An example of such a Gaussian wave-packet is plotted in Fig. 8.1. For many computations clever tricks can be used in order to avoid working with complicated wave packets, allowing us to work with simple wave functions instead. 8.5.2 Example: Particle in a Box Fig. 8.2: Inﬁnite potential well. Fig- ure by Benjamin D. Esham (Wiki- media Commons) released under a public domain licence. URL: http: //commons.wikimedia.org/wiki/File: Infinite_potential_well.svg , Ac- cessed: 4.5.2014 Now we look at one of the standard examples of quantum mechan- ics: a particle conﬁned in a box, here 1-dimensional, with inﬁnitely high potential walls. Inside the box the potential is zero, outside it’s inﬁnite (see Fig. 8.2). The potential is deﬁned piece-wise V(x)= { 0, 0 < x < L ∞, otherwise (8.28) and therefore, we have to solve the one-dimensional Schrödinger equation i∂tΨ(x, t)= − ∂2 x 2m Ψ(x, t)+ V(x)Ψ(x, t) piece-wise. • Inside the box, the solution is equal to the free particle solution, because V(x)= 0 for 0 < x < L. • Outside, because here V(x)= ∞, the only possible, physical solution is Ψ(x, t)= 0. We can rewrite the general free particle solution as1313 Using sin(x)= 1 2i (eix − e−ix) and cos(x)= 1 2 (eix + e−ix), which follows directly from the series expansion of cos(x), sin(x) and eix as derived in Appendix B.4.1. Ψ(x, t)= Ae−i(Et−px) + Be−i(Et+px) = (C sin(px)+ D cos(px))e−iEt , which we can rewrite again using the non-relativistic energy-momentum relation (Eq. 8.22) E = p2 2m → p = √2mE Ψ(x, t)= (C sin(√2mEx)+ D cos(√2mEx))e−iEt .(8.29) Next we use that the wave-function must be a continuous func- tion. If there are any jumps in the wave-function, the momentum of quantum mechanics 187 the particle ˆpxΨ = −i∂xΨ is inﬁnite, because the derivative at the jump would be inﬁnite. Therefore, we have the boundary conditions Ψ(0)= Ψ(L) ! = 0. Because cos(0)= 1, we see that we have D ! = 0. Furthermore, we see that these conditions impose √2mEn ! = nπ L ,(8.30) with arbitrary integer n. This follows because for14 14 Take note that we put an index n on our wave-function, because we have a different solution for each n. Φn(x, t)= C sin( nπ L x)e−iEnt (8.31) both boundary conditions are satisﬁed → Φn(L, t)= C sin( nπ L L)e−iEnt = C sin(nπ)e−iEnt = 0 ✓ → Φn(0, t)= C sin( nπ L 0)e−iEnt = C sin(0)e−iEnt = 0 ✓ The normalization constant C, can be found to be C = √ 2 L , because the probability for ﬁnding the particle anywhere inside the box must be 100% = 1 and the probability outside is zero, because there we have Ψ = 0. Therefore P = ∫ L 0 dxΦ⋆ n(x, t)Φn(x, t) ! = 1 P = ∫ L 0 dxC2 sin( nπ L x)e+iEnt sin( nπ L x)e−iEnt = C2 ∫ L 0 dx sin2( nπ L x)= C2 [ x 2 − sin( 2nπ L x) 4 nπ L ]L 0 = C2 ( L 2 − sin( 2nπ L L) 4 nπ L ) = C2 L 2 ! = 1 → C2 ! = 2 L . We can now solve Eq. 8.30 for the energy E En ! = n2π2 L22m .(8.32) We see here that the possible energies are quantized, which means that only a discrete set of values is allowed and not arbitrary continu- ous values15. Hence the name quantum mechanics. 15 Recall that n is necessarily an integer. The possible energy values are π2 L22m times this integer squared.Take note that we have a solution for each n and linear combina- tions of the form Φ(x, t)= AΦ1(x, t)+ BΦ2(x, t)+ ... 188 physics from symmetry are solutions, too. These solutions have to be normalised again be- cause of the probabilistic interpretation16. 16 A probability of more than 1 = 100% doesn’t make sense. Next we can ask17, what is the probability for measuring the parti- 17 Instead of what’s the probability to ﬁnd a particle at place x. cle having Energy E = E2 = 22π2 L22m . Say our particle is in the normal- ized state given by Ψ(x, t)= √ 3 5 Φ2(x, t)+ √ 2 5 Φ3(x, t). The answer in the conventional interpretation of quantum mechanics is: it is the absolute value squared of the overlap between Ψ and Φ2 P (E = 22π2 L22m ) = ∣ ∣ ∣ ∫ dxΦ⋆ 2(x, t)Ψ(x, t)∣ ∣ ∣2 , where the overlap can be seen as a scalar product18 of Φ2 and Ψ: 18 In fact, this is the scalar product of the Hilbert space in which our state vectors Ψ, Φn live. (Φ2, Ψ)= ∫ dxΦ⋆ 2Ψ = c︸︷︷︸ complex number . The computation is easy, because the solutions we found are orthogo- nal, i.e. ∫ dxΦ⋆ n(x, t)Φn′ (x, t)= δnn′ . For example19, 19 You can check this easily using integration by parts or something like Wolframalpha.com ∫ L 0 dxΦ⋆ 2Φ3(x, t)= ∫ L 0 dxC sin( 2π L x)e+iEtC sin( 3π L x)e−iEt = C2 ∫ L 0 dx sin( 2π L x) sin( 3π L x)= 0. Therefore, we get the probability for ﬁnding the energy E = 22π2 L22m P (E = 22π2 L22m ) = ∣ ∣ ∣ ∫ dxΦ⋆ 2(x, t)Ψ(x, t)∣ ∣ ∣2 = ∣ ∣ ∣ ∫ dxΦ⋆ 2(x, t) (√ 3 5 Φ2(x, t)+ √ 2 5 Φ3(x, t) ) ∣ ∣ ∣2 = ∣ ∣ ∣ ∫ dx ⎛ ⎜ ⎝ √ 3 5 Φ⋆ 2(x, t)Φ2(x, t) ︸ ︷︷ ︸ =1 if integrated + √ 2 5 Φ⋆ 2(x, t)Φ3(x, t) ︸ ︷︷ ︸ =0 if integrated ⎞ ⎟ ⎠ ∣ ∣ ∣2 = (√ 3 5 )2 .(8.33) Take note that we are able to call the functions we just found in Eq. 8.31, eigenstates of the energy operator i∂t or equivalently of the Hamiltonian20 ˆH ≡− ∂2 x 2m , because 20 This follows directly from the Schrödinger equation i∂tΦ = − ∂2 x 2m Φ ≡ ˆHΦ. quantum mechanics 189 ˆHΦn = EnΦn.(8.34) If we act with the energy operator on an eigenstate, we get the same state multiplied with a constant, which we call energy of the state. In contrast, an arbitrary state is changed when the energy operator or the Hamiltonian operator ˆH act on it. For example, if we take a look at the linear combination Ψ = √ 3 5 Φ2 + √ 2 5 Φ3 we see that ˆHΨ = ˆH (√ 3 5 Φ2 + √ 2 5 Φ3 ) =︸︷︷︸ Eq. 8.34 √ 3 5 E2Φ1 + √ 2 5 E3Φ3 which cannot be written as multiple of Ψ because E2 ̸= E3. There- fore, Ψ is not an eigenstate of the energy operator. Nevertheless, every wave function can be expressed in terms of the eigenstates Φn, because they form a complete basis set. Next we want to introduce a useful notation invented by Dirac, which extremely helpful to understand the structure of quantum mechanics. 8.5.3 Dirac Notation In the Dirac notation the state of a physical system is denoted ab- stractly by |Ψ⟩ ,(8.35) which is called a ket21. For example, if we prepare a particle in a box 21 The pun will become clear in a second.in an energy eigenstate we have ˆH |Φn⟩ = En |Φn⟩ . To each ket we can deﬁne a bra, denoted by ⟨Ψ| which is given by ⟨Ψ| = |Ψ⟩† ,(8.36) where the † symbol (called dagger) denotes the Hermitian conjugate, i.e. transposing plus complex conjugation. A bra is an object that acts on a ket. We can deﬁne an inner product as follows: (|Φ⟩ , |Ψ⟩) ≡⟨Φ|Ψ⟩ . If a ket is multiplied with a bra from the left-hand side, the result is a complex number ⟨Φ|Ψ⟩ = c .(8.37) 190 physics from symmetry This complex number is the probability amplitude for a physical sys- tem in the state |Ψ⟩ to be measured in the state |Φ⟩. Consequently, the probability is given by |⟨Φ|Ψ⟩|2. For example, the probabil- ity amplitude for ﬁnding a particle in the state |Ψ⟩ in the interval [x, x + dx] is given by ⟨x|Ψ⟩≡ Ψ(x). This is the wave function we used in the last chapters. Furthermore, we could ask: What’s the probability amplitude for ﬁnding the same particle with momentum in the interval [p, p + dp]? The answer in the Dirac notation is ⟨p|Ψ⟩≡ Ψ(p). Recall that our states must fulﬁl a normalization condition, be- cause we are using a probabilistic interpretation22. For example, we 22 The probability for ﬁnding the par- ticle anywhere must be 100% = 1or equally the probability for ﬁnding the particle with any momentum must be 100% = 1. In other words: the sum of probabilities for all possible outcomes must add up to 1. have ∫ dx|Ψ(x, t)|2 = ∫ dxΨ⋆(x, t)Ψ(x, t) ! = 1(8.38) and equally ∫ dp|Φ(p, t)|2 = ∫ dpΦ⋆(p, t)Φ(p, t) ! = 1(8.39) or written in our new notation ∫ dx|⟨x|Ψ⟩|2 = ∫ dx(⟨x|Ψ⟩)† ⟨x|Ψ⟩ = ∫ dx ⟨Ψ|x⟩⟨x|Ψ⟩ ! = 1(8.40) and ∫ dp|⟨p|Φ⟩|2 = ∫ dp(⟨p|Φ⟩)† ⟨p|Φ⟩ = ∫ dp ⟨Φ|p⟩⟨p|Φ⟩ ! = 1. (8.41) We can see here a new kind of operator: |p⟩⟨p| and |x⟩⟨x|, which are called projection operators23. They are operators because they 23 Exactly like the projection operators for left-chiral and right-chiral spinors we introduced earlier, these projection operators fulﬁl the deﬁning condition P2 = P. transform a ket into another ket. For example, |x⟩⟨x|Ψ⟩ ︸ ︷︷ ︸ =some complex function we call Ψ(x) = |x⟩ Ψ(x), which is again a ket, because the product of a complex function with a ket is again a ket. In general, an operator is any object that acts on a ket to generate another ket. Looking at Eq. 8.40 motivates us to introduce another operator ∫ dx ⟨Ψ|x⟩⟨x|Ψ⟩ = ⟨Ψ| (∫ dx |x⟩⟨x|) ︸ ︷︷ ︸ ≡ ˆI |Ψ⟩ = ⟨Ψ| ˆI |Ψ⟩ ! = 1. (8.42) From this we can conclude ˆI |Ψ⟩ ! = |Ψ⟩ (8.43) quantum mechanics 191 for an arbitrary ket |Ψ⟩, because ⟨Ψ|Ψ⟩ = 1. This follows, because the probability for a system prepared in state the |Ψ⟩ to be found in the state |Ψ⟩, must be, of course, 100% = 1. For example, if we prepare a particle to be at some point x0, the probability for ﬁnding it at point x0 is 1. Therefore, ⟨x0|x0⟩ = 1. Because of this, ˆI is called the unit operator and plays the same role as the number 1 in the multiplication of numbers. The result ∫ dx |x⟩⟨x| = ˆI (8.44) or for a discrete basis ∑ i |i⟩⟨i| = ˆI (8.45) are called completeness relations. In general, we say the component of a ket |a⟩ in the basis |i⟩ is |i⟩† |a⟩≡⟨i|a⟩≡ ai, which is a complex number. Using the completeness relation, i.e. ∑i |i⟩⟨i| = ˆI, we can write |a⟩ = ∑ i |i⟩⟨i|a⟩ = ∑ i |i⟩ ai. This can be seen as the series expansion24 of the ket |a⟩ in terms of 24 Analogous to how we can write a vector in terms of a given basis: ⃗v = v1⃗e1 + v2⃗e2 + v3⃗e3, as explained in Appendix A.1. the basis |i⟩. Consequently, the complex numbers ai can be seen as the expansion coefﬁcients. Equally for a continuous complete basis, we have |Ψ⟩ = ∫ dx |x⟩⟨x|Ψ⟩ ︸ ︷︷ ︸ ≡Ψ(x) complex number = ∫ dx |x⟩ Ψ(x). The expectation value we introduced in Section 8.3.1 is in the Dirac notation given by ⟨ ˆO⟩ = ⟨Ψ| ˆO |Ψ⟩ . Now let’s return to the example of the particle in a box, and solve it using the Dirac notation. 8.5.4 Example: Particle in a Box, Again The question we asked was: What is the probability for ﬁnding the particle having energy E = E2 = n2π2 2mL2 ? This question can be an- swered in the Dirac notation in a very natural way. The probability is given by P(E2)= ∣ ∣ ⟨E = n2π2 2mL2 |Ψ⟩ ∣ ∣2 = ∣ ∣ ⟨E = n2π2 2mL2 | (∫ dx |x⟩⟨x|) ︸ ︷︷ ︸ = ˆI |Ψ⟩ ∣ ∣2 192 physics from symmetry = ∣ ∣ ∫ dx ⟨E = n2π2 2mL2 |x⟩⟨x|Ψ⟩ ∣ ∣2 = ∣ ∣ ∫ dxΦ⋆ 2(x)Ψ(x)∣ ∣2 , which is exactly the result we derived using the standard wave me- chanics in Section 8.5.2. All of this becomes much clearer as soon as you learn more about quantum mechanics and solve some problems on your own, using both notations. 8.5.5 Spin Now it’s time to return to the operator we derived in Section 5.1.1 for a new kind of angular momentum, we called spin. So far we have two loose ends. On the one hand, we have used spin as a label for the representations of the Lorentz group. For example, if we want to describe an elementary particle with spin 1 2 ,wehavetousean object transforming according to the spin 1 2 representation. On the other hand, we derived from rotational symmetry something that we called spin, too25. In the quantum framework, when we act with the 25 The conserved quantity that follows from invariance under rotations has two parts. One part follows from the invariance under rotations of the spacetime coordinates and is called orbital angular momentum. The second parts follows from the invariance under the mixing of the ﬁeld components. See Section 4.5.4. operator that we derived in Section 5.1.1 on a given state, the result is the spin of the particle. For the scalar representation, this operator is given by ˆS = 0, which of course always yields 0 when with it on a state Ψ. For the ( 1 2 ,0) representation we have to use the two-dimensional representation of the rotation generator, which was derived in Sec- tion 3.7.5 ˆSi = σi 2 (8.46) and where σi denotes the Pauli matrices. If we want to know the spin of a particle described by Ψ, we have to act with the spin-operator on Ψ. For example, for ˆS3 this will give us the spin of the corresponding particle in the 3-, or more familiar called z-direction. Analogously for ˆS2 in the y- and ˆS1 in the x-direction. The explicit form of the operator ˆS3 is Fig. 8.3: Illustration of the Stern- Gerlach experiment. The original exper- iment was performed with silver atoms, whose spin behavior is dominated by the one electron in the outermost atomic orbital. The experimental re- sult is the same as with electrons. A beam of particles is affected by an in- homogeneous magnetic ﬁeld. For a classical type of angular momentum the deﬂection of the particles through the magnetic ﬁeld should be a con- tinuous distribution. Measured are just two deﬂection types, i.e. the beam splits in two parts, one corresponding to spin 1 2 and one to − 1 2 . Figure by Theresa Knott (Wikimedia Commons) distributed under a CC BY-SA 3.0 li- cense: http://creativecommons.org/ licenses/by-sa/3.0/deed.en. URL: http://commons.wikimedia.org/wiki/ File:Stern-Gerlach_experiment.PNG , Accessed: 24.5.2014. ˆS3 = σ3 2 = ( 1 2 0 0 − 1 2 ) (8.47) The corresponding eigenstates are v 1 2 = (1 0 ) v− 1 2 = (0 1 ) (8.48) with eigenvalues 1 2 and − 1 2 , respectively. quantum mechanics 193 This means a particle described by a spinor26 has spin 1 2 , which can 26 Recall that a spinor is an object transforming according to the ( 1 2 ,0), the (0, 1 2 ) or ( 1 2 ,0) ⊕ (0, 1 2 ) representation. be aligned or anti-aligned to some arbitrary measurement axis. This is why we call this representation spin 1 2 representation27. In the 27 Analogous statements can be made for the spin 1 or other higher represen- tations. quantum framework this is interpreted by saying that a measurement of spin can only result in 1 2 and − 1 2 . In Section 4.5.4 we learned that spin is something similar to orbital angular momentum, because both notions arise from rotational invariance. Here we can see that this kind of angular momentum gives quite surprising results, when measured. The most famous experiment proving this curious fact of nature is the Stern-Gerlach experiment (see Fig. 8.3). The same is true for a measurement of spin in any direction. A measurement of the spin in the x-,y- or z-direction can only result in 1 2 and − 1 2 . Let’s look at one concrete example of how a spin-measurement works in the quantum formalism. As mentioned above, the explicit form of the spin operator (Eq. 5.4), say for a measurement along the z-axis, is ˆSz = 1 2 σ3 = ( 1 2 0 0 − 1 2 ) .(8.49) The eigenstates are | 1 2 ⟩z ˆ= (1 0 ) and |− 1 2 ⟩z ˆ= (0 1 ) , where the sub- script z denotes that we are dealing with eigenstates of ˆSz. A gen- eral spinor is not a spin-eigenstate, but a superposition |X⟩ = a | 1 2 ⟩z + b |− 1 2 ⟩z. The coefﬁcients depend on how we prepare a given particle. If we did a measurement of the spin along the z-axis and ﬁltered out all particles with spin − 1 2 , the coefﬁcient b would be zero and a would be 1. Without any measurement and ﬁltering the co- efﬁcients are a = b = 1√2 , which means probability28 1 2 for each 28 The coefﬁcients are directly related to the probability amplitude which we need to square in order to get the probability. This will be shown in a moment. possibility. Things get interesting if we make a measurement along the z-axis and afterwards a measurement, for example, along the x- axis. Even if we did ﬁlter out all − 1 2 components along the z-axis, there will be particles with spin − 1 2 along the x-axis. Acting with the spin operator ˆSz on a state means measuring spin along the z-axis. For a general state |X⟩ both outcomes + 1 2 and − 1 2 are possible and the probability is directly related to the factors a and b. If we want to know the probability for measuring − 1 2 , the quan- tum formalism tells us that the corresponding probability amplitude is z⟨− 1 2 |X⟩ = a z⟨− 1 2 | 1 2 ⟩z︸ ︷︷ ︸ =0 +b z⟨ 1 2 |− 1 2 ⟩z︸ ︷︷ ︸ =1 = b (8.50) 194 physics from symmetry Therefore, the probability for measuring spin − 1 2 along the z-axis is Pz=− 1 2 = |b|2. If we want to measure the spin along another axis, say the x-axis, we need to expand our two states in terms of the eigen- states of ˆSx, which reads in explicit matrix form (Eq. 5.4) Sx = (0 1 2 1 2 0 ) (8.51) and the corresponding normalized eigenstates are | 1 2 ⟩x ˆ= 1√2 (1 1 ) and |− 1 2 ⟩x ˆ= 1√2 ( 1 −1 ) . If we want to know the probability for measuring spin − 1 2 along the x-axis, we need to rewrite | 1 2 ⟩z and |− 1 2 ⟩z in terms of | 1 2 ⟩x and |− 1 2 ⟩x: | 1 2 ⟩z︸︷︷︸ ⎛ ⎝1 0 ⎞ ⎠ = 1 √2 ( | 1 2 ⟩x︸︷︷︸ 1√2 ⎛ ⎝1 1 ⎞ ⎠ + |− 1 2 ⟩x︸ ︷︷ ︸ 1√2 ⎛ ⎝ 1 −1 ⎞ ⎠ ) (8.52) |− 1 2 ⟩z︸ ︷︷ ︸ ⎛ ⎝0 1 ⎞ ⎠ = 1 √2 ( | 1 2 ⟩x︸︷︷︸ 1√2 ⎛ ⎝1 1 ⎞ ⎠ −|− 1 2 ⟩x︸ ︷︷ ︸ 1√2 ⎛ ⎝ 1 −1 ⎞ ⎠ ) .(8.53) And therefore |X⟩ = a | 1 2 ⟩z + b |− 1 2 ⟩z = a 1 √2 ( | 1 2 ⟩x + |− 1 2 ⟩x ) + b 1 √2 ( | 1 2 ⟩x −|− 1 2 ⟩x ). (8.54) The probability amplitude for measuring − 1 2 for the spin along the x-axis is then x⟨− 1 2 |X⟩ = x⟨− 1 2 | ( a 1 √2 ( | 1 2 ⟩x + |− 1 2 ⟩x ) + b 1 √2 ( | 1 2 ⟩x −|− 1 2 ⟩x )) = a √2 − b √2 (8.55) and the probability is Px=− 1 2 = | a√2 − b√2 |2. Now, let’s come back to the example outlined at the beginning of this computation. If we ﬁlter out all particles with spin − 1 2 along the z-axis the state |X⟩ is |X⟩after z-axis ﬁltering = | 1 2 ⟩z .(8.56) quantum mechanics 195 This means a = 1 and b = 0 and we get a non-zero probability for measuring spin − 1 2 along the x-axis Px=− 1 2 = | 1√2 − 0√2 |2 = 1 2 .If we now ﬁlter out all particles with spin − 1 2 along the x-axis and repeat our measurement of spin along the z-axis we notice something quite remarkable. After ﬁltering the particles with spin − 1 2 along the x-axis we have the state |X⟩after x-axis ﬁltering = | 1 2 ⟩x .(8.57) If we want to know the probability for measuring spin − 1 2 along the z-axis, we need to write | 1 2 ⟩x in terms of | 1 2 ⟩z and |− 1 2 ⟩z: |X⟩after x-axis ﬁltering = | 1 2 ⟩x︸︷︷︸ 1√2 ⎛ ⎝1 1 ⎞ ⎠ = 1 √2 ( | 1 2 ⟩z︸︷︷︸ ⎛ ⎝1 0 ⎞ ⎠ + |− 1 2 ⟩z︸ ︷︷ ︸ ⎛ ⎝0 1 ⎞ ⎠ ) (8.58) and we get the probability Pz=− 1 2 = | z⟨− 1 2 |X⟩|2 = 1 2 . To summarize, this means: • We start with a spin measurement along the z-axis and ﬁlter out all particles with − 1 2 . This leaves us with a state |X⟩after z-axis ﬁltering = | 1 2 ⟩z .(8.59) • If we now measure again the spin along the z-axis we get a very unsurprising result: The probability for measuring spin − 1 2 is zero and for spin + 1 2 the probability is 100%. z⟨ 1 2 |X⟩after z-axis ﬁltering = 1, (8.60) z⟨− 1 2 |X⟩after z-axis ﬁltering = 0. (8.61) • If we then measure the spin along the x-axis, for our z-ﬁltered par- ticle stream, we get a probability of 1 2 = 50% for a measurement of + 1 2 . Equivalently, we have a probability of 1 2 = 50% for a mea- surement of − 1 2 . If we then ﬁlter out all components with spin − 1 2 along the x-axis we are in the state |X⟩after x-axis ﬁltering = | 1 2 ⟩x. • Now measuring the spin along the z-axis again, gives us the surprising result that the probability for measuring spin − 1 2 is 1 2 = 50%. The measurement along the x-axis did change the state and therefore we are again getting components with spin − 1 2 along the z-axis, even though we did ﬁlter these out in the ﬁrst step! A brilliant discussion of these matters, involving real measuring devices, can be found in the Feynman Lectures29 Vol. 3. 29 Richard P. Feynman, Robert B. Leighton, and Matthew Sands. The Feynman Lectures on Physics, Volume 3. Addison Wesley, 1st edition, 1 1971. ISBN 9780201021189 196 physics from symmetry 8.6 Heisenberg’s Uncertainty Principle Now it’s time to talk about one of the most curious features of quan- tum mechanics. We learned in the last section that a measurement of spin in the x-direction makes everything we knew previously about spin along the z-direction useless. This kind of thing happens for many observables in quantum mechanics. We can trace this behavior back to the fact that30 ˆSx ˆSz ̸= ˆSz ˆSx. This means that a measurement 30 Recall that we identify the spin operators with the corresponding ﬁnite-dimensional representations for the rotation generators. These fulﬁl the commutator relation [Ji, Jj]= Ji Jj − Jj Ji = iϵijk Jk ̸= 0 → Ji Jj ̸= Jj Ji. For example, if we describe spin 1 2 particles, we must use the two-dimensional representation Ji = σi 2 . of spin along the z-axis followed by a measurement of spin along the x-axis is different from a measurement of spin along the x-axis followed by a measurement of spin along the z-axis. After measur- ing the spin along the z-axis the system is in an eigenstate of ˆSz and after a measurement of spin along the x-axis, in an eigenstate of ˆSx. The eigenstates for ˆSz and ˆSx are all different and therefore this is no surprise. We can look at this from a different perspective: We aren’t able to know the spin of a system along the z-axis and the x-axis at the same time! Each time we measure spin along the z-axis the spin along the x-axis becomes undetermined and vice-versa. The same is true for spin along the z-axis/x-axis and spin along the y-axis. Spin may be something really strange, but we can observe the same behavior for measurements of position and momentum. Take a look again at Eq. 5.3, which we recite here for convenience: [ ˆpi, ˆxj]= ˆpi ˆxj − ˆxj ˆpi = iδij.(8.62) Following the line of thought as above tells us that a measurement of momentum in the x-direction changes what we can expect for a mea- surement of position on the x-axis. In other words this means that we can’t know position and momentum in the same direction at the same time with arbitrary precision. Take note that the commutator is only non-zero for measurements along the same axis31. A measure- 31 The Kronecker delta δij is zero for i ̸= j and one for i = j as deﬁned in Appendix B.5.5. ment of momentum in the y-direction has no inﬂuence on what we can expect for the position on the x-axis. Everytime we measure momentum the position becomes uncertain and vice versa. This is known as Heisenberg’s uncertainty principle. Analogous observations can be made for angular momentum along different axes, because the commutator for the corresponding oper- ator is non-zero, too. In general, we can check for any two physical quantities if they commute with each other. If they don’t, we know that they can’t be measured at the same time with arbitrary precision. Maybe this shouldn’t surprise us. Quantum mechanics uses the generators of the corresponding symmetries as measurement oper- quantum mechanics 197 ators. For instance, this has the consequence that a measurement of momentum is equivalent to the action of the translation generator32. 32 Recall that invariance under trans- lations leads us to conservation of momentum. The translation generator moves our system a little bit and there- fore the location is changed. What is more surprising is that nature actually works this way. Over the years there have been many experi- mental tests of the Heisenberg’s uncertainty principle and all proved it to be correct. 8.7 Comments on Interpretations The interpretation and notations described in this chapter are the standard ones. Nevertheless, there are other formalisms equally powerful. For example, the Feynman path integral formalism33 is, 33 To learn more about this see for example, Richard P. Feynman and Albert R. Hibbs. Quantum Mechanics and Path Integrals: Emended Edition.Dover Publications, emended editon edition, 7 2010. ISBN 9780486477220 in terms of results, completely equivalent to the wave mechanics, we described in this chapter. Yet computations in this formalism are completely different. If we want to compute the probability for a particle to get from point a to point b, we have to sum over all possible paths that a particle can go between a and b. As absurd as it sounds, this approach leads to the same result, which can be proved formally as well. Freeman Dyson once told the story34 34 Harry Woolf, editor. Some Strangeness in the Proportion. Addison-Wesley, 1st edition, 2 1981. ISBN 9780201099249 Dick Feynman told me about his \"sum over histories\" version of quan- tum mechanics. \"The electron does anything it likes,\" he said. \"It just goes in any direction at any speed, forward or backward in time, how- ever it likes, and then you add up the amplitudes and it gives you the wavefunction.\" I said to him, \"You’re crazy.\" But he isn’t. Another interpretation for the basic equations of quantum me- chanics, further away from the mainstream, is Bohmian Mechanics. The starting point is to put the ansatz: ReSt into the Schrödinger equation. Separating the imaginary and real part results in two equations, one of which can be seen as completely analogous to the Hamilton-Jacobi equation of classical mechanics plus an additional term. This additional term can be interpreted as an extra potential, which is responsible for the strange quantum effects. Further com- putations are completely analogous to classical mechanics. A new force is computed from the extra potential using the gradient, which is then put into Newton’s classical equation: F = ma. Therefore, in Bohmian mechanics one still has classical particle trajectories. The results from this approach are, as far as I know, equal to those com- puted by standard non-relativistic quantum mechanics. Nevertheless, this approach has fallen into disfavour because the extra potential undergoes non-local changes. 198 physics from symmetry Further Reading Tips • Richard P. Feynman - The Feynman Lectures on Physics, Vol. 33535 Richard P. Feynman, Robert B. Leighton, and Matthew Sands. The Feynman Lectures on Physics, Volume 3. Addison Wesley, 1st edition, 1 1971. ISBN 9780201021189 is a great book to start learning about quantum mechanics. Most concepts of quantum mechanics are explained here more lucidly than anywhere else. • David J. Grifﬁths - Introduction to Quantum Mechanics36 is a36 David J. Grifﬁths. Introduction to Quantum Mechanics. Pearson Pren- tice Hall, 2nd edition, 4 2004. ISBN 9780131118928 very readable and enlightening book. • J. J. Sakurai - Modern Quantum Mechanics37 is a brilliant book, 37 J. J. Sakurai. Modern Quantum Mechan- ics. Addison Wesley, 1st edition, 9 1993. ISBN 9780201539295 which often offers a unique perspective on the concepts of quan- tum mechanics. • Paul A. M. Dirac - Lectures on Quantum Mechanics38 is an old 38 Paul A. M. Dirac and Physics. Lec- tures on Quantum Mechanics.Dover Publications, 1st edition, 3 2001. ISBN 9780486417134 book by one of the fathers of quantum mechanics. Highly recom- mended, because reading about ideas by the person who discov- ered them is always a good idea. • You can ﬁnd a detailed discussion of the interpretation of the components of a Dirac spinor in Appendix 8.8. 8.8 Appendix: Interpretation of the Dirac Spinor Components In this and the corresponding appendices, u and v denote two-component objects inside a Dirac spinor and u and v four-component objects. For exam- ple u1 and u2 describe two different four-component objects. For a general four-component object u, we denote the two two-component objects by u1 and u2, i.e. u = (u1 u2 ) . Up to this point we have been relatively vague about the two Weyl spinors inside a Dirac spinor. What do they stand for? How can they be interpreted? In addition, each such Weyl spinor inside a Dirac spinor consists of two components. How to interpret these? Now, we are ﬁnally in the position to give answers to these questions. In short: • The two Weyl spinors χL, ξR inside a Dirac spinor ψ = (χL ξR ) describe \"different particles\". Nevertheless, it’s conventional to call them the same particle, for example an electron, with different chirality: – χL describes a left-chiral electron, – ξR describes a right-chiral electron, quantum mechanics 199 but the crucial point is that these are really distinct particles/ﬁelds39, 39 They are labelled by different quan- tum numbers and therefore behave differently in experiments! because they aren’t related by a parity transformation or charge conjugation. This is why we use different symbols. There is, of course, some sort of connection between them, which is why we write them in one object. This will be discussed in detail in a mo- ment. • The two components of each Weyl spinor describe different spin conﬁgurations40 of the corresponding particle. 40 This was discussed in Section 8.5.5. Recall that spin can be measured like angular momentum, but for a spin 1 2 particle the result of such a measurement can only be + 1 2 or − 1 2 , no matter what axis we choose. These two measurement results are commonly called spin up and spin down. – A Weyl spinor proportional to (1 0 ) describes a particle with spin up – A Weyl spinor proportional to (0 1 ) describes a particle with spin down – Any other Weyl spinor is simply a mixture of spin up and spin down. Let’s see how this comes about in detail: The important thing we learn from weak interactions and parity violation is that left-chiral and right-chiral particles are really differ- ent particles. Left-chiral particles carry weak charge (isospin) and therefore interact via the weak force. Right chiral particles do not, which was explained in Section 7.7.1. We have for every particle in nature a corresponding antiparticle and in general, we get the antiparticle description through charge conjugation. Charge conjugation ﬂips all particle labels, which in- cludes isospin. Let’s see what particles we can expect that are related to, say electrons. We have • A left-chiral electron χL, with isospin − 1 2 and electric charge −e, which is part of a doublet. • A right-chiral anti-left-chiral-electron (χL)c = χR with isospin 1 2 , electric charge +e, which is part of a doublet, too. This property does not simply vanish through charge conjugation. This may be confusing at the moment, but so far we have only talked about the coupling of the weak force to particles. It turns out that the weak force couples to right-chiral antiparticles as well. • A right-chiral electron ξR with isospin 0 and electric charge −e • A left-chiral anti-right-chiral-electron (ξR)c = ξ L with isospin 0 and electric charge +e 200 physics from symmetry Therefore, when talking about electrons, we have in fact four differ- ent \"things\" we need to consider. These are all really different par- ticles and we need to give them different names! Usually one talks about just two particles related to an electron: The electron and the positron and we will see how this comes about in a moment. We restrict the following discussion to the rest frame of the particles in question. In other frames the discussion works analogous but is more cumbersome. The objects inside a Dirac spinor and its charge conjugate are directly related to these four particles. The physical electron and the physical positron are commonly identiﬁed as the solutions of the Dirac equation. The Dirac equation is an equation of motion, i.e. an equation that determines the dynamics of the particles in question. The explicit solutions are Dirac spinors that evolve in time. We need such Dirac spinors with a deﬁnite time-evolution in order to describe how our particles evolve in time. As we will see this requires that we always use two of the particles listed above at once. An explicit derivation of the solutions of the Dirac equation can be found in the appendix Section 8.9. Here we just use the results. There are four independent solutions of the Dirac equation and two are of the form ψi = (ui ui ) (8.63) with for example41 u1 = (1 0 ) e−imt and u2 = (0 1 ) e−imt and two 41 This is a basis choice. The only requirement is that they are linearly independent. solutions are of the form ˜ψi = (−vi vi ) ,(8.64) with for example v1 = (1 0 ) e+imt and v2 = (0 1 ) e+imt The Dirac equation tells us that the spin conﬁguration of the two particles described by the upper and lower Weyl spinors inside a Dirac spinor, are directly related. In addition, their time depen- dence must be the same. These solutions describe what is commonly known as a physical electron and a physical positron, with different spin conﬁgurations42. 42 Take note that the connection between these objects is charge conjugation. This can be seen by using the explicit form of the charge conjugation operator: ψc 1 = iγ2ψ⋆ 1 . Therefore: (ψ1)c = ˜ψ2 and (ψ2)c = ˜ψ1. • ψ1 is an electron with spin up • ψ2 is an electron with spin down quantum mechanics 201 • ˜ψ1 is a positron with spin up • ˜ψ2 is a positron with spin down We can see nicely that a physical electron has a left-chiral (the up- per two components) and a right-chiral part (the lower two compo- nents). For a physical electron the spin conﬁguration of the left-chiral and the right-chiral part and the time-dependence must be the same for both parts. As discussed above, this left-chiral and right-chiral parts are really different, because they have different weak charge! Nevertheless, in order to describe a dynamical, physical electron we always need both parts. Take note that these solutions do not mean that the object we use to describe a physical electron consists of exactly the same upper and lower two-component objects. Only their spin conﬁguration and their time dependence must be equivalent. The upper object is still part of a doublet, whereas the lower object isn’t. The upper object trans- forms under SU(2) transformations and the lower doesn’t. Using the notation from above we have physical electron = (χL ξR ) ∝ (u u ) .(8.65) This does not mean that χL = ξR. The Weyl spinor χL is part of a doublet and describes a particle with isospin, whereas the particle described by ξR has isospin zero. In addition, we already know that the upper and lower Weyl spinor inside a Dirac spinor transform dif- ferently under Lorentz boosts. Therefore it is important that we use different symbols. In other words: The object describing a left-chiral electron χL carries an additional SU(2) index, because χL transforms as part of a doublet under SU(2) transformations. ξR has no such index and transforms as a singlet under SU(2) transformations. Equivalently we have physical positron = (−ξ L χR ) ∝ (−v v ) (8.66) which we can see through charge conjugation43 43 See Section 7.1.5 and use the ex- plicit form of the matrix as deﬁned in Eq. 6.13: γ2 = ( 0 ¯σ2 σ2 0 ) = ( 0 −σ2 σ2 0 ).(physical electron)c = iγ2 (χL ξR )⋆ = (−ξ L χR ) ∝ iγ2 (u u )⋆ = (−uc uc ) = physical positron (8.67) The message to take away is that the physical electron we observe in nature most of the time is a mixture of two different particles: The 202 physics from symmetry left-chiral electron that carries isospin and the right-chiral electron with isospin zero! Equivalently the physical positron is a mixture of an anti-left-chiral electron, which carries isospin and an anti-right- chiral electron with isospin zero. The solutions of the Dirac equation tell us how our particles evolve in time. Let’s say we start with an electron with spin up that was created in a weak interaction and is therefore purely left-chiral. How does this particle evolve in time? A purely left-chiral electron with spin up e↑ L = ⎛ ⎜ ⎜ ⎜ ⎝ 1 0 0 0 ⎞ ⎟ ⎟ ⎟ ⎠ (8.68) is not a solution of the Dirac equation and therefore, in order to de- termine its time evolution, we must rewrite this in terms of solutions of the Dirac equation. e↑ L = ⎛ ⎜ ⎜ ⎜ ⎝ 1 0 0 0 ⎞ ⎟ ⎟ ⎟ ⎠ = 1 2 ⎛ ⎜ ⎜ ⎜ ⎝ ⎛ ⎜ ⎜ ⎜ ⎝ 1 0 1 0 ⎞ ⎟ ⎟ ⎟ ⎠ − ⎛ ⎜ ⎜ ⎜ ⎝ −1 0 1 0 ⎞ ⎟ ⎟ ⎟ ⎠ ⎞ ⎟ ⎟ ⎟ ⎠ = Ψ1(t = 0) − ˜Ψ1(t = 0) .(8.69) We know how Ψ1 and ˜Ψ1 evolve in time Ψ1(t) − ˜Ψ1(t)=→ 1 2 ⎛ ⎜ ⎜ ⎜ ⎝ ⎛ ⎜ ⎜ ⎜ ⎝ 1 0 1 0 ⎞ ⎟ ⎟ ⎟ ⎠ e−imt − ⎛ ⎜ ⎜ ⎜ ⎝ −1 0 1 0 ⎞ ⎟ ⎟ ⎟ ⎠ eimt ⎞ ⎟ ⎟ ⎟ ⎠ (8.70) For t = 0 this reduces to the left-chiral state as it should be, but as time evolves, say t = π 2m we have → 1 2 ⎛ ⎜ ⎜ ⎜ ⎝ ⎛ ⎜ ⎜ ⎜ ⎝ 1 0 1 0 ⎞ ⎟ ⎟ ⎟ ⎠ e−i π 2 ︸ ︷︷ ︸ =-i − ⎛ ⎜ ⎜ ⎜ ⎝ −1 0 1 0 ⎞ ⎟ ⎟ ⎟ ⎠ ei π 2 ︸︷︷︸ =i ⎞ ⎟ ⎟ ⎟ ⎠ = i 2 ⎛ ⎜ ⎜ ⎜ ⎝ ⎛ ⎜ ⎜ ⎜ ⎝ −1 0 −1 0 ⎞ ⎟ ⎟ ⎟ ⎠ − ⎛ ⎜ ⎜ ⎜ ⎝ −1 0 1 0 ⎞ ⎟ ⎟ ⎟ ⎠ ⎞ ⎟ ⎟ ⎟ ⎠ = −i ⎛ ⎜ ⎜ ⎜ ⎝ 0 0 1 0 ⎞ ⎟ ⎟ ⎟ ⎠ = −ie↑ R (8.71) which describes a right-chiral electron with spin up! The lesson here is that as time evolves, a left-chiral particle changes into a right-chiral quantum mechanics 203 particle and vice versa. To describe the time-evolution of a particle like an electron we need eL and eR, which is why we wrote them together in one object: the Dirac spinor. The same is true for the positron. Recall that the two different particles eL and eR, carry different weak charge, i.e. isospin. Nevertheless as time evolves these two particles can transform into each other. Most of the time it will be a mixture of both and not a deﬁnite eigenstate. Isospin and chirality are therefore not conserved as time evolves, only in interactions. We can now see that the notation with Dirac spinors is necessary, because we have a close, dynamical connection between each two particles of the four particles listed at the beginning of this section. Chirality and therefore isospin are not conserved during propagation. A propagating electron can sometimes be found as left-chiral and sometimes as right-chiral. 8.9 Appendix: Solving the Dirac Equation As explained at the beginning of the last section, we use here the symbols u and v for the two-component objects inside a Dirac spinor, and u and v for four-component objects. This means, for example u1 and u2 describe two different four-component objects. If we don’t want to be speciﬁc and want to consider both four-component objects at the same time we simply write u. Then u1 and u2 are the two two-component objects inside such a four-component object u = (u1 u2 ) In this appendix we will solve the Dirac equation in the rest frame in the chiral basis. The solution for an arbitrary frame can be com- puted by acting with a boost transformation on the solution derived in this section. In addition to the discussion in the last section, we will use these solutions in Chapter 9, when we talk about quantum ﬁeld theory. The Dirac equation is (i∂μγμ − m)ψ = 0. (8.72) Anticipating plane wave solutions, we make the ansatz Ψ = ue−ipx, with some four-component object u, because the matrices γμ in the equation are 4 × 4. In the rest frame, which means momentum zero ⃗p = 0, the exponent reduces to −ipx = −i(p0x0 − ⃗p⃗x)= −ip0x0. Now using the relativistic energy-momentum relation E = √ ⃗p + m2, which we derived at the beginning of this chapter, and using that 204 physics from symmetry p0 = E and x0 = t,wehave −ipx = −iEt = −i√ ⃗p ︸︷︷︸ =0 +m2t = −imt. Putting this ansatz into the Dirac equation yields (i∂μγμ − m)ue−imt = 0 → (i(∂0γ0 + ∂iγi) − m)ue−imt = 0 → i((−im)γ0 − m)ue−imt = 0 → (mγ0 − m)u = 0 →︸︷︷︸ dividing by m ( (01 10 ) − (10 01 ) )c = 0 → (−11 1 −1 )(u1 u2 ) = 0 → (−u1 + u2 u1 − u2 ) = 0(8.73) The 1 inside the remaining matrix here is the 2 × 2 unit matrix and therefore u1 and u2 are two-component objects. We see that our ansatz solves the equation, if u1 = u2. Therefore, we have found two linearly independent solutions of the Dirac equation Ψ1 = ⎛ ⎜ ⎜ ⎜ ⎝ 1 0 1 0 ⎞ ⎟ ⎟ ⎟ ⎠ e−imt Ψ2 = ⎛ ⎜ ⎜ ⎜ ⎝ 0 1 0 1 ⎞ ⎟ ⎟ ⎟ ⎠ e−imt (8.74) We can ﬁnd two other solutions by making the ansatz ˜Ψ = veipx, which analogously reduces in the rest frame to ˜Ψ = veimt. This ansatz yields (i∂μγμ − m)veimt = 0 → (−mγ0 − m)v = 0 → (−1 −1 −1 −1 )(v1 v2 ) = 0 → (−v1 − v2 −v1 − v2 ) = 0. (8.75) We therefore conclude that we have a solution with time depen- dence eimt, if the upper and lower two-component objects in the Dirac spinor are related by −v1 = v2. Two linearly independent quantum mechanics 205 solutions following from this ansatz are ˜Ψ1 = ⎛ ⎜ ⎜ ⎜ ⎝ 1 0 −1 0 ⎞ ⎟ ⎟ ⎟ ⎠ eimt ˜Ψ2 = ⎛ ⎜ ⎜ ⎜ ⎝ 0 1 0 −1 ⎞ ⎟ ⎟ ⎟ ⎠ eimt.(8.76) 8.10 Appendix: Dirac Spinors in Different Bases In the Lagrangian the Dirac spinors ψ appear always in combination with the matrices γμ. This can be used to simplify computations, by switching to a different basis. This works, because we can add terms of the form 1 = N−1N, with some arbitrary invertible matrix N, between ψ and γμ and then redeﬁne both. For example ∂μ ¯ψγμψ = ∂μ ¯ψ N−1N︸ ︷︷ ︸ =1 γμ N−1N︸ ︷︷ ︸ =1 ψ = ∂μ ¯ψN−1 ︸ ︷︷ ︸ ≡ ¯ψ′ Nγμ N−1 ︸ ︷︷ ︸ ≡γ′ μ Nψ ︸︷︷︸ ≡ψ′ = ∂μ ¯ψ′γ′ μψ′. (8.77) The basis we worked with in this text so far is called the chiral basis or Weyl basis. Conventionally the Dirac equation is solved in another basis, called mass basis or Dirac basis. In the chiral basis we worked with so far, the Dirac Lagrangian LD = iχ† Lσμ∂μχL + iξ† R ¯σμ∂μξR − mχ† LξR − mξ† RχL (8.78) has non-diagonal mass terms, i.e. mass terms that mix different states. We can use the freedom to choose a basis to pick a basis where the mass terms are diagonal, which is then called mass ba- sis. This means we want a mass term ψ†mψ, with m = (m1 0 0 m2 ) , which gives us mass terms of the form ¯ψ′ M′ψ′ = ψ†γ′ 0 M′ψ′ = (u′ v′ )† (m1 0 0 m2 )(u′ v′ ) =(u′)†m1u′ +(v′)†m2v′, (8.79) whereas at the moment we are dealing with ¯ψMψ = ψ†γ0 Mψ = (χL ξR )† ( 0 m m 0 )(χL ξR ) = mχ† LξR + mξ† RχL. (8.80) 206 physics from symmetry The latter basis, which we worked with so far, makes it easy to inter- pret things in terms of chirality, whereas it’s easier for Dirac spinors in the mass basis to make the connection to physical propagating particles. To ﬁnd the connection between the second and the ﬁrst form, we need to diagonalize the matrix M = ( 0 m m 0 ) = m (01 10 ) . The matrix is diagonalized through the matrix N = 1√2 (−11 11 ) : N−1 (−m 0 0 m ) ︸ ︷︷ ︸ ≡M′ N = M (8.81) → m 1 √2 (−11 11 )−1 (−10 01 ) 1 √2 (−11 11 ) = m (01 10 ) (8.82) and therefore we redeﬁne the Dirac spinors accordingly ¯ψMψ = ¯ψ NN−1 ︸ ︷︷ ︸ =1 MNN−1 ︸ ︷︷ ︸ =1 ψ = ¯ψN ︸︷︷︸ ≡ ¯ψ′ N−1 MN︸ ︷︷ ︸ ≡M′ N−1ψ ︸ ︷︷ ︸ ≡ψ′ = ¯ψ′ M′ψ′.(8.83) It is instructive to have a look at the chiral projection operators PL = 1−γ5 2 in this basis. We need to calculate how the matrix γ5 looks like in this new basis ˜γ5 = N−1γ5N = 1 √2 (11 1 −1 )(10 0 −1 ) 1 √2 (11 1 −1 ) = 1 2 (11 1 −1 )( 11 −11 ) = (01 10 ) .(8.84) The corresponding eigenvectors are 1√2 ( 1 −1 ) and 1√2 (1 1 ) . This means a chiral eigenstate is now described by a Dirac spinor with upper and lower components. For example, a left-chiral state is in this basis of the form 1√2 ( 1 −1 ) . In contrast, in the chiral basis γ5 quantum mechanics 207 was diagonal and a left-chiral eigenstate was given by a Dirac spinor with upper components only ψL = (χL 0 ) , and a right-chiral Dirac spinor with lower components only ψR = ( 0 ξR ) . The chiral projection operator is in this basis PL = 1 − γ5 2 = 1 2 ( 1 −1 −11 ) .(8.85) 8.10.1 Solutions of the Dirac Equation in the Mass Basis We can solve the Dirac equation in the mass basis (iγμ∂μ − m)Ψ = 0(8.86) by making the ansatz ψ = ue−ipx, which yields (γμ pμ − m)ue−ipx = 0 → ((γμ pμ − m)u = 0. (8.87) Equivalently we can make the ansatz ψ = veipx, which yields ( − γμ pμ − m)veipx = 0 → ( − γμ pμ − m)v = 0. Analogously to our solution in the chiral basis, we work in the rest frame, i.e. ⃗p = 0. We are allowed to make such a choice, because physics is the same in all frames of reference and therefore we can pick one that ﬁts our needs best. In this frame of reference, with pi = 0, we have → (γ0 p0 − m)u = 0 → ( − γ0 p0 − m)v = 0. In addition, we have p0 = E and we can use the relativistic energy- momentum relation, which we derived at the beginning of this chap- ter (Eq. 8.2). In the rest frame we have E = √(pi)2 + m2 = m.We now use the explicit form of γ0 in the mass basis, which can be com- puted using the matrix N from above and the transformation law γ′ 0 = N−1γ0N. Remember that we have an implicit unit matrix be- hind m and therefore → ( (10 0 −1 ) m − m (10 01 ) )u = 0 208 physics from symmetry → ( − (10 0 −1 ) m − m (10 01 ) )v = 0 → (00 0 −2 ) u = 0 → (−20 00 ) v = 0. Recalling that each Dirac spinor consists of two two-component ob- jects, we conclude that the lower two-component object of u and the upper two-component object of v must be zero: → (00 0 −2 )(u1 u2 ) = ( 0 −2u2 ) = 0 → u2 = 0 → (−20 00 )(v1 v2 ) = (−2v1 0 ) = 0 → v1 = 0. We can see that in this basis the physical propagating particles (=solutions of the Dirac equation) are described by spinors with upper components only or equivalently for antiparticles with lower components only. We therefore have again four linearly independent solutions Ψ′ 1 = ⎛ ⎜ ⎜ ⎜ ⎝ 1 0 0 0 ⎞ ⎟ ⎟ ⎟ ⎠ e−imt Ψ′ 2 = ⎛ ⎜ ⎜ ⎜ ⎝ 0 1 0 0 ⎞ ⎟ ⎟ ⎟ ⎠ e−imt (8.88) and ˜Ψ′ 1 = ⎛ ⎜ ⎜ ⎜ ⎝ 0 0 1 0 ⎞ ⎟ ⎟ ⎟ ⎠ eimt ˜Ψ′ 2 = ⎛ ⎜ ⎜ ⎜ ⎝ 0 0 0 1 ⎞ ⎟ ⎟ ⎟ ⎠ eimt.(8.89) A general solution in this frame, in this basis, is a linear combina- tion ψ = ue−ipx + veipx = (u1 0 ) e−ipx + ( 0 v1 ) eipx (8.90) and we get the solution in an arbitrary frame by transforming this solution with a Lorentz boost. In addition, the most general solution is a superposition of all possible momenta and spin conﬁgurations4444 Recall that the two components of a Weyl spinor represent different spin states. Ψ = ∑ r √ m (2π)3 ∫ d3 p √Ep (cr(p)ur(p)e−ipx + d† r (p)vr(p)e+ipx) (8.91) 9 Quantum Field Theory Summary In this chapter the framework of quantum ﬁeld theory is introduced. Starting with the equation derived in Chapter 5 [Φ(x), π(y)] = iδ(x − y), we are able to see that the ﬁelds themselves are operators. The so- lutions of the equations of motion for spin 0, 1 2 and 1 are written in terms of their Fourier expansions1. Using the commutation rela- 1 The idea behind the Fourier transform is explained in Appendix D.1.tion, cited above, we discover that the Fourier coefﬁcients are now operators. Afterwards, we will see how these operators, and with them of course the ﬁelds, create and annihilate particles. Using the Lagrangian for the corresponding ﬁelds, we are able to derive the Hamiltonian operator representing energy. Afterwards, we start developing interaction theory, which is what quantum ﬁeld theory is all about. We will see that in interaction the- ory, the Hamiltonian is given by a linear combination of the Hamilto- nian for the free ﬁeld plus an interaction Hamiltonian. This insight can then be used in the interaction picture, where the time evolu- tion of the ﬁelds is governed by the free Hamiltonian and the time evolution of the states by the interaction Hamiltonian. Using this pic- ture, we are able to derive the probability amplitudes for scattering processes. These are denoted in the Dirac notation ⟨ f | ˆS |i⟩ , where ˆS denotes the operator describing the scattering process, |i⟩ is the initial state and ⟨ f | is the ﬁnal state. We will discover that the operator ˆS can be written in terms of the interaction Hamiltonian HI: ˆS(t, ti)= e−i ∫ t ti dt′ HI . © Springer International Publishing AG 2018 J. Schwichtenberg, Physics from Symmetry, Undergraduate Lecture Notes in Physics, https://doi.org/10.1007/978-3-319-66631-0_9 210 physics from symmetry This can’t be solved and therefore we evaluate the exponential in terms of its series expansions. For most experiments the ﬁrst few terms sufﬁce to get an accurate description. Each term in this series expansion can be interpreted physically as describing a different kind of scattering process. The interaction Hamiltonian contains linear combinations of the ﬁelds, which create and annihilate particles as mentioned above. For the ﬁrst non-trivial order, we get 8 terms and we will see that the ﬁrst term describes a scattering process of the form e−e+ → γ. This means we start with an initial state |e−e+⟩ consisting of an electron and a positron, which are annihilated by the ﬁeld operators of the spin 1 2 ﬁelds and afterwards a photon ⟨γ| is created by the photon ﬁeld. The other terms result in zero when operating on this initial state |e−e+⟩. The next order in the series expansion consists of many, many terms and we will take a look at just one of them. Again, we start with an initial state |e−e+⟩ and we will see that one term describes the process e−e+ → γ → e−e+, where the initial and ﬁnal electron and positron have, in general, completely different momenta. In exactly the same way, all terms can be interpreted for all inter- action Hamiltonians. A pictorial way to simplify these kinds of com- putations are the famous Feynman diagrams. Each line and vertex in such a diagram represents a factor of the kind mentioned above. 9.1 Field Theory Identiﬁcations In this section, we want to understand how the Lagrangians that we derived from symmetry constraints can be used in a ﬁeld theoret- ical framework. The ﬁrst step in deriving a ﬁeld theory describing nature is combining the Lagrangians we found with the result from Chapter 5, speciﬁcally Eq. 5.5, which we recite here for convenience: [Φ(x), π(y)] = iδ(x − y),(9.1) where the conjugate momentum density π(y) is given by π(y)= ∂L ∂(∂0Φ(y)) .(9.2) quantum field theory 211 9.2 Free Spin 0 Field Theory \"Every act of creation is ﬁrst of all an act of destruction.\" - Pablo Picasso2 2 As quoted in Rollo May. The Courage to Create. W. W. Norton and Com- pany, reprint edition, 3 1994. ISBN 9780393311068Again, let’s start with the simplest possible case: free spin 0 ﬁelds. We describe such ﬁelds with scalars, which are objects that do not change at all under Lorentz transformations3. We already derived in 3 This was derived in Section 3.7.4 Chapter 6.2 the corresponding Lagrangian L = 1 2 (∂μΦ∂μΦ − m2Φ2) (9.3) and the equation of motion, called Klein-Gordon equation (∂μ∂μ + m2)Φ = 0. (9.4) Using the Lagrangian in Eq. 9.3, we can calculate the conjugate mo- mentum π(x)= ∂L ∂(∂0Φ(x)) = ∂ ∂(∂0Φ(x)) 1 2 (∂μΦ(x)∂μΦ(x) − m2Φ2(x)) = ∂0Φ(x) . The most general solution of the Klein-Gordon equation can be writ- ten in terms of its Fourier-expansion4 4 See the appendix in Section 9.6 at the end of this chapter for a detailed computation of the integral measure and a justiﬁcation for writing the solution like this. Φ(x)= ∫ dk3 1 (2π)32ωk (a(k)e−i(kx) + b(k)ei(kx)) ,(9.5) with (ωk)2 ≡ ⃗k2 + m2. For real scalar ﬁelds we can rewrite this as Φ(x)= ∫ dk3 1 (2π)32ωk (a(k)e−i(kx) + a†(k)ei(kx)) (9.6) because c + c† = Re(c)+ i · Im(c) ︸ ︷︷ ︸ c + Re(c) − i · Im(c) ︸ ︷︷ ︸ c† = 2Re(c). Now we are having a look at the implications of Eq. 9.1, i.e. the non vanishing commutator [Φ(x), π(y)] ̸= 0. This means that Φ(x) and π(y) cannot be ordinary functions, but must be operators, be- cause ordinary functions commute: (3 + x)(7xy)=(7xy)(3 + x). By looking at Eq. 9.6, we conclude that the Fourier-coefﬁcients a(k) and a(k)† are operators, because e±i(kx) is just a complex number and complex numbers commute. Using Eq. 9.1 we can compute5 5 See for example chapter 4.1 in Lewis H. Ryder. Quantum Field The- ory. Cambridge University Press, 2nd edition, 6 1996. ISBN 9780521478144 [a(k), a†(k′)]=(2π)3δ3(⃗k −⃗k′) (9.7) and [a(k), a(k′)] = 0(9.8) 212 physics from symmetry [a†(k), a†(k′)] = 0. (9.9) Now that we know that our ﬁeld itself is an operator, the logical next thing to ask is: What does it operate on? In a particle theory, we identify the dynamical variables as operators acting on something describing a particle (the wavefunction, an abstract Dirac vector, etc.). In a ﬁeld theory we have up to now nothing to describe a particle. At this point, it is completely unclear how particles appear in a ﬁeld theory. Nevertheless, let’s have a look at how our ﬁeld coefﬁcents a(k) and a†(k) act on something abstract and by doing this, we learn how the ﬁelds act on something abstract. To get some intuition about what is going on here, let’s ﬁrst have a look at something we are familiar with: energy. The energy E of a scalar ﬁeld is given by66 We derived this in Eq. 4.40 from time-translation invariance. E = ∫ d3xT00 = ∫ d3x ⎛ ⎜ ⎜ ⎜ ⎝ ∂L ∂(∂0Φ) ∂Φ ∂x0︸︷︷︸ =∂0Φ −L ⎞ ⎟ ⎟ ⎟ ⎠ = ∫ d3x ((∂0Φ)2 − 1 2 (∂μΦ∂μΦ − m2Φ2)) =︸︷︷︸ ∂μ∂μ=∂0∂0−∂i∂i 1 2 ∫ d3x ((∂0Φ)2 +(∂iΦ)2 + m2Φ2) (9.10) By substituting Eq. 9.6 into Eq. 9.10 and using the commutation relations (Eq. 9.7-9.9), we can write E = 1 2 ∫ dk3 1 (2π)3 ωk (a†(k)a(k)+ a(k)a†(k)) =︸︷︷︸ Eq. 9.7 ∫ dk3 1 (2π)3 ωk (a†(k)a(k)+ 1 2 (2π)3δ3(0)) (9.11) At this point we can see that our theory explodes. The second term in the integral is inﬁnite. We could stop at this point and say that this kind of theory does not work. Nevertheless, some brave physicists dug deeper, ignoring this inﬁnite term and discovered a theory describing nature very accurately. There is no explanation for this and the standard way of continuing from here on is to ignore the second term. The crux here is that this term appears in the energy of every system and we are only able to measure energy differences. Therefore, this constant inﬁnite term appears in none of our measure- ments. quantum field theory 213 Conventionally, the energy written as an operator is called Hamil- tonian ˆH. We can compute the commutator7 of ˆH and the Fourier 7 It will become clear in a moment why this is useful.coefﬁcents a(k) and a†(k). We get [ ˆH, a†(k′)] = ∫ dk3 1 (2π)3 ωk[a†(k)a(k), a†(k′)] =︸︷︷︸ [a†(k),a†(k′)]=0 ∫ dk3 1 (2π)3 ωka†(k)[a(k), a†(k′)] = ∫ dk3ωka†(k)δ3(k − k′) =︸︷︷︸ See Appendix D.2 ωk′ a†(k′) (9.12) and equally [ ˆH, a(k′)] = −ωk′ a(k′) .(9.13) The quantum formalism works by operating with operators on something that describes the physical system8. Here, if we act with 8 This was explained in Section 8.3. the energy operator, i.e. the Hamiltonian ˆH, on something abstract |?⟩ describing our physical system, we get the energy of the system: ˆH |?⟩ = E |?⟩ (9.14) Now we return to our starting question: How does a ﬁeld9 act 9 Remember: Field=Operator! on our system? Let’s have a look at the effect of the ﬁrst Fourier coefﬁcient, now an operator, on the energy E of the system10: 10 We will do something very clever here, which was ﬁrst discovered by Dirac while solving the problem of the harmonic oscillator in quantum mechanics. ˆH (a(k′) |?⟩) = ⎛ ⎜ ⎝a(k′) ˆH + ˆHa(k′) − a(k′) ˆH ︸ ︷︷ ︸ [ ˆH,a(k′)] ⎞ ⎟ ⎠ |?⟩ = a(k′) ˆH |?⟩ ︸ ︷︷ ︸ =E|?⟩ +[ ˆH, a(k′)] |?⟩ = (a(k′)E +[ ˆH, a(k′)]) |?⟩ =︸︷︷︸ Eq. 9.13 (a(k′)E − ωk′ a(k′)) |?⟩ = (E − ωk′ ) (a(k′) |?⟩) (9.15) and equally for the second Fourier coefﬁcent ˆHa†(k′) |?⟩ =(E + ωk′ )a†(k′) |?⟩ .(9.16) How can we interpret this? We see that a(k′) |?⟩ can be interpreted as a new system with energy E − ωk. To make this more concrete we deﬁne |?2⟩≡ a(k′) |?⟩ 214 physics from symmetry with ˆH |?2⟩ =︸︷︷︸ Using Eq. 9.15 (E − ωk′ ) |?2⟩ . This suggests how we should interpret what the ﬁeld does. Imag- ine a completely empty system |0⟩, with, by deﬁnition H |0⟩ = 0 |0⟩. If we now act with a†(k′) on |0⟩, we know that this transforms our empty system into a system having energy ωk′ ˆHa†(k′) |0⟩ =︸︷︷︸ Using Eq. 9.16 ωk′ a†(k′) |0⟩ .(9.17) We see that a†(k′) creates something in the completely empty system with energy ωk′ , which is what we call a particle with momentum k′! If we act a second time on this system with a†(k′) we create a second particle with the same momentum. If we act on it with a†(k′′) we create a particle with momentum k′′ and so on. Therefore, we call a†(k′) a creation operator. Similarly to a†(k′), we can interpret a(k′): a(k′) destroys or annihilates a particle of energy ωk′ and is therefore called annihilation or destruction operator. To make this more concrete we introduce a new notation for particle states a†(k) |0⟩≡|1k⟩ (9.18) a†(k) |1k⟩≡|2k⟩ (9.19) a†(k′) |2k⟩≡|2k,1k′ ⟩ (9.20) Take a look at the energy again: E = ∫ dk3 1 (2π)3 ωka†(k)a(k) . What happens if this operator acts on a state like |2k1, k2⟩? The result should be E = 2ωk1 + ωk2, which is the energy of two particles with energy ωk1 and one particle with energy ωk2 . Therefore, the operator N(k) ≡ a†(k)a(k) (9.21) appearing here is a number operator, denoted N(k) that extracts the number of particles with momentum k from a state: N(k) |nk, n′ k, ...⟩ = nk |nk, n′ k,. . .⟩ (9.22) The energy operator can then be written as E = ∫ dk3 1 (2π)3 ωk N(k). quantum field theory 215 Furthermore, take note that there are physical systems, where the momentum spectrum is not continuous, but discrete11. For such 11 Remember the particle in a box example. It is an often used trick in quantum ﬁeld theory to assume the system in question is restricted to a volume V. This results in a discrete momentum spectrum. At the end of the computation the limit limV→∞ is taken. systems all integrals change to sums, for example, the energy is then of the form E = ∑ k ωk N(k) and the commutation relation changes to [a(k), a†(k′)] = δk,k′ .(9.23) Take note that quantum ﬁeld theory is, like quantum mechanics, a theory making probabilistic predictions. Therefore, our states need to be normalized ⟨k, k′,..|k, k′,..⟩ ! = 1, because a probability of more than 100% = 1 doesn’t make sense. If we act with an operator like a(k) on a ket, the new ket does not necessarily have unit norm12. Therefore, 12 Exactly the same line of though was discussed in Section 3.6.1, where we derived the ﬁnite-dimensional su(2) representations. There, we also introduced \"ladder operators\" J± and derived the constants that we emerge when we act with these operators on a given vector. we write a†(k) |nk⟩ = C |nk + 1⟩ ,(9.24) where nk denotes the number of particles with momentum k and C is some number. From this we get13 13 Recall that |nk⟩† = ⟨nk| and we have of course (a†)† = a. (a†(k) |nk⟩)† =(C |nk + 1⟩)† →⟨nk| a(k)= ⟨nk + 1| C†.(9.25) We can therefore write ⟨nk| a(k) ︸ ︷︷ ︸ 9.25 a†(k) |nk⟩ ︸ ︷︷ ︸ 9.24 = ⟨nk + 1| C†C︸︷︷︸ a number and no operator |nk + 1⟩ = C†C ⟨nk + 1|nk + 1⟩ ︸ ︷︷ ︸ =1 (9.26) or using the discrete commutation relation (Eq. 9.23) ⟨nk| a(k)a†(k) |nk⟩ = ⟨nk| ( a†(k)a(k) ︸ ︷︷ ︸ =N(k) Eq. 9.21 + δk,k ︸︷︷︸ =1 ) |nk⟩ Eq. 9.22 ︷︸︸︷ = ⟨nk| (nk + 1) ︸ ︷︷ ︸ a number and no operator |nk⟩ =(nk + 1) ⟨nk|nk⟩ ︸ ︷︷ ︸ =1 .(9.27) Putting Eq. 9.26 and Eq. 9.27 together yields C†C = nk + 1 → C = √nk + 1(9.28) and we therefore have a†(k) |nk⟩ = √nk + 1 |nk + 1⟩ .(9.29) Following the same steps we can derive a(k) |nk⟩ = √nk |nk − 1⟩ .(9.30) Two questions may pop up at this point. 216 physics from symmetry 1. What happens if we want to annihilate a particle in a completely empty system? 2. What about energy or charge conservation? How can we create something from nothing without violating conservation laws? The conservation laws are, of course, never violated, but how this comes about will only become clear when we develop the theory further. Maybe it helps to see that at this point Richard Feynman had the same problem1414 Feynman’s Nobel Lecture (December 11, 1965) I remember that when someone had started to teach me about creation and annihilation operators, that this operator creates an electron, I said, \"how do you create an electron? It disagrees with the conservation of charge\", and in that way, I blocked my mind from learning a very practical scheme of calculation. Secondly, we are never able to destroy something which is not there in the ﬁrst place. If we act with the destruction operator a(k) on a completely empty state |0⟩ we get, using Eq. 9.30 a(k) |0k⟩ = √0 |0k − 1k⟩ = 0(9.31) or equally a(k′) |1k⟩ = √0 |1k,0k′ − 1k′⟩ = 0. (9.32) We can see that if we act with an annihilation operator a(k′) on a ket, like |k⟩ that does not include a particle with this momentum k′, the theory produces a zero. The creation and annihilation operators appear in the Fourier expansion of the ﬁelds, which includes an integral (or sum) over all possible momenta. Therefore, if these ﬁelds act on a ket like |k⟩, only one annihilation operator will result in something non-zero. This will be of great importance when we try to describe interactions using quantum ﬁeld theory. Before we move on to interactions, we take a brief look at free spin 1 2 and spin 1 ﬁelds. 9.3 Free Spin 1 2 Field Theory The equation of motion for free spin 1 2 ﬁelds is the Dirac equation1515 We derived the Dirac equation in Section 6.3. (iγμ∂μ − m)Ψ = 0. The general solution of the Dirac equation can be written in the form1616 The Dirac equation is solved in Section 8.9. The general solution is then written analogous to the solution of the Klein-Gordon equation, discussed in the last section. quantum field theory 217 Ψ = ∑ r √ m (2π)3 ∫ d3 p √wp (cr(p)ur(p)e−ipx + dr(p)vr(p)e+ipx) = Ψ+ + Ψ−,(9.33) but this time we do not restrict to real ﬁelds, because we saw in Sec- tion 6.3 that a Lorentz invariant Lagrangian needs complex spin 1 2 ﬁelds. In addition, we follow the standard convention and write the solutions as Ψ = ∑ r √ m (2π)3 ∫ d3 p √wp (cr(p)ur(p)e−ipx + d† r (p)vr(p)e+ipx) ,(9.34) because in this way, d† r (p) can be seen to create an anti-particle. If we would name it dr(p) in the solution, this could lead to confusion, because for particles c† r (p) creates and cr(p) annihilates. Naming the Fourier coefﬁcient d† r (p) instead of dr(p), leads to an analogous interpretation for anti-particles: d† r (p) creates and dr(p) annihilates. Analogously, we have for the adjoint Dirac equation (i∂μ ¯Ψγμ + m ¯Ψ)= 0, which was also derived in Section 6.3, the solution ¯Ψ = ∑ r √ m (2π)3 ∫ d3 p √wp (c† r (p) ¯ur(p)e+ipx + dr(p) ¯vr(p)e−ipx) ≡ ¯Ψ+ + ¯Ψ− .(9.35) In these solutions u1, u2, v1, v3 denote the \"basis spinors\" in an arbi- trary frame17 17 We derived these spinors in the rest frame (pi = 0) in Section 8.10. The basis spinors in an arbitrary frame can be computed from the basis spinors in the rest frame by a boost transformation. u1 = √ E + m 2m ⎛ ⎜ ⎜ ⎜ ⎜ ⎜ ⎝ 1 0 p3 E+m p1+ip2 E+m ⎞ ⎟ ⎟ ⎟ ⎟ ⎟ ⎠ u2 = √ E + m 2m ⎛ ⎜ ⎜ ⎜ ⎜ ⎜ ⎝ 0 1 p1−ip2 E+m −p3 E+m ⎞ ⎟ ⎟ ⎟ ⎟ ⎟ ⎠ (9.36) v1 = √ E + m 2m ⎛ ⎜ ⎜ ⎜ ⎜ ⎜ ⎝ p1−ip2 E+m −p3 E+m 0 1 ⎞ ⎟ ⎟ ⎟ ⎟ ⎟ ⎠ v2 = √ E + m 2m ⎛ ⎜ ⎜ ⎜ ⎜ ⎜ ⎝ p3 E+m p1+ip2 E+m 1 0 ⎞ ⎟ ⎟ ⎟ ⎟ ⎟ ⎠ .(9.37) The rest of the theory for free spin 1 2 ﬁelds can be developed simi- larly to the scalar theory, but there is one small difference18. Let’s try 18 With incredible huge consequences! In fact, nothing in this universe would be stable if the spin 1 2 theory would work exactly like the scalar theory. 218 physics from symmetry what we get when we use the formula [Ψ(x), π(y)] = iδ(x − y) (9.38) for spin 1 2 ﬁelds, too. In the general solution for the equation of mo- tion, i.e. the Dirac equation, we have two different coefﬁcients: c† creates particles, whereas d† creates anti-particles. When we now compute the Hamiltonian for a spin 1 2 ﬁeld, using the commutation relation19, we get something of the form 19 [Ψ(x), π(y)] = Ψ(x)π(y) − π(y)Ψ(x)= iδ(x − y) H ∼ ∫ c†c − d†d . This shows that the energy of anti-particles is then negative. This is a serious problem because every state could forever decay to lower en- ergy states and nothing in this universe would be stable. The Hamil- tonian is not bounded from below, in contrast to the scalar case. However, when we use instead the anticommutation relation {Ψ(x), π(y)} = Ψ(x)π(y)+ π(y)Ψ(x)= −iδ(x − y), the term involving the anti-particle creation and annihilation opera- tors comes out positive and the problem is therefore solved. This has very interesting consequences. For example, we then have2020 Analogous to Eq. 9.9 for scalars, but now with the anticommutator instead of the commutator [, ] →{, }. {c†(p), c†(p′)} = 0 from which we can conclude {c†(p), c†(p)} = c†(p)c†(p)+ c†(p)c†(p)= 2c†(p)c†(p)= 0. ⇒ c†(p)c†(p)= 0(9.39) The action of two equal creation operators21always results in a 21 For spin 0 ﬁelds the correspond- ing equation isn’t very surpris- ing, because there we use the commutator: [c†(p), c†(p)] = c†(p)c†(p) − c†(p)c†(p)= 0. zero! This means we cannot create two equal spin 1 2 particles and this is famously called Pauli-exclusion principle. The other anti-commutation relations for the Fourier coefﬁcients can be derived from the anti-commutator of the ﬁeld and the conju- gate momentum to be: {cr(p), c† s (p′)} = δrsδ(p − p′) {dr(p), d† s (p′)} = δrsδ(p − p′) (9.40) and all other possible combinations equal zero. Therefore, these coef- ﬁcients can be seen to have the same properties as those we derived in the last section for the spin 0 ﬁeld. They create and destroy, with quantum field theory 219 the difference that acting twice with the same operator on a state re- sults in a zero. The Hamiltonian for a free spin 1 2 ﬁeld can be derived analogous to the Hamiltonian for a free spin 0 ﬁeld H 1 2 free = ∫ d3x(−i ¯Ψγi∂iΨ − m ¯ΨΨ) (9.41) or expressed in terms of the Fourier coefﬁcients H 1 2 free = ∑ r ∫ d3 pwp(c† r (p)cr(p)+ d† r (p)dr(p)+ const) ,(9.42) where again the constant term leads to an inﬁnite term and we choose to ignore this. 9.4 Free Spin 1 Field Theory The solution for the equation of motion for free spin 1 ﬁelds, the Proca equation22 22 We derived the Proca equation in Section 6.4. m2 Aρ = 1 2 ∂σ(∂σ Aρ − ∂ρ Aσ) (9.43) is, analogous to the spin 0 ﬁeld solution, of the form Aμ = ∫ d3k √(2π)32ωk (ϵr,μ(k)ar(k)e−ikx + ϵr,μ(k)a† r (k)eikx) ≡ A+ μ + A− μ (9.44) where ϵr,μ(k) are basis vectors, called polarization vectors. For spin 1 ﬁelds we are again able to use the commutator instead of the anti- commutator. We are therefore able to derive that the coefﬁcients ar, a† r have the same properties as the coefﬁcients for spin 0 ﬁelds. 9.5 Interacting Field Theory The next step is to look at interactions between ﬁelds of different spin. The corresponding Lagrangians were derived in earlier chapters from Lorentz and gauge symmetry. For example, for the interaction between a massive spin 1 2 ﬁeld and one massless spin 1 ﬁeld, we have the Lagrangian (Eq. 7.17) LDirac+Extra-Term = −m ¯ΨΨ + i ¯Ψγμ∂μΨ + gAμ ¯ΨγμΨ (9.45) from which we derive the corresponding Hamiltonian23 23 We will use this Hamiltonian in a moment! 220 physics from symmetry H = ∫ d3xT00 = ∫ d3x( ∂L ∂(∂0Ψ) ︸ ︷︷ ︸ =i ¯Ψγ0 ∂0Ψ − L ) = ∫ d3x(i ¯Ψγ0∂0Ψ + m ¯ΨΨ − i ¯Ψ γμ∂μ ︸ ︷︷ ︸ =γ0∂0−γi∂i Ψ − gAμ ¯ΨγμΨ) = ∫ d3x(m ¯ΨΨ + i ¯Ψγi∂iΨ) ︸ ︷︷ ︸ =H 1 2 free − ∫ d3x (gAμ ¯ΨγμΨ) ︸ ︷︷ ︸ ≡−HI = H 1 2 free + HI (9.46) 9.5.1 Scatter Amplitudes One of the main goals in quantum ﬁeld theory is to compute the probability for a ﬁxed number n of particles with deﬁned24 momenta 24 This is what physicists prepare in collider experiments. p1, p2, .., pn to transform into a (possibly different) number of (pos- sibly different) particles n′ with momenta q1, q2, .., qn′ . We can write this using Dirac’s notation ⟨q1, q2, .., qn′ | ˆS |p1, p2, .., pn⟩ ,(9.47) where ˆS is the operator describing the scattering. We will derive how this operator looks concretely in the next section. Formulated differently, we have some particles at initial time ti at some points in space xi and after the interaction, i.e. at the ﬁnal time t f , (possibly different) particles at a possibly different location x f . Therefore, the ﬁrst question we have to answer is: What can we say about the time evolution of states in quantum ﬁeld theory? 9.5.2 Time Evolution of States To answer this question we observe that the energy operator is given on the one hand by the identiﬁcation with the generator of time- translations i∂0 and on the other hand by the Hamiltonian. For exam- ple, for the free spin 0 theory we derived (Eq. 9.10) H0 free = 1 2 ∫ d3x ((∂0Φ)2 +(∂iΦ)2 + mΦ2) ,(9.48) while for the free spin 1 2 theory we have (Eq. 9.41) H 1 2 free = ∫ d3x(m ¯ΨΨ + i ¯Ψγi∂iΨ).(9.49) quantum field theory 221 Both identiﬁcations are operators in a ﬁeld theory, representing en- ergy, and we therefore write i∂0 |?(t)⟩ = H |?(t)⟩ ,(9.50) which is the equation governing the time evolution of a state in quan- tum ﬁeld theory. We can use this equation to deﬁne a time-evolution operator U that transforms the state from one point in time to an- other. If we choose, for brevity, the start time t = 0wehave25 25 In general |?(t)⟩ = U(t − t′) |?(t′)⟩. |?(t)⟩ = U(t) |?(0)⟩ .(9.51) Putting this ansatz into Eq. 9.50 yields i∂0U(t) |?(0)⟩ = HU(t) |?(0)⟩ .(9.52) This equation holds for arbitrary |?(0)⟩ and therefore i∂0U(t)= HU(t).(9.53) The general solution of this equation is U(t)= e−i ∫ t 0 dx0 H (9.54) as we can check i∂0U(t)= HU(t) → i∂0e−i ∫ t 0 dx0 H = He−i ∫ t 0 dx0 H → i(−iH)e−i ∫ t 0 dx0 H = He−i ∫ t 0 dx0 H → He−i ∫ t 0 dx0 H = He−i ∫ t 0 dx0 H ✓ (9.55) In experiments we never measure a ket |?(t)⟩, but always the com- binations of a bra with a ket. In general, we have objects of the form ⟨ f (t)| ˆO |i(t)⟩ ,(9.56) with some operator ˆO, initial state |i(t)⟩ and ﬁnal state ⟨ f (t)|. Here the states evolve in time, as described by the operator U, and the operators are time independent. This somewhat arbitrary choice is called Schrödinger picture and in the following we will talk about different possible choices, i.e. different \"pictures\". Writing Eq. 9.56 in terms of the time-evolution operator leads us to26 26 Remember ⟨ f | = | f ⟩† ⟨ f (0)| U†(t) ˆOU(t) |i(0)⟩ .(9.57) An important idea is that we can switch our perspective and say the operator ˆO evolves in time, according to the rule U†(t) ˆOU(t) and 222 physics from symmetry the bra and ket are time-independent. This new perspective is called Heisenberg picture. There is a similar, very useful trick that is helpful in interaction theory. The Hamiltonian is always the sum of the free Hamiltonian and the interaction Hamiltonian (Eq. 9.46) H = Hfree + HI.(9.58) The trick is to use a mixture of the two perspectives introduced above. We let the states evolve according to HI and the operators2727 Recall that in quantum ﬁeld theory the ﬁelds are our operators. according to Hfree. This is incredibly useful, because then we can reuse all results we already derived for free ﬁelds. This type of per- spective is called interaction picture. We deﬁne a state in the interac- tion picture |i(t)⟩I ≡ U† free |i(t)⟩S ,(9.59) where Ufree = e−i ∫ t 0 dx0 Hfree and the index S stands for Schrödinger picture, which is the name for the standard perspective where the states evolve according to the full Hamiltonian and the operators are time-independent. Putting now Eq. 9.59 into Eq. 9.50 we get28 the time-evolution 28 The equation holds in this form for the Schrödinger picture. Therefore, we have to solve |i(t)⟩I ≡ U† free |i(t)⟩S for |i(t)⟩S. We multiply the equation with Ufree and use UfreeU† free = 1. This yields |i(t)⟩S = Ufree |i(t)⟩I , which we can then put into Eq. 9.50. equation in the interaction picture: i∂0 |i(t)⟩S = H |i(t)⟩S → i∂0Ufree |i(t)⟩I = HUfree |i(t)⟩I → i∂0e−i ∫ t 0 dx0 Hfree |i(t)⟩I =(Hfree + HI)e−i ∫ t 0 dx0 Hfree |i(t)⟩I →︸︷︷︸ product rule \u0004\u0004\u0004\u0004\u0004\u0004\u0004\u0004\u0004\u0004\u0004 Hfreee−i ∫ t 0 dx0 Hfree |i(t)⟩I + ie−i ∫ t 0 dx0 Hfree ∂0 |i(t)⟩I =(\u0002\u0002\u0002Hfree + HI)e−i ∫ t 0 dx0 Hfree |i(t)⟩I → ie−i ∫ t 0 dx0 Hfree ∂0 |i(t)⟩I = HIe−i ∫ t 0 dx0 Hfree |i(t)⟩I → i∂0 |i(t)⟩I = ei ∫ t 0 dx0 Hfree HIe−i ∫ t 0 dx0 Hfree ︸ ︷︷ ︸ =Hint I = the interaction Hamiltonian in the interaction picture. |i(t)⟩I → i∂0 |i(t)⟩I = Hint I |i(t)⟩I (9.60) We conclude that the time-evolution of the states is now indeed governed by the interaction Hamiltonian Hint I . This little equation will be incredibly important for everything that follows. Now we are able to return to the starting question: How can we compute scattering processes ⟨ f (t f )| ˆS(t f , ti) |i(ti)⟩ ?(9.61) quantum field theory 223 The operator ˆS(t f , ti) transforms the initial state |i(ti)⟩ at time ti into the ﬁnal state |Ψ(t f )⟩ at time (t f ). In general, the ﬁnal state is not one speciﬁc particle state, but a linear combination of many possible outcomes. If this would be not the case particle physics would be boring. An interaction would always result in one speciﬁc outcome. We are more general here and allow arbitrary linear combinations. After we specify the operator ˆS we will see that this is actually the case. Concretely this means that ˆS transforms an initial state into a linear combination of ﬁnal states. To avoid confusion we will call the ﬁnal time in the following simply t instead of t f . Then we have29 29 This can be seen as a series expansion of the state |Ψ(t)⟩ in terms of our particle states | f (t)⟩.ˆS(t, ti) |i(ti)⟩ = |Ψ(t)⟩ = ∑ f S fi ︸︷︷︸ complex numbers | f (t)⟩ .(9.62) The multiplication with one speciﬁc ⟨ f ′(t)| from the left-hand side terminates all but one term of the sum: ⟨ f ′(t)| ∑ f S fi | f (t)⟩ = ∑ f S fi ⟨ f ′(t)| f (t)⟩ ︸ ︷︷ ︸ =δ ff ′ because basis states are orthogonal = ∑ f S fiδ ff ′ = S f ′i.(9.63) Therefore, the probability for this process to happen is |S f ′i|2. Now we specify the scatter operator ˆS. For this purpose we take a look again at the time-evolution equation that we derived above30 30 Eq. 9.60 and in order to avoid nota- tional clutter we suppress the super- script \"int\", which denotes that we are working in the interaction picture here.i∂t |Ψ(t)⟩I = HI |Ψ(t)⟩I .(9.64) We can rewrite this in terms of our initial state and the operator ˆS using Eq. 9.62 → i∂t ˆS(t, ti) |i(ti)⟩I = HI ˆS |i(ti)⟩I →︸︷︷︸ product rule i(∂t ˆS(t, ti)) |i(ti)⟩I + i ˆS(t, ti) ∂t |i(ti)⟩I︸ ︷︷ ︸ =0 because |i(ti)⟩I does not depend on t = HI ˆS |i(ti)⟩I . Now using that this equation holds for arbitrary initial states we can write i∂t ˆS(t, ti)= HI ˆS (9.65) with the general solution31 31 We omitted something very important here, called time ordering, which we will discuss in the next section. ˆS(t, ti)= e−i ∫ t ti dt′ HI (9.66) At a ﬁrst glance the problem is easy now. We know HI and \"just have to solve the integral\". This gives the operator ˆS(t, ti) and by acting with it on our initial states we get the probability amplitudes for different processes. Unfortunately, the integral cannot be solved 224 physics from symmetry and we therefore have to use an approximation method. To simplify the problem mathematically, the initial time is taken to be ti = −∞ and the ﬁnal time t = ∞. By doing this we avoid our probability amplitudes depending on time. For example, if we scatter particles, the probability that a certain process has happened 10−24 seconds after the assumed \"collision\" is different than 2 · 10−24 seconds after the \"collision\", because the interaction is still happening! By taking the time values to be very large we avoid these kind of complications. What we measure is usually always a result after all the interactions have happened. 9.5.3 Dyson Series Because there is no analytic solution for the exponentiated integral, we expand it in a Taylor series3232 This is derived in Appendix B.4.1: ex = 1 + x + x2 2! + x3 3! + x4 4! + ... ˆS(∞, −∞)= e−i ∫ ∞ −∞ dt′ HI (t′) = 1 − i ∫ ∞ −∞ dt1 HI(t1) − 1 2! (∫ ∞ −∞ dt1 HI(t1))(∫ ∞ −∞ dt2 HI(t2)) + ... (9.67) This is called the Dyson series. We need to take a careful look at the third term. HI(t1) and HI(t2) are not just numeric values, but operators acting on a ket to their right. Therefore, we need to make sure that the earlier time operator acts on the ket before the later time operator. The operators need to operate on the ket in a time ordered manner. It makes no sense if we act on a state with HI(t = 5s) and after that with HI(t = 2s). In the series above, we need for t1 < t2 (∫ ∞ −∞ dt2 HI(t2))(∫ ∞ −∞ dt1 HI(t1)) and for t2 < t1 (∫ ∞ −∞ dt1 HI(t1))(∫ ∞ −∞ dt2 HI(t2)) For this purpose an abstract time-ordering operator T is introduced, which is deﬁned by T {A(x)B(y)} := A(t1)B(t2) if t1 > t2 B(t2)A(t1) if t1 < t2. (9.68) quantum field theory 225 Therefore we write, giving a name to each term of the series expan- sion, ˆS(∞, −∞)= 1︸︷︷︸ S(0) −i ∫ ∞ −∞ dt1 HI(t1) ︸ ︷︷ ︸ S(1) − 1 2! T { (∫ ∞ −∞ dt1 HI(t1))(∫ ∞ −∞ dt2 HI(t2)) } ︸ ︷︷ ︸ S(2) +... (9.69) or written as a sum ˆS(∞, −∞)= ∞ ∑ n=0 (−i)n n! ∫ ∞ −∞ ... ∫ ∞ −∞ T { (∫ ∞ −∞ dt1 HI(t1))(∫ ∞ −∞ dt2 HI(t2)) ... (∫ ∞ −∞ dtn HI(tn)) } = ∞ ∑ n=0 S(n).(9.70) This is useful because HI has a numerical factor33 in it, the cou- 33 See Eq. 9.46. pling constant of the corresponding interaction, i.e. HI ∝ g . This coupling constant is, for example, for electromagnetic interactions, smaller than one. Therefore, the second term in the expansion S(2) ∝ (HI)2 ∝ g2 contributes less than the ﬁrst term S(1) ∝ g. The higher or- der terms in the expansion contribute even less: g > g2 > g3 > .... To describe the system in question it often sufﬁces to evaluate the ﬁrst few terms of the series expansion. Higher order terms often deliver corrections that lie outside the possibility of measurement. Unfortunately, going further from this point needs many pages of heavy algebra. The ﬁrst step is Wick’s-Theorem which enables one to express the time ordering in terms of commutators. Furthermore, these commutators need to be computed, which results in the famous Feynman propagators. Nevertheless, we want to go further34,sowe 34 Because now, the fun is about to begin!are going to use these results without proofs. The interested reader is referred to the standard texts on quantum ﬁeld theory35. 35 Some recommended books will be listed in the last section of this chapter. 9.5.4 Evaluating the Series We will now return to the example introduced at the beginning of this chapter: The interaction between a massive spin 1 2 ﬁeld and a massless spin 0 ﬁeld. The corresponding interaction Hamiltonian is (Eq. 9.46) HI = − ∫ d3xgAμ ¯ΨγμΨ. As explained above, we will look at each term of the series in Eq. 9.70 individually. 226 physics from symmetry The ﬁrst term of the series is trivial as it is simply the identity operator S(0) = I (9.71) The second term is more exciting: S(1) = −i ∫ ∞ −∞ dtHI = ig ∫ ∞ −∞ d4xAμ ¯ΨγμΨ (9.72) which we rewrite, recalling Eq. 9.33 and Eq. 9.44,as S(1) = ig ∫ ∞ −∞ d4x(A+ μ + A− μ )( ¯Ψ+ + ¯Ψ−)γμ(Ψ+ + Ψ−).(9.73) We can see this second term is actually 8 terms. Let us have a look at how one of these terms, we call it S(1) 1 , acts on a state consisting of, for example, one electron and one positron with prepared momenta |e+(p1), e−(p2)⟩ ig ∫ ∞ −∞ d4xA+ μ ¯Ψ+γμΨ+ |e+(p1), e−(p2)⟩ . Ψ+ consists of destruction36 operators for particles for all37 possible 36 Remember the operators with the † are those who create and the operators without are those who destroy. Ψ+ is deﬁned in Eq. 9.33. 37 We integrate over all possible mo- menta! momenta, multiplied with constants and a term of the form e−ipx1: Ψ+ ∝ ∫ d3 pcr(p)e−ipx . For each momentum this destroys the ket, which means we get a zero, because we are trying to destroy something which is not there, except for cr(p)= cr(p2). Therefore, operating with Ψ+ results in Ψ+ |e+(p1), e−(p2)⟩ ∝ e−ip2x |e+,0⟩ In the same way, operating with ¯Ψ+ on the ket results in ¯Ψ+e−ip2x |e+(p1),0⟩ ∝ e−ip2xe−ip1x |0, 0⟩ . Therefore, we are left with the pure vacuum state, multiplied with lots of constants. The last term operating on the ket is A+ μ , which creates photons of all momenta. Fig. 9.1: Feynman graph for the process e+e− → γ Qualitatively we have, when we want the contribution of this one term to the probability amplitude for the creation of a photon ⟨γ| with momentum k′ ⟨ f | S(1) 1 |i⟩ = ⟨γk′ | S(1) 1 |e+(p1), e−(p2)⟩ (9.74) = ∫ ∞ −∞ d4x ⟨γk′ | ∑ k constant(k) |γk⟩ e−ix(p1+p2−k) quantum field theory 227 = ∫ ∞ −∞ d4x ∑ k constant(k) ⟨γk′ ||γk⟩ ︸ ︷︷ ︸ =δkk′ e−ix(p1+p2−k) = ∫ ∞ −∞ d4x constant(k′)e−ix(p1+p2−k′). The integration over x results in a delta function δ(p1 + p2 − k) that represents 4-momentum conservation38. In experiments we are never 38 The 4-momentum (=energy p0 = E and ordinary momentum pi)of e− plus the 4-momentum of e+ must be equal to the 4-momentum of the photon γ: p1 + p2 − k ! = 0. Otherwise δ(p1 + p2 − k)= 0 as explained in Appendix D.2. able to measure or prepare a system in one deﬁned momentum, but only in a range. Therefore, at the end of our computation, we have to integrate over the relevant momentum range. Take note that the seven other terms contributing to ˆS(1) result in a zero, because they destroy for example, a photon, which is not there in the beginning. If we had started with particles other than an electron and a positron, for example, a photon and a positron |γ, e+⟩, the ﬁrst term results in a zero and some other term is non-zero. Next we take a very quick, qualitative look at the third term of ˆS: S(2) = − 1 2! T { (∫ ∞ −∞ d4x1HI(x1))(∫ ∞ −∞ d4x2HI(x2)) } = − 1 2! T { (∫ ∞ −∞ d4x1gAμ(x1) ¯Ψ(x1)γμΨ(x1))(∫ ∞ −∞ d4x2gAμ(x2) ¯Ψ(x2)γμΨ(x2)) } , (9.75) where the time-ordering can be rewritten using Wick’s Theorem into a sum of normal-ordered, denoted N{}, terms with commutators in it. Normal ordering means, putting all creation operators to the left, and all annihilation operators to the right. For instance, N{aa†a†a} = a†a†aa. One of the terms of this sum, for example, is − 1 2! g2 ∫∫ d4x1d4x2N { ¯Ψ(x1)γμΨ(x1)[Aμ(x1), Aμ(x2)] ¯Ψ(x2)γμΨ(x2) } where the computation of the commutator can be done using the explicit solution for Aμ and the result is called Photon propagator39 39 The propagators are one of the most complicated things to derive in quan- tum ﬁeld theory. For instance, consid- ering the scalar propagator, the starting point is iΔ ≡⟨0| T{Φ(x)Φ†(y)}|0⟩, which creates a particle from the vac- uum at y and destroys it again at x. This can be rewritten as the commu- tator iΔ = ⟨0| [Φ+†(y), Φ−(x)] |0⟩ and after many pages of math we get an expression of the form iΔ = −i 2π3 ∫ d3k ωk e−ik(x−y). This ﬁnal expression is what we can use in com- putations. This is just a sketch and many things here are not completely correct. Nevertheless it should give you a rough idea of what is going on. [Aμ(x1), Aμ(x2)] ≡ iDμ(x1 − x2) . From this term we get again many, many terms, because every Ψ, ¯Ψ etc. is actually a sum of two terms, and we will take a look at just one of them. Therefore, qualitatively we have for one40 of these 40 We pick again the term not resulting in a zero for the collision of an electron with a positron. many many terms, if we start again with an electron and a positron, something of the form − 1 2! g2 ∫∫ d4x1d4x2 ¯Ψ−(x1)Ψ−(x1)Dμ(x1 − x2) ¯Ψ+(x2)Ψ+(x2) |e+, e−⟩ (9.76) 228 physics from symmetry This can be understood physically: • The two particles we start with are destroyed at x2 by ¯Ψ+(x2)Ψ+(x2). • Then the propagator creates a \"virtual\" photon at x2 and propa- gates it to x1 where it is destroyed. • Finally ¯Ψ−(x1)Ψ−(x1) again create at x1 an electron and a positron. We can therefore compute with this term the probability ampli- tude for a reaction e+e− → e+e−, where of course the individual momenta of the incoming and outgoing particles can be completely different, but not their sum41. In the same way, all the other terms 41 This must be the case, because we have conservation of momentum. can be interpreted as some reaction between massive42 spin 1 2 and 42 Here we looked at electrons and positrons. Other possibilities are the quarks or the other two leptons μ and τ. massless43 spin 1 ﬁelds. 43 Here photons Fig. 9.2: Feynman graph for the process e+e− → γ → e+e− The probability amplitudes we get from computations like this can then be directly checked in experiments, because the probability amplitude is directly connected to a quantity that can be measured in experiments: the cross section. The techniques outlined in this chapter can be used to derive many important results of quantum ﬁeld theory. The other inter- action terms we derived can be put into the interaction Hamiltonian and the corresponding probability amplitudes follow analogously. Take not that the method we discussed here, only works if the cou- pling constant is smaller than 1. If the coupling constant is bigger than 1, higher order terms in the sum in Eq. 9.70 are bigger than lower order terms and therefore it is by no means justiﬁed to use just the ﬁrst terms of the series, to get an approximation. Further Reading Tips • Robert D. Klauber - Student Friendly Quantum Field Theory4444 Robert D. Klauber. Student Friendly Quantum Field Theory. Sandtrove Press, 2nd edition, 12 2013. ISBN 9780984513956 is, in my humble opinion, the best introduction to quantum ﬁeld theory. All chapters are pedagogically brilliant, because the au- thor spent a lot of time thinking about what problems someone learning quantum ﬁeld theory faces. • Francis Halzen, Alan D. Martin - Quarks and Leptons: An In- troductory Course in Modern Particle Physics45 is a great book 45 Francis Halzen and Alan D. Martin. Quarks and Leptons: An Introductory Course in Modern Particle Physics. Wiley, 1st edition, 1 1984. ISBN 9780471887416 which focusses on the applications of the computational schemes of quantum ﬁeld theory. • Anthony Zee - Quantum Field Theory in a Nutshell46 has some 46 Anthony Zee. Quantum Field Theory in a Nutshell. Princeton University Press, 1st edition, 3 2003. ISBN 9780691010199 brilliant and unique explanations, but some chapters are simply too short to understand as a beginner. Highly recommended after learning some quantum ﬁeld theory from another book. quantum field theory 229 • Franz Mandl, Graham Shaw - Quantum Field Theory47 is a very 47 Franz Mandl and Graham Shaw. Quantum Field Theory. Wiley, 2nd edition, 5 2010. ISBN 9780471496847 good starting point regarding weak and strong interaction theory • Michele Maggiore - A Modern Introduction to Quantum Field Theory48 is a great introduction with a strong focus on group 48 Michele Maggiore. A Modern Intro- duction to Quantum Field Theory. Oxford University Press, 1st edition, 2 2005. ISBN 9780198520740 theoretical concepts. • Matthew Schwartz - Quantum Field Theory and the Standard Model49 offers illuminating explanations on many advanced top- 49 Matthew D. Schwartz. Quantum Field Theory and the Standard Model. Cambridge University Press, 1 edition, 12 2013. ISBN 9781107034730 ics. 9.6 Appendix: Most General Solution of the Klein-Gordon Equation It is not too hard to ﬁnd one solution of the Klein-Gordon equation. Certainly plane waves Φ(x)= aei(px−Et) = ae−i(pμ xμ) do the job, because of the energy-momentum relation of special rela- tivity (Eq. 8.2) E2 = ⃗p2 + m2 → pμ pμ = m2 as we can check: (∂μ∂μ + m2)Φ =(∂μ∂μ + m2)e−i(pμ xμ) =(−pμ pμ + m2)e−i(pμ xμ) =(−m2 + m2)e−i(pμ xμ) = 0 ✓ (9.77) Because we differentiate the ﬁeld twice the sign in the exponent does not matter. Equally Φ†(x)= a†e−i(px−Et) = a†ei(pμ xμ) is a solution. Further solutions can be built as linear combinations. A general solution is given by superposition of all possible solutions, which can be seen as Fourier expansion50 50 That’s were the factors of 2π come from. Another way of seeing this is demanding the solutions to form an orthonormal set: ∫ dkeikxe−ikx′ = ∫ dkeik(x−x′ ) = 2πδ(x − x′). Therefore, the factors of 2π are normalisation constants. Φ(x)= ∫ dp4 (2π)4 (a(p)e−i(pμ xμ) + a†(p)ei(pμ xμ)) Take note that we wrote a = a(p) because we can have a different multiplication factor for each value of p and each term in the summa- tion is a solution on its own. In this context it is conventional to work with the wave number ki ≡ pi ¯h and the frequency k0 = w ≡ E ¯h instead of the energy and 230 physics from symmetry momentum. Because we work with ¯h = 1 we simply have to rename our variables to get the standard textbook expressions. Furthermore it’s conventional to abbreviate kx ≡ kμxμ. We therefore write Φ(x)= ∫ dk4 (2π)4 (a(k)e−i(kx) + a†(k)ei(kx)) Take note that not all solutions of the Klein-Gordon equation are suited to describe nature, because we have the \"mass-shell\" condi- tion pμ pμ = kμkμ = m2 → k2 0 − k2 i ! = m2 → k2 ! = m2.(9.78) Only solutions satisfying the mass-shell condition are in agreement with the relativistic energy-momentum relation (Eq. 8.2). We can build this condition into our equation, excluding all non-physical (off-shell) solutions with a delta distribution5151 This is explained in Appendix D.2. Φ(x)physical = ∫ dk4 (2π)4 2πδ(k2 − m2) (a(k)e−i(kx) + a†(k)ei(kx)) Besides that, only positive energy solutions are physical, because as explained earlier, otherwise the energy would be unbounded from below and nothing would be stable. We can built this constraint on our solutions into the equation by using a Heaviside function θ(k0), being zero for k0 < 0 and 1 for k0 ≥ 0. Our integral then reads Φ(x)physical = ∫ 1 (2π)3 dk4δ(k2 − m2)θ(k0) ︸ ︷︷ ︸ measure (a(k)e−i(kx) + a†(k)ei(kx)) where we can rewrite the measure as follows dk4δ(k2 − m2)θ(k0)= dk4δ(k2 0 −⃗k2 − m2 ︸ ︷︷ ︸ ≡−ω2 k (deﬁnition) )θ(k0) = dk4δ(k2 0 − ω2 k )θ(k0) = dk4δ((k0 − ωk)(k0 + ωk))θ(k0) =︸︷︷︸ using δ( f (x))=∑i δ(x−ai ) ∣ ∣ ∣ ∣ df dx (ai )∣ ∣ ∣ ∣ where ai denotes the roots, i.e. f (ai)=0, of the function f (x) dk4 1 2k0 (δ(k0 − ωk)+ δ(k0 + ωk))θ(k0) =︸︷︷︸ because the argument of δ(k0+ωk) never becomes zero with k0≥0 dk4 1 2k0 δ(k0 − ωk) = dk3dk0 1 2k0 δ(k0 − ωk) =︸︷︷︸ Integrating over k0 dk3 1 2ωk .(9.79) quantum field theory 231 So ﬁnally the general and physical solution of the Klein-Gordon equation reads Φ(x)= ∫ dk3 1 (2π)32ωk (a(k)e−i(kx) + a†(k)ei(kx)) .(9.80) 10 Classical Mechanics In this chapter we want to explore the connection between quan- tum and classical mechanics. We will see that the time derivative of the expectation value for the momentum operator gives us exactly Newton’s second law, which is one of the foundations of classical mechanics. Starting with the expectation value for an operator (Eq. 8.14) ⟨ ˆO⟩ = ∫ d3xΨ⋆ ˆOΨ and the Schrödinger equation for a particle in an external potential (Eq. 8.23) (i d dt − ∇2 2m )Ψ − VΨ = 0 → i d dt Ψ = ( ∇2 2m + V) ︸ ︷︷ ︸ =:H Ψ → d dt Ψ = 1 i HΨ →︸︷︷︸ Because H†=H d dt Ψ⋆ = − 1 i Ψ⋆ ︸︷︷︸ Here Ψ†=Ψ⋆ H . Taking the time derivative of the expectation value yields d dt ⟨ ˆO⟩ = ∫ d3x (( d dt Ψ⋆) ˆOΨ + Ψ⋆ ( d dt ˆO) Ψ + Ψ⋆ ˆO ( d dt Ψ)) . We use now d dt ˆO = 0, which is true for most operators. For example, for ˆO = ˆ⃗p = −i⃗∇ ̸= ˆO(t). In addition, we use the Schrödinger equation to rewrite the time derivatives of the wave function and its © Springer International Publishing AG 2018 J. Schwichtenberg, Physics from Symmetry, Undergraduate Lecture Notes in Physics, https://doi.org/10.1007/978-3-319-66631-0_10 234 physics from symmetry complex conjugate. This yields d dt ⟨ ˆO⟩ = ∫ d3x ((− 1 i Ψ⋆ H) ˆOΨ + Ψ⋆ ˆO ( 1 i HΨ)) = 1 i ∫ d3x( − Ψ⋆ H ˆOΨ + Ψ⋆ ˆOHΨ) = 1 i ∫ d3xΨ⋆[ ˆO, H]Ψ = 1 i ⟨[ ˆO, H]⟩,(10.1) which is known as Ehrenfest theorem. If we specify ˆO = ˆp and use H = ˆp2 2m + V,weget d dt ⟨ ˆp⟩ = 1 i ⟨[ ˆp, H]⟩ = 1 i ⟨[ ˆp, ˆp2 2m + V]⟩ = 1 i ⟨[ ˆp, ˆp2 2m ] ︸ ︷︷ ︸ =0 +[ ˆp, V]⟩ = 1 i ⟨[ ˆp, V]⟩ = 1 i ∫ d3xΨ⋆[ ˆp, V]Ψ = 1 i ∫ d3xΨ⋆ ˆpVΨ − 1 i ∫ d3xΨ⋆V ˆpΨ = 1 i ∫ d3xΨ⋆(−i∇)VΨ − 1 i ∫ d3xΨ⋆V(−i∇)Ψ =︸︷︷︸ Product rule − ∫ d3xΨ⋆(∇V)Ψ − ∫ d3xΨ⋆V∇Ψ + ∫ d3xΨ⋆V∇Ψ = − ∫ d3xΨ⋆(∇V)Ψ = ⟨−∇V⟩ = ⟨F⟩.(10.2) In words this means that the time derivative (of the expectation value) of the momentum equals the (expectation value of the) nega- tive gradient of the potential, which is known as force. This is exactly Newton’s second law1. This equation can be used to compute the 1 Recall that we used this equation, without a derivation, to illustrate the conserved quantities following from Noether’s theorem in Section 4.5. Here we deliver the derivation, as promised. trajectories of macroscopic objects. Historically the force laws were deduced phenomenologically from experiments. All forces acting on an object were added linearly on the right-hand side of the equation. By using the phenomenologically deduced momentum pmak = mv, we can write the left-hand side as d dt pmak = d dt mv, which equals for an object with constant mass m d dt v. The velocity is the time-derivative of the location2 and we therefore have 2 In other words, the velocity v = d dt x(t)= ˙x(t) is the change-rate of the position of the object and equally the acceleration a d dt d dt x(t)= d dt v = ¨x(t) is the change-rate of the velocity. m d2 dt2 x = F1 + F2 + ... (10.3) classical mechanics 235 This is the differential equation one must solve for x = x(t) to get the trajectory of the object in question. An example for such a classical force will be derived in the next chapter. 10.1 Relativistic Mechanics Using the Lagrangian formalism, we can look at classical mechanics from quite a different perspective. We need an equation that de- scribes the motion of individual particles. As always in this book, we assume that we can derive the correct equation if we minimize something. We already discussed at the beginning of Chapter 4 that this something must be invariant under all Lorentz transformations, because otherwise we don’t get the same equations of motion in all frames of reference. Luckily, we already know something that is invariant under all Lorentz transformations: the invariant of special relativity, which was derived in Section 2.1: (ds)2 =(cdτ)2 =(cdt)2 − (dx)2 − (dy)2 − (dz)2,(10.4) where τ is the proper time as explained in Section 2.2. Equally the square root of this is invariant and therefore the simplest possible thing we can minimize is S = ∫ Cdτ (10.5) with some constant C and dτ = 1 c √(cdt)2 − (dx)2 − (dy)2 − (dz)2 .(10.6) The correct constant turns out to be C = −mc2 and therefore we need to minimize S = −mc2 ∫ dτ.(10.7) For brevity we will restrict the following discussion to one dimen- sion. Then we can write dτ = 1 c √(cdt)2 − (dx)2 = 1 c √ (cdt)2 (1 − (dx)2 c2(dt)2 ) = 1 c (cdt) √ 1 − 1 c2 ( dx dt )2 =︸︷︷︸ dx dt = ˙x is the velocity of the particle in question dt √ 1 − ˙x2 c2 .(10.8) 236 physics from symmetry Putting this into Eq. 10.7 yields S = ∫ −mc2√ 1 − ˙x2 c2 ︸ ︷︷ ︸ ≡L dt.(10.9) As always, we can ﬁnd the extremal action by putting the Lagrangian into the Euler-Lagrange equation (Eq. 4.7): 0 = ∂L ∂x − d dt ( ∂L ∂ ˙x ) → 0 = ∂ ∂x ( −mc2√ 1 − ˙x2 c2 ) ︸ ︷︷ ︸ =0 − d dt ( ∂ ∂ ˙x ( −mc2√ 1 − ˙x2 c2 )) → 0 = c2 d dt ⎛ ⎝ −m ˙x c2 √1 − ˙x2 c2 ⎞ ⎠ → 0 = d dt ⎛ ⎝ m ˙x √1 − ˙x2 c2 ⎞ ⎠ .(10.10) This is the correct relativistic equation for a free particle. If the par- ticle moves in an external potential V(x), we must simply add this potential to the Lagrangian33 We add −V(x) instead of V(x), because then we get in the formula for the total energy of the system, which we can compute using Noether’s theorem, the potential energy term +V(x). L = −mc2√ 1 − ( ˙x)2 c2 − V(x) .(10.11) For this Lagrangian the Euler-Lagrange equation yields d dt ⎛ ⎝ m ˙x √1 − ˙x2 c2 ⎞ ⎠ = − dV dx ≡ F.(10.12) Take note that in the non-relativistic limit ( ˙x ≪ c)wehave √1 − ( ˙x)2 c2 ≈ 1 and the equation is exactly the equation of motion we derived in the last section (Eq. 10.3). 10.2 The Lagrangian of Non-Relativistic Mechanics It is instructive to have a look at the non-relativistic limit of the Lagrangian we derived in the last section (Eq. 10.9). The \"non- relativistic limit\" means, we consider a situation where the particle moves slowly compared with the speed of light: ˙x ≪ c. We can then use the Taylor formula for the Lagrangian44 See Appendix B.3 classical mechanics 237 −mc2√ 1 − ˙x2 c2 = −mc2 (1 − 1 2 ˙x2 c2 + ...) .(10.13) In the limit ˙x ≪ c we can neglect higher order terms and the La- grangian reads L = −mc2 + 1 2 m ˙x2 − V(x) .(10.14) We already know that a constant like −mc2 has no inﬂuence on the equation of motion and therefore the Lagrangian for non-relativistic mechanics reads L = 1 2 m ˙x2 − V(x).(10.15) Without the external potential, i.e. V(x)= 0, this is exactly the Lagrangian we used in section 4.5.1 to illustrate the conserved quan- tities that follow from Noether’s theorem. Putting this Lagrangian into the Euler-Lagrange equation (Eq. 4.7) yields ∂L ∂x − d dt ( ∂L ∂ ˙x ) = 0 → ∂ ∂x ( 1 2 m ˙x2 − V(x)) − d dt ( ∂ ∂ ˙x ( 1 2 m ˙x2 − V(x))) = 0 →− ∂ ∂x V(x) − d dt m ˙x = 0 → d dt m ˙x = − ∂ ∂x V(x) (10.16) This is once more exactly the equation of motion we derived at the beginning of this chapter (Eq. 10.3). 11 Electrodynamics We already derived in Chapter 7 one of the most important equations of classical electrodynamics: the inhomogeneous Maxwell equations (Eq. 7.22) ∂σ(∂σ Aρ − ∂ρ Aσ)= Jρ (11.1) or in a more compact form using the electromagnetic tensor1 1 Fσρ ≡ (∂σ Aρ − ∂ρ Aσ) ∂σ Fσρ = Jρ.(11.2) We discovered in Section 7.1.6 that Jρ is a Noether current, i.e. ∂ρ Jρ = 0. In a macroscopic theory this conserved current is the electric four- current. The tensor Fσρ is antisymmetric Fσρ = −Fρσ , which can be seen directly from the deﬁnition Fσρ = ∂σ Aρ − ∂ρ Aσ , and has therefore 6 independent components. Three are Fi0 = ∂i A0 − ∂0 Ai (11.3) with i = 1, 2, 3 and the three other are Fij = ∂i Aj − ∂j Ai =(δi l δj m − δi mδj l )∂l Am =︸︷︷︸ This is a standard relation for the multiplication of two ϵ with one coinciding index ϵijkϵklm∂l Am .(11.4) The standard way to label these components is ∂i A0 − ∂0 Ai ≡ Ei (11.5) ϵijk∂j Ak ≡−Bi (11.6) and therefore Fi0 = Ei (11.7) Fij = ϵijkϵklm∂l Am = −ϵijkBk .(11.8) If we now rewrite the inhomogeneous Maxwell equations2 as 2 Plural because we have one equation for each component ρ. © Springer International Publishing AG 2018 J. Schwichtenberg, Physics from Symmetry, Undergraduate Lecture Notes in Physics, https://doi.org/10.1007/978-3-319-66631-0_11 240 physics from symmetry ∂σ Fρσ = ∂0Fρ0 − ∂k Fρk = Jρ (11.9) we have for the three spatial components3 (ρ → i) 3 ∇× ⃗B is ϵikl ∂k Bl in vector notation and commonly called cross product. ∂0Fi0 − ∂k Fik = ∂0Ei + ϵikl∂kBl = Ji → ∂t⃗E + ∇× ⃗B = ⃗J (11.10) and for the time-component (ρ → 0) ∂0 F00 ︸︷︷︸ =0 see the deﬁnition of Fρσ −∂k F0k Because Fμν=−Fνμ ︷︸︸︷ = ∂k Fk0 =︸︷︷︸ Eq. 11.7 ∂kEk = J0 →∇⃗E = J0 .(11.11) This is the form of the inhomogeneous Maxwell equations that, for example, engineers use. 11.1 The Homogeneous Maxwell Equations It follows directly from the deﬁnition of the electromagnetic tensor Fμν that if we multiply it with something totally antisymmetric44 ϵμνρσ is the four-dimensional Levi- Civita symbol, which is deﬁned in Appendix B.5.5. ˜Fμν = ϵμνρσ Fρσ (11.12) the derivative ∂μ of this new object ˜Fμν, which is called the dual electromagnetic tensor, vanishes: ∂μ ˜Fμν = ∂μϵμνρσ(∂σ Aρ − ∂ρ Aσ)= 0. (11.13) This follows from the fact that if we contract two symmetric indices with two antisymmetric indices, the result is always zero5. This can 5 This is explained in Appendix B.5.4. be seen, focussing for brevity on the ﬁrst term, as follows ϵμνρσ∂μ∂σ Aρ = 1 2 (ϵμνρσ∂μ∂σ Aρ + ϵμνρσ∂μ∂σ Aρ) =︸︷︷︸ Renaming dummy indices 1 2 (ϵμνρσ∂μ∂σ Aρ + ϵσνρμ∂σ∂μ Aρ) =︸︷︷︸ Because ϵμνρσ=−ϵσνρμ and ∂μ∂σ=∂σ∂μ 1 2 (ϵμνρσ∂μ∂σ Aρ − ϵμνρσ∂μ∂σ Aρ)= 0 ✓ (11.14) Equally the second term is zero. The equations66 Plural because we have one equation for each component v = 0, 1, 2, 3. ∂μ ˜Fμν = 0(11.15) are known as homogeneous Maxwell equations and we can see that they are a direct consequence of the deﬁnition of Fμν. In order to electrodynamics 241 rewrite this in terms of B and E, we take a look at the component ν = 0: 0 = ∂μ ˜Fμ0 = ∂μϵμ0ρσ Fρσ = ∂0 ϵ00ρσ ︸ ︷︷ ︸ =0 Fρσ + ∂iϵi0ρσ Fρσ =︸︷︷︸ Because ϵi0ρσ=0 for ρ=0or σ=0 ∂iϵi0jk Fjk = −∂iϵ0ijk Fjk =︸︷︷︸ See Eq. 11.8 ∂i ϵ0ijkϵljk ︸ ︷︷ ︸ =2δil Bl = 2∂iδil Bl = 2∂iBi ⇒ ∂iBi = 0 or in vector notation ∇⃗B = 0(11.16) Analogously, we can take a look at the components ν = i and derive ∇× ⃗E + ∂t⃗B = 0(11.17) This is the conventional form of the homogeneous Maxwell equations that is used in practical applications. 11.2 The Lorentz Force We can use the connection between quantum and classical mechan- ics that we discovered in the last chapter (the Ehrenfest theorem), to derive the famous Lorentz force law. The starting point is the equa- tion describing a non-relativistic particle, without spin, in an external electromagnetic ﬁeld, i.e. the Schrödinger equation with coupling to an external electromagnetic ﬁeld7 (Eq. 8.24): 7 This equation can be derived from the Klein Gordon equation with coupling to an external electromagnetic ﬁeld, which we derived from the Lagrangian describing spin 0 particles which are coupled to a massless spin 1 ﬁeld, i.e. the photon ﬁeld. Therefore, the real starting point is once more Lorentz and gauge symmetry, which we used to derive the corresponding Lagrangian. We use here the notation A0 ≡ Φ. i∂tΨ = ( 1 2m (⃗p − q ⃗A)2 + qΦ) ︸ ︷︷ ︸ ≡H Ψ.(11.18) If we deﬁne the momentum8 of this system as ⃗Π = ⃗p − q ⃗A,wecan 8 This is actually the momentum of the system following from invariance under translations using the Noether theorem ∂L ∂ ˙x = Π. write the Hamiltonian: H = 1 2m ⃗Π2 + qΦ .(11.19) Having deﬁned the Hamiltonian H we are able to follow the exact same steps described in the last section and arrive at Eq. 10.1. But 242 physics from symmetry this time we can’t neglect the partial time-derivative term, because the operator we are going to look at is time dependent: d dt ⟨ ˆO⟩ = 1 i ⟨[O, H]⟩ + ⟨ ∂O ∂t ⟩ → d dt ⟨⃗Π⟩ = 1 i ⟨[⃗Π, H]⟩ + ⟨ ∂⃗Π ∂t ⟩ . We can see that ∂⃗Π ∂t ̸= 0 because A can change with time. If we now put the explicit form of H (Eq. 11.19) into the equation, we get → d dt ⟨⃗Π⟩ = 1 i ⟨[⃗Π, 1 2m ⃗Π2 + qΦ]⟩ + ⟨ ∂⃗Π ∂t ⟩ → d dt ⟨⃗Π⟩ = 1 i ⟨[⃗Π, 1 2m ⃗Π2]⟩ + 1 i ⟨[⃗Π, qΦ]⟩ ︸ ︷︷ ︸ =⟨q∇Φ⟩ +⟨ ∂⃗Π ∂t ⟩. In the last step we use that [⃗Π, qΦ] can be computed analogous to [ ˆp, V], which we considered in the last chapter, because [A, Φ]= 0. The next task is to compute [(⃗Π)2, ⃗Π], which is non-trivial, because the components Πi do not commute. Instead, we have [Πi, Πj]= − q i ( ∂Aj ∂xi − ∂Ai ∂xj ) = − q i ϵijk Bk︸︷︷︸ =ϵklm ∂ ∂xl Am (11.20) with the usual deﬁnition of the magnetic ﬁeld B = ∇× A written in index form. If we now deﬁne the speed9 of our particle as ⃗v ≡ ⃗Π m we 9 The momentum divided by the mass of the particle: p = mv arrive at 1 2m [⃗Π2, ⃗Π]= q 2i (v × B − B × v)= q i (⃗v × ⃗B) Then we can write the classical equation of motion as d dt ⟨⃗Π⟩ = ⟨q∇Φ⟩−⟨q(v × B)⟩ + ⟨ ∂⃗Π ∂t ⟩ ︸ ︷︷ ︸ =−q ∂ ⃗A ∂t d dt ⟨⃗Π⟩ = −q⟨(v × B)⟩ + q ⟨∇Φ − ∂ ⃗A ∂t ⟩ ︸ ︷︷ ︸ =⟨E⟩ see Eq. 11.5 . We ﬁnally get d dt ⟨⃗Π⟩≡ FLorentz = −q(⟨(v × B)⟩ + ⟨E⟩).(11.21) This is the equation of motion that describes the classical trajectory of a particle in an external electromagnetic ﬁeld. electrodynamics 243 11.3 Coulomb Potential We learned in Chapter 7 that our Lagrangians are invariant under internal transformations. We can use this freedom to simplify com- putations, i.e. we transform the ﬁeld in question with an internal transformation such that the computation becomes especially simple. This is allowed because the physics we describe with the ﬁeld and the transformed ﬁeld are the same, as long as we stick to the gauge transformations that leave the Lagrangian invariant. An often used choice is gauging the photon ﬁeld Aμ such that10 ∂μ Aμ = 0. This is 10 It can be shown explicitly that there is such a gauge choice. Further details can be found in the standard textbooks about electrodynamics. called the Lorenz gauge. Using this gauge simpliﬁes the inhomoge- neous Maxwell equations to ∂σ(∂σ Aρ − ∂ρ Aσ)= ∂σ∂σ Aρ = Jρ (11.22) We now have a look at the physical situation where a ﬁxed, static charge is located in a spherically symmetric region around the origin of our coordinate system. We want to describe physics in the outside region, which means in the region without a source in it, i.e. Jρ = 0. Therefore the Maxwell equations are in this region ∂σ∂σ Aρ = ∂0∂0 Aρ − ∂i∂i Aρ = 0. (11.23) We now use that we are considering a static (∂0 Aρ = 0), spherically symmetric system, by rewriting the equation using spherical coordi- nates11. Then we can neglect all terms12 but the term involving the ∂r 11 Instead of using x, y, z to deter- mine the position of some objects, it’s possible to use two angels θ, φ and the distance from the origin r. Then we have ∂i∂i Aρ = ∂2 ∂r2 (rAρ)+ 1 r2 sin θ ∂ ∂θ (sin θ ∂Aρ ∂θ ) + 1 r2 sin2 θ ∂2 Aρ ∂φ2 . This is especially useful when considering spherically symmetric systems, because these do only depend on r. 12 For a spherically symmetric ﬁeld, we have ∂θ A = ∂φ A = 0. derivative. This yields → ∂2 ∂r2 (rAμ)= 0. (11.24) The general solution of this equation is Aμ = ϵμ C r + ϵμD (11.25) with some constant four-vector ϵμ and constants C and D. The ﬁeld Aμ must vanish at inﬁnity and therefore D = 0. For the zeroth com- ponent13 of Aμ this is the famous Coulomb potential 13 In a lengthy computation using symmetry considerations it can be shown that all other components vanish.A0 = Φ = C r = Ze r ,(11.26) where Z is an integer and e the electric charge of an electron. The reason for writing the constant C like this is that the electric charge is quantized in terms of multiples of the electron charge. In the stan- dard model there is no satisfying explanation for this curious fact of nature. 244 physics from symmetry Further Reading Tips • Richard P. Feynman - The Feynman Lectures on Physics Volume 214 is a great book to start learning electrodynamics. 14 Richard P. Feynman, Robert B. Leighton, and Matthew Sands. The Feynman Lectures on Physics: Volume 2. Addison-Wesley, 1st edition, 2 1977. ISBN 9780201021172 • David J. Grifﬁths - Introduction to Electrodynamics15 is another 15 David J. Grifﬁths. Introduction to Electrodynamics. Addison-Wesley, 4th edition, 10 2012. ISBN 9780321856562 great book to learn more about the concepts of electrodynamics. 12 Gravity Unfortunately, the best theory of gravity we have does not ﬁt into the pic- ture outlined in the rest of this book. This is one of the biggest problems of modern physics and the following paragraphs try to give you a ﬁrst impres- sion. The modern theory of gravity is Einstein’s general relativity. The fundamental idea is that gravity is a result of the curvature of spacetime. Mass and energy change the curvature of spacetime and in turn the changed curvature inﬂuences the movement of mass and energy. This interplay between energy and curvature is described by the famous Einstein equation Gμν = 8πGTμν.(12.1) On the left-hand side is the Einstein tensor Gμν, which describes the curvature and on the right-hand side is the energy-momentum tensor1 Tμν. G is the gravitation constant. 1 Recall that the energy-momentum tensor is the quantity which is directly related to translational symmetry (Eq. 4.36). From the idea gravity = curvature of spacetime, the derivation of the Einstein equation is, from a modern point of view, relatively straightforward2. Firstly, one of the most important laws of physics 2 Einstein needed 100 years ago ca. 6 years for the derivation of the correct equation. Today, with the power of hindsight we are much faster. is the conservation of energy and momentum, which as we saw, follows directly when considering a homogeneous spacetime. In a homogeneous spacetime the laws of physics are invariant under translations in space and time and using Noether’s theorem, we can derive the conservation of momentum and energy. Therefore, one of the most basic assumptions of physics is that spacetime is homogeneous and therefore energy and momentum are conserved. In mathematical terms this conservation law is expressed as (Eq. 4.36) ∂μTμν = 0. (12.2) © Springer International Publishing AG 2018 J. Schwichtenberg, Physics from Symmetry, Undergraduate Lecture Notes in Physics, https://doi.org/10.1007/978-3-319-66631-0_12 246 physics from symmetry Next we need something to describe curvature mathematically. This is what makes general relativity computationally very demand- ing. Nevertheless, we already know the most important object: the metric. Recall that metrics are the mathematical objects that enable us to compute the distance between two points3. In a curved space 3 Up to this point we only con- sidered the Minkowski metric ημν = ⎛ ⎜ ⎜ ⎝ 1 000 0 −10 0 00 −10 00 0 −1 ⎞ ⎟ ⎟ ⎠ and the Euclidean metric δij = ⎛ ⎝100 010 001 ⎞ ⎠ the distance between two points is different than in a ﬂat space as illustrated in Fig. 12.1. Therefore metrics will play a very important role when thinking about curvature in mathematical terms. Fig. 12.1: Distance between two points in a curved and a ﬂat space Having talked about this, we are ready to \"derive\" the Einstein equation, because it turns out that there is exactly one mathematical object that we can put on the left-hand side: the Einstein tensor Gμν. The Einstein tensor is the only divergence-free4 function of the metric 4 ∂μGμν = 0 gμν and at most its ﬁrst and second partial derivative. Therefore, the Einstein tensor may be very complicated, but it’s the only object we are allowed to write on the left-hand side describing curvature. This follows, because we can conclude from Tμν = CGμν that ∂μTμν = 0 → ∂μGμν = 0(12.3) must hold, too. The Einstein tensor is a second rank tensor5 and has 5 This means two indices μν, which is a requirement, because Tμν on the right-hand side has two indices, too. exactly this property. The Einstein tensor is deﬁned as a sum of the Ricci Tensor Rμν and the trace of the Ricci tensor, called Ricci scalar R = Rν ν Gμν = Rμν − 1 2 Rgμν (12.4) where the Ricci Tensor Rμν is deﬁned in terms of the Christoffel symbols Γμ νρ Rαβ = ∂ρΓρ βα − ∂βΓρ ρα + Γρ ρλΓλ βα − Γρ βλΓλ ρα (12.5) and the Christoffel Symbols are deﬁned in terms of the metric Γαβρ = 1 2 ( ∂gαβ ∂xρ + ∂gαρ ∂xβ − ∂gβρ ∂xα ) = 1 2 (∂ρgαβ + ∂βgαρ − ∂αgβρ) . (12.6) This can be quite intimidating and shows why computations in gen- eral relativity very often need massive computational efforts. Next we need to know how things react to such a curved space- time. What’s the path of an object from A to B in curved spacetime? The ﬁrst guess is the correct one: An object follows the shortest path between two points in curved spacetime. We can start with a given distribution of energy and mass, which means some Tμν, compute the metric or Christoffel symbols with the Einstein equation and then get gravity 247 the trajectory through the geodesic equation d2xλ dt2 + Γλ μν dxμ dt dxν dt = 0. (12.7) The geodesic is the locally shortest6 curve between two points on a 6 This is a bit oversimpliﬁed, but the correct deﬁnition needs some terms from differential geometry we haven’t introduced here. manifold. It is interesting to note that Einstein thought about the Christoffel Symbols as the gravitational ﬁeld If the Γμ νρ vanish, then the point moves uniformly in a straight line. These quantities therefore condition the deviation of the motion from uniformity. They are the components of the gravitational ﬁeld. - Albert Einstein7 7 Albert Einstein. The foundation of the general theory of relativity. 1916 We can understand what Einstein means by looking at Eq. 12.7. For Γμ νρ = 0 the geodesic equation reduces to d2xλ dt2 = 0. (12.8) The solutions of this equation describe a straight line. Fig. 12.2: In order to be able to compare the red arrow with the black arrow, we transport the black arrow to the location of the red arrow. Another interesting aspect of a curved spacetime is that the notion of differentiation changes. Remember how the derivative is deﬁned in ﬂat space using the difference quotient f ′(a)= lim h→0 f (a + h) − f (a) h .(12.9) This deﬁnition requires that we compare the function in question at two different points. In a curved space this comparison is not as trivial as in the ﬂat space. Take a look at Fig. 12.2. If we want to compare two vectors on a sphere, how can we make sure that the vectors are really different and the difference is not just an effect of the curved space? The answer of differential geometry is parallel transport. We have to move one vector to the location of the other one, to be able to compare them8. 8 In fact in differential geometry one has only local coordinate systems. The deﬁning feature of a manifold is that it looks locally ﬂat=Euclidean. This was discussed in Section 3.11. Therefore, the coefﬁcients we use to describe the objects in questions are only valid in a small region of the manifold and thus we can only compare coefﬁcients of the same coordinate system. The derivative becomes in a curved space the covariant deriva- tive9 9 In this context the Christoffel symbols Γa bc are often called connection coef- ﬁcients, because of their property to connect the points we want to compare. Dbva ≡ ∂bva + Γabcvc.(12.10) Therefore, if we want any equation we derived so far to be valid in curved spacetime, we need to change ∂b → Db = ∂b + Γabc.(12.11) 248 physics from symmetry Does this look familiar? Take a look again at Eq. 7.18. We learned in an earlier chapter that a locally U(1) invariant Lagrangian for spin 0 or spin 1 2 ﬁelds required a speciﬁc coupling with a spin 1 ﬁeld. This speciﬁc coupling can be summarized by the prescription ∂μ → Dμ ≡ ∂μ + ieAμ.(12.12) Remember that this wasn’t just a mathematical gimmick. This pre- scription gives us the correct theory of electromagnetism. The same is true for weak ∂μ → Dμ ≡ ∂μ − ig Wμ ︸︷︷︸ =Wi μσi (12.13) and strong interactions (see Eq. 7.165) ∂μ → Dμ = ∂μ − ig′ Gμ ︸︷︷︸ =TC GC μ .(12.14) Although things look quite similar here, there is for many reasons no formulation of gravity that is compatible with the quantum descrip- tion of all other forces. All other forces are described in a quantum theory and one can only make probability predictions. In contrast, general relativity is a classical theory, because particles follow de- ﬁned trajectories and there is no need for probability predictions. To make things worse, at the current time no experiment can shine any light on the interplay between those forces. The effects of gravity on elementary particles is too weak to be measured. Because of this, the standard model, which ignores gravity entirely and only takes the weak, the strong and the electromagnetic interactions into ac- count, works very well. The effects of general relativity only become measurable with very heavy objects. For such quantum effects play no role, because massive objects consist of many, many elementary particles and all quantum effects get averaged out. We discovered in Chapter 10 that the equation of motion for the average value is just the classical one and no quantum effects are measurable. One can make a long list of things that make constructing a quantum theory of gravity so difﬁcult, but Einstein formulated the difference between gravity and all other forces very concisely: ...according to the general theory of relativity, gravitation occupies an exceptional position with regard to other forces, particularly the electromagnetic forces, since the ten functions representing the gravita- tional ﬁeld at the same time deﬁne the metrical properties of the space measured. - Albert Einstein1010 Albert Einstein and Francis A. Davis. The Principle of Relativity. Dover Publi- cations, reprint edition, 6 1952. ISBN 9780486600819 gravity 249 We are able do describe quantum particles in a curved space, by changing the derivative to the covariant derivative. But this is of course no dynamical theory of gravity. We could make the right- hand side of the Einstein equation quantum, if we make the usual identiﬁcation with the corresponding generator, but what about the left-hand side? The Einstein tensor in terms of the Christoffel Symbols is Gαβ =(δγ α δζ β − 1 2 gαβgγζ )(∂ϵΓϵ γζ − ∂ζ Γϵ γϵ + Γϵ ϵσΓσ γζ − Γϵ ζσΓσ ϵγ).(12.15) Thus maybe we can think of the Einstein equation as the ﬁeld equa- tion11 for Γϵ ζσ, and the terms generated by the prescription 11 Analogous to the Maxwell equation for the electromagnetic ﬁeld. ∂b → Db = ∂b + Γabc as the corresponding coupling between the gravitational ﬁeld Γϵ ζσ and the other ﬁelds? Regardless of if you prefer to think of the metric or the Christof- fel symbols as the gravitational ﬁeld, the two or three vector indices indicate that we may need to investigate the (1, 1) or even higher representations, which we would call consequently spin 2, 3, . . . rep- resentation of the Poincaré group. In fact most physicists believe that the boson responsible for gravitational attraction, the graviton, has spin 2. Until the present day, there is no working12 theory of quantum 12 Many attempts result in an inﬁnite number of inﬁnity terms, which is quite bad for probability predictions. gravity and for further information have a look at the books men- tioned in the next section. Further Reading Tips For more information about the standard theory of gravity, Einstein’s general relativity, see • Ta-Pei Cheng - Relativity, Gravitation and Cosmology13 is a 13 Ta-Pei Cheng. Relativity, Gravitation and Cosmology: A Basic Introduction. Oxford University Press, 2nd edition, 1 2010. ISBN 9780199573646 great, rather low-level introduction to general relativity with many very enlightening explanations. Perfect to get a quick overview. • A. Zee - Einstein Gravity in a Nutshell14, is the best book to learn 14 Anthony Zee. Einstein Gravity in a Nutshell. Princeton University Press, 1st edition, 5 2013. ISBN 9780691145587 about general relativity. It really starts at the beginning, avoids unnecessary, confusing mathematical tools and does a great job explaining the origin and usage of general relativity. • Charles W. Misner, Kip S. Thorne, John Archibald Wheeler - Gravitation15 is a really, really big book, but often offers in depth 15 Charles W. Misner, Kip S. Thorne, and John Archibald Wheeler. Gravitation.W. H. Freeman, 1st edition, 9 1973. ISBN 9780716703440 explanations for points that remain unclear in most other books. 250 physics from symmetry For more information about attempts to quantize gravity have a look at • Lee Smolin -Three Roads to Quantum Gravity16, which is bril- 16 Lee Smolin. Three Roads to Quantum Gravity. Basic Books, 3 edition, 8 2017. ISBN 9780465094547 liant popular science book that summarizes the various attempts to quantize gravity. • John C. Baez, Javier P. Muniain - Gauge Fields, Knots, and Gravity17 which is a magniﬁcent book. The focus lies on intro- 17 John C. Baez and Javier P. Muniain. Gauge Fields, Knots, and Gravity. World Scientiﬁc Pub Co Inc, 1st edition, 9 1994. ISBN 9789810220341 ducing the mathematical tools needed to understand attempts to quantize gravity in a way that physicists understand. 13 Closing Words In my humble opinion we are a long way from a theory that is able to explain all the things that we would like. Even the beautiful theory we developed in the major part of this book still has many loose ends that need clariﬁcation. In addition, we still have no clue how to derive the correct quantum theory of gravity as discussed in the last chapter. Besides that there is experimental evidence, mostly from cosmol- ogy and astroparticle physics (Dark Matter and Dark Energy), which indicates that the present theories are not the end of the story. I personally think there is still much to come and maybe a com- pletely new framework is needed to overcome the present obstacles. Anyway, the future developments will be very interesting and I hope you will continue following the story and maybe contribute some- thing yourself. © Springer International Publishing AG 2018 J. Schwichtenberg, Physics from Symmetry, Undergraduate Lecture Notes in Physics, https://doi.org/10.1007/978-3-319-66631-0_13 Part V Appendices A Vector calculus It is often useful in physics to describe the position of some object using three numbers ⎛ ⎜ ⎝x y z ⎞ ⎟ ⎠. This is what we call a vector ⃗v and de- note by a little arrow above the letter. The three numbers are the components of the vector along the three coordinate axes. The ﬁrst number tells us how far the vector in question goes in the x-direction, the second how far in the y-direction and the third how far in the z-direction. For example, ⃗w = ⎛ ⎜ ⎝0 4 0 ⎞ ⎟ ⎠ is a vector that points exclusively in the y-direction. Vectors can be added ⃗v = ⎛ ⎜ ⎝vx vy vz ⎞ ⎟ ⎠ ⃗w = ⎛ ⎜ ⎝wx wy wz ⎞ ⎟ ⎠ → ⃗v + ⃗w = ⎛ ⎜ ⎝vx + wx vy + wy vz + wy ⎞ ⎟ ⎠ (A.1) and multiplied ⃗v · ⃗w = ⎛ ⎜ ⎝vx vy vz ⎞ ⎟ ⎠ · ⎛ ⎜ ⎝wx wy wz ⎞ ⎟ ⎠ = vxwx + vywy + vzwz. (A.2) The result of this multiplication is not a vector, but a number (= a scalar), hence the name: scalar product. The scalar product of a vec- tor with itself is directly related to its length: length(⃗v)= √ ⃗v · ⃗v. (A.3) Take note that we can’t simply write three quantities below each other between two brackets and expect it to be a vector. For example, © Springer International Publishing AG 2018 J. Schwichtenberg, Physics from Symmetry, Undergraduate Lecture Notes in Physics, https://doi.org/10.1007/978-3-319-66631-0 256 physics from symmetry let’s say we put the temperature T, the pressure P and the humidity H of a room between two brackets: ⎛ ⎜ ⎝ T P H ⎞ ⎟ ⎠ . (A.4) Nothing prevents us from doing so, but the result would be rather pointless and deﬁnitely not a vector, because there is no linear con- nection between these quantities that could lead to the mixing of these quantities. In contrast, the three position coordinates transform into each other, for example if we look at the vector from a different perspective1. Therefore writing the coordinates below each other 1 This will be made explicit in a mo- ment. between two big brackets is useful. Another example would be the momentum of some object. Again, the components mix if we look at the object from a different perspective and therefore writing it like the position vector is useful. For the moment let’s say a vector is a quantity that transforms exactly like the position vector ⃗v. This means, if under some trans- formation we have ⃗v → ⃗v′ = M⃗v any quantity that transforms like ⃗w → ⃗w′ = M⃗w is a vector. Examples are the momentum or accelera- tion of some object. We will encounter this idea quite often in physics. If we write quantities below each other between two brackets, they aren’t nec- essarily vectors, but the quantities can transform into each other through some linear operation. This is often expressed by multiplica- tion with a matrix. A.1 Basis Vectors We can make the idea of components along the coordinate axes more general by introducing basis vectors. Basis vectors are linearly inde- pendent2 vectors of length one. In three dimensions we need three 2 A set of vectors {⃗a,⃗b,⃗c} is called linearly independent if the equation c1⃗a + c2⃗b + c3⃗c = 0 is only true for c1 = c2 = c3 = 0. This means that no vector can be written as a linear combination of the other vectors, because if we have c1⃗a + c2⃗b + c3⃗c = 0 for numbers different than zero, we can write c1⃗a + c2⃗b = −c3⃗c. basis vectors and we can write every vector in terms of these basis vectors. An obvious choice is: ⃗e1 = ⎛ ⎜ ⎝1 0 0 ⎞ ⎟ ⎠ , ⃗e2 = ⎛ ⎜ ⎝0 1 0 ⎞ ⎟ ⎠ , ⃗e3 = ⎛ ⎜ ⎝0 0 1 ⎞ ⎟ ⎠ (A.5) vector calculus 257 and an arbitrary three-dimensional vector ⃗v can be expressed in terms of these basis vectors ⃗v = ⎛ ⎜ ⎝v1 v2 v3 ⎞ ⎟ ⎠ = v1⃗e1 + v2⃗e2 + v3⃗e3 = v1 ⎛ ⎜ ⎝1 0 0 ⎞ ⎟ ⎠ + v2 ⎛ ⎜ ⎝0 1 0 ⎞ ⎟ ⎠ + v3 ⎛ ⎜ ⎝0 0 1 ⎞ ⎟ ⎠ . (A.6) The numbers v1, v2, v3 are called the components of ⃗v. Take note that these components depend on the basis vectors. The vector ⃗w we introduced above3 can therefore be written as 3 ⃗w = ⎛ ⎝0 4 0 ⎞ ⎠ ⃗w = 0⃗e1 + 4⃗e2 + 0⃗e3. An equally good choice for the basis vectors would be ˜⃗e1 = 1 √2 ⎛ ⎜ ⎝1 1 0 ⎞ ⎟ ⎠ , ˜⃗e2 = 1 √2 ⎛ ⎜ ⎝ 1 −1 0 ⎞ ⎟ ⎠ , ˜⃗e3 = ⎛ ⎜ ⎝0 0 1 ⎞ ⎟ ⎠ . (A.7) In this basis the vector ⃗w \"looks\" quite different: ⃗w = 2√2 ˜⃗e1 − 2√2 ˜⃗e2 + 0 ˜⃗e3 = 2√2 1 √2 ⎛ ⎜ ⎝1 1 0 ⎞ ⎟ ⎠ − 2√2 1 √2 ⎛ ⎜ ⎝ 1 −1 0 ⎞ ⎟ ⎠ = ⎛ ⎜ ⎝0 4 0 ⎞ ⎟ ⎠ . (A.8) Therefore we can write ⃗w in terms of components with respect to this new basis as ˜⃗w = ⎛ ⎜ ⎝ 2√2 −2√2 0 ⎞ ⎟ ⎠ . This is not a different vector just a different description! To be pre- cise, ˜⃗w is the description of the vector ⃗w in a coordinate system that is rotated relative to the coordinate system we used in the ﬁrst place. A.2 Change of Coordinate Systems The connection between different coordinate systems can be made precise through the use of matrices. Two different coordinate systems can mean that we have two different observers that look at our exper- iment from different perspectives or this can simply mean that one observer decides to use a different set of basis vectors. How are those descriptions related? To avoid complications, let’s assume that the origin of the two coordinate systems coincide and both coordinate systems have the same z-axes. Therefore only the x and y coordinates 258 physics from symmetry are different. Let’s assume further that the position of something important in the experiment is described by the vector ⃗v. If the ﬁrst observer sees the vector ⃗v = ⎛ ⎜ ⎝vx vy vz ⎞ ⎟ ⎠, we can compute how the same vector looks like in the coordinate system of the second observer ⃗v = ⎛ ⎜ ⎝vx′ vy′ vz′ ⎞ ⎟ ⎠ by using the usual trigonometric functions sin(φ),cos(φ) and tan(φ)= sin(φ) cos(φ) , as illustrated in Fig. A.1. Fig. A.1: Illustration of the components of a vector in two different coordinate systems. Details can be found in the text. The relationship between vx and vx′ can be computed using cos(φ)= vx′ vx + a → vx′ =(vx + a) cos(φ) and tan(φ)= a vy → a = vy tan(φ). This yields vx′ = (vx + vy tan(φ)) cos(φ)= (vx + vy sin(φ) cos(φ) ) cos(φ) = vx cos(φ)+ vy sin(φ). Analogously we can use vector calculus 259 cos(φ)= vy vy′ + b → vy′ = vy 1 cos(φ) − b and tan(φ)= b vx′ → b = vx′ tan(φ), which yields using sin2(φ)+ cos2(φ)= 1 vy′ = vy 1 cos(φ) − vx′ tan(φ)= vy 1 cos(φ) − (vx cos(φ)+ vy sin(φ)) sin(φ) cos(φ) = vy sin2(φ)+ cos2(φ) cos(φ) − vx sin(φ) − vy sin2(φ cos(φ) = vy cos(φ) − vx sin(φ) Therefore vy′ = −vx sin(φ)+ vy cos(φ). We can write this using a rotation matrix: ⎛ ⎜ ⎝vx′ vy′ vz′ ⎞ ⎟ ⎠ = Rz(φ)⃗v = ⎛ ⎜ ⎝ cos(φ) sin(φ) 0 − sin(φ) cos(φ) 0 00 1 ⎞ ⎟ ⎠ ⎛ ⎜ ⎝vx vy vz ⎞ ⎟ ⎠ = ⎛ ⎜ ⎝ cos(φ)vx + sin(φ)vy − sin(φ)vx + cos(φ)vy vz ⎞ ⎟ ⎠ . (A.9) We multiply each row of the matrix with the unrotated vector to compute the rotated vector. As already noted above, the component along the z-axis v3 is the same for both observers. The matrix Rz(φ) describes a rotation by the angle φ about the z-axis. A.3 Matrix Multiplication Fig. A.2: Schematic matrix multi- plication. The important thing to keep in mind is row times col- umn. The ﬁrst index denotes the row number, the second the col- umn number. In the example, the red element of the product matrix is c1,2 = a1,1b1,2 + a1,2b2,2 and the blue ele- ment is c3,3 = a3,1b1,3 + a3,2b2,3. In gen- eral ci,j = ai,kbk,j = ai,1b1,j + ai,2b2,j + .... Figure by Olivier Perrin (Bilou Wikimedia Commons) released un- deraCCBY-SA 3.0 licence: http: //creativecommons.org/licenses/ by-sa/3.0/deed.en . URL: http: //commons.wikimedia.org/wiki/File: Matrix_multiplication_diagram_2.svg , Accessed: 28.1.2015 Computations like this are tremendously simpliﬁed through the use of matrices. The rule for Matrix multiplication is always row times column. We can see the scalar product introduced above as a special case of this, if we interpret a vector as a matrix with one column and three rows (a 3 × 1 matrix). The scalar product of two vectors is then ⃗v · ⃗w = ⃗vT ⃗w = (vx vy vz) ⎛ ⎜ ⎝wx wy wz ⎞ ⎟ ⎠ = vxwx + vywy + vzwz, (A.10) where the T denotes transposing, which means that every columns becomes a row and every row a column. Therefore, ⃗vT is a matrix 260 physics from symmetry with 1 row and 3 columns. Written in this way the scalar product is once more a matrix product with row times columns. Analogously, we get the matrix product of two matrices from the multiplication of each row of the matrix to the left with a column of the matrix to the right. This is explained in Fig. A.2. An explicit example for the multiplication of two matrices is M = (23 10 ) N = (01 48 ) MN = (23 10 )(01 48 ) = (2 · 0 + 3 · 42 · 1 + 3 · 8 1 · 0 + 0 · 41 · 1 + 0 · 8 ) = (12 26 01 ) (A.11) The rule to keep in mind is row times column. Take note that the multiplication of two matrices is not commutative, which means in general MN ̸= NM. A.4 Scalars An important thing to notice is that the scalar product of two vectors has the same value for all observers. This can be seen as the deﬁni- tion of a scalar: A scalar is the same for all observers. This does not simply mean that every number is a scalar, because each component of a vector is a number, but as we have seen above a different number for different observers. In contrast the scalar product of two vectors must be the same for all observers. This follows from the fact that the scalar product of a vector with itself is directly related to the length of the vector. Changing the perspective or the location we choose to look at our experiment may not change the length of anything. The length of a vector is called an invariant for rotations, because it stays the same no matter how we rotate our system. A.5 Right-handed and Left-handed Coordinate Systems When we talked above about two observers, we implicitly assumed they agree in terms of the deﬁnition of their coordinate system. In fact, there are two possible choices, which are again related by matrix multiplication, but not by rotations. One observer may choose what we call a right-handed coordinate system and another observer what we call a left-handed coordinate system.Fig. A.3: Right-handed and left-handed coordinate system. Figure by Pri- malshell (Wikimedia Commons) released under a CC-BY-SA-3.0 li- cence: http://creativecommons.org/ licenses/by-sa/3.0/deed.en. URL: http://commons.wikimedia.org/ wiki/File:3D_Cartesian_Coodinate_ Handedness.jpg , Accessed: 1.12.2014 There is no way to rotate a left-handed into a right-handed coordi- nate system. Instead, such coordinate systems are related through a vector calculus 261 reﬂection in a mirror. This means the descriptions in a right-handed and a left-handed coordinate system are related by a transformation of the form ⎛ ⎜ ⎝v1 v2 v3 ⎞ ⎟ ⎠ → ⎛ ⎜ ⎝−v1 −v2 −v3 ⎞ ⎟ ⎠ , (A.12) which means we ﬂip the sign of all spatial coordinates. The conven- tional name for this kind of transformation is parity transformation. We can describe a parity transformation by ⃗v → ⃗v′ = P⃗v = ⎛ ⎜ ⎝−10 0 0 −10 00 −1 ⎞ ⎟ ⎠ ⎛ ⎜ ⎝v1 v2 v3 ⎞ ⎟ ⎠ = ⎛ ⎜ ⎝−v1 −v2 −v3 ⎞ ⎟ ⎠ . (A.13) B Calculus B.1 Product Rule The product rule d( f (x)g(x)) dx = ( df (x) dx )g(x)+ f (x)( dg(x) dx ) ≡ f ′g + fg′ (B.1) follows directly from the deﬁnition of derivatives d dx [ f (x)g(x)] = lim h→0 f (x + h)g(x + h) − f (x)g(x) h = lim h→0 [ f (x + h)g(x + h) − f (x + h)g(x)]+[ f (x + h)g(x) − f (x)g(x)] h = lim h→0 f (x + h) g(x + h) − g(x) h + g(x) f (x + h) − f (x) h = f (x)g′(x)+ g(x) f ′(x) B.2 Integration by Parts A (likely apocryphal) story goes: when Peter Lax was awarded the National Medal of Science, the other recipients (presumably non- mathematicians) asked him what he did to deserve the Medal. Lax responded: \" I integrated by parts.\" - Willie Wong1 1 Told on www.math.stackexchange.com An important rule for integrals follows directly from the product rule. Integrating the product rule2 2 See Eq. B.1 and we then use for the ﬁrst term the fundamental theorem of calculus ∫ b a dx h′(x)= h(b) − h(a). © Springer International Publishing AG 2018 J. Schwichtenberg, Physics from Symmetry, Undergraduate Lecture Notes in Physics, https://doi.org/10.1007/978-3-319-66631-0 264 physics from symmetry ∫ b a dx d( f (x)g(x)) dx ︸ ︷︷ ︸ = f (x)g(x)∣ ∣b a = ∫ b a dx( df (x) dx )g(x)+ ∫ b a dx f (x)( dg(x) dx ) (B.2) and rearranging the terms yields ∫ b a dx( df (x) dx )g(x)= f (x)g(x)∣ ∣ ∣b a − ∫ b a dx f (x)( dg(x) dx ). (B.3) This rule is particularly useful in physics when working with ﬁelds, because if we integrate over all space, i.e. a = −∞,b = ∞, the bound- ary term vanishes f (x)g(x)∣ ∣ ∣b=∞ a=−∞ = 0, because all ﬁelds must vanish at inﬁnity3. 3 This follows, because otherwise the total ﬁeld energy would be inﬁnity and such ﬁeld conﬁgurations are non- physical. B.3 The Taylor Series The Taylor series is a formula that enables us to write any inﬁnitely differentiable function in terms of a power series f (x)= f (a)+(x − a) f ′(a)+ 1 2 (x − a)2 f ′′(a)+ . . . (B.4) • On the one hand we can use it if we want to know how we can write some function in terms of a series. This can be used for example to show that eix = cos(x)+ i sin(x). • On the other hand we can use the Taylor series to get approxi- mations for a function about a point. This is useful when we can neglect for some reasons higher order terms and don’t need to consider inﬁnitely many terms. If we want to evaluate a function f (x) in some neighbouring point of a point y,say y + Δy,wecan write44 Don’t let yourself get confused by the names of our variables here. In the formula above we want to evaluate the function at x by doing computations at a. Here we want to know something about f at y + Δy, by using information at y. To make the connection precise: x = y + Δy and a = y. f (y + Δy)= f (y)+(y + Δy − y) f ′(y)+ ... = f (y)+ Δyf ′(y)+ ... . (B.5) This means we get an approximation for the function value at y + Δy, by evaluating the function at y. In the extreme case of an inﬁnitesimal neighbourhood Δy → ϵ, the change of the function can be written by one (the linear) term of the Taylor series. Δ f = f (y + ϵ) − f (y)= f (y)+ ϵ f ′(y)+ ... − f (y)= ϵ f ′(y)+ ...︸︷︷︸ ≈0 for ϵ2≈0 (B.6) calculus 265 This formula is one of the most useful mathematical tools and we can derive it using the fundamental theorem of calculus and integration by parts. The fundamental theorem tells us ∫ x a dt f ′(t)= f (x) − f (a) → f (x)= f (a)+ ∫ x a dt f ′(t). (B.7) We can rewrite the second term by integrating by parts, because we have of course an implicit 1 in front of f ′(t)= 1 f ′(t), which we can use as a second function in Eq. B.3: g′(t)= 1. The rule for integration by parts tells us that we can rewrite an integral ∫ b a v′u = vu|b a + ∫ vu′ by integrating one term and differentiating the other. Here we integrate g′(t)= 1 and differentiate f ′(t), i.e. in the formula g′ = v′ and f ′ = u. This yields f (x)= f (a)+ ∫ x a dt f ′(t)= f (a)+ g(t) f ′(t)∣ ∣ ∣x a − ∫ x a dt g(t) f ′′(t). (B.8) Now we need to know what g(t) is. At this point the only infor- mation we have is g′(t)= 1, but there are inﬁnitely many functions with this derivative: For any constant c the function g = t + c satisﬁes g′(t)= 1. Our formula becomes particularly useful5 for g = t − x, i.e. 5 The equation holds for arbitrary c and of course you’re free to choose something different, but you won’t get our formula. We choose the constant c such that we get a useful formula for f (x). Otherwise f (x) would appear on the left- and right-hand side. we use minus the upper integration boundary −x as our constant c. Then we have for the second term in the equation above g(t) f ′(t)∣ ∣ ∣x a =(t − x) f ′(t)∣ ∣ ∣x a =(x − x) ︸ ︷︷ ︸ =0 f ′(x) − (a − x) f ′(a)=(x − a) f ′(a) (B.9) and the formula now reads f (x)= f (a)+(x − a) f ′(a)+ ∫ x a dt (x − t) f ′′(t). (B.10) We can then evaluate the last term once more using integration by parts, now with6 v′ =(x − t) and u = f ′′(t): 6 Take note that integrating v′ =(x − t) yields a minus sign: → v = − 1 2 (x − t)2 + d, because our variable here is t and with some constant d we choose to be zero. → ∫ x a dt (x − t) ︸ ︷︷ ︸ =v′ f ′′(t) ︸ ︷︷ ︸ =u = − 1 2 (x − t)2 ︸ ︷︷ ︸ =v f ′′(t) ︸ ︷︷ ︸ =u ∣ ∣ ∣x a − ∫ x a dt ( − 1 2 (x − t)2) ︸ ︷︷ ︸ =v f ′′′(t) ︸ ︷︷ ︸ =u′ where the boundary term is again simple − 1 2 (x − t)2 f ′′(t)∣ ∣ ∣x a = − 1 2 (x − x)2 ︸ ︷︷ ︸ =0 f ′′(x)+ 1 2 (x − a)2 f ′′(a). This gives us the formula f (x)= f (a)+(x − a) f ′(a)+ 1 2 (x − a)2 f ′′(a)+ ∫ x a dt 1 2 (x − t)2 f ′′′(t). (B.11) 266 physics from symmetry We could go on and integrate the last term by parts, but the pattern should be visible by now. The Taylor series can be written in a more compact form using the mathematical sign for a sum ∑: f (x)= ∞ ∑ n=0 f (n)(a)(x − a)n n! = f (0)(a)(x − a)0 0! + f (1)(a)(x − a)1 1! + f (2)(a)(x − a)2 2! + f (3)(a)(x − a)3 3! + . . . , (B.12) where f (n) denotes the n-th derivative of f , e.g. f (2) = f ′′ and n!is the factorial of n, i.e. n! = 1 · 2 · 3 ... n. For example for n = 5wehave 5! = 5 · 4 · 3 · 2 · 1 = 120, 2! = 2 · 1 = 2 and by deﬁnition 0! = 1. Series are the topic of the next section. B.4 Series In the last section we stumbled upon a very important formula that includes an inﬁnite sum. In this section some basic tricks for sum manipulation and some very important series will be introduced. B.4.1 Important Series In the last section we learned that we can write every inﬁnitely differ- entiable function as a series. Let’s start with maybe the most impor- tant function: The exponential function ex. The Taylor series for the exponential function can be written right away ex = ∞ ∑ n=0 xn n! , (B.13) by using the deﬁning feature of the exponential function that the derivative is the exponential function itself: (ex)′ = ex, evaluating the Taylor series about a = 0 and using e0 = 1. This yields the Taylor series (Eq. B.12) for the exponential function: ex = ∞ ∑ n=0 e0(x − 0)n n! = ∞ ∑ n=0 xn n! (B.14) This series can be seen as a deﬁnition of ex. Two other important, inﬁnitely differentiable functions are sin(x) and cos(x). We can compute the Taylor series for these functions, by using (sin(x))′ = cos(x), (cos(x))′ = − sin(x), cos(0)= 1 and calculus 267 sin(0)= 0. sin(x)= ∞ ∑ n=0 sin(n)(0)(x − 0)n n! . Because of sin(0)= 0 every term with even n vanishes, which we can use if we split the sum. Observe that ∞ ∑ n=0 n = ∞ ∑ n=0(2n + 1)+ ∞ ∑ n=0(2n) 1 + 2 + 3 + 4 + 5 + 6. . . = 1 + 3 + 5 + ... + 2 + 4 + 6 + . . . (B.15) Splitting the sum for sin(x) yields sin(x)= ∞ ∑ n=0 sin(2n+1)(0)(x − 0)2n+1 (2n + 1)! + ∞ ∑ n=0 sin(2n)(0)(x − 0)2n (2n)! ︸ ︷︷ ︸ =0 = ∞ ∑ n=0 sin(2n+1)(0)(x − 0)2n+1 (2n + 1)! . (B.16) Every even derivative of sin(x), i.e. sin(2n) is again sin(x) (with pos- sibly a minus sign in front of it) and therefore the second term van- ishes because of sin(0)= 0. Every uneven derivative of sin(x) is cos(x), with possibly a minus sign in front of it. We have sin(x)(1) = cos(x) sin(x)(2) = cos′(x)= − sin(x) sin(x)(3) = − sin′(x)= − cos(x) sin(x)(4) = − cos′(x)= sin(x) sin(x)(5) = sin′(x)= cos(x) . (B.17) The pattern is therefore sin(2n+1)(x)=(−1)n cos(x), as you can check by putting some integer values for n into the formula7. We can 7 sin(1)(x)= sin(2·0+1)(x)= (−1)·0 cos(x)= cos(x), sin(3)(x)= sin(2·1+1)(x)=(−1)1 cos(x)= − cos(x) therefore rewrite Eq. B.16 as sin(x)= ∞ ∑ n=0 sin(2n+1)(0)(x − 0)2n+1 (2n + 1)! = ∞ ∑ n=0 (−1)n cos(0)(x − 0)2n+1 (2n + 1)! =︸︷︷︸ cos(0)=1 ∞ ∑ n=0 (−1)n(x)2n+1 (2n + 1)! . (B.18) 268 physics from symmetry This is the Taylor series for sin(x), which again can be seen as a deﬁ- nition of sin(x). Analogous we can derive cos(x)= ∞ ∑ n=0 (−1)n(x)2n (2n)! , (B.19) because this time uneven derivatives are proportional to sin(0)= 0. B.4.2 Splitting Sums In the last section we used a trick that is quite useful in many compu- tations. There we used the example ∞ ∑ n=0 n = ∞ ∑ n=0(2n + 1)+ ∞ ∑ n=0(2n) 1 + 2 + 3 + 4 + 5 + 6 ... = 1 + 3 + 5 + ... + 2 + 4 + 6 + . . . , (B.20) to motivate how we can split any sum in terms of even and uneven integers. 2n is always an even integer, whereas 2n + 1isalwaysan uneven integer. We already saw in the last section that this can be useful, but let’s look at another example. What happens if we split the exponential series with complex argument ix? eix = ∞ ∑ n=0 (ix)n n! = ∞ ∑ n=0 (ix)2n (2n)! + ∞ ∑ n=0 (ix)2n+1 (2n + 1)! . (B.21) This can be rewritten using that (ix)2n = i2nx2n and i2n =(i2)n = (−1)n. In addition we have of course i2n+1 = i · i2n = i(−1)n. Then we have eix = ∞ ∑ n=0 (ix)n n! = ∞ ∑ n=0 (−1)n(x)2n (2n)! + i ∞ ∑ n=0 (−1)n(x)2n+1 (2n + 1)! = ∞ ∑ n=0 (−1)n(x)2n (2n)! ︸ ︷︷ ︸ =cos(x) see Eq. B.19 +i ∞ ∑ n=0 (−1)n(x)2n+1 (2n + 1)! ︸ ︷︷ ︸ =sin(x) see Eq. B.18 = cos(x)+ i sin(x) . (B.22) This is famously known as Euler’s formula. calculus 269 B.4.3 Einstein’s Sum Convention Sums are very common in physics and writing the big sum sign ∑ all the time can be quite cumbersome. For this reason a clever man introduced a convention, called Einstein sum convention. According to this convention every time an index appears twice in some term, like n in the sums above, an implicit sum is understood. This means anbn ≡ ∑ n anbn. (B.23) Other examples are anbncm ≡ ∑ n anbncm. (B.24) ambncm ≡ ∑ m ambncm. (B.25) but anbm ̸= ∑ n anbm, (B.26) because in general m ̸= n. An index without a partner is called a free index, an index with a partner a dummy index, for reasons that will be explained in the next section. For example in the sum anbncm ≡ ∑n anbncm, the index n is a dummy index, but m is a free index. Equivalently, in ambncm ≡ ∑m ambncm, the index m is a dummy index and n is free. B.5 Index Notation B.5.1 Dummy Indices It is important to take note that the name of indices with a partner plays absolutely no role. Renaming n → k, changes absolutely noth- ing8, as long as n is contracted 8 Of course we can’t change an index into another type of index. For ex- ample, we can change i → j but not i → μ, because Greek indices like μ are always summed from 0 to 3 and Roman indices, like i from1to3. anbncm = akbkcm ≡ ∑ n anbncm ≡ ∑ k akbkcm. (B.27) On the other hand free indices can not be renamed freely. For exam- ple, m → q can make quite a difference because there must be some term on the other side of the equation with the same free index. This means when we look at a term like anbncm isolated, we must always take into account that there might be other terms with the same free index m that must be renamed, too. Let’s look at an example Fi = ϵijkajbk. (B.28) 270 physics from symmetry A new thing that appears here is that some object, here ϵijk,isal- lowed to carry more than one index, but don’t let that bother you, because we will come back to this in a moment. Therefore, if we look at ϵijkajbk we can change the names of j and k as we like, because these indices are contracted. For example j → u, k → z, which yields ϵiuzaubz is really the same. On the other hand i is not a dummy index and we can’t rename it i → m: ϵmuzaubz , because then our equation would read Fi = ϵmuzaubz. (B.29) This may seem pedantic at this point, because it is clear that we need to rename i at Fi, too in order to get something sensible, but more often than not will we look at isolated terms and it is important to know what we are allowed to do without changing anything. B.5.2 Objects with more than One Index Now, let’s talk about objects with more than one index. Objects with two indices are simply matrices. The ﬁrst index tells us which row and the second index which column we should pick our value from. For example Mij ≡ (M11 M12 M21 M22 ) . (B.30) This means for example that M12 is the object in the ﬁrst row in the second column. We can use this to write matrix multiplication using indices. The product of two matrices is MN ≡ (MN)ij = Mik Nkj. (B.31) On the left hand side we have the element in row i in column j of the product matrix (MN), which we get from multiplying the i-th row of M with the j-th column of N. The index k appears twice and therefore an implicit sum is assumed. One can give names to objects with three or more indices (tensors). For the purpose of this book two are enough and we will discuss only one exception, which is the topic of one of the next sections. B.5.3 Symmetric and Antisymmetric Indices A matrix is said to be symmetric if Mij = Mji. This means in our two dimensional example M12 = M21 and an example for a symmetric calculus 271 matrix is (93 317 ) . (B.32) A matrix is called totally antisymmetric if Mij = −Mji for all i, j holds. An example would be. ( 03 −30 ) . (B.33) Take note that the diagonal elements must vanish here, because M11 = −M11, which is only satisﬁed for M11 = 0 and analogously for M22. B.5.4 Antisymmetric × Symmetric Sums An important observation is that every time we have a sum over something symmetric in its indices multiplied with something anti- symmetric in the same indices, the result is zero: ∑ ij aijbij = 0 (B.34) if aij = −aji and bij = bji holds for all i, j. We can see this by writing ∑ ij aijbij = 1 2 ( ∑ ij aijbij + ∑ ij aijbij) (B.35) As explained earlier we are free to rename our dummy indices i → j and j → i, which we use in the second term → ∑ ij aijbij = 1 2 ( ∑ ij aijbij + ∑ ij ajibji) (B.36) Then we use the symmetry of bij and antisymmetry of aij, to switch the indices in the second term, which yields9 9 If this looks like a cheap trick to you, you should compute some explicit examples to see that this is really true. → ∑ ij aijbij = 1 2 ( ∑ ij aijbij + ∑ ij aji ︸︷︷︸ =−aij bji ︸︷︷︸ =bij ) = 1 2 ( ∑ ij aijbij − ∑ ij aijbij) = 0 . (B.37) 272 physics from symmetry B.5.5 Two Important Symbols One of the most important matrices is of course the unit matrix.In two dimensions we have 1 = (10 01 ) . (B.38) In index notation the unit matrix is called the Kronecker symbol, denoted δij, which is then deﬁned for arbitrary dimensions by δij = ⎧ ⎨ ⎩1if i = j, 0if i ̸= j . (B.39) The Kronecker symbol is symmetric because δij = δji. Equally important is the Levi-Civita symbol ϵijk, which is deﬁned in two dimensions as follows: ϵij = ⎧ ⎪⎪⎨ ⎪⎪⎩ 1if (i, j)= {(1, 2)}, 0if i = j , −1if (i, j)= {(2, 1)}. (B.40) In matrix form, we can write it as ϵij = ( 01 −10 ) (B.41) In three dimensions the Levi-Civita symbol is ϵijk = ⎧ ⎪⎪⎨ ⎪⎪⎩ 1if (i, j, k)= {(1, 2, 3), (2, 3, 1), (3, 1, 2)}, 0if i = j or j = k or k = i, −1if (i, j, k)= {(1, 3, 2), (3, 2, 1), (2, 1, 3)}. (B.42) and in four dimensions ϵijkl = ⎧ ⎪⎪⎨ ⎪⎪⎩ 1if (i, j, k, l) is an even permutation of{(1, 2, 3, 4)}, −1if (i, j, k, l) is an uneven permutation of{(1, 2, 3, 4)}, 0 otherwise. (B.43) For example (1, 2, 4, 3) is an uneven (because we make one change) and (2, 1, 4, 3) is an even permutation (because we make two changes) of (1, 2, 3, 4). The Levi-Civita symbol is totally anti-symmetric because if we change two indices, we always get, by deﬁnition, a minus sign: ϵijk = −ϵjik, ϵijk = −ϵikj etc. or in two dimensions ϵij = −ϵji. C Linear Algebra Many computations can be simpliﬁed by using matrices and tricks from the linear algebra toolbox. Therefore, let’s look at some basic transformations. C.1 Basic Transformations The complex conjugate of a matrix is deﬁned as M⋆ ij = (M⋆ 11 M⋆ 12 M⋆ 21 M⋆ 22 ) , (C.1) which means we simply take the complex conjugate of each ele- ment1. 1 Recall that the complex conjugate of a complex number z = a + ib, where a is the real part and b the imaginary part, is simply z⋆ = a − ib. The transpose of a matrix is deﬁned by MT ij = Mji, in matrix form Mij = (M11 M12 M21 M22 ) → MT ij = (M11 M21 M12 M22 ) , (C.2) which means we swap columns and rows of the matrix. An impor- tant consequence of this deﬁnition and the deﬁnition of the prod- uct of two matrices is that we have (MN)T ̸= MT NT. Instead (MN)T = NT MT, which means by transposing we switch the po- sition of two matrices in a product. We can see this directly in index notation MN ≡ (MN)ij = Mik Nkj (MN)T ≡ ((MN)ij)T =(MN)ji =(Mik Nkj)T (Mik Nkj)T = MT ik NT kj = Mki Njk = Njk Mki ≡ NT MT, (C.3) © Springer International Publishing AG 2018 J. Schwichtenberg, Physics from Symmetry, Undergraduate Lecture Notes in Physics, https://doi.org/10.1007/978-3-319-66631-0 274 physics from symmetry where in the last step we use the general rule that in matrix notation we always multiply rows of the left matrix with columns of the right matrix. To write this in matrix notation, we change the position of the two terms to Njk Mki, which is rows of the left matrix times columns of the right matrix, as it should be and we can write in matrix nota- tion NT MT. Take note that in index notation we can always change the position of the objects in question freely, because for example Mki and Njk are just individual elements of the matrices, i.e. ordinary numbers. C.2 Matrix Exponential Function We already derived how the exponential function looks as a series, and therefore we can deﬁne what we mean when we put a matrix into the exponential function: eM, with an arbitrary matrix M, is deﬁned by the series eM = ∞ ∑ n=0 Mn n! . (C.4) It is important to take note that in general eMeN ̸= eM+N. The iden- tity eMeN = eM+N is only correct if MN = NM. C.3 Determinants The determinant of a matrix is a rather unintuitive, but immensely useful notion. For example, if the determinant of some matrix is non-zero, we automatically know that the matrix is invertible2. Un- 2 A matrix M is invertible, if we can ﬁnd an inverse matrix, denoted by M−1, with M−1 M = 1. fortunately proving this lies beyond the scope of this text and the interested reader is referred to the standard texts about linear alge- bra. The determinant of a 3 × 3 matrix can be deﬁned using the Levi- Civita symbol det(A)= 3 ∑ i=1 3 ∑ j=1 3 ∑ k=1 ϵijk A1i A2j A3k (C.5) and analogously for n-dimensions det(A)= n ∑ i1=1 n ∑ i2=1 ... n ∑ in=1 ϵi1i2...in A1i1 A2i2 ... Anin . (C.6) It is instructive to look at an explicit example in two dimensions: linear algebra 275 det(A)= det (31 52 ) =(3 · 2) − (5 · 1)= 1. For a general three dimensional matrix, we have det ⎛ ⎜ ⎝a1 a2 a3 b1 b2 b3 c1 c2 c3 ⎞ ⎟ ⎠ = a1(b2c3 − b3c2) − a2(b1c3 − b3c1)+ a3(b1c2 − b2c1) . (C.7) C.4 Eigenvalues and Eigenvectors Two very important notions from linear algebra that are used all over physics are eigenvalues and eigenvectors. The eigenvectors ⃗v and eigenvalues λ are deﬁned for each matrix M by the equation M⃗v = λ⃗v. (C.8) The important thing is that we have on both sides of the equation the same vector ⃗v. In words this equation means that the vector ⃗v remains, up to a constant λ, unchanged if multiplied with the matrix M. To each eigenvector we have a corresponding eigenvalue. There are quite sophisticated computational schemes for ﬁnding the eigen- vectors and eigenvalues of a matrix and the details can be found in any book about linear algebra. To get a feeling for the importance of these notions think about rotations. We can describe rotations by matrices and the eigenvector of a rotation matrix deﬁnes the rotational axis. C.5 Diagonalization Eigenvectors and eigenvalues can be used to bring matrices into diag- onal form, which can be quite useful for computations and physical interpretations. It can be shown that any diagonalizable matrix M can be rewritten in the form3 3 In general, a transformation of the form M′ = N−1 MN refers to a basis change. M′ is the matrix M in another coordinate system. Therefore, the result of this section is that we can ﬁnd a basis where M is particularly simple, i.e. diagonal. M = N−1DN, (C.9) where the matrix N consists of the eigenvectors as its column and D is diagonal with the eigenvalues of M on its diagonal: (M11 M12 M21 M22 ) = N−1 (λ1 0 0 λ2 ) N = ( ⃗v1,⃗v2)−1 (λ1 0 0 λ2 ) ( ⃗v1,⃗v2) . (C.10) D Additional Mathematical Notions D.1 Fourier Transform The idea of the Fourier transform is similar to the idea that we can express any vector ⃗v in terms of basis vectors1 ( ⃗e1, ⃗e2, ⃗e3). In ordinary 1 This is explained in more detail in Appendix A.1.Euclidean space the most common choice is ⃗e1 = ⎛ ⎜ ⎝1 0 0 ⎞ ⎟ ⎠ , ⃗e2 = ⎛ ⎜ ⎝0 1 0 ⎞ ⎟ ⎠ , ⃗e3 = ⎛ ⎜ ⎝0 0 1 ⎞ ⎟ ⎠ (D.1) and an arbitrary three-dimensional vector ⃗v can be expressed in terms of these basis vectors ⃗v = ⎛ ⎜ ⎝v1 v2 v3 ⎞ ⎟ ⎠ = v1⃗e1 + v2⃗e2 + v3⃗e3 = v1 ⎛ ⎜ ⎝1 0 0 ⎞ ⎟ ⎠ + v2 ⎛ ⎜ ⎝0 1 0 ⎞ ⎟ ⎠ + v3 ⎛ ⎜ ⎝0 0 1 ⎞ ⎟ ⎠ (D.2) The idea of the Fourier transform is that we can do the same thing with functions2. For periodic functions such a basis is given 2 In a more abstract sense, functions are abstract vectors. This is meant in the sense that functions are elements of some vector space. For different kinds of functions a different vector space. Such abstract vector spaces are deﬁned similar to the usual Euclidean vector space, where our ordinary position vectors live (those with the little arrow ⃗ ). For example, take note that we can add two functions, just as we can add two vectors, and get another function. In addition, it’s possible to deﬁne a scalar product. by sin(kx) and cos(kx). This means we can write every periodic func- tion f (x) as f (x)= ∞ ∑ k=0(ak cos(kx)+ bk sin(kx)) (D.3) with constant coefﬁcients ak and bk. An arbitrary (not necessarily periodic) function can be written in terms of the basis eikx and e−ikx, but this time with an integral instead of a sum3 3 Recall that an integral is just the limit of a sum, where the discrete k in ∑k becomes a continuous variable in ∫ dk. © Springer International Publishing AG 2018 J. Schwichtenberg, Physics from Symmetry, Undergraduate Lecture Notes in Physics, https://doi.org/10.1007/978-3-319-66631-0 278 physics from symmetry f (x)= ∫ ∞ 0 dk(akeikx + bke−ikx), (D.4) which we can also write as f (x)= ∫ ∞ −∞ dk fke−ikx. (D.5) The expansion coefﬁcients fk are often denoted ˜f (k), which is then called the Fourier transform of f (x). D.2 Delta Distribution In some sense, the delta distribution is to integrals what the Kro- necker delta4 is to sums. We can use the Kronecker delta δij to pick 4 The Kronecker delta is deﬁned in Appendix B.5.5. one speciﬁc term of any sum. For example, consider 3 ∑ i=1 aibj = a1bj + a2bj + a3bj (D.6) and let’s say we want to pick the second term of the sum. We can do this using the Kronecker delta δ2i, because then 3 ∑ i=1 δ2iaibj = δ21︸︷︷︸ =0 a1bj + δ22︸︷︷︸ =1 a2bj + δ23︸︷︷︸ =0 a3bj = a2bj. (D.7) Or more general 3 ∑ i=1 δikaibj = akbj. (D.8) The delta distribution δ(x − y) is deﬁned as an object that has exactly this property: ∫ dx f (x)δ(x − y)= f (y). (D.9) Completely analogous to the Kronecker delta, the delta distribution picks one term from the integral5. In addition, we can use this anal- 5 The term where x = y. For example,∫ dx f (x)δ(x − 2)= f (2). ogy to motivate from the equality ∂xi ∂xj = δij (D.10) the equality ∂ f (xi) ∂ f (xj) = δ(xi − xj). (D.11) This is of course by no means a proof, but this equality can be shown in a rigorous way, too. There is a lot more one can say about this ob- ject, but for the purpose of this book it is enough to understand what additional mathematical notions 279 the delta distribution does. In fact, this is how the delta distribution was introduced in the ﬁrst place by Dirac. Bibliography John C. Baez and Javier P. Muniain. Gauge Fields, Knots, and Gravity. World Scientiﬁc Pub Co Inc, 1st edition, 9 1994. ISBN 9789810220341. Alessandro Bettini. Introduction to Elementary Particle Physics. Cam- bridge University Press, 2nd edition, 4 2014. ISBN 9781107050402. Ta-Pei Cheng. Relativity, Gravitation and Cosmology: A Basic In- troduction. Oxford University Press, 2nd edition, 1 2010. ISBN 9780199573646. Predrag Cvitanovi´c. Group Theory: Birdtracks, Lie’s, and Exceptional Groups. Princeton University Press, 7 2008. ISBN 9780691118369. Paul A. M. Dirac and Physics. Lectures on Quantum Mechanics.Dover Publications, 1st edition, 3 2001. ISBN 9780486417134. Albert Einstein. The foundation of the general theory of relativity. 1916. Albert Einstein and Francis A. Davis. The Principle of Relativity. Dover Publications, reprint edition, 6 1952. ISBN 9780486600819. Richard P. Feynman and Albert R. Hibbs. Quantum Mechanics and Path Integrals: Emended Edition. Dover Publications, emended editon edition, 7 2010. ISBN 9780486477220. Richard P. Feynman, Robert B. Leighton, and Matthew Sands. The Feynman Lectures on Physics, Volume 3. Addison Wesley, 1st edition, 1 1971. ISBN 9780201021189. Richard P. Feynman, Robert B. Leighton, and Matthew Sands. The Feynman Lectures on Physics: Volume 2. Addison-Wesley, 1st edition, 2 1977. ISBN 9780201021172. Daniel Fleisch. A Student’s Guide to Vectors and Tensors. Cambridge University Press, 1st edition, 11 2011. ISBN 9780521171908. © Springer International Publishing AG 2018 J. Schwichtenberg, Physics from Symmetry, Undergraduate Lecture Notes in Physics, https://doi.org/10.1007/978-3-319-66631-0 282 physics from symmetry Jon Fripp, Deborah Fripp, and Michael Fripp. Speaking of Science. Newnes, 1st edition, 4 2000. ISBN 9781878707512. William Fulton and Joe Harris. Representation Theory: A First Course. Springer, 1st corrected edition, 8 1999. ISBN 9780387974958. Howard Georgi. Lie Algebras In Particle Physics: from Isospin To Uni- ﬁed Theories (Frontiers in Physics). Westview Press, 2 edition, 10 1999. ISBN 9780738202334. Herbert Goldstein, Charles P. Poole Jr., and John L. Safko. Clas- sical Mechanics. Addison-Wesley, 3rd edition, 6 2001. ISBN 9780201657029. David J. Grifﬁths. Introduction to Quantum Mechanics. Pearson Prentice Hall, 2nd edition, 4 2004. ISBN 9780131118928. David J. Grifﬁths. Introduction to Electrodynamics. Addison-Wesley, 4th edition, 10 2012. ISBN 9780321856562. Francis Halzen and Alan D. Martin. Quarks and Leptons: An Intro- ductory Course in Modern Particle Physics. Wiley, 1st edition, 1 1984. ISBN 9780471887416. Nadir Jeevanjee. An Introduction to Tensors and Group Theory for Physicists. Birkhaeuser, 1st edition, August 2011. ISBN 978- 0817647148. Robert D. Klauber. Student Friendly Quantum Field Theory. Sandtrove Press, 2nd edition, 12 2013. ISBN 9780984513956. Cornelius Lanczos. The Variational Principles of Mechanics.Dover Publications, 4th edition, 3 1986. ISBN 9780486650678. C. S. Lewis. Reﬂections on the Psalms. HarperOne, reprint edition, 2 2017. ISBN 9780062565488. Michele Maggiore. A Modern Introduction to Quantum Field Theory. Oxford University Press, 1st edition, 2 2005. ISBN 9780198520740. Franz Mandl and Graham Shaw. Quantum Field Theory. Wiley, 2nd edition, 5 2010. ISBN 9780471496847. Rollo May. The Courage to Create. W. W. Norton and Company, reprint edition, 3 1994. ISBN 9780393311068. Charles W. Misner, Kip S. Thorne, and John Archibald Wheeler. Gravitation. W. H. Freeman, 1st edition, 9 1973. ISBN 9780716703440. bibliography 283 David Morin. Introduction to Classical Mechanics: With Problems and Solutions. Cambridge University Press, 1 edition, 2 2008. ISBN 9780521876223. Matthew Robinson. Symmetry and the Standard Model. Springer, 1st edition, August 2011. ISBN 978-1-4419-8267-4. Robert S. Root-Bernstein and Michele M. Root-Bernstein. Sparks of Genius. Mariner Books, 1st edition, 8 2001. ISBN 9780618127450. Lewis H. Ryder. Quantum Field Theory. Cambridge University Press, 2nd edition, 6 1996. ISBN 9780521478144. J. J. Sakurai. Modern Quantum Mechanics. Addison Wesley, 1st edition, 9 1993. ISBN 9780201539295. Matthew D. Schwartz. Quantum Field Theory and the Standard Model. Cambridge University Press, 1 edition, 12 2013. ISBN 9781107034730. Lee Smolin. Three Roads to Quantum Gravity. Basic Books, 3 edition, 8 2017. ISBN 9780465094547. Michael Spivak. A Comprehensive Introduction to Differential Geometry, Vol. 1, 3rd Edition. Publish or Perish, 3rd edition, 1 1999. ISBN 9780914098706. Andrew M. Steane. An introduction to spinors. ArXiv e-prints, December 2013. John Stillwell. Naive Lie Theory. Springer, 1st edition, August 2008. ISBN 978-0387782140. Edwin F. Taylor and John Archibald Wheeler. Spacetime Physics.W. H. Freeman, 2nd edition, 3 1992. ISBN 9780716723271. Frank Wilczek. Riemann-einstein structure from volume and gauge symmetry. Phys. Rev. Lett., 80:4851–4854, Jun 1998. doi: 10.1103/PhysRevLett.80.4851. Harry Woolf, editor. Some Strangeness in the Proportion. Addison- Wesley, 1st edition, 2 1981. ISBN 9780201099249. Anthony Zee. Quantum Field Theory in a Nutshell. Princeton Univer- sity Press, 1st edition, 3 2003. ISBN 9780691010199. Anthony Zee. Einstein Gravity in a Nutshell. Princeton University Press, 1st edition, 5 2013. ISBN 9780691145587. Index action, 96 adjoint representation, 170 angular momentum, 104 annihilation operator, 214 anticommutator, 218 B ﬁeld, 239 Baker-Campbell-Hausdorff formula, 41 basis generators, 42 basis spinors, 217 Bohmian mechanics, 197 boost, 67 boost x-axis matrix, 68 boost y-axis matrix, 68 boost z-axis matrix, 68 boson, 174 bra, 189 broken symmetry, 153 Cartan generators, 53 Casimir elements, 53 Casimir operator SU(2), 54 charge conjugation, 86 classical electrodynamics, 239 closure, 41 commutator, 41 commutator quantum ﬁeld theory, 120 commutator quantum mechanics, 118 complex Klein-Gordon ﬁeld, 124 conjugate momentum, 111, 119, 211 continuous symmetry, 26 Coulomb potential, 243 coupling constants, 123 covariance, 21, 122 covariant derivative, 138 creation operator, 214 dagger, 34, 92 delta distribution, 278 determinant, 274 diagonalization, 275 Dirac equation, 127 Dirac equation solution, 216 dotted index, 75 doublet, 131, 144 Dyson series, 224 E ﬁeld, 239 Ehrenfest theorem, 234 eigenvalue, 275 eigenvector, 275 Einstein, 11 Einstein summation convention, 17 Einstein’s Sum Convention, 269 electric charge, 142 electric charge density, 142 electric ﬁeld, 239 electric four-current, 142, 239 electrodynamics, 239 elementary particles, 90 energy-momentum relation, 178 energy-momentum tensor, 107 Euclidean space, 20 Euler’s formula, 268 Euler-Lagrange equation, 99 ﬁeld theory, 101 particle theory, 101 expectation value, 181, 233 extrema of functionals, 97 Fermat’s principle, 96 fermion, 174 fermion mass, 162 ﬁeld energy, 108 ﬁeld momentum, 108 ﬁeld-strength tensor, 239 © Springer International Publishing AG 2018 J. Schwichtenberg, Physics from Symmetry, Undergraduate Lecture Notes in Physics, https://doi.org/10.1007/978-3-319-66631-0 286 physics from symmetry four-vector, 18 Fourier transform, 277 frame of reference, 5 free Hamiltonian, 220 functional, 96 gamma matrices, 126 gauge ﬁeld, 151 gauge symmetry, 133 Gaussian wave-packet, 185 Gell-Mann matrices, 170 general relativity, 245 generator, 38 generator boost x-axis, 68 generator boost y-axis, 68 generator boost z-axis, 68 generators, 40 generators SO(3), 42 generators SU(2), 47 global symmetry, 135 gluons, 174 Goldstone bosons, 154 gravity, 245 Greek indices, 17 group axioms, 29 groups, 26 Hamiltonian, 104 Hamiltonian scalar ﬁeld, 212 Heisenberg picture, 222 Higgs potential, 152 Higgs-ﬁeld, 154 homogeneity, 11 homogeneous Maxwell equations, 142 inertial frame, 11 inﬁnitesimal transformation, 38 inhomogeneous Maxwell equations, 129, 139, 239 interaction Hamiltonian, 220 interaction picture, 222 internal symmetry, 110 invariance, 21, 122 invariant of special-Relativity, 14 invariant of special-relativity, 12 invariant subspace, 52 irreducible representation, 53 isotropy, 11 ket, 189 Klein-Gordon equation, 123, 211 solution, 211 Kronecker symbol, 272 ladder operators, 56 Lagrangian formalism, 97 left-chiral spinor, 74 Levi-Civita symbol, 272 Lie algebra deﬁnition, 40 Lorentz group, 70 modern deﬁnition, 45 Poincaré group, 89 SO(3), 44 SU(2), 47 Lie bracket, 41 local symmetry, 135 Lorentz force, 241 Lorentz group, 63 Lorentz group components, 64 Lorentz transformations, 19 magnetic ﬁeld, 239 Majorana mass terms, 125 mass-shell condition, 230 matrix multiplication, 259 metric, 18 minimal coupling, 139 Minkowski metric, 17 momentum, 103 momentum ﬁeld, 108 natural units, 5 Newton’s second law, 234 Noether current, 109 Noether’s Theorem, 101 non-continuous symmetry, 26 operators of quantum mechanics, 178 parity, 64, 84 particle in a box, 186, 191 path integral formalism, 197 Pauli matrices, 47 Pauli-exclusion principle, 218 Pauli-Lubanski four-vector, 90 Poincaré group, 29, 89 principle of locality, 17 principle of relativity, 11 probabilistic interpretation, 180 probability amplitude, 180 index 287 Proca equation, 129 solution, 219 quantum gravity, 250 quantum mechanics, 177 quantum operators, 178 quaternions, 33 relativity, 11 representation deﬁnition, 50 Lorentz group, 66 (0,0), 72 (0,0)(1/2,0), 72 (0,1/2), 74 (1/2,1/2), 80 spin 0, 91 spin 1, 91 spin 1/2, 91 SU(2), 54 right-chiral spinor, 75 rotation matrices, 33 rotational symmetry, 26 rotations in Euclidean space, 20 rotations with quaternions, 36 scalar ﬁeld energy, 212 scalar product, 255 scalar representation, 91 scatter amplitude, 220 Schrödinger picture, 222 Schur’s Lemma, 53 similarity transformation, 52 SO(2), 29 SO(3), 42 special relativity, 11, 12 spin, 90 spin representation, 90 spinor, 74 spinor metric, 76 spinor representation, 91 Standard Model, 7 strong interaction, 174 SU(2), 35, 46, 143 SU(3), 170 SU(n), 92 subrepresentation, 52 sum over histories, 197 summation convention, 17 superposition, 180 symmetry, 21 symmetry group, 29 time evolution of states, 220 total derivative, 106 trace, 42 triplet, 171 U(1), 31, 134 unit complex number, 31 unit complex numbers, 134 unit matrix, 272 unit quaternions, 33 unitary gauge, 154 vacuum state, 154 vacuum value, 155 Van der Waerden notation, 75 variational calculus, 96 vector representation, 91 wave function, 180, 190 Weyl spinor, 75, 85 Yukawa coupling, 163","libVersion":"0.3.2","langs":""}