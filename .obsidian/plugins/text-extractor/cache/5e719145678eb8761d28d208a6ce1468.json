{"path":"Books and Papers/Probability and Statistics/João - ESTATÍSTICA BAYESIANA APLICADA EM COSMOLOGIA.pdf","text":"JOÃO GABRIEL VICENTE ESTATÍSTICA BAYESIANA APLICADA EM COSMOLOGIA Londrina 2022 JOÃO GABRIEL VICENTE ESTATÍSTICA BAYESIANA APLICADA EM COSMOLOGIA Trabalho de Conclusão de Curso apresentado ao Departamento de Física da Universidade Esta- dual de Londrina, como requisito parcial à ob- tenção do título de Bacharel. Orientador: Prof. Dr. Thiago dos Santos Pe- reira. Londrina 2022 Ficha de identificação da obra elaborada pelo autor, através do Programa de Geração Automática do Sistema de Bibliotecas da UEL Vicente, João Gabriel. Estatística Bayesiana aplicada em Cosmologia / João Gabriel Vicente. - Londrina, 2022. 81 f. : il. Orientador: Thiago dos Santos Pereira. Trabalho de Conclusão de Curso (Graduação em Física) - Universidade Estadual de Londrina, Centro de Ciências Exatas, Graduação em Física, 2022. Inclui bibliografia. 1. Estatística Bayesiana - TCC. 2. Cosmologia - TCC. 3. Previsão de Fisher - TCC. 4. Cadeias de Markov via Monte Carlo - TCC. I. Pereira, Thiago dos Santos. II. Universidade Estadual de Londrina. Centro de Ciências Exatas. Graduação em Física. III. Título. CDU 53 Powered by TCPDF (www.tcpdf.org) JOÃO GABRIEL VICENTE ESTATÍSTICA BAYESIANA APLICADA EM COSMOLOGIA Trabalho de Conclusão de Curso apresentado ao Departamento de Física da Universidade Esta- dual de Londrina, como requisito parcial à ob- tenção do título de Bacharel. BANCA EXAMINADORA Orientador: Prof. Dr. Thiago dos Santos Pereira Universidade Estadual de Londrina Prof. Dr. Sandro Dias Pinto Vitenti Universidade Estadual de Londrina Prof. Dr. Mario Cesar Baldiotti Universidade Estadual de Londrina Londrina, de de 2022. Resumo VICENTE, João Gabriel. Estatística Bayesiana aplicada em Cosmologia. 2022. 81 f. Tra- balho de Conclusão de Curso (Graduação em Física) – Universidade Estadual de Londrina, 2022. Descobertas experimentais sempre foram os agentes para grandes avanços teóricos na cosmolo- gia. Aliado às observações, é preciso que existam métodos de análise capazes de interpretar os dados coletados em toda a sua complexidade. Os métodos bayesianos de estatística surgem como ferramenta principal desse tipo de análise em cosmologia e, em uma época de grandes proble- mas em aberto — de origem experimental —, os métodos aplicados devem ser bem conhecidos e dominados. Desse modo, propomos nesse trabalho de conclusão uma revisão introdutória da estatística bayesiana e suas aplicações em cosmologia. Para isso, consultamos a vasta literatura sobre esse material e apresentamos, a partir de primeiros princípios, a lógica dessa abordagem. Começamos introduzindo conceitos de probabilidade, do Teorema de Bayes (que ocupa local de destaque nessa discussão) e de estatística, sobretudo sobre estimadores e o método da maxi- mização da função de verossimilhança. Em seguida, estudamos dois produtos desses conceitos muito utilizados na área: a matriz de informação de Fisher e o método das cadeias de Markov via Monte Carlo. Por fim, aplicamos todas as técnicas desenvolvidas em problemas simplificados de cosmologia: encontramos um estimador para o sinal da Radiação Cósmica de Fundo (RCF), utilizado para construção de mapas, um estimador para a função de correlação da RCF, a matriz de Fisher para um experimento sobre RCF, estudamos um modelo gaussiano de regressão de curvas e estimamos alguns parâmetros cosmológicos para dados de Supernovas Tipo Ia. Como subproduto, apresentamos uma revisão básica de diversos tópicos de interesse da cosmologia contemporânea. Palavras–Chave: estatística bayesiana, cosmologia, previsão de Fisher, cadeias de Markov via Monte Carlo. Abstract VICENTE, João Gabriel. Bayesian Statistics applied in Cosmology. 2022. 81 p. Course Conclusion Paper (Undergraduation in Physics) – State University of Londrina, 2022. Experimental discoveries have always been the cause of great theoretical development in cosmo- logy. Together with the observations, there have to be analysis methods capable of interpreting the collected data with all its complexity. Bayesian methods of statistics are the main tool for this kind of analysis in cosmology and, in a time of great open problems — of experimental origins —, the applied methods must be known and mastered. Therefore, we propose in this course conclusion project an introductory level review of the foundations and the applications of bayesian statistics in cosmology. To achieve this, we consulted the vast literature on this sub- ject and we developed from first principles the idea of this approach. We begin by introducing concepts of probability, the Bayes’ Theorem (which holds a special place in this discussion ) and statistics, specially estimators and the maximum likelihood estimation method. Then, we study two broadly used products from these concepts: the Fisher information matrix and the Markov Chain Monte Carlo method. At last, we use all this techniques in simplified cosmologi- cal problems: we find an estimator for the cosmic microwave background (CMB) signal, used for making maps, an estimator for the CMB correlation function, the Fisher matrix for an expe- riment on the CMB, we study a gaussian regression model to fit curves, and we estimate some cosmological parameters for data from Type Ia Supernovae. As subproduct, we present a basic review in several topics of interest in contemporary cosmology. Key–words: bayesian statistics, cosmology, Fisher forescast, Markov Chain Monte Carlo. SUMÁRIO INTRODUÇÃO 7 1 PROBABILIDADE 9 1.1 VARIÁVEL ALEATÓRIA . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 9 1.2 VALORES ESPERADOS . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 12 1.3 TEOREMA DE BAYES . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 16 2 ESTATÍSTICA 22 2.1 ESTIMADORES . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 22 2.2 DISTRIBUIÇÃO NORMAL . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 25 2.3 MÉTODO DE MAXIMIZAÇÃO DA FUNÇÃO DE VEROSSIMILHANÇA . . . . . . . . . . 28 3 PREVISÃO DE FISHER 31 3.1 MATRIZ DE FISHER . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 31 3.2 CASO GAUSSIANO . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 33 4 CADEIAS DE MARKOV VIA MONTE CARLO 36 4.1 ALGORITMO DE METROPOLIS–HASTINGS . . . . . . . . . . . . . . . . . . . . . 37 4.2 TESTES DE CONVERGÊNCIA . . . . . . . . . . . . . . . . . . . . . . . . . . . . 40 5 APLICAÇÕES 41 5.1 ESTIMATIVA DE SINAIS . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 41 5.2 FUNÇÃO DE CORRELAÇÃO . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 44 5.3 MODELO GAUSSIANO LINEAR . . . . . . . . . . . . . . . . . . . . . . . . . . . 51 5.4 SUPERNOVAS TIPO IA . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 60 6 CONSIDERAÇÕES FINAIS 69 REFERÊNCIAS 70 APÊNDICES 75 APÊNDICE A — DISTÂNCIA DE LUMINOSIDADE. . . . . . . . . . . . . . . . . . . . 75 APÊNDICE B —INFORMAÇÕES DE HARDWARE, PROCESSAMENTO E CÓDIGOS DESEN- VOLVIDOS . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 78 7 INTRODUÇÃO A física tem como figura central os fatos experimentais, que motivam a construção de todo o ferramental teórico e, via de regra, surgem como protagonistas nas épocas de revoluções científicas. A cosmologia física, embora uma área recente, é exemplo claro da importância de observações experimentais e da mudança que novos fatos descobertos impõem sobre o campo. Em seu princípio, na década de 1910, era consenso a ideia de que o Universo seria es- tático. Conforme a aparelhagem tornou-se mais sensível, essa percepção mudou, pois, com as observações de Hubble (1) e Lemaître (2), inferiu-se que o Universo se expandia com uma taxa (H0) de cerca de 500 km s−1 Mpc−1. Essa observação motivou a formulação de um modelo baseado na expansão do Universo, concorrente com o modelo estático. A derrocada do modelo estático deu-se por conta de uma nova observação. Em 1965, Penzias e Wilson detectaram a Radiação Cósmica de Fundo (RCF), prevista pelo modelo de expansão. Ela ofereceria uma visão única do Universo primordial, papel que começou a exercer com mais intensidade a partir da evolução dos detectores, o que culminou no lançamento da missão COBE, na década de 1990. Trinta anos depois, não é surpreendente que as detecções recentes são muito mais precisas. As missões WMAP e Planck obtiveram um valor para H0 de cerca de 69 km s−1 Mpc−1 e 67 km s−1 Mpc −1 respectivamente (3), (4), mais de 5 vezes menor que o obtido por Hubble. Tão marcante quanto a detecção da Radiação Cósmica de Fundo e contrariando as ex- pectativas da época foi a descoberta, no final da década de 90, de que o Universo se expande de forma acelerada (5), (6). Isso motivou a teorização da energia escura e culminou na formulação do chamado “modelo padrão da cosmologia”, o modelo ΛCDM. Atualmente, os objetos que forneceram tal informação, Supernovas Tipo Ia, estão, em conjunto com a Radiação Cósmica de Fundo, envolvidos em uma nova tensão na medida de H0 (7). É perceptível a evolução no campo que essas descobertas experimentais causaram e que motivaram o lançamento de diversas missões nas últimas décadas: o próprio Planck (4), LIGO e VIRGO (8), DES (9), Sloan (10), entre outras, e uma nova geração de missão, iniciada pelo Te- lescópio James Webb 1, pela futura Euclid 2 e LSST (11), além de diversas missões com o intuito de observar Ondas Gravitacionais. Além disso, a recente tensão no modelo de concordância “pede por novas observações”, segundo Di Valentino, Melchiorri e Silk em (12). Um elemento implícito quando diz-se “observações experimentais”, porém tão impor- tante quanto, é a análise estatística dos dados. É evidente — mas merece ser destacado — que as “descobertas experimentais” são produtos da interpretação das informações diretamente obtidas via observações. Entre uma grande descoberta e outra, sempre, junto com as técnicas de de- tecção, há um aperfeiçoamento dos métodos estatísticos, algo que surge como uma necessidade dada a crescente complexidade das informações. 1https://www.jwst.nasa.gov/ 2https://sci.esa.int/web/euclid 8 A constante vigilância sobre os métodos aplicados torna-se então um elemento princi- pal no que diz respeito a futuras missões, para procurar dar respostas ou pelos menos indicar caminhos para a solução dos problemas atuais em cosmologia. Para efetivamente realizar isso, deve-se ter confiança para com os métodos utilizados. Frente a isso, propomos neste trabalho construir uma revisão, a partir de primeiros prin- cípios, do principal método utilizado na análise de dados em cosmologia e suas aplicações, a estatística bayesiana. Com esse intuito, a monografia começa (capítulo 1) com uma revisão de conceitos básicos de probabilidade, valores esperados e o Teorema de Bayes. No capítulo 2, introduzimos o conceito de estimadores, a distribuição normal, o teorema do limite central e o método de maximização da função de verossimilhança. Nos capítulos 3 e 4, abordamos algumas técnicas baseadas nos conceitos desenvolvidos anteriormente: a previsão de Fisher, que permite estimar a precisão com que um futuro experimento vai restringir os parâmetros de uma teoria e o método das Cadeias de Markov via Monte Carlo, para estimar os parâmetros de uma teoria a partir de dados experimentais. No capítulo 5, aplicamos essas técnicas em exemplos específicos, calculando estimadores para sinais da Radiação Cósmica de Fundo, para a função de correla- ção, para um modelo gaussiano linear sobre os parâmetros da equação de uma parábola e sobre parâmetros cosmológicos de dados de Supernovas Tipo Ia. 9 1 PROBABILIDADE A inferência bayesiana tem como base uma visão muito particular sobre o conceito de probabilidade. Com o intuito de explorar essa visão, precisamos estudar os fundamentos da teoria da probabilidade, o que realizamos neste capítulo. Para realizar essa revisão, nos baseamos principalmente nas referências (13), (14) e (15). 1.1 VARIÁVEL ALEATÓRIA Estudando fenômenos físicos, a primeira observação feita é de que grandezas físicas pos- suem valores bem definidos. Isto corresponde a afirmar que uma partícula possui uma massa determinada, que a Radiação Cósmica de Fundo possui um espectro angular de potências. Tam- bém corresponde a afirmar que o Universo possui uma densidade específica de matéria, ou que ele se expande com uma taxa determinada. Todas essas grandezas apresentam um único valor bem determinado pela natureza. No entanto, percebe-se que o ato de medir não retorna seus valo- res reais, pois, associado à medição, encontram-se erros experimentais com origem nas diversas variáveis incontroláveis que existem 3. Essas variáveis surgem em toda a etapa da preparação do experimento, tendo origem na precisão finita do medidor, na condição do próprio objeto medido e no local de medição; em suma, estão associadas com todos os objetos relacionados com a me- dida. Portanto, medidas de grandezas físicas (determinadas pela natureza) são, em decorrência do erro experimental, aleatórias. O processo de medir é um processo estocástico. Realizada essa observação, não é uma surpresa que medidas sistemáticas de uma gran- deza física geram resultados diferentes. Considere um experimento hipotético onde uma série de medições em sequência de uma mesma grandeza física são realizadas — a massa de uma pes- soa, ou sua altura, etc. Essas medidas podem resultar em valores diferentes. Embora é possível que exista uma expectativa de um resultado, o produto de uma medição é, efetivamente, desco- nhecido antes de ser medido. Essa ideia de uma variável cujo valor não é conhecido antes de ser determinado e que repetidamente pode assumir valores diferentes é a noção intuitiva do que é uma variável aleatória. Note que uma variável aleatória é produto de um processo estocástico, mas uma sequência finita de medições desta pode não ser estatisticamente aleatória. Prosseguindo com essa noção, considere um experimento que consiste no lançamento de um dado. A rigor, conhecendo-se a face que está virada para cima no momento do lançamento, a força que foi aplicada, a densidade do dado, as condições atmosféricas locais, etc, o resultado do lançamento se resume a um problema de mecânica. No entanto, a quantidade e a interdepen- dência entre as variáveis torna o problema tão complexo que o lançamento de um dado é, para todos os efeitos, um processo estocástico (o caso em que uma sequência de lançamentos resulta em, respectivamente, (1,2,3,4,5,6) não é estatisticamente aleatório, mesmo que resulte de um processo estocástico). O conjunto de todos os possíveis resultados desse experimento é 3Note que o contexto considerado aqui é puramente clássico. Na mecânica quântica, a aleatoriedade em medi- ções não vem do limite na precisão do experimento, mas é uma característica da própria natureza. 10 Ω = {1, 2, 3, 4, 5, 6} . Antes de lançar o dado, levantam-se perguntas acerca do resultado do lançamento, sendo “qual será o número da face virada para cima?” a mais natural. Após observar o resultado do ex- perimento, todas as grandezas indagadas vão ter um valor determinado. Essas grandezas são variáveis aleatórias. Chama-se de espaço amostral o espaço de todos os possíveis resultados de um experi- mento. No exemplo anterior, a variável aleatória é o número da face do dado e o espaço amos- tral é Ω. Assim, dado um elemento do espaço amostral, uma variável aleatória gera um número real. Podemos escrever isso matematicamente definindo uma variável aleatória com uma função X : Ω → R. Para uma definição rigorosa de variável aleatória, ver (16). Propomos acima a noção de variáveis aleatórias a partir de valores discretos, mas casos contínuos também existem. Nesse contexto, é preciso considerar medições ideais arbitraria- mente precisas, no qual todas as casas decimais de um número são conhecidas. Observe no entanto que na realidade medições com tamanha precisão não existem e, portanto, mesmo que existam variáveis físicas contínuas, medições dessas grandezas são valores discretos, cuja pre- cisão é determinada pelo aparato sendo utilizado para a medição. Dando um passo além, é possível definir funções de variáveis aleatórias. Considere, por exemplo, no caso acima, que houve uma aposta e uma pessoa irá receber certa quantia q de dinheiro se a face do dado for 2,4 ou 6. Então, existe uma função f (X) = 8 < :0, se X = 1, 3 ou 5; q, se X = 2, 4 ou 6. (1.1) Associado à noção de espaço amostral e de variável aleatória, podemos definir uma fun- ção p, conhecida como função frequência, para cada ponto no espaço amostral. Se forem reali- zadas N medições de uma variável aleatória discreta X e ela assumir um valor x em n(x) ≤ N medições, a função frequência é definida como p(x) ≡ lim N →∞ n N . (1.2) No caso discreto, a função frequência coincide com a noção de probabilidade. Desse modo, a equação (1.2) também é a definição da probabilidade que uma medição resulte em x. Salien- tamos a diferença entre X e x: X é a variável aleatória como foi definida acima, isto é, uma função de Ω em R; x é uma realização particular da variável aleatória. Para o caso de uma variável contínua, definimos como função frequência — ou densidade de probabilidade — p(x) o número de vezes que X assume um valor entre x e x + dx em um total de N → ∞ medições. Desse modo, a probabilidade que X assuma um valor entre x e x + dx é p(x)dx. Em um intervalo [a, b], a probabilidade é 11 P (a ≤ X ≤ b) = Z b a p(x)dx. (1.3) Como exemplo de densidade de probabilidade, considere a distribuição uniforme. Nesse caso, todas as realizações de uma variável aleatória são igualmente prováveis de ocorrer. A Figura 1 representa essa distribuição. Outro exemplo é a distribuição normal (ou gaussiana), onipresente na física, que tratamos na seção 2.2. Figura 1: Densidade de probabilidade uniforme em um intervalo [0,1]. 0.0 0.2 0.4 0.6 0.8 1.0 x 0.96 0.98 1.00 1.02 1.04Densidade de probabilidade Fonte: O próprio autor. Podemos estender esses conceitos para mais de uma variável aleatória. Variáveis aleató- rias conjuntas são, no geral, interdependentes, isto é, o comportamento de uma variável aleatória se reflete no comportamento de outra. Como exemplo, voltemos para o dado lançado, mas agora considerando um segundo dado. O espaço amostral o lançamento de dois dados é Ω = {(1, 1); (1, 2); (1, 3); (1, 4); (1, 5); (1, 6); (2, 1); (2, 2); (2, 3); (2, 4); (2, 5); (2, 6); (3, 1); (3, 2); (3, 3); (3, 4); (3, 5); (3, 6); (4, 1); (4, 2); (4, 3); (4, 4); (4, 5); (4, 6); (5, 1); (5, 2); (5, 3); (5, 4); (5, 5); (5, 6); (6, 1); (6, 2); (6, 3); (6, 4); (6, 5); (6, 6)} . Nesse contexto, há duas variáveis aleatórias, X1 e X2, referentes às faces dos dados 1 e 2. In- troduzimos aqui a noção do vetor de variáveis aleatórias, que nesse caso é X = (X1, X2). Ele é uma função definida no espaço amostral Ω ⊂ R2. Para uma definição rigorosa de vetor de variá- veis aleatórias, ver (16). Para exemplificar a interdependência, considere que uma corda passe por dentro dos dados, ligando-os. Observa-se então que há uma incidência maior de realizações 12 em que ambos os dados apresentam a mesma face. A interdependência se encontra na observa- ção de que o comportamento da medida de uma variável aleatória se reflete no comportamento da outra. Como são possivelmente interdependentes, a densidade de probabilidade precisa agora ser uma função de cada uma das variáveis. Sejam X1, X2, ..., Xm m variáveis aleatórias con- juntas, X = (X1, X2, ..., Xm) o vetor aleatório e p(X) a densidade de probabilidade para essas variáveis. Se forem contínuas, a probabilidade que uma medição resulte em um valor num sub- conjunto V ⊂ Ω, sendo Ω o espaço amostral, é P (X ∈ V) = Z V p(x1, ..., xm)dx1...dxm. (1.4) Há casos em que nem todas as variáveis aleatórias presentes são de algum interesse. Em um problema de cosmologia, por exemplo, podemos ter uma densidade de probabilidade sobre os parâmetros H0 e Ωm, mas sabe-se que esse experimento não restringe bem o valor de H0. É possível retirar da densidade de probabilidade a dependência sobre H0. Esse processo se chama marginalização. Para as m variáveis definidas acima, a densidade de probabilidade ˜p, uma função de ˜X = (X2, ..., Xm), é dada por ˜p( ˜X) = Z ∞ −∞ dx1p(x1, ..., xm). (1.5) Esse processo pode ser feito para quantas variáveis quisermos, até que voltemos a ter apenas um variável aleatória. A densidade de probabilidade p1, associada apenas à variável X1, pode ser obtida pela densidade de probabilidade conjunta realizando: p1(X1) = mY k=2 Z ∞ −∞ dxkp(x1, ..., xm). (1.6) Variáveis aleatórias são ditas estatisticamente independentes se p(X) = p1(X1)p2(X2)...pm(Xm), (1.7) ou seja, o comportamento de uma não se reflete no comportamento de outra. 1.2 VALORES ESPERADOS Já ficou claro que medições experimentais são processos aleatórios. Vimos que, associ- ada às variáveis, existe uma função que exprime a frequência que determinada realização ocorra. Portanto, medidas experimentais têm associado uma densidade de probabilidade, referente ao erro experimental. Suponha que essa função é de algum modo conhecida. Nesse caso, o valor esperado é definido por: 13 ⟨X⟩ ≡ X x xp(x), (1.8) onde a soma é sobre todos os valores possíveis de x. No caso contínuo, ⟨X⟩ ≡ Z ∞ −∞ xp(x)dx. (1.9) O valor esperado de uma variável aleatória, ⟨X⟩, é conhecido como média populacional e é denotado por µX ≡ ⟨X⟩. No contexto de grandezas físicas medidas em processos estocásticos, a média populacional é, segundo M. Boas, frequentemente interpretada como o valor real da quantidade medida (2006, p.770)(13). Se conhecermos a distribuição p, podemos determinar µX, o objetivo final dessa análise. O conceito de valor esperado também pode ser utilizado em outros contextos. Ele ex- prime o comportamento médio de uma grandeza. Assim, em sistemas onde variáveis aleatórias mudam de valor muito rapidamente, o valor médio destas é um bom substituto para a alterna- tiva mais custosa de considerar as frequentes variações. Um exemplo dessa aplicação do valor esperado está na termodinâmica e na mecânica estatística. Um gás é composto de um número de partículas da ordem de 10 23, cada uma com um valor de energia dependente da distribuição de temperatura no recipiente, da distribuição de matéria, etc. Para descrever esse sistema, no qual a distribuição de probabilidade da energia de cada partícula é simétrica ao redor do valor médio, substitui-se a descrição particular de cada partícula para uma descrição geral com base nas variáveis termodinâmicas. É importante destacar que o valor esperado não é necessariamente o valor mais provável de ser medido. Este último pode ser obtido encontrando o ponto de máximo da função frequên- cia. Isso é visível se escrevermos, para o caso discreto e tomando x0 o valor mais provável, ⟨X⟩ = X x<x0 xp(x) + x0p(x0) + X x>x0 xp(x). O valor esperado só é igual ao valor mais provável caso os dois somatórios se anulem. Contanto que a soma em (1.8) ou a integral em (1.9) convirjam, o valor esperado existe para qualquer variável aleatória. Como funções de variáveis aleatórias também são grandezas estocásticas, as definições acima podem ser generalizadas para funções de variáveis aleatórias conjuntas: ⟨f ⟩ ≡ X x1,...,xm f (x1, ..., xm)p(x1, ..., xm), (1.10) no caso discreto e ⟨f ⟩ ≡ mY k=1 Z ∞ −∞ dxkf (x1, ..., xm)p(x1, ..., xm), (1.11) 14 no caso contínuo, mantendo, no geral, o mesmo sentido que descrevemos acima. Para X1, ..., Xm variáveis aleatórias conjuntas, o valor esperado da variável Xj é µXj = ⟨Xj⟩ = mY k=1 Z ∞ −∞ dxkxjp(x1, ..., xj, ..., xm) = Z ∞ −∞ dxjxj Y k̸=j Z ∞ −∞ dxkp(x1, ..., xj, ..., xm), mas, da equação (1.6), µXj = Z ∞ −∞ dxjxjpj(xj), (1.12) onde marginalizamos sobre todas as outras variáveis. Note que o número de integrações neces- sárias para determinar a média é o número de parâmetros presentes. Veremos depois que isso representa um problema que motivará a utilização das cadeias de Markov via Monte Carlo. O valor esperado é apenas uma informação que podemos retirar de uma distribuição de probabilidade. Uma segunda informação possível é a variância, definida como Var[X] ≡ ⟨(X − µX) 2⟩ (1.13) = ⟨X 2⟩ − µ2 X. Da variância acima, definimos desvio padrão populacional como σX = pVar[X]. (1.14) O desvio padrão populacional σ é uma medida da dispersão de uma variável ao redor da média. Quanto maior a dispersão (i.e., quanto maior σ) maior é a probabilidade de que uma medição resulte em um valor distante da média. Como exemplo, considere novamente o lançamento de um dado. Construímos um algoritmo que simula o lançamento de um dado “honesto” (Figura 2a), que possui uma distribuição uniforme para cada face, e um dado viciado (Figura 2b). Em ambos os casos o valor esperado é 3, 5, mas os desvios padrão são diferentes e a probabilidade de encontrar valores distantes de 3, 5 no segundo caso é maior. O valor esperado e o desvio padrão não esgotam completamente as informações sobre a distribuição (exceto em relação à gaussiana). O valor esperado é conhecido como primeiro momento estatístico e a variância como segundo momento estatístico central. Existem outros momentos estatísticos, que também carregam informações sobre a distribuição. A assimetria é o terceiro momento estatístico central e é uma medida da diferença do comportamento da distribuição de probabilidades para valores maiores e menores que a média; o quarto momento estatístico central é a curtose, que mede o quanto uma distribuição se desvia de uma gaussiana 15 Figura 2: Distribuições de probabilidade para dois tipos de dados 1 2 3 4 5 6 Face 1/6Frequência (a) 1 2 3 4 5 6 Face 0.5/6 2/6Frequência (b) a) Distribuição de probabilidade para um dado honesto. b) Distribuição de probabilidade para um dado viciado. Fonte: O próprio autor (15). O conceito de variância pode ser generalizado para mais de uma variável aleatória. Con- sidere duas variáveis aleatórias conjuntas X e Y . A covariância é uma medida de como uma varia quando a outra varia. Matematicamente, escrevemos Cov[X, Y ] ≡ ⟨(X − µX)(Y − µY )⟩, (1.15) = ⟨XY ⟩ − µXµY . Da definição acima, é visível que a covariância é simétrica, isto é, Cov[x, y] = Cov[y, x] e que Cov[x, x] = Var[x]. A covariância pode ser representada por uma matriz, chamada matriz de covariância: Σ = Var[X] Cov[X, Y ] Cov[Y, X] Var[Y ] ! . (1.16) O sinal da covariância diz como uma variável aleatória se comporta dado como a outra se comporta; se Cov[X, Y ] < 0 então uma tende a aumentar quando a outra diminui, se elas são independentes, ⟨XY ⟩ = ⟨X⟩ ⟨Y ⟩ = µXµY e a covariância é nula. Por fim, se Cov[X, Y ] > 0 então uma tende a aumentar/diminuir quando a outra aumenta/diminui. Variáveis correlacionadas adicionam uma dificuldade a mais para a análise de dados. Para m variáveis aleatórias conjuntas, podemos representar a covariância a partir da ma- 16 triz Σ = 0 B B B B @ Var[X1] Cov[X1, X2] ... Cov[X1, Xm] Cov[X2, X1] Var[X2] ... Cov[X2, Xm] ... ... . . . ... Cov[Xm, X1] Cov[Xm, X2] ... Var[Xm] 1 C C C C A . (1.17) Ou seja, a matriz de covariância é uma matriz simétrica cuja a diagonal é dada pela variância de cada variável. Retomando à ideia de que medidas experimentais são descritas por variáveis aleatórias, vemos que a matriz (1.17) pode ser entendida intuitivamente como uma generalização do con- ceito de dispersão nos valores medidos, e, portanto, como o erro intrínseco da medida. Esse erro é normalmente conhecido como erro estatístico, em contraste com o chamado erro sistemático. Este último é normalmente atribuído a fatores não aleatórios (instrumento mal calibrado, to- mada incorreta de dados, etc). Quando os erros de uma medida e outra não são correlacionados, apenas os elementos da diagonal da matriz (1.17) importam. No entanto, na maioria dos casos práticos os erros experimentais são correlacionados, e a questão relevante é se essas correlações podem ou não serem ignoradas. Uma grandeza que expressa mais claramente a “intensidade” da tendência de variação entre duas variáveis é a correlação ρ, definida como ρ ≡ Cov[X, Y ] p Var[X]Var[Y ] . (1.18) A correlação, por definição, está restrita ao intervalo −1 ≤ ρ ≤ 1. Ao dividir pelos desvios pa- drão e, assim, limitar o valor da correlação, torna-se mais perceptível o comportamento que uma variável aleatória tem em relação a outra. Se ρ é muito próximo de 1(-1) então as variáveis são altamente correlacionadas(anti-correlacionadas). Na Figura 3, exemplificamos esse conceito. 1.3 TEOREMA DE BAYES Com o conceito de probabilidade introduzido, podemos analisar um dos pontos centrais da inferência bayesiana, o Teorema de Bayes. Queremos compreender como a ocorrência de um evento modifica as chances de outro evento ocorrer, dado que não são independentes. Vamos observar depois que o cerne da inferência bayesiana se encontra na forma como o conhecimento a priori de um experimento influencia na análise. Para isso, precisamos compreender o que é um evento neste contexto. Um evento A é um fenômeno que ocorre quando a realização de um experimento resulta em um ponto em A ⊂ Ω, sendo A o conjunto de pontos favoráveis à ocorrência de A. Voltemos novamente ao caso do lançamento de dois dados independentes e honestos. 17 Figura 3: Realização de duas variáveis aleatórias conjuntas X e Y com distribuições de proba- bilidade gaussiana. 3 2 1 0 1 2 3 4 x 3 2 1 0 1 2 3y (a) 4 3 2 1 0 1 2 3 x 4 3 2 1 0 1 2 3y (b) 4 2 0 2 4 x 6 4 2 0 2 4y (c) 2 1 0 1 2 3 x 3 2 1 0 1 2y (d) a) As variáveis são independentes, i.e., a correlação é nula; b) As variáveis são completamente correlacionadas, ρ = +1; c) A correlação é ρ = √2/2; d) As variáveis são completamente anti-correlacionadas, ρ = −1. Fonte: O próprio autor. Exemplos de eventos nesse contexto são (analise inspirada em (17)): • Evento A: A soma das faces é 6; • Evento B: As faces são iguais. Para o evento A, o número de pontos favoráveis a sua ocorrência em Ω é 5, enquanto que, para o evento B, o número de pontos é 6. Da definição de probabilidade, (1.2), vemos que a probabilidade de A ocorrer é P (A) = 5/36 e a probabilidade de B ocorrer é P (B) = 6/36. A ocorrência de A e B juntos se refere a um único ponto ((3, 3)) no espaço amostral, de modo que a probabilidade de A e B ocorrerem juntos é dada por P = 1/36 (a frequência com que ocorrem juntos). A ocorrência de A ou B se relaciona com 10 pontos no espaço amostral (tomando o cuidado de não contar duas vezes o ponto (3,3)), de modo que a probabilidade de A ou B ocorrerem é dada por P = 10/36. Agora, considere que estamos interessados em apenas contabilizar os resultados em que B ocorra sabendo que A também ocorrerá. Em outras palavas, não registramos os casos cujo 18 Figura 4: Espaço amostral Ω com subconjuntos A e B. Ω A B Fonte: O próprio autor. o resultado do lançamento não se encontre em A. Isso é equivalente a tomar um novo espaço amostral que consiste em apenas A. Nesse novo espaço amostral, que contém 5 pontos, há um único ponto favorável à ocorrência de B. Portanto, a probabilidade que B ocorra dado que A ocorra é 1/5. Vamos formalizar esse exemplo. A probabilidade que A ocorra em um espaço amostral discreto é P (A) = X (x1,...,xm)∈A p(x1, ..., xm), (1.19) a soma das probabilidades individuais no espaço amostral. Para um conjunto contínuo, P (A) = mY k=1 Z A dxkp(x1, ..., xm). (1.20) Podemos estender esse desenvolvimento para mais de um evento. Considere dois eventos A e B (Figura 4). O evento A ou B acontece quando uma medição obtém algum ponto em A∪B. Desse modo, a probabilidade desse evento ocorrer é dada por P (A + B) = P (A ∪ B) = P (A) + P (B) − P (A ∩ B). (1.21) Por outro lado, a probabilidade de A e B ocorrer é dada por P (AB) = P (A ∩ B). (1.22) A probabilidade de B ocorrer dado que A ocorra, isto é, a probabilidade condicional de B dado A é 19 P (B|A) ≡ P (A ∩ B) P (A) , (1.23) pois, uma vez que A ocorra, o espaço amostral do problema se torna A e as probabilidades precisam ser renormalizadas. A partir da equação (1.23) podemos escrever P (AB) = P (A)P (B|A). (1.24) Já a probabilidade que A ocorra dado que B ocorra é P (A|B) = P (A ∩ B) P (B) , de modo que, a partir da equação (1.23) P (BA) = P (B)P (A|B). As probabilidade P (AB) e P (BA) são iguais, pois se referem à mesma região no espaço amos- tral. Portanto, P (A)P (B|A) = P (B)P (A|B), (1.25) o Teorema de Bayes. No caso de ambos eventos serem estatisticamente independentes, a probabilidade de B ocorrer após A é simplesmente P (B), de modo que P (AB) = P (A)P (B). (1.26) Podemos ainda reescrever a equação (1.25) como P (A|B) = P (B|A)P (A) P (B) . Assim, vemos que o teorema de Bayes nos informa a probabilidade condicional do evento A ocorrer dado que B ocorra se soubermos a probabilidade condicional do evento B ocorrer dado que A ocorra. Vamos exemplificar essa relação a partir de um exercício em (18). Considere que uma pessoa apresente uma tosse persistente por uma semana (evento T). Essa pessoa está interessada em saber a probabilidade de que ela tenha câncer de pulmão dado que ela apresenta essa tosse persistente, isto é, a probabilidade P (P|T ), onde P se refere ao evento “câncer de pulmão”. Um dos principais sintomas de câncer de pulmão é tosse persistente, logo, toda a pessoa com câncer de pulmão apresenta tosse (escrevemos isso como P (T |P) = 1). Suponha que, em um ano, 1 em 2000 pessoas são diagnosticadas com câncer de pulmão (P (P) = 1/2000) e 1 em 5 pessoas apresentam tosse persistente por mais de uma semana (P (T ) = 1/5). O Teorema de Bayes informa que a probabilidade de que essa pessoa tenha câncer de pulmão dado 20 que ela apresente tosse persistente é P (P|T ) = 1 × 1/2000 1/5 = 25 104 . (1.27) Agora temos condições de introduzir as noções da inferência bayesiana. Com base no que foi discutido, podemos propor uma nova perspectiva sobre a ideia de probabilidade. Da definição (1.2), construímos o conceito de probabilidade sob um viés dito frequentista, no qual a probabilidade é unicamente uma medida da frequência que um resultado pode ocorrer após muitas medições. No entanto, sob uma visão bayesiana, a probabilidade também pode ser vista como um grau de confiança em alguma hipótese (discutimos o que isso implica no parágrafo seguinte). De fato, se considerarmos o evento A não como um evento predecessor que modifica o espaço amostral original, mas como uma hipótese H que afirma que as medições das variáveis só podem resultar em pontos em A, a probabilidade P (A), sendo reescrita como P (H) representa o grau de confiança de que essa hipótese reflita a realidade. Nesse sentido, se o evento posterior B for interpretado como a realização de um experimento, uma coleta de dados D = {d1, ..., dn}, de modo que P (D) é a probabilidade de obtermos os dados nos valores que obtivemos, o teorema de Bayes é reescrito como P (H|D) = P (D|H)P (H) P (D) , (1.28) sendo P (D|H) a probabilidade de obter D no experimento dado o modelo teórico, chamada fun- ção de verossimilhança, ou L(D|H). A probabilidade P (H) é conhecida como probabilidade anterior, conceito que exploramos novamente na seção 2.3. P (D), a probabilidade a priori de D, pode ser usada como um fator de normalização da equação (1.28) . Por fim, P (H|D), a pro- babilidade condicional da hipótese H uma vez conhecido o conjunto D de dados, é chamada de probabilidade posterior. Em outras palavras, a quantidade P (H|D) quantifica a pergunta:“qual é a probabilidade de que a hipótese H reflita a realidade, dado que um experimento resulta nos dados D?”. Note que a passagem da ideia de probabilidade como uma frequência para probabilidade como um nível de confiança é um tanto filosófica; não podemos oferecer argumentos que jus- tifiquem completamente essa associação. De fato, segundo Jonathan Weisberg (2011, p.488 – 489) (19), o conceito de “grau de confiança” como uma probabilidade não é consenso. Uma das tentativas de precisar esse conceito, segundo ele, é o Teorema da Representação de Ramsey, que quantifica como uma probabilidade a preferência sobre uma hipótese (dentre várias hipóteses), dado que essa preferência se baseie em um conjunto determinado de imposições. No entanto, ainda segundo Jonathan Weisberg, existem críticas em relação a essa visão. Entretanto, sob uma noção puramente matemática, a quantidade P (H) é bem definida. Esboçamos aqui a ideia da definição de espaço de probabilidade, uma abordagem rigorosa pode ser encontrada em (20). Um espaço de probabilidade é a tripla (Ω, F, P ), sendo Ω o espaço 21 amostral (nesse caso o espaço de toda as hipóteses), F um subconjunto de Ω e P : Ω → R uma medida de probabilidade. Assim, P (H) é uma medida de probabilidade no espaço de todas as hipóteses. A ideia da inferência bayesiana se torna mais palatável frente à seguinte situação: em um caso ideal onde realizamos infinitas medições de uma grandeza física e, com isso, construímos a função frequência, sabemos onde ela é maior, isto é, conhecemos os valores mais prováveis de serem medidos. Portanto, é razoável propor que os valores que mais são medidos sejam os mais próximos do valor real da grandeza. Assim, se a probabilidade de que uma medição posterior resulte em um valor no intervalo [1, 2] é, digamos, 68%, então é razoável dizer que essa é a confiança que temos de que o valor real da grandeza está dentro desse intervalo. A associação do grau de confiança a uma probabilidade na forma como foi feita acima é exemplo de grau de confiança em uma hipótese (de que o valor real está em dado intervalo) e diverge da frequentista que, em última instância, apenas associa probabilidade à frequência. A equação (1.28) é um dos pontos fundamentais da inferência bayesiana. Dela, toda a essência desse tipo de análise surge. Para construir seus fundamentos, tivemos que voltar para os fundamentos da teoria da probabilidade. Para compreender como a análise sobre os dados reais é de fato feita, precisaremos desenvolver alguns conceitos básicos da estatística. 22 2 ESTATÍSTICA Para a análise estatística prática de algum fenômeno, o conhecimento da média popula- cional e do desvio padrão populacional implica, em geral, no conhecimento completo das infor- mações que desejamos. Entretanto, as equações (1.8), (1.9) e (1.14) são incalculáveis, pois, na prática, não conhecemos nem o espaço amostral completo — apenas uma pequena parte dele, a partir de experimentos — nem a função frequência. Dessa maneira, embora existam ferramentas diretas, elas não são acessíveis num primeiro momento. Entretanto, se a média e o desvio populacional não podem ser diretamente calculados, podemos, pelo menos, estimá-los de algum modo. Neste capítulo, estudamos maneiras de encon- trar esses estimadores a partir de dados experimentais, o primeiro passo na maioria das análises estatísticas. Também exploramos a distribuição gaussiana, que, em função do teorema do limite central, pode ser, em vários casos, uma boa aproximação para a função de verossimilhança real no contexto explorado. Introduzimos, por fim, o método da maximização da função de verossi- milhança, uma maneira de construir estimadores e uma das bases da inferência bayesiana. 2.1 ESTIMADORES As primeiras informações que temos sobre um fenômeno físico são os dados experimen- tais coletados. Considere, portanto, que temos acesso a um conjunto de n dados {xi}, com i ∈ {1, ..., n}. Cada dado no conjunto representa a realização de uma medição independente e, por conseguinte, {xi} é um subconjunto do universo de todas as possíveis medições. Além disso, supomos que não há incertezas sistemáticas no experimento em questão e supomos tam- bém que cada dado em {xi} é uma realização de µ somado com um erro experimental aleatório de média 0 e simétrico ao redor da média. Sob essas circunstâncias, iremos estimar a média e o desvio padrão populacional. Para estimar µ, definimos ¯x como um possível estimador. Como tal, ele deve minimi- zar a equação (pois queremos que ele seja o valor que “melhor concorda” com cada medição, considerando todo o conjunto de medições) nX i=1 (xi − ¯x)2, (2.1) Derivando em relação a ¯x e igualando a zero, encontramos ¯x = 1 n nX i=1 xi, (2.2) ¯x é conhecido como média amostral. A média amostral é um possível estimador da média popu- lacional para o conjunto de dados oferecido, mas ainda precisamos conferir se ela é um estimador não enviesado, no sentido de seu valor esperado ser igual à média populacional. Notemos que, como {xi} são realizações de uma variável aleatória, a média amostral é ela mesma uma variá- 23 vel aleatória. Para ser um bom estimador (no sentido de representar o valor que ele pretende estimar), seu valor esperado deve convergir à média populacional. Vemos que ⟨¯x⟩ = 1 n X i=1 ⟨xi⟩ = µ. (2.3) Portanto, dizemos que ¯x é um estimador não enviesado da média populacional. Existem diversos possíveis estimadores para a média populacional que respeitam a equação (2.3). Por exemplo, supondo que os dados no conjunto {xi} estão dispostos de modo crescente (x1 o menor e xn o maior), podemos excluir o primeiro e o último quarto de pontos e construir, ˜x = 2 n 3/4nX i=n/4+1 xi. (2.4) O estimador acima respeita (2.3). Então como escolher dentre esses um estimador? Para nós, a variância deverá ser o critério definitivo. Com efeito, investiguemos a variância de ¯x: Var[¯x] = *\" 1 n X i=1 (xi − µ) #2+ = * 1 n2 X i (xi − µ)2+ + * 1 n2 X i̸=j (xi − µ)(xj − µ) + . Como xi e xj são, por hipótese, independentes e são simétricos ao redor da média µ — pois os erros experimentais são, por suposição, independentes —, o segundo termo é nulo. Comutando a soma com ⟨·⟩, identificamos no primeiro termo a variância populacional σ2, que é a mesma para todos os dados. Portanto, Var[¯x] = σ2 n (2.5) de modo que o desvio padrão da média é σ¯x = σ √n. (2.6) Vamos analisar esse resultado. Considere a definição de variância no caso discreto, σ2 ¯x = X ¯x (¯x − µ)2p(¯x). Se restringirmos a soma para apenas valores de ¯x que satisfaçam |¯x − µ| > t, sendo t uma constante, podemos escrever σ2 ¯x > X |¯x−µ|>t (¯x − µ)2p(¯x). Substituindo o termo ¯x − µ por t, a desigualdade aumenta e 24 σ2 ¯x > X |¯x−µ|>t t 2p(¯x) ⇒ X |¯x−µ|>t p(¯x) < σ2 ¯x t2 , (2.7) mas P |¯x−µ|>t p(¯x) é a probabilidade de que ¯x difira da média populacional por um valor t ou maior. A equação (2.7) é conhecida como desigualdade de Chebyshev. A equação (2.6) implica que X |¯x−µ|>t p(¯x) < σ2 nt2 . (2.8) Vemos assim que se n aumenta, a probabilidade precisa diminuir. Portanto, a média amostral é um bom estimador para a média populacional quando temos grandes conjuntos de dados. Essa é uma manifestação da lei dos grandes números. Agora, precisamos encontrar um estimador para o desvio padrão dos dados medidos ao redor da média. Para isso, inspirado na equação (2.2), podemos propor como variância amostral a equação s2 = 1 n X i (xi − ¯x) 2. (2.9) O valor esperado de s2 é s2\u000b = [(xi − µ) − (¯x − µ)] 2\u000b = σ2 + σ2 n − 2 ⟨(xi − µ)(¯x − µ)⟩ , mas, ⟨(xi − µ)(¯x − µ)⟩ = 1 n (xi − µ) 2\u000b + 1 n X i̸=j ⟨(xi − µ)(xj − µ)⟩ = σ2 n , portanto, s2\u000b = σ2 − σ2 n = (n − 1)σ2 n . (2.10) Vemos que esse estimador tem um viés em relação à quantidade que queremos estimar (isto é, seu valor esperado não é igual à grandeza da qual ele pretende estimar). Desse modo, se redefinirmos o estimador para retirar esse viés, construímos um outro que respeita a condição do valor esperado, ¯σ = r n n − 1s = s P i(xi − ¯x)2 n − 1 . (2.11) A equação acima é o estimador do desvio padrão populacional. Estamos mais interessados no 25 desvio padrão da média amostral, pois, como a média amostral é a estimativa da média popula- cional em um conjunto de dados, o desvio padrão da média representa o grau de confiança nessa estimativa. Da equação (2.6), vemos que σ¯x = s P i(xi − ¯x) 2 n(n − 1) . (2.12) Como resultado dessa análise, pudemos estimar a média populacional de um conjunto de dados e quantificar a confiança nesse resultado. Representamos isso por ¯x ± σ¯x. 2.2 DISTRIBUIÇÃO NORMAL A distribuição gaussiana, ou distribuição normal, é uma distribuição de probabilidades muito comum em estatística. A frequência com que aparece em exames estatísticos e, por con- seguinte, em nossa análise, faz com que alguns conceitos mereçam ser estudados. Em uma dimensão, a distribuição gaussiana normalizada é dada por Φ = 1 √2πσ2 exp \u0014−(x − µ)2 2σ2 \u0015. (2.13) A distribuição gaussiana é completamente caracterizada pela média µ e pela variância σ2, assim, vamos denotá-la por N (µ, σ2). Qualquer gaussiana pode ser escrita como a N (0, 1) a partir de um reescalonamento linear. A Figura 5a mostra algumas distribuições para diferentes valores de σ e a Figura 5b mostra algumas distribuições com médias diferentes. Figura 5: Distribuição gaussiana 10.0 7.5 5.0 2.5 0.0 2.5 5.0 7.5 10.0 0.00 0.05 0.10 0.15 0.20 0.25 0.30 0.35 0.40 = 1 = 2 = 3 (a) 1.00 0.75 0.50 0.25 0.00 0.25 0.50 0.75 1.00 0.0 0.2 0.4 0.6 0.8 1.0 1.2 1.4 1.6 = 0 = 0, 25 = 0, 25 (b) a) Gráfico da distribuição normal para diferentes valores do desvio padrão. b) Distribuições gaussianas para dife- rentes médias. Fonte: O próprio autor. Se uma variável aleatória X tem uma densidade de probabilidade representada por uma distribuição normal, uma integração de Φ entre a e b representa a probabilidade P (a ≤ X ≤ b) 26 de que uma medição de X resulte em um valor em [a, b]. Em particular, a probabilidade de que uma medição resulte em um valor entre [−σ, +σ] é P (µ − σ ≤ X ≤ µ + σ) = 1 √2π Z 1 −1 exp \u0014−Z 2 2 \u0015 dZ ≈ 0, 68. (2.14) O intervalo de 1σ é definido, portanto, como a região onde uma medição tem 68% de chance de resultar em um valor distante até 1σ do valor médio. De modo similar, podemos definir intervalos de 2σ, 3σ, etc (ver Tabela 1). A Figura 6 mostra as regiões de 1σ,2σ e 3σ de uma distribuição gaussiana. Tabela 1: Probabilidade de que uma medição de X resulte em um valor nos intervalos propostos. Intervalo Nomenclatura Probabilidade µ − σ ≤ X ≤ µ + σ 1σ 68, 27% µ − 2σ ≤ X ≤ µ + 2σ 2σ 95, 45% µ − 3σ ≤ X ≤ µ + 3σ 3σ 99, 73% −∞ < X < ∞ 100% Fonte: O próprio autor. A distribuição gaussiana multivariada é uma generalização do conceito de distribuição normal unidimensional (2.13). Considere n variáveis aleatórias conjuntas X1, ..., Xn com média populacional µ1, ..., µn e matriz de covariância Σ. Definimos µ ≡ (µ1, ..., µn) o vetor da média e X = (X1, ..., Xn) o vetor aleatório. A distribuição gaussiana para essas variáveis é Φ = 1 p (2π)n det(Σ) exp \u0014−1 2(X − µ) ⊤Σ −1(X − µ) \u0015, (2.15) onde o vetor (X − µ) é conhecido como distância de Mahalanobis, uma definição de distância no espaço das variáveis aleatórias (21) e (X − µ)⊤ é o transposto de (X − µ). No caso especial de n variáveis não correlacionadas, a matriz de covariância se torna diagonal e a equação (2.15) se reduz a Φ = \" (2π)n nY i=1 Var[xi] #−1/2 exp \" −1 2 nX j=1 (xj − µi) 2(Var[xj]) −1# . Marginalizando sobre n − 1 variáveis, recuperamos a distribuição (2.13). A Figura 7a mostra uma distribuição gaussiana bidimensional; a Figura 7b mostra as cur- vas de nível de 1σ, 2σ e 3σ para essa distribuição. Interpretamos essas regiões como intervalos de confiança sob uma perspectiva bayesiana. A distribuição normal é recorrente ao longo de diferentes problemas, sobretudo nos que envolvem quantidades muito grandes de medições. Essa predisposição não é uma coincidência, mas decorre do teorema do Limite Central, que, de modo informal, declara: a soma de um número grande de variáveis aleatórias independentes é, ela mesma, uma variável aleatória com 27 Figura 6: Distribuição normal com as regiões de 1σ (a), 2σ (b) e 3σ (c) destacadas. 4 2 0 2 4 0.00 0.05 0.10 0.15 0.20 0.25 0.30 0.35 0.40 (a) 4 2 0 2 4 0.00 0.05 0.10 0.15 0.20 0.25 0.30 0.35 0.40 (b) 4 2 0 2 4 0.00 0.05 0.10 0.15 0.20 0.25 0.30 0.35 0.40 (c) Fonte: O próprio autor. distribuição de probabilidade gaussiana, independentemente da distribuição de probabilidade das variáveis que compõem a soma. Nas palavras de Wall e Jenkins “[...]a little bit of averaging will produce a Gaussian distribution of results no matter what the shape of the distribution from which the sample is drawn[...]. It is this theorem which leads us to describe our errors in the universal language of sigmas[...]” (2003, p.31, grifo dos autores) (22). Será o teorema do limite central que vai dar suporte para nossas escolhas de funções de verossimilhança gaussianas sobre os dados. Como exemplo do teorema, considere uma variável aleatória X com densidade de pro- babilidade uniforme. Um grupo de m pessoas realiza n medições cada e, individualmente, cal- culam a média amostral ¯x, de modo a terem, no final um conjunto com m médias amostrais. Se m e n forem suficientemente grandes, ¯x vai seguir uma distribuição de probabilidades gaussi- ana. Realizamos um exemplo a partir de um algoritmo escrito em Python por meio de números pseudo-aleatórios, Figura 8. 28 Figura 7: Distribuição gaussiana bidimensional 2 1 0 1 2 2 10 1 2 (a) 4 3 2 1 0 1 2 3 4 3 2 1 0 1 2 3 (b) a) Distribuição normal com duas variáveis não correlacionadas. b) Curvas de nível de 1σ, 2σ e 3σ da distribuição. Fonte: O próprio autor. Figura 8: Teorema do limite central (a) 0.480 0.485 0.490 0.495 0.500 0.505 0.510 0.515 0.520 0 20 40 60 80 100 120 140 (b) Neste exemplo, usamos m = 103 e n = 104. a) Um dos 1000 conjuntos de dados gerados. A distribuição foi normalizada. b) Histograma do número de ocorrências da média amostral normalizado com 20 colunas. A distribuição gaussiana de média µ = 0, 5 e desvio padrão σ = 0, 003 foi sobreposta (curva preta contínua). Fonte: O próprio autor. 2.3 MÉTODO DE MAXIMIZAÇÃO DA FUNÇÃO DE VEROSSIMILHANÇA Para construir os estimadores na seção 2.1, assumimos implicitamente uma interpreta- ção frequentista da probabilidade. Ainda sob essa perspectiva, somos confrontados com um problema: considere uma função f que depende de alguma maneira de n parâmetros. Realiza- mos medidas experimentais de f ; como encontrar estimadores para os parâmetros? Dependendo de como é f , essa tarefa pode não ter solução analítica e, além disso, pode não oferecer um cami- nho para uma solução numérica. A inferência bayesiana oferece uma ferramenta para encontrar soluções nessas situações através do método de maximização da função de verossimilhança (em- bora o caráter bayesiano não se encontre aqui, mas em informações a prioiri). Outro problema 29 na inferência frequentista é, segundo R. Trotta “frequentist results can depend on what the ex- perimenter thinks about the probability of data that have not been observed[...]Our inferences should not depend on the probability of what could have happened but should be conditional on whatever has actually occurred. ”(2017, p.28, grifo do autor)(23). A função de verossimilhança, L(D|{θi}) (sendo {θi} o conjunto de parâmetros do mo- delo teórico) é, ressaltando o que já foi dito, a probabilidade condicional de se obter esse conjunto D de dados dado um modelo teórico (i.e, uma hipótese H). Assumindo que essa probabilidade é máxima em regiões onde o modelo teórico melhor concorda com a realidade, podemos encontrar estimadores para os parâmetros do modelo encontrando os máximos da função L: ∂L ∂θi = 0 , ∂2L ∂θ2 i < 0. (2.16) O valor de θi que satisfaz (2.16) é um estimador para esses parâmetros. O estimador construído a partir desse método é consistente no sentido proposto na seção 2.1 (24). Na seção 1.3, dissemos que a grandeza que estávamos procurando é a probabilidade posterior. A maximização da posterior equivale a maximização da verossimilhança quando escolhemos distribuições anteriores uniformes (lembrando que P (D) é uma constante de nor- malização na (1.28)). A inferência bayesiana consiste em considerar as informações a priori sobre o problema ao maximizar a função de verossimilhança — ou seja, maximizar a distribui- ção posterior. O método da razão da função de verossimilhança é independente de informações a priori e, portanto, é considerado frequentista (ver (23) para mais informações). A probabilidade anterior é a contabilização de possíveis conhecimentos prévios do fenô- meno. A sua escolha varia para cada problema e a escolha de diferentes anteriores para o mesmo problema pode gerar resultados diferentes, de modo que o impacto dessa escolha deve ser che- cado a posteriori. Suponha que nosso modelo tenha um parâmetro θ. A escolha mais neutra possível é tomar P (θ) como uniforme, isto é, todos os valores possíveis de θ são igualmente prováveis. Entretanto, se no modelo construído observamos que a grandeza cuja qual coletamos os dados é dada por uma função f (θ), poderíamos associar então à P (f (θ)) uma distribuição uniforme, de modo que P (θ) seria P (θ) = \f \f \f \f df dθ \f \f \f \fP (f (θ)), (2.17) portanto, a associação de anteriores precisa ser feita com cuidado. A suposição de uma probabilidade anterior pode ter diversas origens. Podemos construir uma anterior a partir de “preconceitos” teóricos, a partir de dados e resultados de experimentos anteriores ou matrizes de Fisher (ver Capítulo 3). É preciso, no entanto, quantificar quanto do resultado final depende da escolha da anterior. O cerne da inferência bayesiana (e o maior contraste com a visão frequentista) é a pre- sença de probabilidades anteriores. Assintoticamente (i.e, no limite de infinitas medições), 30 os estimadores construídos a partir da posterior deixam de depender da anterior (Teorema de Bernstein-von Mises (25)). De acordo com Leclerq, Pisani e Wandelt “using less informative priors would be refusing to ‘climb on the shoulder of giants”’(2014, p.22)(26). No entanto, a inferência bayesiana não escapa de controvérsias. Existem alguns casos em que o comportamento no limite de infinitas medições da inferência bayesiana diverge do com- portamento da inferência frequentista. Esse problema é abordado pelo Paradoxo de Jeffreys– Lindley. De modo geral o paradoxo demonstra que, dado duas hipóteses, H0 e H1 por exemplo, que fazem afirmações diferentes sobre o valor de um parâmetro θ (H0 afirma que θ = θ0, sendo θ0 um valor determinado, enquanto que H1 toma θ ̸= θ0), a aplicação da inferência frequentista pode obter uma conclusão que rejeite a hipótese H0, enquanto que uma abordagem baseada na inferência bayesiana pode favorecer H0 sobre H1, no limite de infinitas medições. De acordo com C. Robert, nas palavras de Lindley 4, “we [can be] 95% confident [as frequentists] that θ ̸= θ0 but have 95% belief [as Bayesians] that θ = θ0” (LINDLEY,1957, p.187 apud ROBERT, 2013, p.217) (27). Ainda existem debates recentes acerca desse assunto e não há uma interpretação única sobre o paradoxo, pois, segundo E. Wagenmakers e A. Ly (2021, p.3) (28), existem inter- pretações puramente frequentistas e puramente bayesianas. Na opinião de C. Roberts (p.217), a origem do paradoxo se encontra no comportamento inaceitável de algumas distribuições a pri- ori em determinados contextos. De qualquer maneira, esse paradoxo evidencia a necessidade de ter-se controle sobre a influência da probabilidade anterior na análise a partir de diagnósticos que quantificam esse efeito. Podemos citar um desses, que, segundo L. Verde (2010, p.157)(29), relaciona a informação I contida na posterior relativa à anterior a partir da equação I = Z P (θ|D) log \u0014 P (θ|D P (θ) \u0015 dθ. (2.18) 4LINDLEY, Dennis V. A statistical paradox. Biometrika, v. 44, n. 1/2, p. 187-192, 1957. 31 3 PREVISÃO DE FISHER Em última instância, o objetivo de experimentos no contexto da cosmologia é encontrar valores médios e incertezas para os parâmetros cosmológicos e também testar modelos e hipóte- ses. Porém, dada as especificidades de um experimento, é possível determinar, antes da missão ser lançada, o quão bem ela irá restringi-los. Essa informação é obtida a partir da previsão de Fisher, desenvolvida em 1935 (30), método que abordamos neste capítulo. O método de previsão de Fisher é amplamente utilizado em cosmologia. Como alguns exemplos, temos observações de galáxias (31), (32), a Radiação Cósmica de Fundo (33), (34), lenteamento fraco (35), entre outros objetos. A previsão de Fisher demonstra sua utilidade so- bretudo durante o planejamento da missão, pois, caso o experimento idealizado não restrinja bem um certo parâmetro de interesse, é possível que alterações sejam feitas. Desse modo, é visível sua aplicabilidade no contexto que estudamos. Compreender bem o método de previsão de Fisher tem implicação direta no planejamento de missões futuras. O método de previsão de Fisher é uma consequência direta do método de maximização da função de verossimilhança, como vamos investigar. Formalmente, a matriz de Fisher representa uma estimativa do menor valor possível que a covariância sobre os parâmetros da teoria pode assumir. Para isso, é necessário apenas conhecer a matriz de covariância esperada para a missão. Neste capítulo, desenvolvemos a ideia desse método e encontramos equações analíticas para o caso de uma função de verossimilhança gaussiana nos dados. Nos baseamos principal- mente nas referências (29), (33), (36) e (18). 3.1 MATRIZ DE FISHER Considere um modelo teórico com n parâmetros (θ1, ..., θn) e uma função de verossimi- lhança L que se maximiza no ponto (¯θ1, ..., ¯θn). Para construir a função de verossimilhança, precisamos, a princípio, dos dados obtidos, dos estimadores para os parâmetros e da matriz de covariância do experimento. Veremos adiante que precisamos apenas da matriz de covariân- cia, pois os termos proporcionais aos dados medidos se anulam. Próximo do máximo, podemos expandir a função de verossimilhança, ou seu logarítmo, em uma série de Taylor, ln L ≈ ln L(¯θ1, ..., ¯θn) + 1 2 nX i,j=1 ∂2 ln L ∂θi∂θj \f \f \f \fθi=¯θi θj =¯θj (θi − ¯θi)(θj − ¯θj). (3.1) O termo de derivada primeira é nulo, em vista do requisito de maximização da função de veros- similhança. O termo de derivada segunda descreve a curvatura da função ao redor do máximo, a matriz Hessiana. Supondo que a função de verossimilhança ao redor do máximo seja aproxi- madamente gaussiana, vemos que se a curvatura (i.e, o inverso da covariância, como veremos abaixo) for grande, então a função rapidamente muda de valor quando nos afastamos do ponto de máximo; por outro lado, se for pequena, então a função demora para se afastar do ponto de 32 máximo. A taxa com que a função se afasta do máximo exprime a qualidade da restrição que o experimento terá. Se a curvatura for grande, então as incertezas envolvidas na determinação dos parâmetros serão pequenas; se for pequena, as incertezas serão grandes. O valor médio dessa tendência, conhecido como matriz de informação de Fisher, é a grandeza de interesse, Fij ≡ − ˝ ∂2 ln L ∂θi∂θj ˛ , (3.2) pois, como a verossimilhança depende dos dados, há flutuações no valor na matriz hessiana. O valor esperado desta, por outro lado, não depende dos dados e representa a precisão esperada sobre as incertezas nos parâmetros. A definição acima é válida para qualquer forma que a função de verossimilhança possa assumir. O inverso da matriz de Fisher é o limite inferior do possível valor da covariância entre dois parâmetros (29), Covij ≥ (F −1)ij. (3.3) A equação acima é conhecida como Desigualdade de Cramér-Rao. Intuitivamente, ela existe pois, para calcular a matriz de Fisher, ignoramos termos de ordem superior à segunda na ex- pansão. Se a função de verossimilhança for gaussiana nos parâmetros, então a desigualdade se torna uma igualdade, pois os termos de ordem 3 para cima serão nulos. Para exemplificar a relação acima, resolvemos explicitamente o caso de uma função de verossimilhança gaussiana multivariada na qual a matriz de covariância não depende dos parâ- metros, isto é, L(¯θ1, ..., ¯θN ) = 1 p (2π)N det(Σ) exp \" −1 2 NX i,j (θi − ¯θi)(Σ −1)ij(θj − ¯θj) # . (3.4) Derivando ln L em relação a θm, ∂ ln L ∂θm = −1 2 NX i,j [δim(Σ −1)ij(θj − ¯θj) + (θi − ¯θi)(Σ −1)ijδjm]. Derivando em relação a θn, ∂2 ln L ∂θm∂θn = −1 2 NX i,j [δim(Σ −1)ijδjn + δin(Σ −1)ijδjm] = −(Σ −1)mn. Neste contexto, a matriz de informação de Fisher é Fmn = − ˝ ∂2 ln L ∂θm∂θn ˛ = (Σ−1)mn. (3.5) Observamos que a equação acima concorda com a (3.3), no caso da função de verossimilhança 33 gaussiana. O fato da matriz de informação de Fisher oferecer um limite inferior para o erro per- mite mudanças na construção do experimento para diminuir essa incerteza. Nas palavras de A. Heavens, “So if you want to measure some quantity with an accuracy of a metre, and a Fisher analysis tells you the error bar is the size of Belgium, give up”(2010, p.12) (37). Uma complicação existente nessa análise é a correlação de um parâmetro com outros. Se a matriz hessiana (a curvatura) for diagonal, o caso mais simples, então os parâmetros não são correlacionados; se, no entanto, houver termos não diagonais, existe correlação entre os parâmetros, que dificulta a distinção do que é efeito de um parâmetro e do que é de outro. A adição de novas informações à análise via outros experimentos se dá pela multiplicação das funções de verossimilhança de cada experimento. Desse modo, como a matriz de Fisher depende do logaritmo da verossimilhança, a matriz de Fisher resultante será a soma das matrizes para cada experimento. Note que calculamos a matriz de Fisher a partir da função de verossimilhança. Podemos fazer semelhante cálculo para a probabilidade posterior. Em decorrência do fato de que as proba- bilidades anteriores aparecem na equação (1.28) como um fator multiplicativo e P (D) é apenas uma fator de normalização, vemos que a matriz de Fisher F calculada a partir da posterior é F = Π + F, (3.6) sendo Π, Π ≡ − ˝ ∂2Panterior ∂θi∂θj ˛ . (3.7) A inversão da matriz de Fisher para determinar as incertezas pode ser trabalhosa demais, sob um ponto de vista computacional. Contudo, se estamos interessados na incerteza de apenas dois parâmetros, então podemos ignorar as linhas e as colunas dos outros parâmetros e inverter apenas as linhas e as colunas referentes aos parâmetros desejados; isso equivale a marginalizar sobre os parâmetros desinteressantes (36), (29). 3.2 CASO GAUSSIANO Supomos que a função de verossimilhança seja gaussiana nos dados e com variáveis não correlacionadas. A suposição de comportamento gaussiano não é absurda, sobretudo quando levamos em conta o teorema do limite central e o grande volume de dados que um experimento acumula; a suposição de não correlação é, entretanto, limitante. Contudo, os desenvolvimentos realizados aqui são equivalentes ao caso correlacionado, com certas modificações, como reali- zado por Tegmark e colaboradores em (33). As equações a seguir são reprodução das equações em (33). Neste contexto, a função de verossimilhança tem a forma 34 L = 1 p (2π)n det C exp\u0014 −1 2 Tr\u0000 C −1∆ \u0001 \u0015, (3.8) sendo C a matriz de covariância (diagonal) e ∆ uma matriz com componentes ∆mn ≡ (xm − µn)(xn − µn). (3.9) Note que x podem ser visto como dados simulados do experimento. Todavia, a matriz de Fisher não pode depender deles e, de fato, ela não depende, como demonstrado adiante. Ignorando o fator (2π)n/2, o logaritmo da função de correlação é − 2 ln L = ln det C + Tr\u0000 C −1∆ \u0001 . (3.10) Usando a relação ln det C = Tr ln C, vemos que − 2 ln L = Tr\u0000 ln C + C −1∆ \u0001 . (3.11) Em seguida, derivamos em relação a θi e usamos a relação ∂C −1 ∂θi = −C −1 ∂C ∂θi C −1. (3.12) Isso nos leva a − 2 ∂ ln L ∂θi = Tr\u0012 C −1 ∂C ∂θi − C −1 ∂C ∂θi C −1∆ + C −1 ∂∆ ∂θi \u0013 . (3.13) Derivando agora em relação a θj, −2 ∂2 ln L ∂θi∂θj = Tr \u0014 −C −1 ∂C ∂θi C −1 ∂C ∂θi + C −1 ∂2C ∂θi∂θj + C −1 \u0012 ∂C ∂θi \u00132 C −1∆ − C −1 ∂2C ∂θi∂θj C −1∆+ C −1 ∂C ∂θi C −1 ∂C ∂θi C −1∆ − C −1 ∂C ∂θi C −1 ∂∆ ∂θi − C −1 ∂C ∂θi C −1 ∂∆ ∂θi + C −1 ∂2∆ ∂θi∂θj \u0015 . (3.14) Finalmente, usando a propriedade Tr(AB) = Tr(BA) e tomando o valor esperado, a matriz de Fisher é Fij = 1 2 Tr\u0014AiAj + C −1 ˝ ∂2∆ ∂θi∂θj ˛\u0015 , (3.15) sendo Ai = ∂ ln C/∂θi. A equação (3.15), embora tendo sido deduzida para uma matriz de co- variância diagonal, também é aplicável para uma matriz de covariância geral, como demonstrado 35 em (33). 36 4 CADEIAS DE MARKOV VIA MONTE CARLO Tendo em mãos os dados experimentais e um modelo teórico, conseguimos construir uma função de verossimilhança. Com esta e a probabilidade anterior, encontramos, a menos de uma constante de normalização, a probabilidade posterior (equação (1.28), que é a probabilidade associada aos parâmetros do modelo considerando os dados coletados. Com isso, temos todas as informações sobre o problema; para encontrar os valores de interesse, basta aplicar o ferramental desenvolvido no Capítulo 2. Contudo, dependendo da complexidade do problema, investigar diretamente a posterior pode ser trabalhoso, sob uma ótica de eficiência computacional. Para perceber isso, relembramos um comentário feito na seção 1.2 sobre a equação (1.12): o número mínimo de integrações para se encontrar o valor esperado de um parâmetro é o número de parâmetros livres no modelo. Com isso, somado ao fato de que a posterior pode ser uma função complicada em relação aos parâmetros, temos um problema que requer capacidade computacional além do razoável. Impedidos de utilizar a posterior como ferramenta direta de análise, investigamos alter- nativas menos custosas. Uma alternativa mais eficiente é um método de tomar amostras da distri- buição posterior, isto é, sortear pontos a partir da distribuição posterior, e utilizar as ferramentas construídas no capítulo 2 para encontrar estimadores para os valores esperados. Esse processo é mais eficiente pois calcular a posterior em pontos específicos — mesmo que em quantidade elevada — requer menos tempo que calcular numericamente integrais multivariadas. Figura 9: Amostras de uma distribuição gaussiana bidimensional 2 0 2 2 1 0 1 2 3 (a) 3 2 1 0 1 2 3 2 1 0 1 2 3 0 10 20 30 40 50 60 (b) a) Distribuição gaussiana com média zero e matriz de covariância igual a identidade com pontos sorteados ale- atoriamente seguindo a distribuição; b) Histograma em duas dimensões da Figura 9a com as curvas de nível de 1σ e 2σ. Veja que mais pontos caem próximos do máximo da distribuição. Um algoritmo de MCMC deve ter comportamento semelhante. Fonte: O próprio autor. 37 Essa técnica, conhecida como cadeias de Markov via Monte Carlo — Markov chain Monte Carlo (MCMC) —, consiste em tomar pontos que seguem a distribuição posterior e cal- cular a média amostral, equação (2.2), para encontrar valores estimados dos parâmetros da teoria. O método de Monte Carlo se refere a processos que envolvem números aleatórios e cadeias são sequências de números aleatórios. Já as cadeias de Markov são cadeias cujo o próximo ele- mento a ser introduzido só depende do elemento atual da cadeia. Nesse sentido, um algoritmo de MCMC vai gerar números aleatórios que seguem a distribuição de probabilidade posterior e vai construir cadeias de Markov de modo que a probabilidade do ponto θ = (θ1, ..., θn) (onde θi se refere aos parâmetros do modelo) ser aceito na cadeia seja proporcional à P (θ|D). A Figura 9 mostra a ideia desse processo para uma distribuição gaussiana de duas variáveis. Esquematicamente, um algoritmo de MCMC vai gerar um primeiro número aleatório qualquer que será o primeiro elemento da cadeia, θ0. Em seguida, com base em θ0, um novo elemento, θ1, será sorteado e, com base em algum método que analisa se P (θ1|D) é maior ou menor P (θ0|D), a amostra θ1 será ou não aceita na cadeia. Caso não seja aceita, θ0 é repetido. Após vários sorteios, a cadeia irá convergir para amostras próximas dos pontos onde a posterior é maior. O método apresenta uma probabilidade de transição K(θi+1|θi) que informa a probabi- lidade do próximo membro da cadeia ser θi+1 dado que o membro atual é θi. Essa probabilidade deve respeitar a relação de balanceamento detalhado P (θi|D)K(θi+1|θi) = P (θi+1|D)K(θi|θi+1), (4.1) pois ela garante que, assintoticamente, a cadeia preserve a distribuição posterior, condição que implica que a probabilidade da cadeia aceitar θj dado que esteja em qualquer outro ponto é P (θj|D) e pode ser escrita como P (θj|D) = Z dθiP (θi|D)K(θj|θi), (4.2) substituindo a equação (4.1) em (4.2), P (θj|D) = P (θj|D) Z dθiK(θi|θj), (4.3) e a probabilidade de que a cadeia se mova para qualquer ponto da distribuição dado que está em θi é 1. Logo a igualdade é satisfeita e a condição de balanceamento detalhado de fato garante que as amostras continuam a ser obtidas assintoticamente a partir da posterior. 4.1 ALGORITMO DE METROPOLIS–HASTINGS Existem diversas escolhas de probabilidade de transição, dando origem a disversos méto- dos de MCMC diferentes. Um deles é o algoritmo de Metropolis–Hastings, desenvolvido por N. Metropolis (38) e expandido por W.K Hastings (39). Ele propõe uma probabilidade de transição 38 K(θi+1|θi) = α(θi+1|θi)q(θi+1|θi), (4.4) onde α(θi+1|θi) = min \u00121, P (θi+1|D)q(θi|θi+1) P (θi|D)q(θi+1|θi) \u0013 . (4.5) A distribuição q(θi+1|θi) é conhecida como densidade proposta, e representa a distri- buição de onde os possíveis elementos da cadeia serão sorteados. A distribuição α oferece um critério de seleção de novos elementos da cadeia, definindo uma probabilidade de aceitação de novos elementos. A ideia intuitiva do algoritmo fica clara quando tomamos uma densidade proposta simé- trica, isto é, com q(θi|θi+1) = q(θi+1|θi), de modo que α(θi+1|θi) = min \u00121, P (θi+1|D) P (θi|D) \u0013 . (4.6) Se P (θi+1|D) > P (θi|D), isto é, se a posterior é maior em θi+1 do que em θi, então a proba- bilidade de que θi+1 entre na cadeia é 1, visto que P (θi+1|D)/P (θi|D) > 1. No entanto, se P (θi+1|D) < P (θi|D), a probabilidade de θi+1 ser aceito na cadeia é α = P (θi+1|D) P (θi|D) . (4.7) Se P (θi+1|D) for muito menor que P (θi|D) então a probabilidade de θi+1 ser aceito é muito pequena. O algoritmo move a cadeia para pontos cada vez mais próximos da região onde a posterior é maior por meio desse critério. É preciso verificar se essa probabilidade de transição satisfaz a condição de balancea- mento detalhado. Da relação (4.1), P (θi+1|D) P (θi|D) = α(θi+1|θi)q(θi+1|θi) α(θi|θi+1)q(θi|θi+1), (4.8) se P (θi+1|D) > P (θi|D), α(θi+1|θi) = 1, logo, P (θi|D)q(θi+1|θi) P (θi+1|D)q(θi|θi+1) = α(θi|θi+1), (4.9) condizente com (4.6). De modo similar, caso P (θi+1|D) < P (θi|D), também vemos que a relação é satisfeita. A Figura 10 demonstra como o algoritmo induz a cadeia a aceitar pontos com mais frequência ao redor do máximo da distribuição. Exploramos com mais detalhes o caso repre- sentado aqui na seção 5.3. A densidade proposta deve ser escolhida de modo a maximizar a taxa de aceitação de novos membros na cadeia. Escolhas ruins dessa grandeza podem impedir que o algoritmo ex- 39 Figura 10: Comportamento de um algoritmo de MCMC 1.0 0.9 0.8 0.7 0.6 0.5 0.4 0.3 0.2 1 0.20 0.25 0.30 0.35 0.40 0.45 0.502 (a) 1.0 0.9 0.8 0.7 0.6 0.5 0.4 0.3 0.2 1 0.20 0.25 0.30 0.35 0.40 0.45 0.502 (b) 1.0 0.9 0.8 0.7 0.6 0.5 0.4 0.3 0.2 1 0.20 0.25 0.30 0.35 0.40 0.45 0.502 (c) As primeiras a) 10, b) 100 e c) 1000 amostras obtidas pelo algoritmo de Metropolis–Hastings, com base em uma posterior gaussiana. No período inicial, o algoritmo explora o espaço e, conforme mais pontos são aceitos, vemos que as amostras tendem a se concentrar onde a posterior é maior. Fonte: O próprio autor. plore regiões onde a posterior não é negligenciável ou impedir que ela encontre a região onde a posterior é maior. Também pode diminuir a taxa de aceitação ou fazer com que o algoritmo te- nha que dar muitos passos para cobrir a região de interesse (40). Sua escolha também é sensível quando os parâmetros são correlacionados. Em geral, escolhe-se uma densidade proposta com um formato parecido com a posterior. Por exemplo, se a posterior for gaussiana, uma escolha de densidade proposta razoável (com uma taxa de aceitação de aproximadamente 25%) é, segundo (41), uma gaussiana com largura de ∼ 2, 4/ √n, sendo n o número de parâmetros. Outra maneira de encontrar a densidade proposta é realizar uma cadeia exploratória an- terior e, com base na matriz de covariância estimada, definir a densidade proposta. Ou então aproveitar a fase inicial da cadeia — “burn-in phase” —, quando o algoritmo ainda está explo- rando o espaço, para construir a densidade proposta. Para manter a característica de uma cadeia 40 de Markov, essa cadeia exploratória, ou os pontos da fase inicial, devem ser excluídos da análise. Uma vez que se começa a cadeia de Markov, a densidade proposta não pode ser modificada. Por fim, após esse processo, tendo-se uma cadeia de amostras da posterior, toma-se a média amostral e a covariância para encontrar as grandezas de interesse. 4.2 TESTES DE CONVERGÊNCIA A utilização de um algoritmo de MCMC só é justificada se o método for de fato seguro. Podemos usar as amostras e as ferramentas do Capítulo 2 graças ao teorema do limite central, no entanto, não sabemos se a cadeia explorou corretamente todas as regiões do espaço dos parâme- tros. Para adquirir um grau de confiança melhor no resultado, podemos aplicar alguns testes de convergência para averiguar a consistência dos resultados. Segundo Lewis e Bridle (40), esses testes de convergência são necessários mas não suficientes para demonstrar a consistência dos resultados. Talvez o teste mais simples, porém, ressaltando, não suficiente, consiste em gerar diversas cadeias e comparar os resultados entre si. Outro teste é o método de diagnóstico de convergência de Gelman–Rubin (42). Gelman e Rubin sugerem que seja gerado mais de uma cadeia e que seja descartado a primeira metade dos elementos, ou seja, se iniciamos com M cadeias, cada uma com 2N elementos, descartamos os primeiro N elementos. Calculamos a média ¯θi, com i ∈ [1, M ] em cada cadeia e a média das médias, ¯Θ, ¯Θ = 1 M MX i=1 ¯θi. (4.10) Em seguida, calcula-se a variância da média para cada cadeia, Bi = Var[¯θi], i ∈ [1, M ], de modo que B1 é a variância da média na cadeia 1, B2, na segunda, etc. Também calcula-se a média dessas variâncias, ¯B, ¯B = 1 M MX i=1 Bi. (4.11) Por fim, calcula-se a variância da média ¯Θ, Var[ ¯Θ]. O fator que indica uma possível convergência é R: R = \u0012N − 1 N \u0013 ¯B + Var[ ¯Θ] N \u00121 + 1 M \u0013 ¯B . (4.12) Obtém-se a convergência quando R se aproxima de 1. O cenário mais problemático para a utilização de MCMC ocorre quando os parâmetros são correlacionados, pois o algoritmo não consegue distinguir com eficiência regiões de dege- nerescência, e pode dar resultados errados. É possível, em alguns casos, realizar transformações nos parâmetros e explorar o espaço de parâmetros menos correlacionados. 41 5 APLICAÇÕES Passamos agora ao principal objetivo deste trabalho, que é o de aplicar as ferramentas estatísticas dos capítulos anteriores em problemas da cosmologia. 5.1 ESTIMATIVA DE SINAIS A Radiação Cósmica de Fundo (RCF) é uma das maiores fontes de informações cosmo- lógicas do Universo. Isso decorre da precisa descrição dos seus mecanismo físicos (43), (44), (45) e da capacidade tecnológica de efetivamente medi-la, combinação que permite a compa- ração entre a cosmologia teórica e os dados reais do Universo. Durante as últimas décadas, as missões COBE, WMAP e Planck mediram as anisotropias da distribuição de temperatura da RCF com precisão crescente, o que garantiu à comunidade acesso a informações tais como a idade do universo, sua composição e geometria. Um dos desafios para as próximas décadas se volta agora à determinação das flutuações de polarização da RCF, o que em parte justifica um completo domínio dos métodos estatísticos usados na extração de parâmetros cosmológicos. Nesta seção, com base na referência (18), expomos métodos de análise e interpretação dos dados da RCF em contextos simplificados. Exploramos métodos de separação de sinais e encontramos um estimador para o espectro de potências da RCF. A RCF é uma radiação eletromagnética com espectro de corpo negro detectada predomi- nantemente na faixa das microondas. O sinal detectado é uma composição do sinal propriamente dito (i.e., sinal de origem cosmológica) e ruídos de origem astrofísica e experimental. Uma fonte importante de incerteza decorre da resolução do detector, que compacta o sinal observado em uma área A da esfera celeste em uma unidade fundamental, o pixel, visto que o equipamento não consegue distinguir pontos abaixo de sua resolução nominal. A Figura 11 mostra o mapa de tem- peraturas da Radiação Cósmica de Fundo para três diferentes missões com aberturas angulares diferentes. O detector funciona por um tempo determinado, coletando ao todo um conjunto com N dados, {dt}, sendo t referente à t-ésima medição. O detector não irá observar um único pixel por vez, de modo que cada dado é uma composição do sinal de cada pixel observado com um ruído experimental ηt, dt = MX i=1 Ptisi + ηt, (5.1) sendo si o sinal contido no pixel i. A matriz P relaciona o conjunto dos dados com os dos sinais. Ela é uma matriz nt ×ni, sendo nt o número de medições feitas e ni o número de pixels medidos. A equação (5.1) não contabiliza os erros que não agem linearmente sobre o sinal. Estamos interessados em encontrar um estimador para o sinal si. Para isso, considere que o erro experimental é uma variável aleatória gaussiana com média 0 e matriz de covariância 42 Figura 11: Mapas de temperatura da Radiação Cósmica de Fundo (a) COBE (b) WMAP (c) Planck a) O telescópio COBE foi lançado em 1989 com abertura angular de cerca de 6◦ (46); b) WMAP, lançado em 2001, apresentava uma abertura angular de cerca de 0, 15◦ (3); c) O Planck, missão mais recente lançada em 2009, apresentava uma abertura angular de cerca de 0, 07◦ (4). Para calcular esses valores, usamos que a abertura angular é proporcional a 180◦/lmax, sendo lmax o maior multipolo alcançado com precisão pela missão. Fonte: NASA. N conhecida. Com isso, ηt apresenta uma densidade de probabilidade proporcional à exp \" −1 2 NX t,t′=1 ηt(N −1)tt′ηt′ # . (5.2) Portanto, a função de verossimilhança L({dt}|{si}) é proporcional à exp \" −1 2 X i,j,t,t′(dt − Ptisi)(N −1)tt′(dt′ − Pt′jsj) # . (5.3) Um bom estimador para o sinal deve maximizar L. Alternativamente, como o logaritmo é uma função monótona, maximizar a equação (5.3) equivale a minimizar − 2 ln L = X i,j,t,t′(dt − Ptisi)(N −1)tt′(dt′ − Pt′jsj). (5.4) Derivando a equação acima em relação a sk e igualando a 0: 43 − X j,t,t′ Ptiδki(N −1)tt′(dt′ − Pt′jsj) − X i,t,t′ Pt′jδkj(N −1)tt′(dt − Ptisi) = 0, (5.5) ou, em notação matricial, P ⊤N −1(d − P s) = 0 ⇒ ˆs = (P ⊤N −1P ) −1P ⊤N −1d. (5.6) Observando que a derivada segunda de −2 ln L é maior que zero e definindo CN ≡ (P ⊤N −1P ) −1, (5.7) o estimador que procuramos é ˆs = CN P ⊤N −1d. (5.8) Vamos averiguar agora se esse estimador é enviesado. Usando d = P s + η, ⟨s⟩ = s e ⟨η⟩ = 0, segue da definição do estimador que ⟨ˆs⟩ = CN P ⊤N −1 ⟨d⟩ = P −1N (P ⊤) −1P ⊤N −1 ⟨d⟩ = s. (5.9) Portanto, o estimador não é enviesado. Podemos também calcular a matriz de covariância do estimador do sinal, ⟨ˆsiˆsk⟩ − ⟨ˆsi⟩ ⟨ˆsk⟩ = X jtt′mpp′(CN )ijP ⊤ jt (N −1)tt′(CN )kmP ⊤ mp(N −1)pp′ (⟨dt′dp′⟩ − ⟨dt′⟩ ⟨dp′⟩) = X t′p′ P −1 it′ P −1 kp′ (⟨dt′dp′⟩ − ⟨dt′⟩ ⟨dp′⟩) , mas, ⟨dt′dp′⟩ − ⟨dt′⟩ ⟨dp′⟩ = Nt′p′, portanto 44 ⟨ˆsiˆsk⟩ − ⟨ˆsi⟩ ⟨ˆsk⟩ = X t′p′ P −1 it′ Nt′p′(P ⊤) −1 p′k, de modo que a matriz de covariância do estimador do sinal é ⟨ˆsiˆsk⟩ − ⟨ˆsi⟩ ⟨ˆsk⟩ = (CN )ik. (5.10) A equação (5.8) oferece uma ideia de como os mapas apresentados na Figura 11 são construídos. Podemos explorar um caso mais simplificado desse problema. Primeiro, considere que a matriz de covariância do ruído é diagonal e com todos os elementos dados por N . Desse modo, a matriz de covariância do estimador do sinal é (CN )ij = N X t PtiPtj !−1 . (5.11) Supondo agora que o detector observa apenas um pixel por observação, a matriz P só vai apre- sentar um elemento não nulo por linha e o termo somado na equação acima só não é zero se i = j. Tomando os valores não nulos da coluna i de P todos iguais a p, uma constante, temos (CN )ii = N mip , (5.12) sendo mi o número de vezes que o detector observou o pixel i. Observamos, assim, que o desvio padrão do estimador do sinal é inversamente proporcional à raiz quadrada do número de amostras que temos do pixel i, em concordância com a equação (2.6), o desvio padrão da média. De fato, da equação (5.8), ˆsi = X t N mip2 p N dt = 1 mi X t (Pti)−1dt, (5.13) uma média dos dados (levando em conta a calibração). Esse resultado é esperado, pois, da teoria apresentada no capítulo 2, sabemos que para um conjunto de dados de uma mesma grandeza física, o estimador da média populacional é dado por 2.2 e seu erro cai com a raiz quadrada do número de amostras. 5.2 FUNÇÃO DE CORRELAÇÃO Como vimos, a distribuição gaussiana só tem dois parâmetros livres: a média e a vari- ância. No modelo padrão da cosmologia, a distribuição das flutuações de temperatura da RCF é uma variável gaussiana de média zero e variância não nula, em primeira ordem. Portanto, nesta aproximação, a função de correlação das temperaturas da RCF codifica todas as informações conhecidas sobre esse objeto. A função de correlação teórica é construída com base nos proces- 45 sos físicos que influenciam os fótons da RCF antes e depois do período de recombinação5. Ela também oferece um caminho de comparação entre a cosmologia teórica e o Universo real, pois a função de correlação observada pode ser construída com base na radiação medida. Para isso, é preciso interpretar e estimar os sinais da Radiação Cósmica de Fundo. Nesta seção pretendemos usar o formalismo estatístico dos capítulos anteriores para construir um estimador para a função de correlação da RCF em um modelo simples que in- clui a resolução do experimento e o ruído experimental, assumindo o caso simples de um ruído linear. Todo o desenvolvimento presente aqui é uma reprodução do conteúdo contido em (18). Considere Θ(ˆn) a flutuação de temperatura da Radiação Cósmica de Fundo teórica na direção ˆn da esfera celeste: Θ(ˆn) ≡ δT (ˆn) T0 = T (ˆn) − T0 T0 (5.14) sendo T (ˆn) a temperatura na direção ˆn e T0 a temperatura média da Radiação Cósmica de Fundo. Essa função é uma variável aleatória que, no modelo cosmológico padrão, é tomada como gaussi- ana. Portanto, podemos caracterizá-la completamente encontrando sua média e sua covariância. Da definição (5.14), sua média é nula. A covariância entre as flutuações de temperatura em duas direções ˆn1 e ˆn2 na esfera celeste é dada pela função de correlação de dois pontos: C(ˆn1, ˆn2) = ⟨Θ(ˆn1)Θ(ˆn2)⟩ = X l (2l + 1) 4π ClPl(cos γ), (5.15) sendo cos γ = ˆn1 · ˆn2. Isso decorre da hipótese de isotropia estatística. Por ser uma função na esfera, podemos expandir as flutuações de temperatura em harmô- nicos esféricos: Θ(ˆn) = X lm almYlm(ˆn), (5.16) sendo o coeficiente alm alm = Z dΩY ∗ lm(ˆn)Θ(ˆn). (5.17) Na aproximação gaussiana, a partir da média e da covariância das flutuações de temperatura, esses coeficientes satisfazem, ⟨alm⟩ = 0, (5.18) ⟨almal′m′⟩ = δll′δmm′Cl. (5.19) 5A recombinação é o período no qual a luz desacopla da matéria bariônica, isto é, cessa-se o fenômeno de espalhamento da luz com os elétrons livres. 46 Figura 12: Espectro angular de potências da Radiação Cósmica de Fundo. 500 1000 1500 2000 2500 Momento de multipolo l 101 0 1000 2000 3000 4000 5000 6000l(l+1)Cl/2[K2] Entre l = 2 a l = 30, usamos uma escala logarítmica no eixo x. Para multipolos superiores, usamos uma escala linear. Os pontos são os dados coletados pela missão Planck e a linha é o melhor fit dos parâmetros cosmológicos feito pela missão Planck. Fonte: O próprio autor. O termo Cl é conhecido como espectro angular de potências de temperatura, a transformada de Legendre da função de correlação. Veja a Figura 12. Do sinal estimado com os dados obtidos, constrói-se uma função de flutuações de tem- peratura observada ∆(ˆn). Essa função contém informações sobre a flutuação de temperatura real, porém também deve sofrer o efeito da resolução finita do equipamento de medição e das incertezas relacionadas. Podemos modelar esses efeitos a partir da equação ∆(ˆn) = Z dΩ′Θ(ˆn ′)B(ˆn, ˆn ′) + η(ˆn). (5.20) A equação acima indica que a luz observada na direção ˆn é a soma do ruído com o sinal, sendo este último uma convolução do sinal propriamente dito com uma função B(ˆn, ˆn′), chamada de função de resolução, a qual contabiliza a resolução do equipamento. Tipicamente, essa função é fortemente localizada nos pontos n ′ ≈ n, mas os detalhes variam de acordo com as especi- ficidades de cada experimento. Por simplicidade, iremos supor neste trabalho que B(ˆn, ˆn ′) é isotrópica, ou seja B(ˆn, ˆn ′) = B(ˆn · ˆn ′) = X l BlPl(cos ϑ) , (5.21) onde cos ϑ = ˆn · ˆn ′. Supondo que cada pixel cobre uma área muito pequena da esfera celeste, podemos des- prezar os efeitos de pixelização e tomar ∆(ˆn) como uma função contínua. Por estar definida na esfera, podemos expandi-la em harmônicos esféricos com coeficientes 47 aobs lm = Z dΩY ∗(ˆn)∆(ˆn). (5.22) Agora, expandimos as funções Θ, B e η e aplicamos na equação (5.20). Utilizando o teorema da adição dos harmônicos esféricos, Pl(cos γ) = 4π 2l + 1 lX m=−l Ylm(ˆn)Y ∗ lm(ˆn ′), (5.23) podemos reescrever a equação (5.22) como aobs lm = almBl + ηlm. (5.24) Para prosseguir, precisamos determinar Bl e ηlm. Já vimos que a função de resolução é fortemente localizada nas regiões ao redor de ˆn; que, por contabilizar os efeitos da resolução do equipamento, é proporcional à resolução angular do mesmo e que, por hipótese, é isomórfica. Podemos modelar todas essas características em uma função tipo: Bl = exp \u0012 −l2 2 θ2 resolução \u0013 , (5.25) isto é, uma gaussiana, sendo θresolução um ângulo que, grosso modo, mede a resolução angular do equipamento. Vemos que essa função tem as características que queremos. Em relação ao erro ηlm, supomos que seja uma variável aleatória gaussiana, que tenha média 0 e uma matriz de covariância N (ˆn). Com isso, ela apresenta um espectro de potências: ⟨ηlmη∗ l′m′⟩ = Nlδll′δmm′. (5.26) Portanto, conseguimos relacionar as grandezas aobs lm e alm. Com isso e a partir da hipótese de que a incerteza tenha média 0, conseguimos construir a probabilidade condicional: P (aobs lm |alm) = 1 √ 2πNl exp \u0012 −|aobs lm − almBl| 2 2Nl \u0013. (5.27) Estamos interessados em encontrar uma relação entre aobs lm e o espectro de potências Cl. Ou seja, estamos interessados em encontrar a função de verossimilhança L(aobs lm |Cl). Para encontrá-la, fazemos L(aobs lm |Cl) = lY m=−l Z dalmP (aobs lm , alm|Cl). (5.28) Das equações (5.18) e (5.19), P (alm|Cl) = 1 √2πCl exp \u0012− a2 lm 2Cl \u0013 . (5.29) 48 Logo, L(aobs lm |Cl) = lY m=−l Z dalmP (aobs lm |alm)P (alm|C(l)) = 1 2π√NlCl lY m=−l Z dalm exp\u0014 −(aobs lm ) 2 − 2aobs lm Blalm + (Blalm)2 2Nl − a2 lm 2Cl \u0015 . Utilizando a integral tabelada na referência (47) Z ∞ −∞ dxe−ax2+bx+c = r π a exp \u0012 b2 4a + c\u0013 e identificando a = (Nl + B2 l Cl)/(2NlCl), b = −aobs lm Bl/Nl e c = −(aobs lm )2/2Nl, chegamos em L(aobs lm |Cl) = \u0002 2π(ClB2 l + Nl) \u0003−(2l+1)/2 exp −1 2 lX m=−l |aobs lm | 2 B2 l Cl + Nl ! . (5.30) Supondo que a probabilidade anterior seja uniforme, maximizar a função de verossimilhança acima em relação ao espectro de potências equivale a maximizar a posterior. Derivando ln L em relação a Cl e igualando a zero, obtemos um estimador para o espectro de potências, ln L = −(2l + 1) 2 ln[2π(ClB2 l + Nl)] − 1 2 lX m=−l |aobs lm | 2 B2 l Cl + Nl ⇒ ∂ ln L ∂Cl = −(2l + 1) 2 B2 l ClB2 l + Nl + 1 2 lX m=−l |a obs lm | 2 (B2 l Cl + Nl)2 B2 l = 0 (5.31) portanto, ˆCl = B−2 l 1 2l + 1 lX m=l |aobs lm | 2 − Nl ! . (5.32) Derivando novamente a equação (5.31) e substituindo ˆCl vemos que a equação (5.32) é de fato um ponto de máximo. Verificaremos agora se esse estimador é enviesado. Vemos que D ˆClE = B−2 l 1 2l + 1 lX m=−l |aobs lm | 2\u000b − Nl ! , (5.33) mas, da equação (5.24), e supondo que alm e ηlm são independentes, 49 |aobs lm | 2\u000b = B2 l ⟨alma∗ lm⟩ + ⟨ηlmη∗ lm⟩ = B2 l Cl + Nl, (5.34) logo, D ˆClE = Cl, (5.35) ou seja, o estimador não é enviesado. Procuramos agora a variância desse estimador. Temos que Var[ ˆCl] = ˝B−4 l \"\u0012X |aobs lm | 2 2l + 1 \u00132 − 2Nl X |aobs lm | 2 2l + 1 + N 2 l # ˛ − C 2 l , (5.36) mas, a partir da equação (5.34), os três últimos termos da equação acima resultam em −B−4 l ˝ 2Nl X |aobs lm | 2 2l + 1 + N 2 l ˛ − C 2 l = −(Cl + B−2 l Nl)2. Com o intuito de calcular o primeiro termo, vemos que * lX m=−l |aobs lm | 2 2l + 1 !2+ = * lX m,m′=−l |aobs lm | 2|aobs lm′| 2 (2l + 1)2 + = 1 (2l + 1)2 X m̸=m′ |aobs lm | 2\u000b |aobs lm′| 2\u000b + 1 (2l + 1)2 X m |aobs lm | 4\u000b . Podemos encontrar o primeiro termo da equação acima a partir da equação (5.34), 1 (2l + 1)2 X m̸=m′ |aobs lm | 2\u000b |aobs lm′| 2\u000b = 2l 2l + 1 (B2 l Cl + Nl) 2. (5.37) Para encontrar o segundo termo, usamos a equação (1.11) notando que a distribuição de proba- bilidade da variável aleatória aobs lm é L(aobs lm |Cl), dado por (5.30). Com isso, |aobs lm | 4\u000b = \u0002 2π(ClB2 l + Nl) \u0003−(2l+1)/2 lY m′=−l Z daobs lm′|aobs lm | 4 exp\u0012 − |aobs lm′| 2 2(B2 l Cl + Nl) \u0013, (5.38) que resulta em |aobs lm | 4\u000b = 3(B2 l Cl + Nl)2, (5.39) de modo que 50 * lX m=−l |aobs lm | 2 2l + 1 !2+ = 2l + 3 (2l + 1) (ClB2 l + Nl) 2. (5.40) A variância é, portanto, Var[ ˆCl] = 2 2l + 1 (Cl + NlB−2 l ) 2. (5.41) Como alm e al′m são independentes, a matriz de covariância é diagonal: Σll′ = δll′Var[ ˆCl]. (5.42) O estimador do espectro de potências pode ser utilizado para construir o gráfico da Figura 12. Para multipolos l < 30, temos o conhecido platô do efeito Sachs–Wolfe (48), pois, em grandes escalas, o efeito do potencial gravitacional é dominante sobre a Radiação Cósmica de Fundo. Essa região é sensível a parâmetros relacionados com a inflação. A partir de multipolos l > 30, se encontram os picos acústicos, sensíveis aos outros parâmetros cosmológicos. Com isso, finalizamos nosso objetivo de encontrar um estimador para o espectro de po- tências. No entanto, os estimadores encontrados aqui ainda nos proporcionam mais informações, pois com o estimador da variância — e, por conseguinte, da covariância, que é diagonal —, po- demos encontrar a matriz de Fisher para um experimento com as especificidades tomadas aqui. Para essa construção, nos baseamos em (33). Iniciamos a partir da equação (3.15): Fij = 1 2 Tr\u0014 AiAj + Σ−1 ˝ ∂2∆ ∂θi∂θj ˛\u0015 . Temos que (Ai)ll′ = ∂ ln Σll′ ∂θi = 2δll′(Cl + NlB−2 l ) −1 ∂Cl ∂θi , (5.43) Com isso, (AiAj)ll′ = 4δll′(Cl + NlB−2 l ) −2 ∂Cl ∂θi ∂Cl ∂θj . (5.44) Agora precisamos encontrar o segundo termo. Supomos que o estimador do espectro de potên- cias ˆCl não depende dos parâmetros da teoria. Desse modo, ∆ll′ = ( ˆCl − Cl)( ˆCl′ − Cl′) ⇒ ∂2∆ll′ ∂θi∂θj = −( ˆCl′ − Cl′) ∂2Cl ∂θi∂θj + ∂Cl ∂θi ∂Cl′ ∂θj − ( ˆCl − Cl) ∂2Cl′ ∂θi∂θj + ∂Cl ∂θj ∂Cl′ ∂θi . (5.45) Agora precisamos tomar o valor esperado de ∂2∆ ∂θi∂θj . Observando que D ˆClE = Cl, quando to- 51 marmos o valor esperado nos termos com ˆCl − Cl, esses vão zerar. As outras quantidades são teóricas, portanto ˝ ∂2∆ll′ ∂θi∂θj ˛ = ∂Cl ∂θi ∂Cl′ ∂θj + ∂Cl ∂θj ∂Cl′ ∂θi . (5.46) Com isso, obtemos que \u0012Σ −1 ˝ ∂2∆ ∂θi∂θj ˛\u0013 ll′ = (2l + 1) 2 δll′(Cl + NlB−2 l ) −2 \u0012 ∂Cl ∂θi ∂Cl′ ∂θj + ∂Cl ∂θj ∂Cl′ ∂θi \u0013 . (5.47) Por fim, conseguimos encontrar a matriz de Fisher para esse caso: Fij = X l (2l + 5) 2 (Cl + NlB−2 l ) −2 ∂Cl ∂θi ∂Cl ∂θj . (5.48) A equação (5.48) oferece uma forma de, conhecendo as derivadas do espectro de potên- cias, estimar os menores erros possíveis na estimativa dos parâmetros cosmológicos. Segundo Carron em (49), o fator em (5.44) é subdominante em grandes multipolos e é negligenciado em alguns trabalhos, como em (33). Vai além do escopo desse trabalho tentar interpretar esse resultado, portanto, para uma discussão sobre as implicações da equação (5.48), ver (33). Em suma, utilizamos o método de maximização da função de verossimilhança para en- contrar um estimador para o espectro angular de potências e a variância desse estimador. Com isso, fomos capazes de determinar a matriz de Fisher para um experimento nas especificações que propomos. Ressaltamos que o problema abordado aqui contém diversas aproximações e limitações. Por exemplo, podemos ver pela equação (5.41) que o erro no estimador ˆCl aumenta conforme l diminui, o que implica que o erro aumenta com a diminuição da fração da esfera celeste ob- servada. Dessa maneira, a abordagem proposta é mais útil em missões que têm acesso à esfera celeste inteira. Também consideramos simplificações na relação entre sinal e ruídos. Supomos apenas erros lineares sobre os dados coletados, mas efeitos não lineares existem sobre os dados. Como exemplo, temos os efeitos térmicos sobre o detector (50). Também supomos que as flutu- ações da flutuação de temperatura são gaussianas, ou seja, que são completamente determinadas pela média e pelo espectro angular de potências. No entanto, dados da Radiação Cósmica de Fundo revelam a existência de não gaussianidade nas flutuações de temperatura (51), que, por sua vez, não são analisados pela nossa abordagem. A influência de efeitos não gaussianos pode ser verificada pela função de três pontos, pois é nula no limite gaussiano (52). 5.3 MODELO GAUSSIANO LINEAR Uma boa forma de analisar a aplicabilidade do ferramental desenvolvido, sobretudo a Previsão de Fisher e o MCMC, é estudar um problema que tem solução analítica conhecida e 52 comparar com uma solução numérica baseada nesses métodos. Portanto, propomos nesta seção analisar um problema que envolva uma probabilidade posterior gaussiana nos parâmetros, o que nos permite estimar a média e a matriz de covariância de modo analítico e, em seguida, estimar a média e a matriz de covariância utilizando o MCMC. Para construir essa seção, nos baseamos em um exercício proposto em (23). Considere um modelo com uma variável independente x, uma variável dependente y e n parâmetros θi, os quais gostaríamos de determinar a partir das medidas. Esse modelo é linear nos parâmetros se y for uma combinação linear de θi: y(x) = X1(x)θ1 + X2(x)θ2 + ... + Xn(x)θn, (5.49) sendo Xi uma função qualquer de x. Note que Xi não é uma variável aleatória, mas uma função definida nos reais. Suponha agora que são realizadas m medições de y, de modo que temos o conjunto de dados {y1, ..., ym}. “Fitamos” esses dados com o modelo dado pela equação acima considerando erros lineares nas medições, 8 >>>>>>< >>>>>>: y1(x1) = X1(x1)θ1 + X2(x1)θ2 + ... + Xn(x1)θn + η1 y2(x2) = X1(x2)θ1 + X2(x2)θ2 + ... + Xn(x2)θn + η2 ... ym(xm) = X1(xm)θ1 + X2(xm)θ2 + ... + Xn(xm)θn + ηm, (5.50) sendo ηi a incerteza na medida, que supomos ser uma variável aleatória gaussiana multidimensi- onal de média 0 e matriz de covariância Σ = diag(τ 2 1 , τ 2 2 , ..., τ 2 m). Podemos reescrever a equação (5.50) como y = Xθ + η, (5.51) sendo y = 0 B B B B @ y1(x1) y2(x2) ... ym(xm) 1 C C C C A ; X = 0 B B B B @ X1(x1) X2(x1) . . . Xn(x1) X1(x2) X2(x2) . . . Xn(x2) ... ... . . . ... X1(xm) X2(xm) . . . Xn(xm) 1 C C C C A ; θ = 0 B B B B @ θ1 θ2 ... θn 1 C C C C A ; η = 0 B B B B @ η1 η2 ... ηm 1 C C C C A , (5.52) e escrevemos Xij ≡ Xj(xi). Da distribuição de η, encontramos a função de verossimilhança, L(y|θ) = 1 (2π)m/2(det Σ)1/2 exp \u0014−1 2 (˜y − ˜Xθ) ⊤(˜y − ˜Xθ) \u0015, (5.53) onde ˜yi = yi/τi e ˜Xij = Xij/τi. Começamos nossa análise procurando os máximos da função 53 de verossimilhança. Para isso, notamos que maximizar a função de verossimilhança em relação a θ equivale a minimizar o argumento da exponencial, que podemos escrever como (˜y − ˜Xθ) ⊤(˜y − ˜Xθ) = ˜y⊤ ˜y − 2˜y⊤ ˜Xθ + θ⊤Lθ, (5.54) onde usamos que θ⊤ ˜X ⊤ ˜y = ˜y⊤ ˜Xθ, pois ˜y⊤ ˜Xθ é um escalar. Além disso, definimos L = ˜X ⊤ ˜X. Note que L ⊤ = ( ˜X ⊤ ˜X)⊤ = ˜X ⊤ ˜X = L, logo L é simétrica. Portanto, a condição necessária para a minimização é ∇θi(˜y⊤ ˜y − 2˜y⊤ ˜Xθ + θ⊤Lθ) = 0. (5.55) O primeiro termo se anula nessa expressão, pois não depende de θ. Em relação aos demais, ∂ ∂θi \u0010˜y⊤ ˜Xθ\u0011 = ∂ ∂θi X jk ˜yj ˜Xjkθk ! = ( ˜X ⊤ ˜y)i (5.56) e ∂ ∂θi \u0000θ⊤Lθ\u0001 = ∂ ∂θi X jk θjLjkθk ! = (2Lθ)i. (5.57) Portanto, os valores de θ que satisfazem (5.55), θ0, são θ0 = L−1 ˜X ⊤ ˜y. (5.58) Se θ0 é de fato um máximo de (5.53), ele deve satisfazer ∇ 2(˜y⊤ ˜y − 2˜y⊤ ˜Xθ + θ⊤Lθ)\f \fθ0 > 0. (5.59) Mas ∇ 2(˜y⊤ ˜y − 2˜y⊤ ˜Xθ + θ⊤Lθ) = ∇ · (2Lθ) = 2 Tr[L] > 0, (5.60) pois L é o produto de uma matriz pela sua transposta. Podemos agora escrever a função de verossimilhança do problema no espaço dos parâ- metros de modo analítico. Escrevendo o argumento da exponencial em (5.53) como (˜y − ˜Xθ + ˜Xθ0 − ˜Xθ0)⊤(˜y − ˜Xθ + ˜Xθ0 − ˜Xθ0), com θ0 dado por (5.58) e notando que ˜y − ˜Xθ0 = 0 (5.61) encontramos a função de verossimilhança escrita no espaço dos parâmetros: L = L0 exp \u0014−1 2 (θ − θ0) ⊤L(θ − θ0) \u0015, (5.62) 54 com L0 = 1 (2π)m/2(det Σ)1/2 . (5.63) Note que no geral não é possível escrever a função de verossimilhança no espaço dos parâmetros de modo analítico. O fato de conseguirmos aqui é uma especificidade de problemas lineares. Na seção 5.4, analisamos um problema no qual isso não é possível. Considere agora que temos informações sobre o problema que podem, por suposição, serem representadas pela probabilidade anterior p(θ) = (det P ) 1/2 (2π)n/2 exp \u0012 −1 2 θ⊤P θ\u0013, (5.64) sendo P a inversa da matriz de covariância anterior dos parâmetros. Podemos, com isso, cons- truir a probabilidade posterior a partir do teorema de Bayes, (1.28). Como ambas as probabili- dades estão normalizadas, P (θ|y) = p(θ)L = L0 (det P ) 1/2 (2π)n/2 exp \u0014−1 2θ⊤P θ − 1 2 (θ − θ0)⊤L(θ − θ0) \u0015. (5.65) O produto de duas distribuições gaussianas também é uma distribuição gaussiana com uma nova média e uma nova matriz de covariância. Podemos então tentar reescrever o argumento da exponencial acima de modo a termos uma gaussiana de média ¯θ e matriz de covariância F −1. Para isso, ignorando o fator de −1/2, abrimos todos os termos do argumento da exponencial: θ⊤(P + L)θ − θ⊤Lθ0 − θ⊤ 0 Lθ + θ⊤ 0 Lθ0. (5.66) Em seguida, definimos F ≡ P +L e ¯θ ≡ F −1Lθ0. Observe que θ⊤Lθ0 = θ⊤FF −1Lθ0 = θ⊤F ¯θ e θ⊤ 0 Lθ = (F −1Lθ0)⊤Fθ = ¯θ⊤Fθ. Desse modo, o argumento da exponencial se torna θ⊤Fθ − θ⊤F ¯θ − ¯θ⊤Fθ + θ⊤ 0 Lθ0. (5.67) Somando e subtraindo ¯θ⊤F ¯θ, encontramos (θ − ¯θ) ⊤F(θ − ¯θ) + θ⊤ 0 Lθ0 − ¯θ⊤F ¯θ. (5.68) Os dois últimos termos não dependem de θ, portanto eles são constantes. Com isso, podemos escrever a posterior como P (θ|y) = 1 p(y) exp \u0014−1 2 (θ − ¯θ)⊤F(θ − ¯θ) \u0015, (5.69) com 55 p(y) = L0 (det P ) 1/2 (2π)n/2 exp \u0014−1 2(θ⊤ 0 Lθ0 − ¯θ⊤F ¯θ) \u0015 × (2π) n/2 (det F)1/2 . (5.70) Nesse cenário, temos uma forma analítica e simples para a probabilidade posterior no espaço dos parâmetros. Com isso, encontrar os intervalos de 1σ, 2σ e 3σ se resume a encontrar as curvas de níveis da gaussiana (5.69). Dessa forma, podemos construir um algoritmo de MCMC e comparar com essa solução analítica. Com esse intuito, aplicamos agora esse desenvolvimento em um exemplo explícito. Con- sidere um modelo dado por y(x) = θ1 + θ2x + θ3x2 (5.71) e um experimento composto por 10 medições de y, aos quais atribuiremos uma incerteza gaussi- ana de média zero e matriz de covariância Σ = (2/10)2×I10×10, sendo I10×10 a matriz identidade com dez linhas e colunas. Escolhemos o fator de 2/10 arbitrariamente. Medimos a variável de- pendente nos pontos de x que se encontram na Tabela 2. A razão de termos escolhido esses valores para a variável independente x ficará clara abaixo. Para construir os dados de y, utiliza- mos o gerador de números aleatórios integrado à biblioteca numpy da linguagem de programa- ção Python a partir de uma distribuição gaussiana de média (−0, 51; 0, 37; 0, 084) (escolhidos arbitrariamente) e matriz de covariância Σ. Antes de analisar os dados, podemos determinar a matriz de Fisher F analiticamente. Da equação (3.15) e notando que a matriz de covariância dos erros não depende dos parâmetros, Fij = 1 2 Tr\u0014Σ −1 ˝ ∂2∆ ∂θi∂θj ˛\u0015 . (5.72) Mas ∆mn = (ym − Xmkθk)(yn − Xnlθl) (5.73) Logo, ∂2∆mn ∂θi∂θj = XmiXnj + XmjXni, (5.74) portanto, como X não depende de y, ˝ ∂2∆mn ∂θi∂θj ˛ = XmiXnj + XmjXni. (5.75) Agora precisamos determinar o produto do inverso da matriz de covariância com a matriz acima: 56 \u0012 Σ −1 ˝ ∂2∆mn ∂θi∂θj ˛\u0013 pq = X p′ \u0012 10 2 \u00132 δpp′(Xp′iXqj + Xp′jXqi) = \u0012 10 2 \u00132 (XpiXqj + XpjXqi). (5.76) O último passo é calcular o traço da matriz Σ −1 D ∂2∆mn ∂θi∂θj E: Tr \u0014Σ −1 ˝ ∂2∆mn ∂θi∂θj ˛\u0015 = X pq δpq \u0012 10 2 \u00132 (XpiXqj + XpjXqi) = 2 X p 10 2 (X ⊤)ip 10 2 Xpj. (5.77) Mas, da definição de ˜X e de L, vemos que F = L = \u0012 10 2 \u00132 0 B @ 10 P xi P x2 i P xi P x2 i P x3 i P x2 i P x3 i P x4 i 1 C A . (5.78) O que é o esperado, pois sabemos que a matriz de Fisher construída a partir de uma função de verossimilhança gaussiana é a própria inversa da matriz de covariância de L. Substituindo os valores de x encontrados na tabela 2, F = L = 0 B @ 2, 50 × 10 2 0 1, 63 × 10 3 0 1, 63 × 10 3 0 1, 63 × 10 3 0 1, 89 × 10 4 1 C A . (5.79) Segundo a Previsão de Fisher, os parâmetros θ1 e θ2 e os parâmetros θ2 e θ3 não têm correlação. Além disso, também podemos afirmar que as incertezas no parâmetro θ3 serão me- nores que no parâmetro θ2, que, por sua vez, serão menores que no parâmetro θ1. Note que os termos nulos na matriz acima, e, por conseguinte, a não correlação entre os parâmetros decorre da nossa escolha dos valores para a variável independente. Essa é a razão de termos escolhido esses valores. Esse é um exemplo do porque a Previsão de Fisher é importante, já que ela nos permitiu diminuir as complicações presentes na análise. A matriz de covariância prevista para os parâmetros é F −1 = 0 B @ 9, 15 × 10 −3 0 −7, 91 × 10 −4 0 6, 14 × 10 −4 0 −7, 91 × 10 −4 0 1, 21 × 10 −4 1 C A . (5.80) A Figura 13 mostra as curvas de nível da distribuição gaussiana construída com a inversa 57 da matriz de Fisher. Figura 13: Curvas de Nível: inversa da matriz de Fisher 0.4 0.2 0.0 0.2 0.41 0.4 0.2 0.0 0.2 0.4 0.1 0.0 0.12 0.1 0.0 0.1 0.4 0.2 0.0 0.2 0.4 1 0.10 0.05 0.00 0.05 0.103 0.1 0.0 0.1 2 0.10 0.05 0.00 0.05 0.10 0.10 0.05 0.00 0.05 0.10 3 Os gráficos θ1 × θ2, θ1 × θ3 e θ2 × θ3 representam as curvas de 1σ, 2σ e 3σ produzidas a partir da inversa da matriz de Fisher. Escolhemos a média em 0 pois a previsão de Fisher diz respeito apenas às incertezas. Na diagonal estão apresentadas as distribuições unidimensionais para cada um dos parâmetros. Observe que a correlação entre os parâmetros se reflete na inclinação da elipse. Fonte: O próprio autor. Agora podemos prosseguir para a análise dos dados simulados a partir da análise direta da probabilidade posterior. Na Tabela 2, encontram-se os valores simulados. Supondo uma probabilidade anterior com matriz de covariância inversa P = 10−3I10×10 (escolhida de modo a não sobrepujar a informação presente na função de verossimilhança), po- demos construir a probabilidade posterior a partir da equação (5.69). Com isso, é possível plotar as curvas de nível da distribuição posterior (Figura 14). A Figura 13 é aproximadamente igual a Figura 14, o que não é surpreendente, visto que a inversa da matriz de covariância da probabilidade anterior (P ) é cerca de 10 5 vezes menor que F . Isso significa que a probabilidade anterior trás menos informações que a função de verossi- milhança e, portanto, o resultado final depende mais da verossimilhança que da probabilidade anterior. A diferença entre os gráficos se encontra nas médias obtidas. Encontramos as seguintes médias para os parâmetros: 58 Tabela 2: Dados simulados. x y -4,00 -0,888 -3,11 -1,22 -2,22 -0,916 -1,33 -0,986 -0,444 -0,598 0,444 -0,469 1,33 0,270 2,22 0,646 3,11 1,21 4,00 2,25 Fonte: O próprio autor. Figura 14: Curvas de Nível: probabilidade posterior. 0.8 0.6 0.4 0.21 0.8 0.6 0.4 0.2 0.2 0.3 0.4 0.52 0.2 0.3 0.4 0.5 0.6 0.8 0.6 0.4 0.2 1 0.05 0.00 0.05 0.10 0.153 0.2 0.3 0.4 0.5 2 0.05 0.00 0.05 0.10 0.15 0.05 0.00 0.05 0.10 0.15 0.20 3 Os gráficos θ1 ×θ2, θ1 ×θ3 e θ2 ×θ3 representam as curvas de 1σ, 2σ e 3σ da probabilidade posterior. Na diagonal, distribuições de probabilidade unidimensionais para cada parâmetro. Fonte: O próprio autor. 8 >>>< >>>: ¯θ1 = −0, 5 ± 0, 1; ¯θ2 = 0, 38 ± 0, 02; ¯θ3 = 0, 07 ± 0, 01. 59 Figura 15: Parábola formada pelos parâmetros que maximizam a posterior e os dados simula- dos, representados pelos pontos 4 3 2 1 0 1 2 3 4 x 1.0 0.5 0.0 0.5 1.0 1.5 2.0 2.5y Fonte: O próprio autor. e com a matriz de covariância entre os parâmetros dada por (5.80). Na Figura 15 plotamos a parábola formada por esses parâmetros e os dados. Com isso, finalizamos a análise analítica. Agora iremos explorar esse mesmo problema utilizando o método de MCMC. Para isso, construímos um algoritmo de Metropolis–Hastings (o código se encontra no Apêndice B, junto das informações de hardwar e do tempo de pro- cessamento) e realizamos primeiramente uma cadeia exploratória com uma densidade proposta uniforme nos intervalos: 8 >>>< >>>: θ1 ∈ [−0, 8; −0, 2]; θ2 ∈ [−0, 2; 0, 6]; θ3 ∈ [−0, 2; 0, 2]. Escolhemos esses intervalos pois valores além destes geravam posteriores pequenas demais (da ordem de 10 −308), que são inevitavelmente arredondados para 0. Nessa cadeia exploratória, 12000 elementos foram testados e 54 foram aceitos. Isso nos permitiu construir a seguinte matriz de covariância: Cdensidade proposta = 0 B @ 1, 06 × 10 −2 −4, 64 × 10 −4 7, 87 × 10 −5 −4, 64 × 10 −4 3, 23 × 10 −3 4, 04 × 10 −4 7, 87 × 10 −5 4, 04 × 10 −4 1, 61 × 10 −3 1 C A . (5.81) Reescalamos essa matriz por 2, 4/ √3, seguindo a sugestão em (41) e a usamos como a matriz de covariância da densidade proposta gaussiana para uma nova cadeia, onde testamos 36000 elementos, dos quais 5834 foram aceitos, uma taxa de aceitação de 16%. Excluímos os primeiros 60 1002 pontos, pois os pontos inciais ainda estão explorando o espaço dos parâmetros e dividimos a cadeia resultante em 4. A princípio, com o intuito de averiguar a convergência, analisamos as quatro cadeias separadamente. Todas as quatro apresentam a mesma média e o mesmo desvio padrão para cada parâmetro. Esses valores estão expostos abaixo: 8 >>>< >>>: ¯θ1 = −0, 5 ± 0, 1; ¯θ2 = 0, 39 ± 0, 03; ¯θ3 = 0, 07 ± 0, 01. . (5.82) O fato das quatro terem apresentado resultados iguais é um bom indicador de convergência. No entanto, também aplicamos o teste de convergência de Gelman-Rubin — ver seção 4.2. Encon- tramos Rθ1 = 0, 99979341, Rθ2 = 0, 99979311 e Rθ3 = 0, 99979345. Esses valores, aliado com o fato de que todas as cadeias apresentam a mesma média para cada parâmetro, indicam que o resultado obtido é confiável. A matriz de covariância obtida para os parâmetros é CMCMC = 0 B @ 1, 07 × 10 −2 7, 30 × 10 −5 −9, 61 × 10 −4 7, 30 × 10 −5 7, 47 × 10 −4 4, 88 × 10 −6 −9, 61 × 10 −4 4, 88 × 10 −6 1, 60 × 10 −4 1 C A . (5.83) A matriz acima deve ser comparada com (5.80). Vemos que ela é um pouco menos precisa que a matriz de Fisher, como esperado, pois, como vimos, a desigualdade de Cramer- Rao (equação (3.3)) nos diz que a matriz de Fisher oferece um limite inferior para a matriz de covariância. Na Figura 16, plotamos as curvas de níveis formadas pelas amostras do MCMC. Para plotar esse gráfico, usamos a biblioteca Seaborn do Python. Na Figura 17, comparamos os resultados obtidos da análise direta da posterior com o que foi obtido pelo MCMC. Vemos que o resultado a partir do MCMC é menos preciso, porém condizente com a análise direta. 5.4 SUPERNOVAS TIPO IA Vamos aplicar agora o formalismo desenvolvido para Supernovas Tipo Ia. Supernovas Tipo Ia são velas padronizáveis que encontram-se em destaque entre os objetos de interesse cos- mológico uma vez que, no contexto do modelo cosmológico padrão, a distância de luminosidade destes objetos parece sugerir que o Universo se expande de forma acelerada. Supernovas Tipo Ia são observadas com o intuito de melhorar as estimativas sobre os parâmetros cosmológicos. Diversos experimentos foram conduzidos na última década e ainda são conduzidos, como o Pan-STARRS (53) para observar esses objetos. O Pantheon (54) é uma compilação de dados de diferentes levantamentos. 61 Figura 16: Curvas de Nível: probabilidade posterior estimada. 0.8 0.6 0.4 0.21 0.30 0.35 0.40 0.452 0.75 0.50 0.25 1 0.04 0.06 0.08 0.10 0.123 0.3 0.4 2 0.05 0.10 3 No triângulo direito superior, encontram-se as distribuição das amostras no espaço dos parâmetros. Na diagonal, temos a distribuição de probabilidades unidimensional de cada parâmetro marginalizado sobre os outros dois. No triângulo esquerdo inferior, vemos os intervalos de confiança de 68%, 95% e 99%. Fonte: O próprio autor. Velas padrão são objetos astronômicos cujo comportamento similar entre todos os ele- mentos permite realizar estimativas de distâncias além de regiões onde o método da paralaxe é aplicável. Esses objetos apresentam luminosidade L conhecida e suas distâncias dL podem ser inferidas a partir de uma lei de inverso quadrado comparando a luminosidade com o fluxo luminoso observado F : F = L 4πd2 L . (5.84) Supernovas Tipo Ia apresentam luminosidades similares onde quer que ocorram (55) — pode existir variações na luminosidade, mas há correções conhecidas (56). Ignorando por ora complicações observacionais, escrevemos o modulo de distância como (57) µ ≡ m − M = 5 log\u0012 dL 10pc \u0013 + K, (5.85) sendo m a magnitude aparente, M a magnitude absoluta e dL a distância de luminosidade da 62 Figura 17: Curvas de nível teóricas (preenchidas) e experimentais (contornos). 0.9 0.8 0.7 0.6 0.5 0.4 0.3 0.2 1 0.20 0.25 0.30 0.35 0.40 0.45 0.50 0.552 (a) 0.9 0.8 0.7 0.6 0.5 0.4 0.3 0.2 1 0.05 0.00 0.05 0.10 0.153 (b) 0.20 0.25 0.30 0.35 0.40 0.45 0.50 0.55 2 0.05 0.00 0.05 0.10 0.153 (c) Fonte: O próprio autor. Supernova. Baseados em (23), escolhemos M = −19, 3. A distância de luminosidade depende dos parâmetros cosmológicos a partir da equação (que deduzimos no Apêndice A), dL(z) = c H0 (1 + z) × 8 >>>>>>< >>>>>>: 1 p|Ωk| sin \u0014 p |Ωk| R z 0 dz′ E(z′) \u0015 , Ωk < 0; R z 0 dz′ E(z′), Ωk = 0; 1 p|Ωk| sinh \u0014p |Ωk| R z 0 dz′ E(z′) \u0015 , Ωk > 0, (5.86) com E(z′) = qΩm(1 + z′)3 + ΩΛ(1 + z′)3(1+w) + Ωk(1 + z′)2, (5.87) sendo c a velocidade da luz, H0 o parâmetro de Hubble no tempo atual, z o redshift, Ωm o parâ- metro de densidade de matéria, ΩΛ o parâmetro de densidade de energia escura,Ωk o parâmetro de curvatura espacial e w a equação de estado da energia escura. Uma definição completa desses termos pode ser encontrada em (58) e (57). Por ser uma vela padrão, é possível coletar dados experimentais de µ e comparar com a 63 expressão (5.85), que depende da cosmologia. Para realizar uma análise desse objeto, utilizamos os dados disponíveis da missão Pantheon (54). Foram observadas 1048 supernovas Tipo Ia, que foram transformados em 40 dados “binados” 6. Os dados estão disponíveis neste link. Os dados disponíveis são da magnitude aparente m. Desse modo, utilizamos a aproximação M = −19, 3 para calcular a distância modular. Baseado em (54), podemos escolher a constante K = 0. A Figura 18 é o diagrama de Hubble para essas observações. A matriz de covariância para cada observação também está disponível no link informado. Nosso algoritmo tem uma limitação em números muito pequenos (da ordem de 10 −308) de modo que exponenciais de argumentos da ordem de −10 3 são arredondadas para zero. Desse modo, observando a equação (5.88), vemos que a se a diferença entre a distância modular medida e teórica for da ordem de 10 −2, a função de verossimilhança é arredondada para zero. Isso impede a exploração do espaço dos parâmetros de maneira satisfatória e, visto que esse trabalho de conclusão tem um objetivo didático, optamos por reescalar a matriz de covariância por um fator de 10 3, de modo a permitir uma exposição mais direta do assunto. Naturalmente, não conseguimos reproduzir com precisão os resultados obtidos pelo Pantheon. Figura 18: Diagrama de Hubble para os dados do Pantheon Na figura de cima, temos o diagrama de Hubble para todas as Supernovas Tipo Ia coletadas pela missão Pantheon. Na figura de baixo, vemos o resíduo do melhor fit do modelo. Fonte: Scolnic, D.M. et al (54). A partir do teorema do limite central, podemos escrever a função de verossimilhança 6Os dados originais foram agrupados de modo a dar origem a 40 dados. Uma tradução para esse termo seria “dados agrupados”, mas o termo adotado é utilizado pela comunidade e por isso optamos por ele. 64 como L = 1 (2π)20(det C)1/2 exp \u0014−1 2(µobs − µ) ⊤C −1(µobs − µ) \u0015. (5.88) Em seguida, rodamos nosso algoritmo de Metropolis–Hastings para três modelos dife- rentes, os quais chamaremos de Modelo A, B e C. As informações acerca do tempo de proces- samento para cada modelo se encontra no Apêndice B. • Modelo A: Modelo ΛCDM com H0, Ωm e ΩΛ livres e probabilidade anterior gaussiana em H0 com média 74, 0 ± 1, 4 km s −1Mpc−1, com base em (59); • Modelo B: Modelo ΛCDM com parâmetro H0 = 72 km s−1Mpc−1 e probabilidade ante- rior uniforme sobre os parâmetros Ωm e ΩΛ; • Modelo C: Modelo wCDM7 espacialmente plano com H0 = 72 km s−1Mpc −1. Seguimos o mesmo procedimento utilizado no caso gaussiano linear. Para os três casos, utilizamos uma densidade proposta uniforme, pois não conhecemos a distribuição no espaço dos parâmetros e uma densidade proposta gaussiana provou-se ineficaz (diminuiu a taxa de aceitação e impediu o algoritmo de explorar certas regiões). Para o Modelo A, testamos 48000 elementos, dos quais 505 foram aceitos (utilizamos apenas os pontos aceitos na análise). Excluímos os primeiros 101 pontos e dividimos a cadeia resultante em 4. Na tabela 3, expomos a média e o desvio padrão para cada parâmetro calculado em cada cadeia Tabela 3: Média e desvio padrão de cada parâmetro do modelo livre no Modelo A Cadeia H0 ± σ Ωm ± σ ΩΛ ± σ 1 72, 34 ± 1, 24 0, 27 ± 0, 15 0, 74 ± 0, 17 2 72, 27 ± 1, 19 0, 30 ± 0, 17 0, 77 ± 0, 16 3 72, 49 ± 1, 04 0, 26 ± 0, 14 0, 75 ± 0, 16 4 72, 33 ± 1, 15 0, 27 ± 0, 16 0, 74 ± 0, 19 Fonte: O próprio autor. A média e o desvio padrão levando em conta uma única cadeia com 404 elementos é 8 >>>>>>< >>>>>>: H0 = 72, 34 ± 1, 16; Ωm = 0, 28 ± 0, 16; ΩΛ = 0, 75 ± 0, 17; Ωk = −0, 03 ± 0, 3. 7O modelo wCDM difere do modelo ΛCDM somente pela equação de estado da energia escura. No primeiro caso, usa-se um parâmetro livre w e, no segundo, fixa-se esse valor como −1. 65 Note que o parâmetro de curvatura não é calculado diretamente pela cadeia, mas é obtido a partir de Ωm e ΩΛ (veja a equação (A.13)) . Para calcular seu desvio padrão, utilizamos o método de propagação de erros. Além disso, note que o erro em sua medida é maior que sua própria média. A matriz de covariância encontrada é C = 0 B @ 1, 34 −0, 085 0, 076 −0, 085 0, 026 0, 018 0, 076 0, 018 0, 029 1 C A , (5.89) onde o a primeira coluna e a primeira linha se referem a H0, a segunda coluna e a segunda linha se referem a Ωm e a terceira coluna/linha se referem a ΩΛ. Também podemos calcular a correlação entre os elementos. A partir da equação (1.18), 8 >>>< >>>: ρH0Ωm = −0, 46; ρH0ΩΛ = 0, 38; ρΩmΩΛ = 0, 66. Por fim, podemos calcular o fator R. Temos que RH0 = 0, 99753965, RΩm = 0, 9975921 e RΩΛ = 0, 9975451. Observando esses valores de R e a média em cada uma das quatro cadeias, há indicação de que pode ter ocorrido convergência. A Figura 19 mostras as curvas de nível obtidas. Para o Modelo B, 48000 elementos foram testados e 1436 foram aceitos. Excluímos os primeiros 100 pontos e dividimos a cadeia resultante em 4. Na tabela 4 expomos a média e o desvio padrão para cada parâmetro calculado em cada cadeia. Tabela 4: Média e desvio padrão de cada parâmetro no Modelo B Cadeia Ωm ± σ ΩΛ ± σ 1 0, 29 ± 0, 15 0, 73 ± 0, 16 2 0, 28 ± 0, 15 0, 72 ± 0, 16 3 0, 29 ± 0, 15 0, 73 ± 0, 16 4 0, 29 ± 0, 15 0, 73 ± 0, 17 Fonte: O próprio autor. A média e o desvio padrão levando em conta uma única cadeia é 8 >>>< >>>: Ωm = 0, 29 ± 0, 15; ΩΛ = 0, 72 ± 0, 16; Ωk = −0, 015 ± 0, 3. Encontramos uma matriz de covariância 66 Figura 19: Curvas de nível para o Modelo A 70 71 72 73 74 75H0 0.0 0.2 0.4 0.6 0.8 1.0m 0.2 0.4 0.6 0.8 1.0 70 72 74 76 H0 1.0 0.5 0.0 0.5 1.0k 0.0 0.5 1.0 m 0.5 1.0 1 0 1 k Fonte: O próprio autor. C = 0, 022 0, 024 0, 024 0, 027 ! , (5.90) onde a primeira coluna/linha se refere a Ωm e a segunda coluna/linhas se refe a ΩΛ. Também podemos tomar a correlação entre os parâmetros, ρΩmΩΛ = 0, 86. (5.91) Por fim, podemos analisar o fator R. Obtemos RΩm = 0, 9922944 e RΩΛ = 0, 99922931. Com isso, há indicação que pode ter ocorrido convergência. A Figura 20 mostra as curvas de nível. Comparamos as curvas na Figura 20 com as 67 curvas análogas na Figura 19. Figura 20: Regiões de confiança de 1σ, 2σ e 3σ para o Modelo B. 0.0 0.1 0.2 0.3 0.4 0.5 0.6m 0.4 0.6 0.8 1.0 0.00 0.25 0.50 m 0.5 0.0 0.5k 0.25 0.50 0.75 1.00 0.5 0.0 0.5 k Fonte: O próprio autor. Nos dois casos, observamos uma tendência a um Universo espacialmente plano composto de aproximadamente 30% de matéria e 70% de energia escura. Para o modelo C, testamos 48000 elementos e 739 foram aceitos. Excluímos os primeiros 103 elementos e dividimos a cadeia resultante em 4. Na tabela 5, expomos a média e o desvio padrão para cada parâmetro calculado em cada cadeia. Tabela 5: Média e desvio padrão de cada parâmetro do modelo livre no Modelo B. Cadeia Ωm ± σ w ± σ 1 0, 27 ± 0, 13 −1, 04 ± 0, 26 2 0, 28 ± 0, 12 −1, 05 ± 0, 25 3 0, 28 ± 0, 12 −1, 05 ± 0, 25 4 0, 27 ± 0, 11 −1, 02 ± 0, 24 Fonte: O próprio autor. A média e o desvio padrão levando em conta uma única cadeia com todos os elementos é 68 Figura 21: Regiões de confiança de 1σ, 2σ e 3σ para o terceiro caso abordado. 0.0 0.1 0.2 0.3 0.4m 0.0 0.2 0.4 m 1.6 1.4 1.2 1.0 0.8 0.6 0.4w 1.5 1.0 0.5 w Fonte: O próprio autor. 8 < :Ωm = 0, 27 ± 0, 12 w = −1, 04 ± 0, 25. A matriz de covariância encontrada é C = 0, 015 −0, 030 −0, 030 0, 063. ! , (5.92) onde a primeira linha/coluna se refere a Ωm e a segunda linha/coluna se refere a w. Também podemos calcular a correlação entre esses dois parâmetros, ρΩmw = −0, 97. (5.93) Por fim, podemos analisar o fator R. Obtemos, RΩm = 0, 9922975 e Rw = 0, 9923004. A Figura 21 mostra as regiões de confiança para o Modelo C. Não restringimos bem a equação de estado w, implicando que, com essa análise, não conseguimos determinar com precisão a natureza da energia escura. 69 6 CONSIDERAÇÕES FINAIS Procuramos neste trabalho de conclusão de curso apresentar uma revisão dos fundamen- tos da estatística bayesiana e suas aplicações em cosmologia. Por ser o método de análise mais comum nessa área e também amplamente empregado pela comunidade de física de partículas, o estudo deste é um passo importante em um nível pessoal, como elemento de formação. As- sim como é em um nível comunitário, no sentido de proporcionar uma revisão das bases desse método. Por ser um trabalho de revisão, utilizamos uma variedade de textos, que vão da fí- sica matemática ((13), (14)) até artigos consagrados em assuntos específicos (33). Com isso em mente, o presente texto se apresenta como um trabalho introdutório sobre o tema, cobrindo tópicos fundamentais, abordando superficialmente alguns problemas atuais (como a análise de Supernovas) e ignorando, por restrição de tema e por limitações de tempo, certos tópicos também relacionados à estatística bayesiana, como métodos de seleção de modelos e outros algoritmos de MCMC. As aplicações do método são destaque aqui. Somos limitados pela complexidade dos problemas frente ao nível introdutório de exposição que propomos, de modo que todas as apli- cações são ou elementares ou situações simplificadas. As três primeiras seções do capítulo 5 tratam da Radiação Cósmica de Fundo. Na primeira, encontramos que, para o caso onde temos incertezas lineares nos dados, o estimador do sinal é dado pela equação (5.8). Situações reais vão ter problemas bem mais drásticos, como o disco galático que esconde certas regiões da RCF. No entanto, a ideia que desenvolvemos nessa seção é a base para a construção de mapas realis- tas. De modo similar, encontramos um estimador para o espectro de potências (equação (5.32)) levando em conta apenas um problema experimental, o da abertura angular. Demonstramos que nosso algoritmo de Metropolis–Hastings tem resultados confiáveis para modelos simples com parâmetros não correlacionados (Figura 17). Para o caso de Supernovas Tipo Ia, os resultados apresentados aqui indicam que o algoritmo não se mostrou eficiente, mas essa análise não tem qualquer pretensão de conter valor científico, e a ideia da seção se encontra puramente no seu ca- ráter didático. De qualquer modo, fomos capazes de encontrar regiões de confiança (Figuras 19, 20 e 21) e parâmetros cosmológicos estimados em acordo razoável com os valores atualmente aceitos pela comunidade. Com as bases da estatística bayesiana bem fundamentadas, os próximos passos para uma futura pesquisa são, de um lado, ampliar o conhecimento sobre a própria estatística e programa- ção e, de outro, sobre cosmologia. Com um novo degrau mais amplo, problemas mais complexos — antigos e atuais — poderão ser examinados e correções aos problemas aqui expostos poderão ser feitas. 70 Referências 1 Hubble, E. A Relation between Distance and Radial Velocity among Extra-Galactic Nebulae. Proceedings of the National Academy of Science, v. 15, n. 3, p. 168–173, mar. 1929. 2 Lemaître, G. Expansion of the universe, The expanding universe. Monthly Notices of the Royal Astronomical Society, v. 91, p. 490–501, mar. 1931. 3 BENNETT, C. L. et al. Nine-year wilkinson microwave anisotropy probe (wmap) observations: final maps and results. The Astrophysical Journal Supplement Series, IOP Publishing, v. 208, n. 2, p. 20, 2013. 4 AGHANIM, N. et al. Planck 2018 results-vi. cosmological parameters. Astronomy & Astrophysics, EDP sciences, v. 641, p. A6, 2020. 5 Riess, A. G. et al. Observational Evidence from Supernovae for an Accelerating Universe and a Cosmological Constant. The Astronomical Journal, v. 116, n. 3, p. 1009–1038, set. 1998. 6 Perlmutter, S. et al. Measurements of Ω and Λ from 42 High-Redshift Supernovae. The Astrophysical Journal, v. 517, n. 2, p. 565–586, jun. 1999. 7 VALENTINO, E. D. et al. In the realm of the hubble tension—a review of solutions. Classical and Quantum Gravity, IOP Publishing, v. 38, n. 15, p. 153001, jul 2021. Disponível em: <https://doi.org/10.1088/1361-6382/ac086d>. 8 ABBOTT, R. et al. Observation of gravitational waves from two neutron star–black hole coalescences. The Astrophysical Journal Letters, American Astronomical Society, v. 915, n. 1, p. L5, jun 2021. Disponível em: <https://doi.org/10.3847/2041-8213/ac082e>. 9 SEVILLA-NOARBE, I. et al. Dark energy survey year 3 results: Photometric data set for cosmology. The Astrophysical Journal Supplement Series, American Astronomical Society, v. 254, n. 2, p. 24, may 2021. Disponível em: <https://doi.org/10.3847/1538-4365/abeb66>. 10 Alam, S. et al. Completed SDSS-IV extended Baryon Oscillation Spectroscopic Survey: Cosmological implications from two decades of spectroscopic surveys at the Apache Point Observatory. Physical Review D, v. 103, n. 8, p. 083533, abr. 2021. 11 Ivezić, Ž. et al. LSST: From Science Drivers to Reference Design and Anticipated Data Products. The Astrophysical Journal, v. 873, n. 2, p. 111, mar. 2019. 12 VALENTINO, E. D.; MELCHIORRI, A.; SILK, J. Investigating cosmic discordance. The Astrophysical Journal Letters, American Astronomical Society, v. 908, n. 1, p. L9, feb 2021. Disponível em: <https://doi.org/10.3847/2041-8213/abe1c4>. 13 BOAS, M. L. Mathematical methods in the physical sciences; 3rd ed. Hoboken, NJ: Wiley, 2006. Disponível em: <https://cds.cern.ch/record/913305>. 14 ARFKEN, G. B.; WEBER, H. J.; HARRIS, F. E. Chapter 23 - probability and statistics. In: ARFKEN, G. B.; WEBER, H. J.; HARRIS, F. E. (Ed.). Mathematical Methods for Physicists (Seventh Edition). Seventh edition. Boston: Academic Press, 2013. p. 1125–1179. ISBN 978-0-12-384654-9. Disponível em: <https://www.sciencedirect.com/science/article/pii/ B9780123846549000232>. 71 15 RICE, J. A. Mathematical Statistics and Data Analysis. Third. [S.l.]: Belmont, CA: Duxbury Press., 2006. 16 GUT, A. Random variables. In: GUT, ALLAN. Probability: A Graduate Course: A Graduate Course. New York, NY: Springer New York, 2013. p. 25–117. ISBN 978-1-4614- 4708-5. Disponível em: <https://doi.org/10.1007/978-1-4614-4708-5_2>. 17 ASH, R. Basic Probability Theory. Dover Publications, Incorporated, 2012. (Dover Books on Mathematics Series). ISBN 9780486135199. Disponível em: <https://books.google.com.br/ books?id=fmNbFnfrb14C>. 18 DODELSON, S.; SCHMIDT, F. 14 - analysis and inference. In: DODELSON, S.; SCHMIDT, F. (Ed.). Modern Cosmology (Second Edition). Second edition. Academic Press, 2021. p. 401–431. ISBN 978-0-12-815948-4. Disponível em: <https://www.sciencedirect.com/ science/article/pii/B9780128159484000206>. 19 JONATHAN, W. Varieties of bayesianism. In: GABBAY, D. M.; HARTMANN, S.; WOODS, J. (Ed.). Inductive Logic. North-Holland, 2011, (Handbook of the History of Logic, v. 10). p. 477–551. Disponível em: <https://www.sciencedirect.com/science/article/pii/ B9780444529367500136>. 20 GUT, A. Introductory measure theory. In: GUT, ALLAN. Probability: A Graduate Course: A Graduate Course. New York, NY: Springer New York, 2013. p. 1–24. ISBN 978-1-4614-4708-5. Disponível em: <https://doi.org/10.1007/978-1-4614-4708-5_1>. 21 MAHALANOBIS, P. C. On the generalized distance in statistics. Proceedings of the National Institute of Sciences (Calcutta), v. 2, p. 49–55, 1936. 22 WALL, J. V.; JENKINS, C. R. Probability. In: WALL, J. V. AND JENKINS, C. R. Practical Statistics for Astronomers. [S.l.]: Cambridge University Press, 2003. (Cambridge Observing Handbooks for Research Astronomers), p. 31. 23 TROTTA, R. Bayesian methods in cosmology. arXiv preprint arXiv:1701.01467, 2017. 24 WALD, A. Note on the consistency of the maximum likelihood estimate. The Annals of Mathematical Statistics, JSTOR, v. 20, n. 4, p. 595–601, 1949. 25 VAART, A. W. v. d. Bayes procedures. In: VAART, A. W. VAN DER. Asymptotic Statistics. [S.l.]: Cambridge University Press, 1998. (Cambridge Series in Statistical and Probabilistic Mathematics), p. 138–152. 26 F., L.; A., P.; B.D., W. Cosmology: From theory to data, from data to theory. Proceedings of the International School of Physics ;Enrico Fermi;, IOS Press, v. 186, n. New Horizons for Observational Cosmology, p. 189–233, 2014. ISSN 0074-784X. Disponível em: <https://doi.org/10.3254/978-1-61499-476-3-189>. 27 ROBERT, C. P. On the jeffreys-lindley paradox. Philosophy of Science, University of Chicago Press Chicago, IL, v. 81, n. 2, p. 216–232, 2014. 28 WAGENMAKERS, E.-J.; LY, A. History and nature of the jeffreys-lindley paradox. arXiv preprint arXiv:2111.10191, 2021. 72 29 VERDE, L. Statistical methods in cosmology. In: WOLSCHIN, GEORG. Lectures on Cosmology: Accelerated Expansion of the Universe. Berlin, Heidelberg: Springer Berlin Heidelberg, 2010. p. 147–177. ISBN 978-3-642-10598-2. Disponível em: <https: //doi.org/10.1007/978-3-642-10598-2_4>. 30 FISHER, R. A. The logic of inductive inference. Journal of the royal statistical society, JSTOR, v. 98, n. 1, p. 39–82, 1935. 31 HAMILTON, A.; TEGMARK, M. Decorrelating the power spectrum of galaxies. Monthly Notices of the Royal Astronomical Society, Blackwell Science Ltd Oxford, UK, v. 312, n. 2, p. 285–294, 2000. 32 ABRAMO, L. R. The full Fisher matrix for galaxy surveys. Monthly Notices of the Royal Astronomical Society, v. 420, n. 3, p. 2042–2057, 02 2012. ISSN 0035-8711. Disponível em: <https://doi.org/10.1111/j.1365-2966.2011.20166.x>. 33 TEGMARK, M.; TAYLOR, A. N.; HEAVENS, A. F. Karhunen-loeve eigenvalue problems in cosmology: How should we tackle large data sets? The Astrophysical Journal, American Astronomical Society, v. 480, n. 1, p. 22–35, may 1997. Disponível em: <https://doi.org/10.1086/303939>. 34 PEROTTO, L. et al. Probing cosmological parameters with the CMB: forecasts from monte carlo simulations. Journal of Cosmology and Astroparticle Physics, IOP Publishing, v. 2006, n. 10, p. 013–013, oct 2006. Disponível em: <https://doi.org/10.1088/1475-7516/2006/10/013>. 35 HU, W. Power spectrum tomography with weak lensing. The Astrophysical Journal, IOP Publishing, v. 522, n. 1, p. L21, 1999. 36 TROTTA, R. et al. Bayesian experimental design and model selection forecasting. In: HOBSON, M. et al. (Ed.). Bayesian Methods in Cosmology. [S.l.]: Cambridge University Press, 2009. p. 99–125. 37 HEAVENS, A. Statistical techniques in cosmology. arXiv preprint arXiv:0906.0664, 2009. 38 METROPOLIS, N. et al. Equation of state calculations by fast computing machines. The Journal of Chemical Physics, v. 21, n. 6, p. 1087–1092, 1953. Disponível em: <https://doi.org/10.1063/1.1699114>. 39 HASTINGS, W. K. Monte Carlo sampling methods using Markov chains and their applications. Biometrika, v. 57, n. 1, p. 97–109, 04 1970. ISSN 0006-3444. Disponível em: <https://doi.org/10.1093/biomet/57.1.97>. 40 LEWIS, A.; BRIDLE, S. Parameter estimation using monte carlo sampling. In: HOBSON, M. et al. (Ed.). Bayesian Methods in Cosmology. [S.l.]: Cambridge University Press, 2009. p. 57–78. 41 GELMAN, A.; ROBERTS, G. O.; GILKS, W. R. Eﬀicient metropolis jumping rules. In: BERNARDO, J. M. et al. (Ed.). Bayesian Statistics. [S.l.]: Oxford University Press, Oxford, 1996. p. 599–608. 42 GELMAN, A.; RUBIN, D. B. Inference from Iterative Simulation Using Multiple Sequences. Statistical Science, Institute of Mathematical Statistics, v. 7, n. 4, p. 457 – 472, 1992. Disponível em: <https://doi.org/10.1214/ss/1177011136>. 73 43 DURRER, R. The Cosmic Microwave Background. 2. ed. [S.l.]: Cambridge University Press, 2020. 44 PETER, P.; UZAN, J.-P. Primordial cosmology. Oxford: Oxford Univ. Press, 2009. (Oxford graduate texts). Disponível em: <https://cds.cern.ch/record/1208401>. 45 DODELSON, S.; SCHMIDT, F. 9 - the cosmic microwave background. In: DODELSON, S.; SCHMIDT, F. (Ed.). Modern Cosmology (Second Edition). Second edition. Academic Press, 2021. p. 231–269. ISBN 978-0-12-815948-4. Disponível em: <https://www.sciencedirect.com/ science/article/pii/B9780128159484000152>. 46 TEGMARK, M. The angular power spectrum of the four-year cobe data. The Astrophysical Journal, IOP Publishing, v. 464, n. 1, p. L35, 1996. 47 JEFFREY, A. et al. 3–4 - definite integrals of elementary functions. In: JEFFREY, A. et al. (Ed.). Table of Integrals, Series, and Products (Seventh Edition). Seventh edition. Boston: Academic Press, 2007. p. 247–617. ISBN 978-0-12-373637-6. Disponível em: <https://www.sciencedirect.com/science/article/pii/B9780080471112500133>. 48 Sachs, R. K.; Wolfe, A. M. Perturbations of a Cosmological Model and Angular Variations of the Microwave Background. The Astrophysical Journal, v. 147, p. 73, jan. 1967. 49 CARRON, J. On the assumption of gaussianity for cosmological two-point statistics and parameter dependent covariance matrices. Astronomy & Astrophysics, EDP Sciences, v. 551, p. A88, 2013. 50 ADE, P. et al. Planck 2013 results. vi. high frequency instrument data processing. Astronomy & Astrophysics, EDP sciences, v. 571, p. A6, 2014. 51 AKRAMI, Y. et al. Planck 2018 results-ix. constraints on primordial non-gaussianity. Astronomy & Astrophysics, EDP sciences, v. 641, p. A9, 2020. 52 MUKHANOV, V. Cosmic microwave background anisotropies. In: MUKHANOV, VIATCHESLAV. Physical Foundations of Cosmology. [S.l.]: Cambridge University Press, 2005. p. 356–409. 53 REST, A. et al. Cosmological constraints from measurements of type ia supernovae discovered during the first 1.5 yr of the pan-starrs1 survey. The Astrophysical Journal, IOP Publishing, v. 795, n. 1, p. 44, 2014. 54 Scolnic, D. M. et al. The Complete Light-curve Sample of Spectroscopically Confirmed SNe Ia from Pan-STARRS1 and Cosmological Constraints from the Combined Pantheon Sample. The Astrophysical Journal, v. 859, n. 2, p. 101, jun. 2018. 55 COELHO, R. C. V. et al. Standardization of type ia supernovae. European Journal of Physics, IOP Publishing, v. 36, n. 1, p. 015007, nov 2014. Disponível em: <https: //doi.org/10.1088/0143-0807/36/1/015007>. 56 LEIBUNDGUT, B. Type ia supernovae. The Astronomy and Astrophysics Review, v. 10, p. 179–209, 2000. 74 57 DODELSON, S.; SCHMIDT, F. 2 - the expanding universe. In: DODELSON, S.; SCHMIDT, F. (Ed.). Modern Cosmology (Second Edition). Second edition. Academic Press, 2021. p. 21–55. ISBN 978-0-12-815948-4. Disponível em: <https://www.sciencedirect.com/ science/article/pii/B9780128159484000085>. 58 DODELSON, S.; SCHMIDT, F. 1 - the concordance model of cosmology. In: DODELSON, S.; SCHMIDT, F. (Ed.). Modern Cosmology (Second Edition). Second edition. Academic Press, 2021. p. 1–19. ISBN 978-0-12-815948-4. Disponível em: <https://www.sciencedirect.com/science/article/pii/B9780128159484000073>. 59 RIESS, A. G. The expansion of the universe is faster than expected. Nature Reviews Physics, Nature Publishing Group, v. 2, n. 1, p. 10–12, 2020. 75 APÊNDICES APÊNDICE A — DISTÂNCIA DE LUMINOSIDADE. A relação entre o fluxo de luz e luminosidade é dada pela equação (5.84) F = L 4πd2 L , sendo L a luminosidade do corpo e dL a distância de luminosidade. Em um Universo em expan- são, podemos reescrever a equação acima em coordenadas comóveis como F = L(r) 4πr2 , (A.1) sendo r o raio comóvel de uma superfície esférica ao redor da fonte e L(r) a luminosidade medida passando por uma casca esférica com raio r. Precisamos relacionar L(r) com L. Para isso, notamos que a luminosidade é proporcional à energia dos fótons emitidos e, assim, deve ser inversamente proporcional ao comprimento de onda. Graças ao redshift sofrido pela luz, o comprimento de onda aumenta com o aumento do fator de escala a do Universo, de modo que λ(temitido) λ(tmedido) = a(temitido) a(tmedido) = a(temitido), (A.2) onde λ(temitido) e a(temitido) são, respectivamente, o comprimento de onda do fóton e o fator de escala do Universo no momento da emissão e λ(tmedido) e a(tmedido) ≡ 1 o comprimento de onda e fator de escala no momento da medição. Além disso, como o comprimento da casca esférica aumenta proporcionalmente a a, o número de fótons que cruzam a casca esférica em um intervalo de tempo cai com a. Desse modo, contabilizando ambos os efeitos e supondo que todos podemos associar a todos os fótons um mesmo comprimento de onda médio na emissão, o decréscimo na luminosidade medida é L L(r) = Eemitido Emedido = 1 a2(temitido), (A.3) portanto, omitindo a especificação do tempo de emissão, F = La2 4πr2 . (A.4) Igualando as equações (5.84) e (A.1), dL = r a = (1 + z)r, (A.5) onde usamos a equação (A.2) para definir o redshift z, 1 + z ≡ λ(temitido) λ(tmedido) . (A.6) 76 Para determinar r, usamos a métrica de FLRW, ds 2 = −c2dt 2 + a2(t) \u0012 dr2 1 − kr2 + r2dΩ \u0013 , (A.7) sendo k o parâmetro de curvatura espacial e dΩ2 = dθ2 + sin 2 θdφ2. (A.8) Para o percurso infinitesimal de um fóton, dr √1 − kr2 = cdt a(t), (A.9) se k = 0, r = Z t0 t cdt ′ a(t′) = Z z 0 cdz H(z) = c H0 Z z 0 dz E(z), (A.10) sendo t o instante da emissão e H o parâmetro de Hubble, dado a partir de uma das equações de Friedmann, H 2(z) = 1 a2(z) \u0012 da dt \u00132 = H 2 0 [Ωm(1 + z)3 + ΩΛ(1 + z) 3(1+w) + Ωk(1 + z) 2], (A.11) onde negligenciamos os efeitos da radiação eletromagnética e definimos Ωk como Ωk ≡ − kc2 H 2 0 , (A.12) tal que Ωm + ΩΛ + Ωk = 1. (A.13) No caso de k ̸= 0, temos r = c H0 1 √Ωk sinh \u0012p Ωk Z z 0 dz E(z) \u0013. (A.14) se k < 0, Ωk > 0 e r = c H0 1 p |Ωk| sinh\u0012 p |Ωk| Z z 0 dz E(z) \u0013; (A.15) se k > 0, Ωk < 0 e r = c H0 1 p |Ωk| sin\u0012 p |Ωk| Z z 0 dz E(z) \u0013 . (A.16) 77 Substituindo as equações (A.10), (A.15) e (A.16) em (A.5), deduzimos a expressão (5.86). 78 APÊNDICE B — INFORMAÇÕES DE HARDWARE, TEMPO DE PROCESSAMENTO E CÓDIGOS DESEN- VOLVIDOS Encontram-se aqui algumas informações relevantes a cerca do hardware utilizado, do processamento do algoritmo desenvolvido e o próprio script do algoritmo. Informações sobre o processador: • Modelo: Intel(R) Core(TM) i5-8250U; • Clock: 1,60GHz; • Núcleos: 4. Informações acerca do tempo de processamento do algoritmo de MCMC desenvolvido em cada utilização: • Caso gaussiano linear: 27,736 segundos; • Modelo A: 111,787 segundos; • Modelo B: 109,466 segundos; • Modelo C: 117, 334 segundos. Códigos escritos para o algoritmo de Metropolis-Hastings e para o cálculo de R. import numpy as np import scipy as sp from scipy.stats import multivariate_normal from numpy.random import default_rng rng = default_rng() def mcmc(data, y, x, cov, p_dim, lim, n_samples = 1000, prior = None, pdensity = False): \"\"\" Samples a gaussian posterior distribuition on the data based on the \\ Metropolis-Hastings algorithm. Parameters ---------- data: 1darray The data vector. y: function theorethical function to be compared with the data. x: 1darray independent variable of y. cov: 2darray covariance matrix of the data. 79 p_dim: int number of parameters to be estimated. lim: 2darray of the shape (p_dim, 2); interval in which each parameter will be sampled.\\ First parameter in params tuple refers to the first row and so on. n_samples: int number of samples wanted. It may not be achieved,\\ maximum number of tries is 60,000. prior: function. prior probability. If none is provided,\\ an uniform distribution in the provided limits will be considered.\\ Must be a function of all posterior parameters. pdensity: bool distribution from which the algorithm will collect the samples.\\ If set 'False', then it is an uniform distribution\\ in the provided limits, if it is set 'True', the algorithm will run\\ an exploratory chain to find the best covariance matrix and\\ will use as proposal density a gaussian distribution with\\ this covariance multiplied by 2.4/sqrt(p_dim). \"\"\" cov_inv= np.linalg.inv(cov) #inverse of the covariance matrix det_cov = np.linalg.det(cov) #determinant of the covariance matrix d = len(data) def Posterior(params): \"\"\"Posterior distribution\"\"\" distance = data - y(x, *params) #mahalanobis distance arg_1 = np.matmul(cov_inv, distance.T) arg = np.matmul(distance, arg_1) #argument of the exponential #likelihood function likelihood = (2 * np.pi)**(-d/2) * (det_cov)**(-1/2) * np.exp( -(1/2) * arg) if prior == None: post = likelihood #posterior distribution without any priors. else: post = prior(*params) *likelihood #posterior with priors return post def MH(value, pchain = False, cov_proposal = None): \"\"\" Metropolis Hastings algorithm. Parameters ---------- value: int number of elements in the chain. If it is an exploratory chain,\\ number of elements == n_samples/4. 80 pchain : bool Determines the proposal density. Default is 'False' and\\ the proposal density is uniform on the given interval.\\ If set 'True', the proposal density will be a multivariate\\ gaussian distribuition with its mean in last accepted element\\ of the chain and with a provided covariance matrix. cov_proposal: 2darray Covariance matrix of the gaussian proposal density.\\ If pchain is set 'True', then cov_proposal is\\ calculated. \"\"\" i = 0 #number of elements in the chain n= 0 #treshold value == 60,000 tries random_0 = np.empty(p_dim) #first element of the chain for j in range (p_dim): random_0[j] = (lim[j][1] - lim[j][0]) * rng.random(1) + lim[j][0] #first element samples = np.array([random_0]) #chain of the sampled values. #chain of posterior values calculate at the element chain = np.array([Posterior(random_0)]) while i <= value: random = np.empty(p_dim) if pchain == False: #possible next element for j in range (p_dim): random[j] = (lim[j][1] - lim[j][0]) * rng.random(1) + lim[j][0] else: #possible next element for j in range (p_dim): random[j] = rng.multivariate_normal(samples[i], cov_proposal)[j] n +=1 candidate = Posterior(random) #value of the posterior at the next element cadidate ratio = candidate/chain[i] #Test to determine if the proposed element will join the chain if ratio >=1: samples = np.concatenate((samples, [random])) i+=1 chain = np.concatenate((chain, [candidate])) else: random_test = (rng.random(1)) if ratio >= random_test: samples = np.concatenate((samples, [random])) i+=1 chain = np.concatenate((chain, [candidate])) if n == 60000: 81 break return samples if pdensity == False: #if there is no proposal density result = MH(n_samples) r= len(result) result = np.reshape(result, (r, p_dim)) else: #if there is a proposal density samples_proposal = MH(n_samples/4) p = len(samples_proposal) samples_proposal = np.reshape(samples_proposal, (p,p_dim)) cov_proposal = (2.4/ np.sqrt(p_dim)) * np.cov(samples_proposal, rowvar = False) result = MH(n_samples, pchain = True, cov_proposal = cov_proposal) r= len(result) result = np.reshape(result, (r, p_dim)) return result def R_test(chain, chain_amount): ''' Calculates the R factor of the Gelman-Rubin Convergence test. Parameters ---------- chain: 1darray Markov chain for a single parameter. chain_amount: int number of chains wanted. If the number of elements in the chain is not\\ divisible by chain_amount, then the first elements of the chain\\ are deleted so that the new chain is divisible by chain_amount. ''' num_rows = len(chain) #number of elements in the chain #number of elements in the new divisible chain N = int(chain_amount * np.floor((num_rows-100)/chain_amount)) j = int(num_rows - N) #number of elements to be deleted. samples = np.delete(chain, np.s_[0:j], 0) chains = samples.reshape((int(N/chain_amount), chain_amount)) mean_param = np.mean(chains) #mean of all elements mean_chain = np.mean(chains, axis = 0) #mean in each chain. var_chain = np.var(chains, axis =0) #variance in each chain var_mean = np.mean(var_chain) #mean of the variances. var_between_chains = np.var(mean_chain) #variance of the means in each chain R = (var_mean*(N-1)/N + var_between_chains * (1 + 1/chain_amount))/var_mean #R factor return R","libVersion":"0.3.2","langs":""}