Click here to see the [Live Lecture Hall Lesson](https://ocw.mit.edu/courses/6-041-probabilistic-systems-analysis-and-applied-probability-fall-2010/resources/lecture-4-counting/). 

![[L04.pdf]]

The probability of a given event $A$ over a sample space $\Omega$ that follows the [[1. Probability models and axioms#Discrete uniform law and Uniform probability law|discrete uniform law]] is
$$
P(A) = \frac{\text{number of elements of} A}{\text{number of elements of }\Omega}.
$$
It shall be useful to learn methods that will help us count these elements given a requirement or a description.

## Basic counting principle

Say we have $r$ different stages on which we must choose between $n_i$ options. The total number of states $s$ is
$$
s = \prod_{i = 1}^r n_i.
$$
For instance, the total number of states of the creation of license plates consisting of two letters followed by three digits is
$$
s = 26 \cdot 26 \cdot 10 \cdot 10 \cdot 10 = 6,76 \times 10^5.
$$

Another example is the ordering of $n$ elements. We can begin by choosing from $n$ elements one to be the first in our order. We follow by picking from $n-1$. This goes on until we have only one element to choose from.
$$
s = \prod_{i=1}^n i \overset{\text{def}}{=} n!.
$$
We are defining the factorial operator in the expression above. Therefore, the factorial of $n$ is defined as the number of **permutations** of $n$ distinct elements.

A final example is the total number of subsets in a set $\Omega$ that consistis of $n$ elements. The trick here is to think in a *binary* manner. For each element, we will classify them as being $\text{in}$ or $\text{out}$ of our subset. Therefore, we have $n$ stages, each with $2$ options. The total number of states is
$$
s = \prod_{i = 1}^n2 = 2^n.
$$
### Die roll example

What is the probability that six rolls of a six-sided die all give different numbers? To answer this question we must first assume that all outcomes of our die are equally likely. This will assure us that we are dealing with a sample space, $\Omega$, that follows the [[1. Probability models and axioms#Discrete uniform law and Uniform probability law|discrete uniform law]] with each trial being [[2. Conditioning and Independence#Independence|independent]]. Moreover, we shall call the event where all six rolls result in different numbers $A$. 

The total number of element in our sample space is
$$
s_{\Omega} = 6^6 = 46656.
$$
However, our subset $A$ consists of all permutations of six sides where no number repeats, *i.e.*,
$$
s_A = 6! = 720.
$$
Finally, the probability $P(A)$ is
$$
P(A) = \frac{s_A}{s_{\Omega}} = \frac{720}{46656} \approx 0.0154.
$$

## Combinations

Given a set of $n$ elements, the number of possible combinations of $k$ elements is defined as 
$$
\binom{n}{k}.
$$

To find this value, we begin by counting the number of **ordered** sequences of $k$ **distinct** items from our set. We fist choose from $n$ elements, then $n-1$, $n-2$, $n-3$, so on, until we fill all $n-k+1$ possible slots. By rewriting this process using factorials we find that
$$
n \cdot (n-1) \cdot (n-2) \cdots (n-k+1) = \frac{n!}{(n-k)!}.
$$Now, we shall count these **ordered** sequences from a different perspective. If we know that the number of possible combinations is $\binom{n}{k}$, and each subset has a number of $k!$ permutations. Therefore, the number of states is
$$
\binom{n}{k}\cdot k!.
$$
Since both of these possible ways yield the same result, we can solve for the combination of $k$ elements from $n$, finding
$$
\binom{n}{k} = \frac{n!}{k! (n- k)!}.
$$

![[L04E3.png]]

## Binomial probabilities

Suppose we conduct $n$ experiments with two possible outcomes, $A$ and $B$. $A$ and $B$ are [[2. Conditioning and Independence#Independence|independent]] from each other. The probability of outcome $A$ is $p$. We aim to determine the probability that out of these $n$ experiments, exactly $k$ result in outcome $A$.

Say we do six experiments. The probability of these outcomes turning out $A$, $B$, $B$, $B$, $B$, and $A$ is
$$
P(A \cap B \cap B \cap B \cap B \cap A) = p(1-p)(1-p)(1-p)(1-p)p = p^2(1-p)^4.
$$
This probability remains consistent for any sequence with two occurrences of outcome $A$. The [[1. Probability models and axioms#Examples of sample spaces#Discrete and finite|probability tree]] representing these six experiments illustrates various permutations where two $A$ outcomes appear in distinct orders. Thus, the overall probability of achieving two instances of outcome $A$ is calculated as $P(\text{two outcome} A) = p^2(1-p)^4 \cdot \text{\# of different A placements}$. We can envision the placement of outcome $A$ within our probability tree as selecting two positions from a total of six experiments, *i.e.*, $6 \choose{2}$.

Generalizing for every $k$ and $n$ the binomial probability is
$$
P(k; n, p) = p^k \cdot (1-p)^{n-k} \cdot \binom{n}{k}.
$$

### A coin tossing example

Given that there were three heads in ten tosse, what is the probability that the first two tosses were heads?

Assuming that each toss is [[2. Conditioning and Independence#Independence|independent]] and that $P(H) = p$ the [[2. Conditioning and Independence#Conditional probabilities|conditional probability]] is
$$
P(H\cap H | \text{3 heads}) = \frac{P(H\cap H\cap \text{Any combination of 7 tails and 1 head})}{P(\text{3 heads})}.
$$
The numerator can be written as the probability of two heads times the binomial probability of one head given eight tosses, $p^2 \times P(1; 8, p)$. The denominator is $P(3; 10, p)$. Replacing theses changes into the first expression yields:
$$
P(H \cap H | \text{3 heads}) = \frac{p^2 \binom{8}{1} p^1 (1-p)^7}{\binom{10}{3}p^3(1-p)^7} = \frac{\binom{8}{1}}{\binom{10}{3}} = \frac{1}{15}.
$$

***GPT Addendum:***
	 To find the probability of the first two tosses being heads given that there were three heads in ten tosses, we can approach it by counting the favorable outcomes where the first two tosses are heads and one head occurs in the subsequent eight tosses. This can be done by considering the combinations where we have three heads in total out of the ten tosses.1. First, let's count the number of ways the first two tosses can be heads. Since we are looking at the first two tosses, there are two tosses in total, and both need to result in heads. This gives us 1 way.
	 Next, let's count the total number of ways we can get three heads out of ten tosses. This is calculated using combinations, which is the number of ways to choose 3 heads out of 10 tosses.
	 By dividing the favorable outcomes (the first two tosses being heads) by the total outcomes  (three heads in ten tosses), we obtain the probability of the first two tosses being heads given that there were three heads in total out of ten tosses.

## Partitions

Given a set of $n$ elements we can redistribute these elements into $r$ sets each with $n_i$ elements. The sum of the elements distributed into each new set is equal to the original number of elements, *i.e.*,
$$
n = \sum_i^r n_i.
$$
The number of ways we can do this partitioning of elements is
$$
c = \frac{n!}{\prod_i^rn_r!}.
$$
**Proof:**
	 The permutation of $n$ elements is given by its factorial $n!$. However, we can also order these same elements in a indirect way. Given that $c$ is total number of ways we can partition these elements and that each partition can be ordered in $n_i!$ ways, the total number of permutations of the original set is
	 $$
	 n! = c \times n_1! \times n_2! \times \cdots \times n_r! = c \times \prod_i^rn_i.
	 $$
	 Solving the expression for $c$ we find the **multinomial coefficient**.
$\square$